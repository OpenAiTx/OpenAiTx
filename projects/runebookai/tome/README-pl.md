# Tome - Magiczna KsiÄ™ga ZaklÄ™Ä‡ AI

<img src="https://raw.githubusercontent.com/runebookai/tome/main/static/images/repo-header.png" alt="Tome" />

<p align="center">
    <code>magiczna aplikacja desktopowa, ktÃ³ra oddaje moc LLM i MCP w rÄ™ce kaÅ¼dego</code>
</p>

<p align="center">
    <a href="https://discord.gg/9CH6us29YA" target="_blank"><img src="https://img.shields.io/discord/1365100902561742868?logo=discord&logoColor=fff&label=Join%20Us!&color=9D7CD8" alt="DoÅ‚Ä…cz do nas na Discordzie" /></a>
    <a href="https://opensource.org/licenses/Apache-2.0" target="_blank"><img src="https://img.shields.io/badge/License-Apache_2.0-blue.svg" alt="Licencja: Apache 2.0" /></a>
    <a href="https://github.com/runebookai/tome/releases" target="_blank"><img src="https://img.shields.io/github/v/release/runebookai/tome" alt="Wydanie GitHub" /></a>
</p>

<p align="center">
    ğŸ”® Pobierz aplikacjÄ™ Tome Desktop: <a href="https://github.com/runebookai/tome/releases/download/0.6.0/Tome_0.6.0_x64-setup.exe">Windows</a> | <a href="https://github.com/runebookai/tome/releases/download/0.6.0/Tome_0.6.0_aarch64.dmg">MacOS</a>
</p>

# Tome

Tome to aplikacja desktopowa, ktÃ³ra pozwala **kaÅ¼demu** korzystaÄ‡ z magii LLM i MCP. Pobierz Tome, poÅ‚Ä…cz dowolny lokalny lub zdalny LLM i podÅ‚Ä…cz go do tysiÄ™cy serwerÃ³w MCP, aby stworzyÄ‡ wÅ‚asnÄ… magicznÄ… ksiÄ™gÄ™ zaklÄ™Ä‡ zasilanÄ… przez AI.

ğŸ«¥ Chcesz, aby wszystko dziaÅ‚aÅ‚o w 100% lokalnie i w 100% prywatnie? UÅ¼yj Ollama i Qwen3 wyÅ‚Ä…cznie z lokalnymi serwerami MCP, aby rzucaÄ‡ zaklÄ™cia w swoim wÅ‚asnym kieszonkowym uniwersum. âš¡ Chcesz korzystaÄ‡ z najnowoczeÅ›niejszych modeli w chmurze z najnowszymi zdalnymi serwerami MCP? TeÅ¼ moÅ¼esz to mieÄ‡. WybÃ³r naleÅ¼y do Ciebie!

ğŸ—ï¸ To jest Wersja Techniczna Preview, wiÄ™c miej na uwadze, Å¼e nie wszystko jest jeszcze dopracowane. [DoÅ‚Ä…cz do nas na Discordzie](https://discord.gg/9CH6us29YA), aby dzieliÄ‡ siÄ™ wskazÃ³wkami, trikami i zgÅ‚aszaÄ‡ napotkane problemy. Oznacz repozytorium gwiazdkÄ…, aby byÄ‡ na bieÅ¼Ä…co z aktualizacjami i nowoÅ›ciami!

## ğŸª„ Funkcje

- ğŸ§™ **Uproszczone, przyjazne dla poczÄ…tkujÄ…cych doÅ›wiadczenie**
  - Po prostu pobierz i zainstaluj Tome oraz podÅ‚Ä…cz wybrany przez siebie LLM
  - Bez grzebania w JSON, Dockerze, pythonie czy node
- ğŸ¤– **Wsparcie dla modeli AI**
  - **Zdalne**: Google Gemini, OpenAI, dowolny endpoint kompatybilny z API OpenAI
  - **Lokalne**: Ollama, LM Studio, Cortex, dowolny endpoint kompatybilny z API OpenAI
- ğŸ”® **Zaawansowane wsparcie MCP**
  - Interfejs do instalowania, usuwania, wÅ‚Ä…czania/wyÅ‚Ä…czania serwerÃ³w MCP
  - Serwery MCP npm, uvx, node, python obsÅ‚ugiwane od razu po instalacji
- ğŸª **Integracja z rejestrem [Smithery.ai](https://smithery.ai)**
  - TysiÄ…ce serwerÃ³w MCP dostÄ™pnych poprzez instalacjÄ™ jednym klikniÄ™ciem
- âœï¸ **Dostosowanie okien kontekstowych i temperatury**
- ğŸ§° **Nattywne wsparcie dla wywoÅ‚aÅ„ narzÄ™dzi i modeli rozumowania**
  - Ulepszenia UI, ktÃ³re wyraÅºnie rozrÃ³Å¼niajÄ… wywoÅ‚ania narzÄ™dzi i komunikaty myÅ›lowe

## Demo

https://github.com/user-attachments/assets/0775d100-3eba-4219-9e2f-360a01f28cce

# Pierwsze Kroki

## Wymagania

- MacOS lub Windows (Linux juÅ¼ wkrÃ³tce!)
- Dostawca LLM wedÅ‚ug wyboru: [Ollama](https://ollama.com/) lub [klucz API Gemini](https://aistudio.google.com/app/apikey) sÄ… Å‚atwe/darmowe
- [Pobierz najnowszÄ… wersjÄ™ Tome](https://github.com/runebookai/tome/releases)

## Szybki start

1. Zainstaluj [Tome](https://github.com/runebookai/tome/releases)
2. PodÅ‚Ä…cz preferowanego dostawcÄ™ LLM - OpenAI, Ollama i Gemini sÄ… ustawione domyÅ›lnie, ale moÅ¼esz teÅ¼ dodaÄ‡ dostawcÃ³w takich jak LM Studio, uÅ¼ywajÄ…c URL http://localhost:1234/v1
3. OtwÃ³rz zakÅ‚adkÄ™ MCP w Tome i zainstaluj swÃ³j pierwszy [serwer MCP](https://github.com/modelcontextprotocol/servers) (Fetch to prosty na poczÄ…tek, po prostu wklej `uvx mcp-server-fetch` w polu serwera).
4. Rozmawiaj z modelem zasilanym MCP! PoproÅ› go o pobranie najnowszej wiadomoÅ›ci z Hacker News.

# Wizja

Chcemy, aby lokalne LLM i MCP byÅ‚y dostÄ™pne dla kaÅ¼dego. Budujemy narzÄ™dzie, ktÃ³re pozwoli Ci byÄ‡ kreatywnym z LLM, niezaleÅ¼nie od tego, czy jesteÅ› inÅ¼ynierem, majsterkowiczem, hobbystÄ… czy kimkolwiek pomiÄ™dzy.

## Kluczowe zasady

- **Tome jest w pierwszej kolejnoÅ›ci lokalny:** Ty decydujesz, gdzie trafiajÄ… Twoje dane.
- **Tome jest dla wszystkich:** Nie musisz zarzÄ…dzaÄ‡ jÄ™zykami programowania, menedÅ¼erami pakietÃ³w ani plikami konfiguracyjnymi json.

## Co dalej

OtrzymaliÅ›my mnÃ³stwo niesamowitych opinii od czasu wydania Tome, ale mamy wielkie plany na przyszÅ‚oÅ›Ä‡. Chcemy uwolniÄ‡ LLM-y z ich okna czatu i mamy w planach wiele funkcji, ktÃ³re pomogÄ… Wam to osiÄ…gnÄ…Ä‡.

- Zadania zaplanowane: LLM-y powinny robiÄ‡ pomocne rzeczy nawet, gdy nie siedzisz przy komputerze.
- Natywne integracje: Serwery MCP to Å›wietny sposÃ³b na dostÄ™p do narzÄ™dzi i informacji, ale chcemy dodaÄ‡ jeszcze potÄ™Å¼niejsze integracje do unikalnej interakcji z LLM.
- Kreator aplikacji: Wierzymy, Å¼e docelowo najlepsze doÅ›wiadczenia nie bÄ™dÄ… w interfejsie czatu. Planujemy dodaÄ‡ dodatkowe narzÄ™dzia, ktÃ³re pozwolÄ… Ci tworzyÄ‡ zaawansowane aplikacje i przepÅ‚ywy pracy.
- ??? Daj nam znaÄ‡, co chciaÅ‚byÅ› zobaczyÄ‡! DoÅ‚Ä…cz do naszej spoÅ‚ecznoÅ›ci przez linki poniÅ¼ej, chÄ™tnie poznamy TwojÄ… opiniÄ™.

# SpoÅ‚ecznoÅ›Ä‡

[Discord](https://discord.gg/9CH6us29YA) [Blog](https://blog.runebook.ai) [Bluesky](https://bsky.app/profile/gettome.app) [Twitter](https://twitter.com/get_tome) 


---

Tranlated By [Open Ai Tx](https://github.com/OpenAiTx/OpenAiTx) | Last indexed: 2025-07-03

---