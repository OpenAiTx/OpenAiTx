<div align="center">

![thinking-spongebob](https://raw.githubusercontent.com/ruixin31/Spurious_Rewards/main/figs/thinking-spongebob.png)

# ğŸ’­ í—ˆìœ„ ë³´ìƒ: RLVRì—ì„œ í•™ìŠµ ì‹ í˜¸ ì¬ê³ í•˜ê¸°
  
[ìƒ¤ì˜¤ ë£¨ë¦°*](https://rulinshao.github.io/), [ë¦¬ ìŠˆìœ„ì— ìŠ¤í…”ë¼*](https://stellalisy.com/), [ì‹  ë£¨ì´*](https://ruixin31.github.io/), [ê²¡ ìŠ¤ì½§*](https://www.scottgeng.com/), [ì™• ì´í•‘](https://ypwang61.github.io/), [ì˜¤ ì„¸ì›…](https://homes.cs.washington.edu/~sewoong/), [ë‘ ì‹œëª¬ ìƒ¤ì˜¤ë ˆì´](https://simonshaoleidu.com/), [ë¨ë²„íŠ¸ ë„¤ì´ì„ ](https://www.natolambert.com/), [ë¯¼ ì„¸ì›](https://www.sewonmin.com/), [í¬ë¦¬ìŠˆë‚˜ ë€ì œì´](https://www.ranjaykrishna.com/index.html), [ì¸ ë² íŠ¸ì½”í”„ ìœ¨ë¦¬ì•„](https://homes.cs.washington.edu/~yuliats/), [í•˜ì§€ì‹œë¥´ì§€ í•˜ë‚œë„¤](https://homes.cs.washington.edu/~hannaneh/), [ì½” íŒ¡ì›¨ì´](https://koh.pw/), [ì œí‹€ë ˆëª¨ì´ì–´ ë£¨í¬](https://www.cs.washington.edu/people/faculty/luke-zettlemoyer/)
</div>

<div align="center">

[![Github](https://img.shields.io/badge/Github-000000?style=for-the-badge&logo=github&logoColor=000&logoColor=white)](https://github.com/ruixin31/Rethink_RLVR)
[![Website](https://img.shields.io/badge/Site-000000.svg?style=for-the-badge&logo=notion&logoColor=white)](https://rethink-rlvr.notion.site/Spurious-Rewards-Rethinking-Training-Signals-in-RLVR-1f4df34dac1880948858f95aeb88872f) 
[![Paper](https://img.shields.io/badge/Paper-000000.svg?style=for-the-badge&logo=arxiv&logoColor=white)](http://arxiv.org/abs/2506.10947) 
[![Twitter](https://img.shields.io/badge/Twitter-000000?style=for-the-badge&logo=x&logoColor=white)](https://x.com/StellaLisy/status/1927392717593526780)
[![Wandb](https://img.shields.io/badge/ğŸ“_reproduction_W&B-000000?style=for-the-badge&logo=wandb&logoColor=white)](https://wandb.ai/rx31/SpuriousRewardRLVR)
[![Models](https://img.shields.io/badge/Models-000000?style=for-the-badge&logo=huggingface&logoColor=white)](https://huggingface.co/collections/stellalisy/spurious-rewards-684a38b8eeb32273c287a4db)

</div>


## í™˜ê²½ ì„¤ì •

```sh
# Our codebase is based on TTRL (https://github.com/PRIME-RL/TTRL).
git clone git@github.com:ruixin31/Spurious_Rewards
cd code

conda create -n spurious-rewards python=3.10 
conda activate spurious-rewards

pip install -r requirements.txt
pip install flash_attn==2.7.0.post2
pip install -e .
```
## êµìœ¡

```sh
bash scripts/rlvr_deepscaler_grpo_qwen_ground_truth.sh
```
## ì„¤ì •

### ë°ì´í„°
ë…¼ë¬¸ì—ëŠ” í•„í„°ë§ëœ ë°ì´í„°ì™€ ë‹¤ìˆ˜ê²° ë¼ë²¨ ë°ì´í„°ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì „ì²´ ëª©ë¡ì€ `code/data` ë””ë ‰í† ë¦¬ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì •ë‹µ ë°ì´í„°ëŠ” `DeepScaleR`ë¡œ ëª…ëª…ë˜ì–´ ìˆê³ , Llama 3.2 3B instruct ë¼ë²¨ ë°ì´í„° ì¤‘ ì˜¤ë‹µ ë¼ë²¨ë§Œ í•„í„°ë§í•œ ë°ì´í„°ëŠ” `DeepScaleR_mv_labeled_llama3.2_3b_instruct_incorrect` í´ë”ì— ìˆìŠµë‹ˆë‹¤. ë°ì´í„° ì†ŒìŠ¤ëŠ” `code/scripts/rlvr_deepscaler_grpo_qwen_ground_truth.sh` íŒŒì¼ì˜ `TASK` ë³€ìˆ˜ë¥¼ ë³€ê²½í•˜ì—¬ ë°”ê¿€ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ë³´ìƒ
ë…¼ë¬¸ì—ì„œ ì‚¬ìš©ëœ ë³´ìƒ ëª©ë¡ì„ ì•„ë˜ì— í¬í•¨í•˜ì˜€ìŠµë‹ˆë‹¤. ë˜í•œ, ì±— í…œí”Œë¦¿ì´ ì—†ëŠ” ëª¨ë¸ì˜ ê²½ìš°, ë°˜ë“œì‹œ ì ‘ë¯¸ì‚¬ë¡œ `_r1_only`ë¥¼ ì¶”ê°€í•´ì•¼ í•©ë‹ˆë‹¤. ë³´ìƒ í•¨ìˆ˜ëŠ” `code/scripts/rlvr_deepscaler_grpo_qwen_ground_truth.sh` íŒŒì¼ì˜ `REWARD` ë³€ìˆ˜ë¥¼ ë³€ê²½í•˜ì—¬ ë°”ê¿€ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

- `math`: ìˆ˜í•™ì  ë™ë“±ì„± ë³´ìƒ(ê¸°ë³¸ê°’)
- `box_only_format`: ë°•ìŠ¤ ì „ìš© í˜•ì‹ ë³´ìƒ
- `contain_python_wo_backticks`: Python ì–¸ê¸‰ ë³´ìƒ
- `random0.5`: 50% í™•ë¥ ë¡œ 1ì„ ë°˜í™˜í•˜ëŠ” ëœë¤ ë³´ìƒ

## í‰ê°€
í‰ê°€ ê²°ê³¼ë¥¼ ì¬í˜„í•˜ë ¤ë©´ ë‹¤ìŒ ëª…ë ¹ì–´ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”:



```sh
cd code

# For MATH-500 evaluation (requires NVIDIA A100 80GB PCIe for exact reproduction)
python scripts/eval_checkpoint.py --model_path Qwen/Qwen2.5-Math-7B --datasets MATH-500,AIME-2024,AIME-2025,AMC

# For MATH-500 evaluation matching our reported scores in wandb using checkpoints (requires NVIDIA H200 for exact reproduction)
python scripts/eval_checkpoint.py --model_path {} --datasets MATH-500,AIME-2024,AIME-2025,AMC --shards 2
```
ì°¸ê³ : `temperature = 0` ê²°ê³¼ë¥¼ ì •í™•í•˜ê²Œ ì¬í˜„í•˜ë ¤ë©´, GPU ìœ í˜•ê³¼ `--shards` íŒŒë¼ë¯¸í„°ê°€ ì›ë˜ í‰ê°€ ì„¤ì •ê³¼ ì¼ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤. ì´ëŠ” VLLMì— ì „ë‹¬ë˜ëŠ” ë°°ì¹˜ í¬ê¸°ê°€ ìƒì„± ê²°ê³¼ì— ë³€ë™ì„ ì¼ìœ¼í‚¬ ìˆ˜ ìˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.

## ë…¼ë¬¸

[ì—¬ê¸° ë§í¬](http://arxiv.org/abs/2506.10947)ì—ì„œ ë…¼ë¬¸ì„ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ì¸ìš©


```bibtex
@misc{shao2025spuriousrewardsrethinkingtraining,
      title={Spurious Rewards: Rethinking Training Signals in RLVR}, 
      author={Rulin Shao and Shuyue Stella Li and Rui Xin and Scott Geng and Yiping Wang and Sewoong Oh and Simon Shaolei Du and Nathan Lambert and Sewon Min and Ranjay Krishna and Yulia Tsvetkov and Hannaneh Hajishirzi and Pang Wei Koh and Luke Zettlemoyer},
      year={2025},
      eprint={2506.10947},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2506.10947}, 
}
```
## ê°ì‚¬ì˜ ë§ì”€
ì´ ì €ì¥ì†ŒëŠ” [TTRL](https://github.com/PRIME-RL/TTRL)ì„ ê¸°ë°˜ìœ¼ë¡œ êµ¬ì¶•ë˜ì—ˆìœ¼ë©°, TTRLì€ [OpenRLHF](https://github.com/OpenRLHF/OpenRLHF)ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•©ë‹ˆë‹¤.
ìš°ë¦¬ëŠ” ì½”ë“œë² ì´ìŠ¤ì— ë¹„ë™ê¸° í‰ê°€ì™€ ê¸°íƒ€ ë§ì¶¤í˜• ê¸°ëŠ¥ì„ ì¶”ê°€í•˜ì˜€ìŠµë‹ˆë‹¤.


---

Tranlated By [Open Ai Tx](https://github.com/OpenAiTx/OpenAiTx) | Last indexed: 2025-07-14

---