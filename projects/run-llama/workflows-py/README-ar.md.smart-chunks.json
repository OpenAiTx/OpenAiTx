[
  {
    "Id": 1,
    "Content": "# LlamaIndex Workflows\n\n[![Unit Testing](https://github.com/run-llama/workflows/actions/workflows/test.yml/badge.svg)](https://github.com/run-llama/workflows/actions/workflows/test.yml)\n[![Coverage Status](https://coveralls.io/repos/github/run-llama/workflows/badge.svg?branch=main)](https://coveralls.io/github/run-llama/workflows?branch=main)\n[![GitHub contributors](https://img.shields.io/github/contributors/run-llama/workflows)](https://github.com/run-llama/llama-index-workflows/graphs/contributors)\n\n\n[![PyPI - Downloads](https://img.shields.io/pypi/dm/llama-index-workflows)](https://pypi.org/project/llama-index-workflows/)\n[![Discord](https://img.shields.io/discord/1059199217496772688)](https://discord.gg/dGcwcsnxhU)\n[![Twitter](https://img.shields.io/twitter/follow/llama_index)](https://x.com/llama_index)\n[![Reddit](https://img.shields.io/reddit/subreddit-subscribers/LlamaIndex?style=plastic&logo=reddit&label=r%2FLlamaIndex&labelColor=white)](https://www.reddit.com/r/LlamaIndex/)\n\nLlamaIndex Workflows are a framework for orchestrating and chaining together complex systems of steps and events.\n\n## What can you build with Workflows?\n\nWorkflows shine when you need to orchestrate complex, multi-step processes that involve AI models, APIs, and decision-making. Here are some examples of what you can build:\n\n- **AI Agents** - Create intelligent systems that can reason, make decisions, and take actions across multiple steps\n- **Document Processing Pipelines** - Build systems that ingest, analyze, summarize, and route documents through various processing stages\n- **Multi-Model AI Applications** - Coordinate between different AI models (LLMs, vision models, etc.) to solve complex tasks\n- **Research Assistants** - Develop workflows that can search, analyze, synthesize information, and provide comprehensive answers\n- **Content Generation Systems** - Create pipelines that generate, review, edit, and publish content with human-in-the-loop approval\n- **Customer Support Automation** - Build intelligent routing systems that can understand, categorize, and respond to customer inquiries\n\nThe async-first, event-driven architecture makes it easy to build workflows that can route between different capabilities, implement parallel processing patterns, loop over complex sequences, and maintain state across multiple steps - all the features you need to make your AI applications production-ready.\n",
    "ContentSha": "PrOw0sXCtw/kMf6D4N5eKll4XAnD3LIP64BH4KmOS5g=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "# سير عمل LlamaIndex\n\n[![اختبار الوحدات](https://github.com/run-llama/workflows/actions/workflows/test.yml/badge.svg)](https://github.com/run-llama/workflows/actions/workflows/test.yml)\n[![حالة التغطية](https://coveralls.io/repos/github/run-llama/workflows/badge.svg?branch=main)](https://coveralls.io/github/run-llama/workflows?branch=main)\n[![مساهمو GitHub](https://img.shields.io/github/contributors/run-llama/workflows)](https://github.com/run-llama/llama-index-workflows/graphs/contributors)\n\n[![تنزيلات PyPI](https://img.shields.io/pypi/dm/llama-index-workflows)](https://pypi.org/project/llama-index-workflows/)\n[![ديسكورد](https://img.shields.io/discord/1059199217496772688)](https://discord.gg/dGcwcsnxhU)\n[![تويتر](https://img.shields.io/twitter/follow/llama_index)](https://x.com/llama_index)\n[![ريديت](https://img.shields.io/reddit/subreddit-subscribers/LlamaIndex?style=plastic&logo=reddit&label=r%2FLlamaIndex&labelColor=white)](https://www.reddit.com/r/LlamaIndex/)\n\nسير عمل LlamaIndex هو إطار عمل لتنظيم وربط أنظمة معقدة من الخطوات والأحداث معًا.\n\n## ماذا يمكنك أن تبني باستخدام سير العمل؟\n\nيتميز سير العمل عندما تحتاج إلى تنظيم عمليات متعددة الخطوات ومعقدة تتضمن نماذج الذكاء الاصطناعي وواجهات برمجة التطبيقات واتخاذ القرار. فيما يلي بعض الأمثلة على ما يمكنك بناؤه:\n\n- **وكلاء الذكاء الاصطناعي** - إنشاء أنظمة ذكية يمكنها الاستنتاج واتخاذ القرارات وتنفيذ الإجراءات عبر خطوات متعددة\n- **خطوط معالجة المستندات** - بناء أنظمة تستوعب وتحلل وتلخص وتوجه المستندات عبر مراحل معالجة مختلفة\n- **تطبيقات الذكاء الاصطناعي متعددة النماذج** - التنسيق بين نماذج ذكاء اصطناعي مختلفة (نماذج اللغة الكبيرة، نماذج الرؤية، إلخ) لحل مهام معقدة\n- **مساعدو البحث** - تطوير سير عمل يمكنه البحث والتحليل وتوليف المعلومات وتقديم إجابات شاملة\n- **أنظمة توليد المحتوى** - إنشاء خطوط عمل لإنتاج ومراجعة وتحرير ونشر المحتوى مع وجود موافقة بشرية في الحلقة\n- **أتمتة دعم العملاء** - بناء أنظمة توجيه ذكية يمكنها فهم وتصنيف والرد على استفسارات العملاء\n\nتجعل بنية العمل المعتمدة على الأحداث والتزامن السهل من بناء سير عمل يمكنه التوجيه بين قدرات مختلفة، وتنفيذ أنماط المعالجة المتوازية، والتكرار عبر تسلسلات معقدة، والحفاظ على الحالة عبر خطوات متعددة - كل الميزات التي تحتاجها لجعل تطبيقات الذكاء الاصطناعي الخاصة بك جاهزة للإنتاج.",
    "Status": "ok"
  },
  {
    "Id": 2,
    "Content": "## Key Features\n\n- **async-first** - workflows are built around python's async functionality - steps are async functions that process incoming events from an asyncio queue and emit new events to other queues. This also means that workflows work best in your async apps like FastAPI, Jupyter Notebooks, etc.\n- **event-driven** - workflows consist of steps and events. Organizing your code around events and steps makes it easier to reason about and test.\n- **state management** - each run of a workflow is self-contained, meaning you can launch a workflow, save information within it, serialize the state of a workflow and resume it later.\n- **observability** - workflows are automatically instrumented for observability, meaning you can use tools like `Arize Phoenix` and `OpenTelemetry` right out of the box.\n\n## Quick Start\n\nInstall the package:\n\n```bash\npip install llama-index-workflows\n```\n\nAnd create your first workflow:\n\n```python\nimport asyncio\nfrom pydantic import BaseModel, Field\nfrom workflows import Context, Workflow, step\nfrom workflows.events import Event, StartEvent, StopEvent\n\nclass MyEvent(Event):\n    msg: list[str]\n\nclass RunState(BaseModel):\n    num_runs: int = Field(default=0)\n\nclass MyWorkflow(Workflow):\n    @step\n    async def start(self, ctx: Context[RunState], ev: StartEvent) -> MyEvent:\n        async with ctx.store.edit_state() as state:\n            state.num_runs += 1\n\n            return MyEvent(msg=[ev.input_msg] * state.num_runs)\n\n    @step\n    async def process(self, ctx: Context[RunState], ev: MyEvent) -> StopEvent:\n        data_length = len(\"\".join(ev.msg))\n        new_msg = f\"Processed {len(ev.msg)} times, data length: {data_length}\"\n        return StopEvent(result=new_msg)\n\nasync def main():\n    workflow = MyWorkflow()\n",
    "ContentSha": "2y3u8OCMQZxV5p9IHLSVu9zwJnNilh9ufQ0F3eUU8bo=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "## الميزات الرئيسية\n\n- **البرمجة غير المتزامنة أولاً (async-first)** - يتم بناء سير العمل حول وظائف بايثون غير المتزامنة (async) - الخطوات هي دوال غير متزامنة تعالج الأحداث الواردة من قائمة انتظار asyncio وتصدر أحداثًا جديدة إلى قوائم انتظار أخرى. هذا يعني أيضًا أن سير العمل يعمل بشكل أفضل في تطبيقاتك غير المتزامنة مثل FastAPI ودفاتر Jupyter وغيرها.\n- **مدفوع بالأحداث (event-driven)** - يتكون سير العمل من خطوات وأحداث. تنظيم الكود الخاص بك حول الأحداث والخطوات يجعل من السهل فهمه واختباره.\n- **إدارة الحالة (state management)** - كل تشغيل لسير العمل مستقل بذاته، مما يعني أنه يمكنك تشغيل سير عمل، حفظ المعلومات بداخله، تسلسل حالة سير العمل واستئنافها لاحقًا.\n- **قابلية الرصد (observability)** - يتم تجهيز سير العمل تلقائيًا لقابلية الرصد، مما يعني أنه يمكنك استخدام أدوات مثل `Arize Phoenix` و `OpenTelemetry` مباشرة دون إعداد إضافي.\n\n## البدء السريع\n\nقم بتثبيت الحزمة:\n\n```bash\npip install llama-index-workflows\n```\n\nوأنشئ أول سير عمل لك:\n\n```python\nimport asyncio\nfrom pydantic import BaseModel, Field\nfrom workflows import Context, Workflow, step\nfrom workflows.events import Event, StartEvent, StopEvent\n\nclass MyEvent(Event):\n    msg: list[str]\n\nclass RunState(BaseModel):\n    num_runs: int = Field(default=0)\n\nclass MyWorkflow(Workflow):\n    @step\n    async def start(self, ctx: Context[RunState], ev: StartEvent) -> MyEvent:\n        async with ctx.store.edit_state() as state:\n            state.num_runs += 1\n\n            return MyEvent(msg=[ev.input_msg] * state.num_runs)\n\n    @step\n    async def process(self, ctx: Context[RunState], ev: MyEvent) -> StopEvent:\n        data_length = len(\"\".join(ev.msg))\n        new_msg = f\"Processed {len(ev.msg)} times, data length: {data_length}\"\n        return StopEvent(result=new_msg)\n\nasync def main():\n    workflow = MyWorkflow()\n```",
    "Status": "ok"
  },
  {
    "Id": 3,
    "Content": "    # [optional] provide a context object to the workflow\n    ctx = Context(workflow)\n    result = await workflow.run(input_msg=\"Hello, world!\", ctx=ctx)\n    print(\"Workflow result:\", result)\n\n    # re-running with the same context will retain the state\n    result = await workflow.run(input_msg=\"Hello, world!\", ctx=ctx)\n    print(\"Workflow result:\", result)\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```\n\nIn the example above\n- Steps that accept a `StartEvent` will be run first.\n- Steps that return a `StopEvent` will end the workflow.\n- Intermediate events are user defined and can be used to pass information between steps.\n- The `Context` object is also used to share information between steps.\n\nVisit the [complete documentation](https://docs.llamaindex.ai/en/stable/understanding/workflows/) for more examples using `llama-index`!\n",
    "ContentSha": "uyQUuCIsjVJreK2NjTBRYDljiKMj85DiFJfof3LjHfg=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "    # [اختياري] توفير كائن السياق إلى سير العمل\n    ctx = Context(workflow)\n    result = await workflow.run(input_msg=\"Hello, world!\", ctx=ctx)\n    print(\"نتيجة سير العمل:\", result)\n\n    # إعادة التشغيل بنفس السياق سيحتفظ بالحالة\n    result = await workflow.run(input_msg=\"Hello, world!\", ctx=ctx)\n    print(\"نتيجة سير العمل:\", result)\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```\n\nفي المثال أعلاه\n- الخطوات التي تقبل `StartEvent` سيتم تشغيلها أولاً.\n- الخطوات التي تُرجع `StopEvent` ستُنهي سير العمل.\n- الأحداث الوسيطة يحددها المستخدم ويمكن استخدامها لنقل المعلومات بين الخطوات.\n- يُستخدم كائن `Context` أيضًا لمشاركة المعلومات بين الخطوات.\n\nقم بزيارة [التوثيق الكامل](https://docs.llamaindex.ai/en/stable/understanding/workflows/) لمزيد من الأمثلة باستخدام `llama-index`!\n",
    "Status": "ok"
  },
  {
    "Id": 4,
    "Content": "## More examples\n\n- [Basic Feature Run-Through](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/feature_walkthrough.ipynb)\n- [Building a Function Calling Agent with `llama-index`](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/agent.ipynb)\n- [Human-in-the-loop Iterative Document Extraction](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/document_processing.ipynb)\n- Observability\n  - [OpenTelemetry + Instrumentation Primer](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/observability/workflows_observability_pt1.ipynb)\n  - [OpenTelemetry + LlamaIndex](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/observability/workflows_observability_pt2.ipynb)\n  - [Arize Phoenix + LlamaIndex](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/observability/workflows_observablitiy_arize_phoenix.ipynb)\n  - [Langfuse + LlamaIndex](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/observability/workflows_observablitiy_langfuse.ipynb)\n\n## Related Packages\n\n- [Typescript Workflows](https://github.com/run-llama/workflows-ts)\n",
    "ContentSha": "DXwxZAa92R4ZF5bTYguiDm43cfYLGufWuZ5d/mzsQ24=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "## المزيد من الأمثلة\n\n- [استعراض الميزات الأساسية](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/feature_walkthrough.ipynb)\n- [بناء وكيل استدعاء الدوال باستخدام `llama-index`](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/agent.ipynb)\n- [استخراج المستندات التكراري بمشاركة الإنسان في الحلقة](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/document_processing.ipynb)\n- قابلية الملاحظة\n  - [مقدمة عن OpenTelemetry + الأدوات](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/observability/workflows_observability_pt1.ipynb)\n  - [OpenTelemetry + LlamaIndex](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/observability/workflows_observability_pt2.ipynb)\n  - [Arize Phoenix + LlamaIndex](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/observability/workflows_observablitiy_arize_phoenix.ipynb)\n  - [Langfuse + LlamaIndex](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/observability/workflows_observablitiy_langfuse.ipynb)\n\n## الحزم ذات الصلة\n\n- [مهام العمل Typescript](https://github.com/run-llama/workflows-ts)\n",
    "Status": "ok"
  }
]