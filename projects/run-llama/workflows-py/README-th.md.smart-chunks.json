[
  {
    "Id": 1,
    "Content": "# LlamaIndex Workflows\n\n[![Unit Testing](https://github.com/run-llama/workflows/actions/workflows/test.yml/badge.svg)](https://github.com/run-llama/workflows/actions/workflows/test.yml)\n[![Coverage Status](https://coveralls.io/repos/github/run-llama/workflows/badge.svg?branch=main)](https://coveralls.io/github/run-llama/workflows?branch=main)\n[![GitHub contributors](https://img.shields.io/github/contributors/run-llama/workflows)](https://github.com/run-llama/llama-index-workflows/graphs/contributors)\n\n\n[![PyPI - Downloads](https://img.shields.io/pypi/dm/llama-index-workflows)](https://pypi.org/project/llama-index-workflows/)\n[![Discord](https://img.shields.io/discord/1059199217496772688)](https://discord.gg/dGcwcsnxhU)\n[![Twitter](https://img.shields.io/twitter/follow/llama_index)](https://x.com/llama_index)\n[![Reddit](https://img.shields.io/reddit/subreddit-subscribers/LlamaIndex?style=plastic&logo=reddit&label=r%2FLlamaIndex&labelColor=white)](https://www.reddit.com/r/LlamaIndex/)\n\nLlamaIndex Workflows are a framework for orchestrating and chaining together complex systems of steps and events.\n\n## What can you build with Workflows?\n\nWorkflows shine when you need to orchestrate complex, multi-step processes that involve AI models, APIs, and decision-making. Here are some examples of what you can build:\n\n- **AI Agents** - Create intelligent systems that can reason, make decisions, and take actions across multiple steps\n- **Document Processing Pipelines** - Build systems that ingest, analyze, summarize, and route documents through various processing stages\n- **Multi-Model AI Applications** - Coordinate between different AI models (LLMs, vision models, etc.) to solve complex tasks\n- **Research Assistants** - Develop workflows that can search, analyze, synthesize information, and provide comprehensive answers\n- **Content Generation Systems** - Create pipelines that generate, review, edit, and publish content with human-in-the-loop approval\n- **Customer Support Automation** - Build intelligent routing systems that can understand, categorize, and respond to customer inquiries\n\nThe async-first, event-driven architecture makes it easy to build workflows that can route between different capabilities, implement parallel processing patterns, loop over complex sequences, and maintain state across multiple steps - all the features you need to make your AI applications production-ready.\n",
    "ContentSha": "PrOw0sXCtw/kMf6D4N5eKll4XAnD3LIP64BH4KmOS5g=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "# LlamaIndex Workflows\n\n[![Unit Testing](https://github.com/run-llama/workflows/actions/workflows/test.yml/badge.svg)](https://github.com/run-llama/workflows/actions/workflows/test.yml)\n[![Coverage Status](https://coveralls.io/repos/github/run-llama/workflows/badge.svg?branch=main)](https://coveralls.io/github/run-llama/workflows?branch=main)\n[![GitHub contributors](https://img.shields.io/github/contributors/run-llama/workflows)](https://github.com/run-llama/llama-index-workflows/graphs/contributors)\n\n\n[![PyPI - Downloads](https://img.shields.io/pypi/dm/llama-index-workflows)](https://pypi.org/project/llama-index-workflows/)\n[![Discord](https://img.shields.io/discord/1059199217496772688)](https://discord.gg/dGcwcsnxhU)\n[![Twitter](https://img.shields.io/twitter/follow/llama_index)](https://x.com/llama_index)\n[![Reddit](https://img.shields.io/reddit/subreddit-subscribers/LlamaIndex?style=plastic&logo=reddit&label=r%2FLlamaIndex&labelColor=white)](https://www.reddit.com/r/LlamaIndex/)\n\nLlamaIndex Workflows เป็นเฟรมเวิร์กสำหรับการจัดลำดับและเชื่อมโยงระบบที่ซับซ้อนของขั้นตอนและเหตุการณ์เข้าด้วยกัน\n\n## คุณสามารถสร้างอะไรกับ Workflows ได้บ้าง?\n\nWorkflows โดดเด่นเมื่อคุณต้องการจัดลำดับกระบวนการที่ซับซ้อนหลายขั้นตอนซึ่งเกี่ยวข้องกับโมเดล AI, API และการตัดสินใจ ตัวอย่างเช่นสิ่งที่คุณสามารถสร้างได้มีดังนี้:\n\n- **AI Agents** - สร้างระบบอัจฉริยะที่สามารถให้เหตุผล ตัดสินใจ และดำเนินการต่าง ๆ ได้ในหลายขั้นตอน\n- **Document Processing Pipelines** - สร้างระบบที่รับเข้า วิเคราะห์ สรุป และส่งต่อเอกสารผ่านหลายขั้นตอนการประมวลผล\n- **Multi-Model AI Applications** - ประสานงานระหว่างโมเดล AI ต่าง ๆ (LLMs, vision models ฯลฯ) เพื่อแก้ไขงานที่ซับซ้อน\n- **Research Assistants** - พัฒนา workflows ที่สามารถค้นหา วิเคราะห์ สังเคราะห์ข้อมูล และให้คำตอบที่ครอบคลุม\n- **Content Generation Systems** - สร้าง pipeline ที่สร้าง ทบทวน แก้ไข และเผยแพร่เนื้อหาพร้อมการอนุมัติจากมนุษย์ในวงจร\n- **Customer Support Automation** - สร้างระบบการจัดเส้นทางอัจฉริยะที่สามารถเข้าใจ จัดหมวดหมู่ และตอบสนองต่อคำถามของลูกค้า\n\nสถาปัตยกรรมแบบ async-first และ event-driven นี้ ทำให้ง่ายต่อการสร้าง workflows ที่สามารถสลับการทำงานระหว่างความสามารถต่าง ๆ, ใช้รูปแบบการประมวลผลแบบขนาน, วนซ้ำตามลำดับที่ซับซ้อน, และคงสถานะข้ามหลายขั้นตอน — ครบทุกฟีเจอร์ที่คุณต้องการเพื่อให้แอปพลิเคชัน AI ของคุณพร้อมใช้งานในระดับ production",
    "Status": "ok"
  },
  {
    "Id": 2,
    "Content": "## Key Features\n\n- **async-first** - workflows are built around python's async functionality - steps are async functions that process incoming events from an asyncio queue and emit new events to other queues. This also means that workflows work best in your async apps like FastAPI, Jupyter Notebooks, etc.\n- **event-driven** - workflows consist of steps and events. Organizing your code around events and steps makes it easier to reason about and test.\n- **state management** - each run of a workflow is self-contained, meaning you can launch a workflow, save information within it, serialize the state of a workflow and resume it later.\n- **observability** - workflows are automatically instrumented for observability, meaning you can use tools like `Arize Phoenix` and `OpenTelemetry` right out of the box.\n\n## Quick Start\n\nInstall the package:\n\n```bash\npip install llama-index-workflows\n```\n\nAnd create your first workflow:\n\n```python\nimport asyncio\nfrom pydantic import BaseModel, Field\nfrom workflows import Context, Workflow, step\nfrom workflows.events import Event, StartEvent, StopEvent\n\nclass MyEvent(Event):\n    msg: list[str]\n\nclass RunState(BaseModel):\n    num_runs: int = Field(default=0)\n\nclass MyWorkflow(Workflow):\n    @step\n    async def start(self, ctx: Context[RunState], ev: StartEvent) -> MyEvent:\n        async with ctx.store.edit_state() as state:\n            state.num_runs += 1\n\n            return MyEvent(msg=[ev.input_msg] * state.num_runs)\n\n    @step\n    async def process(self, ctx: Context[RunState], ev: MyEvent) -> StopEvent:\n        data_length = len(\"\".join(ev.msg))\n        new_msg = f\"Processed {len(ev.msg)} times, data length: {data_length}\"\n        return StopEvent(result=new_msg)\n\nasync def main():\n    workflow = MyWorkflow()\n",
    "ContentSha": "2y3u8OCMQZxV5p9IHLSVu9zwJnNilh9ufQ0F3eUU8bo=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "## คุณสมบัติเด่น\n\n- **async-first** - เวิร์กโฟลว์ถูกสร้างขึ้นโดยอิงกับฟังก์ชัน async ของ Python - แต่ละขั้นตอนเป็นฟังก์ชัน async ที่ประมวลผลอีเวนต์ขาเข้าจากคิว asyncio และส่งอีเวนต์ใหม่ไปยังคิวอื่นๆ ซึ่งหมายความว่าเวิร์กโฟลว์จะทำงานได้ดีที่สุดในแอป async ของคุณ เช่น FastAPI, Jupyter Notebooks ฯลฯ\n- **event-driven** - เวิร์กโฟลว์ประกอบด้วยขั้นตอนและอีเวนต์ การจัดระเบียบโค้ดของคุณโดยอิงกับอีเวนต์และขั้นตอนทำให้ง่ายต่อการทำความเข้าใจและทดสอบ\n- **state management** - การรันแต่ละครั้งของเวิร์กโฟลว์จะแยกออกจากกันโดยสมบูรณ์ หมายความว่าคุณสามารถเริ่มเวิร์กโฟลว์ บันทึกข้อมูลภายในเวิร์กโฟลว์นั้น ทำการ serialize สถานะของเวิร์กโฟลว์ และกลับมาทำงานต่อในภายหลังได้\n- **observability** - เวิร์กโฟลว์จะถูกติดตั้งเครื่องมือสำหรับตรวจสอบสภาพการทำงานโดยอัตโนมัติ คุณจึงสามารถใช้เครื่องมืออย่าง `Arize Phoenix` และ `OpenTelemetry` ได้ทันที\n\n## เริ่มต้นอย่างรวดเร็ว\n\nติดตั้งแพ็กเกจ:\n\n```bash\npip install llama-index-workflows\n```\n\nและสร้างเวิร์กโฟลว์แรกของคุณ:\n\n```python\nimport asyncio\nfrom pydantic import BaseModel, Field\nfrom workflows import Context, Workflow, step\nfrom workflows.events import Event, StartEvent, StopEvent\n\nclass MyEvent(Event):\n    msg: list[str]\n\nclass RunState(BaseModel):\n    num_runs: int = Field(default=0)\n\nclass MyWorkflow(Workflow):\n    @step\n    async def start(self, ctx: Context[RunState], ev: StartEvent) -> MyEvent:\n        async with ctx.store.edit_state() as state:\n            state.num_runs += 1\n\n            return MyEvent(msg=[ev.input_msg] * state.num_runs)\n\n    @step\n    async def process(self, ctx: Context[RunState], ev: MyEvent) -> StopEvent:\n        data_length = len(\"\".join(ev.msg))\n        new_msg = f\"Processed {len(ev.msg)} times, data length: {data_length}\"\n        return StopEvent(result=new_msg)\n\nasync def main():\n    workflow = MyWorkflow()\n```",
    "Status": "ok"
  },
  {
    "Id": 3,
    "Content": "    # [optional] provide a context object to the workflow\n    ctx = Context(workflow)\n    result = await workflow.run(input_msg=\"Hello, world!\", ctx=ctx)\n    print(\"Workflow result:\", result)\n\n    # re-running with the same context will retain the state\n    result = await workflow.run(input_msg=\"Hello, world!\", ctx=ctx)\n    print(\"Workflow result:\", result)\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```\n\nIn the example above\n- Steps that accept a `StartEvent` will be run first.\n- Steps that return a `StopEvent` will end the workflow.\n- Intermediate events are user defined and can be used to pass information between steps.\n- The `Context` object is also used to share information between steps.\n\nVisit the [complete documentation](https://docs.llamaindex.ai/en/stable/understanding/workflows/) for more examples using `llama-index`!\n",
    "ContentSha": "uyQUuCIsjVJreK2NjTBRYDljiKMj85DiFJfof3LjHfg=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```\n# [optional] ให้ context object กับ workflow\nctx = Context(workflow)\nresult = await workflow.run(input_msg=\"Hello, world!\", ctx=ctx)\nprint(\"Workflow result:\", result)\n\n# การรันซ้ำด้วย context เดิมจะคงสถานะไว้\nresult = await workflow.run(input_msg=\"Hello, world!\", ctx=ctx)\nprint(\"Workflow result:\", result)\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```\n\nในตัวอย่างข้างต้น\n- ขั้นตอนที่รับ `StartEvent` จะถูกรันก่อน\n- ขั้นตอนที่คืนค่า `StopEvent` จะจบ workflow\n- เหตุการณ์กลางเป็นเหตุการณ์ที่ผู้ใช้กำหนดเอง และสามารถใช้ถ่ายทอดข้อมูลระหว่างขั้นตอนได้\n- วัตถุ `Context` ก็ถูกใช้เพื่อแบ่งปันข้อมูลระหว่างขั้นตอนเช่นกัน\n\nเยี่ยมชม [เอกสารประกอบฉบับเต็ม](https://docs.llamaindex.ai/en/stable/understanding/workflows/) สำหรับตัวอย่างเพิ่มเติมที่ใช้ `llama-index`!\n",
    "Status": "ok"
  },
  {
    "Id": 4,
    "Content": "## More examples\n\n- [Basic Feature Run-Through](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/feature_walkthrough.ipynb)\n- [Building a Function Calling Agent with `llama-index`](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/agent.ipynb)\n- [Human-in-the-loop Iterative Document Extraction](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/document_processing.ipynb)\n- Observability\n  - [OpenTelemetry + Instrumentation Primer](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/observability/workflows_observability_pt1.ipynb)\n  - [OpenTelemetry + LlamaIndex](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/observability/workflows_observability_pt2.ipynb)\n  - [Arize Phoenix + LlamaIndex](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/observability/workflows_observablitiy_arize_phoenix.ipynb)\n  - [Langfuse + LlamaIndex](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/observability/workflows_observablitiy_langfuse.ipynb)\n\n## Related Packages\n\n- [Typescript Workflows](https://github.com/run-llama/workflows-ts)\n",
    "ContentSha": "DXwxZAa92R4ZF5bTYguiDm43cfYLGufWuZ5d/mzsQ24=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "## ตัวอย่างเพิ่มเติม\n\n- [การสาธิตฟีเจอร์พื้นฐาน](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/feature_walkthrough.ipynb)\n- [การสร้างเอเจนต์เรียกใช้ฟังก์ชันด้วย `llama-index`](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/agent.ipynb)\n- [การสกัดเอกสารแบบวนรอบโดยมนุษย์ร่วมในกระบวนการ](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/document_processing.ipynb)\n- Observability\n  - [OpenTelemetry + แนะนำการใช้เครื่องมืออินสตรูเมนต์](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/observability/workflows_observability_pt1.ipynb)\n  - [OpenTelemetry + LlamaIndex](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/observability/workflows_observability_pt2.ipynb)\n  - [Arize Phoenix + LlamaIndex](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/observability/workflows_observablitiy_arize_phoenix.ipynb)\n  - [Langfuse + LlamaIndex](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/observability/workflows_observablitiy_langfuse.ipynb)\n\n## แพ็กเกจที่เกี่ยวข้อง\n\n- [Typescript Workflows](https://github.com/run-llama/workflows-ts)\n",
    "Status": "ok"
  }
]