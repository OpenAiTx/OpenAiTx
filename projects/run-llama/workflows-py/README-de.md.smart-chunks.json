[
  {
    "Id": 1,
    "Content": "# LlamaIndex Workflows\n\n[![Unit Testing](https://github.com/run-llama/workflows/actions/workflows/test.yml/badge.svg)](https://github.com/run-llama/workflows/actions/workflows/test.yml)\n[![Coverage Status](https://coveralls.io/repos/github/run-llama/workflows/badge.svg?branch=main)](https://coveralls.io/github/run-llama/workflows?branch=main)\n[![GitHub contributors](https://img.shields.io/github/contributors/run-llama/workflows)](https://github.com/run-llama/llama-index-workflows/graphs/contributors)\n\n\n[![PyPI - Downloads](https://img.shields.io/pypi/dm/llama-index-workflows)](https://pypi.org/project/llama-index-workflows/)\n[![Discord](https://img.shields.io/discord/1059199217496772688)](https://discord.gg/dGcwcsnxhU)\n[![Twitter](https://img.shields.io/twitter/follow/llama_index)](https://x.com/llama_index)\n[![Reddit](https://img.shields.io/reddit/subreddit-subscribers/LlamaIndex?style=plastic&logo=reddit&label=r%2FLlamaIndex&labelColor=white)](https://www.reddit.com/r/LlamaIndex/)\n\nLlamaIndex Workflows are a framework for orchestrating and chaining together complex systems of steps and events.\n\n## What can you build with Workflows?\n\nWorkflows shine when you need to orchestrate complex, multi-step processes that involve AI models, APIs, and decision-making. Here are some examples of what you can build:\n\n- **AI Agents** - Create intelligent systems that can reason, make decisions, and take actions across multiple steps\n- **Document Processing Pipelines** - Build systems that ingest, analyze, summarize, and route documents through various processing stages\n- **Multi-Model AI Applications** - Coordinate between different AI models (LLMs, vision models, etc.) to solve complex tasks\n- **Research Assistants** - Develop workflows that can search, analyze, synthesize information, and provide comprehensive answers\n- **Content Generation Systems** - Create pipelines that generate, review, edit, and publish content with human-in-the-loop approval\n- **Customer Support Automation** - Build intelligent routing systems that can understand, categorize, and respond to customer inquiries\n\nThe async-first, event-driven architecture makes it easy to build workflows that can route between different capabilities, implement parallel processing patterns, loop over complex sequences, and maintain state across multiple steps - all the features you need to make your AI applications production-ready.\n",
    "ContentSha": "PrOw0sXCtw/kMf6D4N5eKll4XAnD3LIP64BH4KmOS5g=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "# LlamaIndex Workflows\n\n[![Unit Testing](https://github.com/run-llama/workflows/actions/workflows/test.yml/badge.svg)](https://github.com/run-llama/workflows/actions/workflows/test.yml)\n[![Coverage Status](https://coveralls.io/repos/github/run-llama/workflows/badge.svg?branch=main)](https://coveralls.io/github/run-llama/workflows?branch=main)\n[![GitHub contributors](https://img.shields.io/github/contributors/run-llama/workflows)](https://github.com/run-llama/llama-index-workflows/graphs/contributors)\n\n\n[![PyPI - Downloads](https://img.shields.io/pypi/dm/llama-index-workflows)](https://pypi.org/project/llama-index-workflows/)\n[![Discord](https://img.shields.io/discord/1059199217496772688)](https://discord.gg/dGcwcsnxhU)\n[![Twitter](https://img.shields.io/twitter/follow/llama_index)](https://x.com/llama_index)\n[![Reddit](https://img.shields.io/reddit/subreddit-subscribers/LlamaIndex?style=plastic&logo=reddit&label=r%2FLlamaIndex&labelColor=white)](https://www.reddit.com/r/LlamaIndex/)\n\nLlamaIndex Workflows sind ein Framework zur Orchestrierung und Verkettung komplexer Systeme aus Schritten und Ereignissen.\n\n## Was können Sie mit Workflows bauen?\n\nWorkflows sind besonders dann hilfreich, wenn Sie komplexe, mehrstufige Prozesse orchestrieren müssen, die KI-Modelle, APIs und Entscheidungsfindung einbeziehen. Hier sind einige Beispiele, was Sie bauen können:\n\n- **KI-Agenten** – Erstellen Sie intelligente Systeme, die über mehrere Schritte hinweg schlussfolgern, Entscheidungen treffen und Aktionen ausführen können\n- **Dokumentenverarbeitungspipelines** – Entwickeln Sie Systeme, die Dokumente aufnehmen, analysieren, zusammenfassen und durch verschiedene Verarbeitungsstufen leiten\n- **Multi-Model-KI-Anwendungen** – Koordinieren Sie verschiedene KI-Modelle (LLMs, Vision-Modelle usw.), um komplexe Aufgaben zu lösen\n- **Forschungsassistenten** – Entwickeln Sie Workflows, die Informationen suchen, analysieren, synthetisieren und umfassende Antworten liefern können\n- **Systeme zur Inhaltserstellung** – Erstellen Sie Pipelines, die Inhalte generieren, prüfen, bearbeiten und mit menschlicher Freigabe veröffentlichen\n- **Automatisierung des Kundensupports** – Bauen Sie intelligente Routingsysteme, die Kundenanfragen verstehen, kategorisieren und beantworten können\n\nDie asynchrone, ereignisgesteuerte Architektur erleichtert das Erstellen von Workflows, die zwischen verschiedenen Fähigkeiten routen, parallele Verarbeitung implementieren, komplexe Sequenzen wiederholen und den Zustand über mehrere Schritte hinweg beibehalten können – all die Funktionen, die Sie benötigen, um Ihre KI-Anwendungen produktionsreif zu machen.",
    "Status": "ok"
  },
  {
    "Id": 2,
    "Content": "## Key Features\n\n- **async-first** - workflows are built around python's async functionality - steps are async functions that process incoming events from an asyncio queue and emit new events to other queues. This also means that workflows work best in your async apps like FastAPI, Jupyter Notebooks, etc.\n- **event-driven** - workflows consist of steps and events. Organizing your code around events and steps makes it easier to reason about and test.\n- **state management** - each run of a workflow is self-contained, meaning you can launch a workflow, save information within it, serialize the state of a workflow and resume it later.\n- **observability** - workflows are automatically instrumented for observability, meaning you can use tools like `Arize Phoenix` and `OpenTelemetry` right out of the box.\n\n## Quick Start\n\nInstall the package:\n\n```bash\npip install llama-index-workflows\n```\n\nAnd create your first workflow:\n\n```python\nimport asyncio\nfrom pydantic import BaseModel, Field\nfrom workflows import Context, Workflow, step\nfrom workflows.events import Event, StartEvent, StopEvent\n\nclass MyEvent(Event):\n    msg: list[str]\n\nclass RunState(BaseModel):\n    num_runs: int = Field(default=0)\n\nclass MyWorkflow(Workflow):\n    @step\n    async def start(self, ctx: Context[RunState], ev: StartEvent) -> MyEvent:\n        async with ctx.store.edit_state() as state:\n            state.num_runs += 1\n\n            return MyEvent(msg=[ev.input_msg] * state.num_runs)\n\n    @step\n    async def process(self, ctx: Context[RunState], ev: MyEvent) -> StopEvent:\n        data_length = len(\"\".join(ev.msg))\n        new_msg = f\"Processed {len(ev.msg)} times, data length: {data_length}\"\n        return StopEvent(result=new_msg)\n\nasync def main():\n    workflow = MyWorkflow()\n",
    "ContentSha": "2y3u8OCMQZxV5p9IHLSVu9zwJnNilh9ufQ0F3eUU8bo=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "## Hauptmerkmale\n\n- **async-first** – Workflows sind um die asynchrone Funktionalität von Python aufgebaut – Schritte sind asynchrone Funktionen, die eingehende Ereignisse aus einer asyncio-Warteschlange verarbeiten und neue Ereignisse an andere Warteschlangen senden. Das bedeutet auch, dass Workflows am besten in asynchronen Anwendungen wie FastAPI, Jupyter Notebooks usw. funktionieren.\n- **ereignisgesteuert** – Workflows bestehen aus Schritten und Ereignissen. Die Organisation Ihres Codes rund um Ereignisse und Schritte erleichtert das Verständnis und das Testen.\n- **Zustandsverwaltung** – Jeder Durchlauf eines Workflows ist in sich abgeschlossen, das heißt, Sie können einen Workflow starten, Informationen darin speichern, den Zustand eines Workflows serialisieren und ihn später fortsetzen.\n- **Beobachtbarkeit** – Workflows sind automatisch für die Beobachtbarkeit instrumentiert, das bedeutet, Sie können Tools wie `Arize Phoenix` und `OpenTelemetry` direkt verwenden.\n\n## Schnellstart\n\nInstallieren Sie das Paket:\n\n```bash\npip install llama-index-workflows\n```\n\nUnd erstellen Sie Ihren ersten Workflow:\n\n```python\nimport asyncio\nfrom pydantic import BaseModel, Field\nfrom workflows import Context, Workflow, step\nfrom workflows.events import Event, StartEvent, StopEvent\n\nclass MyEvent(Event):\n    msg: list[str]\n\nclass RunState(BaseModel):\n    num_runs: int = Field(default=0)\n\nclass MyWorkflow(Workflow):\n    @step\n    async def start(self, ctx: Context[RunState], ev: StartEvent) -> MyEvent:\n        async with ctx.store.edit_state() as state:\n            state.num_runs += 1\n\n            return MyEvent(msg=[ev.input_msg] * state.num_runs)\n\n    @step\n    async def process(self, ctx: Context[RunState], ev: MyEvent) -> StopEvent:\n        data_length = len(\"\".join(ev.msg))\n        new_msg = f\"Processed {len(ev.msg)} times, data length: {data_length}\"\n        return StopEvent(result=new_msg)\n\nasync def main():\n    workflow = MyWorkflow()\n```",
    "Status": "ok"
  },
  {
    "Id": 3,
    "Content": "    # [optional] provide a context object to the workflow\n    ctx = Context(workflow)\n    result = await workflow.run(input_msg=\"Hello, world!\", ctx=ctx)\n    print(\"Workflow result:\", result)\n\n    # re-running with the same context will retain the state\n    result = await workflow.run(input_msg=\"Hello, world!\", ctx=ctx)\n    print(\"Workflow result:\", result)\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```\n\nIn the example above\n- Steps that accept a `StartEvent` will be run first.\n- Steps that return a `StopEvent` will end the workflow.\n- Intermediate events are user defined and can be used to pass information between steps.\n- The `Context` object is also used to share information between steps.\n\nVisit the [complete documentation](https://docs.llamaindex.ai/en/stable/understanding/workflows/) for more examples using `llama-index`!\n",
    "ContentSha": "uyQUuCIsjVJreK2NjTBRYDljiKMj85DiFJfof3LjHfg=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```markdown\n    # [optional] Geben Sie ein Kontextobjekt an den Workflow weiter\n    ctx = Context(workflow)\n    result = await workflow.run(input_msg=\"Hallo, Welt!\", ctx=ctx)\n    print(\"Workflow-Ergebnis:\", result)\n\n    # Das erneute Ausführen mit demselben Kontext behält den Zustand bei\n    result = await workflow.run(input_msg=\"Hallo, Welt!\", ctx=ctx)\n    print(\"Workflow-Ergebnis:\", result)\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```\n\nIm obigen Beispiel gilt:\n- Schritte, die ein `StartEvent` akzeptieren, werden zuerst ausgeführt.\n- Schritte, die ein `StopEvent` zurückgeben, beenden den Workflow.\n- Zwischenereignisse sind benutzerdefiniert und können verwendet werden, um Informationen zwischen Schritten zu übergeben.\n- Das `Context`-Objekt wird ebenfalls verwendet, um Informationen zwischen Schritten zu teilen.\n\nBesuchen Sie die [vollständige Dokumentation](https://docs.llamaindex.ai/en/stable/understanding/workflows/) für weitere Beispiele zur Verwendung von `llama-index`!\n```",
    "Status": "ok"
  },
  {
    "Id": 4,
    "Content": "## More examples\n\n- [Basic Feature Run-Through](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/feature_walkthrough.ipynb)\n- [Building a Function Calling Agent with `llama-index`](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/agent.ipynb)\n- [Human-in-the-loop Iterative Document Extraction](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/document_processing.ipynb)\n- Observability\n  - [OpenTelemetry + Instrumentation Primer](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/observability/workflows_observability_pt1.ipynb)\n  - [OpenTelemetry + LlamaIndex](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/observability/workflows_observability_pt2.ipynb)\n  - [Arize Phoenix + LlamaIndex](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/observability/workflows_observablitiy_arize_phoenix.ipynb)\n  - [Langfuse + LlamaIndex](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/observability/workflows_observablitiy_langfuse.ipynb)\n\n## Related Packages\n\n- [Typescript Workflows](https://github.com/run-llama/workflows-ts)\n",
    "ContentSha": "DXwxZAa92R4ZF5bTYguiDm43cfYLGufWuZ5d/mzsQ24=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "## Weitere Beispiele\n\n- [Grundlegende Funktionsübersicht](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/feature_walkthrough.ipynb)\n- [Erstellung eines Function Calling Agent mit `llama-index`](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/agent.ipynb)\n- [Iterative Dokumentenextraktion mit Mensch-in-der-Schleife](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/document_processing.ipynb)\n- Beobachtbarkeit\n  - [OpenTelemetry + Instrumentierungseinführung](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/observability/workflows_observability_pt1.ipynb)\n  - [OpenTelemetry + LlamaIndex](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/observability/workflows_observability_pt2.ipynb)\n  - [Arize Phoenix + LlamaIndex](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/observability/workflows_observablitiy_arize_phoenix.ipynb)\n  - [Langfuse + LlamaIndex](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/observability/workflows_observablitiy_langfuse.ipynb)\n\n## Verwandte Pakete\n\n- [Typescript Workflows](https://github.com/run-llama/workflows-ts)\n",
    "Status": "ok"
  }
]