[
  {
    "Id": 1,
    "Content": "# LlamaIndex Workflows\n\n[![Unit Testing](https://github.com/run-llama/workflows/actions/workflows/test.yml/badge.svg)](https://github.com/run-llama/workflows/actions/workflows/test.yml)\n[![Coverage Status](https://coveralls.io/repos/github/run-llama/workflows/badge.svg?branch=main)](https://coveralls.io/github/run-llama/workflows?branch=main)\n[![GitHub contributors](https://img.shields.io/github/contributors/run-llama/workflows)](https://github.com/run-llama/llama-index-workflows/graphs/contributors)\n\n\n[![PyPI - Downloads](https://img.shields.io/pypi/dm/llama-index-workflows)](https://pypi.org/project/llama-index-workflows/)\n[![Discord](https://img.shields.io/discord/1059199217496772688)](https://discord.gg/dGcwcsnxhU)\n[![Twitter](https://img.shields.io/twitter/follow/llama_index)](https://x.com/llama_index)\n[![Reddit](https://img.shields.io/reddit/subreddit-subscribers/LlamaIndex?style=plastic&logo=reddit&label=r%2FLlamaIndex&labelColor=white)](https://www.reddit.com/r/LlamaIndex/)\n\nLlamaIndex Workflows are a framework for orchestrating and chaining together complex systems of steps and events.\n\n## What can you build with Workflows?\n\nWorkflows shine when you need to orchestrate complex, multi-step processes that involve AI models, APIs, and decision-making. Here are some examples of what you can build:\n\n- **AI Agents** - Create intelligent systems that can reason, make decisions, and take actions across multiple steps\n- **Document Processing Pipelines** - Build systems that ingest, analyze, summarize, and route documents through various processing stages\n- **Multi-Model AI Applications** - Coordinate between different AI models (LLMs, vision models, etc.) to solve complex tasks\n- **Research Assistants** - Develop workflows that can search, analyze, synthesize information, and provide comprehensive answers\n- **Content Generation Systems** - Create pipelines that generate, review, edit, and publish content with human-in-the-loop approval\n- **Customer Support Automation** - Build intelligent routing systems that can understand, categorize, and respond to customer inquiries\n\nThe async-first, event-driven architecture makes it easy to build workflows that can route between different capabilities, implement parallel processing patterns, loop over complex sequences, and maintain state across multiple steps - all the features you need to make your AI applications production-ready.\n",
    "ContentSha": "PrOw0sXCtw/kMf6D4N5eKll4XAnD3LIP64BH4KmOS5g=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "# LlamaIndex 워크플로우\n\n[![단위 테스트](https://github.com/run-llama/workflows/actions/workflows/test.yml/badge.svg)](https://github.com/run-llama/workflows/actions/workflows/test.yml)\n[![커버리지 상태](https://coveralls.io/repos/github/run-llama/workflows/badge.svg?branch=main)](https://coveralls.io/github/run-llama/workflows?branch=main)\n[![GitHub 기여자](https://img.shields.io/github/contributors/run-llama/workflows)](https://github.com/run-llama/llama-index-workflows/graphs/contributors)\n\n\n[![PyPI - 다운로드](https://img.shields.io/pypi/dm/llama-index-workflows)](https://pypi.org/project/llama-index-workflows/)\n[![Discord](https://img.shields.io/discord/1059199217496772688)](https://discord.gg/dGcwcsnxhU)\n[![Twitter](https://img.shields.io/twitter/follow/llama_index)](https://x.com/llama_index)\n[![Reddit](https://img.shields.io/reddit/subreddit-subscribers/LlamaIndex?style=plastic&logo=reddit&label=r%2FLlamaIndex&labelColor=white)](https://www.reddit.com/r/LlamaIndex/)\n\nLlamaIndex 워크플로우는 단계와 이벤트로 이루어진 복잡한 시스템을 조율하고 연결하는 프레임워크입니다.\n\n## 워크플로우로 무엇을 만들 수 있나요?\n\n워크플로우는 AI 모델, API, 의사결정이 포함된 복잡하고 다단계의 프로세스를 조율해야 할 때 탁월합니다. 다음은 워크플로우로 만들 수 있는 예시입니다:\n\n- **AI 에이전트** - 복수 단계에 걸쳐 추론, 의사결정, 행동이 가능한 지능형 시스템을 만듭니다\n- **문서 처리 파이프라인** - 다양한 처리 단계를 거치며 문서를 수집, 분석, 요약, 라우팅하는 시스템을 구축합니다\n- **다중 모델 AI 애플리케이션** - 여러 AI 모델(LLM, 비전 모델 등) 간의 협력을 통해 복잡한 작업을 해결합니다\n- **연구 도우미** - 정보를 검색, 분석, 종합하고 포괄적인 답변을 제공하는 워크플로우를 개발합니다\n- **콘텐츠 생성 시스템** - 생성, 검토, 편집, 인간 승인 후 게시까지의 파이프라인을 구축합니다\n- **고객 지원 자동화** - 고객 문의를 이해, 분류, 응답하는 지능형 라우팅 시스템을 만듭니다\n\n비동기 우선, 이벤트 기반 아키텍처를 통해 다양한 기능 간의 라우팅, 병렬 처리 패턴 구현, 복잡한 시퀀스 반복, 여러 단계에 걸친 상태 유지 등, AI 애플리케이션을 프로덕션 환경에 적합하게 만드는 데 필요한 모든 기능을 손쉽게 구현할 수 있습니다.",
    "Status": "ok"
  },
  {
    "Id": 2,
    "Content": "## Key Features\n\n- **async-first** - workflows are built around python's async functionality - steps are async functions that process incoming events from an asyncio queue and emit new events to other queues. This also means that workflows work best in your async apps like FastAPI, Jupyter Notebooks, etc.\n- **event-driven** - workflows consist of steps and events. Organizing your code around events and steps makes it easier to reason about and test.\n- **state management** - each run of a workflow is self-contained, meaning you can launch a workflow, save information within it, serialize the state of a workflow and resume it later.\n- **observability** - workflows are automatically instrumented for observability, meaning you can use tools like `Arize Phoenix` and `OpenTelemetry` right out of the box.\n\n## Quick Start\n\nInstall the package:\n\n```bash\npip install llama-index-workflows\n```\n\nAnd create your first workflow:\n\n```python\nimport asyncio\nfrom pydantic import BaseModel, Field\nfrom workflows import Context, Workflow, step\nfrom workflows.events import Event, StartEvent, StopEvent\n\nclass MyEvent(Event):\n    msg: list[str]\n\nclass RunState(BaseModel):\n    num_runs: int = Field(default=0)\n\nclass MyWorkflow(Workflow):\n    @step\n    async def start(self, ctx: Context[RunState], ev: StartEvent) -> MyEvent:\n        async with ctx.store.edit_state() as state:\n            state.num_runs += 1\n\n            return MyEvent(msg=[ev.input_msg] * state.num_runs)\n\n    @step\n    async def process(self, ctx: Context[RunState], ev: MyEvent) -> StopEvent:\n        data_length = len(\"\".join(ev.msg))\n        new_msg = f\"Processed {len(ev.msg)} times, data length: {data_length}\"\n        return StopEvent(result=new_msg)\n\nasync def main():\n    workflow = MyWorkflow()\n",
    "ContentSha": "2y3u8OCMQZxV5p9IHLSVu9zwJnNilh9ufQ0F3eUU8bo=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "## 주요 특징\n\n- **async-first** - 워크플로우는 Python의 async 기능을 중심으로 구축되어 있습니다. 각 스텝은 asyncio 큐에서 들어오는 이벤트를 처리하고, 다른 큐로 새로운 이벤트를 내보내는 async 함수입니다. 따라서 FastAPI, Jupyter Notebooks 등과 같은 async 앱에서 워크플로우가 최적의 성능을 발휘합니다.\n- **이벤트 기반(event-driven)** - 워크플로우는 스텝과 이벤트로 구성됩니다. 코드를 이벤트와 스텝 중심으로 구성하면 이해 및 테스트가 쉬워집니다.\n- **상태 관리(state management)** - 워크플로우의 각 실행(run)은 독립적이며, 워크플로우를 시작하고 그 안에 정보를 저장하며, 워크플로우의 상태를 직렬화하여 나중에 이어서 실행할 수 있습니다.\n- **관측 가능성(observability)** - 워크플로우는 자동으로 관측 가능성 도구가 적용되어 있습니다. 즉, `Arize Phoenix`, `OpenTelemetry`와 같은 도구를 즉시 사용할 수 있습니다.\n\n## 빠른 시작\n\n패키지 설치:\n\n```bash\npip install llama-index-workflows\n```\n\n그리고 첫 번째 워크플로우를 생성하세요:\n\n```python\nimport asyncio\nfrom pydantic import BaseModel, Field\nfrom workflows import Context, Workflow, step\nfrom workflows.events import Event, StartEvent, StopEvent\n\nclass MyEvent(Event):\n    msg: list[str]\n\nclass RunState(BaseModel):\n    num_runs: int = Field(default=0)\n\nclass MyWorkflow(Workflow):\n    @step\n    async def start(self, ctx: Context[RunState], ev: StartEvent) -> MyEvent:\n        async with ctx.store.edit_state() as state:\n            state.num_runs += 1\n\n            return MyEvent(msg=[ev.input_msg] * state.num_runs)\n\n    @step\n    async def process(self, ctx: Context[RunState], ev: MyEvent) -> StopEvent:\n        data_length = len(\"\".join(ev.msg))\n        new_msg = f\"Processed {len(ev.msg)} times, data length: {data_length}\"\n        return StopEvent(result=new_msg)\n\nasync def main():\n    workflow = MyWorkflow()\n```",
    "Status": "ok"
  },
  {
    "Id": 3,
    "Content": "    # [optional] provide a context object to the workflow\n    ctx = Context(workflow)\n    result = await workflow.run(input_msg=\"Hello, world!\", ctx=ctx)\n    print(\"Workflow result:\", result)\n\n    # re-running with the same context will retain the state\n    result = await workflow.run(input_msg=\"Hello, world!\", ctx=ctx)\n    print(\"Workflow result:\", result)\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```\n\nIn the example above\n- Steps that accept a `StartEvent` will be run first.\n- Steps that return a `StopEvent` will end the workflow.\n- Intermediate events are user defined and can be used to pass information between steps.\n- The `Context` object is also used to share information between steps.\n\nVisit the [complete documentation](https://docs.llamaindex.ai/en/stable/understanding/workflows/) for more examples using `llama-index`!\n",
    "ContentSha": "uyQUuCIsjVJreK2NjTBRYDljiKMj85DiFJfof3LjHfg=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```python\n# [optional] 워크플로우에 컨텍스트 객체를 제공합니다.\nctx = Context(workflow)\nresult = await workflow.run(input_msg=\"Hello, world!\", ctx=ctx)\nprint(\"Workflow result:\", result)\n\n# 동일한 컨텍스트로 다시 실행하면 상태가 유지됩니다.\nresult = await workflow.run(input_msg=\"Hello, world!\", ctx=ctx)\nprint(\"Workflow result:\", result)\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```\n\n위의 예제에서\n- `StartEvent`를 수락하는 단계가 먼저 실행됩니다.\n- `StopEvent`를 반환하는 단계는 워크플로우를 종료합니다.\n- 중간 이벤트는 사용자가 정의하며, 단계 간에 정보를 전달하는 데 사용할 수 있습니다.\n- `Context` 객체 또한 단계 간에 정보를 공유하는 데 사용됩니다.\n\n`llama-index`를 사용한 더 많은 예제는 [전체 문서](https://docs.llamaindex.ai/en/stable/understanding/workflows/)를 방문하세요!\n",
    "Status": "ok"
  },
  {
    "Id": 4,
    "Content": "## More examples\n\n- [Basic Feature Run-Through](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/feature_walkthrough.ipynb)\n- [Building a Function Calling Agent with `llama-index`](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/agent.ipynb)\n- [Human-in-the-loop Iterative Document Extraction](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/document_processing.ipynb)\n- Observability\n  - [OpenTelemetry + Instrumentation Primer](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/observability/workflows_observability_pt1.ipynb)\n  - [OpenTelemetry + LlamaIndex](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/observability/workflows_observability_pt2.ipynb)\n  - [Arize Phoenix + LlamaIndex](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/observability/workflows_observablitiy_arize_phoenix.ipynb)\n  - [Langfuse + LlamaIndex](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/observability/workflows_observablitiy_langfuse.ipynb)\n\n## Related Packages\n\n- [Typescript Workflows](https://github.com/run-llama/workflows-ts)\n",
    "ContentSha": "DXwxZAa92R4ZF5bTYguiDm43cfYLGufWuZ5d/mzsQ24=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "## 추가 예시\n\n- [기본 기능 실행 가이드](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/feature_walkthrough.ipynb)\n- [`llama-index`로 함수 호출 에이전트 구축하기](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/agent.ipynb)\n- 인간이 참여하는 반복적 문서 추출(Human-in-the-loop Iterative Document Extraction)\n  - [OpenTelemetry + 계측 입문](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/observability/workflows_observability_pt1.ipynb)\n  - [OpenTelemetry + LlamaIndex](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/observability/workflows_observability_pt2.ipynb)\n  - [Arize Phoenix + LlamaIndex](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/observability/workflows_observablitiy_arize_phoenix.ipynb)\n  - [Langfuse + LlamaIndex](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/observability/workflows_observablitiy_langfuse.ipynb)\n\n## 관련 패키지\n\n- [Typescript Workflows](https://github.com/run-llama/workflows-ts)\n",
    "Status": "ok"
  }
]