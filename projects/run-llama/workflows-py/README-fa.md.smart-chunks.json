[
  {
    "Id": 1,
    "Content": "# LlamaIndex Workflows\n\n[![Unit Testing](https://github.com/run-llama/workflows/actions/workflows/test.yml/badge.svg)](https://github.com/run-llama/workflows/actions/workflows/test.yml)\n[![Coverage Status](https://coveralls.io/repos/github/run-llama/workflows/badge.svg?branch=main)](https://coveralls.io/github/run-llama/workflows?branch=main)\n[![GitHub contributors](https://img.shields.io/github/contributors/run-llama/workflows)](https://github.com/run-llama/llama-index-workflows/graphs/contributors)\n\n\n[![PyPI - Downloads](https://img.shields.io/pypi/dm/llama-index-workflows)](https://pypi.org/project/llama-index-workflows/)\n[![Discord](https://img.shields.io/discord/1059199217496772688)](https://discord.gg/dGcwcsnxhU)\n[![Twitter](https://img.shields.io/twitter/follow/llama_index)](https://x.com/llama_index)\n[![Reddit](https://img.shields.io/reddit/subreddit-subscribers/LlamaIndex?style=plastic&logo=reddit&label=r%2FLlamaIndex&labelColor=white)](https://www.reddit.com/r/LlamaIndex/)\n\nLlamaIndex Workflows are a framework for orchestrating and chaining together complex systems of steps and events.\n\n## What can you build with Workflows?\n\nWorkflows shine when you need to orchestrate complex, multi-step processes that involve AI models, APIs, and decision-making. Here are some examples of what you can build:\n\n- **AI Agents** - Create intelligent systems that can reason, make decisions, and take actions across multiple steps\n- **Document Processing Pipelines** - Build systems that ingest, analyze, summarize, and route documents through various processing stages\n- **Multi-Model AI Applications** - Coordinate between different AI models (LLMs, vision models, etc.) to solve complex tasks\n- **Research Assistants** - Develop workflows that can search, analyze, synthesize information, and provide comprehensive answers\n- **Content Generation Systems** - Create pipelines that generate, review, edit, and publish content with human-in-the-loop approval\n- **Customer Support Automation** - Build intelligent routing systems that can understand, categorize, and respond to customer inquiries\n\nThe async-first, event-driven architecture makes it easy to build workflows that can route between different capabilities, implement parallel processing patterns, loop over complex sequences, and maintain state across multiple steps - all the features you need to make your AI applications production-ready.\n",
    "ContentSha": "PrOw0sXCtw/kMf6D4N5eKll4XAnD3LIP64BH4KmOS5g=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "# جریان‌های کاری LlamaIndex\n\n[![تست واحد](https://github.com/run-llama/workflows/actions/workflows/test.yml/badge.svg)](https://github.com/run-llama/workflows/actions/workflows/test.yml)\n[![وضعیت پوشش](https://coveralls.io/repos/github/run-llama/workflows/badge.svg?branch=main)](https://coveralls.io/github/run-llama/workflows?branch=main)\n[![مشارکت‌کنندگان GitHub](https://img.shields.io/github/contributors/run-llama/workflows)](https://github.com/run-llama/llama-index-workflows/graphs/contributors)\n\n[![PyPI - دانلودها](https://img.shields.io/pypi/dm/llama-index-workflows)](https://pypi.org/project/llama-index-workflows/)\n[![دیسکورد](https://img.shields.io/discord/1059199217496772688)](https://discord.gg/dGcwcsnxhU)\n[![توییتر](https://img.shields.io/twitter/follow/llama_index)](https://x.com/llama_index)\n[![ردیت](https://img.shields.io/reddit/subreddit-subscribers/LlamaIndex?style=plastic&logo=reddit&label=r%2FLlamaIndex&labelColor=white)](https://www.reddit.com/r/LlamaIndex/)\n\nجریان‌های کاری LlamaIndex یک چارچوب برای سازمان‌دهی و زنجیره‌سازی سیستم‌های پیچیده‌ای از مراحل و رویدادها هستند.\n\n## با جریان‌های کاری چه چیزی می‌توانید بسازید؟\n\nجریان‌های کاری زمانی می‌درخشند که نیاز به سازمان‌دهی فرآیندهای پیچیده و چندمرحله‌ای دارید که شامل مدل‌های هوش مصنوعی، APIها و تصمیم‌گیری می‌شوند. در اینجا چند نمونه از مواردی که می‌توانید بسازید آورده شده است:\n\n- **عوامل هوش مصنوعی** - ساخت سیستم‌های هوشمندی که می‌توانند استدلال کنند، تصمیم بگیرند و در چندین مرحله اقدام انجام دهند\n- **خطوط لوله پردازش اسناد** - ساخت سیستم‌هایی که اسناد را دریافت، تحلیل، خلاصه و از مراحل پردازشی مختلف عبور می‌دهند\n- **برنامه‌های هوش مصنوعی چندمدلی** - هماهنگی بین مدل‌های مختلف هوش مصنوعی (مدل‌های زبانی بزرگ، مدل‌های بینایی و غیره) برای حل وظایف پیچیده\n- **دستیاران پژوهشی** - توسعه جریان‌های کاری که می‌توانند جستجو، تحلیل، ترکیب اطلاعات و ارائه پاسخ‌های جامع را انجام دهند\n- **سیستم‌های تولید محتوا** - ایجاد خطوط لوله‌ای که محتوا را تولید، بازبینی، ویرایش و با تأیید انسانی منتشر می‌کنند\n- **اتوماسیون پشتیبانی مشتری** - ساخت سیستم‌های مسیریابی هوشمند که می‌توانند درخواست‌های مشتری را درک، دسته‌بندی و به آن‌ها پاسخ دهند\n\nمعماری مبتنی بر رویداد و اولویت‌دهی به عملیات ناهمزمان (async-first) این امکان را فراهم می‌کند که جریان‌های کاری بسازید که بتوانند بین قابلیت‌های مختلف مسیردهی کنند، الگوهای پردازش موازی را پیاده‌سازی کنند، بر دنباله‌های پیچیده حلقه بزنند و وضعیت را در چندین مرحله حفظ کنند - تمام ویژگی‌هایی که برای آماده‌سازی برنامه‌های هوش مصنوعی خود برای محیط عملیاتی نیاز دارید.",
    "Status": "ok"
  },
  {
    "Id": 2,
    "Content": "## Key Features\n\n- **async-first** - workflows are built around python's async functionality - steps are async functions that process incoming events from an asyncio queue and emit new events to other queues. This also means that workflows work best in your async apps like FastAPI, Jupyter Notebooks, etc.\n- **event-driven** - workflows consist of steps and events. Organizing your code around events and steps makes it easier to reason about and test.\n- **state management** - each run of a workflow is self-contained, meaning you can launch a workflow, save information within it, serialize the state of a workflow and resume it later.\n- **observability** - workflows are automatically instrumented for observability, meaning you can use tools like `Arize Phoenix` and `OpenTelemetry` right out of the box.\n\n## Quick Start\n\nInstall the package:\n\n```bash\npip install llama-index-workflows\n```\n\nAnd create your first workflow:\n\n```python\nimport asyncio\nfrom pydantic import BaseModel, Field\nfrom workflows import Context, Workflow, step\nfrom workflows.events import Event, StartEvent, StopEvent\n\nclass MyEvent(Event):\n    msg: list[str]\n\nclass RunState(BaseModel):\n    num_runs: int = Field(default=0)\n\nclass MyWorkflow(Workflow):\n    @step\n    async def start(self, ctx: Context[RunState], ev: StartEvent) -> MyEvent:\n        async with ctx.store.edit_state() as state:\n            state.num_runs += 1\n\n            return MyEvent(msg=[ev.input_msg] * state.num_runs)\n\n    @step\n    async def process(self, ctx: Context[RunState], ev: MyEvent) -> StopEvent:\n        data_length = len(\"\".join(ev.msg))\n        new_msg = f\"Processed {len(ev.msg)} times, data length: {data_length}\"\n        return StopEvent(result=new_msg)\n\nasync def main():\n    workflow = MyWorkflow()\n",
    "ContentSha": "2y3u8OCMQZxV5p9IHLSVu9zwJnNilh9ufQ0F3eUU8bo=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "## ویژگی‌های کلیدی\n\n- **اولویت با async** - گردش‌کارها بر اساس قابلیت async پایتون ساخته شده‌اند - مراحل به صورت توابع async هستند که رویدادهای ورودی را از یک صف asyncio پردازش می‌کنند و رویدادهای جدیدی را به صف‌های دیگر ارسال می‌نمایند. این همچنین به این معناست که گردش‌کارها بهترین عملکرد را در برنامه‌های async شما مانند FastAPI، Jupyter Notebooks و غیره دارند.\n- **مبتنی بر رویداد** - گردش‌کارها از مراحل و رویدادها تشکیل شده‌اند. سازماندهی کد شما بر اساس رویدادها و مراحل باعث می‌شود درک و تست آن آسان‌تر شود.\n- **مدیریت وضعیت** - هر اجرای یک گردش‌کار به صورت مستقل است، به این معنی که می‌توانید یک گردش‌کار را اجرا کنید، اطلاعات را در آن ذخیره نمایید، وضعیت گردش‌کار را سریال‌سازی کرده و بعداً ادامه دهید.\n- **قابلیت مشاهده‌پذیری** - گردش‌کارها به طور خودکار برای مشاهده‌پذیری ابزارسازی شده‌اند، به این معنا که می‌توانید بلافاصله از ابزارهایی مانند `Arize Phoenix` و `OpenTelemetry` استفاده کنید.\n\n## شروع سریع\n\nبسته را نصب کنید:\n\n```bash\npip install llama-index-workflows\n```\n\nو اولین گردش‌کار خود را ایجاد کنید:\n\n```python\nimport asyncio\nfrom pydantic import BaseModel, Field\nfrom workflows import Context, Workflow, step\nfrom workflows.events import Event, StartEvent, StopEvent\n\nclass MyEvent(Event):\n    msg: list[str]\n\nclass RunState(BaseModel):\n    num_runs: int = Field(default=0)\n\nclass MyWorkflow(Workflow):\n    @step\n    async def start(self, ctx: Context[RunState], ev: StartEvent) -> MyEvent:\n        async with ctx.store.edit_state() as state:\n            state.num_runs += 1\n\n            return MyEvent(msg=[ev.input_msg] * state.num_runs)\n\n    @step\n    async def process(self, ctx: Context[RunState], ev: MyEvent) -> StopEvent:\n        data_length = len(\"\".join(ev.msg))\n        new_msg = f\"Processed {len(ev.msg)} times, data length: {data_length}\"\n        return StopEvent(result=new_msg)\n\nasync def main():\n    workflow = MyWorkflow()\n```",
    "Status": "ok"
  },
  {
    "Id": 3,
    "Content": "    # [optional] provide a context object to the workflow\n    ctx = Context(workflow)\n    result = await workflow.run(input_msg=\"Hello, world!\", ctx=ctx)\n    print(\"Workflow result:\", result)\n\n    # re-running with the same context will retain the state\n    result = await workflow.run(input_msg=\"Hello, world!\", ctx=ctx)\n    print(\"Workflow result:\", result)\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```\n\nIn the example above\n- Steps that accept a `StartEvent` will be run first.\n- Steps that return a `StopEvent` will end the workflow.\n- Intermediate events are user defined and can be used to pass information between steps.\n- The `Context` object is also used to share information between steps.\n\nVisit the [complete documentation](https://docs.llamaindex.ai/en/stable/understanding/workflows/) for more examples using `llama-index`!\n",
    "ContentSha": "uyQUuCIsjVJreK2NjTBRYDljiKMj85DiFJfof3LjHfg=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```python\n    # [اختیاری] یک شیء context به جریان کاری ارائه دهید\n    ctx = Context(workflow)\n    result = await workflow.run(input_msg=\"سلام، دنیا!\", ctx=ctx)\n    print(\"نتیجه جریان کاری:\", result)\n\n    # اجرای مجدد با همان context وضعیت را حفظ خواهد کرد\n    result = await workflow.run(input_msg=\"سلام، دنیا!\", ctx=ctx)\n    print(\"نتیجه جریان کاری:\", result)\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```\n\nدر مثال بالا\n- مراحلی که یک `StartEvent` را می‌پذیرند ابتدا اجرا خواهند شد.\n- مراحلی که یک `StopEvent` بازمی‌گردانند جریان کاری را خاتمه می‌دهند.\n- رویدادهای میانی توسط کاربر تعریف می‌شوند و می‌توانند برای انتقال اطلاعات بین مراحل استفاده شوند.\n- شیء `Context` نیز برای به اشتراک‌گذاری اطلاعات بین مراحل استفاده می‌شود.\n\nبرای مثال‌های بیشتر از استفاده با `llama-index` [مستندات کامل](https://docs.llamaindex.ai/en/stable/understanding/workflows/) را مشاهده کنید!\n",
    "Status": "ok"
  },
  {
    "Id": 4,
    "Content": "## More examples\n\n- [Basic Feature Run-Through](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/feature_walkthrough.ipynb)\n- [Building a Function Calling Agent with `llama-index`](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/agent.ipynb)\n- [Human-in-the-loop Iterative Document Extraction](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/document_processing.ipynb)\n- Observability\n  - [OpenTelemetry + Instrumentation Primer](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/observability/workflows_observability_pt1.ipynb)\n  - [OpenTelemetry + LlamaIndex](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/observability/workflows_observability_pt2.ipynb)\n  - [Arize Phoenix + LlamaIndex](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/observability/workflows_observablitiy_arize_phoenix.ipynb)\n  - [Langfuse + LlamaIndex](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/observability/workflows_observablitiy_langfuse.ipynb)\n\n## Related Packages\n\n- [Typescript Workflows](https://github.com/run-llama/workflows-ts)\n",
    "ContentSha": "DXwxZAa92R4ZF5bTYguiDm43cfYLGufWuZ5d/mzsQ24=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "## مثال‌های بیشتر\n\n- [مرور ویژگی‌های پایه](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/feature_walkthrough.ipynb)\n- [ساخت یک عامل برای فراخوانی توابع با `llama-index`](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/agent.ipynb)\n- [استخراج سند به صورت تعاملی با حضور انسان در حلقه](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/document_processing.ipynb)\n- قابلیت مشاهده‌پذیری\n  - [مقدمه‌ای بر OpenTelemetry + ابزارسازی](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/observability/workflows_observability_pt1.ipynb)\n  - [OpenTelemetry + LlamaIndex](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/observability/workflows_observability_pt2.ipynb)\n  - [Arize Phoenix + LlamaIndex](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/observability/workflows_observablitiy_arize_phoenix.ipynb)\n  - [Langfuse + LlamaIndex](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/observability/workflows_observablitiy_langfuse.ipynb)\n\n## بسته‌های مرتبط\n\n- [Workflowهای Typescript](https://github.com/run-llama/workflows-ts)\n",
    "Status": "ok"
  }
]