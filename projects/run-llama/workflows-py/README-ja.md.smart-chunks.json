[
  {
    "Id": 1,
    "Content": "# LlamaIndex Workflows\n\n[![Unit Testing](https://github.com/run-llama/workflows/actions/workflows/test.yml/badge.svg)](https://github.com/run-llama/workflows/actions/workflows/test.yml)\n[![Coverage Status](https://coveralls.io/repos/github/run-llama/workflows/badge.svg?branch=main)](https://coveralls.io/github/run-llama/workflows?branch=main)\n[![GitHub contributors](https://img.shields.io/github/contributors/run-llama/workflows)](https://github.com/run-llama/llama-index-workflows/graphs/contributors)\n\n\n[![PyPI - Downloads](https://img.shields.io/pypi/dm/llama-index-workflows)](https://pypi.org/project/llama-index-workflows/)\n[![Discord](https://img.shields.io/discord/1059199217496772688)](https://discord.gg/dGcwcsnxhU)\n[![Twitter](https://img.shields.io/twitter/follow/llama_index)](https://x.com/llama_index)\n[![Reddit](https://img.shields.io/reddit/subreddit-subscribers/LlamaIndex?style=plastic&logo=reddit&label=r%2FLlamaIndex&labelColor=white)](https://www.reddit.com/r/LlamaIndex/)\n\nLlamaIndex Workflows are a framework for orchestrating and chaining together complex systems of steps and events.\n\n## What can you build with Workflows?\n\nWorkflows shine when you need to orchestrate complex, multi-step processes that involve AI models, APIs, and decision-making. Here are some examples of what you can build:\n\n- **AI Agents** - Create intelligent systems that can reason, make decisions, and take actions across multiple steps\n- **Document Processing Pipelines** - Build systems that ingest, analyze, summarize, and route documents through various processing stages\n- **Multi-Model AI Applications** - Coordinate between different AI models (LLMs, vision models, etc.) to solve complex tasks\n- **Research Assistants** - Develop workflows that can search, analyze, synthesize information, and provide comprehensive answers\n- **Content Generation Systems** - Create pipelines that generate, review, edit, and publish content with human-in-the-loop approval\n- **Customer Support Automation** - Build intelligent routing systems that can understand, categorize, and respond to customer inquiries\n\nThe async-first, event-driven architecture makes it easy to build workflows that can route between different capabilities, implement parallel processing patterns, loop over complex sequences, and maintain state across multiple steps - all the features you need to make your AI applications production-ready.\n",
    "ContentSha": "PrOw0sXCtw/kMf6D4N5eKll4XAnD3LIP64BH4KmOS5g=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "# LlamaIndex Workflows\n\n[![ユニットテスト](https://github.com/run-llama/workflows/actions/workflows/test.yml/badge.svg)](https://github.com/run-llama/workflows/actions/workflows/test.yml)\n[![カバレッジステータス](https://coveralls.io/repos/github/run-llama/workflows/badge.svg?branch=main)](https://coveralls.io/github/run-llama/workflows?branch=main)\n[![GitHub コントリビューター](https://img.shields.io/github/contributors/run-llama/workflows)](https://github.com/run-llama/llama-index-workflows/graphs/contributors)\n\n\n[![PyPI - ダウンロード数](https://img.shields.io/pypi/dm/llama-index-workflows)](https://pypi.org/project/llama-index-workflows/)\n[![Discord](https://img.shields.io/discord/1059199217496772688)](https://discord.gg/dGcwcsnxhU)\n[![Twitter](https://img.shields.io/twitter/follow/llama_index)](https://x.com/llama_index)\n[![Reddit](https://img.shields.io/reddit/subreddit-subscribers/LlamaIndex?style=plastic&logo=reddit&label=r%2FLlamaIndex&labelColor=white)](https://www.reddit.com/r/LlamaIndex/)\n\nLlamaIndex Workflowsは、複雑なステップやイベントのシステムをオーケストレーションし、連鎖させるためのフレームワークです。\n\n## Workflowsで何が構築できますか？\n\nWorkflowsは、AIモデル、API、意思決定を含む複雑で多段階なプロセスのオーケストレーションが必要な場合に特に力を発揮します。以下は構築可能な例です：\n\n- **AIエージェント** - 複数のステップにわたり推論、意思決定、アクションを実行できるインテリジェントなシステムの作成\n- **ドキュメント処理パイプライン** - 文書の取り込み、分析、要約、および様々な処理段階へのルーティングを行うシステムの構築\n- **マルチモデルAIアプリケーション** - 異なるAIモデル（LLM、ビジョンモデル等）を連携させて複雑なタスクを解決\n- **リサーチアシスタント** - 情報の検索、分析、統合を行い、包括的な回答を提供するワークフローの開発\n- **コンテンツ生成システム** - コンテンツの生成、レビュー、編集、そして人間による承認を経て公開までを行うパイプラインの構築\n- **カスタマーサポート自動化** - 顧客からの問い合わせを理解、分類、応答できるインテリジェントなルーティングシステムの構築\n\n非同期・イベント駆動型アーキテクチャにより、異なる機能間のルーティング、並列処理パターンの実装、複雑なシーケンスのループ、多段階にわたる状態の維持などが容易になり、AIアプリケーションを本番運用に耐えうるものにします。",
    "Status": "ok"
  },
  {
    "Id": 2,
    "Content": "## Key Features\n\n- **async-first** - workflows are built around python's async functionality - steps are async functions that process incoming events from an asyncio queue and emit new events to other queues. This also means that workflows work best in your async apps like FastAPI, Jupyter Notebooks, etc.\n- **event-driven** - workflows consist of steps and events. Organizing your code around events and steps makes it easier to reason about and test.\n- **state management** - each run of a workflow is self-contained, meaning you can launch a workflow, save information within it, serialize the state of a workflow and resume it later.\n- **observability** - workflows are automatically instrumented for observability, meaning you can use tools like `Arize Phoenix` and `OpenTelemetry` right out of the box.\n\n## Quick Start\n\nInstall the package:\n\n```bash\npip install llama-index-workflows\n```\n\nAnd create your first workflow:\n\n```python\nimport asyncio\nfrom pydantic import BaseModel, Field\nfrom workflows import Context, Workflow, step\nfrom workflows.events import Event, StartEvent, StopEvent\n\nclass MyEvent(Event):\n    msg: list[str]\n\nclass RunState(BaseModel):\n    num_runs: int = Field(default=0)\n\nclass MyWorkflow(Workflow):\n    @step\n    async def start(self, ctx: Context[RunState], ev: StartEvent) -> MyEvent:\n        async with ctx.store.edit_state() as state:\n            state.num_runs += 1\n\n            return MyEvent(msg=[ev.input_msg] * state.num_runs)\n\n    @step\n    async def process(self, ctx: Context[RunState], ev: MyEvent) -> StopEvent:\n        data_length = len(\"\".join(ev.msg))\n        new_msg = f\"Processed {len(ev.msg)} times, data length: {data_length}\"\n        return StopEvent(result=new_msg)\n\nasync def main():\n    workflow = MyWorkflow()\n",
    "ContentSha": "2y3u8OCMQZxV5p9IHLSVu9zwJnNilh9ufQ0F3eUU8bo=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "## 主な特徴\n\n- **async-first** - ワークフローは Python の async 機能を中心に構築されています。ステップは asyncio キューからのイベントを処理し、新しいイベントを他のキューに発行する非同期関数です。つまり、FastAPI や Jupyter Notebooks などの非同期アプリで最も効果的に動作します。\n- **イベント駆動型** - ワークフローはステップとイベントで構成されます。コードをイベントとステップで整理することで、理解やテストが容易になります。\n- **状態管理** - 各ワークフローの実行は自己完結型であり、ワークフローを起動して情報を保存し、ワークフローの状態をシリアライズして後で再開することができます。\n- **オブザーバビリティ** - ワークフローは自動的にオブザーバビリティ向けに計装されており、`Arize Phoenix` や `OpenTelemetry` などのツールをすぐに利用できます。\n\n## クイックスタート\n\nパッケージをインストールします：\n\n```bash\npip install llama-index-workflows\n```\n\nそして、最初のワークフローを作成します：\n\n```python\nimport asyncio\nfrom pydantic import BaseModel, Field\nfrom workflows import Context, Workflow, step\nfrom workflows.events import Event, StartEvent, StopEvent\n\nclass MyEvent(Event):\n    msg: list[str]\n\nclass RunState(BaseModel):\n    num_runs: int = Field(default=0)\n\nclass MyWorkflow(Workflow):\n    @step\n    async def start(self, ctx: Context[RunState], ev: StartEvent) -> MyEvent:\n        async with ctx.store.edit_state() as state:\n            state.num_runs += 1\n\n            return MyEvent(msg=[ev.input_msg] * state.num_runs)\n\n    @step\n    async def process(self, ctx: Context[RunState], ev: MyEvent) -> StopEvent:\n        data_length = len(\"\".join(ev.msg))\n        new_msg = f\"Processed {len(ev.msg)} times, data length: {data_length}\"\n        return StopEvent(result=new_msg)\n\nasync def main():\n    workflow = MyWorkflow()\n```",
    "Status": "ok"
  },
  {
    "Id": 3,
    "Content": "    # [optional] provide a context object to the workflow\n    ctx = Context(workflow)\n    result = await workflow.run(input_msg=\"Hello, world!\", ctx=ctx)\n    print(\"Workflow result:\", result)\n\n    # re-running with the same context will retain the state\n    result = await workflow.run(input_msg=\"Hello, world!\", ctx=ctx)\n    print(\"Workflow result:\", result)\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```\n\nIn the example above\n- Steps that accept a `StartEvent` will be run first.\n- Steps that return a `StopEvent` will end the workflow.\n- Intermediate events are user defined and can be used to pass information between steps.\n- The `Context` object is also used to share information between steps.\n\nVisit the [complete documentation](https://docs.llamaindex.ai/en/stable/understanding/workflows/) for more examples using `llama-index`!\n",
    "ContentSha": "uyQUuCIsjVJreK2NjTBRYDljiKMj85DiFJfof3LjHfg=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```\n    # [オプション] ワークフローにコンテキストオブジェクトを提供する\n    ctx = Context(workflow)\n    result = await workflow.run(input_msg=\"Hello, world!\", ctx=ctx)\n    print(\"Workflow result:\", result)\n\n    # 同じコンテキストで再実行すると、状態が保持される\n    result = await workflow.run(input_msg=\"Hello, world!\", ctx=ctx)\n    print(\"Workflow result:\", result)\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```\n\n上記の例では\n- `StartEvent` を受け入れるステップが最初に実行されます。\n- `StopEvent` を返すステップがワークフローを終了させます。\n- 中間イベントはユーザー定義であり、ステップ間で情報を渡すために使用できます。\n- `Context` オブジェクトもステップ間で情報を共有するために使用されます。\n\n`llama-index` を使ったさらなる例については、[完全なドキュメント](https://docs.llamaindex.ai/en/stable/understanding/workflows/)をご覧ください！\n",
    "Status": "ok"
  },
  {
    "Id": 4,
    "Content": "## More examples\n\n- [Basic Feature Run-Through](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/feature_walkthrough.ipynb)\n- [Building a Function Calling Agent with `llama-index`](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/agent.ipynb)\n- [Human-in-the-loop Iterative Document Extraction](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/document_processing.ipynb)\n- Observability\n  - [OpenTelemetry + Instrumentation Primer](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/observability/workflows_observability_pt1.ipynb)\n  - [OpenTelemetry + LlamaIndex](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/observability/workflows_observability_pt2.ipynb)\n  - [Arize Phoenix + LlamaIndex](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/observability/workflows_observablitiy_arize_phoenix.ipynb)\n  - [Langfuse + LlamaIndex](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/observability/workflows_observablitiy_langfuse.ipynb)\n\n## Related Packages\n\n- [Typescript Workflows](https://github.com/run-llama/workflows-ts)\n",
    "ContentSha": "DXwxZAa92R4ZF5bTYguiDm43cfYLGufWuZ5d/mzsQ24=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "## さらに多くの例\n\n- [基本機能のウォークスルー](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/feature_walkthrough.ipynb)\n- [`llama-index`を使った関数呼び出しエージェントの構築](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/agent.ipynb)\n- 人間が介在する反復的なドキュメント抽出\n  - [OpenTelemetry + インストルメンテーション入門](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/observability/workflows_observability_pt1.ipynb)\n  - [OpenTelemetry + LlamaIndex](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/observability/workflows_observability_pt2.ipynb)\n  - [Arize Phoenix + LlamaIndex](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/observability/workflows_observablitiy_arize_phoenix.ipynb)\n  - [Langfuse + LlamaIndex](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/observability/workflows_observablitiy_langfuse.ipynb)\n\n## 関連パッケージ\n\n- [Typescript Workflows](https://github.com/run-llama/workflows-ts)\n",
    "Status": "ok"
  }
]