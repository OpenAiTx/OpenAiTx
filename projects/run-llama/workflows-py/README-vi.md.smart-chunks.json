[
  {
    "Id": 1,
    "Content": "# LlamaIndex Workflows\n\n[![Unit Testing](https://github.com/run-llama/workflows/actions/workflows/test.yml/badge.svg)](https://github.com/run-llama/workflows/actions/workflows/test.yml)\n[![Coverage Status](https://coveralls.io/repos/github/run-llama/workflows/badge.svg?branch=main)](https://coveralls.io/github/run-llama/workflows?branch=main)\n[![GitHub contributors](https://img.shields.io/github/contributors/run-llama/workflows)](https://github.com/run-llama/llama-index-workflows/graphs/contributors)\n\n\n[![PyPI - Downloads](https://img.shields.io/pypi/dm/llama-index-workflows)](https://pypi.org/project/llama-index-workflows/)\n[![Discord](https://img.shields.io/discord/1059199217496772688)](https://discord.gg/dGcwcsnxhU)\n[![Twitter](https://img.shields.io/twitter/follow/llama_index)](https://x.com/llama_index)\n[![Reddit](https://img.shields.io/reddit/subreddit-subscribers/LlamaIndex?style=plastic&logo=reddit&label=r%2FLlamaIndex&labelColor=white)](https://www.reddit.com/r/LlamaIndex/)\n\nLlamaIndex Workflows are a framework for orchestrating and chaining together complex systems of steps and events.\n\n## What can you build with Workflows?\n\nWorkflows shine when you need to orchestrate complex, multi-step processes that involve AI models, APIs, and decision-making. Here are some examples of what you can build:\n\n- **AI Agents** - Create intelligent systems that can reason, make decisions, and take actions across multiple steps\n- **Document Processing Pipelines** - Build systems that ingest, analyze, summarize, and route documents through various processing stages\n- **Multi-Model AI Applications** - Coordinate between different AI models (LLMs, vision models, etc.) to solve complex tasks\n- **Research Assistants** - Develop workflows that can search, analyze, synthesize information, and provide comprehensive answers\n- **Content Generation Systems** - Create pipelines that generate, review, edit, and publish content with human-in-the-loop approval\n- **Customer Support Automation** - Build intelligent routing systems that can understand, categorize, and respond to customer inquiries\n\nThe async-first, event-driven architecture makes it easy to build workflows that can route between different capabilities, implement parallel processing patterns, loop over complex sequences, and maintain state across multiple steps - all the features you need to make your AI applications production-ready.\n",
    "ContentSha": "PrOw0sXCtw/kMf6D4N5eKll4XAnD3LIP64BH4KmOS5g=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "# LlamaIndex Workflows\n\n[![Kiểm thử đơn vị](https://github.com/run-llama/workflows/actions/workflows/test.yml/badge.svg)](https://github.com/run-llama/workflows/actions/workflows/test.yml)\n[![Tình trạng bao phủ](https://coveralls.io/repos/github/run-llama/workflows/badge.svg?branch=main)](https://coveralls.io/github/run-llama/workflows?branch=main)\n[![Số lượng người đóng góp GitHub](https://img.shields.io/github/contributors/run-llama/workflows)](https://github.com/run-llama/llama-index-workflows/graphs/contributors)\n\n\n[![PyPI - Lượt tải xuống](https://img.shields.io/pypi/dm/llama-index-workflows)](https://pypi.org/project/llama-index-workflows/)\n[![Discord](https://img.shields.io/discord/1059199217496772688)](https://discord.gg/dGcwcsnxhU)\n[![Twitter](https://img.shields.io/twitter/follow/llama_index)](https://x.com/llama_index)\n[![Reddit](https://img.shields.io/reddit/subreddit-subscribers/LlamaIndex?style=plastic&logo=reddit&label=r%2FLlamaIndex&labelColor=white)](https://www.reddit.com/r/LlamaIndex/)\n\nLlamaIndex Workflows là một framework để điều phối và liên kết các hệ thống phức tạp gồm nhiều bước và sự kiện.\n\n## Bạn có thể xây dựng gì với Workflows?\n\nWorkflows phát huy tối đa sức mạnh khi bạn cần điều phối các quy trình đa bước phức tạp liên quan đến mô hình AI, API và các quyết định. Dưới đây là một số ví dụ về những gì bạn có thể xây dựng:\n\n- **AI Agents** - Tạo ra các hệ thống thông minh có khả năng suy luận, ra quyết định và thực hiện hành động qua nhiều bước\n- **Chuỗi xử lý tài liệu** - Xây dựng hệ thống tiếp nhận, phân tích, tóm tắt và điều hướng tài liệu qua nhiều giai đoạn xử lý khác nhau\n- **Ứng dụng AI đa mô hình** - Điều phối giữa các mô hình AI khác nhau (LLM, mô hình thị giác, v.v.) để giải quyết các nhiệm vụ phức tạp\n- **Trợ lý nghiên cứu** - Phát triển các workflow có khả năng tìm kiếm, phân tích, tổng hợp thông tin và cung cấp câu trả lời toàn diện\n- **Hệ thống tạo nội dung** - Tạo ra các chuỗi xử lý để tạo, kiểm tra, chỉnh sửa và xuất bản nội dung với quy trình phê duyệt có sự tham gia của con người\n- **Tự động hóa hỗ trợ khách hàng** - Xây dựng hệ thống điều hướng thông minh có thể hiểu, phân loại và phản hồi các yêu cầu từ khách hàng\n\nKiến trúc ưu tiên bất đồng bộ, dựa trên sự kiện giúp bạn dễ dàng xây dựng các workflow có thể điều phối giữa các khả năng khác nhau, triển khai các mẫu xử lý song song, lặp qua các chuỗi phức tạp, và duy trì trạng thái qua nhiều bước - tất cả những tính năng bạn cần để đưa ứng dụng AI của mình vào vận hành thực tế.",
    "Status": "ok"
  },
  {
    "Id": 2,
    "Content": "## Key Features\n\n- **async-first** - workflows are built around python's async functionality - steps are async functions that process incoming events from an asyncio queue and emit new events to other queues. This also means that workflows work best in your async apps like FastAPI, Jupyter Notebooks, etc.\n- **event-driven** - workflows consist of steps and events. Organizing your code around events and steps makes it easier to reason about and test.\n- **state management** - each run of a workflow is self-contained, meaning you can launch a workflow, save information within it, serialize the state of a workflow and resume it later.\n- **observability** - workflows are automatically instrumented for observability, meaning you can use tools like `Arize Phoenix` and `OpenTelemetry` right out of the box.\n\n## Quick Start\n\nInstall the package:\n\n```bash\npip install llama-index-workflows\n```\n\nAnd create your first workflow:\n\n```python\nimport asyncio\nfrom pydantic import BaseModel, Field\nfrom workflows import Context, Workflow, step\nfrom workflows.events import Event, StartEvent, StopEvent\n\nclass MyEvent(Event):\n    msg: list[str]\n\nclass RunState(BaseModel):\n    num_runs: int = Field(default=0)\n\nclass MyWorkflow(Workflow):\n    @step\n    async def start(self, ctx: Context[RunState], ev: StartEvent) -> MyEvent:\n        async with ctx.store.edit_state() as state:\n            state.num_runs += 1\n\n            return MyEvent(msg=[ev.input_msg] * state.num_runs)\n\n    @step\n    async def process(self, ctx: Context[RunState], ev: MyEvent) -> StopEvent:\n        data_length = len(\"\".join(ev.msg))\n        new_msg = f\"Processed {len(ev.msg)} times, data length: {data_length}\"\n        return StopEvent(result=new_msg)\n\nasync def main():\n    workflow = MyWorkflow()\n",
    "ContentSha": "2y3u8OCMQZxV5p9IHLSVu9zwJnNilh9ufQ0F3eUU8bo=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "## Tính Năng Chính\n\n- **ưu tiên async** - các workflow được xây dựng dựa trên tính năng async của Python - các bước là các hàm async xử lý các sự kiện nhận vào từ một hàng đợi asyncio và phát ra các sự kiện mới tới các hàng đợi khác. Điều này cũng có nghĩa là workflow hoạt động tốt nhất trong các ứng dụng async của bạn như FastAPI, Jupyter Notebooks, v.v.\n- **dẫn động bởi sự kiện** - workflow bao gồm các bước và các sự kiện. Việc tổ chức mã nguồn của bạn xung quanh các sự kiện và bước giúp dễ dàng suy luận và kiểm thử hơn.\n- **quản lý trạng thái** - mỗi lần chạy một workflow là độc lập, nghĩa là bạn có thể khởi chạy một workflow, lưu thông tin trong đó, tuần tự hóa trạng thái của workflow và tiếp tục lại sau này.\n- **khả năng quan sát** - các workflow được tự động gắn công cụ quan sát, nghĩa là bạn có thể sử dụng các công cụ như `Arize Phoenix` và `OpenTelemetry` ngay lập tức.\n\n## Bắt Đầu Nhanh\n\nCài đặt gói:\n\n```bash\npip install llama-index-workflows\n```\n\nVà tạo workflow đầu tiên của bạn:\n\n```python\nimport asyncio\nfrom pydantic import BaseModel, Field\nfrom workflows import Context, Workflow, step\nfrom workflows.events import Event, StartEvent, StopEvent\n\nclass MyEvent(Event):\n    msg: list[str]\n\nclass RunState(BaseModel):\n    num_runs: int = Field(default=0)\n\nclass MyWorkflow(Workflow):\n    @step\n    async def start(self, ctx: Context[RunState], ev: StartEvent) -> MyEvent:\n        async with ctx.store.edit_state() as state:\n            state.num_runs += 1\n\n            return MyEvent(msg=[ev.input_msg] * state.num_runs)\n\n    @step\n    async def process(self, ctx: Context[RunState], ev: MyEvent) -> StopEvent:\n        data_length = len(\"\".join(ev.msg))\n        new_msg = f\"Processed {len(ev.msg)} times, data length: {data_length}\"\n        return StopEvent(result=new_msg)\n\nasync def main():\n    workflow = MyWorkflow()\n```",
    "Status": "ok"
  },
  {
    "Id": 3,
    "Content": "    # [optional] provide a context object to the workflow\n    ctx = Context(workflow)\n    result = await workflow.run(input_msg=\"Hello, world!\", ctx=ctx)\n    print(\"Workflow result:\", result)\n\n    # re-running with the same context will retain the state\n    result = await workflow.run(input_msg=\"Hello, world!\", ctx=ctx)\n    print(\"Workflow result:\", result)\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```\n\nIn the example above\n- Steps that accept a `StartEvent` will be run first.\n- Steps that return a `StopEvent` will end the workflow.\n- Intermediate events are user defined and can be used to pass information between steps.\n- The `Context` object is also used to share information between steps.\n\nVisit the [complete documentation](https://docs.llamaindex.ai/en/stable/understanding/workflows/) for more examples using `llama-index`!\n",
    "ContentSha": "uyQUuCIsjVJreK2NjTBRYDljiKMj85DiFJfof3LjHfg=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```python\n# [tùy chọn] cung cấp một đối tượng context cho workflow\nctx = Context(workflow)\nresult = await workflow.run(input_msg=\"Hello, world!\", ctx=ctx)\nprint(\"Kết quả Workflow:\", result)\n\n# chạy lại với cùng một context sẽ giữ nguyên trạng thái\nresult = await workflow.run(input_msg=\"Hello, world!\", ctx=ctx)\nprint(\"Kết quả Workflow:\", result)\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```\n\nTrong ví dụ trên\n- Các bước chấp nhận một `StartEvent` sẽ được chạy trước tiên.\n- Các bước trả về một `StopEvent` sẽ kết thúc workflow.\n- Các sự kiện trung gian do người dùng định nghĩa và có thể được sử dụng để truyền thông tin giữa các bước.\n- Đối tượng `Context` cũng được sử dụng để chia sẻ thông tin giữa các bước.\n\nTruy cập [tài liệu đầy đủ](https://docs.llamaindex.ai/en/stable/understanding/workflows/) để xem thêm các ví dụ sử dụng `llama-index`!\n",
    "Status": "ok"
  },
  {
    "Id": 4,
    "Content": "## More examples\n\n- [Basic Feature Run-Through](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/feature_walkthrough.ipynb)\n- [Building a Function Calling Agent with `llama-index`](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/agent.ipynb)\n- [Human-in-the-loop Iterative Document Extraction](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/document_processing.ipynb)\n- Observability\n  - [OpenTelemetry + Instrumentation Primer](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/observability/workflows_observability_pt1.ipynb)\n  - [OpenTelemetry + LlamaIndex](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/observability/workflows_observability_pt2.ipynb)\n  - [Arize Phoenix + LlamaIndex](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/observability/workflows_observablitiy_arize_phoenix.ipynb)\n  - [Langfuse + LlamaIndex](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/observability/workflows_observablitiy_langfuse.ipynb)\n\n## Related Packages\n\n- [Typescript Workflows](https://github.com/run-llama/workflows-ts)\n",
    "ContentSha": "DXwxZAa92R4ZF5bTYguiDm43cfYLGufWuZ5d/mzsQ24=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "## Thêm ví dụ\n\n- [Chạy thử các tính năng cơ bản](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/feature_walkthrough.ipynb)\n- [Xây dựng một Agent gọi hàm với `llama-index`](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/agent.ipynb)\n- [Trích xuất tài liệu lặp lại với sự tham gia của con người](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/document_processing.ipynb)\n- Khả năng quan sát\n  - [Giới thiệu về OpenTelemetry + Instrumentation](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/observability/workflows_observability_pt1.ipynb)\n  - [OpenTelemetry + LlamaIndex](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/observability/workflows_observability_pt2.ipynb)\n  - [Arize Phoenix + LlamaIndex](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/observability/workflows_observablitiy_arize_phoenix.ipynb)\n  - [Langfuse + LlamaIndex](https://raw.githubusercontent.com/run-llama/workflows-py/main/./examples/observability/workflows_observablitiy_langfuse.ipynb)\n\n## Các gói liên quan\n\n- [Workflows Typescript](https://github.com/run-llama/workflows-ts)\n",
    "Status": "ok"
  }
]