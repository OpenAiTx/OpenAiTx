[
  {
    "row": 1,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 2,
    "rowsha": "6vgIR6WfUAFmULhn8LhxFttPwZEo/YwGhN1DAECwHCQ=",
    "originContent": "- `wav_name` is the name of the output wav file.",
    "translatedContent": "- `wav_name` is de naam van het uitvoer wav-bestand."
  },
  {
    "row": 3,
    "rowsha": "7BNq8UaBvTut4Ow/oJBAgIDTn3EwEZXK7mlUaYdFwqw=",
    "originContent": "- `spk1_prompt_transcription` is the transcription of the first speaker's prompt wav, e.g, \"Hello\"",
    "translatedContent": "- `spk1_prompt_transcription` is de transcriptie van het prompt wav-bestand van de eerste spreker, bijvoorbeeld \"Hallo\"."
  },
  {
    "row": 4,
    "rowsha": "CES8w9dqVdkdJyOJBUVP282aaKeevVWB3d/+59TEsuk=",
    "originContent": "- `spk2_prompt_transcription` is the transcription of the second speaker's prompt wav, e.g, \"How are you?\"",
    "translatedContent": "- `spk2_prompt_transcription` is de transcriptie van het prompt wav-bestand van de tweede spreker, bijvoorbeeld \"Hoe gaat het?\""
  },
  {
    "row": 5,
    "rowsha": "gXLLRf4BR7Xko2q2l4nK04KIs/L8CjvZ/UBQaP1+vck=",
    "originContent": "- `spk1_prompt_wav` is the path to the first speaker's prompt wav file.",
    "translatedContent": "- `spk1_prompt_wav` is het pad naar het prompt wav-bestand van de eerste spreker."
  },
  {
    "row": 6,
    "rowsha": "oS1+heJwBnnDtA57WYtG6LbzxK79DOIeb8hwhZQwcDg=",
    "originContent": "- `spk2_prompt_wav` is the path to the second speaker's prompt wav file.",
    "translatedContent": "- `spk2_prompt_wav` is het pad naar het prompt wav-bestand van de tweede spreker."
  },
  {
    "row": 7,
    "rowsha": "M4Z2DDajNBdyF/JosIaDZ44oyZnjNA7lzfGzEpuoako=",
    "originContent": "- `text` is the text to be synthesized, e.g. \"[S1] I'm fine. [S2] What's your name? [S1] I'm Eric. [S2] Hi Eric.\"",
    "translatedContent": "- `text` is de te synthetiseren tekst, bijvoorbeeld \"[S1] Het gaat goed. [S2] Hoe heet je? [S1] Ik ben Eric. [S2] Hallo Eric.\""
  },
  {
    "row": 8,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 9,
    "rowsha": "SdDI3h73wOzKSM3kbrbNrmpigHGer7kumuaZsQgAeao=",
    "originContent": "### 3 Guidance for better usage:",
    "translatedContent": "### 3 Richtlijnen voor beter gebruik:"
  },
  {
    "row": 10,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 11,
    "rowsha": "cVxukE6jyFFOxlNKI5ecOTo/suYYJ8hnYyW2XA2wg+o=",
    "originContent": "#### 3.1 Prompt length",
    "translatedContent": "#### 3.1 Lengte van de prompt"
  },
  {
    "row": 12,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 13,
    "rowsha": "f19zq78QrLul7wiVSlCSojGS7qNEvtef9GFg6AA8eMY=",
    "originContent": "We recommand a short prompt wav file (e.g., less than 3 seconds for single-speaker speech generation, less than 10 seconds for dialogue speech generation) for faster inference speed. A very long prompt will slow down the inference and degenerate the speech quality.",
    "translatedContent": "Wij raden een kort prompt wav-bestand aan (bijvoorbeeld minder dan 3 seconden voor spraakgeneratie met één spreker, minder dan 10 seconden voor dialoogspraakgeneratie) voor snellere inferentiesnelheid. Een heel lang promptbestand vertraagt de inferentie en verslechtert de spraakkwaliteit."
  },
  {
    "row": 14,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 15,
    "rowsha": "lpgNpm20ulCcTiEU/xfEVVgMZhjiQjymkdljF8dD/vw=",
    "originContent": "#### 3.2 Speed optimization",
    "translatedContent": "#### 3.2 Snelheidsoptimalisatie"
  },
  {
    "row": 16,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 17,
    "rowsha": "iBJxMfYOjV9HvSuRT3p/EsU/iATeDCDAk/wGWLXqQI8=",
    "originContent": "If the inference speed is unsatisfactory, you can speed it up as follows:",
    "translatedContent": "Als de inferentiesnelheid onvoldoende is, kun je deze als volgt verhogen:"
  },
  {
    "row": 18,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 19,
    "rowsha": "IzTHxzS1e5yJRhHF5d8CsjfqjIzhNX1AeGR4FTjuUCA=",
    "originContent": "- **Distill model and less steps**: For the single-speaker speech generation model, we use the `zipvoice` model by default for better speech quality. If faster speed is a priority, you can switch to the `zipvoice_distill` and can reduce the `--num-steps` to as low as `4` (8 by default).",
    "translatedContent": "- **Gedistilleerd model en minder stappen**: Voor het spraakgeneratiemodel met één spreker gebruiken we standaard het `zipvoice`-model voor betere spraakkwaliteit. Als een hogere snelheid de prioriteit heeft, kun je overschakelen op `zipvoice_distill` en het aantal stappen (`--num-steps`) verlagen tot minimaal `4` (standaard 8)."
  },
  {
    "row": 20,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 21,
    "rowsha": "mNiqyHjFr4rbx4boH0cix2peH8Q0+tDTOlzgZeLLDqM=",
    "originContent": "- **CPU speedup with multi-threading**: When running on CPU, you can pass the `--num-thread` parameter (e.g., `--num-thread 4`) to increase the number of threads for faster speed. We use 1 thread by default.",
    "translatedContent": "- **CPU-versnelling met multithreading**: Bij gebruik van de CPU kun je de parameter `--num-thread` meegeven (bijv. `--num-thread 4`) om het aantal threads te verhogen voor meer snelheid. Standaard gebruiken we 1 thread."
  },
  {
    "row": 22,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 23,
    "rowsha": "YqtmXdPz7OfUIbrIkeeIwyKEPdEZUqn3m5EyTNd967s=",
    "originContent": "- **CPU speedup with ONNX**: When running on CPU, you can use ONNX models with `zipvoice.bin.infer_zipvoice_onnx` for faster speed (haven't supported ONNX for dialogue generation models yet). For even faster speed, you can further set `--onnx-int8 True` to use an INT8-quantized ONNX model. Note that the quantized model will result in a certain degree of speech quality degradation. **Don't use ONNX on GPU**, as it is slower than PyTorch on GPU.",
    "translatedContent": "- **CPU-versnelling met ONNX**: Bij gebruik van de CPU kun je ONNX-modellen gebruiken met `zipvoice.bin.infer_zipvoice_onnx` voor hogere snelheid (ONNX wordt nog niet ondersteund voor dialooggeneratiemodellen). Voor nog meer snelheid kun je `--onnx-int8 True` instellen om een INT8-gekwantiseerd ONNX-model te gebruiken. Houd er rekening mee dat het gekwantiseerde model leidt tot een zekere mate van degradatie van de spraakkwaliteit. **Gebruik ONNX niet op GPU**, omdat het trager is dan PyTorch op GPU."
  },
  {
    "row": 24,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 25,
    "rowsha": "kj1A4DWWe02Utusq07KI3xRRH55QdxQWRCzFeimIzww=",
    "originContent": "- **GPU Acceleration with NVIDIA TensorRT**: For a significant performance boost on NVIDIA GPUs, first export the model to a TensorRT engine using zipvoice.bin.tensorrt_export. Then, run inference on your dataset (e.g., a Hugging Face dataset) with zipvoice.bin.infer_zipvoice. This can achieve approximately 2x the throughput compared to the standard PyTorch implementation on a GPU.",
    "translatedContent": "- **GPU-versnelling met NVIDIA TensorRT**: Voor een aanzienlijke prestatieverbetering op NVIDIA GPU's exporteer je eerst het model naar een TensorRT-engine met zipvoice.bin.tensorrt_export. Voer daarna inferentie uit op je dataset (bijvoorbeeld een Hugging Face-dataset) met zipvoice.bin.infer_zipvoice. Dit kan ongeveer 2x meer throughput behalen dan de standaard PyTorch-implementatie op een GPU."
  },
  {
    "row": 26,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 27,
    "rowsha": "fze8iMUXPcPsZgNFyWFzWSuCffZnzh7SpzLs21tQLtE=",
    "originContent": "#### 3.3 Memory control",
    "translatedContent": "#### 3.3 Geheugenbeheer"
  },
  {
    "row": 28,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 29,
    "rowsha": "uM67TExtHYq7ALHmglqtjLRqv0Xu0OOSx2aFJquZPmw=",
    "originContent": "The given text will be splitted into chunks based on punctuation (for single-speaker speech generation) or speaker-turn symbol (for dialogue speech generation). Then, the chunked texts will be processed in batches. Therefore, the model can process arbitrarily long text with almost constant memory usage. You can control memory usage by adjusting the `--max-duration` parameter.",
    "translatedContent": "De opgegeven tekst wordt gesplitst in stukken op basis van leestekens (voor spraakgeneratie met één spreker) of sprekerwisselsymbolen (voor dialoogspraakgeneratie). Vervolgens worden de tekststukken in batches verwerkt. Hierdoor kan het model willekeurig lange tekst verwerken met vrijwel constant geheugengebruik. Je kunt het geheugengebruik regelen met de parameter `--max-duration`."
  },
  {
    "row": 30,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 31,
    "rowsha": "foa86E9JcH+Sc/k2OCmyfIKHwggsFBXhSUfHDcmJQA0=",
    "originContent": "#### 3.4 \"Raw\" evaluation",
    "translatedContent": "#### 3.4 \"Ruwe\" evaluatie"
  },
  {
    "row": 32,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 33,
    "rowsha": "+2nxKNvXmuxUQpf2Z+hw0Rxydt00FpmK4y4rlK5/8og=",
    "originContent": "By default, we preprocess inputs (prompt wav, prompt transcription, and text) for efficient inference and better performance. If you want to evaluate the model’s \"raw\" performance using exact provided inputs (e.g., to reproduce the results in our paper), you can pass `--raw-evaluation True`.",
    "translatedContent": "Standaard preprocessen we de invoer (prompt wav, prompt transcriptie en tekst) voor efficiënte inferentie en betere prestaties. Als je de \"ruwe\" prestaties van het model wilt evalueren met exact de opgegeven invoer (bijvoorbeeld om de resultaten in ons paper te reproduceren), kun je `--raw-evaluation True` meegeven."
  },
  {
    "row": 34,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 35,
    "rowsha": "g658opDssPKmJCvr7Jw9N130Xud1IbMHTwMK+S89WO0=",
    "originContent": "#### 3.5 Short text",
    "translatedContent": "#### 3.5 Korte tekst"
  },
  {
    "row": 36,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 37,
    "rowsha": "/IVkHehTtKgVQNwGOgQO/BoRh95RFHVJPH3e0W6Gixs=",
    "originContent": "When generating speech for very short texts (e.g., one or two words), the generated speech may sometimes omit certain pronunciations. To resolve this issue, you can pass `--speed 0.3` (where 0.3 is a tunable value) to extend the duration of the generated speech.",
    "translatedContent": "Bij het genereren van spraak voor zeer korte teksten (bijvoorbeeld één of twee woorden) kan het gebeuren dat bepaalde uitspraken soms worden weggelaten. Om dit probleem op te lossen kun je `--speed 0.3` meegeven (waarbij 0.3 een afstembare waarde is) om de duur van de gegenereerde spraak te verlengen."
  },
  {
    "row": 38,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 39,
    "rowsha": "PAPz1JYDhpLF6dsiNH/BVipH4SufvLcqzLiPLACOcK4=",
    "originContent": "#### 3.6 Correcting mispronounced chinese polyphone characters",
    "translatedContent": "#### 3.6 Het corrigeren van verkeerd uitgesproken Chinese polyfoonkarakters"
  },
  {
    "row": 40,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 41,
    "rowsha": "hF52KZEnGKLuaot2w0AmXt52eB6Y3adYIo2qMJSMx5o=",
    "originContent": "We use [pypinyin](https://github.com/mozillazg/python-pinyin) to convert Chinese characters to pinyin. However, it can occasionally mispronounce **polyphone characters** (多音字).",
    "translatedContent": "We gebruiken [pypinyin](https://github.com/mozillazg/python-pinyin) om Chinese karakters naar pinyin om te zetten. Echter, het kan soms **polyfone karakters** (多音字) verkeerd uitspreken."
  },
  {
    "row": 42,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 43,
    "rowsha": "h6Qq8AvUPYme90k2BWG054cVE6RHNflr0OwdnKA4BEE=",
    "originContent": "To manually correct these mispronunciations, enclose the **corrected pinyin** in angle brackets `< >` and include the **tone mark**.",
    "translatedContent": "Om deze verkeerde uitspraken handmatig te corrigeren, zet je de **gecorrigeerde pinyin** tussen punthaken `< >` en voeg je het **toonaccent** toe."
  },
  {
    "row": 44,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 45,
    "rowsha": "fP4bnCe7+qhcgDDajGMIv4obksa4WSdUp3hExEbpci0=",
    "originContent": "**Example:**",
    "translatedContent": "**Voorbeeld:**"
  },
  {
    "row": 46,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 47,
    "rowsha": "ntwz9/IQqGC1ThJXQn9D83h+54cDriyg2snkkrk0KoI=",
    "originContent": "- Original text: `这把剑长三十公分`",
    "translatedContent": "- Originele tekst: `这把剑长三十公分`"
  },
  {
    "row": 48,
    "rowsha": "sfnMRvscnvdKs1fvbVePwH0RpAikXkFIi9i7HZK7D9w=",
    "originContent": "- Correct the pinyin of `长`:  `这把剑<chang2>三十公分`",
    "translatedContent": "- Corrigeer de pinyin van `长`:  `这把剑<chang2>三十公分`"
  },
  {
    "row": 49,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 50,
    "rowsha": "7f45Y23fyK7AQrUO7HdTtPZZzoyRkW6WwoznauYmQew=",
    "originContent": "> **Note:** If you want to manually assign multiple pinyins, enclose each pinyin with `<>`, e.g., `这把<jian4><chang2><san1>十公分`",
    "translatedContent": "> **Opmerking:** Wil je handmatig meerdere pinyins toewijzen, zet dan elke pinyin tussen `<>`, bijvoorbeeld: `这把<jian4><chang2><san1>十公分`"
  },
  {
    "row": 51,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 52,
    "rowsha": "FJBRXZnczlB/CZyp0UgEFMr440NrcuTPBheyQJ9lxZI=",
    "originContent": "#### 3.7 Remove long silences from the generated speech",
    "translatedContent": "#### 3.7 Verwijder lange stiltes uit de gegenereerde spraak"
  },
  {
    "row": 53,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 54,
    "rowsha": "9UF5wHdPZ48OWeIPfCnOHPEWzgW4Z6I0e+GaTEZ1GXI=",
    "originContent": "Model will automatically determine the positions and lengths of silences in the generated speech. It occasionally has long silence in the middle of the speech. If you don't want this, you can pass `--remove-long-sil` to remove long silences in the middle of the generated speech (edge silences will be removed by default).",
    "translatedContent": "Het model bepaalt automatisch de posities en lengtes van stiltes in de gegenereerde spraak. Soms zit er een lange stilte midden in de spraak. Wil je dit niet, dan kun je `--remove-long-sil` meegeven om lange stiltes in het midden van de gegenereerde spraak te verwijderen (randstiltes worden standaard verwijderd)."
  },
  {
    "row": 55,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 56,
    "rowsha": "t3GDCbkkN4PM6Y7xA/ZDAXgu4WdMFfXJ+5E/xKU9AKo=",
    "originContent": "#### 3.8 Model downloading",
    "translatedContent": "#### 3.8 Model downloaden"
  },
  {
    "row": 57,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 58,
    "rowsha": "I2UvthbxkflPXxq8Yy6W9nJCtzb40mZPJbfmDIWQPmA=",
    "originContent": "If you have trouble connecting to HuggingFace when downloading the pre-trained models, try switching endpoint to the mirror site: `export HF_ENDPOINT=https://hf-mirror.com`.",
    "translatedContent": "Als je problemen hebt met verbinden naar HuggingFace bij het downloaden van de voorgetrainde modellen, probeer dan het endpoint te wisselen naar de mirror-site: `export HF_ENDPOINT=https://hf-mirror.com`."
  },
  {
    "row": 59,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 60,
    "rowsha": "SEsrfyGZhBYqHMMdMldgN+tSz6ynJT5BVJeLrTV5lHw=",
    "originContent": "## Train Your Own Model",
    "translatedContent": "## Train Je Eigen Model"
  },
  {
    "row": 61,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 62,
    "rowsha": "XaSJNyFaxQRx1Xc0mphwUGAxovKELo/54WkMCnFDLyE=",
    "originContent": "See the [egs](egs) directory for training, fine-tuning and evaluation examples.",
    "translatedContent": "Zie de [egs](egs) map voor voorbeelden van training, fine-tuning en evaluatie."
  },
  {
    "row": 63,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 64,
    "rowsha": "tfXaiJ7qvaTkZXp5azeYhmiU88iPPhEvLfYayUjE5+g=",
    "originContent": "## Production Deployment",
    "translatedContent": "## Productie Implementatie"
  },
  {
    "row": 65,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 66,
    "rowsha": "Tv94iSjTAB/OzGKZj2XftoBUCOzD2x+C0/xHRwRVo1c=",
    "originContent": "### NVIDIA Triton GPU Runtime",
    "translatedContent": "### NVIDIA Triton GPU Runtime"
  },
  {
    "row": 67,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 68,
    "rowsha": "cGPOVgf7Mpi/ILRt8hu96EmjQo85nhgnSfBGLfBqMeM=",
    "originContent": "For production-ready deployment with high performance and scalability, check out the [Triton Inference Server integration](runtime/nvidia_triton/) that provides optimized TensorRT engines, concurrent request handling, and both gRPC/HTTP APIs for enterprise use.",
    "translatedContent": "Voor productieklare implementatie met hoge prestaties en schaalbaarheid, bekijk de [Triton Inference Server integratie](runtime/nvidia_triton/) die geoptimaliseerde TensorRT-engines, gelijktijdige aanvraagverwerking en zowel gRPC/HTTP API's voor zakelijk gebruik biedt."
  },
  {
    "row": 69,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 70,
    "rowsha": "qR/CeuOSoGV5ipBKRWpnI+ohlytt878WhTEjtxZenks=",
    "originContent": "### CPU Deployment",
    "translatedContent": "### CPU Implementatie"
  },
  {
    "row": 71,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 72,
    "rowsha": "B8jnXFyKu8XRyVw/Pu0Xuj1ted9/BVoBfwJ1WW9LrcE=",
    "originContent": "Check [sherpa-onnx](https://github.com/k2-fsa/sherpa-onnx/pull/2487#issuecomment-3227884498) for the C++ deployment solution on CPU.",
    "translatedContent": "Bekijk [sherpa-onnx](https://github.com/k2-fsa/sherpa-onnx/pull/2487#issuecomment-3227884498) voor de C++ implementatie-oplossing op CPU."
  },
  {
    "row": 73,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 74,
    "rowsha": "dEqRbPItUt3FEp1iC+8Ww+A6L57yd6oGeXfxSn5BYzs=",
    "originContent": "## Discussion & Communication",
    "translatedContent": "## Discussie & Communicatie"
  },
  {
    "row": 75,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 76,
    "rowsha": "wjQUwaDgSP1a6ggLgGx8TWt44Dxu5IlJytNwCAlzZKg=",
    "originContent": "You can directly discuss on [Github Issues](https://github.com/k2-fsa/ZipVoice/issues).",
    "translatedContent": "Je kunt direct discussiëren op [Github Issues](https://github.com/k2-fsa/ZipVoice/issues)."
  },
  {
    "row": 77,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 78,
    "rowsha": "WLbsT+slCE72T0wpzVIN8KFxhP+RAw29VxFhJcBEEIo=",
    "originContent": "You can also scan the QR code to join our wechat group or follow our wechat official account.",
    "translatedContent": "Je kunt ook de QR-code scannen om lid te worden van onze wechat-groep of ons officiële wechat-account te volgen."
  },
  {
    "row": 79,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 80,
    "rowsha": "XMNeg//PyHlCkY1XlL7caNd2vlVOKKoslrNeasADjMY=",
    "originContent": "| Wechat Group | Wechat Official Account |",
    "translatedContent": "| Wechat Groep | Wechat Officieel Account |"
  },
  {
    "row": 81,
    "rowsha": "jdP52Pdk9hJ4eEQC1YzC887/bGdD6V25zHK1FxUbFjM=",
    "originContent": "| ------------ | ----------------------- |",
    "translatedContent": "| ------------ | ----------------------- |"
  },
  {
    "row": 82,
    "rowsha": "Q6eYrtLPPuG0fiZxZqhYquTYNk0vlyIOh+CRuwGZVk4=",
    "originContent": "|![wechat](https://k2-fsa.org/zh-CN/assets/pic/wechat_group.jpg) |![wechat](https://k2-fsa.org/zh-CN/assets/pic/wechat_account.jpg) |",
    "translatedContent": "|![wechat](https://k2-fsa.org/zh-CN/assets/pic/wechat_group.jpg) |![wechat](https://k2-fsa.org/zh-CN/assets/pic/wechat_account.jpg) |"
  },
  {
    "row": 83,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 84,
    "rowsha": "ZwTp5ajUmpHTJefyHhIKzXcG2wnB1jv8iv8cvmdcb/g=",
    "originContent": "## Citation",
    "translatedContent": "## Citaat"
  },
  {
    "row": 85,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  }
]