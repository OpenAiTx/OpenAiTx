[
  {
    "row": 1,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "- `wav_name` est le nom du fichier wav de sortie."
  },
  {
    "row": 2,
    "rowsha": "6vgIR6WfUAFmULhn8LhxFttPwZEo/YwGhN1DAECwHCQ=",
    "originContent": "- `wav_name` is the name of the output wav file.",
    "translatedContent": "- `spk1_prompt_transcription` est la transcription du prompt du premier locuteur, par exemple, \"Bonjour\""
  },
  {
    "row": 3,
    "rowsha": "7BNq8UaBvTut4Ow/oJBAgIDTn3EwEZXK7mlUaYdFwqw=",
    "originContent": "- `spk1_prompt_transcription` is the transcription of the first speaker's prompt wav, e.g, \"Hello\"",
    "translatedContent": "- `spk2_prompt_transcription` est la transcription du prompt du deuxième locuteur, par exemple, \"Comment ça va ?\""
  },
  {
    "row": 4,
    "rowsha": "CES8w9dqVdkdJyOJBUVP282aaKeevVWB3d/+59TEsuk=",
    "originContent": "- `spk2_prompt_transcription` is the transcription of the second speaker's prompt wav, e.g, \"How are you?\"",
    "translatedContent": "- `spk1_prompt_wav` est le chemin vers le fichier wav du prompt du premier locuteur."
  },
  {
    "row": 5,
    "rowsha": "gXLLRf4BR7Xko2q2l4nK04KIs/L8CjvZ/UBQaP1+vck=",
    "originContent": "- `spk1_prompt_wav` is the path to the first speaker's prompt wav file.",
    "translatedContent": "- `spk2_prompt_wav` est le chemin vers le fichier wav du prompt du deuxième locuteur."
  },
  {
    "row": 6,
    "rowsha": "oS1+heJwBnnDtA57WYtG6LbzxK79DOIeb8hwhZQwcDg=",
    "originContent": "- `spk2_prompt_wav` is the path to the second speaker's prompt wav file.",
    "translatedContent": "- `text` est le texte à synthétiser, par exemple, \"[S1] Je vais bien. [S2] Comment tu t'appelles ? [S1] Je m'appelle Eric. [S2] Salut Eric.\""
  },
  {
    "row": 7,
    "rowsha": "M4Z2DDajNBdyF/JosIaDZ44oyZnjNA7lzfGzEpuoako=",
    "originContent": "- `text` is the text to be synthesized, e.g. \"[S1] I'm fine. [S2] What's your name? [S1] I'm Eric. [S2] Hi Eric.\"",
    "translatedContent": ""
  },
  {
    "row": 8,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "### 3 Conseils pour une meilleure utilisation :"
  },
  {
    "row": 9,
    "rowsha": "SdDI3h73wOzKSM3kbrbNrmpigHGer7kumuaZsQgAeao=",
    "originContent": "### 3 Guidance for better usage:",
    "translatedContent": ""
  },
  {
    "row": 10,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "#### 3.1 Longueur du prompt"
  },
  {
    "row": 11,
    "rowsha": "cVxukE6jyFFOxlNKI5ecOTo/suYYJ8hnYyW2XA2wg+o=",
    "originContent": "#### 3.1 Prompt length",
    "translatedContent": ""
  },
  {
    "row": 12,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "Nous recommandons un fichier wav de prompt court (par exemple, moins de 3 secondes pour la génération de parole à un seul locuteur, moins de 10 secondes pour la génération de dialogue) pour une vitesse d'inférence plus rapide. Un prompt très long ralentira l'inférence et dégradera la qualité de la parole."
  },
  {
    "row": 13,
    "rowsha": "f19zq78QrLul7wiVSlCSojGS7qNEvtef9GFg6AA8eMY=",
    "originContent": "We recommand a short prompt wav file (e.g., less than 3 seconds for single-speaker speech generation, less than 10 seconds for dialogue speech generation) for faster inference speed. A very long prompt will slow down the inference and degenerate the speech quality.",
    "translatedContent": ""
  },
  {
    "row": 14,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "#### 3.2 Optimisation de la vitesse"
  },
  {
    "row": 15,
    "rowsha": "lpgNpm20ulCcTiEU/xfEVVgMZhjiQjymkdljF8dD/vw=",
    "originContent": "#### 3.2 Speed optimization",
    "translatedContent": ""
  },
  {
    "row": 16,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "Si la vitesse d'inférence n'est pas satisfaisante, vous pouvez l'accélérer comme suit :"
  },
  {
    "row": 17,
    "rowsha": "iBJxMfYOjV9HvSuRT3p/EsU/iATeDCDAk/wGWLXqQI8=",
    "originContent": "If the inference speed is unsatisfactory, you can speed it up as follows:",
    "translatedContent": ""
  },
  {
    "row": 18,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "- **Modèle distillé et moins d'étapes** : Pour le modèle de génération de parole à un seul locuteur, nous utilisons par défaut le modèle `zipvoice` pour une meilleure qualité vocale. Si la vitesse est prioritaire, vous pouvez passer à `zipvoice_distill` et réduire le paramètre `--num-steps` jusqu'à `4` (8 par défaut)."
  },
  {
    "row": 19,
    "rowsha": "IzTHxzS1e5yJRhHF5d8CsjfqjIzhNX1AeGR4FTjuUCA=",
    "originContent": "- **Distill model and less steps**: For the single-speaker speech generation model, we use the `zipvoice` model by default for better speech quality. If faster speed is a priority, you can switch to the `zipvoice_distill` and can reduce the `--num-steps` to as low as `4` (8 by default).",
    "translatedContent": ""
  },
  {
    "row": 20,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "- **Accélération CPU avec multi-threading** : Lors de l'exécution sur CPU, vous pouvez passer le paramètre `--num-thread` (par exemple, `--num-thread 4`) pour augmenter le nombre de threads et accélérer l'exécution. Nous utilisons 1 thread par défaut."
  },
  {
    "row": 21,
    "rowsha": "mNiqyHjFr4rbx4boH0cix2peH8Q0+tDTOlzgZeLLDqM=",
    "originContent": "- **CPU speedup with multi-threading**: When running on CPU, you can pass the `--num-thread` parameter (e.g., `--num-thread 4`) to increase the number of threads for faster speed. We use 1 thread by default.",
    "translatedContent": ""
  },
  {
    "row": 22,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "- **Accélération CPU avec ONNX** : Lors de l'exécution sur CPU, vous pouvez utiliser des modèles ONNX avec `zipvoice.bin.infer_zipvoice_onnx` pour une vitesse accrue (pas encore de support ONNX pour les modèles de génération de dialogue). Pour encore plus de vitesse, vous pouvez aussi définir `--onnx-int8 True` pour utiliser un modèle ONNX quantifié INT8. Notez que le modèle quantifié entraînera une certaine dégradation de la qualité vocale. **N'utilisez pas ONNX sur GPU**, car il est plus lent que PyTorch sur GPU."
  },
  {
    "row": 23,
    "rowsha": "YqtmXdPz7OfUIbrIkeeIwyKEPdEZUqn3m5EyTNd967s=",
    "originContent": "- **CPU speedup with ONNX**: When running on CPU, you can use ONNX models with `zipvoice.bin.infer_zipvoice_onnx` for faster speed (haven't supported ONNX for dialogue generation models yet). For even faster speed, you can further set `--onnx-int8 True` to use an INT8-quantized ONNX model. Note that the quantized model will result in a certain degree of speech quality degradation. **Don't use ONNX on GPU**, as it is slower than PyTorch on GPU.",
    "translatedContent": ""
  },
  {
    "row": 24,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "- **Accélération GPU avec NVIDIA TensorRT** : Pour une amélioration significative des performances sur GPU NVIDIA, exportez d'abord le modèle vers un moteur TensorRT avec zipvoice.bin.tensorrt_export. Ensuite, lancez l'inférence sur votre ensemble de données (par exemple, un dataset Hugging Face) avec zipvoice.bin.infer_zipvoice. Cela permet d'obtenir environ 2x plus de débit que l'implémentation PyTorch standard sur GPU."
  },
  {
    "row": 25,
    "rowsha": "kj1A4DWWe02Utusq07KI3xRRH55QdxQWRCzFeimIzww=",
    "originContent": "- **GPU Acceleration with NVIDIA TensorRT**: For a significant performance boost on NVIDIA GPUs, first export the model to a TensorRT engine using zipvoice.bin.tensorrt_export. Then, run inference on your dataset (e.g., a Hugging Face dataset) with zipvoice.bin.infer_zipvoice. This can achieve approximately 2x the throughput compared to the standard PyTorch implementation on a GPU.",
    "translatedContent": ""
  },
  {
    "row": 26,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "#### 3.3 Contrôle de la mémoire"
  },
  {
    "row": 27,
    "rowsha": "fze8iMUXPcPsZgNFyWFzWSuCffZnzh7SpzLs21tQLtE=",
    "originContent": "#### 3.3 Memory control",
    "translatedContent": ""
  },
  {
    "row": 28,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "Le texte fourni sera découpé en segments en fonction de la ponctuation (pour la génération de parole à un seul locuteur) ou du symbole de changement de locuteur (pour la génération de dialogue). Ensuite, les textes segmentés seront traités par lots. Ainsi, le modèle peut traiter des textes arbitrairement longs avec une utilisation mémoire quasi constante. Vous pouvez contrôler l'utilisation de la mémoire en ajustant le paramètre `--max-duration`."
  },
  {
    "row": 29,
    "rowsha": "uM67TExtHYq7ALHmglqtjLRqv0Xu0OOSx2aFJquZPmw=",
    "originContent": "The given text will be splitted into chunks based on punctuation (for single-speaker speech generation) or speaker-turn symbol (for dialogue speech generation). Then, the chunked texts will be processed in batches. Therefore, the model can process arbitrarily long text with almost constant memory usage. You can control memory usage by adjusting the `--max-duration` parameter.",
    "translatedContent": ""
  },
  {
    "row": 30,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "#### 3.4 Évaluation « brute »"
  },
  {
    "row": 31,
    "rowsha": "foa86E9JcH+Sc/k2OCmyfIKHwggsFBXhSUfHDcmJQA0=",
    "originContent": "#### 3.4 \"Raw\" evaluation",
    "translatedContent": ""
  },
  {
    "row": 32,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "Par défaut, nous prétraitons les entrées (wav prompt, transcription du prompt et texte) pour une inférence efficace et de meilleures performances. Si vous souhaitez évaluer la performance « brute » du modèle en utilisant exactement les entrées fournies (par exemple, pour reproduire les résultats de notre article), vous pouvez passer `--raw-evaluation True`."
  },
  {
    "row": 33,
    "rowsha": "+2nxKNvXmuxUQpf2Z+hw0Rxydt00FpmK4y4rlK5/8og=",
    "originContent": "By default, we preprocess inputs (prompt wav, prompt transcription, and text) for efficient inference and better performance. If you want to evaluate the model’s \"raw\" performance using exact provided inputs (e.g., to reproduce the results in our paper), you can pass `--raw-evaluation True`.",
    "translatedContent": ""
  },
  {
    "row": 34,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "#### 3.5 Texte court"
  },
  {
    "row": 35,
    "rowsha": "g658opDssPKmJCvr7Jw9N130Xud1IbMHTwMK+S89WO0=",
    "originContent": "#### 3.5 Short text",
    "translatedContent": ""
  },
  {
    "row": 36,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "Lors de la génération de parole pour des textes très courts (par exemple, un ou deux mots), la parole générée peut parfois omettre certaines prononciations. Pour résoudre ce problème, vous pouvez passer `--speed 0.3` (où 0.3 est une valeur ajustable) pour allonger la durée de la parole générée."
  },
  {
    "row": 37,
    "rowsha": "/IVkHehTtKgVQNwGOgQO/BoRh95RFHVJPH3e0W6Gixs=",
    "originContent": "When generating speech for very short texts (e.g., one or two words), the generated speech may sometimes omit certain pronunciations. To resolve this issue, you can pass `--speed 0.3` (where 0.3 is a tunable value) to extend the duration of the generated speech.",
    "translatedContent": ""
  },
  {
    "row": 38,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "#### 3.6 Correction des caractères polyphoniques chinois mal prononcés"
  },
  {
    "row": 39,
    "rowsha": "PAPz1JYDhpLF6dsiNH/BVipH4SufvLcqzLiPLACOcK4=",
    "originContent": "#### 3.6 Correcting mispronounced chinese polyphone characters",
    "translatedContent": ""
  },
  {
    "row": 40,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 41,
    "rowsha": "hF52KZEnGKLuaot2w0AmXt52eB6Y3adYIo2qMJSMx5o=",
    "originContent": "We use [pypinyin](https://github.com/mozillazg/python-pinyin) to convert Chinese characters to pinyin. However, it can occasionally mispronounce **polyphone characters** (多音字).",
    "translatedContent": "Nous utilisons [pypinyin](https://github.com/mozillazg/python-pinyin) pour convertir les caractères chinois en pinyin. Cependant, il peut parfois mal prononcer les **caractères polyphoniques** (多音字)."
  },
  {
    "row": 42,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 43,
    "rowsha": "h6Qq8AvUPYme90k2BWG054cVE6RHNflr0OwdnKA4BEE=",
    "originContent": "To manually correct these mispronunciations, enclose the **corrected pinyin** in angle brackets `< >` and include the **tone mark**.",
    "translatedContent": "Pour corriger manuellement ces erreurs de prononciation, entourez le **pinyin corrigé** avec des chevrons `< >` et incluez la **marque de ton**."
  },
  {
    "row": 44,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 45,
    "rowsha": "fP4bnCe7+qhcgDDajGMIv4obksa4WSdUp3hExEbpci0=",
    "originContent": "**Example:**",
    "translatedContent": "**Exemple :**"
  },
  {
    "row": 46,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 47,
    "rowsha": "ntwz9/IQqGC1ThJXQn9D83h+54cDriyg2snkkrk0KoI=",
    "originContent": "- Original text: `这把剑长三十公分`",
    "translatedContent": "- Texte original : `这把剑长三十公分`"
  },
  {
    "row": 48,
    "rowsha": "sfnMRvscnvdKs1fvbVePwH0RpAikXkFIi9i7HZK7D9w=",
    "originContent": "- Correct the pinyin of `长`:  `这把剑<chang2>三十公分`",
    "translatedContent": "- Corrigez le pinyin de `长` :  `这把剑<chang2>三十公分`"
  },
  {
    "row": 49,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 50,
    "rowsha": "7f45Y23fyK7AQrUO7HdTtPZZzoyRkW6WwoznauYmQew=",
    "originContent": "> **Note:** If you want to manually assign multiple pinyins, enclose each pinyin with `<>`, e.g., `这把<jian4><chang2><san1>十公分`",
    "translatedContent": "> **Remarque :** Si vous souhaitez attribuer manuellement plusieurs pinyins, entourez chaque pinyin avec `<>`, par exemple : `这把<jian4><chang2><san1>十公分`"
  },
  {
    "row": 51,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 52,
    "rowsha": "FJBRXZnczlB/CZyp0UgEFMr440NrcuTPBheyQJ9lxZI=",
    "originContent": "#### 3.7 Remove long silences from the generated speech",
    "translatedContent": "#### 3.7 Supprimer les longues silences de la parole générée"
  },
  {
    "row": 53,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 54,
    "rowsha": "9UF5wHdPZ48OWeIPfCnOHPEWzgW4Z6I0e+GaTEZ1GXI=",
    "originContent": "Model will automatically determine the positions and lengths of silences in the generated speech. It occasionally has long silence in the middle of the speech. If you don't want this, you can pass `--remove-long-sil` to remove long silences in the middle of the generated speech (edge silences will be removed by default).",
    "translatedContent": "Le modèle détermine automatiquement les positions et la durée des silences dans la parole générée. Il peut parfois y avoir un long silence au milieu de la parole. Si vous ne souhaitez pas cela, vous pouvez ajouter `--remove-long-sil` pour supprimer les longues silences au milieu de la parole générée (les silences aux extrémités seront supprimés par défaut)."
  },
  {
    "row": 55,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 56,
    "rowsha": "t3GDCbkkN4PM6Y7xA/ZDAXgu4WdMFfXJ+5E/xKU9AKo=",
    "originContent": "#### 3.8 Model downloading",
    "translatedContent": "#### 3.8 Téléchargement du modèle"
  },
  {
    "row": 57,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 58,
    "rowsha": "I2UvthbxkflPXxq8Yy6W9nJCtzb40mZPJbfmDIWQPmA=",
    "originContent": "If you have trouble connecting to HuggingFace when downloading the pre-trained models, try switching endpoint to the mirror site: `export HF_ENDPOINT=https://hf-mirror.com`.",
    "translatedContent": "Si vous rencontrez des difficultés pour vous connecter à HuggingFace lors du téléchargement des modèles pré-entraînés, essayez de passer l’endpoint au site miroir : `export HF_ENDPOINT=https://hf-mirror.com`."
  },
  {
    "row": 59,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 60,
    "rowsha": "SEsrfyGZhBYqHMMdMldgN+tSz6ynJT5BVJeLrTV5lHw=",
    "originContent": "## Train Your Own Model",
    "translatedContent": "## Entraînez Votre Propre Modèle"
  },
  {
    "row": 61,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 62,
    "rowsha": "XaSJNyFaxQRx1Xc0mphwUGAxovKELo/54WkMCnFDLyE=",
    "originContent": "See the [egs](egs) directory for training, fine-tuning and evaluation examples.",
    "translatedContent": "Consultez le répertoire [egs](egs) pour des exemples d’entraînement, de fine-tuning et d’évaluation."
  },
  {
    "row": 63,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 64,
    "rowsha": "tfXaiJ7qvaTkZXp5azeYhmiU88iPPhEvLfYayUjE5+g=",
    "originContent": "## Production Deployment",
    "translatedContent": "## Déploiement en Production"
  },
  {
    "row": 65,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 66,
    "rowsha": "Tv94iSjTAB/OzGKZj2XftoBUCOzD2x+C0/xHRwRVo1c=",
    "originContent": "### NVIDIA Triton GPU Runtime",
    "translatedContent": "### Runtime GPU NVIDIA Triton"
  },
  {
    "row": 67,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 68,
    "rowsha": "cGPOVgf7Mpi/ILRt8hu96EmjQo85nhgnSfBGLfBqMeM=",
    "originContent": "For production-ready deployment with high performance and scalability, check out the [Triton Inference Server integration](runtime/nvidia_triton/) that provides optimized TensorRT engines, concurrent request handling, and both gRPC/HTTP APIs for enterprise use.",
    "translatedContent": "Pour un déploiement en production offrant performance et scalabilité, consultez l’[intégration du serveur Triton Inference](runtime/nvidia_triton/) qui fournit des moteurs TensorRT optimisés, une gestion des requêtes concurrentes, ainsi que des API gRPC/HTTP pour une utilisation en entreprise."
  },
  {
    "row": 69,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 70,
    "rowsha": "qR/CeuOSoGV5ipBKRWpnI+ohlytt878WhTEjtxZenks=",
    "originContent": "### CPU Deployment",
    "translatedContent": "### Déploiement CPU"
  },
  {
    "row": 71,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 72,
    "rowsha": "B8jnXFyKu8XRyVw/Pu0Xuj1ted9/BVoBfwJ1WW9LrcE=",
    "originContent": "Check [sherpa-onnx](https://github.com/k2-fsa/sherpa-onnx/pull/2487#issuecomment-3227884498) for the C++ deployment solution on CPU.",
    "translatedContent": "Consultez [sherpa-onnx](https://github.com/k2-fsa/sherpa-onnx/pull/2487#issuecomment-3227884498) pour la solution de déploiement C++ sur CPU."
  },
  {
    "row": 73,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 74,
    "rowsha": "dEqRbPItUt3FEp1iC+8Ww+A6L57yd6oGeXfxSn5BYzs=",
    "originContent": "## Discussion & Communication",
    "translatedContent": "## Discussion & Communication"
  },
  {
    "row": 75,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 76,
    "rowsha": "wjQUwaDgSP1a6ggLgGx8TWt44Dxu5IlJytNwCAlzZKg=",
    "originContent": "You can directly discuss on [Github Issues](https://github.com/k2-fsa/ZipVoice/issues).",
    "translatedContent": "Vous pouvez discuter directement sur [Github Issues](https://github.com/k2-fsa/ZipVoice/issues)."
  },
  {
    "row": 77,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 78,
    "rowsha": "WLbsT+slCE72T0wpzVIN8KFxhP+RAw29VxFhJcBEEIo=",
    "originContent": "You can also scan the QR code to join our wechat group or follow our wechat official account.",
    "translatedContent": "Vous pouvez également scanner le QR code pour rejoindre notre groupe Wechat ou suivre notre compte officiel Wechat."
  },
  {
    "row": 79,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 80,
    "rowsha": "XMNeg//PyHlCkY1XlL7caNd2vlVOKKoslrNeasADjMY=",
    "originContent": "| Wechat Group | Wechat Official Account |",
    "translatedContent": "| Groupe Wechat | Compte Officiel Wechat |"
  },
  {
    "row": 81,
    "rowsha": "jdP52Pdk9hJ4eEQC1YzC887/bGdD6V25zHK1FxUbFjM=",
    "originContent": "| ------------ | ----------------------- |",
    "translatedContent": "| ------------ | ----------------------- |"
  },
  {
    "row": 82,
    "rowsha": "Q6eYrtLPPuG0fiZxZqhYquTYNk0vlyIOh+CRuwGZVk4=",
    "originContent": "|![wechat](https://k2-fsa.org/zh-CN/assets/pic/wechat_group.jpg) |![wechat](https://k2-fsa.org/zh-CN/assets/pic/wechat_account.jpg) |",
    "translatedContent": "|![wechat](https://k2-fsa.org/zh-CN/assets/pic/wechat_group.jpg) |![wechat](https://k2-fsa.org/zh-CN/assets/pic/wechat_account.jpg) |"
  },
  {
    "row": 83,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 84,
    "rowsha": "ZwTp5ajUmpHTJefyHhIKzXcG2wnB1jv8iv8cvmdcb/g=",
    "originContent": "## Citation",
    "translatedContent": "## Citation"
  },
  {
    "row": 85,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  }
]