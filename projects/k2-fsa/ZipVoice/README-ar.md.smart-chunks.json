[
  {
    "Id": 1,
    "Content": "\n<div align=\"right\">\n  <details>\n    <summary >🌐 Language</summary>\n    <div>\n      <div align=\"center\">\n        <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=en\">English</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=zh-CN\">简体中文</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=zh-TW\">繁體中文</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ja\">日本語</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ko\">한국어</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=hi\">हिन्दी</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=th\">ไทย</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=fr\">Français</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=de\">Deutsch</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=es\">Español</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=it\">Itapano</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ru\">Русский</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=pt\">Português</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=nl\">Nederlands</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=pl\">Polski</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ar\">العربية</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=fa\">فارسی</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=tr\">Türkçe</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=vi\">Tiếng Việt</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=id\">Bahasa Indonesia</a>\n      </div>\n    </div>\n  </details>\n</div>\n\n<div align=\"center\">\n\n# ZipVoice⚡\n\n## Fast and High-Quality Zero-Shot Text-to-Speech with Flow Matching\n</div>\n\n## Overview\n",
    "ContentSha": "4yvqxrt72y1T/XJlpvF5+w536K1FZVvNlGdllJQl3D8=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "\n<div align=\"right\">\n  <details>\n    <summary >🌐 اللغة</summary>\n    <div>\n      <div align=\"center\">\n        <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=en\">English</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=zh-CN\">简体中文</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=zh-TW\">繁體中文</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ja\">日本語</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ko\">한국어</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=hi\">हिन्दी</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=th\">ไทย</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=fr\">Français</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=de\">Deutsch</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=es\">Español</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=it\">Itapano</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ru\">Русский</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=pt\">Português</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=nl\">Nederlands</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=pl\">Polski</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ar\">العربية</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=fa\">فارسی</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=tr\">Türkçe</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=vi\">Tiếng Việt</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=id\">Bahasa Indonesia</a>\n      </div>\n    </div>\n  </details>\n</div>\n\n<div align=\"center\">\n\n# ZipVoice⚡\n\n## تحويل النص إلى كلام سريع وعالي الجودة بدون تدريب مسبق باستخدام مطابقة التدفق\n</div>\n\n## نظرة عامة\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 2,
        "rowsha": "cWgam+tnnXudu7i74+ahMEGk/A9dQS+EwWLAIfi3dHk=",
        "originContent": "<div align=\"right\">",
        "translatedContent": "<div align=\"right\">"
      },
      {
        "row": 3,
        "rowsha": "orOcu5ARna/hb3RUkj6dBI8pHTM3WHeTvby17l5E0h0=",
        "originContent": "  <details>",
        "translatedContent": "  <details>"
      },
      {
        "row": 4,
        "rowsha": "TtgkLzblnvP0q9aAIVXt6s2LczXjy5k+QvHKcU0/5Ms=",
        "originContent": "    <summary >🌐 Language</summary>",
        "translatedContent": "    <summary >🌐 اللغة</summary>"
      },
      {
        "row": 5,
        "rowsha": "fZtk4rPTAJEEslnbhSVkHEcPlsctYSzAV7CDPL3rJmA=",
        "originContent": "    <div>",
        "translatedContent": "    <div>"
      },
      {
        "row": 6,
        "rowsha": "9KQxOeJSigvTmGWO+mtnl8kZY9zQfueoy8sk4lYm09Q=",
        "originContent": "      <div align=\"center\">",
        "translatedContent": "      <div align=\"center\">"
      },
      {
        "row": 7,
        "rowsha": "CcXpQm1/9iKvN+A/uJNpETB0rQK265sk/3d1b8LJQvw=",
        "originContent": "        <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=en\">English</a>",
        "translatedContent": "        <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=en\">English</a>"
      },
      {
        "row": 8,
        "rowsha": "2ehWvRtwvqGgM54qlLoitqATfwSTpMIFoXVVk/tTbZk=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=zh-CN\">简体中文</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=zh-CN\">简体中文</a>"
      },
      {
        "row": 9,
        "rowsha": "1Tvr2tQAiIWOxk8K1sahQkXFaTfirEHUjC6CllQsguU=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=zh-TW\">繁體中文</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=zh-TW\">繁體中文</a>"
      },
      {
        "row": 10,
        "rowsha": "viezuYRV23r39DGnn2fqOoF8t4QQbZ3lGyQ4E/gKw50=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ja\">日本語</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ja\">日本語</a>"
      },
      {
        "row": 11,
        "rowsha": "58406DeYvrKlvqudebrWq+GPeIz8UsbceVEMZSbjPfo=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ko\">한국어</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ko\">한국어</a>"
      },
      {
        "row": 12,
        "rowsha": "v5RXbnVfWV0Tg1ipPFatAoRHQuK6otAxURhh9EL6oDI=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=hi\">हिन्दी</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=hi\">हिन्दी</a>"
      },
      {
        "row": 13,
        "rowsha": "WDhcLwM8wmfLsLyFOnzsTQ4H2X2S7KkNz897OsHtDa4=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=th\">ไทย</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=th\">ไทย</a>"
      },
      {
        "row": 14,
        "rowsha": "720JVKr0dHx3FSQCXiSfarWZShlzQL9HzYaW4cRQOSE=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=fr\">Français</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=fr\">Français</a>"
      },
      {
        "row": 15,
        "rowsha": "1DtWHtMk7/aAwtrrxeFamTGgcASobQlMfFoWQwsVKgc=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=de\">Deutsch</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=de\">Deutsch</a>"
      },
      {
        "row": 16,
        "rowsha": "H+5dK1gegkmcz74mwWxfH0NM5j9vtNmcVh9n3bhYBZs=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=es\">Español</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=es\">Español</a>"
      },
      {
        "row": 17,
        "rowsha": "f3xikpvVpOqPqS0kyScUlycc8Zt+diO9Zsw9FgLmd/Q=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=it\">Itapano</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=it\">Itapano</a>"
      },
      {
        "row": 18,
        "rowsha": "1+LH4k3BSN/Gkx95+faUF9zhlMy65p97wcjIXEw4dUg=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ru\">Русский</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ru\">Русский</a>"
      },
      {
        "row": 19,
        "rowsha": "JwE8Np2ImgiLGwhoGlsXFKpsgI9EU68Mjs8pysrvz9s=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=pt\">Português</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=pt\">Português</a>"
      },
      {
        "row": 20,
        "rowsha": "0eaTuNvMrL1d1tHfXDuGbl4NwHpIqSCOYgyWn+DeCd8=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=nl\">Nederlands</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=nl\">Nederlands</a>"
      },
      {
        "row": 21,
        "rowsha": "OD8ikjviedFkX4Kx5kNhXmU45dL9qIxmcf2cgTGhqlM=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=pl\">Polski</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=pl\">Polski</a>"
      },
      {
        "row": 22,
        "rowsha": "iYQFhiOJcKRK727JftPgQg0wEibC4UGYoysohgY4ZkE=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ar\">العربية</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ar\">العربية</a>"
      },
      {
        "row": 23,
        "rowsha": "bZuriOvMlwwmbrlK623agOuY9pyTAfsswef0LRsT3tU=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=fa\">فارسی</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=fa\">فارسی</a>"
      },
      {
        "row": 24,
        "rowsha": "b7kL+KXfHE4Tqjt5V/TAEJQhMqU1SNWf9VVdfYkTrWY=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=tr\">Türkçe</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=tr\">Türkçe</a>"
      },
      {
        "row": 25,
        "rowsha": "j0cS+2vemRltrd4DFNjdvu5Ad+ZpSR763x+uEnlcxks=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=vi\">Tiếng Việt</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=vi\">Tiếng Việt</a>"
      },
      {
        "row": 26,
        "rowsha": "BI82Vx/H9f+weopSKKN3mOM7UAihcqzf7CfJbkigJ2A=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=id\">Bahasa Indonesia</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=id\">Bahasa Indonesia</a>"
      },
      {
        "row": 27,
        "rowsha": "0OM5wNEm0TO56MEBvQzL7AUZM7/3OpgIeqRf2zFre3Q=",
        "originContent": "      </div>",
        "translatedContent": "      </div>"
      },
      {
        "row": 28,
        "rowsha": "fcjTfY+fs8YnY5slBs1sZvWPAqEQR7tzaBDO54skkGQ=",
        "originContent": "    </div>",
        "translatedContent": "    </div>"
      },
      {
        "row": 29,
        "rowsha": "+fQNH2ldI7UM/rqRscP3hUSWAmw1HvQ2wEKDN8JagT0=",
        "originContent": "  </details>",
        "translatedContent": "  </details>"
      },
      {
        "row": 30,
        "rowsha": "qsMmUbEPVnxGG5tPJV1vsfpoWbU2jYvZpRr5IKshzyM=",
        "originContent": "</div>",
        "translatedContent": "</div>"
      },
      {
        "row": 31,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 32,
        "rowsha": "94MDjHJY1ZLwHNTLIEUIfk7TMc9cq1L/1FmwhqBTe/k=",
        "originContent": "<div align=\"center\">",
        "translatedContent": "<div align=\"center\">"
      },
      {
        "row": 33,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 34,
        "rowsha": "43x8VXS2NIrGxEvJGcd03L2DM5gZshFS9vGXAT/nWoY=",
        "originContent": "# ZipVoice⚡",
        "translatedContent": "# ZipVoice⚡"
      },
      {
        "row": 35,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 36,
        "rowsha": "8cGkXE2E2Lj/nZFTwxIMm6gFZ5z+nFFHUz8ryL9qi64=",
        "originContent": "## Fast and High-Quality Zero-Shot Text-to-Speech with Flow Matching",
        "translatedContent": "## تحويل النص إلى كلام سريع وعالي الجودة بدون تدريب مسبق باستخدام مطابقة التدفق"
      },
      {
        "row": 37,
        "rowsha": "qsMmUbEPVnxGG5tPJV1vsfpoWbU2jYvZpRr5IKshzyM=",
        "originContent": "</div>",
        "translatedContent": "</div>"
      },
      {
        "row": 38,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 39,
        "rowsha": "czfz0Kop6agrjxZQt0Opju+QeUYx+nY6MZaG5pxUaCE=",
        "originContent": "## Overview",
        "translatedContent": "## نظرة عامة"
      },
      {
        "row": 40,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 2,
    "Content": "ZipVoice is a series of fast and high-quality zero-shot TTS models based on flow matching.\n\n### 1. Key features\n\n- Small and fast: only 123M parameters.\n\n- High-quality voice cloning: state-of-the-art performance in speaker similarity, intelligibility, and naturalness.\n\n- Multi-lingual: support Chinese and English.\n\n- Multi-mode: support both single-speaker and dialogue speech generation.\n\n### 2. Model variants\n\n<table>\n  <thead>\n    <tr>\n      <th>Model Name</th>\n      <th>Description</th>\n      <th>Paper</th>\n      <th>Demo</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>ZipVoice</td>\n      <td>The basic model supporting zero-shot single-speaker TTS in both Chinese and English.</td>\n      <td rowspan=\"2\"><a href=\"https://arxiv.org/abs/2506.13053\"><img src=\"https://img.shields.io/badge/arXiv-Paper-COLOR.svg\"></a></td>\n      <td rowspan=\"2\"><a href=\"https://zipvoice.github.io\"><img src=\"https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square\"></a></td>\n    </tr>\n    <tr>\n      <td>ZipVoice-Distill</td>\n      <td>The distilled version of ZipVoice, featuring improved speed with minimal performance degradation.</td>\n    </tr>\n    <tr>\n      <td>ZipVoice-Dialog</td>\n      <td>A dialogue generation model built on ZipVoice, capable of generating single-channel two-party spoken dialogues.</td>\n      <td rowspan=\"2\"><a href=\"https://arxiv.org/abs/2507.09318\"><img src=\"https://img.shields.io/badge/arXiv-Paper-COLOR.svg\"></a></td>\n      <td rowspan=\"2\"><a href=\"https://zipvoice-dialog.github.io\"><img src=\"https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square\"></a></td>\n    </tr>",
    "ContentSha": "qUZer10kkUVucN3aqovgCkJ059aWMO67vNYjNUfJcJw=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "ZipVoice هي سلسلة من نماذج تحويل النص إلى كلام (TTS) السريعة وعالية الجودة بدون تدريب مسبق، تعتمد على تقنية مطابقة التدفق.\n\n### 1. الميزات الرئيسية\n\n- صغيرة وسريعة: تحتوي فقط على 123 مليون معامل.\n\n- استنساخ صوت عالي الجودة: أداء متقدم في تشابه المتحدث، والوضوح، والطبيعية.\n\n- متعددة اللغات: تدعم الصينية والإنجليزية.\n\n- متعددة الأنماط: تدعم توليد الكلام لمتحدث واحد أو الحوار.\n\n### 2. أنواع النماذج\n\n<table>\n  <thead>\n    <tr>\n      <th>اسم النموذج</th>\n      <th>الوصف</th>\n      <th>البحث العلمي</th>\n      <th>التجربة</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>ZipVoice</td>\n      <td>النموذج الأساسي الذي يدعم تحويل النص إلى كلام بدون تدريب مسبق لمتحدث واحد بالصينية والإنجليزية.</td>\n      <td rowspan=\"2\"><a href=\"https://arxiv.org/abs/2506.13053\"><img src=\"https://img.shields.io/badge/arXiv-Paper-COLOR.svg\"></a></td>\n      <td rowspan=\"2\"><a href=\"https://zipvoice.github.io\"><img src=\"https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square\"></a></td>\n    </tr>\n    <tr>\n      <td>ZipVoice-Distill</td>\n      <td>النسخة المقطرة من ZipVoice، وتتميز بسرعة محسنة مع تدهور طفيف في الأداء.</td>\n    </tr>\n    <tr>\n      <td>ZipVoice-Dialog</td>\n      <td>نموذج توليد الحوار مبني على ZipVoice، وقادر على توليد حوارات منطوقة لطرفين في قناة واحدة.</td>\n      <td rowspan=\"2\"><a href=\"https://arxiv.org/abs/2507.09318\"><img src=\"https://img.shields.io/badge/arXiv-Paper-COLOR.svg\"></a></td>\n      <td rowspan=\"2\"><a href=\"https://zipvoice-dialog.github.io\"><img src=\"https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square\"></a></td>\n    </tr>",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "nQS2T1vCMqJruAgLkxb46w0hSAkEn/IM3WAyxZjZ41Q=",
        "originContent": "ZipVoice is a series of fast and high-quality zero-shot TTS models based on flow matching.",
        "translatedContent": "ZipVoice هي سلسلة من نماذج تحويل النص إلى كلام (TTS) السريعة وعالية الجودة بدون تدريب مسبق، تعتمد على تقنية مطابقة التدفق."
      },
      {
        "row": 2,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 3,
        "rowsha": "ucC7hUEIiT/76texV2ocUEuEh3ipUzSv7QRGCII6ZzM=",
        "originContent": "### 1. Key features",
        "translatedContent": "### 1. الميزات الرئيسية"
      },
      {
        "row": 4,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 5,
        "rowsha": "mnMSMs6GmKRNnNbe05VmoRtRBkZF0/KoDIo2RGx2miQ=",
        "originContent": "- Small and fast: only 123M parameters.",
        "translatedContent": "- صغيرة وسريعة: تحتوي فقط على 123 مليون معامل."
      },
      {
        "row": 6,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 7,
        "rowsha": "DTc6Shc7YIXhauUP00lzZgJfeGsA8b/7jnpoWq4PK0U=",
        "originContent": "- High-quality voice cloning: state-of-the-art performance in speaker similarity, intelligibility, and naturalness.",
        "translatedContent": "- استنساخ صوت عالي الجودة: أداء متقدم في تشابه المتحدث، والوضوح، والطبيعية."
      },
      {
        "row": 8,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 9,
        "rowsha": "yt9ntJffC7kC7o3urvP30pUjjiFSCTNvFa2IsukbVDE=",
        "originContent": "- Multi-lingual: support Chinese and English.",
        "translatedContent": "- متعددة اللغات: تدعم الصينية والإنجليزية."
      },
      {
        "row": 10,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 11,
        "rowsha": "zxFH2T15/GT24QXdR/3+MTlLcndjhW81in4fA6q/NqI=",
        "originContent": "- Multi-mode: support both single-speaker and dialogue speech generation.",
        "translatedContent": "- متعددة الأنماط: تدعم توليد الكلام لمتحدث واحد أو الحوار."
      },
      {
        "row": 12,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 13,
        "rowsha": "euhnPJYVS9UO65MqpSJ6SGItveAQx/PEyxlOhvoL7gQ=",
        "originContent": "### 2. Model variants",
        "translatedContent": "### 2. أنواع النماذج"
      },
      {
        "row": 14,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 15,
        "rowsha": "kq0DFTS69SZCm3Odp9SwOmLuj08yYNkZvbhcRxtdMkQ=",
        "originContent": "<table>",
        "translatedContent": "<table>"
      },
      {
        "row": 16,
        "rowsha": "fVeZa2zHTj+GejNZeOMEq73p8lrPy91L7a2SAORQGww=",
        "originContent": "  <thead>",
        "translatedContent": "  <thead>"
      },
      {
        "row": 17,
        "rowsha": "mQe8Du3ITIgeK5HrAaAmVDg4p8IDxaiLEnVYSpNSPoQ=",
        "originContent": "    <tr>",
        "translatedContent": "    <tr>"
      },
      {
        "row": 18,
        "rowsha": "z4Rwl4uu63uzLboduV7OD40QtA50BzuyfDCtbD3ZuGA=",
        "originContent": "      <th>Model Name</th>",
        "translatedContent": "      <th>اسم النموذج</th>"
      },
      {
        "row": 19,
        "rowsha": "O/DS90B9w8GpepemJkQp634TTVY3fEDiLIPL5Ltaq78=",
        "originContent": "      <th>Description</th>",
        "translatedContent": "      <th>الوصف</th>"
      },
      {
        "row": 20,
        "rowsha": "YGp5skEXJ0tuyZL/KspO3fgVUV+H1ijs8hRaS27I9zg=",
        "originContent": "      <th>Paper</th>",
        "translatedContent": "      <th>البحث العلمي</th>"
      },
      {
        "row": 21,
        "rowsha": "nq0QdUA8EPB/UZOofw7s5hdITABnq7ZhH3chJk3iFow=",
        "originContent": "      <th>Demo</th>",
        "translatedContent": "      <th>التجربة</th>"
      },
      {
        "row": 22,
        "rowsha": "qMXSfcecmgpTcWjU4/DonhxZrtbJe20/4kuvSQqv9HU=",
        "originContent": "    </tr>",
        "translatedContent": "    </tr>"
      },
      {
        "row": 23,
        "rowsha": "QAgj2Ue5ZqUAelXIN3OwGwnCFXD2scHVIkAz9iHowbw=",
        "originContent": "  </thead>",
        "translatedContent": "  </thead>"
      },
      {
        "row": 24,
        "rowsha": "V8SoadU3qlQEyQXfcDO5Evu+vSduzv+IQXpGHlNEQ4M=",
        "originContent": "  <tbody>",
        "translatedContent": "  <tbody>"
      },
      {
        "row": 25,
        "rowsha": "mQe8Du3ITIgeK5HrAaAmVDg4p8IDxaiLEnVYSpNSPoQ=",
        "originContent": "    <tr>",
        "translatedContent": "    <tr>"
      },
      {
        "row": 26,
        "rowsha": "ndVKgIyPesKKyqCb1fPiiBsMn4f9r+E9zy2h+rEQMEg=",
        "originContent": "      <td>ZipVoice</td>",
        "translatedContent": "      <td>ZipVoice</td>"
      },
      {
        "row": 27,
        "rowsha": "V4nOcrSY1j7m4uPd0Q3jKJV5OYsg3vveAhj2uXuDYpo=",
        "originContent": "      <td>The basic model supporting zero-shot single-speaker TTS in both Chinese and English.</td>",
        "translatedContent": "      <td>النموذج الأساسي الذي يدعم تحويل النص إلى كلام بدون تدريب مسبق لمتحدث واحد بالصينية والإنجليزية.</td>"
      },
      {
        "row": 28,
        "rowsha": "oYsdnyALg8AzIa9SQc6g12SHxZsEaAnuMNKRixdVEOI=",
        "originContent": "      <td rowspan=\"2\"><a href=\"https://arxiv.org/abs/2506.13053\"><img src=\"https://img.shields.io/badge/arXiv-Paper-COLOR.svg\"></a></td>",
        "translatedContent": "      <td rowspan=\"2\"><a href=\"https://arxiv.org/abs/2506.13053\"><img src=\"https://img.shields.io/badge/arXiv-Paper-COLOR.svg\"></a></td>"
      },
      {
        "row": 29,
        "rowsha": "D4+fblzP0Ay8rjWW7tpMeTQtV1brxxngEj2VRAwXeG4=",
        "originContent": "      <td rowspan=\"2\"><a href=\"https://zipvoice.github.io\"><img src=\"https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square\"></a></td>",
        "translatedContent": "      <td rowspan=\"2\"><a href=\"https://zipvoice.github.io\"><img src=\"https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square\"></a></td>"
      },
      {
        "row": 30,
        "rowsha": "qMXSfcecmgpTcWjU4/DonhxZrtbJe20/4kuvSQqv9HU=",
        "originContent": "    </tr>",
        "translatedContent": "    </tr>"
      },
      {
        "row": 31,
        "rowsha": "mQe8Du3ITIgeK5HrAaAmVDg4p8IDxaiLEnVYSpNSPoQ=",
        "originContent": "    <tr>",
        "translatedContent": "    <tr>"
      },
      {
        "row": 32,
        "rowsha": "O5M2zS2wTgQ/tb2NGv9Zwg2M/p4ap3H3QEscfDprkLY=",
        "originContent": "      <td>ZipVoice-Distill</td>",
        "translatedContent": "      <td>ZipVoice-Distill</td>"
      },
      {
        "row": 33,
        "rowsha": "+GY4P77oZKf2OE98WJt+uHde+9Pfx5adwPX/hgBXv/0=",
        "originContent": "      <td>The distilled version of ZipVoice, featuring improved speed with minimal performance degradation.</td>",
        "translatedContent": "      <td>النسخة المقطرة من ZipVoice، وتتميز بسرعة محسنة مع تدهور طفيف في الأداء.</td>"
      },
      {
        "row": 34,
        "rowsha": "qMXSfcecmgpTcWjU4/DonhxZrtbJe20/4kuvSQqv9HU=",
        "originContent": "    </tr>",
        "translatedContent": "    </tr>"
      },
      {
        "row": 35,
        "rowsha": "mQe8Du3ITIgeK5HrAaAmVDg4p8IDxaiLEnVYSpNSPoQ=",
        "originContent": "    <tr>",
        "translatedContent": "    <tr>"
      },
      {
        "row": 36,
        "rowsha": "AokiHqhaQvuU9KuEm8+8XFm12AAfehl/iUS5IKh25hg=",
        "originContent": "      <td>ZipVoice-Dialog</td>",
        "translatedContent": "      <td>ZipVoice-Dialog</td>"
      },
      {
        "row": 37,
        "rowsha": "VyLj//yzuicS9drxTtHyEb23TlyYimyWqSLjKnhiPRI=",
        "originContent": "      <td>A dialogue generation model built on ZipVoice, capable of generating single-channel two-party spoken dialogues.</td>",
        "translatedContent": "      <td>نموذج توليد الحوار مبني على ZipVoice، وقادر على توليد حوارات منطوقة لطرفين في قناة واحدة.</td>"
      },
      {
        "row": 38,
        "rowsha": "52missEFmjbF4iX2P0jQNQNcxMRdvKLCWURi53zHj9c=",
        "originContent": "      <td rowspan=\"2\"><a href=\"https://arxiv.org/abs/2507.09318\"><img src=\"https://img.shields.io/badge/arXiv-Paper-COLOR.svg\"></a></td>",
        "translatedContent": "      <td rowspan=\"2\"><a href=\"https://arxiv.org/abs/2507.09318\"><img src=\"https://img.shields.io/badge/arXiv-Paper-COLOR.svg\"></a></td>"
      },
      {
        "row": 39,
        "rowsha": "cDPQ2lSV0MvAN7W5vsgpUGdH0r3KovLhGy8iNUb891g=",
        "originContent": "      <td rowspan=\"2\"><a href=\"https://zipvoice-dialog.github.io\"><img src=\"https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square\"></a></td>",
        "translatedContent": "      <td rowspan=\"2\"><a href=\"https://zipvoice-dialog.github.io\"><img src=\"https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square\"></a></td>"
      },
      {
        "row": 40,
        "rowsha": "qMXSfcecmgpTcWjU4/DonhxZrtbJe20/4kuvSQqv9HU=",
        "originContent": "    </tr>",
        "translatedContent": "    </tr>"
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 3,
    "Content": "    <tr>\n      <td>ZipVoice-Dialog-Stereo</td>\n      <td>The stereo variant of ZipVoice-Dialog, enabling two-channel dialogue generation with each speaker assigned to a distinct channel.</td>\n    </tr>\n  </tbody>\n</table>\n\n## News\n\n**2025/07/14**: **ZipVoice-Dialog** and **ZipVoice-Dialog-Stereo**, two spoken dialogue generation models, are released. [![arXiv](https://img.shields.io/badge/arXiv-Paper-COLOR.svg)](https://arxiv.org/abs/2507.09318) [![demo page](https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square)](https://zipvoice-dialog.github.io)\n\n**2025/07/14**: **OpenDialog** dataset, a 6.8k-hour spoken dialogue dataset, is released. Download at [![hf](https://img.shields.io/badge/%F0%9F%A4%97%20HuggingFace-Dataset-yellow)](https://huggingface.co/datasets/k2-fsa/OpenDialog), [![ms](https://img.shields.io/badge/ModelScope-Dataset-blue?logo=data)](https://www.modelscope.cn/datasets/k2-fsa/OpenDialog). Check details at [![arXiv](https://img.shields.io/badge/arXiv-Paper-COLOR.svg)](https://arxiv.org/abs/2507.09318).\n\n**2025/06/16**: **ZipVoice** and **ZipVoice-Distill** are released. [![arXiv](https://img.shields.io/badge/arXiv-Paper-COLOR.svg)](https://arxiv.org/abs/2506.13053) [![demo page](https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square)](https://zipvoice.github.io)\n\n## Installation\n\n### 1. Clone the ZipVoice repository\n",
    "ContentSha": "qyykZIxy9KKTHUZalqgKJAhZ9ZS/CaAb/vbLISMH1+E=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "    <tr>\n      <td>ZipVoice-Dialog-Stereo</td>\n      <td>النسخة الستيريو من ZipVoice-Dialog، والتي تتيح توليد حوارات ثنائية القناة مع تخصيص كل متحدث لقناة منفصلة.</td>\n    </tr>\n  </tbody>\n</table>\n\n## الأخبار\n\n**2025/07/14**: تم إصدار **ZipVoice-Dialog** و **ZipVoice-Dialog-Stereo**، وهما نموذجان لتوليد الحوارات المنطوقة. [![arXiv](https://img.shields.io/badge/arXiv-Paper-COLOR.svg)](https://arxiv.org/abs/2507.09318) [![demo page](https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square)](https://zipvoice-dialog.github.io)\n\n**2025/07/14**: تم إصدار قاعدة بيانات **OpenDialog**، وهي قاعدة بيانات للحوارات المنطوقة مدتها 6.8 ألف ساعة. يمكن التحميل من [![hf](https://img.shields.io/badge/%F0%9F%A4%97%20HuggingFace-Dataset-yellow)](https://huggingface.co/datasets/k2-fsa/OpenDialog)، [![ms](https://img.shields.io/badge/ModelScope-Dataset-blue?logo=data)](https://www.modelscope.cn/datasets/k2-fsa/OpenDialog). تفاصيل إضافية على [![arXiv](https://img.shields.io/badge/arXiv-Paper-COLOR.svg)](https://arxiv.org/abs/2507.09318).\n\n**2025/06/16**: تم إصدار **ZipVoice** و **ZipVoice-Distill**. [![arXiv](https://img.shields.io/badge/arXiv-Paper-COLOR.svg)](https://arxiv.org/abs/2506.13053) [![demo page](https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square)](https://zipvoice.github.io)\n\n## التثبيت\n\n### 1. استنساخ مستودع ZipVoice\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "mQe8Du3ITIgeK5HrAaAmVDg4p8IDxaiLEnVYSpNSPoQ=",
        "originContent": "    <tr>",
        "translatedContent": "    <tr>"
      },
      {
        "row": 2,
        "rowsha": "5wxh9pzh0ath/did6Y4bnHT5G0oknzB4REIMmmpbrWc=",
        "originContent": "      <td>ZipVoice-Dialog-Stereo</td>",
        "translatedContent": "      <td>ZipVoice-Dialog-Stereo</td>"
      },
      {
        "row": 3,
        "rowsha": "4zPgKHyoRGqee2hEpKE1kawe5id33R887ovyXGFAikU=",
        "originContent": "      <td>The stereo variant of ZipVoice-Dialog, enabling two-channel dialogue generation with each speaker assigned to a distinct channel.</td>",
        "translatedContent": "      <td>النسخة الستيريو من ZipVoice-Dialog، والتي تتيح توليد حوارات ثنائية القناة مع تخصيص كل متحدث لقناة منفصلة.</td>"
      },
      {
        "row": 4,
        "rowsha": "qMXSfcecmgpTcWjU4/DonhxZrtbJe20/4kuvSQqv9HU=",
        "originContent": "    </tr>",
        "translatedContent": "    </tr>"
      },
      {
        "row": 5,
        "rowsha": "HgAQR47u7qD0p8NwuwwZJ7dDJg35+B/lslvDHWuZaBU=",
        "originContent": "  </tbody>",
        "translatedContent": "  </tbody>"
      },
      {
        "row": 6,
        "rowsha": "H+dtb55ry3VN2CLvAetudgE9ICnYQdUralLHuIqMdZM=",
        "originContent": "</table>",
        "translatedContent": "</table>"
      },
      {
        "row": 7,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 8,
        "rowsha": "4SzYJwNNDn2R2kkHsB4X4H4ZhUVuQo9QZvhInidlbxE=",
        "originContent": "## News",
        "translatedContent": "## الأخبار"
      },
      {
        "row": 9,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 10,
        "rowsha": "DfOZSiFY93Zgx5ovWAl3CGk0WussCMIUOrJfiCw6Ul0=",
        "originContent": "**2025/07/14**: **ZipVoice-Dialog** and **ZipVoice-Dialog-Stereo**, two spoken dialogue generation models, are released. [![arXiv](https://img.shields.io/badge/arXiv-Paper-COLOR.svg)](https://arxiv.org/abs/2507.09318) [![demo page](https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square)](https://zipvoice-dialog.github.io)",
        "translatedContent": "**2025/07/14**: تم إصدار **ZipVoice-Dialog** و **ZipVoice-Dialog-Stereo**، وهما نموذجان لتوليد الحوارات المنطوقة. [![arXiv](https://img.shields.io/badge/arXiv-Paper-COLOR.svg)](https://arxiv.org/abs/2507.09318) [![demo page](https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square)](https://zipvoice-dialog.github.io)"
      },
      {
        "row": 11,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 12,
        "rowsha": "HdUKrlzAn5/ebTtUoBeZCSvFc7yoA+bUx9wm05BLIyI=",
        "originContent": "**2025/07/14**: **OpenDialog** dataset, a 6.8k-hour spoken dialogue dataset, is released. Download at [![hf](https://img.shields.io/badge/%F0%9F%A4%97%20HuggingFace-Dataset-yellow)](https://huggingface.co/datasets/k2-fsa/OpenDialog), [![ms](https://img.shields.io/badge/ModelScope-Dataset-blue?logo=data)](https://www.modelscope.cn/datasets/k2-fsa/OpenDialog). Check details at [![arXiv](https://img.shields.io/badge/arXiv-Paper-COLOR.svg)](https://arxiv.org/abs/2507.09318).",
        "translatedContent": "**2025/07/14**: تم إصدار قاعدة بيانات **OpenDialog**، وهي قاعدة بيانات للحوارات المنطوقة مدتها 6.8 ألف ساعة. يمكن التحميل من [![hf](https://img.shields.io/badge/%F0%9F%A4%97%20HuggingFace-Dataset-yellow)](https://huggingface.co/datasets/k2-fsa/OpenDialog)، [![ms](https://img.shields.io/badge/ModelScope-Dataset-blue?logo=data)](https://www.modelscope.cn/datasets/k2-fsa/OpenDialog). تفاصيل إضافية على [![arXiv](https://img.shields.io/badge/arXiv-Paper-COLOR.svg)](https://arxiv.org/abs/2507.09318)."
      },
      {
        "row": 13,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 14,
        "rowsha": "0OIq3Ae2KEaqpQCFjIP/3rxyTxS6RICMJWSmPyeMdA8=",
        "originContent": "**2025/06/16**: **ZipVoice** and **ZipVoice-Distill** are released. [![arXiv](https://img.shields.io/badge/arXiv-Paper-COLOR.svg)](https://arxiv.org/abs/2506.13053) [![demo page](https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square)](https://zipvoice.github.io)",
        "translatedContent": "**2025/06/16**: تم إصدار **ZipVoice** و **ZipVoice-Distill**. [![arXiv](https://img.shields.io/badge/arXiv-Paper-COLOR.svg)](https://arxiv.org/abs/2506.13053) [![demo page](https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square)](https://zipvoice.github.io)"
      },
      {
        "row": 15,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 16,
        "rowsha": "oV0SUDvwD2VN8Gi9nlr2JZ2xcDrASmE2W5kc5SVX5eo=",
        "originContent": "## Installation",
        "translatedContent": "## التثبيت"
      },
      {
        "row": 17,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 18,
        "rowsha": "3s/0urTHhRlVIuxHnj5ytcB39gCSsfn6y5cYocnuTIs=",
        "originContent": "### 1. Clone the ZipVoice repository",
        "translatedContent": "### 1. استنساخ مستودع ZipVoice"
      },
      {
        "row": 19,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 4,
    "Content": "```bash\ngit clone https://github.com/k2-fsa/ZipVoice.git\n```",
    "ContentSha": "JJo1EP7bWO0BWMfBMdp5X937bp3+DWhl7nAOm71R7lA=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\ngit clone https://github.com/k2-fsa/ZipVoice.git\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 5,
    "Content": "\n### 2. (Optional) Create a Python virtual environment\n",
    "ContentSha": "SdfmTQw39ITwBrkeETcUaJ4CPFr6cQ+HCqumZ483/iY=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "### 2. (اختياري) إنشاء بيئة افتراضية في بايثون\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 6,
    "Content": "```bash\npython3 -m venv zipvoice\nsource zipvoice/bin/activate\n```",
    "ContentSha": "glR0Rdvd5rjEtSF3LycYEtxGB8VzT68abW/ywL40bxw=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\npython3 -m venv zipvoice\nsource zipvoice/bin/activate\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 7,
    "Content": "\n### 3. Install the required packages\n",
    "ContentSha": "97VTTWuamYvk4THPyO5Ex48XMRIdHtV0dBXABNHe3qQ=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "### 3. تثبيت الحزم المطلوبة\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 8,
    "Content": "```bash\npip install -r requirements.txt\n```",
    "ContentSha": "TxMa9uJC0PmBOnm3/TRl4YDLNvSwCWaRNjyXpFhndHU=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\npip install -r requirements.txt\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 9,
    "Content": "\n### 4. Install k2 for training or efficient inference\n\n**k2 is necessary for training** and can speed up inference. Nevertheless, you can still use the inference mode of ZipVoice without installing k2.\n\n> **Note:**  Make sure to install the k2 version that matches your PyTorch and CUDA version. For example, if you are using pytorch 2.5.1 and CUDA 12.1, you can install k2 as follows:\n",
    "ContentSha": "it0kOYkTtKi6ipV/r+Px+BHDpullJx7ZxRNyR9UNc40=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "### 4. تثبيت k2 للتدريب أو الاستدلال الفعال\n\n**k2 ضروري للتدريب** ويمكنه تسريع الاستدلال. ومع ذلك، لا يزال بإمكانك استخدام وضع الاستدلال في ZipVoice دون تثبيت k2.\n\n> **ملاحظة:** تأكد من تثبيت إصدار k2 الذي يتوافق مع إصدار PyTorch و CUDA لديك. على سبيل المثال، إذا كنت تستخدم pytorch 2.5.1 و CUDA 12.1، يمكنك تثبيت k2 كما يلي:\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 10,
    "Content": "```bash\npip install k2==1.24.4.dev20250208+cuda12.1.torch2.5.1 -f https://k2-fsa.github.io/k2/cuda.html\n```",
    "ContentSha": "ScZHk5YUmlVP9WL5ZgwHsvBVbwTCenfwKc3cJb6nrWo=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\npip install k2==1.24.4.dev20250208+cuda12.1.torch2.5.1 -f https://k2-fsa.github.io/k2/cuda.html\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 11,
    "Content": "\nPlease refer to https://k2-fsa.org/get-started/k2/ for details.\nUsers in China mainland can refer to https://k2-fsa.org/zh-CN/get-started/k2/.\n\n- To check the k2 installation:\n",
    "ContentSha": "rY1Zhq3aduWMw4XQSft+r2qBy7l8kqnHBs8cs4FGpZ4=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "يرجى الرجوع إلى https://k2-fsa.org/get-started/k2/ لمزيد من التفاصيل.\nيمكن للمستخدمين في الصين القارية الرجوع إلى https://k2-fsa.org/zh-CN/get-started/k2/.\n\n- للتحقق من تثبيت k2:\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 12,
    "Content": "```bash\npython3 -c \"import k2; print(k2.__file__)\"\n```",
    "ContentSha": "PH4E7oc9yWRIVi2n1L4BiFuChpCHjHuJ65gAwNBxvHE=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\npython3 -c \"import k2; print(k2.__file__)\"\n```",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "rTMjNc+qNIxb1xXDR5hEYiJw1fc4muBwuBsTXVIaIho=",
        "originContent": "```bash",
        "translatedContent": "```bash"
      },
      {
        "row": 2,
        "rowsha": "7yHd9AwCS2R/DPcwaogfIhkKXz9t9u3yeddGTQpSgnE=",
        "originContent": "python3 -c \"import k2; print(k2.__file__)\"",
        "translatedContent": "python3 -c \"import k2; print(k2.__file__)\""
      },
      {
        "row": 3,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      }
    ],
    "IsCodeBlock": true
  },
  {
    "Id": 13,
    "Content": "\n## Usage\n\n### 1. Single-speaker speech generation\n\nTo generate single-speaker speech with our pre-trained ZipVoice or ZipVoice-Distill models, use the following commands (Required models will be downloaded from HuggingFace):\n\n#### 1.1 Inference of a single sentence\n",
    "ContentSha": "B4h5YyIywYfr2neMM1PwmS6nY8/eY48N4jkDeP3wG+Y=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "## الاستخدام\n\n### 1. توليد الكلام لمتحدث واحد\n\nلتوليد كلام لمتحدث واحد باستخدام نماذج ZipVoice أو ZipVoice-Distill المدربة مسبقًا، استخدم الأوامر التالية (سيتم تنزيل النماذج المطلوبة من HuggingFace):\n\n#### 1.1 الاستدلال على جملة واحدة\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 14,
    "Content": "```bash\npython3 -m zipvoice.bin.infer_zipvoice \\\n    --model-name zipvoice \\\n    --prompt-wav prompt.wav \\\n    --prompt-text \"I am the transcription of the prompt wav.\" \\\n    --text \"I am the text to be synthesized.\" \\\n    --res-wav-path result.wav\n```",
    "ContentSha": "s3L0IUGcm9ppsQesBx8AKaxAjpRhRDaqb8rE/HLRinc=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\npython3 -m zipvoice.bin.infer_zipvoice \\\n    --model-name zipvoice \\\n    --prompt-wav prompt.wav \\\n    --prompt-text \"I am the transcription of the prompt wav.\" \\\n    --text \"I am the text to be synthesized.\" \\\n    --res-wav-path result.wav\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 15,
    "Content": "- `--model-name` can be `zipvoice` or `zipvoice_distill`, which are models before and after distillation, respectively.\n- If `<>` or `[]` appear in the text, strings enclosed by them will be treated as special tokens. `<>` denotes Chinese pinyin and `[]` denotes other special tags.\n\n#### 1.2 Inference of a list of sentences\n",
    "ContentSha": "9gu4tqRbp3LNcYk2S6twKEix9A9CPCJP4IQ8qVja+jw=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "- يمكن أن تكون قيمة `--model-name` هي `zipvoice` أو `zipvoice_distill`، حيث تمثل النماذج قبل وبعد التقطير على التوالي.\n- إذا ظهرت `<>` أو `[]` في النص، فسيتم التعامل مع السلاسل المحاطة بها على أنها رموز خاصة. تشير `<>` إلى كتابة بينيين الصينية، و`[]` تشير إلى علامات خاصة أخرى.\n\n#### 1.2 استنتاج قائمة من الجمل\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "Vk0m6NrE3gMzFw6jIUmVS2xf8e53UPorfjw3hnyoR8g=",
        "originContent": "- `--model-name` can be `zipvoice` or `zipvoice_distill`, which are models before and after distillation, respectively.",
        "translatedContent": "- يمكن أن تكون قيمة `--model-name` هي `zipvoice` أو `zipvoice_distill`، حيث تمثل النماذج قبل وبعد التقطير على التوالي."
      },
      {
        "row": 2,
        "rowsha": "l7kUz5yeNN2aq8iILGY4UuGx9dvsTL+VIkCcGFxqaHc=",
        "originContent": "- If `<>` or `[]` appear in the text, strings enclosed by them will be treated as special tokens. `<>` denotes Chinese pinyin and `[]` denotes other special tags.",
        "translatedContent": "- إذا ظهرت `<>` أو `[]` في النص، فسيتم التعامل مع السلاسل المحاطة بها على أنها رموز خاصة. تشير `<>` إلى كتابة بينيين الصينية، و`[]` تشير إلى علامات خاصة أخرى."
      },
      {
        "row": 3,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 4,
        "rowsha": "8zUs0xdKItgiKM1ReiXt8Pbmo0PrH0yE33PZ24pLLIw=",
        "originContent": "#### 1.2 Inference of a list of sentences",
        "translatedContent": "#### 1.2 استنتاج قائمة من الجمل"
      },
      {
        "row": 5,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 16,
    "Content": "```bash\npython3 -m zipvoice.bin.infer_zipvoice \\\n    --model-name zipvoice \\\n    --test-list test.tsv \\\n    --res-dir results\n```",
    "ContentSha": "wVKNQBx9Qf3wuIvCUTrQwDyZzDuqDpC7W9a1psJg5Ds=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\npython3 -m zipvoice.bin.infer_zipvoice \\\n    --model-name zipvoice \\\n    --test-list test.tsv \\\n    --res-dir results\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 17,
    "Content": "\n- Each line of `test.tsv` is in the format of `{wav_name}\\t{prompt_transcription}\\t{prompt_wav}\\t{text}`.\n\n### 2. Dialogue speech generation\n\n#### 2.1 Inference command\n\nTo generate two-party spoken dialogues with our pre-trained ZipVoice-Dialogue or ZipVoice-Dialogue-Stereo models, use the following commands (Required models will be downloaded from HuggingFace):\n",
    "ContentSha": "bkRixLiKF8JLzfAqriyk1UZSkb5qCPhJVvI3VACgZos=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "- كل سطر في ملف `test.tsv` يكون بالصيغة `{wav_name}\\t{prompt_transcription}\\t{prompt_wav}\\t{text}`.\n\n### 2. توليد الكلام الحواري\n\n#### 2.1 أمر الاستدلال\n\nلإنشاء حوارات منطوقة ثنائية الأطراف باستخدام نماذج ZipVoice-Dialogue أو ZipVoice-Dialogue-Stereo المدربة مسبقًا، استخدم الأوامر التالية (سيتم تحميل النماذج المطلوبة من HuggingFace):\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 18,
    "Content": "```bash\npython3 -m zipvoice.bin.infer_zipvoice_dialog \\\n    --model-name \"zipvoice_dialog\" \\\n    --test-list test.tsv \\\n    --res-dir results\n```",
    "ContentSha": "SmNrjO7IvCsVTs0ROGG3evCMgCtj54DYGkGCZbRdz8k=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\npython3 -m zipvoice.bin.infer_zipvoice_dialog \\\n    --model-name \"zipvoice_dialog\" \\\n    --test-list test.tsv \\\n    --res-dir results\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 19,
    "Content": "\n- `--model-name` can be `zipvoice_dialog` or `zipvoice_dialog_stereo`,\n    which generate mono and stereo dialogues, respectively.\n\n#### 2.2 Input formats\n\nEach line of `test.tsv` is in one of the following formats:\n\n(1) **Merged prompt format** where the audios and transcriptions of two speakers prompts are merged into one prompt wav file:",
    "ContentSha": "e336Qt1qFvFmNefniyPEWJue5A1mLBZUSlD6p1+H8To=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "- يمكن أن تكون قيمة `--model-name` هي `zipvoice_dialog` أو `zipvoice_dialog_stereo`,\n    حيث تقوم بتوليد حوارات أحادية أو ثنائية القناة على التوالي.\n\n#### 2.2 تنسيقات الإدخال\n\nكل سطر في ملف `test.tsv` يكون بأحد التنسيقات التالية:\n\n(1) **تنسيق الموجه المدمج** حيث يتم دمج ملفات الصوت والنصوص الخاصة بمتحدثين اثنين في ملف موجه واحد:\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 20,
    "Content": "```\n{wav_name}\\t{prompt_transcription}\\t{prompt_wav}\\t{text}\n```",
    "ContentSha": "F8c2S4lpByZ5Nhd693ESYvOeDT7lT7vF2Txm3q64ync=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```\n{wav_name}\\t{prompt_transcription}\\t{prompt_wav}\\t{text}\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 21,
    "Content": "\n- `wav_name` is the name of the output wav file.\n- `prompt_transcription` is the transcription of the conversational prompt wav, e.g, \"[S1] Hello. [S2] How are you?\"\n- `prompt_wav` is the path to the prompt wav.\n- `text` is the text to be synthesized, e.g. \"[S1] I'm fine. [S2] What's your name? [S1] I'm Eric. [S2] Hi Eric.\"\n\n(2) **Splitted prompt format** where the audios and transciptions of two speakers exist in separate files:\n",
    "ContentSha": "Gj5W4GhLunSOhvyVf7uwdfnNL3DFgIeOvHB01tH9I/A=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "\n- `wav_name` هو اسم ملف wav الناتج.\n- `prompt_transcription` هو نص تفريغ ملف wav الخاص بالمحادثة، مثل \"[S1] مرحباً. [S2] كيف حالك؟\"\n- `prompt_wav` هو مسار ملف wav الخاص بالمحادثة.\n- `text` هو النص المراد توليفه، مثل \"[S1] أنا بخير. [S2] ما اسمك؟ [S1] أنا إريك. [S2] مرحباً إريك.\"\n\n(2) **تنسيق المحادثة المقسمة** حيث توجد تسجيلات الصوت والنصوص التفريغية للمتحدثين الاثنين في ملفات منفصلة:\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 2,
        "rowsha": "6vgIR6WfUAFmULhn8LhxFttPwZEo/YwGhN1DAECwHCQ=",
        "originContent": "- `wav_name` is the name of the output wav file.",
        "translatedContent": "- `wav_name` هو اسم ملف wav الناتج."
      },
      {
        "row": 3,
        "rowsha": "8kGHHZ7ObsZ8uyIBm+8FSBfPWSNEFzO6a4avI5fvxU8=",
        "originContent": "- `prompt_transcription` is the transcription of the conversational prompt wav, e.g, \"[S1] Hello. [S2] How are you?\"",
        "translatedContent": "- `prompt_transcription` هو نص تفريغ ملف wav الخاص بالمحادثة، مثل \"[S1] مرحباً. [S2] كيف حالك؟\""
      },
      {
        "row": 4,
        "rowsha": "49ZQfEoq6fSJWYpjq6scIFSZl4p3azUAuAfh/UGDXoQ=",
        "originContent": "- `prompt_wav` is the path to the prompt wav.",
        "translatedContent": "- `prompt_wav` هو مسار ملف wav الخاص بالمحادثة."
      },
      {
        "row": 5,
        "rowsha": "M4Z2DDajNBdyF/JosIaDZ44oyZnjNA7lzfGzEpuoako=",
        "originContent": "- `text` is the text to be synthesized, e.g. \"[S1] I'm fine. [S2] What's your name? [S1] I'm Eric. [S2] Hi Eric.\"",
        "translatedContent": "- `text` هو النص المراد توليفه، مثل \"[S1] أنا بخير. [S2] ما اسمك؟ [S1] أنا إريك. [S2] مرحباً إريك.\""
      },
      {
        "row": 6,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 7,
        "rowsha": "cDDd56+0WMPRH7CargkOcXZpCX+wGZvzj4Pws7l8G8M=",
        "originContent": "(2) **Splitted prompt format** where the audios and transciptions of two speakers exist in separate files:",
        "translatedContent": "(2) **تنسيق المحادثة المقسمة** حيث توجد تسجيلات الصوت والنصوص التفريغية للمتحدثين الاثنين في ملفات منفصلة:"
      },
      {
        "row": 8,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 22,
    "Content": "```\n{wav_name}\\t{spk1_prompt_transcription}\\t{spk2_prompt_transcription}\\t{spk1_prompt_wav}\\t{spk2_prompt_wav}\\t{text}\n```",
    "ContentSha": "zPaMLy5mnnAP5WeOve+uEMlDenRN6Anuru4V4waQX9w=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```\n{wav_name}\\t{spk1_prompt_transcription}\\t{spk2_prompt_transcription}\\t{spk1_prompt_wav}\\t{spk2_prompt_wav}\\t{text}\n```",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      },
      {
        "row": 2,
        "rowsha": "hHgFoD5R+Rt1H2Gp8j7APyv0GrmZvViGd4j3PLgnJuE=",
        "originContent": "{wav_name}\\t{spk1_prompt_transcription}\\t{spk2_prompt_transcription}\\t{spk1_prompt_wav}\\t{spk2_prompt_wav}\\t{text}",
        "translatedContent": "{wav_name}\\t{spk1_prompt_transcription}\\t{spk2_prompt_transcription}\\t{spk1_prompt_wav}\\t{spk2_prompt_wav}\\t{text}"
      },
      {
        "row": 3,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      }
    ],
    "IsCodeBlock": true
  },
  {
    "Id": 23,
    "Content": "\n- `wav_name` is the name of the output wav file.\n- `spk1_prompt_transcription` is the transcription of the first speaker's prompt wav, e.g, \"Hello\"\n- `spk2_prompt_transcription` is the transcription of the second speaker's prompt wav, e.g, \"How are you?\"\n- `spk1_prompt_wav` is the path to the first speaker's prompt wav file.\n- `spk2_prompt_wav` is the path to the second speaker's prompt wav file.\n- `text` is the text to be synthesized, e.g. \"[S1] I'm fine. [S2] What's your name? [S1] I'm Eric. [S2] Hi Eric.\"\n\n### 3 Guidance for better usage:\n\n#### 3.1 Prompt length\n\nWe recommand a short prompt wav file (e.g., less than 3 seconds for single-speaker speech generation, less than 10 seconds for dialogue speech generation) for faster inference speed. A very long prompt will slow down the inference and degenerate the speech quality.\n\n#### 3.2 Speed optimization\n\nIf the inference speed is unsatisfactory, you can speed it up as follows:\n\n- **Distill model and less steps**: For the single-speaker speech generation model, we use the `zipvoice` model by default for better speech quality. If faster speed is a priority, you can switch to the `zipvoice_distill` and can reduce the `--num-steps` to as low as `4` (8 by default).\n\n- **CPU speedup with multi-threading**: When running on CPU, you can pass the `--num-thread` parameter (e.g., `--num-thread 4`) to increase the number of threads for faster speed. We use 1 thread by default.\n\n- **CPU speedup with ONNX**: When running on CPU, you can use ONNX models with `zipvoice.bin.infer_zipvoice_onnx` for faster speed (haven't supported ONNX for dialogue generation models yet). For even faster speed, you can further set `--onnx-int8 True` to use an INT8-quantized ONNX model. Note that the quantized model will result in a certain degree of speech quality degradation. **Don't use ONNX on GPU**, as it is slower than PyTorch on GPU.\n\n#### 3.3 Memory control\n\nThe given text will be splitted into chunks based on punctuation (for single-speaker speech generation) or speaker-turn symbol (for dialogue speech generation). Then, the chunked texts will be processed in batches. Therefore, the model can process arbitrarily long text with almost constant memory usage. You can control memory usage by adjusting the `--max-duration` parameter.\n\n#### 3.4 \"Raw\" evaluation\n\nBy default, we preprocess inputs (prompt wav, prompt transcription, and text) for efficient inference and better performance. If you want to evaluate the model’s \"raw\" performance using exact provided inputs (e.g., to reproduce the results in our paper), you can pass `--raw-evaluation True`.\n\n#### 3.5 Short text\n\nWhen generating speech for very short texts (e.g., one or two words), the generated speech may sometimes omit certain pronunciations. To resolve this issue, you can pass `--speed 0.3` (where 0.3 is a tunable value) to extend the duration of the generated speech.\n\n#### 3.6 Correcting mispronounced chinese polyphone characters\n\nWe use [pypinyin](https://github.com/mozillazg/python-pinyin) to convert Chinese characters to pinyin. However, it can occasionally mispronounce **polyphone characters** (多音字).\n",
    "ContentSha": "UWr/j4Eh3KpiD5yu2h2lngpeAgJev3NJrlmr/VCcZUc=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "- `wav_name` هو اسم ملف wav الناتج.\n- `spk1_prompt_transcription` هو نص الموجه لملف wav الخاص بالمتحدث الأول، مثل \"مرحباً\"\n- `spk2_prompt_transcription` هو نص الموجه لملف wav الخاص بالمتحدث الثاني، مثل \"كيف حالك؟\"\n- `spk1_prompt_wav` هو مسار ملف wav الخاص بالموجه للمتحدث الأول.\n- `spk2_prompt_wav` هو مسار ملف wav الخاص بالموجه للمتحدث الثاني.\n- `text` هو النص المراد توليده، مثل \"[S1] أنا بخير. [S2] ما اسمك؟ [S1] اسمي إريك. [S2] مرحباً إريك.\"\n\n### 3 إرشادات للاستخدام الأفضل:\n\n#### 3.1 طول الموجه\n\nنوصي باستخدام ملف wav موجه قصير (على سبيل المثال، أقل من 3 ثوانٍ لتوليد الكلام لمتحدث واحد، وأقل من 10 ثوانٍ لتوليد كلام الحوار) لزيادة سرعة الاستنتاج. الموجه الطويل جداً سيبطئ الاستنتاج ويؤدي إلى تدهور جودة الصوت.\n\n#### 3.2 تحسين السرعة\n\nإذا كانت سرعة الاستنتاج غير مرضية، يمكنك تسريعها كما يلي:\n\n- **نمذجة التكثيف وخطوات أقل**: بالنسبة لنموذج توليد الكلام للمتحدث الواحد، نستخدم نموذج `zipvoice` افتراضياً لجودة صوت أفضل. إذا كانت السرعة أولوية، يمكنك التبديل إلى `zipvoice_distill` وتقليل قيمة `--num-steps` إلى أدنى حد وهو `4` (القيمة الافتراضية 8).\n\n- **تسريع وحدة المعالجة المركزية باستخدام تعدد الخيوط**: عند التشغيل على وحدة المعالجة المركزية، يمكنك تمرير معامل `--num-thread` (مثلاً، `--num-thread 4`) لزيادة عدد الخيوط وتسريع الأداء. القيمة الافتراضية هي خيط واحد.\n\n- **تسريع وحدة المعالجة المركزية باستخدام ONNX**: عند التشغيل على وحدة المعالجة المركزية، يمكنك استخدام نماذج ONNX مع `zipvoice.bin.infer_zipvoice_onnx` لزيادة السرعة (لم يتم دعم ONNX بعد لنماذج توليد الحوار). لمزيد من السرعة، يمكنك ضبط `--onnx-int8 True` لاستخدام نموذج ONNX كمي INT8. لاحظ أن النموذج المكمي يؤدي إلى تدهور جودة الصوت بدرجة معينة. **لا تستخدم ONNX على وحدة معالجة الرسومات**، لأنه أبطأ من PyTorch على وحدة معالجة الرسومات.\n\n#### 3.3 التحكم في الذاكرة\n\nسيتم تقسيم النص المقدم إلى أجزاء بناءً على علامات الترقيم (لتوليد الكلام للمتحدث الواحد) أو رمز تبديل المتحدث (لتوليد كلام الحوار). بعد ذلك، تتم معالجة النصوص المجزأة على دفعات. وبالتالي، يمكن للنموذج معالجة نص طويل جداً باستخدام ذاكرة شبه ثابتة. يمكنك التحكم في استخدام الذاكرة عن طريق ضبط معامل `--max-duration`.\n\n#### 3.4 التقييم \"الخام\"\n\nبشكل افتراضي، نقوم بمعالجة المدخلات مسبقاً (ملف wav للموجه، نص الموجه، والنص) لتحقيق استنتاج فعال وأداء أفضل. إذا رغبت في تقييم أداء النموذج \"الخام\" باستخدام المدخلات المقدمة بالضبط (مثل لإعادة إنتاج نتائج بحثنا)، يمكنك تمرير `--raw-evaluation True`.\n\n#### 3.5 النصوص القصيرة\n\nعند توليد الكلام لنصوص قصيرة جداً (مثل كلمة أو كلمتين)، قد يتجاهل الكلام الناتج أحياناً بعض النطق. لحل هذه المشكلة، يمكنك تمرير `--speed 0.3` (حيث 0.3 قيمة قابلة للضبط) لتمديد مدة الكلام الناتج.\n\n#### 3.6 تصحيح نطق حروف الصينية متعددة الأصوات\n\nنستخدم [pypinyin](https://github.com/mozillazg/python-pinyin) لتحويل الحروف الصينية إلى بينيين. ومع ذلك، قد يخطئ أحياناً في نطق **الحروف متعددة الأصوات** (多音字).\n\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "- `wav_name` هو اسم ملف wav الناتج."
      },
      {
        "row": 2,
        "rowsha": "6vgIR6WfUAFmULhn8LhxFttPwZEo/YwGhN1DAECwHCQ=",
        "originContent": "- `wav_name` is the name of the output wav file.",
        "translatedContent": "- `spk1_prompt_transcription` هو نص الموجه لملف wav الخاص بالمتحدث الأول، مثل \"مرحباً\""
      },
      {
        "row": 3,
        "rowsha": "7BNq8UaBvTut4Ow/oJBAgIDTn3EwEZXK7mlUaYdFwqw=",
        "originContent": "- `spk1_prompt_transcription` is the transcription of the first speaker's prompt wav, e.g, \"Hello\"",
        "translatedContent": "- `spk2_prompt_transcription` هو نص الموجه لملف wav الخاص بالمتحدث الثاني، مثل \"كيف حالك؟\""
      },
      {
        "row": 4,
        "rowsha": "CES8w9dqVdkdJyOJBUVP282aaKeevVWB3d/+59TEsuk=",
        "originContent": "- `spk2_prompt_transcription` is the transcription of the second speaker's prompt wav, e.g, \"How are you?\"",
        "translatedContent": "- `spk1_prompt_wav` هو مسار ملف wav الخاص بالموجه للمتحدث الأول."
      },
      {
        "row": 5,
        "rowsha": "gXLLRf4BR7Xko2q2l4nK04KIs/L8CjvZ/UBQaP1+vck=",
        "originContent": "- `spk1_prompt_wav` is the path to the first speaker's prompt wav file.",
        "translatedContent": "- `spk2_prompt_wav` هو مسار ملف wav الخاص بالموجه للمتحدث الثاني."
      },
      {
        "row": 6,
        "rowsha": "oS1+heJwBnnDtA57WYtG6LbzxK79DOIeb8hwhZQwcDg=",
        "originContent": "- `spk2_prompt_wav` is the path to the second speaker's prompt wav file.",
        "translatedContent": "- `text` هو النص المراد توليده، مثل \"[S1] أنا بخير. [S2] ما اسمك؟ [S1] اسمي إريك. [S2] مرحباً إريك.\""
      },
      {
        "row": 7,
        "rowsha": "M4Z2DDajNBdyF/JosIaDZ44oyZnjNA7lzfGzEpuoako=",
        "originContent": "- `text` is the text to be synthesized, e.g. \"[S1] I'm fine. [S2] What's your name? [S1] I'm Eric. [S2] Hi Eric.\"",
        "translatedContent": ""
      },
      {
        "row": 8,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "### 3 إرشادات للاستخدام الأفضل:"
      },
      {
        "row": 9,
        "rowsha": "SdDI3h73wOzKSM3kbrbNrmpigHGer7kumuaZsQgAeao=",
        "originContent": "### 3 Guidance for better usage:",
        "translatedContent": ""
      },
      {
        "row": 10,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "#### 3.1 طول الموجه"
      },
      {
        "row": 11,
        "rowsha": "cVxukE6jyFFOxlNKI5ecOTo/suYYJ8hnYyW2XA2wg+o=",
        "originContent": "#### 3.1 Prompt length",
        "translatedContent": ""
      },
      {
        "row": 12,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "نوصي باستخدام ملف wav موجه قصير (على سبيل المثال، أقل من 3 ثوانٍ لتوليد الكلام لمتحدث واحد، وأقل من 10 ثوانٍ لتوليد كلام الحوار) لزيادة سرعة الاستنتاج. الموجه الطويل جداً سيبطئ الاستنتاج ويؤدي إلى تدهور جودة الصوت."
      },
      {
        "row": 13,
        "rowsha": "f19zq78QrLul7wiVSlCSojGS7qNEvtef9GFg6AA8eMY=",
        "originContent": "We recommand a short prompt wav file (e.g., less than 3 seconds for single-speaker speech generation, less than 10 seconds for dialogue speech generation) for faster inference speed. A very long prompt will slow down the inference and degenerate the speech quality.",
        "translatedContent": ""
      },
      {
        "row": 14,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "#### 3.2 تحسين السرعة"
      },
      {
        "row": 15,
        "rowsha": "lpgNpm20ulCcTiEU/xfEVVgMZhjiQjymkdljF8dD/vw=",
        "originContent": "#### 3.2 Speed optimization",
        "translatedContent": ""
      },
      {
        "row": 16,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "إذا كانت سرعة الاستنتاج غير مرضية، يمكنك تسريعها كما يلي:"
      },
      {
        "row": 17,
        "rowsha": "iBJxMfYOjV9HvSuRT3p/EsU/iATeDCDAk/wGWLXqQI8=",
        "originContent": "If the inference speed is unsatisfactory, you can speed it up as follows:",
        "translatedContent": ""
      },
      {
        "row": 18,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "- **نمذجة التكثيف وخطوات أقل**: بالنسبة لنموذج توليد الكلام للمتحدث الواحد، نستخدم نموذج `zipvoice` افتراضياً لجودة صوت أفضل. إذا كانت السرعة أولوية، يمكنك التبديل إلى `zipvoice_distill` وتقليل قيمة `--num-steps` إلى أدنى حد وهو `4` (القيمة الافتراضية 8)."
      },
      {
        "row": 19,
        "rowsha": "IzTHxzS1e5yJRhHF5d8CsjfqjIzhNX1AeGR4FTjuUCA=",
        "originContent": "- **Distill model and less steps**: For the single-speaker speech generation model, we use the `zipvoice` model by default for better speech quality. If faster speed is a priority, you can switch to the `zipvoice_distill` and can reduce the `--num-steps` to as low as `4` (8 by default).",
        "translatedContent": ""
      },
      {
        "row": 20,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "- **تسريع وحدة المعالجة المركزية باستخدام تعدد الخيوط**: عند التشغيل على وحدة المعالجة المركزية، يمكنك تمرير معامل `--num-thread` (مثلاً، `--num-thread 4`) لزيادة عدد الخيوط وتسريع الأداء. القيمة الافتراضية هي خيط واحد."
      },
      {
        "row": 21,
        "rowsha": "mNiqyHjFr4rbx4boH0cix2peH8Q0+tDTOlzgZeLLDqM=",
        "originContent": "- **CPU speedup with multi-threading**: When running on CPU, you can pass the `--num-thread` parameter (e.g., `--num-thread 4`) to increase the number of threads for faster speed. We use 1 thread by default.",
        "translatedContent": ""
      },
      {
        "row": 22,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "- **تسريع وحدة المعالجة المركزية باستخدام ONNX**: عند التشغيل على وحدة المعالجة المركزية، يمكنك استخدام نماذج ONNX مع `zipvoice.bin.infer_zipvoice_onnx` لزيادة السرعة (لم يتم دعم ONNX بعد لنماذج توليد الحوار). لمزيد من السرعة، يمكنك ضبط `--onnx-int8 True` لاستخدام نموذج ONNX كمي INT8. لاحظ أن النموذج المكمي يؤدي إلى تدهور جودة الصوت بدرجة معينة. **لا تستخدم ONNX على وحدة معالجة الرسومات**، لأنه أبطأ من PyTorch على وحدة معالجة الرسومات."
      },
      {
        "row": 23,
        "rowsha": "YqtmXdPz7OfUIbrIkeeIwyKEPdEZUqn3m5EyTNd967s=",
        "originContent": "- **CPU speedup with ONNX**: When running on CPU, you can use ONNX models with `zipvoice.bin.infer_zipvoice_onnx` for faster speed (haven't supported ONNX for dialogue generation models yet). For even faster speed, you can further set `--onnx-int8 True` to use an INT8-quantized ONNX model. Note that the quantized model will result in a certain degree of speech quality degradation. **Don't use ONNX on GPU**, as it is slower than PyTorch on GPU.",
        "translatedContent": ""
      },
      {
        "row": 24,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "#### 3.3 التحكم في الذاكرة"
      },
      {
        "row": 25,
        "rowsha": "fze8iMUXPcPsZgNFyWFzWSuCffZnzh7SpzLs21tQLtE=",
        "originContent": "#### 3.3 Memory control",
        "translatedContent": ""
      },
      {
        "row": 26,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "سيتم تقسيم النص المقدم إلى أجزاء بناءً على علامات الترقيم (لتوليد الكلام للمتحدث الواحد) أو رمز تبديل المتحدث (لتوليد كلام الحوار). بعد ذلك، تتم معالجة النصوص المجزأة على دفعات. وبالتالي، يمكن للنموذج معالجة نص طويل جداً باستخدام ذاكرة شبه ثابتة. يمكنك التحكم في استخدام الذاكرة عن طريق ضبط معامل `--max-duration`."
      },
      {
        "row": 27,
        "rowsha": "uM67TExtHYq7ALHmglqtjLRqv0Xu0OOSx2aFJquZPmw=",
        "originContent": "The given text will be splitted into chunks based on punctuation (for single-speaker speech generation) or speaker-turn symbol (for dialogue speech generation). Then, the chunked texts will be processed in batches. Therefore, the model can process arbitrarily long text with almost constant memory usage. You can control memory usage by adjusting the `--max-duration` parameter.",
        "translatedContent": ""
      },
      {
        "row": 28,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "#### 3.4 التقييم \"الخام\""
      },
      {
        "row": 29,
        "rowsha": "foa86E9JcH+Sc/k2OCmyfIKHwggsFBXhSUfHDcmJQA0=",
        "originContent": "#### 3.4 \"Raw\" evaluation",
        "translatedContent": ""
      },
      {
        "row": 30,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "بشكل افتراضي، نقوم بمعالجة المدخلات مسبقاً (ملف wav للموجه، نص الموجه، والنص) لتحقيق استنتاج فعال وأداء أفضل. إذا رغبت في تقييم أداء النموذج \"الخام\" باستخدام المدخلات المقدمة بالضبط (مثل لإعادة إنتاج نتائج بحثنا)، يمكنك تمرير `--raw-evaluation True`."
      },
      {
        "row": 31,
        "rowsha": "+2nxKNvXmuxUQpf2Z+hw0Rxydt00FpmK4y4rlK5/8og=",
        "originContent": "By default, we preprocess inputs (prompt wav, prompt transcription, and text) for efficient inference and better performance. If you want to evaluate the model’s \"raw\" performance using exact provided inputs (e.g., to reproduce the results in our paper), you can pass `--raw-evaluation True`.",
        "translatedContent": ""
      },
      {
        "row": 32,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "#### 3.5 النصوص القصيرة"
      },
      {
        "row": 33,
        "rowsha": "g658opDssPKmJCvr7Jw9N130Xud1IbMHTwMK+S89WO0=",
        "originContent": "#### 3.5 Short text",
        "translatedContent": ""
      },
      {
        "row": 34,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "عند توليد الكلام لنصوص قصيرة جداً (مثل كلمة أو كلمتين)، قد يتجاهل الكلام الناتج أحياناً بعض النطق. لحل هذه المشكلة، يمكنك تمرير `--speed 0.3` (حيث 0.3 قيمة قابلة للضبط) لتمديد مدة الكلام الناتج."
      },
      {
        "row": 35,
        "rowsha": "/IVkHehTtKgVQNwGOgQO/BoRh95RFHVJPH3e0W6Gixs=",
        "originContent": "When generating speech for very short texts (e.g., one or two words), the generated speech may sometimes omit certain pronunciations. To resolve this issue, you can pass `--speed 0.3` (where 0.3 is a tunable value) to extend the duration of the generated speech.",
        "translatedContent": ""
      },
      {
        "row": 36,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "#### 3.6 تصحيح نطق حروف الصينية متعددة الأصوات"
      },
      {
        "row": 37,
        "rowsha": "PAPz1JYDhpLF6dsiNH/BVipH4SufvLcqzLiPLACOcK4=",
        "originContent": "#### 3.6 Correcting mispronounced chinese polyphone characters",
        "translatedContent": ""
      },
      {
        "row": 38,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "نستخدم [pypinyin](https://github.com/mozillazg/python-pinyin) لتحويل الحروف الصينية إلى بينيين. ومع ذلك، قد يخطئ أحياناً في نطق **الحروف متعددة الأصوات** (多音字)."
      },
      {
        "row": 39,
        "rowsha": "hF52KZEnGKLuaot2w0AmXt52eB6Y3adYIo2qMJSMx5o=",
        "originContent": "We use [pypinyin](https://github.com/mozillazg/python-pinyin) to convert Chinese characters to pinyin. However, it can occasionally mispronounce **polyphone characters** (多音字).",
        "translatedContent": ""
      },
      {
        "row": 40,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 24,
    "Content": "To manually correct these mispronunciations, enclose the **corrected pinyin** in angle brackets `< >` and include the **tone mark**.\n\n**Example:**\n\n- Original text: `这把剑长三十公分`\n- Correct the pinyin of `长`:  `这把剑<chang2>三十公分`\n\n> **Note:** If you want to manually assign multiple pinyins, enclose each pinyin with `<>`, e.g., `这把<jian4><chang2><san1>十公分`\n\n#### 3.7 Remove long silences from the generated speech\n\nModel will automatically determine the positions and lengths of silences in the generated speech. It occasionally has long silence in the middle of the speech. If you don't want this, you can pass `--remove-long-sil` to remove long silences in the middle of the generated speech (edge silences will be removed by default).\n\n#### 3.8 Model downloading\n\nIf you have trouble connecting to HuggingFace when downloading the pre-trained models, try switching endpoint to the mirror site: `export HF_ENDPOINT=https://hf-mirror.com`.\n\n## Train Your Own Model\n\nSee the [egs](egs) directory for training, fine-tuning and evaluation examples.\n\n## C++ Deployment\n\nCheck [sherpa-onnx](https://github.com/k2-fsa/sherpa-onnx/pull/2487#issuecomment-3227884498) for the C++ deployment solution on CPU.\n\n## Discussion & Communication\n\nYou can directly discuss on [Github Issues](https://github.com/k2-fsa/ZipVoice/issues).\n\nYou can also scan the QR code to join our wechat group or follow our wechat official account.\n\n| Wechat Group | Wechat Official Account |\n| ------------ | ----------------------- |\n|![wechat](https://k2-fsa.org/zh-CN/assets/pic/wechat_group.jpg) |![wechat](https://k2-fsa.org/zh-CN/assets/pic/wechat_account.jpg) |\n\n## Citation\n",
    "ContentSha": "4XVNGS5kZAhMaOVNNfOEa6tjINlsa4d7Tmrgr+cYo9w=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "لتصحيح هذه الأخطاء في النطق يدويًا، ضع **التهجئة الصحيحة (بينيين)** بين علامات الزاوية `< >` وضمنها **علامة النبرة**.\n\n**مثال:**\n\n- النص الأصلي: `这把剑长三十公分`\n- صحح تهجئة كلمة `长`:  `这把剑<chang2>三十公分`\n\n> **ملاحظة:** إذا أردت تعيين عدة تهجئات يدويًا، ضع كل تهجئة بين `<>`، مثل: `这把<jian4><chang2><san1>十公分`\n\n#### 3.7 إزالة الفترات الطويلة من الصمت في الكلام الناتج\n\nسيحدد النموذج تلقائيًا مواضع وأطوال الفترات الصامتة في الكلام الناتج. أحيانًا تظهر فترات صمت طويلة في منتصف الكلام. إذا كنت لا ترغب بذلك، يمكنك تمرير الخيار `--remove-long-sil` لإزالة الفترات الطويلة في منتصف الكلام الناتج (سيتم إزالة الفترات الصامتة في الأطراف تلقائيًا).\n\n#### 3.8 تنزيل النموذج\n\nإذا واجهت مشكلة في الاتصال بـ HuggingFace أثناء تنزيل النماذج المدربة مسبقًا، جرب تغيير نقطة النهاية إلى الموقع المرآة: `export HF_ENDPOINT=https://hf-mirror.com`.\n\n## تدريب نموذجك الخاص\n\nراجع دليل [egs](egs) لأمثلة التدريب، وضبط النموذج، والتقييم.\n\n## النشر باستخدام C++\n\nراجع [sherpa-onnx](https://github.com/k2-fsa/sherpa-onnx/pull/2487#issuecomment-3227884498) لحل النشر باستخدام لغة C++ على وحدة المعالجة المركزية.\n\n## المناقشة والتواصل\n\nيمكنك المناقشة مباشرة عبر [Github Issues](https://github.com/k2-fsa/ZipVoice/issues).\n\nيمكنك أيضًا مسح رمز الاستجابة السريعة للانضمام إلى مجموعة Wechat أو متابعة الحساب الرسمي لـ Wechat.\n\n| مجموعة Wechat | الحساب الرسمي لـ Wechat |\n| ------------- | ----------------------- |\n|![wechat](https://k2-fsa.org/zh-CN/assets/pic/wechat_group.jpg) |![wechat](https://k2-fsa.org/zh-CN/assets/pic/wechat_account.jpg) |\n\n## الاقتباس\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "h6Qq8AvUPYme90k2BWG054cVE6RHNflr0OwdnKA4BEE=",
        "originContent": "To manually correct these mispronunciations, enclose the **corrected pinyin** in angle brackets `< >` and include the **tone mark**.",
        "translatedContent": "لتصحيح هذه الأخطاء في النطق يدويًا، ضع **التهجئة الصحيحة (بينيين)** بين علامات الزاوية `< >` وضمنها **علامة النبرة**."
      },
      {
        "row": 2,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 3,
        "rowsha": "fP4bnCe7+qhcgDDajGMIv4obksa4WSdUp3hExEbpci0=",
        "originContent": "**Example:**",
        "translatedContent": "**مثال:**"
      },
      {
        "row": 4,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 5,
        "rowsha": "ntwz9/IQqGC1ThJXQn9D83h+54cDriyg2snkkrk0KoI=",
        "originContent": "- Original text: `这把剑长三十公分`",
        "translatedContent": "- النص الأصلي: `这把剑长三十公分`"
      },
      {
        "row": 6,
        "rowsha": "sfnMRvscnvdKs1fvbVePwH0RpAikXkFIi9i7HZK7D9w=",
        "originContent": "- Correct the pinyin of `长`:  `这把剑<chang2>三十公分`",
        "translatedContent": "- صحح تهجئة كلمة `长`:  `这把剑<chang2>三十公分`"
      },
      {
        "row": 7,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 8,
        "rowsha": "7f45Y23fyK7AQrUO7HdTtPZZzoyRkW6WwoznauYmQew=",
        "originContent": "> **Note:** If you want to manually assign multiple pinyins, enclose each pinyin with `<>`, e.g., `这把<jian4><chang2><san1>十公分`",
        "translatedContent": "> **ملاحظة:** إذا أردت تعيين عدة تهجئات يدويًا، ضع كل تهجئة بين `<>`، مثل: `这把<jian4><chang2><san1>十公分`"
      },
      {
        "row": 9,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 10,
        "rowsha": "FJBRXZnczlB/CZyp0UgEFMr440NrcuTPBheyQJ9lxZI=",
        "originContent": "#### 3.7 Remove long silences from the generated speech",
        "translatedContent": "#### 3.7 إزالة الفترات الطويلة من الصمت في الكلام الناتج"
      },
      {
        "row": 11,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 12,
        "rowsha": "9UF5wHdPZ48OWeIPfCnOHPEWzgW4Z6I0e+GaTEZ1GXI=",
        "originContent": "Model will automatically determine the positions and lengths of silences in the generated speech. It occasionally has long silence in the middle of the speech. If you don't want this, you can pass `--remove-long-sil` to remove long silences in the middle of the generated speech (edge silences will be removed by default).",
        "translatedContent": "سيحدد النموذج تلقائيًا مواضع وأطوال الفترات الصامتة في الكلام الناتج. أحيانًا تظهر فترات صمت طويلة في منتصف الكلام. إذا كنت لا ترغب بذلك، يمكنك تمرير الخيار `--remove-long-sil` لإزالة الفترات الطويلة في منتصف الكلام الناتج (سيتم إزالة الفترات الصامتة في الأطراف تلقائيًا)."
      },
      {
        "row": 13,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 14,
        "rowsha": "t3GDCbkkN4PM6Y7xA/ZDAXgu4WdMFfXJ+5E/xKU9AKo=",
        "originContent": "#### 3.8 Model downloading",
        "translatedContent": "#### 3.8 تنزيل النموذج"
      },
      {
        "row": 15,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 16,
        "rowsha": "I2UvthbxkflPXxq8Yy6W9nJCtzb40mZPJbfmDIWQPmA=",
        "originContent": "If you have trouble connecting to HuggingFace when downloading the pre-trained models, try switching endpoint to the mirror site: `export HF_ENDPOINT=https://hf-mirror.com`.",
        "translatedContent": "إذا واجهت مشكلة في الاتصال بـ HuggingFace أثناء تنزيل النماذج المدربة مسبقًا، جرب تغيير نقطة النهاية إلى الموقع المرآة: `export HF_ENDPOINT=https://hf-mirror.com`."
      },
      {
        "row": 17,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 18,
        "rowsha": "SEsrfyGZhBYqHMMdMldgN+tSz6ynJT5BVJeLrTV5lHw=",
        "originContent": "## Train Your Own Model",
        "translatedContent": "## تدريب نموذجك الخاص"
      },
      {
        "row": 19,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 20,
        "rowsha": "XaSJNyFaxQRx1Xc0mphwUGAxovKELo/54WkMCnFDLyE=",
        "originContent": "See the [egs](egs) directory for training, fine-tuning and evaluation examples.",
        "translatedContent": "راجع دليل [egs](egs) لأمثلة التدريب، وضبط النموذج، والتقييم."
      },
      {
        "row": 21,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 22,
        "rowsha": "ESfW2TcYQsyWp1w1J57QxpfNXtuvVGrf4Amg7ahWfYI=",
        "originContent": "## C++ Deployment",
        "translatedContent": "## النشر باستخدام C++"
      },
      {
        "row": 23,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 24,
        "rowsha": "B8jnXFyKu8XRyVw/Pu0Xuj1ted9/BVoBfwJ1WW9LrcE=",
        "originContent": "Check [sherpa-onnx](https://github.com/k2-fsa/sherpa-onnx/pull/2487#issuecomment-3227884498) for the C++ deployment solution on CPU.",
        "translatedContent": "راجع [sherpa-onnx](https://github.com/k2-fsa/sherpa-onnx/pull/2487#issuecomment-3227884498) لحل النشر باستخدام لغة C++ على وحدة المعالجة المركزية."
      },
      {
        "row": 25,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 26,
        "rowsha": "dEqRbPItUt3FEp1iC+8Ww+A6L57yd6oGeXfxSn5BYzs=",
        "originContent": "## Discussion & Communication",
        "translatedContent": "## المناقشة والتواصل"
      },
      {
        "row": 27,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 28,
        "rowsha": "wjQUwaDgSP1a6ggLgGx8TWt44Dxu5IlJytNwCAlzZKg=",
        "originContent": "You can directly discuss on [Github Issues](https://github.com/k2-fsa/ZipVoice/issues).",
        "translatedContent": "يمكنك المناقشة مباشرة عبر [Github Issues](https://github.com/k2-fsa/ZipVoice/issues)."
      },
      {
        "row": 29,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 30,
        "rowsha": "WLbsT+slCE72T0wpzVIN8KFxhP+RAw29VxFhJcBEEIo=",
        "originContent": "You can also scan the QR code to join our wechat group or follow our wechat official account.",
        "translatedContent": "يمكنك أيضًا مسح رمز الاستجابة السريعة للانضمام إلى مجموعة Wechat أو متابعة الحساب الرسمي لـ Wechat."
      },
      {
        "row": 31,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 32,
        "rowsha": "XMNeg//PyHlCkY1XlL7caNd2vlVOKKoslrNeasADjMY=",
        "originContent": "| Wechat Group | Wechat Official Account |",
        "translatedContent": "| مجموعة Wechat | الحساب الرسمي لـ Wechat |"
      },
      {
        "row": 33,
        "rowsha": "jdP52Pdk9hJ4eEQC1YzC887/bGdD6V25zHK1FxUbFjM=",
        "originContent": "| ------------ | ----------------------- |",
        "translatedContent": "| ------------- | ----------------------- |"
      },
      {
        "row": 34,
        "rowsha": "Q6eYrtLPPuG0fiZxZqhYquTYNk0vlyIOh+CRuwGZVk4=",
        "originContent": "|![wechat](https://k2-fsa.org/zh-CN/assets/pic/wechat_group.jpg) |![wechat](https://k2-fsa.org/zh-CN/assets/pic/wechat_account.jpg) |",
        "translatedContent": "|![wechat](https://k2-fsa.org/zh-CN/assets/pic/wechat_group.jpg) |![wechat](https://k2-fsa.org/zh-CN/assets/pic/wechat_account.jpg) |"
      },
      {
        "row": 35,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 36,
        "rowsha": "ZwTp5ajUmpHTJefyHhIKzXcG2wnB1jv8iv8cvmdcb/g=",
        "originContent": "## Citation",
        "translatedContent": "## الاقتباس"
      },
      {
        "row": 37,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 25,
    "Content": "```bibtex\n@article{zhu2025zipvoice,\n      title={ZipVoice: Fast and High-Quality Zero-Shot Text-to-Speech with Flow Matching},\n      author={Zhu, Han and Kang, Wei and Yao, Zengwei and Guo, Liyong and Kuang, Fangjun and Li, Zhaoqing and Zhuang, Weiji and Lin, Long and Povey, Daniel},\n      journal={arXiv preprint arXiv:2506.13053},\n      year={2025}\n}\n\n@article{zhu2025zipvoicedialog,\n      title={ZipVoice-Dialog: Non-Autoregressive Spoken Dialogue Generation with Flow Matching},\n      author={Zhu, Han and Kang, Wei and Guo, Liyong and Yao, Zengwei and Kuang, Fangjun and Zhuang, Weiji and Li, Zhaoqing and Han, Zhifeng and Zhang, Dong and Zhang, Xin and Song, Xingchen and Lin, Long and Povey, Daniel},\n      journal={arXiv preprint arXiv:2507.09318},\n      year={2025}\n}\n```",
    "ContentSha": "4y5htVtgE8qDxiQNpfNmGGVhWO4hKo26DrPCI9N/e9E=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bibtex\n@article{zhu2025zipvoice,\n      title={ZipVoice: Fast and High-Quality Zero-Shot Text-to-Speech with Flow Matching},\n      author={Zhu, Han and Kang, Wei and Yao, Zengwei and Guo, Liyong and Kuang, Fangjun and Li, Zhaoqing and Zhuang, Weiji and Lin, Long and Povey, Daniel},\n      journal={arXiv preprint arXiv:2506.13053},\n      year={2025}\n}\n\n@article{zhu2025zipvoicedialog,\n      title={ZipVoice-Dialog: Non-Autoregressive Spoken Dialogue Generation with Flow Matching},\n      author={Zhu, Han and Kang, Wei and Guo, Liyong and Yao, Zengwei and Kuang, Fangjun and Zhuang, Weiji and Li, Zhaoqing and Han, Zhifeng and Zhang, Dong and Zhang, Xin and Song, Xingchen and Lin, Long and Povey, Daniel},\n      journal={arXiv preprint arXiv:2507.09318},\n      year={2025}\n}\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 26,
    "Content": "",
    "ContentSha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "<translate-content></translate-content>",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  }
]