[
  {
    "Id": 1,
    "Content": "\n<div align=\"right\">\n  <details>\n    <summary >ğŸŒ Language</summary>\n    <div>\n      <div align=\"center\">\n        <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=en\">English</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=zh-CN\">ç®€ä½“ä¸­æ–‡</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=zh-TW\">ç¹é«”ä¸­æ–‡</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ja\">æ—¥æœ¬èª</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ko\">í•œêµ­ì–´</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=hi\">à¤¹à¤¿à¤¨à¥à¤¦à¥€</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=th\">à¹„à¸—à¸¢</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=fr\">FranÃ§ais</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=de\">Deutsch</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=es\">EspaÃ±ol</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=it\">Itapano</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ru\">Ğ ÑƒÑÑĞºĞ¸Ğ¹</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=pt\">PortuguÃªs</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=nl\">Nederlands</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=pl\">Polski</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ar\">Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=fa\">ÙØ§Ø±Ø³ÛŒ</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=tr\">TÃ¼rkÃ§e</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=vi\">Tiáº¿ng Viá»‡t</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=id\">Bahasa Indonesia</a>\n      </div>\n    </div>\n  </details>\n</div>\n\n<div align=\"center\">\n\n# ZipVoiceâš¡\n\n## Fast and High-Quality Zero-Shot Text-to-Speech with Flow Matching\n</div>\n\n## Overview\n",
    "ContentSha": "4yvqxrt72y1T/XJlpvF5+w536K1FZVvNlGdllJQl3D8=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "\n<div align=\"right\">\n  <details>\n    <summary >ğŸŒ Dil</summary>\n    <div>\n      <div align=\"center\">\n        <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=en\">English</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=zh-CN\">ç®€ä½“ä¸­æ–‡</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=zh-TW\">ç¹é«”ä¸­æ–‡</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ja\">æ—¥æœ¬èª</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ko\">í•œêµ­ì–´</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=hi\">à¤¹à¤¿à¤¨à¥à¤¦à¥€</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=th\">à¹„à¸—à¸¢</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=fr\">FranÃ§ais</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=de\">Deutsch</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=es\">EspaÃ±ol</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=it\">Itapano</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ru\">Ğ ÑƒÑÑĞºĞ¸Ğ¹</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=pt\">PortuguÃªs</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=nl\">Nederlands</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=pl\">Polski</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ar\">Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=fa\">ÙØ§Ø±Ø³ÛŒ</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=tr\">TÃ¼rkÃ§e</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=vi\">Tiáº¿ng Viá»‡t</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=id\">Bahasa Indonesia</a>\n      </div>\n    </div>\n  </details>\n</div>\n\n<div align=\"center\">\n\n# ZipVoiceâš¡\n\n## Flow Matching ile HÄ±zlÄ± ve YÃ¼ksek Kaliteli SÄ±fÄ±rdan Metinden Sese DÃ¶nÃ¼ÅŸÃ¼m\n</div>\n\n## Genel BakÄ±ÅŸ\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 2,
    "Content": "ZipVoice is a series of fast and high-quality zero-shot TTS models based on flow matching.\n\n### 1. Key features\n\n- Small and fast: only 123M parameters.\n\n- High-quality voice cloning: state-of-the-art performance in speaker similarity, intelligibility, and naturalness.\n\n- Multi-lingual: support Chinese and English.\n\n- Multi-mode: support both single-speaker and dialogue speech generation.\n\n### 2. Model variants\n\n<table>\n  <thead>\n    <tr>\n      <th>Model Name</th>\n      <th>Description</th>\n      <th>Paper</th>\n      <th>Demo</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>ZipVoice</td>\n      <td>The basic model supporting zero-shot single-speaker TTS in both Chinese and English.</td>\n      <td rowspan=\"2\"><a href=\"https://arxiv.org/abs/2506.13053\"><img src=\"https://img.shields.io/badge/arXiv-Paper-COLOR.svg\"></a></td>\n      <td rowspan=\"2\"><a href=\"https://zipvoice.github.io\"><img src=\"https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square\"></a></td>\n    </tr>\n    <tr>\n      <td>ZipVoice-Distill</td>\n      <td>The distilled version of ZipVoice, featuring improved speed with minimal performance degradation.</td>\n    </tr>\n    <tr>\n      <td>ZipVoice-Dialog</td>\n      <td>A dialogue generation model built on ZipVoice, capable of generating single-channel two-party spoken dialogues.</td>\n      <td rowspan=\"2\"><a href=\"https://arxiv.org/abs/2507.09318\"><img src=\"https://img.shields.io/badge/arXiv-Paper-COLOR.svg\"></a></td>\n      <td rowspan=\"2\"><a href=\"https://zipvoice-dialog.github.io\"><img src=\"https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square\"></a></td>\n    </tr>",
    "ContentSha": "qUZer10kkUVucN3aqovgCkJ059aWMO67vNYjNUfJcJw=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "ZipVoice, flow matching tabanlÄ± hÄ±zlÄ± ve yÃ¼ksek kaliteli sÄ±fÄ±r atÄ±ÅŸlÄ± TTS modellerinden oluÅŸan bir seridir.\n\n### 1. Temel Ã–zellikler\n\n- KÃ¼Ã§Ã¼k ve hÄ±zlÄ±: yalnÄ±zca 123M parametre.\n\n- YÃ¼ksek kaliteli ses klonlama: konuÅŸmacÄ± benzerliÄŸi, anlaÅŸÄ±labilirlik ve doÄŸallÄ±kta alanÄ±nda Ã¶ncÃ¼ performans.\n\n- Ã‡ok dilli: Ã‡ince ve Ä°ngilizce desteÄŸi.\n\n- Ã‡ok modlu: hem tek konuÅŸmacÄ±lÄ± hem de diyalog konuÅŸmasÄ± Ã¼retimini destekler.\n\n### 2. Model varyantlarÄ±\n\n<table>\n  <thead>\n    <tr>\n      <th>Model AdÄ±</th>\n      <th>AÃ§Ä±klama</th>\n      <th>Makale</th>\n      <th>Demo</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>ZipVoice</td>\n      <td>Ã‡ince ve Ä°ngilizce'de sÄ±fÄ±r atÄ±ÅŸlÄ± tek konuÅŸmacÄ±lÄ± TTS'yi destekleyen temel model.</td>\n      <td rowspan=\"2\"><a href=\"https://arxiv.org/abs/2506.13053\"><img src=\"https://img.shields.io/badge/arXiv-Makale-COLOR.svg\"></a></td>\n      <td rowspan=\"2\"><a href=\"https://zipvoice.github.io\"><img src=\"https://img.shields.io/badge/GitHub.io-Demo_SayfasÄ±-blue?logo=Github&style=flat-square\"></a></td>\n    </tr>\n    <tr>\n      <td>ZipVoice-Distill</td>\n      <td>ZipVoiceâ€™un damÄ±tÄ±lmÄ±ÅŸ sÃ¼rÃ¼mÃ¼; minimum performans kaybÄ±yla geliÅŸtirilmiÅŸ hÄ±z sunar.</td>\n    </tr>\n    <tr>\n      <td>ZipVoice-Dialog</td>\n      <td>ZipVoice Ã¼zerine kurulu, tek kanallÄ± iki taraflÄ± konuÅŸma diyaloglarÄ± Ã¼retebilen bir diyalog Ã¼retim modeli.</td>\n      <td rowspan=\"2\"><a href=\"https://arxiv.org/abs/2507.09318\"><img src=\"https://img.shields.io/badge/arXiv-Makale-COLOR.svg\"></a></td>\n      <td rowspan=\"2\"><a href=\"https://zipvoice-dialog.github.io\"><img src=\"https://img.shields.io/badge/GitHub.io-Demo_SayfasÄ±-blue?logo=Github&style=flat-square\"></a></td>\n    </tr>",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 3,
    "Content": "    <tr>\n      <td>ZipVoice-Dialog-Stereo</td>\n      <td>The stereo variant of ZipVoice-Dialog, enabling two-channel dialogue generation with each speaker assigned to a distinct channel.</td>\n    </tr>\n  </tbody>\n</table>\n\n## News\n\n**2025/07/14**: **ZipVoice-Dialog** and **ZipVoice-Dialog-Stereo**, two spoken dialogue generation models, are released. [![arXiv](https://img.shields.io/badge/arXiv-Paper-COLOR.svg)](https://arxiv.org/abs/2507.09318) [![demo page](https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square)](https://zipvoice-dialog.github.io)\n\n**2025/07/14**: **OpenDialog** dataset, a 6.8k-hour spoken dialogue dataset, is released. Download at [![hf](https://img.shields.io/badge/%F0%9F%A4%97%20HuggingFace-Dataset-yellow)](https://huggingface.co/datasets/k2-fsa/OpenDialog), [![ms](https://img.shields.io/badge/ModelScope-Dataset-blue?logo=data)](https://www.modelscope.cn/datasets/k2-fsa/OpenDialog). Check details at [![arXiv](https://img.shields.io/badge/arXiv-Paper-COLOR.svg)](https://arxiv.org/abs/2507.09318).\n\n**2025/06/16**: **ZipVoice** and **ZipVoice-Distill** are released. [![arXiv](https://img.shields.io/badge/arXiv-Paper-COLOR.svg)](https://arxiv.org/abs/2506.13053) [![demo page](https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square)](https://zipvoice.github.io)\n\n## Installation\n\n### 1. Clone the ZipVoice repository\n",
    "ContentSha": "qyykZIxy9KKTHUZalqgKJAhZ9ZS/CaAb/vbLISMH1+E=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "    <tr>\n      <td>ZipVoice-Dialog-Stereo</td>\n      <td>ZipVoice-Dialog'Ä±n stereo varyantÄ±, her konuÅŸmacÄ±nÄ±n ayrÄ± bir kanala atanmasÄ±yla iki kanallÄ± diyalog Ã¼retimini saÄŸlar.</td>\n    </tr>\n  </tbody>\n</table>\n\n## Haberler\n\n**2025/07/14**: **ZipVoice-Dialog** ve **ZipVoice-Dialog-Stereo**, iki konuÅŸma diyalogu Ã¼retim modeli yayÄ±nlandÄ±. [![arXiv](https://img.shields.io/badge/arXiv-Paper-COLOR.svg)](https://arxiv.org/abs/2507.09318) [![demo page](https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square)](https://zipvoice-dialog.github.io)\n\n**2025/07/14**: **OpenDialog** veri seti, 6.8k saatlik konuÅŸma diyalogu veri seti yayÄ±nlandÄ±. Ä°ndir: [![hf](https://img.shields.io/badge/%F0%9F%A4%97%20HuggingFace-Dataset-yellow)](https://huggingface.co/datasets/k2-fsa/OpenDialog), [![ms](https://img.shields.io/badge/ModelScope-Dataset-blue?logo=data)](https://www.modelscope.cn/datasets/k2-fsa/OpenDialog). Detaylara bakÄ±nÄ±z: [![arXiv](https://img.shields.io/badge/arXiv-Paper-COLOR.svg)](https://arxiv.org/abs/2507.09318).\n\n**2025/06/16**: **ZipVoice** ve **ZipVoice-Distill** yayÄ±nlandÄ±. [![arXiv](https://img.shields.io/badge/arXiv-Paper-COLOR.svg)](https://arxiv.org/abs/2506.13053) [![demo page](https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square)](https://zipvoice.github.io)\n\n## Kurulum\n\n### 1. ZipVoice deposunu klonlayÄ±n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 4,
    "Content": "```bash\ngit clone https://github.com/k2-fsa/ZipVoice.git\n```",
    "ContentSha": "JJo1EP7bWO0BWMfBMdp5X937bp3+DWhl7nAOm71R7lA=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\ngit clone https://github.com/k2-fsa/ZipVoice.git\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 5,
    "Content": "\n### 2. (Optional) Create a Python virtual environment\n",
    "ContentSha": "SdfmTQw39ITwBrkeETcUaJ4CPFr6cQ+HCqumZ483/iY=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "### 2. (Ä°steÄŸe baÄŸlÄ±) Bir Python sanal ortamÄ± oluÅŸturun\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 6,
    "Content": "```bash\npython3 -m venv zipvoice\nsource zipvoice/bin/activate\n```",
    "ContentSha": "glR0Rdvd5rjEtSF3LycYEtxGB8VzT68abW/ywL40bxw=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\npython3 -m venv zipvoice\nsource zipvoice/bin/activate\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 7,
    "Content": "\n### 3. Install the required packages\n",
    "ContentSha": "97VTTWuamYvk4THPyO5Ex48XMRIdHtV0dBXABNHe3qQ=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "### 3. Gerekli paketleri yÃ¼kleyin\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 8,
    "Content": "```bash\npip install -r requirements.txt\n```",
    "ContentSha": "TxMa9uJC0PmBOnm3/TRl4YDLNvSwCWaRNjyXpFhndHU=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\npip install -r requirements.txt\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 9,
    "Content": "\n### 4. Install k2 for training or efficient inference\n\n**k2 is necessary for training** and can speed up inference. Nevertheless, you can still use the inference mode of ZipVoice without installing k2.\n\n> **Note:**  Make sure to install the k2 version that matches your PyTorch and CUDA version. For example, if you are using pytorch 2.5.1 and CUDA 12.1, you can install k2 as follows:\n",
    "ContentSha": "it0kOYkTtKi6ipV/r+Px+BHDpullJx7ZxRNyR9UNc40=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "### 4. EÄŸitim veya verimli Ã§Ä±karÄ±m iÃ§in k2'yi kurun\n\n**k2 eÄŸitim iÃ§in gereklidir** ve Ã§Ä±karÄ±mÄ± hÄ±zlandÄ±rabilir. Yine de, k2 yÃ¼klemeden ZipVoice'Ä±n Ã§Ä±karÄ±m modunu kullanabilirsiniz.\n\n> **Not:**  KullandÄ±ÄŸÄ±nÄ±z PyTorch ve CUDA sÃ¼rÃ¼mÃ¼ne uygun k2 sÃ¼rÃ¼mÃ¼nÃ¼ kurduÄŸunuzdan emin olun. Ã–rneÄŸin, eÄŸer pytorch 2.5.1 ve CUDA 12.1 kullanÄ±yorsanÄ±z, k2'yi ÅŸu ÅŸekilde kurabilirsiniz:\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 10,
    "Content": "```bash\npip install k2==1.24.4.dev20250208+cuda12.1.torch2.5.1 -f https://k2-fsa.github.io/k2/cuda.html\n```",
    "ContentSha": "ScZHk5YUmlVP9WL5ZgwHsvBVbwTCenfwKc3cJb6nrWo=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\npip install k2==1.24.4.dev20250208+cuda12.1.torch2.5.1 -f https://k2-fsa.github.io/k2/cuda.html\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 11,
    "Content": "\nPlease refer to https://k2-fsa.org/get-started/k2/ for details.\nUsers in China mainland can refer to https://k2-fsa.org/zh-CN/get-started/k2/.\n\n- To check the k2 installation:\n",
    "ContentSha": "rY1Zhq3aduWMw4XQSft+r2qBy7l8kqnHBs8cs4FGpZ4=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "LÃ¼tfen ayrÄ±ntÄ±lar iÃ§in https://k2-fsa.org/get-started/k2/ adresine bakÄ±nÄ±z.\nÃ‡in anakarasÄ±ndaki kullanÄ±cÄ±lar https://k2-fsa.org/zh-CN/get-started/k2/ adresine baÅŸvurabilirler.\n\n- k2 kurulumunu kontrol etmek iÃ§in:\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 12,
    "Content": "```bash\npython3 -c \"import k2; print(k2.__file__)\"\n```",
    "ContentSha": "PH4E7oc9yWRIVi2n1L4BiFuChpCHjHuJ65gAwNBxvHE=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\npython3 -c \"import k2; print(k2.__file__)\"\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 13,
    "Content": "\n## Usage\n\n### 1. Single-speaker speech generation\n\nTo generate single-speaker speech with our pre-trained ZipVoice or ZipVoice-Distill models, use the following commands (Required models will be downloaded from HuggingFace):\n\n#### 1.1 Inference of a single sentence\n",
    "ContentSha": "B4h5YyIywYfr2neMM1PwmS6nY8/eY48N4jkDeP3wG+Y=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "## KullanÄ±m\n\n### 1. Tek konuÅŸmacÄ±lÄ± konuÅŸma Ã¼retimi\n\nÃ–nceden eÄŸitilmiÅŸ ZipVoice veya ZipVoice-Distill modellerimizle tek konuÅŸmacÄ±lÄ± konuÅŸma Ã¼retmek iÃ§in aÅŸaÄŸÄ±daki komutlarÄ± kullanÄ±n (Gerekli modeller HuggingFace Ã¼zerinden indirilecektir):\n\n#### 1.1 Tek bir cÃ¼mlenin Ã§Ä±karÄ±mÄ±\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 14,
    "Content": "```bash\npython3 -m zipvoice.bin.infer_zipvoice \\\n    --model-name zipvoice \\\n    --prompt-wav prompt.wav \\\n    --prompt-text \"I am the transcription of the prompt wav.\" \\\n    --text \"I am the text to be synthesized.\" \\\n    --res-wav-path result.wav\n```",
    "ContentSha": "s3L0IUGcm9ppsQesBx8AKaxAjpRhRDaqb8rE/HLRinc=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\npython3 -m zipvoice.bin.infer_zipvoice \\\n    --model-name zipvoice \\\n    --prompt-wav prompt.wav \\\n    --prompt-text \"I am the transcription of the prompt wav.\" \\\n    --text \"I am the text to be synthesized.\" \\\n    --res-wav-path result.wav\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 15,
    "Content": "- `--model-name` can be `zipvoice` or `zipvoice_distill`, which are models before and after distillation, respectively.\n- If `<>` or `[]` appear in the text, strings enclosed by them will be treated as special tokens. `<>` denotes Chinese pinyin and `[]` denotes other special tags.\n\n#### 1.2 Inference of a list of sentences\n",
    "ContentSha": "9gu4tqRbp3LNcYk2S6twKEix9A9CPCJP4IQ8qVja+jw=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "- `--model-name` deÄŸeri `zipvoice` veya `zipvoice_distill` olabilir; bunlar sÄ±rasÄ±yla distilasyon Ã¶ncesi ve sonrasÄ± modellerdir.\n- EÄŸer metinde `<>` veya `[]` gÃ¶rÃ¼nÃ¼rse, bunlar arasÄ±ndaki dizeler Ã¶zel belirteÃ§ler olarak kabul edilir. `<>` Ã‡in pinyin'ini, `[]` ise diÄŸer Ã¶zel etiketleri ifade eder.\n\n#### 1.2 Bir cÃ¼mle listesinin Ã§Ä±karÄ±mÄ±\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 16,
    "Content": "```bash\npython3 -m zipvoice.bin.infer_zipvoice \\\n    --model-name zipvoice \\\n    --test-list test.tsv \\\n    --res-dir results\n```",
    "ContentSha": "wVKNQBx9Qf3wuIvCUTrQwDyZzDuqDpC7W9a1psJg5Ds=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\npython3 -m zipvoice.bin.infer_zipvoice \\\n    --model-name zipvoice \\\n    --test-list test.tsv \\\n    --res-dir results\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 17,
    "Content": "\n- Each line of `test.tsv` is in the format of `{wav_name}\\t{prompt_transcription}\\t{prompt_wav}\\t{text}`.\n\n### 2. Dialogue speech generation\n\n#### 2.1 Inference command\n\nTo generate two-party spoken dialogues with our pre-trained ZipVoice-Dialogue or ZipVoice-Dialogue-Stereo models, use the following commands (Required models will be downloaded from HuggingFace):\n",
    "ContentSha": "bkRixLiKF8JLzfAqriyk1UZSkb5qCPhJVvI3VACgZos=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "- `test.tsv` dosyasÄ±nÄ±n her satÄ±rÄ± `{wav_name}\\t{prompt_transcription}\\t{prompt_wav}\\t{text}` formatÄ±ndadÄ±r.\n\n### 2. Diyalog konuÅŸma Ã¼retimi\n\n#### 2.1 Ã‡Ä±karÄ±m komutu\n\nÃ–nceden eÄŸitilmiÅŸ ZipVoice-Dialogue veya ZipVoice-Dialogue-Stereo modellerimizle iki taraflÄ± konuÅŸmalÄ± diyaloglar Ã¼retmek iÃ§in aÅŸaÄŸÄ±daki komutlarÄ± kullanÄ±n (Gerekli modeller HuggingFace Ã¼zerinden indirilecektir):\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 18,
    "Content": "```bash\npython3 -m zipvoice.bin.infer_zipvoice_dialog \\\n    --model-name \"zipvoice_dialog\" \\\n    --test-list test.tsv \\\n    --res-dir results\n```",
    "ContentSha": "SmNrjO7IvCsVTs0ROGG3evCMgCtj54DYGkGCZbRdz8k=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\npython3 -m zipvoice.bin.infer_zipvoice_dialog \\\n    --model-name \"zipvoice_dialog\" \\\n    --test-list test.tsv \\\n    --res-dir results\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 19,
    "Content": "\n- `--model-name` can be `zipvoice_dialog` or `zipvoice_dialog_stereo`,\n    which generate mono and stereo dialogues, respectively.\n\n#### 2.2 Input formats\n\nEach line of `test.tsv` is in one of the following formats:\n\n(1) **Merged prompt format** where the audios and transcriptions of two speakers prompts are merged into one prompt wav file:",
    "ContentSha": "e336Qt1qFvFmNefniyPEWJue5A1mLBZUSlD6p1+H8To=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "- `--model-name` `zipvoice_dialog` veya `zipvoice_dialog_stereo` olabilir,\n    sÄ±rasÄ±yla mono ve stereo diyaloglar Ã¼retir.\n\n#### 2.2 Girdi formatlarÄ±\n\n`test.tsv` dosyasÄ±ndaki her satÄ±r aÅŸaÄŸÄ±daki formatlardan birindedir:\n\n(1) **BirleÅŸtirilmiÅŸ istem formatÄ±**: Ä°ki konuÅŸmacÄ±nÄ±n sesleri ve transkriptleri tek bir istem wav dosyasÄ±nda birleÅŸtirilir:\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 20,
    "Content": "```\n{wav_name}\\t{prompt_transcription}\\t{prompt_wav}\\t{text}\n```",
    "ContentSha": "F8c2S4lpByZ5Nhd693ESYvOeDT7lT7vF2Txm3q64ync=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```\n{wav_name}\\t{prompt_transcription}\\t{prompt_wav}\\t{text}\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 21,
    "Content": "\n- `wav_name` is the name of the output wav file.\n- `prompt_transcription` is the transcription of the conversational prompt wav, e.g, \"[S1] Hello. [S2] How are you?\"\n- `prompt_wav` is the path to the prompt wav.\n- `text` is the text to be synthesized, e.g. \"[S1] I'm fine. [S2] What's your name? [S1] I'm Eric. [S2] Hi Eric.\"\n\n(2) **Splitted prompt format** where the audios and transciptions of two speakers exist in separate files:\n",
    "ContentSha": "Gj5W4GhLunSOhvyVf7uwdfnNL3DFgIeOvHB01tH9I/A=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "\n- `wav_name`, Ã§Ä±ktÄ± wav dosyasÄ±nÄ±n adÄ±dÄ±r.\n- `prompt_transcription`, konuÅŸma istemi wav dosyasÄ±nÄ±n transkripsiyonudur, Ã¶rneÄŸin, \"[S1] Merhaba. [S2] NasÄ±lsÄ±n?\"\n- `prompt_wav`, istem wav dosyasÄ±nÄ±n yoludur.\n- `text`, sentezlenecek metindir, Ã¶rneÄŸin, \"[S1] Ä°yiyim. [S2] AdÄ±n ne? [S1] Ben Eric. [S2] Merhaba Eric.\"\n\n(2) **BÃ¶lÃ¼nmÃ¼ÅŸ istem formatÄ±**: iki konuÅŸmacÄ±nÄ±n sesleri ve transkripsiyonlarÄ± ayrÄ± dosyalarda bulunur:\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 22,
    "Content": "```\n{wav_name}\\t{spk1_prompt_transcription}\\t{spk2_prompt_transcription}\\t{spk1_prompt_wav}\\t{spk2_prompt_wav}\\t{text}\n```",
    "ContentSha": "zPaMLy5mnnAP5WeOve+uEMlDenRN6Anuru4V4waQX9w=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```\n{wav_name}\\t{spk1_prompt_transcription}\\t{spk2_prompt_transcription}\\t{spk1_prompt_wav}\\t{spk2_prompt_wav}\\t{text}\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 23,
    "Content": "\n- `wav_name` is the name of the output wav file.\n- `spk1_prompt_transcription` is the transcription of the first speaker's prompt wav, e.g, \"Hello\"\n- `spk2_prompt_transcription` is the transcription of the second speaker's prompt wav, e.g, \"How are you?\"\n- `spk1_prompt_wav` is the path to the first speaker's prompt wav file.\n- `spk2_prompt_wav` is the path to the second speaker's prompt wav file.\n- `text` is the text to be synthesized, e.g. \"[S1] I'm fine. [S2] What's your name? [S1] I'm Eric. [S2] Hi Eric.\"\n\n### 3 Guidance for better usage:\n\n#### 3.1 Prompt length\n\nWe recommand a short prompt wav file (e.g., less than 3 seconds for single-speaker speech generation, less than 10 seconds for dialogue speech generation) for faster inference speed. A very long prompt will slow down the inference and degenerate the speech quality.\n\n#### 3.2 Speed optimization\n\nIf the inference speed is unsatisfactory, you can speed it up as follows:\n\n- **Distill model and less steps**: For the single-speaker speech generation model, we use the `zipvoice` model by default for better speech quality. If faster speed is a priority, you can switch to the `zipvoice_distill` and can reduce the `--num-steps` to as low as `4` (8 by default).\n\n- **CPU speedup with multi-threading**: When running on CPU, you can pass the `--num-thread` parameter (e.g., `--num-thread 4`) to increase the number of threads for faster speed. We use 1 thread by default.\n\n- **CPU speedup with ONNX**: When running on CPU, you can use ONNX models with `zipvoice.bin.infer_zipvoice_onnx` for faster speed (haven't supported ONNX for dialogue generation models yet). For even faster speed, you can further set `--onnx-int8 True` to use an INT8-quantized ONNX model. Note that the quantized model will result in a certain degree of speech quality degradation. **Don't use ONNX on GPU**, as it is slower than PyTorch on GPU.\n\n- **GPU Acceleration with NVIDIA TensorRT**: For a significant performance boost on NVIDIA GPUs, first export the model to a TensorRT engine using zipvoice.bin.tensorrt_export. Then, run inference on your dataset (e.g., a Hugging Face dataset) with zipvoice.bin.infer_zipvoice. This can achieve approximately 2x the throughput compared to the standard PyTorch implementation on a GPU.\n\n#### 3.3 Memory control\n\nThe given text will be splitted into chunks based on punctuation (for single-speaker speech generation) or speaker-turn symbol (for dialogue speech generation). Then, the chunked texts will be processed in batches. Therefore, the model can process arbitrarily long text with almost constant memory usage. You can control memory usage by adjusting the `--max-duration` parameter.\n\n#### 3.4 \"Raw\" evaluation\n\nBy default, we preprocess inputs (prompt wav, prompt transcription, and text) for efficient inference and better performance. If you want to evaluate the modelâ€™s \"raw\" performance using exact provided inputs (e.g., to reproduce the results in our paper), you can pass `--raw-evaluation True`.\n\n#### 3.5 Short text\n\nWhen generating speech for very short texts (e.g., one or two words), the generated speech may sometimes omit certain pronunciations. To resolve this issue, you can pass `--speed 0.3` (where 0.3 is a tunable value) to extend the duration of the generated speech.\n\n#### 3.6 Correcting mispronounced chinese polyphone characters\n",
    "ContentSha": "6AwuUDJOteKl74OkYkXg6kAf+AJPVnWbItdRfk762Xs=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "- `wav_name`, Ã§Ä±ktÄ± wav dosyasÄ±nÄ±n adÄ±dÄ±r.\n- `spk1_prompt_transcription`, birinci konuÅŸmacÄ±nÄ±n istem wav dosyasÄ±nÄ±n transkripsiyonudur, Ã¶rn. \"Merhaba\"\n- `spk2_prompt_transcription`, ikinci konuÅŸmacÄ±nÄ±n istem wav dosyasÄ±nÄ±n transkripsiyonudur, Ã¶rn. \"NasÄ±lsÄ±n?\"\n- `spk1_prompt_wav`, birinci konuÅŸmacÄ±nÄ±n istem wav dosyasÄ±nÄ±n yoludur.\n- `spk2_prompt_wav`, ikinci konuÅŸmacÄ±nÄ±n istem wav dosyasÄ±nÄ±n yoludur.\n- `text`, sentezlenecek metindir, Ã¶rn. \"[S1] Ä°yiyim. [S2] AdÄ±n ne? [S1] Ben Eric. [S2] Merhaba Eric.\"\n\n### 3 Daha iyi kullanÄ±m iÃ§in rehberlik:\n\n#### 3.1 Ä°stem uzunluÄŸu\n\nDaha hÄ±zlÄ± Ã§Ä±karÄ±m hÄ±zÄ± iÃ§in kÄ±sa bir istem wav dosyasÄ± Ã¶neriyoruz (Ã¶rn., tek konuÅŸmacÄ±lÄ± konuÅŸma Ã¼retimi iÃ§in 3 saniyeden az, diyalog konuÅŸma Ã¼retimi iÃ§in 10 saniyeden az). Ã‡ok uzun bir istem, Ã§Ä±karÄ±mÄ± yavaÅŸlatÄ±r ve konuÅŸma kalitesini dÃ¼ÅŸÃ¼rÃ¼r.\n\n#### 3.2 HÄ±z optimizasyonu\n\nÃ‡Ä±karÄ±m hÄ±zÄ± tatmin edici deÄŸilse, aÅŸaÄŸÄ±daki ÅŸekilde hÄ±zlandÄ±rabilirsiniz:\n\n- **Distil model ve daha az adÄ±m**: Tek konuÅŸmacÄ±lÄ± konuÅŸma Ã¼retim modeli iÃ§in, daha iyi konuÅŸma kalitesi iÃ§in varsayÄ±lan olarak `zipvoice` modelini kullanÄ±yoruz. EÄŸer hÄ±z Ã¶nceliÄŸinizse, `zipvoice_distill` modeline geÃ§ebilir ve `--num-steps` deÄŸerini varsayÄ±lan 8â€™den 4â€™e kadar dÃ¼ÅŸÃ¼rebilirsiniz.\n\n- **CPUâ€™da Ã§oklu iÅŸ parÃ§acÄ±ÄŸÄ± ile hÄ±zlandÄ±rma**: CPUâ€™da Ã§alÄ±ÅŸtÄ±rÄ±rken, daha hÄ±zlÄ± bir hÄ±z iÃ§in `--num-thread` parametresiyle (Ã¶rn., `--num-thread 4`) iÅŸ parÃ§acÄ±ÄŸÄ± sayÄ±sÄ±nÄ± artÄ±rabilirsiniz. VarsayÄ±lan olarak 1 iÅŸ parÃ§acÄ±ÄŸÄ± kullanÄ±yoruz.\n\n- **CPUâ€™da ONNX ile hÄ±zlandÄ±rma**: CPUâ€™da Ã§alÄ±ÅŸÄ±rken, daha hÄ±zlÄ± bir hÄ±z iÃ§in ONNX modellerini `zipvoice.bin.infer_zipvoice_onnx` ile kullanabilirsiniz (henÃ¼z diyalog Ã¼retim modelleri iÃ§in ONNX desteklenmiyor). Daha da hÄ±zlÄ± bir hÄ±z iÃ§in `--onnx-int8 True` ayarlayarak INT8-kuantize ONNX modeli kullanabilirsiniz. Kuantize modelin konuÅŸma kalitesinde belli bir dÃ¼ÅŸÃ¼ÅŸe neden olacaÄŸÄ±nÄ± unutmayÄ±n. **ONNXâ€™i GPUâ€™da kullanmayÄ±n**, Ã§Ã¼nkÃ¼ GPUâ€™da PyTorchâ€™tan daha yavaÅŸtÄ±r.\n\n- **NVIDIA TensorRT ile GPU HÄ±zlandÄ±rma**: NVIDIA GPUâ€™larda Ã¶nemli bir performans artÄ±ÅŸÄ± iÃ§in, Ã¶nce modeli zipvoice.bin.tensorrt_export kullanarak bir TensorRT motoruna aktarÄ±n. ArdÄ±ndan, veri kÃ¼meniz Ã¼zerinde (Ã¶rn., bir Hugging Face veri kÃ¼mesi) zipvoice.bin.infer_zipvoice ile Ã§Ä±karÄ±m Ã§alÄ±ÅŸtÄ±rÄ±n. Bu, GPUâ€™da standart PyTorch uygulamasÄ±na gÃ¶re yaklaÅŸÄ±k 2 kat daha fazla verim saÄŸlayabilir.\n\n#### 3.3 Bellek kontrolÃ¼\n\nVerilen metin, noktalama iÅŸaretlerine (tek konuÅŸmacÄ±lÄ± konuÅŸma Ã¼retimi iÃ§in) veya konuÅŸmacÄ± deÄŸiÅŸim sembolÃ¼ne (diyalog konuÅŸma Ã¼retimi iÃ§in) gÃ¶re parÃ§alara ayrÄ±lacaktÄ±r. Sonra, parÃ§alara ayrÄ±lan metinler toplu halde iÅŸlenecektir. Bu nedenle, model neredeyse sabit bellek kullanÄ±mÄ±yla rastgele uzunluktaki metni iÅŸleyebilir. Bellek kullanÄ±mÄ±nÄ± `--max-duration` parametresiyle ayarlayabilirsiniz.\n\n#### 3.4 \"Ham\" deÄŸerlendirme\n\nVarsayÄ±lan olarak, verimli Ã§Ä±karÄ±m ve daha iyi performans iÃ§in girdileri (istem wav, istem transkripsiyonu ve metin) Ã¶n iÅŸleme tabi tutuyoruz. Modelin tam olarak verilen girdilerle (\"ham\" performansÄ±nÄ±) deÄŸerlendirmek isterseniz (Ã¶rn., makalemizdeki sonuÃ§larÄ± Ã§oÄŸaltmak iÃ§in), `--raw-evaluation True` parametresini geÃ§ebilirsiniz.\n\n#### 3.5 KÄ±sa metin\n\nÃ‡ok kÄ±sa metinler iÃ§in konuÅŸma Ã¼retirken (Ã¶rn., bir ya da iki kelime), Ã¼retilen konuÅŸma bazen bazÄ± telaffuzlarÄ± atlayabilir. Bu sorunu Ã§Ã¶zmek iÃ§in, `--speed 0.3` (0.3 ayarlanabilir bir deÄŸerdir) parametresiyle Ã¼retilen konuÅŸmanÄ±n sÃ¼resini uzatabilirsiniz.\n\n#### 3.6 YanlÄ±ÅŸ telaffuz edilen Ã‡ince polifon karakterlerin dÃ¼zeltilmesi\n\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "- `wav_name`, Ã§Ä±ktÄ± wav dosyasÄ±nÄ±n adÄ±dÄ±r."
      },
      {
        "row": 2,
        "rowsha": "6vgIR6WfUAFmULhn8LhxFttPwZEo/YwGhN1DAECwHCQ=",
        "originContent": "- `wav_name` is the name of the output wav file.",
        "translatedContent": "- `spk1_prompt_transcription`, birinci konuÅŸmacÄ±nÄ±n istem wav dosyasÄ±nÄ±n transkripsiyonudur, Ã¶rn. \"Merhaba\""
      },
      {
        "row": 3,
        "rowsha": "7BNq8UaBvTut4Ow/oJBAgIDTn3EwEZXK7mlUaYdFwqw=",
        "originContent": "- `spk1_prompt_transcription` is the transcription of the first speaker's prompt wav, e.g, \"Hello\"",
        "translatedContent": "- `spk2_prompt_transcription`, ikinci konuÅŸmacÄ±nÄ±n istem wav dosyasÄ±nÄ±n transkripsiyonudur, Ã¶rn. \"NasÄ±lsÄ±n?\""
      },
      {
        "row": 4,
        "rowsha": "CES8w9dqVdkdJyOJBUVP282aaKeevVWB3d/+59TEsuk=",
        "originContent": "- `spk2_prompt_transcription` is the transcription of the second speaker's prompt wav, e.g, \"How are you?\"",
        "translatedContent": "- `spk1_prompt_wav`, birinci konuÅŸmacÄ±nÄ±n istem wav dosyasÄ±nÄ±n yoludur."
      },
      {
        "row": 5,
        "rowsha": "gXLLRf4BR7Xko2q2l4nK04KIs/L8CjvZ/UBQaP1+vck=",
        "originContent": "- `spk1_prompt_wav` is the path to the first speaker's prompt wav file.",
        "translatedContent": "- `spk2_prompt_wav`, ikinci konuÅŸmacÄ±nÄ±n istem wav dosyasÄ±nÄ±n yoludur."
      },
      {
        "row": 6,
        "rowsha": "oS1+heJwBnnDtA57WYtG6LbzxK79DOIeb8hwhZQwcDg=",
        "originContent": "- `spk2_prompt_wav` is the path to the second speaker's prompt wav file.",
        "translatedContent": "- `text`, sentezlenecek metindir, Ã¶rn. \"[S1] Ä°yiyim. [S2] AdÄ±n ne? [S1] Ben Eric. [S2] Merhaba Eric.\""
      },
      {
        "row": 7,
        "rowsha": "M4Z2DDajNBdyF/JosIaDZ44oyZnjNA7lzfGzEpuoako=",
        "originContent": "- `text` is the text to be synthesized, e.g. \"[S1] I'm fine. [S2] What's your name? [S1] I'm Eric. [S2] Hi Eric.\"",
        "translatedContent": ""
      },
      {
        "row": 8,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "### 3 Daha iyi kullanÄ±m iÃ§in rehberlik:"
      },
      {
        "row": 9,
        "rowsha": "SdDI3h73wOzKSM3kbrbNrmpigHGer7kumuaZsQgAeao=",
        "originContent": "### 3 Guidance for better usage:",
        "translatedContent": ""
      },
      {
        "row": 10,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "#### 3.1 Ä°stem uzunluÄŸu"
      },
      {
        "row": 11,
        "rowsha": "cVxukE6jyFFOxlNKI5ecOTo/suYYJ8hnYyW2XA2wg+o=",
        "originContent": "#### 3.1 Prompt length",
        "translatedContent": ""
      },
      {
        "row": 12,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "Daha hÄ±zlÄ± Ã§Ä±karÄ±m hÄ±zÄ± iÃ§in kÄ±sa bir istem wav dosyasÄ± Ã¶neriyoruz (Ã¶rn., tek konuÅŸmacÄ±lÄ± konuÅŸma Ã¼retimi iÃ§in 3 saniyeden az, diyalog konuÅŸma Ã¼retimi iÃ§in 10 saniyeden az). Ã‡ok uzun bir istem, Ã§Ä±karÄ±mÄ± yavaÅŸlatÄ±r ve konuÅŸma kalitesini dÃ¼ÅŸÃ¼rÃ¼r."
      },
      {
        "row": 13,
        "rowsha": "f19zq78QrLul7wiVSlCSojGS7qNEvtef9GFg6AA8eMY=",
        "originContent": "We recommand a short prompt wav file (e.g., less than 3 seconds for single-speaker speech generation, less than 10 seconds for dialogue speech generation) for faster inference speed. A very long prompt will slow down the inference and degenerate the speech quality.",
        "translatedContent": ""
      },
      {
        "row": 14,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "#### 3.2 HÄ±z optimizasyonu"
      },
      {
        "row": 15,
        "rowsha": "lpgNpm20ulCcTiEU/xfEVVgMZhjiQjymkdljF8dD/vw=",
        "originContent": "#### 3.2 Speed optimization",
        "translatedContent": ""
      },
      {
        "row": 16,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "Ã‡Ä±karÄ±m hÄ±zÄ± tatmin edici deÄŸilse, aÅŸaÄŸÄ±daki ÅŸekilde hÄ±zlandÄ±rabilirsiniz:"
      },
      {
        "row": 17,
        "rowsha": "iBJxMfYOjV9HvSuRT3p/EsU/iATeDCDAk/wGWLXqQI8=",
        "originContent": "If the inference speed is unsatisfactory, you can speed it up as follows:",
        "translatedContent": ""
      },
      {
        "row": 18,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "- **Distil model ve daha az adÄ±m**: Tek konuÅŸmacÄ±lÄ± konuÅŸma Ã¼retim modeli iÃ§in, daha iyi konuÅŸma kalitesi iÃ§in varsayÄ±lan olarak `zipvoice` modelini kullanÄ±yoruz. EÄŸer hÄ±z Ã¶nceliÄŸinizse, `zipvoice_distill` modeline geÃ§ebilir ve `--num-steps` deÄŸerini varsayÄ±lan 8â€™den 4â€™e kadar dÃ¼ÅŸÃ¼rebilirsiniz."
      },
      {
        "row": 19,
        "rowsha": "IzTHxzS1e5yJRhHF5d8CsjfqjIzhNX1AeGR4FTjuUCA=",
        "originContent": "- **Distill model and less steps**: For the single-speaker speech generation model, we use the `zipvoice` model by default for better speech quality. If faster speed is a priority, you can switch to the `zipvoice_distill` and can reduce the `--num-steps` to as low as `4` (8 by default).",
        "translatedContent": ""
      },
      {
        "row": 20,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "- **CPUâ€™da Ã§oklu iÅŸ parÃ§acÄ±ÄŸÄ± ile hÄ±zlandÄ±rma**: CPUâ€™da Ã§alÄ±ÅŸtÄ±rÄ±rken, daha hÄ±zlÄ± bir hÄ±z iÃ§in `--num-thread` parametresiyle (Ã¶rn., `--num-thread 4`) iÅŸ parÃ§acÄ±ÄŸÄ± sayÄ±sÄ±nÄ± artÄ±rabilirsiniz. VarsayÄ±lan olarak 1 iÅŸ parÃ§acÄ±ÄŸÄ± kullanÄ±yoruz."
      },
      {
        "row": 21,
        "rowsha": "mNiqyHjFr4rbx4boH0cix2peH8Q0+tDTOlzgZeLLDqM=",
        "originContent": "- **CPU speedup with multi-threading**: When running on CPU, you can pass the `--num-thread` parameter (e.g., `--num-thread 4`) to increase the number of threads for faster speed. We use 1 thread by default.",
        "translatedContent": ""
      },
      {
        "row": 22,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "- **CPUâ€™da ONNX ile hÄ±zlandÄ±rma**: CPUâ€™da Ã§alÄ±ÅŸÄ±rken, daha hÄ±zlÄ± bir hÄ±z iÃ§in ONNX modellerini `zipvoice.bin.infer_zipvoice_onnx` ile kullanabilirsiniz (henÃ¼z diyalog Ã¼retim modelleri iÃ§in ONNX desteklenmiyor). Daha da hÄ±zlÄ± bir hÄ±z iÃ§in `--onnx-int8 True` ayarlayarak INT8-kuantize ONNX modeli kullanabilirsiniz. Kuantize modelin konuÅŸma kalitesinde belli bir dÃ¼ÅŸÃ¼ÅŸe neden olacaÄŸÄ±nÄ± unutmayÄ±n. **ONNXâ€™i GPUâ€™da kullanmayÄ±n**, Ã§Ã¼nkÃ¼ GPUâ€™da PyTorchâ€™tan daha yavaÅŸtÄ±r."
      },
      {
        "row": 23,
        "rowsha": "YqtmXdPz7OfUIbrIkeeIwyKEPdEZUqn3m5EyTNd967s=",
        "originContent": "- **CPU speedup with ONNX**: When running on CPU, you can use ONNX models with `zipvoice.bin.infer_zipvoice_onnx` for faster speed (haven't supported ONNX for dialogue generation models yet). For even faster speed, you can further set `--onnx-int8 True` to use an INT8-quantized ONNX model. Note that the quantized model will result in a certain degree of speech quality degradation. **Don't use ONNX on GPU**, as it is slower than PyTorch on GPU.",
        "translatedContent": ""
      },
      {
        "row": 24,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "- **NVIDIA TensorRT ile GPU HÄ±zlandÄ±rma**: NVIDIA GPUâ€™larda Ã¶nemli bir performans artÄ±ÅŸÄ± iÃ§in, Ã¶nce modeli zipvoice.bin.tensorrt_export kullanarak bir TensorRT motoruna aktarÄ±n. ArdÄ±ndan, veri kÃ¼meniz Ã¼zerinde (Ã¶rn., bir Hugging Face veri kÃ¼mesi) zipvoice.bin.infer_zipvoice ile Ã§Ä±karÄ±m Ã§alÄ±ÅŸtÄ±rÄ±n. Bu, GPUâ€™da standart PyTorch uygulamasÄ±na gÃ¶re yaklaÅŸÄ±k 2 kat daha fazla verim saÄŸlayabilir."
      },
      {
        "row": 25,
        "rowsha": "kj1A4DWWe02Utusq07KI3xRRH55QdxQWRCzFeimIzww=",
        "originContent": "- **GPU Acceleration with NVIDIA TensorRT**: For a significant performance boost on NVIDIA GPUs, first export the model to a TensorRT engine using zipvoice.bin.tensorrt_export. Then, run inference on your dataset (e.g., a Hugging Face dataset) with zipvoice.bin.infer_zipvoice. This can achieve approximately 2x the throughput compared to the standard PyTorch implementation on a GPU.",
        "translatedContent": ""
      },
      {
        "row": 26,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "#### 3.3 Bellek kontrolÃ¼"
      },
      {
        "row": 27,
        "rowsha": "fze8iMUXPcPsZgNFyWFzWSuCffZnzh7SpzLs21tQLtE=",
        "originContent": "#### 3.3 Memory control",
        "translatedContent": ""
      },
      {
        "row": 28,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "Verilen metin, noktalama iÅŸaretlerine (tek konuÅŸmacÄ±lÄ± konuÅŸma Ã¼retimi iÃ§in) veya konuÅŸmacÄ± deÄŸiÅŸim sembolÃ¼ne (diyalog konuÅŸma Ã¼retimi iÃ§in) gÃ¶re parÃ§alara ayrÄ±lacaktÄ±r. Sonra, parÃ§alara ayrÄ±lan metinler toplu halde iÅŸlenecektir. Bu nedenle, model neredeyse sabit bellek kullanÄ±mÄ±yla rastgele uzunluktaki metni iÅŸleyebilir. Bellek kullanÄ±mÄ±nÄ± `--max-duration` parametresiyle ayarlayabilirsiniz."
      },
      {
        "row": 29,
        "rowsha": "uM67TExtHYq7ALHmglqtjLRqv0Xu0OOSx2aFJquZPmw=",
        "originContent": "The given text will be splitted into chunks based on punctuation (for single-speaker speech generation) or speaker-turn symbol (for dialogue speech generation). Then, the chunked texts will be processed in batches. Therefore, the model can process arbitrarily long text with almost constant memory usage. You can control memory usage by adjusting the `--max-duration` parameter.",
        "translatedContent": ""
      },
      {
        "row": 30,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "#### 3.4 \"Ham\" deÄŸerlendirme"
      },
      {
        "row": 31,
        "rowsha": "foa86E9JcH+Sc/k2OCmyfIKHwggsFBXhSUfHDcmJQA0=",
        "originContent": "#### 3.4 \"Raw\" evaluation",
        "translatedContent": ""
      },
      {
        "row": 32,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "VarsayÄ±lan olarak, verimli Ã§Ä±karÄ±m ve daha iyi performans iÃ§in girdileri (istem wav, istem transkripsiyonu ve metin) Ã¶n iÅŸleme tabi tutuyoruz. Modelin tam olarak verilen girdilerle (\"ham\" performansÄ±nÄ±) deÄŸerlendirmek isterseniz (Ã¶rn., makalemizdeki sonuÃ§larÄ± Ã§oÄŸaltmak iÃ§in), `--raw-evaluation True` parametresini geÃ§ebilirsiniz."
      },
      {
        "row": 33,
        "rowsha": "+2nxKNvXmuxUQpf2Z+hw0Rxydt00FpmK4y4rlK5/8og=",
        "originContent": "By default, we preprocess inputs (prompt wav, prompt transcription, and text) for efficient inference and better performance. If you want to evaluate the modelâ€™s \"raw\" performance using exact provided inputs (e.g., to reproduce the results in our paper), you can pass `--raw-evaluation True`.",
        "translatedContent": ""
      },
      {
        "row": 34,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "#### 3.5 KÄ±sa metin"
      },
      {
        "row": 35,
        "rowsha": "g658opDssPKmJCvr7Jw9N130Xud1IbMHTwMK+S89WO0=",
        "originContent": "#### 3.5 Short text",
        "translatedContent": ""
      },
      {
        "row": 36,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "Ã‡ok kÄ±sa metinler iÃ§in konuÅŸma Ã¼retirken (Ã¶rn., bir ya da iki kelime), Ã¼retilen konuÅŸma bazen bazÄ± telaffuzlarÄ± atlayabilir. Bu sorunu Ã§Ã¶zmek iÃ§in, `--speed 0.3` (0.3 ayarlanabilir bir deÄŸerdir) parametresiyle Ã¼retilen konuÅŸmanÄ±n sÃ¼resini uzatabilirsiniz."
      },
      {
        "row": 37,
        "rowsha": "/IVkHehTtKgVQNwGOgQO/BoRh95RFHVJPH3e0W6Gixs=",
        "originContent": "When generating speech for very short texts (e.g., one or two words), the generated speech may sometimes omit certain pronunciations. To resolve this issue, you can pass `--speed 0.3` (where 0.3 is a tunable value) to extend the duration of the generated speech.",
        "translatedContent": ""
      },
      {
        "row": 38,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "#### 3.6 YanlÄ±ÅŸ telaffuz edilen Ã‡ince polifon karakterlerin dÃ¼zeltilmesi"
      },
      {
        "row": 39,
        "rowsha": "PAPz1JYDhpLF6dsiNH/BVipH4SufvLcqzLiPLACOcK4=",
        "originContent": "#### 3.6 Correcting mispronounced chinese polyphone characters",
        "translatedContent": ""
      },
      {
        "row": 40,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 24,
    "Content": "We use [pypinyin](https://github.com/mozillazg/python-pinyin) to convert Chinese characters to pinyin. However, it can occasionally mispronounce **polyphone characters** (å¤šéŸ³å­—).\n\nTo manually correct these mispronunciations, enclose the **corrected pinyin** in angle brackets `< >` and include the **tone mark**.\n\n**Example:**\n\n- Original text: `è¿™æŠŠå‰‘é•¿ä¸‰åå…¬åˆ†`\n- Correct the pinyin of `é•¿`:  `è¿™æŠŠå‰‘<chang2>ä¸‰åå…¬åˆ†`\n\n> **Note:** If you want to manually assign multiple pinyins, enclose each pinyin with `<>`, e.g., `è¿™æŠŠ<jian4><chang2><san1>åå…¬åˆ†`\n\n#### 3.7 Remove long silences from the generated speech\n\nModel will automatically determine the positions and lengths of silences in the generated speech. It occasionally has long silence in the middle of the speech. If you don't want this, you can pass `--remove-long-sil` to remove long silences in the middle of the generated speech (edge silences will be removed by default).\n\n#### 3.8 Model downloading\n\nIf you have trouble connecting to HuggingFace when downloading the pre-trained models, try switching endpoint to the mirror site: `export HF_ENDPOINT=https://hf-mirror.com`.\n\n## Train Your Own Model\n\nSee the [egs](egs) directory for training, fine-tuning and evaluation examples.\n\n## Production Deployment\n\n### NVIDIA Triton GPU Runtime\n\nFor production-ready deployment with high performance and scalability, check out the [Triton Inference Server integration](runtime/nvidia_triton/) that provides optimized TensorRT engines, concurrent request handling, and both gRPC/HTTP APIs for enterprise use.\n\n### CPU Deployment\n\nCheck [sherpa-onnx](https://github.com/k2-fsa/sherpa-onnx/pull/2487#issuecomment-3227884498) for the C++ deployment solution on CPU.\n\n## Discussion & Communication\n\nYou can directly discuss on [Github Issues](https://github.com/k2-fsa/ZipVoice/issues).\n\nYou can also scan the QR code to join our wechat group or follow our wechat official account.\n\n| Wechat Group | Wechat Official Account |",
    "ContentSha": "nAAjO+GVPZsjYiLFM/o02EX48i9vuDX4qL4j6+7om6U=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "Ã‡ince karakterleri pinyinâ€™e dÃ¶nÃ¼ÅŸtÃ¼rmek iÃ§in [pypinyin](https://github.com/mozillazg/python-pinyin) kullanÄ±yoruz. Ancak bazen **Ã§ok sesli karakterleri** (å¤šéŸ³å­—) yanlÄ±ÅŸ telaffuz edebilir.\n\nBu yanlÄ±ÅŸ telaffuzlarÄ± elle dÃ¼zeltmek iÃ§in, **dÃ¼zeltilmiÅŸ pinyinâ€™i** kÃ¶ÅŸeli parantezler `< >` iÃ§ine alÄ±n ve **ton iÅŸaretini** ekleyin.\n\n**Ã–rnek:**\n\n- Orijinal metin: `è¿™æŠŠå‰‘é•¿ä¸‰åå…¬åˆ†`\n- `é•¿` karakterinin pinyinâ€™ini dÃ¼zeltin:  `è¿™æŠŠå‰‘<chang2>ä¸‰åå…¬åˆ†`\n\n> **Not:** Birden fazla pinyinâ€™i elle atamak isterseniz, her pinyinâ€™i `<>` ile Ã§evreleyin, Ã¶rn: `è¿™æŠŠ<jian4><chang2><san1>åå…¬åˆ†`\n\n#### 3.7 OluÅŸturulan konuÅŸmadan uzun sessizlikleri kaldÄ±rma\n\nModel, oluÅŸturulan konuÅŸmadaki sessizliklerin yerini ve uzunluÄŸunu otomatik olarak belirler. Bazen konuÅŸmanÄ±n ortasÄ±nda uzun bir sessizlik olabilir. Bunu istemiyorsanÄ±z, oluÅŸturulan konuÅŸmanÄ±n ortasÄ±ndaki uzun sessizlikleri kaldÄ±rmak iÃ§in `--remove-long-sil` komutunu kullanabilirsiniz (kenar sessizlikleri varsayÄ±lan olarak kaldÄ±rÄ±lÄ±r).\n\n#### 3.8 Model indirme\n\nÃ–nceden eÄŸitilmiÅŸ modelleri indirirken HuggingFaceâ€™e baÄŸlanmada sorun yaÅŸarsanÄ±z, uÃ§ noktayÄ± yansÄ± (mirror) siteye geÃ§irmeyi deneyin: `export HF_ENDPOINT=https://hf-mirror.com`.\n\n## Kendi Modelinizi EÄŸitin\n\nEÄŸitim, ince ayar ve deÄŸerlendirme Ã¶rnekleri iÃ§in [egs](egs) dizinine bakÄ±n.\n\n## Ãœretim OrtamÄ±nda KullanÄ±m\n\n### NVIDIA Triton GPU Ã‡alÄ±ÅŸma ZamanÄ±\n\nYÃ¼ksek performans ve Ã¶lÃ§eklenebilir Ã¼retim daÄŸÄ±tÄ±mÄ± iÃ§in, optimize edilmiÅŸ TensorRT motorlarÄ±, eÅŸzamanlÄ± istek iÅŸleme ve kurumsal kullanÄ±m iÃ§in gRPC/HTTP APIâ€™leri saÄŸlayan [Triton Inference Server entegrasyonuna](runtime/nvidia_triton/) gÃ¶z atÄ±n.\n\n### CPU DaÄŸÄ±tÄ±mÄ±\n\nCPU Ã¼zerinde C++ ile daÄŸÄ±tÄ±m Ã§Ã¶zÃ¼mÃ¼ iÃ§in [sherpa-onnx](https://github.com/k2-fsa/sherpa-onnx/pull/2487#issuecomment-3227884498) inceleyin.\n\n## TartÄ±ÅŸma ve Ä°letiÅŸim\n\nDoÄŸrudan [Github Issues](https://github.com/k2-fsa/ZipVoice/issues) Ã¼zerinden tartÄ±ÅŸabilirsiniz.\n\nAyrÄ±ca QR kodunu tarayarak WeChat grubumuza katÄ±labilir veya WeChat resmi hesabÄ±mÄ±zÄ± takip edebilirsiniz.\n\n| Wechat Grubu | Wechat Resmi HesabÄ± |",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "hF52KZEnGKLuaot2w0AmXt52eB6Y3adYIo2qMJSMx5o=",
        "originContent": "We use [pypinyin](https://github.com/mozillazg/python-pinyin) to convert Chinese characters to pinyin. However, it can occasionally mispronounce **polyphone characters** (å¤šéŸ³å­—).",
        "translatedContent": "Ã‡ince karakterleri pinyinâ€™e dÃ¶nÃ¼ÅŸtÃ¼rmek iÃ§in [pypinyin](https://github.com/mozillazg/python-pinyin) kullanÄ±yoruz. Ancak bazen **Ã§ok sesli karakterleri** (å¤šéŸ³å­—) yanlÄ±ÅŸ telaffuz edebilir."
      },
      {
        "row": 2,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 3,
        "rowsha": "h6Qq8AvUPYme90k2BWG054cVE6RHNflr0OwdnKA4BEE=",
        "originContent": "To manually correct these mispronunciations, enclose the **corrected pinyin** in angle brackets `< >` and include the **tone mark**.",
        "translatedContent": "Bu yanlÄ±ÅŸ telaffuzlarÄ± elle dÃ¼zeltmek iÃ§in, **dÃ¼zeltilmiÅŸ pinyinâ€™i** kÃ¶ÅŸeli parantezler `< >` iÃ§ine alÄ±n ve **ton iÅŸaretini** ekleyin."
      },
      {
        "row": 4,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 5,
        "rowsha": "fP4bnCe7+qhcgDDajGMIv4obksa4WSdUp3hExEbpci0=",
        "originContent": "**Example:**",
        "translatedContent": "**Ã–rnek:**"
      },
      {
        "row": 6,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 7,
        "rowsha": "ntwz9/IQqGC1ThJXQn9D83h+54cDriyg2snkkrk0KoI=",
        "originContent": "- Original text: `è¿™æŠŠå‰‘é•¿ä¸‰åå…¬åˆ†`",
        "translatedContent": "- Orijinal metin: `è¿™æŠŠå‰‘é•¿ä¸‰åå…¬åˆ†`"
      },
      {
        "row": 8,
        "rowsha": "sfnMRvscnvdKs1fvbVePwH0RpAikXkFIi9i7HZK7D9w=",
        "originContent": "- Correct the pinyin of `é•¿`:  `è¿™æŠŠå‰‘<chang2>ä¸‰åå…¬åˆ†`",
        "translatedContent": "- `é•¿` karakterinin pinyinâ€™ini dÃ¼zeltin:  `è¿™æŠŠå‰‘<chang2>ä¸‰åå…¬åˆ†`"
      },
      {
        "row": 9,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 10,
        "rowsha": "7f45Y23fyK7AQrUO7HdTtPZZzoyRkW6WwoznauYmQew=",
        "originContent": "> **Note:** If you want to manually assign multiple pinyins, enclose each pinyin with `<>`, e.g., `è¿™æŠŠ<jian4><chang2><san1>åå…¬åˆ†`",
        "translatedContent": "> **Not:** Birden fazla pinyinâ€™i elle atamak isterseniz, her pinyinâ€™i `<>` ile Ã§evreleyin, Ã¶rn: `è¿™æŠŠ<jian4><chang2><san1>åå…¬åˆ†`"
      },
      {
        "row": 11,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 12,
        "rowsha": "FJBRXZnczlB/CZyp0UgEFMr440NrcuTPBheyQJ9lxZI=",
        "originContent": "#### 3.7 Remove long silences from the generated speech",
        "translatedContent": "#### 3.7 OluÅŸturulan konuÅŸmadan uzun sessizlikleri kaldÄ±rma"
      },
      {
        "row": 13,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 14,
        "rowsha": "9UF5wHdPZ48OWeIPfCnOHPEWzgW4Z6I0e+GaTEZ1GXI=",
        "originContent": "Model will automatically determine the positions and lengths of silences in the generated speech. It occasionally has long silence in the middle of the speech. If you don't want this, you can pass `--remove-long-sil` to remove long silences in the middle of the generated speech (edge silences will be removed by default).",
        "translatedContent": "Model, oluÅŸturulan konuÅŸmadaki sessizliklerin yerini ve uzunluÄŸunu otomatik olarak belirler. Bazen konuÅŸmanÄ±n ortasÄ±nda uzun bir sessizlik olabilir. Bunu istemiyorsanÄ±z, oluÅŸturulan konuÅŸmanÄ±n ortasÄ±ndaki uzun sessizlikleri kaldÄ±rmak iÃ§in `--remove-long-sil` komutunu kullanabilirsiniz (kenar sessizlikleri varsayÄ±lan olarak kaldÄ±rÄ±lÄ±r)."
      },
      {
        "row": 15,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 16,
        "rowsha": "t3GDCbkkN4PM6Y7xA/ZDAXgu4WdMFfXJ+5E/xKU9AKo=",
        "originContent": "#### 3.8 Model downloading",
        "translatedContent": "#### 3.8 Model indirme"
      },
      {
        "row": 17,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 18,
        "rowsha": "I2UvthbxkflPXxq8Yy6W9nJCtzb40mZPJbfmDIWQPmA=",
        "originContent": "If you have trouble connecting to HuggingFace when downloading the pre-trained models, try switching endpoint to the mirror site: `export HF_ENDPOINT=https://hf-mirror.com`.",
        "translatedContent": "Ã–nceden eÄŸitilmiÅŸ modelleri indirirken HuggingFaceâ€™e baÄŸlanmada sorun yaÅŸarsanÄ±z, uÃ§ noktayÄ± yansÄ± (mirror) siteye geÃ§irmeyi deneyin: `export HF_ENDPOINT=https://hf-mirror.com`."
      },
      {
        "row": 19,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 20,
        "rowsha": "SEsrfyGZhBYqHMMdMldgN+tSz6ynJT5BVJeLrTV5lHw=",
        "originContent": "## Train Your Own Model",
        "translatedContent": "## Kendi Modelinizi EÄŸitin"
      },
      {
        "row": 21,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 22,
        "rowsha": "XaSJNyFaxQRx1Xc0mphwUGAxovKELo/54WkMCnFDLyE=",
        "originContent": "See the [egs](egs) directory for training, fine-tuning and evaluation examples.",
        "translatedContent": "EÄŸitim, ince ayar ve deÄŸerlendirme Ã¶rnekleri iÃ§in [egs](egs) dizinine bakÄ±n."
      },
      {
        "row": 23,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 24,
        "rowsha": "tfXaiJ7qvaTkZXp5azeYhmiU88iPPhEvLfYayUjE5+g=",
        "originContent": "## Production Deployment",
        "translatedContent": "## Ãœretim OrtamÄ±nda KullanÄ±m"
      },
      {
        "row": 25,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 26,
        "rowsha": "Tv94iSjTAB/OzGKZj2XftoBUCOzD2x+C0/xHRwRVo1c=",
        "originContent": "### NVIDIA Triton GPU Runtime",
        "translatedContent": "### NVIDIA Triton GPU Ã‡alÄ±ÅŸma ZamanÄ±"
      },
      {
        "row": 27,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 28,
        "rowsha": "cGPOVgf7Mpi/ILRt8hu96EmjQo85nhgnSfBGLfBqMeM=",
        "originContent": "For production-ready deployment with high performance and scalability, check out the [Triton Inference Server integration](runtime/nvidia_triton/) that provides optimized TensorRT engines, concurrent request handling, and both gRPC/HTTP APIs for enterprise use.",
        "translatedContent": "YÃ¼ksek performans ve Ã¶lÃ§eklenebilir Ã¼retim daÄŸÄ±tÄ±mÄ± iÃ§in, optimize edilmiÅŸ TensorRT motorlarÄ±, eÅŸzamanlÄ± istek iÅŸleme ve kurumsal kullanÄ±m iÃ§in gRPC/HTTP APIâ€™leri saÄŸlayan [Triton Inference Server entegrasyonuna](runtime/nvidia_triton/) gÃ¶z atÄ±n."
      },
      {
        "row": 29,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 30,
        "rowsha": "qR/CeuOSoGV5ipBKRWpnI+ohlytt878WhTEjtxZenks=",
        "originContent": "### CPU Deployment",
        "translatedContent": "### CPU DaÄŸÄ±tÄ±mÄ±"
      },
      {
        "row": 31,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 32,
        "rowsha": "B8jnXFyKu8XRyVw/Pu0Xuj1ted9/BVoBfwJ1WW9LrcE=",
        "originContent": "Check [sherpa-onnx](https://github.com/k2-fsa/sherpa-onnx/pull/2487#issuecomment-3227884498) for the C++ deployment solution on CPU.",
        "translatedContent": "CPU Ã¼zerinde C++ ile daÄŸÄ±tÄ±m Ã§Ã¶zÃ¼mÃ¼ iÃ§in [sherpa-onnx](https://github.com/k2-fsa/sherpa-onnx/pull/2487#issuecomment-3227884498) inceleyin."
      },
      {
        "row": 33,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 34,
        "rowsha": "dEqRbPItUt3FEp1iC+8Ww+A6L57yd6oGeXfxSn5BYzs=",
        "originContent": "## Discussion & Communication",
        "translatedContent": "## TartÄ±ÅŸma ve Ä°letiÅŸim"
      },
      {
        "row": 35,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 36,
        "rowsha": "wjQUwaDgSP1a6ggLgGx8TWt44Dxu5IlJytNwCAlzZKg=",
        "originContent": "You can directly discuss on [Github Issues](https://github.com/k2-fsa/ZipVoice/issues).",
        "translatedContent": "DoÄŸrudan [Github Issues](https://github.com/k2-fsa/ZipVoice/issues) Ã¼zerinden tartÄ±ÅŸabilirsiniz."
      },
      {
        "row": 37,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 38,
        "rowsha": "WLbsT+slCE72T0wpzVIN8KFxhP+RAw29VxFhJcBEEIo=",
        "originContent": "You can also scan the QR code to join our wechat group or follow our wechat official account.",
        "translatedContent": "AyrÄ±ca QR kodunu tarayarak WeChat grubumuza katÄ±labilir veya WeChat resmi hesabÄ±mÄ±zÄ± takip edebilirsiniz."
      },
      {
        "row": 39,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 40,
        "rowsha": "XMNeg//PyHlCkY1XlL7caNd2vlVOKKoslrNeasADjMY=",
        "originContent": "| Wechat Group | Wechat Official Account |",
        "translatedContent": "| Wechat Grubu | Wechat Resmi HesabÄ± |"
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 25,
    "Content": "| ------------ | ----------------------- |\n|![wechat](https://k2-fsa.org/zh-CN/assets/pic/wechat_group.jpg) |![wechat](https://k2-fsa.org/zh-CN/assets/pic/wechat_account.jpg) |\n\n## Citation\n",
    "ContentSha": "z5P7Ai9AO6w/XhHPT5bFJ00FeUxhB51crq68OHJeIus=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "| ------------ | ----------------------- |\n|![wechat](https://k2-fsa.org/zh-CN/assets/pic/wechat_group.jpg) |![wechat](https://k2-fsa.org/zh-CN/assets/pic/wechat_account.jpg) |\n\n## AtÄ±f\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "jdP52Pdk9hJ4eEQC1YzC887/bGdD6V25zHK1FxUbFjM=",
        "originContent": "| ------------ | ----------------------- |",
        "translatedContent": "| ------------ | ----------------------- |"
      },
      {
        "row": 2,
        "rowsha": "Q6eYrtLPPuG0fiZxZqhYquTYNk0vlyIOh+CRuwGZVk4=",
        "originContent": "|![wechat](https://k2-fsa.org/zh-CN/assets/pic/wechat_group.jpg) |![wechat](https://k2-fsa.org/zh-CN/assets/pic/wechat_account.jpg) |",
        "translatedContent": "|![wechat](https://k2-fsa.org/zh-CN/assets/pic/wechat_group.jpg) |![wechat](https://k2-fsa.org/zh-CN/assets/pic/wechat_account.jpg) |"
      },
      {
        "row": 3,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 4,
        "rowsha": "ZwTp5ajUmpHTJefyHhIKzXcG2wnB1jv8iv8cvmdcb/g=",
        "originContent": "## Citation",
        "translatedContent": "## AtÄ±f"
      },
      {
        "row": 5,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 26,
    "Content": "```bibtex\n@article{zhu2025zipvoice,\n      title={ZipVoice: Fast and High-Quality Zero-Shot Text-to-Speech with Flow Matching},\n      author={Zhu, Han and Kang, Wei and Yao, Zengwei and Guo, Liyong and Kuang, Fangjun and Li, Zhaoqing and Zhuang, Weiji and Lin, Long and Povey, Daniel},\n      journal={arXiv preprint arXiv:2506.13053},\n      year={2025}\n}\n\n@article{zhu2025zipvoicedialog,\n      title={ZipVoice-Dialog: Non-Autoregressive Spoken Dialogue Generation with Flow Matching},\n      author={Zhu, Han and Kang, Wei and Guo, Liyong and Yao, Zengwei and Kuang, Fangjun and Zhuang, Weiji and Li, Zhaoqing and Han, Zhifeng and Zhang, Dong and Zhang, Xin and Song, Xingchen and Lin, Long and Povey, Daniel},\n      journal={arXiv preprint arXiv:2507.09318},\n      year={2025}\n}\n```",
    "ContentSha": "4y5htVtgE8qDxiQNpfNmGGVhWO4hKo26DrPCI9N/e9E=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bibtex\n@article{zhu2025zipvoice,\n      title={ZipVoice: Fast and High-Quality Zero-Shot Text-to-Speech with Flow Matching},\n      author={Zhu, Han and Kang, Wei and Yao, Zengwei and Guo, Liyong and Kuang, Fangjun and Li, Zhaoqing and Zhuang, Weiji and Lin, Long and Povey, Daniel},\n      journal={arXiv preprint arXiv:2506.13053},\n      year={2025}\n}\n\n@article{zhu2025zipvoicedialog,\n      title={ZipVoice-Dialog: Non-Autoregressive Spoken Dialogue Generation with Flow Matching},\n      author={Zhu, Han and Kang, Wei and Guo, Liyong and Yao, Zengwei and Kuang, Fangjun and Zhuang, Weiji and Li, Zhaoqing and Han, Zhifeng and Zhang, Dong and Zhang, Xin and Song, Xingchen and Lin, Long and Povey, Daniel},\n      journal={arXiv preprint arXiv:2507.09318},\n      year={2025}\n}\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 27,
    "Content": "",
    "ContentSha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "<translate-content></translate-content>",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  }
]