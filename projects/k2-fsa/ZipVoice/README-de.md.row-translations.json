[
  {
    "row": 1,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 2,
    "rowsha": "6vgIR6WfUAFmULhn8LhxFttPwZEo/YwGhN1DAECwHCQ=",
    "originContent": "- `wav_name` is the name of the output wav file.",
    "translatedContent": "- `wav_name` ist der Name der Ausgabedatei im WAV-Format."
  },
  {
    "row": 3,
    "rowsha": "7BNq8UaBvTut4Ow/oJBAgIDTn3EwEZXK7mlUaYdFwqw=",
    "originContent": "- `spk1_prompt_transcription` is the transcription of the first speaker's prompt wav, e.g, \"Hello\"",
    "translatedContent": "- `spk1_prompt_transcription` ist die Transkription der Prompt-WAV-Datei des ersten Sprechers, z. B. „Hallo“."
  },
  {
    "row": 4,
    "rowsha": "CES8w9dqVdkdJyOJBUVP282aaKeevVWB3d/+59TEsuk=",
    "originContent": "- `spk2_prompt_transcription` is the transcription of the second speaker's prompt wav, e.g, \"How are you?\"",
    "translatedContent": "- `spk2_prompt_transcription` ist die Transkription der Prompt-WAV-Datei des zweiten Sprechers, z. B. „Wie geht's?“"
  },
  {
    "row": 5,
    "rowsha": "gXLLRf4BR7Xko2q2l4nK04KIs/L8CjvZ/UBQaP1+vck=",
    "originContent": "- `spk1_prompt_wav` is the path to the first speaker's prompt wav file.",
    "translatedContent": "- `spk1_prompt_wav` ist der Pfad zur Prompt-WAV-Datei des ersten Sprechers."
  },
  {
    "row": 6,
    "rowsha": "oS1+heJwBnnDtA57WYtG6LbzxK79DOIeb8hwhZQwcDg=",
    "originContent": "- `spk2_prompt_wav` is the path to the second speaker's prompt wav file.",
    "translatedContent": "- `spk2_prompt_wav` ist der Pfad zur Prompt-WAV-Datei des zweiten Sprechers."
  },
  {
    "row": 7,
    "rowsha": "M4Z2DDajNBdyF/JosIaDZ44oyZnjNA7lzfGzEpuoako=",
    "originContent": "- `text` is the text to be synthesized, e.g. \"[S1] I'm fine. [S2] What's your name? [S1] I'm Eric. [S2] Hi Eric.\"",
    "translatedContent": "- `text` ist der zu synthetisierende Text, z. B. „[S1] Mir geht's gut. [S2] Wie heißt du? [S1] Ich bin Eric. [S2] Hallo Eric.“"
  },
  {
    "row": 8,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 9,
    "rowsha": "SdDI3h73wOzKSM3kbrbNrmpigHGer7kumuaZsQgAeao=",
    "originContent": "### 3 Guidance for better usage:",
    "translatedContent": "### 3 Anleitung für bessere Nutzung:"
  },
  {
    "row": 10,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 11,
    "rowsha": "cVxukE6jyFFOxlNKI5ecOTo/suYYJ8hnYyW2XA2wg+o=",
    "originContent": "#### 3.1 Prompt length",
    "translatedContent": "#### 3.1 Länge des Prompts"
  },
  {
    "row": 12,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 13,
    "rowsha": "f19zq78QrLul7wiVSlCSojGS7qNEvtef9GFg6AA8eMY=",
    "originContent": "We recommand a short prompt wav file (e.g., less than 3 seconds for single-speaker speech generation, less than 10 seconds for dialogue speech generation) for faster inference speed. A very long prompt will slow down the inference and degenerate the speech quality.",
    "translatedContent": "Wir empfehlen eine kurze Prompt-WAV-Datei (z. B. weniger als 3 Sekunden für die Einzelsprecher-Spracherzeugung, weniger als 10 Sekunden für die Dialog-Spracherzeugung) für eine schnellere Inferenzgeschwindigkeit. Ein sehr langer Prompt verlangsamt die Inferenz und verschlechtert die Sprachqualität."
  },
  {
    "row": 14,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 15,
    "rowsha": "lpgNpm20ulCcTiEU/xfEVVgMZhjiQjymkdljF8dD/vw=",
    "originContent": "#### 3.2 Speed optimization",
    "translatedContent": "#### 3.2 Geschwindigkeitsoptimierung"
  },
  {
    "row": 16,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 17,
    "rowsha": "iBJxMfYOjV9HvSuRT3p/EsU/iATeDCDAk/wGWLXqQI8=",
    "originContent": "If the inference speed is unsatisfactory, you can speed it up as follows:",
    "translatedContent": "Wenn die Inferenzgeschwindigkeit unzufriedenstellend ist, können Sie wie folgt beschleunigen:"
  },
  {
    "row": 18,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 19,
    "rowsha": "IzTHxzS1e5yJRhHF5d8CsjfqjIzhNX1AeGR4FTjuUCA=",
    "originContent": "- **Distill model and less steps**: For the single-speaker speech generation model, we use the `zipvoice` model by default for better speech quality. If faster speed is a priority, you can switch to the `zipvoice_distill` and can reduce the `--num-steps` to as low as `4` (8 by default).",
    "translatedContent": "- **Distill-Modell und weniger Schritte**: Für das Einzelsprecher-Spracherzeugungsmodell verwenden wir standardmäßig das `zipvoice`-Modell für bessere Sprachqualität. Wenn schnellere Geschwindigkeit Priorität hat, können Sie auf `zipvoice_distill` wechseln und die `--num-steps` auf bis zu `4` reduzieren (Standard ist 8)."
  },
  {
    "row": 20,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 21,
    "rowsha": "mNiqyHjFr4rbx4boH0cix2peH8Q0+tDTOlzgZeLLDqM=",
    "originContent": "- **CPU speedup with multi-threading**: When running on CPU, you can pass the `--num-thread` parameter (e.g., `--num-thread 4`) to increase the number of threads for faster speed. We use 1 thread by default.",
    "translatedContent": "- **CPU-Beschleunigung durch Multi-Threading**: Beim Ausführen auf der CPU können Sie den Parameter `--num-thread` übergeben (z. B. `--num-thread 4`), um die Anzahl der Threads für höhere Geschwindigkeit zu erhöhen. Standardmäßig wird 1 Thread verwendet."
  },
  {
    "row": 22,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 23,
    "rowsha": "YqtmXdPz7OfUIbrIkeeIwyKEPdEZUqn3m5EyTNd967s=",
    "originContent": "- **CPU speedup with ONNX**: When running on CPU, you can use ONNX models with `zipvoice.bin.infer_zipvoice_onnx` for faster speed (haven't supported ONNX for dialogue generation models yet). For even faster speed, you can further set `--onnx-int8 True` to use an INT8-quantized ONNX model. Note that the quantized model will result in a certain degree of speech quality degradation. **Don't use ONNX on GPU**, as it is slower than PyTorch on GPU.",
    "translatedContent": "- **CPU-Beschleunigung mit ONNX**: Bei CPU-Ausführung können Sie ONNX-Modelle mit `zipvoice.bin.infer_zipvoice_onnx` für höhere Geschwindigkeit verwenden (ONNX wird für Dialog-Generierungsmodelle noch nicht unterstützt). Für noch höhere Geschwindigkeit können Sie zusätzlich `--onnx-int8 True` setzen, um ein INT8-quantisiertes ONNX-Modell zu nutzen. Beachten Sie, dass das quantisierte Modell zu einer gewissen Verschlechterung der Sprachqualität führt. **Verwenden Sie ONNX nicht auf der GPU**, da es dort langsamer als PyTorch ist."
  },
  {
    "row": 24,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 25,
    "rowsha": "kj1A4DWWe02Utusq07KI3xRRH55QdxQWRCzFeimIzww=",
    "originContent": "- **GPU Acceleration with NVIDIA TensorRT**: For a significant performance boost on NVIDIA GPUs, first export the model to a TensorRT engine using zipvoice.bin.tensorrt_export. Then, run inference on your dataset (e.g., a Hugging Face dataset) with zipvoice.bin.infer_zipvoice. This can achieve approximately 2x the throughput compared to the standard PyTorch implementation on a GPU.",
    "translatedContent": "- **GPU-Beschleunigung mit NVIDIA TensorRT**: Für einen deutlichen Leistungsschub auf NVIDIA-GPUs exportieren Sie zunächst das Modell mit zipvoice.bin.tensorrt_export als TensorRT-Engine. Führen Sie dann die Inferenz auf Ihrem Datensatz (z. B. Hugging Face-Datensatz) mit zipvoice.bin.infer_zipvoice aus. Dies kann etwa die doppelte Durchsatzrate im Vergleich zur Standard-PyTorch-Implementierung auf einer GPU erreichen."
  },
  {
    "row": 26,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 27,
    "rowsha": "fze8iMUXPcPsZgNFyWFzWSuCffZnzh7SpzLs21tQLtE=",
    "originContent": "#### 3.3 Memory control",
    "translatedContent": "#### 3.3 Speichersteuerung"
  },
  {
    "row": 28,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 29,
    "rowsha": "uM67TExtHYq7ALHmglqtjLRqv0Xu0OOSx2aFJquZPmw=",
    "originContent": "The given text will be splitted into chunks based on punctuation (for single-speaker speech generation) or speaker-turn symbol (for dialogue speech generation). Then, the chunked texts will be processed in batches. Therefore, the model can process arbitrarily long text with almost constant memory usage. You can control memory usage by adjusting the `--max-duration` parameter.",
    "translatedContent": "Der angegebene Text wird anhand von Satzzeichen (bei Einzelsprecher-Spracherzeugung) oder Sprecherwechsel-Symbolen (bei Dialog-Spracherzeugung) in Abschnitte unterteilt. Anschließend werden die Abschnitte stapelweise verarbeitet. Dadurch kann das Modell beliebig lange Texte mit nahezu konstantem Speicherbedarf verarbeiten. Sie können den Speicherverbrauch durch Anpassung des Parameters `--max-duration` steuern."
  },
  {
    "row": 30,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 31,
    "rowsha": "foa86E9JcH+Sc/k2OCmyfIKHwggsFBXhSUfHDcmJQA0=",
    "originContent": "#### 3.4 \"Raw\" evaluation",
    "translatedContent": "#### 3.4 „Rohe“ Auswertung"
  },
  {
    "row": 32,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 33,
    "rowsha": "+2nxKNvXmuxUQpf2Z+hw0Rxydt00FpmK4y4rlK5/8og=",
    "originContent": "By default, we preprocess inputs (prompt wav, prompt transcription, and text) for efficient inference and better performance. If you want to evaluate the model’s \"raw\" performance using exact provided inputs (e.g., to reproduce the results in our paper), you can pass `--raw-evaluation True`.",
    "translatedContent": "Standardmäßig werden Eingaben (Prompt-WAV, Prompt-Transkription und Text) für effiziente Inferenz und bessere Leistung vorverarbeitet. Wenn Sie die „rohe“ Leistung des Modells mit den exakt angegebenen Eingaben bewerten möchten (z. B. zur Reproduktion der Ergebnisse unserer Publikation), können Sie `--raw-evaluation True` übergeben."
  },
  {
    "row": 34,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 35,
    "rowsha": "g658opDssPKmJCvr7Jw9N130Xud1IbMHTwMK+S89WO0=",
    "originContent": "#### 3.5 Short text",
    "translatedContent": "#### 3.5 Kurzer Text"
  },
  {
    "row": 36,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 37,
    "rowsha": "/IVkHehTtKgVQNwGOgQO/BoRh95RFHVJPH3e0W6Gixs=",
    "originContent": "When generating speech for very short texts (e.g., one or two words), the generated speech may sometimes omit certain pronunciations. To resolve this issue, you can pass `--speed 0.3` (where 0.3 is a tunable value) to extend the duration of the generated speech.",
    "translatedContent": "Bei der Generierung von Sprache für sehr kurze Texte (z. B. ein oder zwei Wörter) kann es vorkommen, dass bestimmte Aussprachen im erzeugten Sprachsignal fehlen. Um dieses Problem zu beheben, können Sie `--speed 0.3` übergeben (wobei 0.3 ein anpassbarer Wert ist), um die Dauer der erzeugten Sprache zu verlängern."
  },
  {
    "row": 38,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 39,
    "rowsha": "PAPz1JYDhpLF6dsiNH/BVipH4SufvLcqzLiPLACOcK4=",
    "originContent": "#### 3.6 Correcting mispronounced chinese polyphone characters",
    "translatedContent": "#### 3.6 Korrektur von falsch ausgesprochenen chinesischen Polyphonen-Zeichen"
  },
  {
    "row": 40,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 41,
    "rowsha": "hF52KZEnGKLuaot2w0AmXt52eB6Y3adYIo2qMJSMx5o=",
    "originContent": "We use [pypinyin](https://github.com/mozillazg/python-pinyin) to convert Chinese characters to pinyin. However, it can occasionally mispronounce **polyphone characters** (多音字).",
    "translatedContent": "Wir verwenden [pypinyin](https://github.com/mozillazg/python-pinyin), um chinesische Schriftzeichen in Pinyin umzuwandeln. Allerdings kann es gelegentlich **polyphone Zeichen** (多音字) falsch aussprechen."
  },
  {
    "row": 42,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 43,
    "rowsha": "h6Qq8AvUPYme90k2BWG054cVE6RHNflr0OwdnKA4BEE=",
    "originContent": "To manually correct these mispronunciations, enclose the **corrected pinyin** in angle brackets `< >` and include the **tone mark**.",
    "translatedContent": "Um diese Fehl-Aussprache manuell zu korrigieren, schließen Sie das **korrigierte Pinyin** in spitze Klammern `< >` ein und fügen Sie das **Tonzeichen** hinzu."
  },
  {
    "row": 44,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 45,
    "rowsha": "fP4bnCe7+qhcgDDajGMIv4obksa4WSdUp3hExEbpci0=",
    "originContent": "**Example:**",
    "translatedContent": "**Beispiel:**"
  },
  {
    "row": 46,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 47,
    "rowsha": "ntwz9/IQqGC1ThJXQn9D83h+54cDriyg2snkkrk0KoI=",
    "originContent": "- Original text: `这把剑长三十公分`",
    "translatedContent": "- Originaltext: `这把剑长三十公分`"
  },
  {
    "row": 48,
    "rowsha": "sfnMRvscnvdKs1fvbVePwH0RpAikXkFIi9i7HZK7D9w=",
    "originContent": "- Correct the pinyin of `长`:  `这把剑<chang2>三十公分`",
    "translatedContent": "- Pinyin von `长` korrigieren:  `这把剑<chang2>三十公分`"
  },
  {
    "row": 49,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 50,
    "rowsha": "7f45Y23fyK7AQrUO7HdTtPZZzoyRkW6WwoznauYmQew=",
    "originContent": "> **Note:** If you want to manually assign multiple pinyins, enclose each pinyin with `<>`, e.g., `这把<jian4><chang2><san1>十公分`",
    "translatedContent": "> **Hinweis:** Wenn Sie mehreren Zeichen manuell Pinyin zuweisen möchten, schließen Sie jedes Pinyin in `<>` ein, z.B. `这把<jian4><chang2><san1>十公分`"
  },
  {
    "row": 51,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 52,
    "rowsha": "FJBRXZnczlB/CZyp0UgEFMr440NrcuTPBheyQJ9lxZI=",
    "originContent": "#### 3.7 Remove long silences from the generated speech",
    "translatedContent": "#### 3.7 Entfernen von langen Pausen aus der generierten Sprache"
  },
  {
    "row": 53,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 54,
    "rowsha": "9UF5wHdPZ48OWeIPfCnOHPEWzgW4Z6I0e+GaTEZ1GXI=",
    "originContent": "Model will automatically determine the positions and lengths of silences in the generated speech. It occasionally has long silence in the middle of the speech. If you don't want this, you can pass `--remove-long-sil` to remove long silences in the middle of the generated speech (edge silences will be removed by default).",
    "translatedContent": "Das Modell bestimmt automatisch die Positionen und Längen der Pausen in der generierten Sprache. Gelegentlich gibt es lange Pausen mitten in der Sprache. Wenn Sie dies nicht wünschen, können Sie `--remove-long-sil` verwenden, um lange Pausen in der Mitte der generierten Sprache zu entfernen (Randpausen werden standardmäßig entfernt)."
  },
  {
    "row": 55,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 56,
    "rowsha": "t3GDCbkkN4PM6Y7xA/ZDAXgu4WdMFfXJ+5E/xKU9AKo=",
    "originContent": "#### 3.8 Model downloading",
    "translatedContent": "#### 3.8 Modell-Download"
  },
  {
    "row": 57,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 58,
    "rowsha": "I2UvthbxkflPXxq8Yy6W9nJCtzb40mZPJbfmDIWQPmA=",
    "originContent": "If you have trouble connecting to HuggingFace when downloading the pre-trained models, try switching endpoint to the mirror site: `export HF_ENDPOINT=https://hf-mirror.com`.",
    "translatedContent": "Wenn Sie beim Herunterladen der vortrainierten Modelle Schwierigkeiten haben, eine Verbindung zu HuggingFace herzustellen, versuchen Sie, den Endpunkt auf die Spiegelseite zu wechseln: `export HF_ENDPOINT=https://hf-mirror.com`."
  },
  {
    "row": 59,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 60,
    "rowsha": "SEsrfyGZhBYqHMMdMldgN+tSz6ynJT5BVJeLrTV5lHw=",
    "originContent": "## Train Your Own Model",
    "translatedContent": "## Eigenes Modell trainieren"
  },
  {
    "row": 61,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 62,
    "rowsha": "XaSJNyFaxQRx1Xc0mphwUGAxovKELo/54WkMCnFDLyE=",
    "originContent": "See the [egs](egs) directory for training, fine-tuning and evaluation examples.",
    "translatedContent": "Siehe das [egs](egs)-Verzeichnis für Beispiele zum Training, Fine-Tuning und zur Bewertung."
  },
  {
    "row": 63,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 64,
    "rowsha": "tfXaiJ7qvaTkZXp5azeYhmiU88iPPhEvLfYayUjE5+g=",
    "originContent": "## Production Deployment",
    "translatedContent": "## Produktiv-Einsatz"
  },
  {
    "row": 65,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 66,
    "rowsha": "Tv94iSjTAB/OzGKZj2XftoBUCOzD2x+C0/xHRwRVo1c=",
    "originContent": "### NVIDIA Triton GPU Runtime",
    "translatedContent": "### NVIDIA Triton GPU-Laufzeit"
  },
  {
    "row": 67,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 68,
    "rowsha": "cGPOVgf7Mpi/ILRt8hu96EmjQo85nhgnSfBGLfBqMeM=",
    "originContent": "For production-ready deployment with high performance and scalability, check out the [Triton Inference Server integration](runtime/nvidia_triton/) that provides optimized TensorRT engines, concurrent request handling, and both gRPC/HTTP APIs for enterprise use.",
    "translatedContent": "Für produktionsbereiten Einsatz mit hoher Leistung und Skalierbarkeit sehen Sie sich die [Triton Inference Server-Integration](runtime/nvidia_triton/) an, die optimierte TensorRT-Engines, gleichzeitige Anfragebearbeitung und sowohl gRPC/HTTP-APIs für den Unternehmenseinsatz bietet."
  },
  {
    "row": 69,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 70,
    "rowsha": "qR/CeuOSoGV5ipBKRWpnI+ohlytt878WhTEjtxZenks=",
    "originContent": "### CPU Deployment",
    "translatedContent": "### CPU-Bereitstellung"
  },
  {
    "row": 71,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 72,
    "rowsha": "B8jnXFyKu8XRyVw/Pu0Xuj1ted9/BVoBfwJ1WW9LrcE=",
    "originContent": "Check [sherpa-onnx](https://github.com/k2-fsa/sherpa-onnx/pull/2487#issuecomment-3227884498) for the C++ deployment solution on CPU.",
    "translatedContent": "Siehe [sherpa-onnx](https://github.com/k2-fsa/sherpa-onnx/pull/2487#issuecomment-3227884498) für die C++-Bereitstellungslösung auf der CPU."
  },
  {
    "row": 73,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 74,
    "rowsha": "dEqRbPItUt3FEp1iC+8Ww+A6L57yd6oGeXfxSn5BYzs=",
    "originContent": "## Discussion & Communication",
    "translatedContent": "## Diskussion & Kommunikation"
  },
  {
    "row": 75,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 76,
    "rowsha": "wjQUwaDgSP1a6ggLgGx8TWt44Dxu5IlJytNwCAlzZKg=",
    "originContent": "You can directly discuss on [Github Issues](https://github.com/k2-fsa/ZipVoice/issues).",
    "translatedContent": "Sie können direkt auf [Github Issues](https://github.com/k2-fsa/ZipVoice/issues) diskutieren."
  },
  {
    "row": 77,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 78,
    "rowsha": "WLbsT+slCE72T0wpzVIN8KFxhP+RAw29VxFhJcBEEIo=",
    "originContent": "You can also scan the QR code to join our wechat group or follow our wechat official account.",
    "translatedContent": "Sie können auch den QR-Code scannen, um unserer WeChat-Gruppe beizutreten oder unserem offiziellen WeChat-Account zu folgen."
  },
  {
    "row": 79,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 80,
    "rowsha": "XMNeg//PyHlCkY1XlL7caNd2vlVOKKoslrNeasADjMY=",
    "originContent": "| Wechat Group | Wechat Official Account |",
    "translatedContent": "| WeChat-Gruppe | Offizieller WeChat-Account |"
  },
  {
    "row": 81,
    "rowsha": "jdP52Pdk9hJ4eEQC1YzC887/bGdD6V25zHK1FxUbFjM=",
    "originContent": "| ------------ | ----------------------- |",
    "translatedContent": "| ------------ | ----------------------- |"
  },
  {
    "row": 82,
    "rowsha": "Q6eYrtLPPuG0fiZxZqhYquTYNk0vlyIOh+CRuwGZVk4=",
    "originContent": "|![wechat](https://k2-fsa.org/zh-CN/assets/pic/wechat_group.jpg) |![wechat](https://k2-fsa.org/zh-CN/assets/pic/wechat_account.jpg) |",
    "translatedContent": "|![wechat](https://k2-fsa.org/zh-CN/assets/pic/wechat_group.jpg) |![wechat](https://k2-fsa.org/zh-CN/assets/pic/wechat_account.jpg) |"
  },
  {
    "row": 83,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 84,
    "rowsha": "ZwTp5ajUmpHTJefyHhIKzXcG2wnB1jv8iv8cvmdcb/g=",
    "originContent": "## Citation",
    "translatedContent": "## Zitation"
  },
  {
    "row": 85,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  }
]