<div align="right">
  <details>
    <summary >🌐 زبان</summary>
    <div>
      <div align="center">
        <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=en">انگلیسی</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=zh-CN">简体中文</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=zh-TW">繁體中文</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ja">ژاپنی</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ko">کره‌ای</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=hi">هندی</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=th">تایلندی</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=fr">فرانسوی</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=de">آلمانی</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=es">اسپانیایی</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=it">ایتالیایی</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ru">روسی</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=pt">پرتغالی</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=nl">هلندی</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=pl">لهستانی</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ar">عربی</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=fa">فارسی</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=tr">ترکی</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=vi">ویتنامی</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=id">اندونزیایی</a>
      </div>
    </div>
  </details>
</div>

<div align="center">

# ZipVoice⚡

## تبدیل متن به گفتار سریع و باکیفیت با یادگیری تطبیقی جریان (Flow Matching)
</div>

## مروری کلی

ZipVoice مجموعه‌ای از مدل‌های تبدیل متن به گفتار سریع و باکیفیت (TTS) بر پایه Flow Matching است.

### 1. ویژگی‌های کلیدی

- کوچک و سریع: تنها ۱۲۳ میلیون پارامتر.

- شبیه‌سازی صدای باکیفیت: عملکرد پیشرفته در شباهت به گوینده، وضوح و طبیعی بودن.

- چندزبانه: پشتیبانی از چینی و انگلیسی.

- چندحالته: پشتیبانی از تولید گفتار تک‌گوینده و گفتگوی چندنفری.

### 2. انواع مدل

<table>
  <thead>
    <tr>
      <th>نام مدل</th>
      <th>توضیحات</th>
      <th>مقاله</th>
      <th>دمو</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>ZipVoice</td>
      <td>مدل پایه که از تبدیل متن به گفتار تک‌گوینده به‌صورت zero-shot در زبان‌های چینی و انگلیسی پشتیبانی می‌کند.</td>
      <td rowspan="2"><a href="https://arxiv.org/abs/2506.13053"><img src="https://img.shields.io/badge/arXiv-Paper-COLOR.svg"></a></td>
      <td rowspan="2"><a href="https://zipvoice.github.io"><img src="https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square"></a></td>
    </tr>
    <tr>
      <td>ZipVoice-Distill</td>
      <td>نسخه تقطیرشده ZipVoice که سرعت بالاتری با کاهش حداقلی در عملکرد ارائه می‌دهد.</td>
    </tr>
    <tr>
      <td>ZipVoice-Dialog</td>
      <td>مدل تولید گفتگو که بر پایه ZipVoice ساخته شده و قادر به تولید گفت‌وگوی دو نفره تک‌کاناله می‌باشد.</td>
      <td rowspan="2"><a href="https://arxiv.org/abs/2507.09318"><img src="https://img.shields.io/badge/arXiv-Paper-COLOR.svg"></a></td>
      <td rowspan="2"><a href="https://zipvoice-dialog.github.io"><img src="https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square"></a></td>
    </tr>
    <tr>
      <td>ZipVoice-Dialog-Stereo</td>
      <td>نسخه استریوی ZipVoice-Dialog که تولید گفت‌وگوی دوکاناله را با اختصاص هر گوینده به یک کانال مجزا ممکن می‌سازد.</td>
    </tr>
  </tbody>
</table>

## اخبار

**۱۴۰۴/۰۴/۲۳**: **ZipVoice-Dialog** و **ZipVoice-Dialog-Stereo**، دو مدل تولید گفت‌وگوی صوتی منتشر شدند. [![arXiv](https://img.shields.io/badge/arXiv-Paper-COLOR.svg)](https://arxiv.org/abs/2507.09318) [![demo page](https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square)](https://zipvoice-dialog.github.io)

**۱۴۰۴/۰۴/۲۳**: دیتاست **OpenDialog**، مجموعه‌ای از ۶.۸ هزار ساعت گفت‌وگوی صوتی، منتشر شد. دانلود از [![hf](https://img.shields.io/badge/%F0%9F%A4%97%20HuggingFace-Dataset-yellow)](https://huggingface.co/datasets/k2-fsa/OpenDialog)، [![ms](https://img.shields.io/badge/ModelScope-Dataset-blue?logo=data)](https://www.modelscope.cn/datasets/k2-fsa/OpenDialog). جزئیات در [![arXiv](https://img.shields.io/badge/arXiv-Paper-COLOR.svg)](https://arxiv.org/abs/2507.09318).

**۱۴۰۴/۰۳/۲۶**: **ZipVoice** و **ZipVoice-Distill** منتشر شدند. [![arXiv](https://img.shields.io/badge/arXiv-Paper-COLOR.svg)](https://arxiv.org/abs/2506.13053) [![demo page](https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square)](https://zipvoice.github.io)

## نصب

### ۱. کلون کردن مخزن ZipVoice


```bash
git clone https://github.com/k2-fsa/ZipVoice.git
```
### ۲. (اختیاری) ایجاد یک محیط مجازی پایتون


```bash
python3 -m venv zipvoice
source zipvoice/bin/activate
```
### ۳. بسته‌های مورد نیاز را نصب کنید


```bash
pip install -r requirements.txt
```
### ۴. (اختیاری) نصب k2 برای آموزش یا استنتاج کارآمد

k2 برای آموزش ضروری است و می‌تواند سرعت استنتاج را افزایش دهد. با این حال، همچنان می‌توانید از حالت استنتاج ZipVoice بدون نصب k2 استفاده کنید.

> **توجه:**  اطمینان حاصل کنید که نسخه k2 متناسب با نسخه PyTorch و CUDA شما باشد. به عنوان مثال، اگر از pytorch 2.5.1 و CUDA 12.1 استفاده می‌کنید، می‌توانید k2 را به صورت زیر نصب کنید:


```bash
pip install k2==1.24.4.dev20250208+cuda12.1.torch2.5.1 -f https://k2-fsa.github.io/k2/cuda.html
```
لطفاً برای جزئیات به https://k2-fsa.org/get-started/k2/ مراجعه کنید.
کاربران داخل سرزمین اصلی چین می‌توانند به https://k2-fsa.org/zh-CN/get-started/k2/ مراجعه نمایند.

## نحوه استفاده

### ۱. تولید گفتار تک‌گوینده

برای تولید گفتار تک‌گوینده با مدل‌های از پیش آموزش‌دیده ZipVoice یا ZipVoice-Distill، از دستورات زیر استفاده کنید (مدل‌های مورد نیاز از HuggingFace دانلود خواهند شد):

#### ۱.۱ استنتاج یک جمله منفرد


```bash
python3 -m zipvoice.bin.infer_zipvoice \
    --model-name zipvoice \
    --prompt-wav prompt.wav \
    --prompt-text "I am the transcription of the prompt wav." \
    --text "I am the text to be synthesized." \
    --res-wav-path result.wav
```
- `--model-name` می‌تواند `zipvoice` یا `zipvoice_distill` باشد، که به ترتیب مدل‌های قبل و بعد از تقطیر هستند.
- اگر `<>` یا `[]` در متن ظاهر شود، رشته‌های داخل آنها به عنوان توکن‌های ویژه در نظر گرفته می‌شوند. `<>` نشان‌دهنده پین‌یین چینی و `[]` نشان‌دهنده سایر برچسب‌های ویژه است.
- با `zipvoice.bin.infer_zipvoice_onnx` می‌توانید مدل‌های ONNX را سریع‌تر روی CPU اجرا کنید.

> **توجه:** اگر در اتصال به HuggingFace مشکل داشتید، امتحان کنید:
> ```bash
> export HF_ENDPOINT=https://hf-mirror.com
> ```

#### 1.2 استنتاج یک لیست از جملات


```bash
python3 -m zipvoice.bin.infer_zipvoice \
    --model-name zipvoice \
    --test-list test.tsv \
    --res-dir results
```
- هر خط از `test.tsv` به صورت `{wav_name}\t{prompt_transcription}\t{prompt_wav}\t{text}` فرمت شده است.

### ۲. تولید گفت‌وگوی صوتی

#### ۲.۱ دستور استنتاج

برای تولید گفت‌وگوهای صوتی دو نفره با مدل‌های از پیش آموزش‌دیده ZipVoice-Dialogue یا ZipVoice-Dialogue-Stereo ما، از دستورات زیر استفاده کنید (مدل‌های مورد نیاز از HuggingFace دانلود خواهند شد):


```bash
python3 -m zipvoice.bin.infer_zipvoice_dialog \
    --model-name "zipvoice_dialog" \
    --test-list test.tsv \
    --res-dir results
```
- `--model-name` می‌تواند `zipvoice_dialog` یا `zipvoice_dialog_stereo` باشد،
    که به ترتیب دیالوگ‌های مونو و استریو تولید می‌کنند.

#### 2.2 فرمت‌های ورودی

هر خط از فایل `test.tsv` یکی از فرمت‌های زیر را دارد:

(1) **فرمت پرامپت ادغام‌شده** که در آن صداها و رونوشت‌های دو گوینده در یک فایل صوتی پرامپت ترکیب شده‌اند:

```
{wav_name}\t{prompt_transcription}\t{prompt_wav}\t{text}
```
- `wav_name` نام فایل خروجی wav است.
- `prompt_transcription` رونویسی از فایل صوتی مکالمه‌ای prompt است، برای مثال، "[S1] سلام. [S2] حالت چطوره؟"
- `prompt_wav` مسیر فایل صوتی prompt است.
- `text` متنی است که باید سنتز شود، برای مثال، "[S1] من خوبم. [S2] اسمت چیه؟"

(2) **فرمت prompt تفکیک‌شده** که در آن فایل‌های صوتی و رونویسی دو گوینده در فایل‌های جداگانه وجود دارند:


```
{wav_name}\t{spk1_prompt_transcription}\t{spk2_prompt_transcription}\t{spk1_prompt_wav}\t{spk2_prompt_wav}\t{text}'
```
- `wav_name` نام فایل wav خروجی است.
- `spk1_prompt_transcription` متن رونویسی شده از فایل wav نمونه‌گوی گوینده اول است، مثلاً "سلام"
- `spk2_prompt_transcription` متن رونویسی شده از فایل wav نمونه‌گوی گوینده دوم است، مثلاً "حالت چطوره؟"
- `spk1_prompt_wav` مسیر فایل wav نمونه‌گوی گوینده اول است.
- `spk2_prompt_wav` مسیر فایل wav نمونه‌گوی گوینده دوم است.
- `text` متنی است که باید سنتز شود، مثلاً "[S1] من خوبم. [S2] اسم شما چیست؟"

### ۳. سایر قابلیت‌ها

#### ۳.۱ اصلاح تلفظ اشتباه حروف چندآوایی چینی

ما از [pypinyin](https://github.com/mozillazg/python-pinyin) برای تبدیل کاراکترهای چینی به پین‌یین استفاده می‌کنیم. با این حال، گاهی اوقات **حروف چندآوایی** (多音字) را اشتباه تلفظ می‌کند.

برای اصلاح دستی این تلفظ‌های اشتباه، پین‌یین **اصلاح‌شده** را درون براکت زاویه‌دار `< >` قرار دهید و **علامت نغمه** را نیز اضافه کنید.

**مثال:**

- متن اصلی: `这把剑长三十公分`
- اصلاح پین‌یین `长`:  `这把剑<chang2>三十公分`

> **توجه:** اگر می‌خواهید چند پین‌یین را به صورت دستی اختصاص دهید، هر پین‌یین را با `<>` جدا کنید، مثلاً: `这把<jian4><chang2><san1>十公分`

## آموزش مدل اختصاصی خودتان

برای مثال‌های آموزش و تنظیم دقیق به پوشه [egs](egs) مراجعه کنید.

## بحث و ارتباط

می‌توانید مستقیماً در [Github Issues](https://github.com/k2-fsa/ZipVoice/issues) گفتگو کنید.

همچنین می‌توانید کد QR را اسکن کنید تا به گروه وی‌چت ما بپیوندید یا حساب رسمی ما در وی‌چت را دنبال کنید.

| گروه وی‌چت | حساب رسمی وی‌چت |
| ------------ | ----------------------- |
|![wechat](https://k2-fsa.org/zh-CN/assets/pic/wechat_group.jpg) |![wechat](https://k2-fsa.org/zh-CN/assets/pic/wechat_account.jpg) |

## استناد


```bibtex
@article{zhu2025zipvoice,
      title={ZipVoice: Fast and High-Quality Zero-Shot Text-to-Speech with Flow Matching},
      author={Zhu, Han and Kang, Wei and Yao, Zengwei and Guo, Liyong and Kuang, Fangjun and Li, Zhaoqing and Zhuang, Weiji and Lin, Long and Povey, Daniel},
      journal={arXiv preprint arXiv:2506.13053},
      year={2025}
}

@article{zhu2025zipvoicedialog,
      title={ZipVoice-Dialog: Non-Autoregressive Spoken Dialogue Generation with Flow Matching},
      author={Zhu, Han and Kang, Wei and Guo, Liyong and Yao, Zengwei and Kuang, Fangjun and Zhuang, Weiji and Li, Zhaoqing and Han, Zhifeng and Zhang, Dong and Zhang, Xin and Song, Xingchen and Lin, Long and Povey, Daniel},
      journal={arXiv preprint arXiv:2507.09318},
      year={2025}
}
```
<translate-content></translate-content>

---

Tranlated By [Open Ai Tx](https://github.com/OpenAiTx/OpenAiTx) | Last indexed: 2025-07-17

---