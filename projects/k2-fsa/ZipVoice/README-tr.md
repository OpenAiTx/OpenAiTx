
<div align="right">
  <details>
    <summary >ğŸŒ Dil</summary>
    <div>
      <div align="center">
        <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=en">English</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=zh-CN">ç®€ä½“ä¸­æ–‡</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=zh-TW">ç¹é«”ä¸­æ–‡</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ja">æ—¥æœ¬èª</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ko">í•œêµ­ì–´</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=hi">à¤¹à¤¿à¤¨à¥à¤¦à¥€</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=th">à¹„à¸—à¸¢</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=fr">FranÃ§ais</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=de">Deutsch</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=es">EspaÃ±ol</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=it">Itapano</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ru">Ğ ÑƒÑÑĞºĞ¸Ğ¹</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=pt">PortuguÃªs</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=nl">Nederlands</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=pl">Polski</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ar">Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=fa">ÙØ§Ø±Ø³ÛŒ</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=tr">TÃ¼rkÃ§e</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=vi">Tiáº¿ng Viá»‡t</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=id">Bahasa Indonesia</a>
      </div>
    </div>
  </details>
</div>

<div align="center">

# ZipVoiceâš¡

## Flow Matching ile HÄ±zlÄ± ve YÃ¼ksek Kaliteli SÄ±fÄ±rdan Metinden Sese DÃ¶nÃ¼ÅŸÃ¼m
</div>

## Genel BakÄ±ÅŸ

ZipVoice, flow matching tabanlÄ± hÄ±zlÄ± ve yÃ¼ksek kaliteli sÄ±fÄ±r atÄ±ÅŸlÄ± TTS modellerinden oluÅŸan bir seridir.

### 1. Temel Ã–zellikler

- KÃ¼Ã§Ã¼k ve hÄ±zlÄ±: yalnÄ±zca 123M parametre.

- YÃ¼ksek kaliteli ses klonlama: konuÅŸmacÄ± benzerliÄŸi, anlaÅŸÄ±labilirlik ve doÄŸallÄ±kta alanÄ±nda Ã¶ncÃ¼ performans.

- Ã‡ok dilli: Ã‡ince ve Ä°ngilizce desteÄŸi.

- Ã‡ok modlu: hem tek konuÅŸmacÄ±lÄ± hem de diyalog konuÅŸmasÄ± Ã¼retimini destekler.

### 2. Model varyantlarÄ±

<table>
  <thead>
    <tr>
      <th>Model AdÄ±</th>
      <th>AÃ§Ä±klama</th>
      <th>Makale</th>
      <th>Demo</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>ZipVoice</td>
      <td>Ã‡ince ve Ä°ngilizce'de sÄ±fÄ±r atÄ±ÅŸlÄ± tek konuÅŸmacÄ±lÄ± TTS'yi destekleyen temel model.</td>
      <td rowspan="2"><a href="https://arxiv.org/abs/2506.13053"><img src="https://img.shields.io/badge/arXiv-Makale-COLOR.svg"></a></td>
      <td rowspan="2"><a href="https://zipvoice.github.io"><img src="https://img.shields.io/badge/GitHub.io-Demo_SayfasÄ±-blue?logo=Github&style=flat-square"></a></td>
    </tr>
    <tr>
      <td>ZipVoice-Distill</td>
      <td>ZipVoiceâ€™un damÄ±tÄ±lmÄ±ÅŸ sÃ¼rÃ¼mÃ¼; minimum performans kaybÄ±yla geliÅŸtirilmiÅŸ hÄ±z sunar.</td>
    </tr>
    <tr>
      <td>ZipVoice-Dialog</td>
      <td>ZipVoice Ã¼zerine kurulu, tek kanallÄ± iki taraflÄ± konuÅŸma diyaloglarÄ± Ã¼retebilen bir diyalog Ã¼retim modeli.</td>
      <td rowspan="2"><a href="https://arxiv.org/abs/2507.09318"><img src="https://img.shields.io/badge/arXiv-Makale-COLOR.svg"></a></td>
      <td rowspan="2"><a href="https://zipvoice-dialog.github.io"><img src="https://img.shields.io/badge/GitHub.io-Demo_SayfasÄ±-blue?logo=Github&style=flat-square"></a></td>
    </tr>
    <tr>
      <td>ZipVoice-Dialog-Stereo</td>
      <td>ZipVoice-Dialog'Ä±n stereo varyantÄ±, her konuÅŸmacÄ±nÄ±n ayrÄ± bir kanala atanmasÄ±yla iki kanallÄ± diyalog Ã¼retimini saÄŸlar.</td>
    </tr>
  </tbody>
</table>

## Haberler

**2025/07/14**: **ZipVoice-Dialog** ve **ZipVoice-Dialog-Stereo**, iki konuÅŸma diyalogu Ã¼retim modeli yayÄ±nlandÄ±. [![arXiv](https://img.shields.io/badge/arXiv-Paper-COLOR.svg)](https://arxiv.org/abs/2507.09318) [![demo page](https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square)](https://zipvoice-dialog.github.io)

**2025/07/14**: **OpenDialog** veri seti, 6.8k saatlik konuÅŸma diyalogu veri seti yayÄ±nlandÄ±. Ä°ndir: [![hf](https://img.shields.io/badge/%F0%9F%A4%97%20HuggingFace-Dataset-yellow)](https://huggingface.co/datasets/k2-fsa/OpenDialog), [![ms](https://img.shields.io/badge/ModelScope-Dataset-blue?logo=data)](https://www.modelscope.cn/datasets/k2-fsa/OpenDialog). Detaylara bakÄ±nÄ±z: [![arXiv](https://img.shields.io/badge/arXiv-Paper-COLOR.svg)](https://arxiv.org/abs/2507.09318).

**2025/06/16**: **ZipVoice** ve **ZipVoice-Distill** yayÄ±nlandÄ±. [![arXiv](https://img.shields.io/badge/arXiv-Paper-COLOR.svg)](https://arxiv.org/abs/2506.13053) [![demo page](https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square)](https://zipvoice.github.io)

## Kurulum

### 1. ZipVoice deposunu klonlayÄ±n

```bash
git clone https://github.com/k2-fsa/ZipVoice.git
```
### 2. (Ä°steÄŸe baÄŸlÄ±) Bir Python sanal ortamÄ± oluÅŸturun


```bash
python3 -m venv zipvoice
source zipvoice/bin/activate
```
### 3. Gerekli paketleri yÃ¼kleyin


```bash
pip install -r requirements.txt
```
### 4. EÄŸitim veya verimli Ã§Ä±karÄ±m iÃ§in k2'yi kurun

**k2 eÄŸitim iÃ§in gereklidir** ve Ã§Ä±karÄ±mÄ± hÄ±zlandÄ±rabilir. Yine de, k2 yÃ¼klemeden ZipVoice'Ä±n Ã§Ä±karÄ±m modunu kullanabilirsiniz.

> **Not:**  KullandÄ±ÄŸÄ±nÄ±z PyTorch ve CUDA sÃ¼rÃ¼mÃ¼ne uygun k2 sÃ¼rÃ¼mÃ¼nÃ¼ kurduÄŸunuzdan emin olun. Ã–rneÄŸin, eÄŸer pytorch 2.5.1 ve CUDA 12.1 kullanÄ±yorsanÄ±z, k2'yi ÅŸu ÅŸekilde kurabilirsiniz:


```bash
pip install k2==1.24.4.dev20250208+cuda12.1.torch2.5.1 -f https://k2-fsa.github.io/k2/cuda.html
```
LÃ¼tfen ayrÄ±ntÄ±lar iÃ§in https://k2-fsa.org/get-started/k2/ adresine bakÄ±nÄ±z.
Ã‡in anakarasÄ±ndaki kullanÄ±cÄ±lar https://k2-fsa.org/zh-CN/get-started/k2/ adresine baÅŸvurabilirler.

- k2 kurulumunu kontrol etmek iÃ§in:


```bash
python3 -c "import k2; print(k2.__file__)"
```
## KullanÄ±m

### 1. Tek konuÅŸmacÄ±lÄ± konuÅŸma Ã¼retimi

Ã–nceden eÄŸitilmiÅŸ ZipVoice veya ZipVoice-Distill modellerimizle tek konuÅŸmacÄ±lÄ± konuÅŸma Ã¼retmek iÃ§in aÅŸaÄŸÄ±daki komutlarÄ± kullanÄ±n (Gerekli modeller HuggingFace Ã¼zerinden indirilecektir):

#### 1.1 Tek bir cÃ¼mlenin Ã§Ä±karÄ±mÄ±


```bash
python3 -m zipvoice.bin.infer_zipvoice \
    --model-name zipvoice \
    --prompt-wav prompt.wav \
    --prompt-text "I am the transcription of the prompt wav." \
    --text "I am the text to be synthesized." \
    --res-wav-path result.wav
```
- `--model-name` deÄŸeri `zipvoice` veya `zipvoice_distill` olabilir; bunlar sÄ±rasÄ±yla distilasyon Ã¶ncesi ve sonrasÄ± modellerdir.
- EÄŸer metinde `<>` veya `[]` gÃ¶rÃ¼nÃ¼rse, bunlar arasÄ±ndaki dizeler Ã¶zel belirteÃ§ler olarak kabul edilir. `<>` Ã‡in pinyin'ini, `[]` ise diÄŸer Ã¶zel etiketleri ifade eder.

#### 1.2 Bir cÃ¼mle listesinin Ã§Ä±karÄ±mÄ±

```bash
python3 -m zipvoice.bin.infer_zipvoice \
    --model-name zipvoice \
    --test-list test.tsv \
    --res-dir results
```
- `test.tsv` dosyasÄ±nÄ±n her satÄ±rÄ± `{wav_name}\t{prompt_transcription}\t{prompt_wav}\t{text}` formatÄ±ndadÄ±r.

### 2. Diyalog konuÅŸma Ã¼retimi

#### 2.1 Ã‡Ä±karÄ±m komutu

Ã–nceden eÄŸitilmiÅŸ ZipVoice-Dialogue veya ZipVoice-Dialogue-Stereo modellerimizle iki taraflÄ± konuÅŸmalÄ± diyaloglar Ã¼retmek iÃ§in aÅŸaÄŸÄ±daki komutlarÄ± kullanÄ±n (Gerekli modeller HuggingFace Ã¼zerinden indirilecektir):


```bash
python3 -m zipvoice.bin.infer_zipvoice_dialog \
    --model-name "zipvoice_dialog" \
    --test-list test.tsv \
    --res-dir results
```
- `--model-name` `zipvoice_dialog` veya `zipvoice_dialog_stereo` olabilir,
    sÄ±rasÄ±yla mono ve stereo diyaloglar Ã¼retir.

#### 2.2 Girdi formatlarÄ±

`test.tsv` dosyasÄ±ndaki her satÄ±r aÅŸaÄŸÄ±daki formatlardan birindedir:

(1) **BirleÅŸtirilmiÅŸ istem formatÄ±**: Ä°ki konuÅŸmacÄ±nÄ±n sesleri ve transkriptleri tek bir istem wav dosyasÄ±nda birleÅŸtirilir:

```
{wav_name}\t{prompt_transcription}\t{prompt_wav}\t{text}
```

- `wav_name`, Ã§Ä±ktÄ± wav dosyasÄ±nÄ±n adÄ±dÄ±r.
- `prompt_transcription`, konuÅŸma istemi wav dosyasÄ±nÄ±n transkripsiyonudur, Ã¶rneÄŸin, "[S1] Merhaba. [S2] NasÄ±lsÄ±n?"
- `prompt_wav`, istem wav dosyasÄ±nÄ±n yoludur.
- `text`, sentezlenecek metindir, Ã¶rneÄŸin, "[S1] Ä°yiyim. [S2] AdÄ±n ne? [S1] Ben Eric. [S2] Merhaba Eric."

(2) **BÃ¶lÃ¼nmÃ¼ÅŸ istem formatÄ±**: iki konuÅŸmacÄ±nÄ±n sesleri ve transkripsiyonlarÄ± ayrÄ± dosyalarda bulunur:

```
{wav_name}\t{spk1_prompt_transcription}\t{spk2_prompt_transcription}\t{spk1_prompt_wav}\t{spk2_prompt_wav}\t{text}
```
- `wav_name`, Ã§Ä±ktÄ± wav dosyasÄ±nÄ±n adÄ±dÄ±r.
- `spk1_prompt_transcription`, birinci konuÅŸmacÄ±nÄ±n istem wav dosyasÄ±nÄ±n transkripsiyonudur, Ã¶rn. "Merhaba"
- `spk2_prompt_transcription`, ikinci konuÅŸmacÄ±nÄ±n istem wav dosyasÄ±nÄ±n transkripsiyonudur, Ã¶rn. "NasÄ±lsÄ±n?"
- `spk1_prompt_wav`, birinci konuÅŸmacÄ±nÄ±n istem wav dosyasÄ±nÄ±n yoludur.
- `spk2_prompt_wav`, ikinci konuÅŸmacÄ±nÄ±n istem wav dosyasÄ±nÄ±n yoludur.
- `text`, sentezlenecek metindir, Ã¶rn. "[S1] Ä°yiyim. [S2] AdÄ±n ne? [S1] Ben Eric. [S2] Merhaba Eric."

### 3 Daha iyi kullanÄ±m iÃ§in rehberlik:

#### 3.1 Ä°stem uzunluÄŸu

Daha hÄ±zlÄ± Ã§Ä±karÄ±m hÄ±zÄ± iÃ§in kÄ±sa bir istem wav dosyasÄ± Ã¶neriyoruz (Ã¶rn., tek konuÅŸmacÄ±lÄ± konuÅŸma Ã¼retimi iÃ§in 3 saniyeden az, diyalog konuÅŸma Ã¼retimi iÃ§in 10 saniyeden az). Ã‡ok uzun bir istem, Ã§Ä±karÄ±mÄ± yavaÅŸlatÄ±r ve konuÅŸma kalitesini dÃ¼ÅŸÃ¼rÃ¼r.

#### 3.2 HÄ±z optimizasyonu

Ã‡Ä±karÄ±m hÄ±zÄ± tatmin edici deÄŸilse, aÅŸaÄŸÄ±daki ÅŸekilde hÄ±zlandÄ±rabilirsiniz:

- **Distil model ve daha az adÄ±m**: Tek konuÅŸmacÄ±lÄ± konuÅŸma Ã¼retim modeli iÃ§in, daha iyi konuÅŸma kalitesi iÃ§in varsayÄ±lan olarak `zipvoice` modelini kullanÄ±yoruz. EÄŸer hÄ±z Ã¶nceliÄŸinizse, `zipvoice_distill` modeline geÃ§ebilir ve `--num-steps` deÄŸerini varsayÄ±lan 8â€™den 4â€™e kadar dÃ¼ÅŸÃ¼rebilirsiniz.

- **CPUâ€™da Ã§oklu iÅŸ parÃ§acÄ±ÄŸÄ± ile hÄ±zlandÄ±rma**: CPUâ€™da Ã§alÄ±ÅŸtÄ±rÄ±rken, daha hÄ±zlÄ± bir hÄ±z iÃ§in `--num-thread` parametresiyle (Ã¶rn., `--num-thread 4`) iÅŸ parÃ§acÄ±ÄŸÄ± sayÄ±sÄ±nÄ± artÄ±rabilirsiniz. VarsayÄ±lan olarak 1 iÅŸ parÃ§acÄ±ÄŸÄ± kullanÄ±yoruz.

- **CPUâ€™da ONNX ile hÄ±zlandÄ±rma**: CPUâ€™da Ã§alÄ±ÅŸÄ±rken, daha hÄ±zlÄ± bir hÄ±z iÃ§in ONNX modellerini `zipvoice.bin.infer_zipvoice_onnx` ile kullanabilirsiniz (henÃ¼z diyalog Ã¼retim modelleri iÃ§in ONNX desteklenmiyor). Daha da hÄ±zlÄ± bir hÄ±z iÃ§in `--onnx-int8 True` ayarlayarak INT8-kuantize ONNX modeli kullanabilirsiniz. Kuantize modelin konuÅŸma kalitesinde belli bir dÃ¼ÅŸÃ¼ÅŸe neden olacaÄŸÄ±nÄ± unutmayÄ±n. **ONNXâ€™i GPUâ€™da kullanmayÄ±n**, Ã§Ã¼nkÃ¼ GPUâ€™da PyTorchâ€™tan daha yavaÅŸtÄ±r.

- **NVIDIA TensorRT ile GPU HÄ±zlandÄ±rma**: NVIDIA GPUâ€™larda Ã¶nemli bir performans artÄ±ÅŸÄ± iÃ§in, Ã¶nce modeli zipvoice.bin.tensorrt_export kullanarak bir TensorRT motoruna aktarÄ±n. ArdÄ±ndan, veri kÃ¼meniz Ã¼zerinde (Ã¶rn., bir Hugging Face veri kÃ¼mesi) zipvoice.bin.infer_zipvoice ile Ã§Ä±karÄ±m Ã§alÄ±ÅŸtÄ±rÄ±n. Bu, GPUâ€™da standart PyTorch uygulamasÄ±na gÃ¶re yaklaÅŸÄ±k 2 kat daha fazla verim saÄŸlayabilir.

#### 3.3 Bellek kontrolÃ¼

Verilen metin, noktalama iÅŸaretlerine (tek konuÅŸmacÄ±lÄ± konuÅŸma Ã¼retimi iÃ§in) veya konuÅŸmacÄ± deÄŸiÅŸim sembolÃ¼ne (diyalog konuÅŸma Ã¼retimi iÃ§in) gÃ¶re parÃ§alara ayrÄ±lacaktÄ±r. Sonra, parÃ§alara ayrÄ±lan metinler toplu halde iÅŸlenecektir. Bu nedenle, model neredeyse sabit bellek kullanÄ±mÄ±yla rastgele uzunluktaki metni iÅŸleyebilir. Bellek kullanÄ±mÄ±nÄ± `--max-duration` parametresiyle ayarlayabilirsiniz.

#### 3.4 "Ham" deÄŸerlendirme

VarsayÄ±lan olarak, verimli Ã§Ä±karÄ±m ve daha iyi performans iÃ§in girdileri (istem wav, istem transkripsiyonu ve metin) Ã¶n iÅŸleme tabi tutuyoruz. Modelin tam olarak verilen girdilerle ("ham" performansÄ±nÄ±) deÄŸerlendirmek isterseniz (Ã¶rn., makalemizdeki sonuÃ§larÄ± Ã§oÄŸaltmak iÃ§in), `--raw-evaluation True` parametresini geÃ§ebilirsiniz.

#### 3.5 KÄ±sa metin

Ã‡ok kÄ±sa metinler iÃ§in konuÅŸma Ã¼retirken (Ã¶rn., bir ya da iki kelime), Ã¼retilen konuÅŸma bazen bazÄ± telaffuzlarÄ± atlayabilir. Bu sorunu Ã§Ã¶zmek iÃ§in, `--speed 0.3` (0.3 ayarlanabilir bir deÄŸerdir) parametresiyle Ã¼retilen konuÅŸmanÄ±n sÃ¼resini uzatabilirsiniz.

#### 3.6 YanlÄ±ÅŸ telaffuz edilen Ã‡ince polifon karakterlerin dÃ¼zeltilmesi


Ã‡ince karakterleri pinyinâ€™e dÃ¶nÃ¼ÅŸtÃ¼rmek iÃ§in [pypinyin](https://github.com/mozillazg/python-pinyin) kullanÄ±yoruz. Ancak bazen **Ã§ok sesli karakterleri** (å¤šéŸ³å­—) yanlÄ±ÅŸ telaffuz edebilir.

Bu yanlÄ±ÅŸ telaffuzlarÄ± elle dÃ¼zeltmek iÃ§in, **dÃ¼zeltilmiÅŸ pinyinâ€™i** kÃ¶ÅŸeli parantezler `< >` iÃ§ine alÄ±n ve **ton iÅŸaretini** ekleyin.

**Ã–rnek:**

- Orijinal metin: `è¿™æŠŠå‰‘é•¿ä¸‰åå…¬åˆ†`
- `é•¿` karakterinin pinyinâ€™ini dÃ¼zeltin:  `è¿™æŠŠå‰‘<chang2>ä¸‰åå…¬åˆ†`

> **Not:** Birden fazla pinyinâ€™i elle atamak isterseniz, her pinyinâ€™i `<>` ile Ã§evreleyin, Ã¶rn: `è¿™æŠŠ<jian4><chang2><san1>åå…¬åˆ†`

#### 3.7 OluÅŸturulan konuÅŸmadan uzun sessizlikleri kaldÄ±rma

Model, oluÅŸturulan konuÅŸmadaki sessizliklerin yerini ve uzunluÄŸunu otomatik olarak belirler. Bazen konuÅŸmanÄ±n ortasÄ±nda uzun bir sessizlik olabilir. Bunu istemiyorsanÄ±z, oluÅŸturulan konuÅŸmanÄ±n ortasÄ±ndaki uzun sessizlikleri kaldÄ±rmak iÃ§in `--remove-long-sil` komutunu kullanabilirsiniz (kenar sessizlikleri varsayÄ±lan olarak kaldÄ±rÄ±lÄ±r).

#### 3.8 Model indirme

Ã–nceden eÄŸitilmiÅŸ modelleri indirirken HuggingFaceâ€™e baÄŸlanmada sorun yaÅŸarsanÄ±z, uÃ§ noktayÄ± yansÄ± (mirror) siteye geÃ§irmeyi deneyin: `export HF_ENDPOINT=https://hf-mirror.com`.

## Kendi Modelinizi EÄŸitin

EÄŸitim, ince ayar ve deÄŸerlendirme Ã¶rnekleri iÃ§in [egs](egs) dizinine bakÄ±n.

## Ãœretim OrtamÄ±nda KullanÄ±m

### NVIDIA Triton GPU Ã‡alÄ±ÅŸma ZamanÄ±

YÃ¼ksek performans ve Ã¶lÃ§eklenebilir Ã¼retim daÄŸÄ±tÄ±mÄ± iÃ§in, optimize edilmiÅŸ TensorRT motorlarÄ±, eÅŸzamanlÄ± istek iÅŸleme ve kurumsal kullanÄ±m iÃ§in gRPC/HTTP APIâ€™leri saÄŸlayan [Triton Inference Server entegrasyonuna](runtime/nvidia_triton/) gÃ¶z atÄ±n.

### CPU DaÄŸÄ±tÄ±mÄ±

CPU Ã¼zerinde C++ ile daÄŸÄ±tÄ±m Ã§Ã¶zÃ¼mÃ¼ iÃ§in [sherpa-onnx](https://github.com/k2-fsa/sherpa-onnx/pull/2487#issuecomment-3227884498) inceleyin.

## TartÄ±ÅŸma ve Ä°letiÅŸim

DoÄŸrudan [Github Issues](https://github.com/k2-fsa/ZipVoice/issues) Ã¼zerinden tartÄ±ÅŸabilirsiniz.

AyrÄ±ca QR kodunu tarayarak WeChat grubumuza katÄ±labilir veya WeChat resmi hesabÄ±mÄ±zÄ± takip edebilirsiniz.

| Wechat Grubu | Wechat Resmi HesabÄ± |
| ------------ | ----------------------- |
|![wechat](https://k2-fsa.org/zh-CN/assets/pic/wechat_group.jpg) |![wechat](https://k2-fsa.org/zh-CN/assets/pic/wechat_account.jpg) |

## AtÄ±f

```bibtex
@article{zhu2025zipvoice,
      title={ZipVoice: Fast and High-Quality Zero-Shot Text-to-Speech with Flow Matching},
      author={Zhu, Han and Kang, Wei and Yao, Zengwei and Guo, Liyong and Kuang, Fangjun and Li, Zhaoqing and Zhuang, Weiji and Lin, Long and Povey, Daniel},
      journal={arXiv preprint arXiv:2506.13053},
      year={2025}
}

@article{zhu2025zipvoicedialog,
      title={ZipVoice-Dialog: Non-Autoregressive Spoken Dialogue Generation with Flow Matching},
      author={Zhu, Han and Kang, Wei and Guo, Liyong and Yao, Zengwei and Kuang, Fangjun and Zhuang, Weiji and Li, Zhaoqing and Han, Zhifeng and Zhang, Dong and Zhang, Xin and Song, Xingchen and Lin, Long and Povey, Daniel},
      journal={arXiv preprint arXiv:2507.09318},
      year={2025}
}
```




---

Tranlated By [Open Ai Tx](https://github.com/OpenAiTx/OpenAiTx) | Last indexed: 2025-12-30

---