<div align="right">
  <details>
    <summary >ğŸŒ JÄ™zyk</summary>
    <div>
      <div align="center">
        <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=en">English</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=zh-CN">ç®€ä½“ä¸­æ–‡</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=zh-TW">ç¹é«”ä¸­æ–‡</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ja">æ—¥æœ¬èª</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ko">í•œêµ­ì–´</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=hi">à¤¹à¤¿à¤¨à¥à¤¦à¥€</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=th">à¹„à¸—à¸¢</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=fr">FranÃ§ais</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=de">Deutsch</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=es">EspaÃ±ol</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=it">Itapano</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ru">Ğ ÑƒÑÑĞºĞ¸Ğ¹</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=pt">PortuguÃªs</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=nl">Nederlands</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=pl">Polski</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ar">Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=fa">ÙØ§Ø±Ø³ÛŒ</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=tr">TÃ¼rkÃ§e</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=vi">Tiáº¿ng Viá»‡t</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=id">Bahasa Indonesia</a>
      </div>
    </div>
  </details>
</div>

<div align="center">

# ZipVoiceâš¡

## Szybki i Wysokiej JakoÅ›ci Zero-Shot Text-to-Speech z Flow Matching
</div>

## PrzeglÄ…d

ZipVoice to seria szybkich i wysokiej jakoÅ›ci modeli zero-shot TTS opartych na flow matching.

### 1. NajwaÅ¼niejsze cechy

- MaÅ‚y i szybki: tylko 123M parametrÃ³w.

- Wysokiej jakoÅ›ci klonowanie gÅ‚osu: najnowoczeÅ›niejsza wydajnoÅ›Ä‡ w zakresie podobieÅ„stwa gÅ‚osu, zrozumiaÅ‚oÅ›ci i naturalnoÅ›ci.

- WielojÄ™zyczny: obsÅ‚uga jÄ™zyka chiÅ„skiego i angielskiego.

- Tryb wielofunkcyjny: obsÅ‚uga generowania mowy jednoosobowej oraz dialogÃ³w.

### 2. Warianty modelu

<table>
  <thead>
    <tr>
      <th>Nazwa modelu</th>
      <th>Opis</th>
      <th>ArtykuÅ‚</th>
      <th>Demo</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>ZipVoice</td>
      <td>Podstawowy model wspierajÄ…cy zero-shot TTS jednoosobowy w jÄ™zyku chiÅ„skim i angielskim.</td>
      <td rowspan="2"><a href="https://arxiv.org/abs/2506.13053"><img src="https://img.shields.io/badge/arXiv-Paper-COLOR.svg"></a></td>
      <td rowspan="2"><a href="https://zipvoice.github.io"><img src="https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square"></a></td>
    </tr>
    <tr>
      <td>ZipVoice-Distill</td>
      <td>Wersja destylowana ZipVoice, zapewniajÄ…ca zwiÄ™kszonÄ… szybkoÅ›Ä‡ przy minimalnej utracie wydajnoÅ›ci.</td>
    </tr>
    <tr>
      <td>ZipVoice-Dialog</td>
      <td>Model generowania dialogÃ³w oparty na ZipVoice, zdolny do generowania jednoÅ›cieÅ¼kowych rozmÃ³w dwuosobowych.</td>
      <td rowspan="2"><a href="https://arxiv.org/abs/2507.09318"><img src="https://img.shields.io/badge/arXiv-Paper-COLOR.svg"></a></td>
      <td rowspan="2"><a href="https://zipvoice-dialog.github.io"><img src="https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square"></a></td>
    </tr>
    <tr>
      <td>ZipVoice-Dialog-Stereo</td>
      <td>Wariant stereo ZipVoice-Dialog, umoÅ¼liwiajÄ…cy generowanie dwukanaÅ‚owych dialogÃ³w, gdzie kaÅ¼dy mÃ³wca jest przypisany do osobnego kanaÅ‚u.</td>
    </tr>
  </tbody>
</table>

## AktualnoÅ›ci

**2025/07/14**: **ZipVoice-Dialog** oraz **ZipVoice-Dialog-Stereo**, dwa modele generowania mÃ³wionych dialogÃ³w, zostaÅ‚y wydane. [![arXiv](https://img.shields.io/badge/arXiv-Paper-COLOR.svg)](https://arxiv.org/abs/2507.09318) [![demo page](https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square)](https://zipvoice-dialog.github.io)

**2025/07/14**: Zestaw danych **OpenDialog**, 6,8 tys. godzin nagraÅ„ dialogÃ³w mÃ³wionych, zostaÅ‚ wydany. Pobierz z [![hf](https://img.shields.io/badge/%F0%9F%A4%97%20HuggingFace-Dataset-yellow)](https://huggingface.co/datasets/k2-fsa/OpenDialog), [![ms](https://img.shields.io/badge/ModelScope-Dataset-blue?logo=data)](https://www.modelscope.cn/datasets/k2-fsa/OpenDialog). SzczegÃ³Å‚y na [![arXiv](https://img.shields.io/badge/arXiv-Paper-COLOR.svg)](https://arxiv.org/abs/2507.09318).

**2025/06/16**: **ZipVoice** oraz **ZipVoice-Distill** zostaÅ‚y wydane. [![arXiv](https://img.shields.io/badge/arXiv-Paper-COLOR.svg)](https://arxiv.org/abs/2506.13053) [![demo page](https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square)](https://zipvoice.github.io)

## Instalacja

### 1. Sklonuj repozytorium ZipVoice


```bash
git clone https://github.com/k2-fsa/ZipVoice.git
```
### 2. (Opcjonalnie) UtwÃ³rz wirtualne Å›rodowisko Pythona


```bash
python3 -m venv zipvoice
source zipvoice/bin/activate
```
### 3. Zainstaluj wymagane pakiety


```bash
pip install -r requirements.txt
```
### 4. Zainstaluj k2 do treningu lub wydajnego wnioskowania

**k2 jest niezbÄ™dne do treningu** i moÅ¼e przyspieszyÄ‡ wnioskowanie. Niemniej jednak, moÅ¼esz korzystaÄ‡ z trybu wnioskowania ZipVoice bez instalowania k2.

> **Uwaga:** Upewnij siÄ™, Å¼e instalujesz wersjÄ™ k2 pasujÄ…cÄ… do Twojej wersji PyTorch i CUDA. Na przykÅ‚ad, jeÅ›li uÅ¼ywasz pytorch 2.5.1 i CUDA 12.1, moÅ¼esz zainstalowaÄ‡ k2 w nastÄ™pujÄ…cy sposÃ³b:


```bash
pip install k2==1.24.4.dev20250208+cuda12.1.torch2.5.1 -f https://k2-fsa.github.io/k2/cuda.html
```
ProszÄ™ zapoznaÄ‡ siÄ™ ze stronÄ… https://k2-fsa.org/get-started/k2/ po szczegÃ³Å‚y.
UÅ¼ytkownicy z Chin kontynentalnych mogÄ… zapoznaÄ‡ siÄ™ ze stronÄ… https://k2-fsa.org/zh-CN/get-started/k2/.

- Aby sprawdziÄ‡ instalacjÄ™ k2:


```
python3 -c "import k2; print(k2.__file__)"
```
## UÅ¼ytkowanie

### 1. Generowanie mowy jednego mÃ³wcy

Aby wygenerowaÄ‡ mowÄ™ jednego mÃ³wcy przy uÅ¼yciu naszych wytrenowanych modeli ZipVoice lub ZipVoice-Distill, uÅ¼yj nastÄ™pujÄ…cych poleceÅ„ (wymagane modele zostanÄ… pobrane z HuggingFace):

#### 1.1 Wnioskowanie dla pojedynczego zdania


```bash
python3 -m zipvoice.bin.infer_zipvoice \
    --model-name zipvoice \
    --prompt-wav prompt.wav \
    --prompt-text "I am the transcription of the prompt wav." \
    --text "I am the text to be synthesized." \
    --res-wav-path result.wav
```
- `--model-name` moÅ¼e przyjmowaÄ‡ wartoÅ›ci `zipvoice` lub `zipvoice_distill`, ktÃ³re oznaczajÄ… modele odpowiednio przed i po destylacji.
- JeÅ›li w tekÅ›cie pojawiÄ… siÄ™ `<>` lub `[]`, ciÄ…gi znakÃ³w objÄ™te tymi znakami bÄ™dÄ… traktowane jako specjalne tokeny. `<>` oznacza chiÅ„skie pinyin, a `[]` oznacza inne specjalne tagi.
- Modele ONNX moÅ¼na uruchamiaÄ‡ szybciej na CPU za pomocÄ… `zipvoice.bin.infer_zipvoice_onnx`.

> **Uwaga:** JeÅ›li masz problemy z poÅ‚Ä…czeniem z HuggingFace, sprÃ³buj:
> ```bash
> export HF_ENDPOINT=https://hf-mirror.com
> ```

#### 1.2 Wnioskowanie dla listy zdaÅ„


```bash
python3 -m zipvoice.bin.infer_zipvoice \
    --model-name zipvoice \
    --test-list test.tsv \
    --res-dir results
```
- KaÅ¼da linia pliku `test.tsv` ma format `{wav_name}\t{prompt_transcription}\t{prompt_wav}\t{text}`.

### 2. Generowanie mowy dialogowej

#### 2.1 Polecenie inferencji

Aby wygenerowaÄ‡ dwuosobowe dialogi mÃ³wione za pomocÄ… naszych wytrenowanych modeli ZipVoice-Dialogue lub ZipVoice-Dialogue-Stereo, uÅ¼yj nastÄ™pujÄ…cych poleceÅ„ (Wymagane modele zostanÄ… pobrane z HuggingFace):


```bash
python3 -m zipvoice.bin.infer_zipvoice_dialog \
    --model-name "zipvoice_dialog" \
    --test-list test.tsv \
    --res-dir results
```
- `--model-name` moÅ¼e przyjmowaÄ‡ wartoÅ›ci `zipvoice_dialog` lub `zipvoice_dialog_stereo`,
    ktÃ³re generujÄ… odpowiednio dialogi mono i stereo.

#### 2.2 Format wejÅ›ciowy

KaÅ¼da linia w pliku `test.tsv` ma jeden z poniÅ¼szych formatÃ³w:

(1) **Format scalonej podpowiedzi**, gdzie nagrania audio i transkrypcje dwÃ³ch mÃ³wcÃ³w sÄ… scalone w jeden plik wav z podpowiedziÄ…:

```
{wav_name}\t{prompt_transcription}\t{prompt_wav}\t{text}
```
- `wav_name` to nazwa wyjÅ›ciowego pliku wav.
- `prompt_transcription` to transkrypcja pliku wav z promptem konwersacyjnym, np. "[S1] Hello. [S2] How are you?"
- `prompt_wav` to Å›cieÅ¼ka do pliku wav z promptem.
- `text` to tekst do syntezy, np. "[S1] I'm fine. [S2] What's your name?"

(2) **Format rozdzielonego promptu**, w ktÃ³rym nagrania i transkrypcje dwÃ³ch rozmÃ³wcÃ³w znajdujÄ… siÄ™ w osobnych plikach:


```
{wav_name}\t{spk1_prompt_transcription}\t{spk2_prompt_transcription}\t{spk1_prompt_wav}\t{spk2_prompt_wav}\t{text}'
```
- `wav_name` to nazwa wyjÅ›ciowego pliku wav.
- `spk1_prompt_transcription` to transkrypcja prÃ³bki wav pierwszego mÃ³wcy, np. "Hello"
- `spk2_prompt_transcription` to transkrypcja prÃ³bki wav drugiego mÃ³wcy, np. "How are you?"
- `spk1_prompt_wav` to Å›cieÅ¼ka do prÃ³bki wav pierwszego mÃ³wcy.
- `spk2_prompt_wav` to Å›cieÅ¼ka do prÃ³bki wav drugiego mÃ³wcy.
- `text` to tekst do syntezy, np. "[S1] I'm fine. [S2] What's your name?"

### 3. Inne funkcje

#### 3.1 Poprawianie bÅ‚Ä™dnie wymawianych chiÅ„skich znakÃ³w wieloznacznych

UÅ¼ywamy [pypinyin](https://github.com/mozillazg/python-pinyin) do konwersji chiÅ„skich znakÃ³w na pinyin. Jednak czasami moÅ¼e bÅ‚Ä™dnie wymÃ³wiÄ‡ **znaki wieloznaczne** (å¤šéŸ³å­—).

Aby rÄ™cznie poprawiÄ‡ te bÅ‚Ä™dy wymowy, naleÅ¼y umieÅ›ciÄ‡ **poprawny pinyin** w nawiasach ostrych `< >` i dodaÄ‡ **znak tonu**.

**PrzykÅ‚ad:**

- Oryginalny tekst: `è¿™æŠŠå‰‘é•¿ä¸‰åå…¬åˆ†`
- Popraw pinyin znaku `é•¿`: `è¿™æŠŠå‰‘<chang2>ä¸‰åå…¬åˆ†`

> **Uwaga:** JeÅ›li chcesz rÄ™cznie przypisaÄ‡ kilka pinyinÃ³w, umieÅ›Ä‡ kaÅ¼dy pinyin w `<>`, np. `è¿™æŠŠ<jian4><chang2><san1>åå…¬åˆ†`

## Trenuj swÃ³j wÅ‚asny model

Zobacz katalog [egs](egs) po przykÅ‚ady trenowania, fine-tuningu i ewaluacji.

## Dyskusja i komunikacja

MoÅ¼esz bezpoÅ›rednio dyskutowaÄ‡ na [Github Issues](https://github.com/k2-fsa/ZipVoice/issues).

MoÅ¼esz takÅ¼e zeskanowaÄ‡ kod QR, aby doÅ‚Ä…czyÄ‡ do naszej grupy na WeChat lub obserwowaÄ‡ nasze oficjalne konto WeChat.

| Grupa WeChat | Oficjalne konto WeChat |
| ------------ | ---------------------- |
|![wechat](https://k2-fsa.org/zh-CN/assets/pic/wechat_group.jpg) |![wechat](https://k2-fsa.org/zh-CN/assets/pic/wechat_account.jpg) |

## Cytowanie


```bibtex
@article{zhu2025zipvoice,
      title={ZipVoice: Fast and High-Quality Zero-Shot Text-to-Speech with Flow Matching},
      author={Zhu, Han and Kang, Wei and Yao, Zengwei and Guo, Liyong and Kuang, Fangjun and Li, Zhaoqing and Zhuang, Weiji and Lin, Long and Povey, Daniel},
      journal={arXiv preprint arXiv:2506.13053},
      year={2025}
}

@article{zhu2025zipvoicedialog,
      title={ZipVoice-Dialog: Non-Autoregressive Spoken Dialogue Generation with Flow Matching},
      author={Zhu, Han and Kang, Wei and Guo, Liyong and Yao, Zengwei and Kuang, Fangjun and Zhuang, Weiji and Li, Zhaoqing and Han, Zhifeng and Zhang, Dong and Zhang, Xin and Song, Xingchen and Lin, Long and Povey, Daniel},
      journal={arXiv preprint arXiv:2507.09318},
      year={2025}
}
```
<translate-content></translate-content>

---

Tranlated By [Open Ai Tx](https://github.com/OpenAiTx/OpenAiTx) | Last indexed: 2025-07-22

---