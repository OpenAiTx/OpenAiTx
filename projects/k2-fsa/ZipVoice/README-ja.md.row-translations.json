[
  {
    "row": 1,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "- `wav_name` は出力 wav ファイルの名前です。"
  },
  {
    "row": 2,
    "rowsha": "6vgIR6WfUAFmULhn8LhxFttPwZEo/YwGhN1DAECwHCQ=",
    "originContent": "- `wav_name` is the name of the output wav file.",
    "translatedContent": "- `spk1_prompt_transcription` は最初の話者のプロンプト wav の書き起こし（例: \"Hello\"）です。"
  },
  {
    "row": 3,
    "rowsha": "7BNq8UaBvTut4Ow/oJBAgIDTn3EwEZXK7mlUaYdFwqw=",
    "originContent": "- `spk1_prompt_transcription` is the transcription of the first speaker's prompt wav, e.g, \"Hello\"",
    "translatedContent": "- `spk2_prompt_transcription` は二人目の話者のプロンプト wav の書き起こし（例: \"How are you?\"）です。"
  },
  {
    "row": 4,
    "rowsha": "CES8w9dqVdkdJyOJBUVP282aaKeevVWB3d/+59TEsuk=",
    "originContent": "- `spk2_prompt_transcription` is the transcription of the second speaker's prompt wav, e.g, \"How are you?\"",
    "translatedContent": "- `spk1_prompt_wav` は最初の話者のプロンプト wav ファイルのパスです。"
  },
  {
    "row": 5,
    "rowsha": "gXLLRf4BR7Xko2q2l4nK04KIs/L8CjvZ/UBQaP1+vck=",
    "originContent": "- `spk1_prompt_wav` is the path to the first speaker's prompt wav file.",
    "translatedContent": "- `spk2_prompt_wav` は二人目の話者のプロンプト wav ファイルのパスです。"
  },
  {
    "row": 6,
    "rowsha": "oS1+heJwBnnDtA57WYtG6LbzxK79DOIeb8hwhZQwcDg=",
    "originContent": "- `spk2_prompt_wav` is the path to the second speaker's prompt wav file.",
    "translatedContent": "- `text` は合成するテキストです。例: \"[S1] I'm fine. [S2] What's your name? [S1] I'm Eric. [S2] Hi Eric.\""
  },
  {
    "row": 7,
    "rowsha": "M4Z2DDajNBdyF/JosIaDZ44oyZnjNA7lzfGzEpuoako=",
    "originContent": "- `text` is the text to be synthesized, e.g. \"[S1] I'm fine. [S2] What's your name? [S1] I'm Eric. [S2] Hi Eric.\"",
    "translatedContent": ""
  },
  {
    "row": 8,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "### 3 より良い利用のためのガイダンス:"
  },
  {
    "row": 9,
    "rowsha": "SdDI3h73wOzKSM3kbrbNrmpigHGer7kumuaZsQgAeao=",
    "originContent": "### 3 Guidance for better usage:",
    "translatedContent": ""
  },
  {
    "row": 10,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "#### 3.1 プロンプトの長さ"
  },
  {
    "row": 11,
    "rowsha": "cVxukE6jyFFOxlNKI5ecOTo/suYYJ8hnYyW2XA2wg+o=",
    "originContent": "#### 3.1 Prompt length",
    "translatedContent": ""
  },
  {
    "row": 12,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "推論速度を速めるために、短いプロンプト wav ファイル（例: 単一話者音声生成の場合 3 秒未満、対話音声生成の場合 10 秒未満）を推奨します。非常に長いプロンプトは推論を遅くし、音声品質が劣化します。"
  },
  {
    "row": 13,
    "rowsha": "f19zq78QrLul7wiVSlCSojGS7qNEvtef9GFg6AA8eMY=",
    "originContent": "We recommand a short prompt wav file (e.g., less than 3 seconds for single-speaker speech generation, less than 10 seconds for dialogue speech generation) for faster inference speed. A very long prompt will slow down the inference and degenerate the speech quality.",
    "translatedContent": ""
  },
  {
    "row": 14,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "#### 3.2 スピード最適化"
  },
  {
    "row": 15,
    "rowsha": "lpgNpm20ulCcTiEU/xfEVVgMZhjiQjymkdljF8dD/vw=",
    "originContent": "#### 3.2 Speed optimization",
    "translatedContent": ""
  },
  {
    "row": 16,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "推論速度が不満な場合、以下の方法で高速化できます:"
  },
  {
    "row": 17,
    "rowsha": "iBJxMfYOjV9HvSuRT3p/EsU/iATeDCDAk/wGWLXqQI8=",
    "originContent": "If the inference speed is unsatisfactory, you can speed it up as follows:",
    "translatedContent": ""
  },
  {
    "row": 18,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "- **蒸留モデルとステップ数の削減**: 単一話者音声生成モデルでは、デフォルトで `zipvoice` モデルを使用して音声品質を高めています。速度を優先する場合は `zipvoice_distill` に切り替え、`--num-steps` を最小 `4`（デフォルトは 8）まで減らせます。"
  },
  {
    "row": 19,
    "rowsha": "IzTHxzS1e5yJRhHF5d8CsjfqjIzhNX1AeGR4FTjuUCA=",
    "originContent": "- **Distill model and less steps**: For the single-speaker speech generation model, we use the `zipvoice` model by default for better speech quality. If faster speed is a priority, you can switch to the `zipvoice_distill` and can reduce the `--num-steps` to as low as `4` (8 by default).",
    "translatedContent": ""
  },
  {
    "row": 20,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "- **CPU のマルチスレッドによる高速化**: CPU で実行する場合、`--num-thread` パラメータ（例: `--num-thread 4`）を指定してスレッド数を増やし、高速化できます。デフォルトは 1 スレッドです。"
  },
  {
    "row": 21,
    "rowsha": "mNiqyHjFr4rbx4boH0cix2peH8Q0+tDTOlzgZeLLDqM=",
    "originContent": "- **CPU speedup with multi-threading**: When running on CPU, you can pass the `--num-thread` parameter (e.g., `--num-thread 4`) to increase the number of threads for faster speed. We use 1 thread by default.",
    "translatedContent": ""
  },
  {
    "row": 22,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "- **ONNX による CPU 高速化**: CPU で実行する場合、`zipvoice.bin.infer_zipvoice_onnx` で ONNX モデルを利用すると高速化できます（対話生成モデルはまだ ONNX 非対応）。さらに高速化したい場合は `--onnx-int8 True` を設定し、INT8 量子化 ONNX モデルを使えます。量子化モデルは音声品質の低下を招く場合があります。**GPU で ONNX を使わないでください**。PyTorch より遅くなります。"
  },
  {
    "row": 23,
    "rowsha": "YqtmXdPz7OfUIbrIkeeIwyKEPdEZUqn3m5EyTNd967s=",
    "originContent": "- **CPU speedup with ONNX**: When running on CPU, you can use ONNX models with `zipvoice.bin.infer_zipvoice_onnx` for faster speed (haven't supported ONNX for dialogue generation models yet). For even faster speed, you can further set `--onnx-int8 True` to use an INT8-quantized ONNX model. Note that the quantized model will result in a certain degree of speech quality degradation. **Don't use ONNX on GPU**, as it is slower than PyTorch on GPU.",
    "translatedContent": ""
  },
  {
    "row": 24,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "- **NVIDIA TensorRT による GPU 高速化**: NVIDIA GPU で大幅なパフォーマンス向上のため、まず zipvoice.bin.tensorrt_export を使ってモデルを TensorRT エンジンにエクスポートします。その後、zipvoice.bin.infer_zipvoice で（例: Hugging Face データセット上で）推論を実行します。これにより標準の PyTorch GPU 実装の約 2 倍のスループットが得られます。"
  },
  {
    "row": 25,
    "rowsha": "kj1A4DWWe02Utusq07KI3xRRH55QdxQWRCzFeimIzww=",
    "originContent": "- **GPU Acceleration with NVIDIA TensorRT**: For a significant performance boost on NVIDIA GPUs, first export the model to a TensorRT engine using zipvoice.bin.tensorrt_export. Then, run inference on your dataset (e.g., a Hugging Face dataset) with zipvoice.bin.infer_zipvoice. This can achieve approximately 2x the throughput compared to the standard PyTorch implementation on a GPU.",
    "translatedContent": ""
  },
  {
    "row": 26,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "#### 3.3 メモリ制御"
  },
  {
    "row": 27,
    "rowsha": "fze8iMUXPcPsZgNFyWFzWSuCffZnzh7SpzLs21tQLtE=",
    "originContent": "#### 3.3 Memory control",
    "translatedContent": ""
  },
  {
    "row": 28,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "与えられたテキストは句読点（単一話者音声生成の場合）または話者交代記号（対話音声生成の場合）で分割されます。分割されたテキストはバッチ処理されるため、モデルはほぼ一定のメモリ使用量で任意の長さのテキストを処理できます。`--max-duration` パラメータでメモリ使用量を調整できます。"
  },
  {
    "row": 29,
    "rowsha": "uM67TExtHYq7ALHmglqtjLRqv0Xu0OOSx2aFJquZPmw=",
    "originContent": "The given text will be splitted into chunks based on punctuation (for single-speaker speech generation) or speaker-turn symbol (for dialogue speech generation). Then, the chunked texts will be processed in batches. Therefore, the model can process arbitrarily long text with almost constant memory usage. You can control memory usage by adjusting the `--max-duration` parameter.",
    "translatedContent": ""
  },
  {
    "row": 30,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "#### 3.4 \"Raw\" 評価"
  },
  {
    "row": 31,
    "rowsha": "foa86E9JcH+Sc/k2OCmyfIKHwggsFBXhSUfHDcmJQA0=",
    "originContent": "#### 3.4 \"Raw\" evaluation",
    "translatedContent": ""
  },
  {
    "row": 32,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "デフォルトでは、効率的な推論と高いパフォーマンスのため、入力（プロンプト wav、書き起こし、テキスト）を前処理します。提供された入力をそのまま使いモデルの「生」の性能を評価したい場合（例: 論文の再現）、`--raw-evaluation True` を指定できます。"
  },
  {
    "row": 33,
    "rowsha": "+2nxKNvXmuxUQpf2Z+hw0Rxydt00FpmK4y4rlK5/8og=",
    "originContent": "By default, we preprocess inputs (prompt wav, prompt transcription, and text) for efficient inference and better performance. If you want to evaluate the model’s \"raw\" performance using exact provided inputs (e.g., to reproduce the results in our paper), you can pass `--raw-evaluation True`.",
    "translatedContent": ""
  },
  {
    "row": 34,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "#### 3.5 短いテキスト"
  },
  {
    "row": 35,
    "rowsha": "g658opDssPKmJCvr7Jw9N130Xud1IbMHTwMK+S89WO0=",
    "originContent": "#### 3.5 Short text",
    "translatedContent": ""
  },
  {
    "row": 36,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "ごく短いテキスト（例: 1～2 語）の音声生成時、生成音声が一部の発音を省略する場合があります。この場合は `--speed 0.3`（0.3 は調整可能値）を指定し、生成音声の長さを延ばすことで解決できます。"
  },
  {
    "row": 37,
    "rowsha": "/IVkHehTtKgVQNwGOgQO/BoRh95RFHVJPH3e0W6Gixs=",
    "originContent": "When generating speech for very short texts (e.g., one or two words), the generated speech may sometimes omit certain pronunciations. To resolve this issue, you can pass `--speed 0.3` (where 0.3 is a tunable value) to extend the duration of the generated speech.",
    "translatedContent": ""
  },
  {
    "row": 38,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "#### 3.6 中国語多音字の誤発音修正"
  },
  {
    "row": 39,
    "rowsha": "PAPz1JYDhpLF6dsiNH/BVipH4SufvLcqzLiPLACOcK4=",
    "originContent": "#### 3.6 Correcting mispronounced chinese polyphone characters",
    "translatedContent": ""
  },
  {
    "row": 40,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 41,
    "rowsha": "hF52KZEnGKLuaot2w0AmXt52eB6Y3adYIo2qMJSMx5o=",
    "originContent": "We use [pypinyin](https://github.com/mozillazg/python-pinyin) to convert Chinese characters to pinyin. However, it can occasionally mispronounce **polyphone characters** (多音字).",
    "translatedContent": "私たちは [pypinyin](https://github.com/mozillazg/python-pinyin) を使用して中国語の漢字をピンインに変換しています。ただし、**多音字**（複数の発音を持つ漢字）を時々誤って発音することがあります。"
  },
  {
    "row": 42,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 43,
    "rowsha": "h6Qq8AvUPYme90k2BWG054cVE6RHNflr0OwdnKA4BEE=",
    "originContent": "To manually correct these mispronunciations, enclose the **corrected pinyin** in angle brackets `< >` and include the **tone mark**.",
    "translatedContent": "これらの誤発音を手動で修正するには、**修正済みのピンイン**を山括弧 `< >` で囲み、**声調記号**を含めてください。"
  },
  {
    "row": 44,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 45,
    "rowsha": "fP4bnCe7+qhcgDDajGMIv4obksa4WSdUp3hExEbpci0=",
    "originContent": "**Example:**",
    "translatedContent": "**例:**"
  },
  {
    "row": 46,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 47,
    "rowsha": "ntwz9/IQqGC1ThJXQn9D83h+54cDriyg2snkkrk0KoI=",
    "originContent": "- Original text: `这把剑长三十公分`",
    "translatedContent": "- 元のテキスト: `这把剑长三十公分`"
  },
  {
    "row": 48,
    "rowsha": "sfnMRvscnvdKs1fvbVePwH0RpAikXkFIi9i7HZK7D9w=",
    "originContent": "- Correct the pinyin of `长`:  `这把剑<chang2>三十公分`",
    "translatedContent": "- `长` のピンインを修正: `这把剑<chang2>三十公分`"
  },
  {
    "row": 49,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 50,
    "rowsha": "7f45Y23fyK7AQrUO7HdTtPZZzoyRkW6WwoznauYmQew=",
    "originContent": "> **Note:** If you want to manually assign multiple pinyins, enclose each pinyin with `<>`, e.g., `这把<jian4><chang2><san1>十公分`",
    "translatedContent": "> **注意:** 複数のピンインを手動で割り当てたい場合は、各ピンインを `<>` で囲んでください。例: `这把<jian4><chang2><san1>十公分`"
  },
  {
    "row": 51,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 52,
    "rowsha": "FJBRXZnczlB/CZyp0UgEFMr440NrcuTPBheyQJ9lxZI=",
    "originContent": "#### 3.7 Remove long silences from the generated speech",
    "translatedContent": "#### 3.7 生成された音声から長い無音部分を削除する"
  },
  {
    "row": 53,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 54,
    "rowsha": "9UF5wHdPZ48OWeIPfCnOHPEWzgW4Z6I0e+GaTEZ1GXI=",
    "originContent": "Model will automatically determine the positions and lengths of silences in the generated speech. It occasionally has long silence in the middle of the speech. If you don't want this, you can pass `--remove-long-sil` to remove long silences in the middle of the generated speech (edge silences will be removed by default).",
    "translatedContent": "モデルは生成された音声内の無音部分の位置と長さを自動的に判断します。時折、音声の途中に長い無音が入ることがあります。これを避けたい場合は、`--remove-long-sil` を指定することで、生成された音声の途中の長い無音部分を削除できます（端の無音はデフォルトで削除されます）。"
  },
  {
    "row": 55,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 56,
    "rowsha": "t3GDCbkkN4PM6Y7xA/ZDAXgu4WdMFfXJ+5E/xKU9AKo=",
    "originContent": "#### 3.8 Model downloading",
    "translatedContent": "#### 3.8 モデルのダウンロード"
  },
  {
    "row": 57,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 58,
    "rowsha": "I2UvthbxkflPXxq8Yy6W9nJCtzb40mZPJbfmDIWQPmA=",
    "originContent": "If you have trouble connecting to HuggingFace when downloading the pre-trained models, try switching endpoint to the mirror site: `export HF_ENDPOINT=https://hf-mirror.com`.",
    "translatedContent": "事前学習済みモデルのダウンロード時に HuggingFace への接続に問題がある場合は、エンドポイントをミラーサイトに切り替えてください: `export HF_ENDPOINT=https://hf-mirror.com`。"
  },
  {
    "row": 59,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 60,
    "rowsha": "SEsrfyGZhBYqHMMdMldgN+tSz6ynJT5BVJeLrTV5lHw=",
    "originContent": "## Train Your Own Model",
    "translatedContent": "## 独自モデルの学習"
  },
  {
    "row": 61,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 62,
    "rowsha": "XaSJNyFaxQRx1Xc0mphwUGAxovKELo/54WkMCnFDLyE=",
    "originContent": "See the [egs](egs) directory for training, fine-tuning and evaluation examples.",
    "translatedContent": "学習、ファインチューニング、評価の例については [egs](egs) ディレクトリを参照してください。"
  },
  {
    "row": 63,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 64,
    "rowsha": "tfXaiJ7qvaTkZXp5azeYhmiU88iPPhEvLfYayUjE5+g=",
    "originContent": "## Production Deployment",
    "translatedContent": "## 本番環境へのデプロイ"
  },
  {
    "row": 65,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 66,
    "rowsha": "Tv94iSjTAB/OzGKZj2XftoBUCOzD2x+C0/xHRwRVo1c=",
    "originContent": "### NVIDIA Triton GPU Runtime",
    "translatedContent": "### NVIDIA Triton GPU ランタイム"
  },
  {
    "row": 67,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 68,
    "rowsha": "cGPOVgf7Mpi/ILRt8hu96EmjQo85nhgnSfBGLfBqMeM=",
    "originContent": "For production-ready deployment with high performance and scalability, check out the [Triton Inference Server integration](runtime/nvidia_triton/) that provides optimized TensorRT engines, concurrent request handling, and both gRPC/HTTP APIs for enterprise use.",
    "translatedContent": "高いパフォーマンスとスケーラビリティを備えた本番環境へのデプロイには、TensorRT エンジン最適化、同時リクエスト処理、企業向け gRPC/HTTP API を提供する [Triton Inference Server 連携](runtime/nvidia_triton/) をご確認ください。"
  },
  {
    "row": 69,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 70,
    "rowsha": "qR/CeuOSoGV5ipBKRWpnI+ohlytt878WhTEjtxZenks=",
    "originContent": "### CPU Deployment",
    "translatedContent": "### CPU デプロイ"
  },
  {
    "row": 71,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 72,
    "rowsha": "B8jnXFyKu8XRyVw/Pu0Xuj1ted9/BVoBfwJ1WW9LrcE=",
    "originContent": "Check [sherpa-onnx](https://github.com/k2-fsa/sherpa-onnx/pull/2487#issuecomment-3227884498) for the C++ deployment solution on CPU.",
    "translatedContent": "CPU での C++ デプロイソリューションについては [sherpa-onnx](https://github.com/k2-fsa/sherpa-onnx/pull/2487#issuecomment-3227884498) をご覧ください。"
  },
  {
    "row": 73,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 74,
    "rowsha": "dEqRbPItUt3FEp1iC+8Ww+A6L57yd6oGeXfxSn5BYzs=",
    "originContent": "## Discussion & Communication",
    "translatedContent": "## 議論 & コミュニケーション"
  },
  {
    "row": 75,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 76,
    "rowsha": "wjQUwaDgSP1a6ggLgGx8TWt44Dxu5IlJytNwCAlzZKg=",
    "originContent": "You can directly discuss on [Github Issues](https://github.com/k2-fsa/ZipVoice/issues).",
    "translatedContent": "[Github Issues](https://github.com/k2-fsa/ZipVoice/issues) で直接議論できます。"
  },
  {
    "row": 77,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 78,
    "rowsha": "WLbsT+slCE72T0wpzVIN8KFxhP+RAw29VxFhJcBEEIo=",
    "originContent": "You can also scan the QR code to join our wechat group or follow our wechat official account.",
    "translatedContent": "QRコードをスキャンして Wechat グループに参加したり、Wechat 公式アカウントをフォローすることもできます。"
  },
  {
    "row": 79,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 80,
    "rowsha": "XMNeg//PyHlCkY1XlL7caNd2vlVOKKoslrNeasADjMY=",
    "originContent": "| Wechat Group | Wechat Official Account |",
    "translatedContent": "| Wechat グループ | Wechat 公式アカウント |"
  },
  {
    "row": 81,
    "rowsha": "jdP52Pdk9hJ4eEQC1YzC887/bGdD6V25zHK1FxUbFjM=",
    "originContent": "| ------------ | ----------------------- |",
    "translatedContent": "| ------------ | ----------------------- |"
  },
  {
    "row": 82,
    "rowsha": "Q6eYrtLPPuG0fiZxZqhYquTYNk0vlyIOh+CRuwGZVk4=",
    "originContent": "|![wechat](https://k2-fsa.org/zh-CN/assets/pic/wechat_group.jpg) |![wechat](https://k2-fsa.org/zh-CN/assets/pic/wechat_account.jpg) |",
    "translatedContent": "|![wechat](https://k2-fsa.org/zh-CN/assets/pic/wechat_group.jpg) |![wechat](https://k2-fsa.org/zh-CN/assets/pic/wechat_account.jpg) |"
  },
  {
    "row": 83,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 84,
    "rowsha": "ZwTp5ajUmpHTJefyHhIKzXcG2wnB1jv8iv8cvmdcb/g=",
    "originContent": "## Citation",
    "translatedContent": "## 引用"
  },
  {
    "row": 85,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  }
]