
<div align="right">
  <details>
    <summary >üåê Idioma</summary>
    <div>
      <div align="center">
        <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=en">English</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=zh-CN">ÁÆÄ‰Ωì‰∏≠Êñá</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=zh-TW">ÁπÅÈ´î‰∏≠Êñá</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ja">Êó•Êú¨Ë™û</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ko">ÌïúÍµ≠Ïñ¥</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=hi">‡§π‡§ø‡§®‡•ç‡§¶‡•Ä</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=th">‡πÑ‡∏ó‡∏¢</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=fr">Fran√ßais</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=de">Deutsch</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=es">Espa√±ol</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=it">Itapano</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ru">–†—É—Å—Å–∫–∏–π</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=pt">Portugu√™s</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=nl">Nederlands</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=pl">Polski</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ar">ÿßŸÑÿπÿ±ÿ®Ÿäÿ©</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=fa">ŸÅÿßÿ±ÿ≥€å</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=tr">T√ºrk√ße</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=vi">Ti·∫øng Vi·ªát</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=id">Bahasa Indonesia</a>
      </div>
    </div>
  </details>
</div>

<div align="center">

# ZipVoice‚ö°

## Texto para Fala Zero-Shot R√°pido e de Alta Qualidade com Flow Matching
</div>

## Vis√£o Geral

ZipVoice √© uma s√©rie de modelos TTS de zero-shot r√°pidos e de alta qualidade baseados em flow matching.

### 1. Principais caracter√≠sticas

- Pequeno e r√°pido: apenas 123M de par√¢metros.

- Clonagem de voz de alta qualidade: desempenho de ponta em similaridade de locutor, inteligibilidade e naturalidade.

- Multi-idiomas: suporta chin√™s e ingl√™s.

- Multi-modo: suporta gera√ß√£o de fala de locutor √∫nico e de di√°logos.

### 2. Variantes do modelo

<table>
  <thead>
    <tr>
      <th>Nome do Modelo</th>
      <th>Descri√ß√£o</th>
      <th>Artigo</th>
      <th>Demo</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>ZipVoice</td>
      <td>O modelo b√°sico que suporta TTS zero-shot de locutor √∫nico em chin√™s e ingl√™s.</td>
      <td rowspan="2"><a href="https://arxiv.org/abs/2506.13053"><img src="https://img.shields.io/badge/arXiv-Paper-COLOR.svg"></a></td>
      <td rowspan="2"><a href="https://zipvoice.github.io"><img src="https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square"></a></td>
    </tr>
    <tr>
      <td>ZipVoice-Distill</td>
      <td>Vers√£o destilada do ZipVoice, com velocidade aprimorada e m√≠nima degrada√ß√£o de desempenho.</td>
    </tr>
    <tr>
      <td>ZipVoice-Dialog</td>
      <td>Modelo de gera√ß√£o de di√°logos baseado no ZipVoice, capaz de gerar di√°logos falados de dois participantes em canal √∫nico.</td>
      <td rowspan="2"><a href="https://arxiv.org/abs/2507.09318"><img src="https://img.shields.io/badge/arXiv-Paper-COLOR.svg"></a></td>
      <td rowspan="2"><a href="https://zipvoice-dialog.github.io"><img src="https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square"></a></td>
    </tr>
    <tr>
      <td>ZipVoice-Dialog-Stereo</td>
      <td>A variante est√©reo do ZipVoice-Dialog, permitindo gera√ß√£o de di√°logos em dois canais com cada falante atribu√≠do a um canal distinto.</td>
    </tr>
  </tbody>
</table>

## Novidades

**2025/07/14**: **ZipVoice-Dialog** e **ZipVoice-Dialog-Stereo**, dois modelos de gera√ß√£o de di√°logos falados, foram lan√ßados. [![arXiv](https://img.shields.io/badge/arXiv-Paper-COLOR.svg)](https://arxiv.org/abs/2507.09318) [![demo page](https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square)](https://zipvoice-dialog.github.io)

**2025/07/14**: O conjunto de dados **OpenDialog**, um dataset de di√°logos falados de 6,8 mil horas, foi lan√ßado. Baixe em [![hf](https://img.shields.io/badge/%F0%9F%A4%97%20HuggingFace-Dataset-yellow)](https://huggingface.co/datasets/k2-fsa/OpenDialog), [![ms](https://img.shields.io/badge/ModelScope-Dataset-blue?logo=data)](https://www.modelscope.cn/datasets/k2-fsa/OpenDialog). Confira os detalhes em [![arXiv](https://img.shields.io/badge/arXiv-Paper-COLOR.svg)](https://arxiv.org/abs/2507.09318).

**2025/06/16**: **ZipVoice** e **ZipVoice-Distill** foram lan√ßados. [![arXiv](https://img.shields.io/badge/arXiv-Paper-COLOR.svg)](https://arxiv.org/abs/2506.13053) [![demo page](https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square)](https://zipvoice.github.io)

## Instala√ß√£o

### 1. Clone o reposit√≥rio ZipVoice

```bash
git clone https://github.com/k2-fsa/ZipVoice.git
```
### 2. (Opcional) Crie um ambiente virtual Python


```bash
python3 -m venv zipvoice
source zipvoice/bin/activate
```
### 3. Instale os pacotes necess√°rios


```bash
pip install -r requirements.txt
```
### 4. Instale o k2 para treinamento ou infer√™ncia eficiente

**k2 √© necess√°rio para o treinamento** e pode acelerar a infer√™ncia. No entanto, voc√™ ainda pode usar o modo de infer√™ncia do ZipVoice sem instalar o k2.

> **Nota:** Certifique-se de instalar a vers√£o do k2 que corresponde √† sua vers√£o do PyTorch e do CUDA. Por exemplo, se voc√™ estiver usando pytorch 2.5.1 e CUDA 12.1, voc√™ pode instalar o k2 da seguinte forma:


```bash
pip install k2==1.24.4.dev20250208+cuda12.1.torch2.5.1 -f https://k2-fsa.github.io/k2/cuda.html
```
Consulte https://k2-fsa.org/get-started/k2/ para mais detalhes.
Usu√°rios na China continental podem consultar https://k2-fsa.org/zh-CN/get-started/k2/.

- Para verificar a instala√ß√£o do k2:


```bash
python3 -c "import k2; print(k2.__file__)"
```
## Uso

### 1. Gera√ß√£o de fala de um √∫nico locutor

Para gerar fala de um √∫nico locutor com nossos modelos pr√©-treinados ZipVoice ou ZipVoice-Distill, use os seguintes comandos (Os modelos necess√°rios ser√£o baixados do HuggingFace):

#### 1.1 Infer√™ncia de uma √∫nica senten√ßa


```bash
python3 -m zipvoice.bin.infer_zipvoice \
    --model-name zipvoice \
    --prompt-wav prompt.wav \
    --prompt-text "I am the transcription of the prompt wav." \
    --text "I am the text to be synthesized." \
    --res-wav-path result.wav
```
- `--model-name` pode ser `zipvoice` ou `zipvoice_distill`, que s√£o modelos antes e depois da destila√ß√£o, respectivamente.
- Se `<>` ou `[]` aparecerem no texto, cadeias de caracteres entre eles ser√£o tratadas como tokens especiais. `<>` denota pinyin chin√™s e `[]` denota outras tags especiais.

#### 1.2 Infer√™ncia de uma lista de senten√ßas

```bash
python3 -m zipvoice.bin.infer_zipvoice \
    --model-name zipvoice \
    --test-list test.tsv \
    --res-dir results
```
- Cada linha de `test.tsv` est√° no formato `{wav_name}\t{prompt_transcription}\t{prompt_wav}\t{text}`.

### 2. Gera√ß√£o de fala em di√°logo

#### 2.1 Comando de infer√™ncia

Para gerar di√°logos falados entre duas pessoas com nossos modelos pr√©-treinados ZipVoice-Dialogue ou ZipVoice-Dialogue-Stereo, use os seguintes comandos (Os modelos necess√°rios ser√£o baixados do HuggingFace):


```bash
python3 -m zipvoice.bin.infer_zipvoice_dialog \
    --model-name "zipvoice_dialog" \
    --test-list test.tsv \
    --res-dir results
```
- `--model-name` pode ser `zipvoice_dialog` ou `zipvoice_dialog_stereo`,
    que geram di√°logos mono e est√©reo, respectivamente.

#### 2.2 Formatos de entrada

Cada linha do `test.tsv` est√° em um dos seguintes formatos:

(1) **Formato de prompt mesclado** onde os √°udios e transcri√ß√µes dos prompts de dois falantes s√£o mesclados em um √∫nico arquivo wav de prompt:

```
{wav_name}\t{prompt_transcription}\t{prompt_wav}\t{text}
```

- `wav_name` √© o nome do arquivo wav de sa√≠da.
- `prompt_transcription` √© a transcri√ß√£o do arquivo wav de prompt de conversa√ß√£o, por exemplo, "[S1] Ol√°. [S2] Como vai voc√™?"
- `prompt_wav` √© o caminho para o arquivo wav de prompt.
- `text` √© o texto a ser sintetizado, por exemplo, "[S1] Estou bem. [S2] Qual √© o seu nome? [S1] Sou Eric. [S2] Oi Eric."

(2) **Formato de prompt dividido** onde os √°udios e transcri√ß√µes de dois falantes existem em arquivos separados:

```
{wav_name}\t{spk1_prompt_transcription}\t{spk2_prompt_transcription}\t{spk1_prompt_wav}\t{spk2_prompt_wav}\t{text}
```
- `wav_name` √© o nome do arquivo wav de sa√≠da.
- `spk1_prompt_transcription` √© a transcri√ß√£o do arquivo wav de prompt do primeiro falante, por exemplo, "Ol√°"
- `spk2_prompt_transcription` √© a transcri√ß√£o do arquivo wav de prompt do segundo falante, por exemplo, "Como vai voc√™?"
- `spk1_prompt_wav` √© o caminho para o arquivo wav de prompt do primeiro falante.
- `spk2_prompt_wav` √© o caminho para o arquivo wav de prompt do segundo falante.
- `text` √© o texto a ser sintetizado, por exemplo, "[S1] Estou bem. [S2] Qual √© o seu nome? [S1] Sou Eric. [S2] Ol√° Eric."

### 3 Orienta√ß√µes para melhor uso:

#### 3.1 Comprimento do prompt

Recomendamos um arquivo wav de prompt curto (por exemplo, menos de 3 segundos para gera√ß√£o de fala de um √∫nico falante, menos de 10 segundos para gera√ß√£o de di√°logos) para maior velocidade de infer√™ncia. Um prompt muito longo ir√° desacelerar a infer√™ncia e prejudicar a qualidade da fala.

#### 3.2 Otimiza√ß√£o de velocidade

Se a velocidade de infer√™ncia n√£o for satisfat√≥ria, voc√™ pode aceler√°-la da seguinte forma:

- **Modelo distilado e menos etapas**: Para o modelo de gera√ß√£o de fala de um √∫nico falante, usamos o modelo `zipvoice` por padr√£o para melhor qualidade de fala. Se a velocidade for prioridade, voc√™ pode alternar para `zipvoice_distill` e reduzir o par√¢metro `--num-steps` para at√© `4` (8 por padr√£o).

- **Acelera√ß√£o da CPU com multithreading**: Ao executar na CPU, voc√™ pode passar o par√¢metro `--num-thread` (por exemplo, `--num-thread 4`) para aumentar o n√∫mero de threads e obter maior velocidade. Usamos 1 thread por padr√£o.

- **Acelera√ß√£o da CPU com ONNX**: Ao executar na CPU, voc√™ pode usar modelos ONNX com `zipvoice.bin.infer_zipvoice_onnx` para maior velocidade (ainda n√£o h√° suporte para modelos de gera√ß√£o de di√°logos em ONNX). Para velocidade ainda maior, voc√™ pode definir `--onnx-int8 True` para usar um modelo ONNX quantizado em INT8. Observe que o modelo quantizado pode resultar em alguma degrada√ß√£o na qualidade da fala. **N√£o use ONNX na GPU**, pois √© mais lento do que PyTorch na GPU.

#### 3.3 Controle de mem√≥ria

O texto fornecido ser√° dividido em partes com base em pontua√ß√£o (para gera√ß√£o de fala de um √∫nico falante) ou s√≠mbolo de troca de falante (para gera√ß√£o de di√°logos). Em seguida, os textos divididos ser√£o processados em lotes. Portanto, o modelo pode processar textos arbitrariamente longos com uso de mem√≥ria quase constante. Voc√™ pode controlar o uso de mem√≥ria ajustando o par√¢metro `--max-duration`.

#### 3.4 Avalia√ß√£o "Bruta"

Por padr√£o, pr√©-processamos as entradas (wav de prompt, transcri√ß√£o do prompt e texto) para infer√™ncia eficiente e melhor desempenho. Se voc√™ quiser avaliar o desempenho "bruto" do modelo usando exatamente as entradas fornecidas (por exemplo, para reproduzir os resultados do nosso artigo), pode passar `--raw-evaluation True`.

#### 3.5 Texto curto

Ao gerar fala para textos muito curtos (por exemplo, uma ou duas palavras), a fala gerada pode, √†s vezes, omitir certas pron√∫ncias. Para resolver esse problema, voc√™ pode passar `--speed 0.3` (onde 0.3 √© um valor ajust√°vel) para estender a dura√ß√£o da fala gerada.

#### 3.6 Corrigindo caracteres polif√¥nicos chineses pronunciados incorretamente

Usamos [pypinyin](https://github.com/mozillazg/python-pinyin) para converter caracteres chineses em pinyin. No entanto, ocasionalmente pode pronunciar incorretamente **caracteres polif√¥nicos** (Â§öÈü≥Â≠ó).


Para corrigir manualmente essas pron√∫ncias incorretas, coloque o **pinyin corrigido** entre sinais de menor `< >` e inclua o **marcador de tom**.

**Exemplo:**

- Texto original: `ËøôÊääÂâëÈïø‰∏âÂçÅÂÖ¨ÂàÜ`
- Corrija o pinyin de `Èïø`:  `ËøôÊääÂâë<chang2>‰∏âÂçÅÂÖ¨ÂàÜ`

> **Nota:** Se quiser atribuir manualmente m√∫ltiplos pinyins, coloque cada pinyin entre `< >`, por exemplo: `ËøôÊää<jian4><chang2><san1>ÂçÅÂÖ¨ÂàÜ`

#### 3.7 Remover longos per√≠odos de sil√™ncio da fala gerada

O modelo determinar√° automaticamente as posi√ß√µes e dura√ß√µes dos sil√™ncios na fala gerada. Ocasionalmente, h√° longos per√≠odos de sil√™ncio no meio da fala. Se voc√™ n√£o quiser isso, pode passar `--remove-long-sil` para remover longos sil√™ncios no meio da fala gerada (os sil√™ncios nas bordas ser√£o removidos por padr√£o).

#### 3.8 Download do modelo

Se voc√™ tiver problemas para conectar ao HuggingFace ao baixar os modelos pr√©-treinados, tente mudar o endpoint para o site espelho: `export HF_ENDPOINT=https://hf-mirror.com`.

## Treine Seu Pr√≥prio Modelo

Veja o diret√≥rio [egs](egs) para exemplos de treinamento, ajuste fino e avalia√ß√£o.

## Implanta√ß√£o em C++

Confira [sherpa-onnx](https://github.com/k2-fsa/sherpa-onnx/pull/2487#issuecomment-3227884498) para a solu√ß√£o de implanta√ß√£o em C++ na CPU.

## Discuss√£o & Comunica√ß√£o

Voc√™ pode discutir diretamente nas [Issues do Github](https://github.com/k2-fsa/ZipVoice/issues).

Voc√™ tamb√©m pode escanear o c√≥digo QR para entrar em nosso grupo no WeChat ou seguir nossa conta oficial do WeChat.

| Grupo WeChat | Conta Oficial WeChat |
| ------------ | ------------------- |
|![wechat](https://k2-fsa.org/zh-CN/assets/pic/wechat_group.jpg) |![wechat](https://k2-fsa.org/zh-CN/assets/pic/wechat_account.jpg) |

## Cita√ß√£o

```bibtex
@article{zhu2025zipvoice,
      title={ZipVoice: Fast and High-Quality Zero-Shot Text-to-Speech with Flow Matching},
      author={Zhu, Han and Kang, Wei and Yao, Zengwei and Guo, Liyong and Kuang, Fangjun and Li, Zhaoqing and Zhuang, Weiji and Lin, Long and Povey, Daniel},
      journal={arXiv preprint arXiv:2506.13053},
      year={2025}
}

@article{zhu2025zipvoicedialog,
      title={ZipVoice-Dialog: Non-Autoregressive Spoken Dialogue Generation with Flow Matching},
      author={Zhu, Han and Kang, Wei and Guo, Liyong and Yao, Zengwei and Kuang, Fangjun and Zhuang, Weiji and Li, Zhaoqing and Han, Zhifeng and Zhang, Dong and Zhang, Xin and Song, Xingchen and Lin, Long and Povey, Daniel},
      journal={arXiv preprint arXiv:2507.09318},
      year={2025}
}
```




---

Tranlated By [Open Ai Tx](https://github.com/OpenAiTx/OpenAiTx) | Last indexed: 2025-10-06

---