<div align="right">
  <details>
    <summary >üåê Idioma</summary>
    <div>
      <div align="center">
        <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=en">English</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=zh-CN">ÁÆÄ‰Ωì‰∏≠Êñá</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=zh-TW">ÁπÅÈ´î‰∏≠Êñá</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ja">Êó•Êú¨Ë™û</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ko">ÌïúÍµ≠Ïñ¥</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=hi">‡§π‡§ø‡§®‡•ç‡§¶‡•Ä</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=th">‡πÑ‡∏ó‡∏¢</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=fr">Fran√ßais</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=de">Deutsch</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=es">Espa√±ol</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=it">Itapano</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ru">–†—É—Å—Å–∫–∏–π</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=pt">Portugu√™s</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=nl">Nederlands</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=pl">Polski</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ar">ÿßŸÑÿπÿ±ÿ®Ÿäÿ©</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=fa">ŸÅÿßÿ±ÿ≥€å</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=tr">T√ºrk√ße</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=vi">Ti·∫øng Vi·ªát</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=id">Bahasa Indonesia</a>
      </div>
    </div>
  </details>
</div>

<div align="center">

# ZipVoice‚ö°

## Texto-para-Fala Zero-Shot R√°pido e de Alta Qualidade com Flow Matching
</div>

## Vis√£o Geral

ZipVoice √© uma s√©rie de modelos TTS zero-shot r√°pidos e de alta qualidade baseados em flow matching.

### 1. Principais caracter√≠sticas

- Pequeno e r√°pido: apenas 123M de par√¢metros.

- Clonagem de voz de alta qualidade: desempenho de ponta em similaridade de locutor, inteligibilidade e naturalidade.

- Multi-idiomas: suporta Chin√™s e Ingl√™s.

- Multi-modo: suporta gera√ß√£o de fala de locutor √∫nico e de di√°logo.

### 2. Variantes do modelo

<table>
  <thead>
    <tr>
      <th>Nome do Modelo</th>
      <th>Descri√ß√£o</th>
      <th>Artigo</th>
      <th>Demonstra√ß√£o</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>ZipVoice</td>
      <td>O modelo b√°sico que suporta TTS zero-shot de locutor √∫nico em Chin√™s e Ingl√™s.</td>
      <td rowspan="2"><a href="https://arxiv.org/abs/2506.13053"><img src="https://img.shields.io/badge/arXiv-Paper-COLOR.svg"></a></td>
      <td rowspan="2"><a href="https://zipvoice.github.io"><img src="https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square"></a></td>
    </tr>
    <tr>
      <td>ZipVoice-Distill</td>
      <td>A vers√£o destilada do ZipVoice, com velocidade aprimorada e m√≠nima degrada√ß√£o de desempenho.</td>
    </tr>
    <tr>
      <td>ZipVoice-Dialog</td>
      <td>Um modelo de gera√ß√£o de di√°logo baseado no ZipVoice, capaz de gerar di√°logos falados de duas partes em um canal √∫nico.</td>
      <td rowspan="2"><a href="https://arxiv.org/abs/2507.09318"><img src="https://img.shields.io/badge/arXiv-Paper-COLOR.svg"></a></td>
      <td rowspan="2"><a href="https://zipvoice-dialog.github.io"><img src="https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square"></a></td>
    </tr>
    <tr>
      <td>ZipVoice-Dialog-Stereo</td>
      <td>A variante est√©reo do ZipVoice-Dialog, permitindo gera√ß√£o de di√°logos em dois canais com cada locutor em um canal distinto.</td>
    </tr>
  </tbody>
</table>

## Novidades

**2025/07/14**: **ZipVoice-Dialog** e **ZipVoice-Dialog-Stereo**, dois modelos de gera√ß√£o de di√°logo falado, foram lan√ßados. [![arXiv](https://img.shields.io/badge/arXiv-Paper-COLOR.svg)](https://arxiv.org/abs/2507.09318) [![demo page](https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square)](https://zipvoice-dialog.github.io)

**2025/07/14**: O dataset **OpenDialog**, um conjunto de dados de di√°logo falado com 6,8k horas, foi lan√ßado. Baixe em [![hf](https://img.shields.io/badge/%F0%9F%A4%97%20HuggingFace-Dataset-yellow)](https://huggingface.co/datasets/k2-fsa/OpenDialog), [![ms](https://img.shields.io/badge/ModelScope-Dataset-blue?logo=data)](https://www.modelscope.cn/datasets/k2-fsa/OpenDialog). Confira detalhes em [![arXiv](https://img.shields.io/badge/arXiv-Paper-COLOR.svg)](https://arxiv.org/abs/2507.09318).

**2025/06/16**: **ZipVoice** e **ZipVoice-Distill** foram lan√ßados. [![arXiv](https://img.shields.io/badge/arXiv-Paper-COLOR.svg)](https://arxiv.org/abs/2506.13053) [![demo page](https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square)](https://zipvoice.github.io)

## Instala√ß√£o

### 1. Clone o reposit√≥rio ZipVoice


```bash
git clone https://github.com/k2-fsa/ZipVoice.git
```
### 2. (Opcional) Crie um ambiente virtual Python


```bash
python3 -m venv zipvoice
source zipvoice/bin/activate
```
### 3. Instale os pacotes necess√°rios


```bash
pip install -r requirements.txt
```
### 4. Instale o k2 para treinamento ou infer√™ncia eficiente

**k2 √© necess√°rio para o treinamento** e pode acelerar a infer√™ncia. No entanto, voc√™ ainda pode usar o modo de infer√™ncia do ZipVoice sem instalar o k2.

> **Nota:** Certifique-se de instalar a vers√£o do k2 que corresponde √† sua vers√£o do PyTorch e do CUDA. Por exemplo, se voc√™ estiver usando pytorch 2.5.1 e CUDA 12.1, voc√™ pode instalar o k2 da seguinte forma:


```bash
pip install k2==1.24.4.dev20250208+cuda12.1.torch2.5.1 -f https://k2-fsa.github.io/k2/cuda.html
```
Consulte https://k2-fsa.org/get-started/k2/ para mais detalhes.
Usu√°rios na China continental podem consultar https://k2-fsa.org/zh-CN/get-started/k2/.

- Para verificar a instala√ß√£o do k2:


```
python3 -c "import k2; print(k2.__file__)"
```
## Uso

### 1. Gera√ß√£o de fala de um √∫nico locutor

Para gerar fala de um √∫nico locutor com nossos modelos pr√©-treinados ZipVoice ou ZipVoice-Distill, use os seguintes comandos (Os modelos necess√°rios ser√£o baixados do HuggingFace):

#### 1.1 Infer√™ncia de uma √∫nica senten√ßa


```bash
python3 -m zipvoice.bin.infer_zipvoice \
    --model-name zipvoice \
    --prompt-wav prompt.wav \
    --prompt-text "I am the transcription of the prompt wav." \
    --text "I am the text to be synthesized." \
    --res-wav-path result.wav
```
- `--model-name` pode ser `zipvoice` ou `zipvoice_distill`, que s√£o modelos antes e depois da destila√ß√£o, respectivamente.
- Se `<>` ou `[]` aparecerem no texto, as strings entre eles ser√£o tratadas como tokens especiais. `<>` denota pinyin chin√™s e `[]` denota outras tags especiais.
- Pode executar modelos ONNX na CPU mais r√°pido com `zipvoice.bin.infer_zipvoice_onnx`.

> **Nota:** Se voc√™ tiver problemas para se conectar ao HuggingFace, tente:
> ```bash
> export HF_ENDPOINT=https://hf-mirror.com
> ```

#### 1.2 Infer√™ncia de uma lista de senten√ßas


```bash
python3 -m zipvoice.bin.infer_zipvoice \
    --model-name zipvoice \
    --test-list test.tsv \
    --res-dir results
```
- Cada linha de `test.tsv` est√° no formato `{wav_name}\t{prompt_transcription}\t{prompt_wav}\t{text}`.

### 2. Gera√ß√£o de fala em di√°logo

#### 2.1 Comando de infer√™ncia

Para gerar di√°logos falados entre duas pessoas com nossos modelos pr√©-treinados ZipVoice-Dialogue ou ZipVoice-Dialogue-Stereo, use os seguintes comandos (Os modelos necess√°rios ser√£o baixados do HuggingFace):


```bash
python3 -m zipvoice.bin.infer_zipvoice_dialog \
    --model-name "zipvoice_dialog" \
    --test-list test.tsv \
    --res-dir results
```
- `--model-name` pode ser `zipvoice_dialog` ou `zipvoice_dialog_stereo`,
    que geram di√°logos mono e est√©reo, respectivamente.

#### 2.2 Formatos de entrada

Cada linha do `test.tsv` est√° em um dos seguintes formatos:

(1) **Formato de prompt mesclado** onde os √°udios e transcri√ß√µes dos prompts de dois falantes s√£o mesclados em um √∫nico arquivo wav de prompt:

```
{wav_name}\t{prompt_transcription}\t{prompt_wav}\t{text}
```
- `wav_name` √© o nome do arquivo wav de sa√≠da.
- `prompt_transcription` √© a transcri√ß√£o do arquivo wav do prompt de conversa√ß√£o, por exemplo, "[S1] Ol√°. [S2] Como voc√™ est√°?"
- `prompt_wav` √© o caminho para o arquivo wav do prompt.
- `text` √© o texto a ser sintetizado, por exemplo, "[S1] Estou bem. [S2] Qual √© o seu nome?"

(2) **Formato de prompt dividido** onde os √°udios e transcri√ß√µes de dois falantes existem em arquivos separados:


```
{wav_name}\t{spk1_prompt_transcription}\t{spk2_prompt_transcription}\t{spk1_prompt_wav}\t{spk2_prompt_wav}\t{text}'
```
- `wav_name` √© o nome do arquivo wav de sa√≠da.
- `spk1_prompt_transcription` √© a transcri√ß√£o do prompt wav do primeiro falante, por exemplo, "Ol√°"
- `spk2_prompt_transcription` √© a transcri√ß√£o do prompt wav do segundo falante, por exemplo, "Como vai voc√™?"
- `spk1_prompt_wav` √© o caminho para o arquivo wav do prompt do primeiro falante.
- `spk2_prompt_wav` √© o caminho para o arquivo wav do prompt do segundo falante.
- `text` √© o texto a ser sintetizado, por exemplo, "[S1] Estou bem. [S2] Qual √© o seu nome?"

### 3. Outras funcionalidades

#### 3.1 Corrigindo caracteres polif√¥nicos chineses pronunciados incorretamente

Usamos [pypinyin](https://github.com/mozillazg/python-pinyin) para converter caracteres chineses em pinyin. No entanto, ocasionalmente pode pronunciar incorretamente **caracteres polif√¥nicos** (Â§öÈü≥Â≠ó).

Para corrigir manualmente essas pron√∫ncias, coloque o **pinyin corrigido** entre sinais de menor e maior `< >` e inclua o **marcador de tom**.

**Exemplo:**

- Texto original: `ËøôÊääÂâëÈïø‰∏âÂçÅÂÖ¨ÂàÜ`
- Corrija o pinyin de `Èïø`:  `ËøôÊääÂâë<chang2>‰∏âÂçÅÂÖ¨ÂàÜ`

> **Nota:** Se quiser atribuir manualmente v√°rios pinyins, coloque cada pinyin entre `<>`, por exemplo, `ËøôÊää<jian4><chang2><san1>ÂçÅÂÖ¨ÂàÜ`

## Treine Seu Pr√≥prio Modelo

Veja o diret√≥rio [egs](egs) para exemplos de treinamento, ajuste fino e avalia√ß√£o.

## Discuss√£o & Comunica√ß√£o

Voc√™ pode discutir diretamente em [Github Issues](https://github.com/k2-fsa/ZipVoice/issues).

Voc√™ tamb√©m pode escanear o QR code para entrar no nosso grupo do WeChat ou seguir nossa conta oficial no WeChat.

| Grupo WeChat | Conta Oficial WeChat |
| ------------ | ----------------------- |
|![wechat](https://k2-fsa.org/zh-CN/assets/pic/wechat_group.jpg) |![wechat](https://k2-fsa.org/zh-CN/assets/pic/wechat_account.jpg) |

## Cita√ß√£o


```bibtex
@article{zhu2025zipvoice,
      title={ZipVoice: Fast and High-Quality Zero-Shot Text-to-Speech with Flow Matching},
      author={Zhu, Han and Kang, Wei and Yao, Zengwei and Guo, Liyong and Kuang, Fangjun and Li, Zhaoqing and Zhuang, Weiji and Lin, Long and Povey, Daniel},
      journal={arXiv preprint arXiv:2506.13053},
      year={2025}
}

@article{zhu2025zipvoicedialog,
      title={ZipVoice-Dialog: Non-Autoregressive Spoken Dialogue Generation with Flow Matching},
      author={Zhu, Han and Kang, Wei and Guo, Liyong and Yao, Zengwei and Kuang, Fangjun and Zhuang, Weiji and Li, Zhaoqing and Han, Zhifeng and Zhang, Dong and Zhang, Xin and Song, Xingchen and Lin, Long and Povey, Daniel},
      journal={arXiv preprint arXiv:2507.09318},
      year={2025}
}
```
<translate-content></translate-content>

---

Tranlated By [Open Ai Tx](https://github.com/OpenAiTx/OpenAiTx) | Last indexed: 2025-07-22

---