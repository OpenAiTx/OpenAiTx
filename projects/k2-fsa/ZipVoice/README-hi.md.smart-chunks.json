[
  {
    "Id": 1,
    "Content": "\n<div align=\"right\">\n  <details>\n    <summary >ЁЯМР Language</summary>\n    <div>\n      <div align=\"center\">\n        <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=en\">English</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=zh-CN\">чоАф╜Уф╕нцЦЗ</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=zh-TW\">ч╣БщлФф╕нцЦЗ</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ja\">цЧецЬмшкЮ</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ko\">эХЬъ╡ньЦ┤</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=hi\">рд╣рд┐рдиреНрджреА</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=th\">р╣Др╕Чр╕в</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=fr\">Fran├зais</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=de\">Deutsch</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=es\">Espa├▒ol</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=it\">Itapano</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ru\">╨а╤Г╤Б╤Б╨║╨╕╨╣</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=pt\">Portugu├кs</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=nl\">Nederlands</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=pl\">Polski</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ar\">╪з┘Д╪╣╪▒╪и┘К╪й</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=fa\">┘Б╪з╪▒╪│█М</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=tr\">T├╝rk├зe</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=vi\">Tiс║┐ng Viс╗Зt</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=id\">Bahasa Indonesia</a>\n      </div>\n    </div>\n  </details>\n</div>\n\n<div align=\"center\">\n\n# ZipVoiceтЪб\n\n## Fast and High-Quality Zero-Shot Text-to-Speech with Flow Matching\n</div>\n\n## Overview\n",
    "ContentSha": "4yvqxrt72y1T/XJlpvF5+w536K1FZVvNlGdllJQl3D8=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "\n<div align=\"right\">\n  <details>\n    <summary >ЁЯМР рднрд╛рд╖рд╛</summary>\n    <div>\n      <div align=\"center\">\n        <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=en\">English</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=zh-CN\">чоАф╜Уф╕нцЦЗ</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=zh-TW\">ч╣БщлФф╕нцЦЗ</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ja\">цЧецЬмшкЮ</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ko\">эХЬъ╡ньЦ┤</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=hi\">рд╣рд┐рдиреНрджреА</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=th\">р╣Др╕Чр╕в</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=fr\">Fran├зais</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=de\">Deutsch</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=es\">Espa├▒ol</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=it\">Itapano</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ru\">╨а╤Г╤Б╤Б╨║╨╕╨╣</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=pt\">Portugu├кs</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=nl\">Nederlands</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=pl\">Polski</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ar\">╪з┘Д╪╣╪▒╪и┘К╪й</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=fa\">┘Б╪з╪▒╪│█М</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=tr\">T├╝rk├зe</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=vi\">Tiс║┐ng Viс╗Зt</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=id\">Bahasa Indonesia</a>\n      </div>\n    </div>\n  </details>\n</div>\n\n<div align=\"center\">\n\n# ZipVoiceтЪб\n\n## рдлреНрд▓реЛ рдореИрдЪрд┐рдВрдЧ рдХреЗ рд╕рд╛рде рддреЗрдЬрд╝ рдФрд░ рдЙрдЪреНрдЪ рдЧреБрдгрд╡рддреНрддрд╛ рд╡рд╛рд▓реА рдЬрд╝реАрд░реЛ-рд╢реЙрдЯ рдЯреЗрдХреНрд╕реНрдЯ-рдЯреВ-рд╕реНрдкреАрдЪ\n</div>\n\n## рдЕрд╡рд▓реЛрдХрди\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 2,
    "Content": "ZipVoice is a series of fast and high-quality zero-shot TTS models based on flow matching.\n\n### 1. Key features\n\n- Small and fast: only 123M parameters.\n\n- High-quality voice cloning: state-of-the-art performance in speaker similarity, intelligibility, and naturalness.\n\n- Multi-lingual: support Chinese and English.\n\n- Multi-mode: support both single-speaker and dialogue speech generation.\n\n### 2. Model variants\n\n<table>\n  <thead>\n    <tr>\n      <th>Model Name</th>\n      <th>Description</th>\n      <th>Paper</th>\n      <th>Demo</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>ZipVoice</td>\n      <td>The basic model supporting zero-shot single-speaker TTS in both Chinese and English.</td>\n      <td rowspan=\"2\"><a href=\"https://arxiv.org/abs/2506.13053\"><img src=\"https://img.shields.io/badge/arXiv-Paper-COLOR.svg\"></a></td>\n      <td rowspan=\"2\"><a href=\"https://zipvoice.github.io\"><img src=\"https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square\"></a></td>\n    </tr>\n    <tr>\n      <td>ZipVoice-Distill</td>\n      <td>The distilled version of ZipVoice, featuring improved speed with minimal performance degradation.</td>\n    </tr>\n    <tr>\n      <td>ZipVoice-Dialog</td>\n      <td>A dialogue generation model built on ZipVoice, capable of generating single-channel two-party spoken dialogues.</td>\n      <td rowspan=\"2\"><a href=\"https://arxiv.org/abs/2507.09318\"><img src=\"https://img.shields.io/badge/arXiv-Paper-COLOR.svg\"></a></td>\n      <td rowspan=\"2\"><a href=\"https://zipvoice-dialog.github.io\"><img src=\"https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square\"></a></td>\n    </tr>",
    "ContentSha": "qUZer10kkUVucN3aqovgCkJ059aWMO67vNYjNUfJcJw=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "ZipVoice рдПрдХ рддреЗрдЬрд╝ рдФрд░ рдЙрдЪреНрдЪ-рдЧреБрдгрд╡рддреНрддрд╛ рд╡рд╛рд▓реА рдЬрд╝реАрд░реЛ-рд╢реЙрдЯ TTS рдореЙрдбрд▓ рд╢реНрд░реГрдВрдЦрд▓рд╛ рд╣реИ, рдЬреЛ рдлреНрд▓реЛ рдореИрдЪрд┐рдВрдЧ рдкрд░ рдЖрдзрд╛рд░рд┐рдд рд╣реИред\n\n### 1. рдореБрдЦреНрдп рд╡рд┐рд╢реЗрд╖рддрд╛рдПрдБ\n\n- рдЫреЛрдЯрд╛ рдФрд░ рддреЗрдЬрд╝: рдХреЗрд╡рд▓ 123M рдкреИрд░рд╛рдореАрдЯрд░ред\n\n- рдЙрдЪреНрдЪ рдЧреБрдгрд╡рддреНрддрд╛ рд╡рд╛рд▓реА рд╡реЙрдпрд╕ рдХреНрд▓реЛрдирд┐рдВрдЧ: рд╡рдХреНрддрд╛ рд╕рдорд╛рдирддрд╛, рд╕реНрдкрд╖реНрдЯрддрд╛ рдФрд░ рдкреНрд░рд╛рдХреГрддрд┐рдХрддрд╛ рдореЗрдВ рдЕрддреНрдпрд╛рдзреБрдирд┐рдХ рдкреНрд░рджрд░реНрд╢рдиред\n\n- рдмрд╣реБрднрд╛рд╖реА: рдЪреАрдиреА рдФрд░ рдЕрдВрдЧреНрд░реЗрдЬрд╝реА рдХрд╛ рд╕рдорд░реНрдерди рдХрд░рддрд╛ рд╣реИред\n\n- рдмрд╣реБ-рдореЛрдб: рдПрдХрд▓ рд╡рдХреНрддрд╛ рдФрд░ рд╕рдВрд╡рд╛рдж рднрд╛рд╖рдг рдЬрдирд░реЗрд╢рди рджреЛрдиреЛрдВ рдХрд╛ рд╕рдорд░реНрдерди рдХрд░рддрд╛ рд╣реИред\n\n### 2. рдореЙрдбрд▓ рд╡реЗрд░рд┐рдПрдВрдЯреНрд╕\n\n<table>\n  <thead>\n    <tr>\n      <th>рдореЙрдбрд▓ рдирд╛рдо</th>\n      <th>рд╡рд┐рд╡рд░рдг</th>\n      <th>рдкреЗрдкрд░</th>\n      <th>рдбреЗрдореЛ</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>ZipVoice</td>\n      <td>рдореВрд▓ рдореЙрдбрд▓ рдЬреЛ рдЪреАрдиреА рдФрд░ рдЕрдВрдЧреНрд░реЗрдЬрд╝реА рдореЗрдВ рдЬрд╝реАрд░реЛ-рд╢реЙрдЯ рдПрдХрд▓-рд╡рдХреНрддрд╛ TTS рдХрд╛ рд╕рдорд░реНрдерди рдХрд░рддрд╛ рд╣реИред</td>\n      <td rowspan=\"2\"><a href=\"https://arxiv.org/abs/2506.13053\"><img src=\"https://img.shields.io/badge/arXiv-Paper-COLOR.svg\"></a></td>\n      <td rowspan=\"2\"><a href=\"https://zipvoice.github.io\"><img src=\"https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square\"></a></td>\n    </tr>\n    <tr>\n      <td>ZipVoice-Distill</td>\n      <td>ZipVoice рдХрд╛ рдбрд┐рд╕реНрдЯрд┐рд▓реНрдб рд╕рдВрд╕реНрдХрд░рдг, рдЬрд┐рд╕рдореЗрдВ рдиреНрдпреВрдирддрдо рдкреНрд░рджрд░реНрд╢рди рд╣рд╛рдирд┐ рдХреЗ рд╕рд╛рде рдмреЗрд╣рддрд░ рдЧрддрд┐ рд╣реИред</td>\n    </tr>\n    <tr>\n      <td>ZipVoice-Dialog</td>\n      <td>ZipVoice рдкрд░ рдЖрдзрд╛рд░рд┐рдд рдПрдХ рд╕рдВрд╡рд╛рдж рдЬрдирд░реЗрд╢рди рдореЙрдбрд▓, рдЬреЛ рдПрдХрд▓-рдЪреИрдирд▓ рджреЛ-рдкрдХреНрд╖реАрдп рдмреЛрд▓реЗ рдЧрдП рд╕рдВрд╡рд╛рдж рдЙрддреНрдкрдиреНрди рдХрд░ рд╕рдХрддрд╛ рд╣реИред</td>\n      <td rowspan=\"2\"><a href=\"https://arxiv.org/abs/2507.09318\"><img src=\"https://img.shields.io/badge/arXiv-Paper-COLOR.svg\"></a></td>\n      <td rowspan=\"2\"><a href=\"https://zipvoice-dialog.github.io\"><img src=\"https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square\"></a></td>\n    </tr>",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 3,
    "Content": "    <tr>\n      <td>ZipVoice-Dialog-Stereo</td>\n      <td>The stereo variant of ZipVoice-Dialog, enabling two-channel dialogue generation with each speaker assigned to a distinct channel.</td>\n    </tr>\n  </tbody>\n</table>\n\n## News\n\n**2025/07/14**: **ZipVoice-Dialog** and **ZipVoice-Dialog-Stereo**, two spoken dialogue generation models, are released. [![arXiv](https://img.shields.io/badge/arXiv-Paper-COLOR.svg)](https://arxiv.org/abs/2507.09318) [![demo page](https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square)](https://zipvoice-dialog.github.io)\n\n**2025/07/14**: **OpenDialog** dataset, a 6.8k-hour spoken dialogue dataset, is released. Download at [![hf](https://img.shields.io/badge/%F0%9F%A4%97%20HuggingFace-Dataset-yellow)](https://huggingface.co/datasets/k2-fsa/OpenDialog), [![ms](https://img.shields.io/badge/ModelScope-Dataset-blue?logo=data)](https://www.modelscope.cn/datasets/k2-fsa/OpenDialog). Check details at [![arXiv](https://img.shields.io/badge/arXiv-Paper-COLOR.svg)](https://arxiv.org/abs/2507.09318).\n\n**2025/06/16**: **ZipVoice** and **ZipVoice-Distill** are released. [![arXiv](https://img.shields.io/badge/arXiv-Paper-COLOR.svg)](https://arxiv.org/abs/2506.13053) [![demo page](https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square)](https://zipvoice.github.io)\n\n## Installation\n\n### 1. Clone the ZipVoice repository\n",
    "ContentSha": "qyykZIxy9KKTHUZalqgKJAhZ9ZS/CaAb/vbLISMH1+E=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "    <tr>\n      <td>ZipVoice-Dialog-Stereo</td>\n      <td>ZipVoice-Dialog рдХрд╛ рд╕реНрдЯреАрд░рд┐рдпреЛ рд╕рдВрд╕реНрдХрд░рдг, рдЬреЛ рджреЛ-рдЪреИрдирд▓ рд╕рдВрд╡рд╛рдж рдирд┐рд░реНрдорд╛рдг рд╕рдХреНрд╖рдо рдХрд░рддрд╛ рд╣реИ, рдЬрд┐рд╕рдореЗрдВ рдкреНрд░рддреНрдпреЗрдХ рд╡рдХреНрддрд╛ рдХреЛ рдПрдХ рдЕрд▓рдЧ рдЪреИрдирд▓ рд╕реМрдВрдкрд╛ рдЬрд╛рддрд╛ рд╣реИред</td>\n    </tr>\n  </tbody>\n</table>\n\n## рд╕рдорд╛рдЪрд╛рд░\n\n**2025/07/14**: **ZipVoice-Dialog** рдФрд░ **ZipVoice-Dialog-Stereo**, рджреЛ рдмреЛрд▓реЗ рдЧрдП рд╕рдВрд╡рд╛рдж рдирд┐рд░реНрдорд╛рдг рдореЙрдбрд▓ рдЬрд╛рд░реА рдХрд┐рдП рдЧрдП рд╣реИрдВред [![arXiv](https://img.shields.io/badge/arXiv-Paper-COLOR.svg)](https://arxiv.org/abs/2507.09318) [![demo page](https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square)](https://zipvoice-dialog.github.io)\n\n**2025/07/14**: **OpenDialog** рдбреЗрдЯрд╛рд╕реЗрдЯ, рдПрдХ 6.8k-рдШрдВрдЯреЗ рдХреА рдмреЛрд▓реЗ рдЧрдП рд╕рдВрд╡рд╛рдж рдбреЗрдЯрд╛рд╕реЗрдЯ, рдЬрд╛рд░реА рдХреА рдЧрдИ рд╣реИред рдбрд╛рдЙрдирд▓реЛрдб рдХрд░реЗрдВ [![hf](https://img.shields.io/badge/%F0%9F%A4%97%20HuggingFace-Dataset-yellow)](https://huggingface.co/datasets/k2-fsa/OpenDialog), [![ms](https://img.shields.io/badge/ModelScope-Dataset-blue?logo=data)](https://www.modelscope.cn/datasets/k2-fsa/OpenDialog)ред рд╡рд┐рд╡рд░рдг рджреЗрдЦреЗрдВ [![arXiv](https://img.shields.io/badge/arXiv-Paper-COLOR.svg)](https://arxiv.org/abs/2507.09318).\n\n**2025/06/16**: **ZipVoice** рдФрд░ **ZipVoice-Distill** рдЬрд╛рд░реА рдХрд┐рдП рдЧрдП рд╣реИрдВред [![arXiv](https://img.shields.io/badge/arXiv-Paper-COLOR.svg)](https://arxiv.org/abs/2506.13053) [![demo page](https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square)](https://zipvoice.github.io)\n\n## рд╕реНрдерд╛рдкрдирд╛\n\n### 1. ZipVoice рд░рд┐рдкреЙрдЬрд┐рдЯрд░реА рдХреНрд▓реЛрди рдХрд░реЗрдВ\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 4,
    "Content": "```bash\ngit clone https://github.com/k2-fsa/ZipVoice.git\n```",
    "ContentSha": "JJo1EP7bWO0BWMfBMdp5X937bp3+DWhl7nAOm71R7lA=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\ngit clone https://github.com/k2-fsa/ZipVoice.git\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 5,
    "Content": "\n### 2. (Optional) Create a Python virtual environment\n",
    "ContentSha": "SdfmTQw39ITwBrkeETcUaJ4CPFr6cQ+HCqumZ483/iY=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "### 2. (рд╡реИрдХрд▓реНрдкрд┐рдХ) рдПрдХ рдкрд╛рдпрдерди рд╡рд░реНрдЪреБрдЕрд▓ рдПрдирд╡рд╛рдпрд░рдирдореЗрдВрдЯ рдмрдирд╛рдПрдВ\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 6,
    "Content": "```bash\npython3 -m venv zipvoice\nsource zipvoice/bin/activate\n```",
    "ContentSha": "glR0Rdvd5rjEtSF3LycYEtxGB8VzT68abW/ywL40bxw=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\npython3 -m venv zipvoice\nsource zipvoice/bin/activate\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 7,
    "Content": "\n### 3. Install the required packages\n",
    "ContentSha": "97VTTWuamYvk4THPyO5Ex48XMRIdHtV0dBXABNHe3qQ=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "### 3. рдЖрд╡рд╢реНрдпрдХ рдкреИрдХреЗрдЬ рдЗрдВрд╕реНрдЯреЙрд▓ рдХрд░реЗрдВ\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 8,
    "Content": "```bash\npip install -r requirements.txt\n```",
    "ContentSha": "TxMa9uJC0PmBOnm3/TRl4YDLNvSwCWaRNjyXpFhndHU=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\npip install -r requirements.txt\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 9,
    "Content": "\n### 4. Install k2 for training or efficient inference\n\n**k2 is necessary for training** and can speed up inference. Nevertheless, you can still use the inference mode of ZipVoice without installing k2.\n\n> **Note:**  Make sure to install the k2 version that matches your PyTorch and CUDA version. For example, if you are using pytorch 2.5.1 and CUDA 12.1, you can install k2 as follows:\n",
    "ContentSha": "it0kOYkTtKi6ipV/r+Px+BHDpullJx7ZxRNyR9UNc40=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "### 4. рдкреНрд░рд╢рд┐рдХреНрд╖рдг рдпрд╛ рдХреБрд╢рд▓ рдЕрдиреБрдХрд░рдг рдХреЗ рд▓рд┐рдП k2 рд╕реНрдерд╛рдкрд┐рдд рдХрд░реЗрдВ\n\n**рдкреНрд░рд╢рд┐рдХреНрд╖рдг рдХреЗ рд▓рд┐рдП k2 рдЖрд╡рд╢реНрдпрдХ рд╣реИ** рдФрд░ рдпрд╣ рдЕрдиреБрдХрд░рдг рдХреЛ рддреЗрдЬ рдХрд░ рд╕рдХрддрд╛ рд╣реИред рдлрд┐рд░ рднреА, рдЖрдк k2 рд╕реНрдерд╛рдкрд┐рдд рдХрд┐рдП рдмрд┐рдирд╛ рднреА ZipVoice рдХреЗ рдЕрдиреБрдХрд░рдг рдореЛрдб рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░ рд╕рдХрддреЗ рд╣реИрдВред\n\n> **рдиреЛрдЯ:**  рд╕реБрдирд┐рд╢реНрдЪрд┐рдд рдХрд░реЗрдВ рдХрд┐ рдЖрдк рдЕрдкрдиреЗ PyTorch рдФрд░ CUDA рд╕рдВрд╕реНрдХрд░рдг рдХреЗ рдЕрдиреБрд╕рд╛рд░ k2 рдХрд╛ рд╕рдВрд╕реНрдХрд░рдг рд╕реНрдерд╛рдкрд┐рдд рдХрд░ рд░рд╣реЗ рд╣реИрдВред рдЙрджрд╛рд╣рд░рдг рдХреЗ рд▓рд┐рдП, рдпрджрд┐ рдЖрдк pytorch 2.5.1 рдФрд░ CUDA 12.1 рдЙрдкрдпреЛрдЧ рдХрд░ рд░рд╣реЗ рд╣реИрдВ, рддреЛ рдЖрдк рдЗрд╕ рдкреНрд░рдХрд╛рд░ k2 рд╕реНрдерд╛рдкрд┐рдд рдХрд░ рд╕рдХрддреЗ рд╣реИрдВ:\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 10,
    "Content": "```bash\npip install k2==1.24.4.dev20250208+cuda12.1.torch2.5.1 -f https://k2-fsa.github.io/k2/cuda.html\n```",
    "ContentSha": "ScZHk5YUmlVP9WL5ZgwHsvBVbwTCenfwKc3cJb6nrWo=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\npip install k2==1.24.4.dev20250208+cuda12.1.torch2.5.1 -f https://k2-fsa.github.io/k2/cuda.html\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 11,
    "Content": "\nPlease refer to https://k2-fsa.org/get-started/k2/ for details.\nUsers in China mainland can refer to https://k2-fsa.org/zh-CN/get-started/k2/.\n\n- To check the k2 installation:\n",
    "ContentSha": "rY1Zhq3aduWMw4XQSft+r2qBy7l8kqnHBs8cs4FGpZ4=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "рдХреГрдкрдпрд╛ рд╡рд┐рд╡рд░рдг рдХреЗ рд▓рд┐рдП https://k2-fsa.org/get-started/k2/ рджреЗрдЦреЗрдВред\nрдЪреАрди рдореБрдЦреНрдпрднреВрдорд┐ рдХреЗ рдЙрдкрдпреЛрдЧрдХрд░реНрддрд╛ https://k2-fsa.org/zh-CN/get-started/k2/ рджреЗрдЦ рд╕рдХрддреЗ рд╣реИрдВред\n\n- k2 рдЗрдВрд╕реНрдЯреЙрд▓реЗрд╢рди рдЬрд╛рдВрдЪрдиреЗ рдХреЗ рд▓рд┐рдП:\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 12,
    "Content": "```bash\npython3 -c \"import k2; print(k2.__file__)\"\n```",
    "ContentSha": "PH4E7oc9yWRIVi2n1L4BiFuChpCHjHuJ65gAwNBxvHE=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\npython3 -c \"import k2; print(k2.__file__)\"\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 13,
    "Content": "\n## Usage\n\n### 1. Single-speaker speech generation\n\nTo generate single-speaker speech with our pre-trained ZipVoice or ZipVoice-Distill models, use the following commands (Required models will be downloaded from HuggingFace):\n\n#### 1.1 Inference of a single sentence\n",
    "ContentSha": "B4h5YyIywYfr2neMM1PwmS6nY8/eY48N4jkDeP3wG+Y=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "## рдЙрдкрдпреЛрдЧ\n\n### 1. рдПрдХрд▓-рд╡рдХреНрддрд╛ рднрд╛рд╖рдг рдЬрдирд░реЗрд╢рди\n\nрд╣рдорд╛рд░реЗ рдкреНрд░реА-рдЯреНрд░реЗрдВрдб ZipVoice рдпрд╛ ZipVoice-Distill рдореЙрдбрд▓ рдХреЗ рд╕рд╛рде рдПрдХрд▓-рд╡рдХреНрддрд╛ рднрд╛рд╖рдг рдЬрдирд░реЗрдЯ рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП, рдирд┐рдореНрдирд▓рд┐рдЦрд┐рдд рдХрдорд╛рдВрдбреНрд╕ рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░реЗрдВ (рдЖрд╡рд╢реНрдпрдХ рдореЙрдбрд▓ HuggingFace рд╕реЗ рдбрд╛рдЙрдирд▓реЛрдб рдХрд┐рдП рдЬрд╛рдПрдВрдЧреЗ):\n\n#### 1.1 рдПрдХрд▓ рд╡рд╛рдХреНрдп рдХрд╛ рдЗрдирдлрд░реЗрдВрд╕\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 14,
    "Content": "```bash\npython3 -m zipvoice.bin.infer_zipvoice \\\n    --model-name zipvoice \\\n    --prompt-wav prompt.wav \\\n    --prompt-text \"I am the transcription of the prompt wav.\" \\\n    --text \"I am the text to be synthesized.\" \\\n    --res-wav-path result.wav\n```",
    "ContentSha": "s3L0IUGcm9ppsQesBx8AKaxAjpRhRDaqb8rE/HLRinc=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\npython3 -m zipvoice.bin.infer_zipvoice \\\n    --model-name zipvoice \\\n    --prompt-wav prompt.wav \\\n    --prompt-text \"I am the transcription of the prompt wav.\" \\\n    --text \"I am the text to be synthesized.\" \\\n    --res-wav-path result.wav\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 15,
    "Content": "- `--model-name` can be `zipvoice` or `zipvoice_distill`, which are models before and after distillation, respectively.\n- If `<>` or `[]` appear in the text, strings enclosed by them will be treated as special tokens. `<>` denotes Chinese pinyin and `[]` denotes other special tags.\n\n#### 1.2 Inference of a list of sentences\n",
    "ContentSha": "9gu4tqRbp3LNcYk2S6twKEix9A9CPCJP4IQ8qVja+jw=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "- `--model-name` рдХреЛ `zipvoice` рдпрд╛ `zipvoice_distill` рд╕реЗрдЯ рдХрд┐рдпрд╛ рдЬрд╛ рд╕рдХрддрд╛ рд╣реИ, рдЬреЛ рдХреНрд░рдорд╢рдГ рдЖрд╕рд╡рди рд╕реЗ рдкрд╣рд▓реЗ рдФрд░ рдмрд╛рдж рдХреЗ рдореЙрдбрд▓ рд╣реИрдВред\n- рдпрджрд┐ рдкрд╛рда рдореЗрдВ `<>` рдпрд╛ `[]` рдЖрддреЗ рд╣реИрдВ, рддреЛ рдЙрдирдХреЗ рднреАрддрд░ рдмрдВрдж рд╕реНрдЯреНрд░рд┐рдВрдЧреНрд╕ рдХреЛ рд╡рд┐рд╢реЗрд╖ рдЯреЛрдХрди рдХреЗ рд░реВрдк рдореЗрдВ рдорд╛рдирд╛ рдЬрд╛рдПрдЧрд╛ред `<>` рдЪреАрдиреА рдкрд┐рдирдпрд┐рди рдХреЛ рджрд░реНрд╢рд╛рддрд╛ рд╣реИ рдФрд░ `[]` рдЕрдиреНрдп рд╡рд┐рд╢реЗрд╖ рдЯреИрдЧ рдХреЛ рджрд░реНрд╢рд╛рддрд╛ рд╣реИред\n\n#### 1.2 рд╡рд╛рдХреНрдпреЛрдВ рдХреА рд╕реВрдЪреА рдХрд╛ рдЕрдиреБрдорд╛рди\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 16,
    "Content": "```bash\npython3 -m zipvoice.bin.infer_zipvoice \\\n    --model-name zipvoice \\\n    --test-list test.tsv \\\n    --res-dir results\n```",
    "ContentSha": "wVKNQBx9Qf3wuIvCUTrQwDyZzDuqDpC7W9a1psJg5Ds=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\npython3 -m zipvoice.bin.infer_zipvoice \\\n    --model-name zipvoice \\\n    --test-list test.tsv \\\n    --res-dir results\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 17,
    "Content": "\n- Each line of `test.tsv` is in the format of `{wav_name}\\t{prompt_transcription}\\t{prompt_wav}\\t{text}`.\n\n### 2. Dialogue speech generation\n\n#### 2.1 Inference command\n\nTo generate two-party spoken dialogues with our pre-trained ZipVoice-Dialogue or ZipVoice-Dialogue-Stereo models, use the following commands (Required models will be downloaded from HuggingFace):\n",
    "ContentSha": "bkRixLiKF8JLzfAqriyk1UZSkb5qCPhJVvI3VACgZos=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "- `test.tsv` рдХреА рдкреНрд░рддреНрдпреЗрдХ рдкрдВрдХреНрддрд┐ рдЗрд╕ рдкреНрд░рд╛рд░реВрдк рдореЗрдВ рд╣реЛрддреА рд╣реИ: `{wav_name}\\t{prompt_transcription}\\t{prompt_wav}\\t{text}`ред\n\n### 2. рд╕рдВрд╡рд╛рдж рднрд╛рд╖рдг рдирд┐рд░реНрдорд╛рдг\n\n#### 2.1 рдкреВрд░реНрд╡рд╛рдиреБрдорд╛рди рдХрдорд╛рдВрдб\n\nрд╣рдорд╛рд░реЗ рдкреНрд░реА-рдЯреНрд░реЗрдВрдб ZipVoice-Dialogue рдпрд╛ ZipVoice-Dialogue-Stereo рдореЙрдбрд▓ рдХреЗ рд╕рд╛рде рджреЛ-рдкрдХреНрд╖реАрдп рдмреЛрд▓реЗ рдЧрдП рд╕рдВрд╡рд╛рдж рдЙрддреНрдкрдиреНрди рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП, рдирд┐рдореНрдирд▓рд┐рдЦрд┐рдд рдХрдорд╛рдВрдб рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░реЗрдВ (рдЖрд╡рд╢реНрдпрдХ рдореЙрдбрд▓ HuggingFace рд╕реЗ рдбрд╛рдЙрдирд▓реЛрдб рдХрд┐рдП рдЬрд╛рдПрдВрдЧреЗ):\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 18,
    "Content": "```bash\npython3 -m zipvoice.bin.infer_zipvoice_dialog \\\n    --model-name \"zipvoice_dialog\" \\\n    --test-list test.tsv \\\n    --res-dir results\n```",
    "ContentSha": "SmNrjO7IvCsVTs0ROGG3evCMgCtj54DYGkGCZbRdz8k=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\npython3 -m zipvoice.bin.infer_zipvoice_dialog \\\n    --model-name \"zipvoice_dialog\" \\\n    --test-list test.tsv \\\n    --res-dir results\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 19,
    "Content": "\n- `--model-name` can be `zipvoice_dialog` or `zipvoice_dialog_stereo`,\n    which generate mono and stereo dialogues, respectively.\n\n#### 2.2 Input formats\n\nEach line of `test.tsv` is in one of the following formats:\n\n(1) **Merged prompt format** where the audios and transcriptions of two speakers prompts are merged into one prompt wav file:",
    "ContentSha": "e336Qt1qFvFmNefniyPEWJue5A1mLBZUSlD6p1+H8To=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "- `--model-name` рдпрд╛ рддреЛ `zipvoice_dialog` рдпрд╛ `zipvoice_dialog_stereo` рд╣реЛ рд╕рдХрддрд╛ рд╣реИ,\n    рдЬреЛ рдХреНрд░рдорд╢рдГ рдореЛрдиреЛ рдФрд░ рд╕реНрдЯреАрд░рд┐рдпреЛ рд╕рдВрд╡рд╛рдж рдЙрддреНрдкрдиреНрди рдХрд░рддреЗ рд╣реИрдВред\n\n#### 2.2 рдЗрдирдкреБрдЯ рдкреНрд░рд╛рд░реВрдк\n\n`test.tsv` рдХреА рдкреНрд░рддреНрдпреЗрдХ рдкрдВрдХреНрддрд┐ рдирд┐рдореНрдирд▓рд┐рдЦрд┐рдд рдкреНрд░рд╛рд░реВрдкреЛрдВ рдореЗрдВ рд╕реЗ рдПрдХ рдореЗрдВ рд╣реЛрддреА рд╣реИ:\n\n(1) **рдорд░реНрдЬреНрдб рдкреНрд░реЙрдореНрдкреНрдЯ рдкреНрд░рд╛рд░реВрдк** рдЬрд┐рд╕рдореЗрдВ рджреЛ рд╡рдХреНрддрд╛рдУрдВ рдХреЗ рдкреНрд░реЙрдореНрдкреНрдЯ рдСрдбрд┐рдпреЛ рдФрд░ рдЯреНрд░рд╛рдВрд╕рдХреНрд░рд┐рдкреНрд╢рди рдХреЛ рдПрдХ рдкреНрд░реЙрдореНрдкреНрдЯ рд╡реЗрд╡ рдлрд╝рд╛рдЗрд▓ рдореЗрдВ рдорд░реНрдЬ рдХрд░ рджрд┐рдпрд╛ рдЬрд╛рддрд╛ рд╣реИ:\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 20,
    "Content": "```\n{wav_name}\\t{prompt_transcription}\\t{prompt_wav}\\t{text}\n```",
    "ContentSha": "F8c2S4lpByZ5Nhd693ESYvOeDT7lT7vF2Txm3q64ync=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```\n{wav_name}\\t{prompt_transcription}\\t{prompt_wav}\\t{text}\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 21,
    "Content": "\n- `wav_name` is the name of the output wav file.\n- `prompt_transcription` is the transcription of the conversational prompt wav, e.g, \"[S1] Hello. [S2] How are you?\"\n- `prompt_wav` is the path to the prompt wav.\n- `text` is the text to be synthesized, e.g. \"[S1] I'm fine. [S2] What's your name? [S1] I'm Eric. [S2] Hi Eric.\"\n\n(2) **Splitted prompt format** where the audios and transciptions of two speakers exist in separate files:\n",
    "ContentSha": "Gj5W4GhLunSOhvyVf7uwdfnNL3DFgIeOvHB01tH9I/A=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "\n- `wav_name` рдЖрдЙрдЯрдкреБрдЯ рд╡реЗрд╡ рдлрд╛рдЗрд▓ рдХрд╛ рдирд╛рдо рд╣реИред\n- `prompt_transcription` рд╡рд╛рд░реНрддрд╛рд▓рд╛рдк рд╕рдВрдХреЗрдд рд╡реЗрд╡ рдХреА рдЯреНрд░рд╛рдВрд╕рдХреНрд░рд┐рдкреНрд╢рди рд╣реИ, рдЙрджрд╛рд╣рд░рдг рдХреЗ рд▓рд┐рдП, \"[S1] рд╣реИрд▓реЛред [S2] рдЖрдк рдХреИрд╕реЗ рд╣реИрдВ?\"\n- `prompt_wav` рд╕рдВрдХреЗрдд рд╡реЗрд╡ рдХрд╛ рдкрде рд╣реИред\n- `text` рд╡рд╣ рдЯреЗрдХреНрд╕реНрдЯ рд╣реИ рдЬрд┐рд╕реЗ рд╕рд┐рдВрдереЗрд╕рд╛рдЗрдЬрд╝ рдХрд┐рдпрд╛ рдЬрд╛рдирд╛ рд╣реИ, рдЬреИрд╕реЗ рдХрд┐ \"[S1] рдореИрдВ рдареАрдХ рд╣реВрдБред [S2] рдЖрдкрдХрд╛ рдирд╛рдо рдХреНрдпрд╛ рд╣реИ? [S1] рдореЗрд░рд╛ рдирд╛рдо рдПрд░рд┐рдХ рд╣реИред [S2] рд╣рд╛рдп рдПрд░рд┐рдХред\"\n\n(2) **рд╡рд┐рднрд╛рдЬрд┐рдд рд╕рдВрдХреЗрдд рдкреНрд░рд╛рд░реВрдк** рдЬрд┐рд╕рдореЗрдВ рджреЛ рд╡рдХреНрддрд╛рдУрдВ рдХреА рдСрдбрд┐рдпреЛ рдФрд░ рдЯреНрд░рд╛рдВрд╕рдХреНрд░рд┐рдкреНрд╢рди рдЕрд▓рдЧ-рдЕрд▓рдЧ рдлрд╛рдЗрд▓реЛрдВ рдореЗрдВ рд╣реЛрддреА рд╣реИрдВ:\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 22,
    "Content": "```\n{wav_name}\\t{spk1_prompt_transcription}\\t{spk2_prompt_transcription}\\t{spk1_prompt_wav}\\t{spk2_prompt_wav}\\t{text}\n```",
    "ContentSha": "zPaMLy5mnnAP5WeOve+uEMlDenRN6Anuru4V4waQX9w=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```\n{wav_name}\\t{spk1_prompt_transcription}\\t{spk2_prompt_transcription}\\t{spk1_prompt_wav}\\t{spk2_prompt_wav}\\t{text}\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 23,
    "Content": "\n- `wav_name` is the name of the output wav file.\n- `spk1_prompt_transcription` is the transcription of the first speaker's prompt wav, e.g, \"Hello\"\n- `spk2_prompt_transcription` is the transcription of the second speaker's prompt wav, e.g, \"How are you?\"\n- `spk1_prompt_wav` is the path to the first speaker's prompt wav file.\n- `spk2_prompt_wav` is the path to the second speaker's prompt wav file.\n- `text` is the text to be synthesized, e.g. \"[S1] I'm fine. [S2] What's your name? [S1] I'm Eric. [S2] Hi Eric.\"\n\n### 3 Guidance for better usage:\n\n#### 3.1 Prompt length\n\nWe recommand a short prompt wav file (e.g., less than 3 seconds for single-speaker speech generation, less than 10 seconds for dialogue speech generation) for faster inference speed. A very long prompt will slow down the inference and degenerate the speech quality.\n\n#### 3.2 Speed optimization\n\nIf the inference speed is unsatisfactory, you can speed it up as follows:\n\n- **Distill model and less steps**: For the single-speaker speech generation model, we use the `zipvoice` model by default for better speech quality. If faster speed is a priority, you can switch to the `zipvoice_distill` and can reduce the `--num-steps` to as low as `4` (8 by default).\n\n- **CPU speedup with multi-threading**: When running on CPU, you can pass the `--num-thread` parameter (e.g., `--num-thread 4`) to increase the number of threads for faster speed. We use 1 thread by default.\n\n- **CPU speedup with ONNX**: When running on CPU, you can use ONNX models with `zipvoice.bin.infer_zipvoice_onnx` for faster speed (haven't supported ONNX for dialogue generation models yet). For even faster speed, you can further set `--onnx-int8 True` to use an INT8-quantized ONNX model. Note that the quantized model will result in a certain degree of speech quality degradation. **Don't use ONNX on GPU**, as it is slower than PyTorch on GPU.\n\n- **GPU Acceleration with NVIDIA TensorRT**: For a significant performance boost on NVIDIA GPUs, first export the model to a TensorRT engine using zipvoice.bin.tensorrt_export. Then, run inference on your dataset (e.g., a Hugging Face dataset) with zipvoice.bin.infer_zipvoice. This can achieve approximately 2x the throughput compared to the standard PyTorch implementation on a GPU.\n\n#### 3.3 Memory control\n\nThe given text will be splitted into chunks based on punctuation (for single-speaker speech generation) or speaker-turn symbol (for dialogue speech generation). Then, the chunked texts will be processed in batches. Therefore, the model can process arbitrarily long text with almost constant memory usage. You can control memory usage by adjusting the `--max-duration` parameter.\n\n#### 3.4 \"Raw\" evaluation\n\nBy default, we preprocess inputs (prompt wav, prompt transcription, and text) for efficient inference and better performance. If you want to evaluate the modelтАЩs \"raw\" performance using exact provided inputs (e.g., to reproduce the results in our paper), you can pass `--raw-evaluation True`.\n\n#### 3.5 Short text\n\nWhen generating speech for very short texts (e.g., one or two words), the generated speech may sometimes omit certain pronunciations. To resolve this issue, you can pass `--speed 0.3` (where 0.3 is a tunable value) to extend the duration of the generated speech.\n\n#### 3.6 Correcting mispronounced chinese polyphone characters\n",
    "ContentSha": "6AwuUDJOteKl74OkYkXg6kAf+AJPVnWbItdRfk762Xs=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "- `wav_name` рдЖрдЙрдЯрдкреБрдЯ wav рдлрд╝рд╛рдЗрд▓ рдХрд╛ рдирд╛рдо рд╣реИред\n- `spk1_prompt_transcription` рдкрд╣рд▓реЗ рд╡рдХреНрддрд╛ рдХреЗ рдкреНрд░реЙрдореНрдкреНрдЯ wav рдХреА рдЯреНрд░рд╛рдВрд╕рдХреНрд░рд┐рдкреНрд╢рди рд╣реИ, рдЬреИрд╕реЗ, \"Hello\"\n- `spk2_prompt_transcription` рджреВрд╕рд░реЗ рд╡рдХреНрддрд╛ рдХреЗ рдкреНрд░реЙрдореНрдкреНрдЯ wav рдХреА рдЯреНрд░рд╛рдВрд╕рдХреНрд░рд┐рдкреНрд╢рди рд╣реИ, рдЬреИрд╕реЗ, \"How are you?\"\n- `spk1_prompt_wav` рдкрд╣рд▓реЗ рд╡рдХреНрддрд╛ рдХреЗ рдкреНрд░реЙрдореНрдкреНрдЯ wav рдлрд╝рд╛рдЗрд▓ рдХрд╛ рдкрде рд╣реИред\n- `spk2_prompt_wav` рджреВрд╕рд░реЗ рд╡рдХреНрддрд╛ рдХреЗ рдкреНрд░реЙрдореНрдкреНрдЯ wav рдлрд╝рд╛рдЗрд▓ рдХрд╛ рдкрде рд╣реИред\n- `text` рд╡рд╣ рдкрд╛рда рд╣реИ рдЬрд┐рд╕реЗ рд╕рд┐рдВрдереЗрд╕рд╛рдЗрдЬрд╝ рдХрд┐рдпрд╛ рдЬрд╛рдирд╛ рд╣реИ, рдЬреИрд╕реЗ, \"[S1] I'm fine. [S2] What's your name? [S1] I'm Eric. [S2] Hi Eric.\"\n\n### 3 рдмреЗрд╣рддрд░ рдЙрдкрдпреЛрдЧ рдХреЗ рд▓рд┐рдП рдорд╛рд░реНрдЧрджрд░реНрд╢рди:\n\n#### 3.1 рдкреНрд░реЙрдореНрдкреНрдЯ рдХреА рд▓рдВрдмрд╛рдИ\n\nрд╣рдо рдПрдХ рдЫреЛрдЯрд╛ рдкреНрд░реЙрдореНрдкреНрдЯ wav рдлрд╝рд╛рдЗрд▓ (рдЬреИрд╕реЗ, рдПрдХрд▓-рд╡рдХреНрддрд╛ рднрд╛рд╖рдг рдирд┐рд░реНрдорд╛рдг рдХреЗ рд▓рд┐рдП 3 рд╕реЗрдХрдВрдб рд╕реЗ рдХрдо, рд╕рдВрд╡рд╛рдж рднрд╛рд╖рдг рдирд┐рд░реНрдорд╛рдг рдХреЗ рд▓рд┐рдП 10 рд╕реЗрдХрдВрдб рд╕реЗ рдХрдо) рдХреА рд╕рд▓рд╛рд╣ рджреЗрддреЗ рд╣реИрдВ рддрд╛рдХрд┐ рдЗрдирдлреЗрд░реЗрдВрд╕ рдЧрддрд┐ рддреЗрдЬ рд╣реЛред рдмрд╣реБрдд рд▓рдВрдмрд╛ рдкреНрд░реЙрдореНрдкреНрдЯ рдЗрдирдлреЗрд░реЗрдВрд╕ рдХреЛ рдзреАрдорд╛ рдХрд░ рджреЗрдЧрд╛ рдФрд░ рднрд╛рд╖рдг рдХреА рдЧреБрдгрд╡рддреНрддрд╛ рдХреЛ рдШрдЯрд╛ рд╕рдХрддрд╛ рд╣реИред\n\n#### 3.2 рдЧрддрд┐ рдЕрдиреБрдХреВрд▓рди\n\nрдпрджрд┐ рдЗрдирдлреЗрд░реЗрдВрд╕ рдЧрддрд┐ рдЕрд╕рдВрддреЛрд╖рдЬрдирдХ рд╣реИ, рддреЛ рдЖрдк рдЗрд╕реЗ рдирд┐рдореНрдирд▓рд┐рдЦрд┐рдд рддрд░реАрдХреЛрдВ рд╕реЗ рддреЗрдЬ рдХрд░ рд╕рдХрддреЗ рд╣реИрдВ:\n\n- **рдбрд┐рд╕реНрдЯрд┐рд▓ рдореЙрдбрд▓ рдФрд░ рдХрдо рд╕реНрдЯреЗрдкреНрд╕**: рдПрдХрд▓-рд╡рдХреНрддрд╛ рднрд╛рд╖рдг рдирд┐рд░реНрдорд╛рдг рдореЙрдбрд▓ рдХреЗ рд▓рд┐рдП, рд╣рдо рдмреЗрд╣рддрд░ рднрд╛рд╖рдг рдЧреБрдгрд╡рддреНрддрд╛ рдХреЗ рд▓рд┐рдП рдбрд┐рдлрд╝реЙрд▓реНрдЯ рд░реВрдк рд╕реЗ `zipvoice` рдореЙрдбрд▓ рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рддреЗ рд╣реИрдВред рдпрджрд┐ рддреЗрдЬ рдЧрддрд┐ рдкреНрд░рд╛рдердорд┐рдХрддрд╛ рд╣реИ, рддреЛ рдЖрдк `zipvoice_distill` рдкрд░ рд╕реНрд╡рд┐рдЪ рдХрд░ рд╕рдХрддреЗ рд╣реИрдВ рдФрд░ `--num-steps` рдХреЛ рдиреНрдпреВрдирддрдо `4` (рдбрд┐рдлрд╝реЙрд▓реНрдЯ 8) рддрдХ рдХрдо рдХрд░ рд╕рдХрддреЗ рд╣реИрдВред\n\n- **CPU рдорд▓реНрдЯреА-рдереНрд░реЗрдбрд┐рдВрдЧ рдХреЗ рд╕рд╛рде рдЧрддрд┐ рдмрдврд╝рд╛рдирд╛**: рдпрджрд┐ рдЖрдк CPU рдкрд░ рдЪрд▓рд╛ рд░рд╣реЗ рд╣реИрдВ, рддреЛ рдЖрдк рддреЗрдЬ рдЧрддрд┐ рдХреЗ рд▓рд┐рдП `--num-thread` рдкреИрд░рд╛рдореАрдЯрд░ (рдЬреИрд╕реЗ, `--num-thread 4`) рджреЗ рд╕рдХрддреЗ рд╣реИрдВ рддрд╛рдХрд┐ рдереНрд░реЗрдбреНрд╕ рдХреА рд╕рдВрдЦреНрдпрд╛ рдмрдврд╝рд╛рдИ рдЬрд╛ рд╕рдХреЗред рдбрд┐рдлрд╝реЙрд▓реНрдЯ рд░реВрдк рд╕реЗ рд╣рдо 1 рдереНрд░реЗрдб рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рддреЗ рд╣реИрдВред\n\n- **CPU рдкрд░ ONNX рдХреЗ рд╕рд╛рде рдЧрддрд┐ рдмрдврд╝рд╛рдирд╛**: CPU рдкрд░ рдЪрд▓рддреЗ рд╕рдордп, рдЖрдк рддреЗрдЬ рдЧрддрд┐ рдХреЗ рд▓рд┐рдП ONNX рдореЙрдбрд▓ рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░ рд╕рдХрддреЗ рд╣реИрдВ `zipvoice.bin.infer_zipvoice_onnx` рдХреЗ рд╕рд╛рде (рд╕рдВрд╡рд╛рдж рдирд┐рд░реНрдорд╛рдг рдореЙрдбрд▓ рдХреЗ рд▓рд┐рдП ONNX рдХрд╛ рд╕рдорд░реНрдерди рдирд╣реАрдВ рд╣реИ)ред рдФрд░ рднреА рддреЗрдЬ рдЧрддрд┐ рдХреЗ рд▓рд┐рдП, рдЖрдк `--onnx-int8 True` рд╕реЗрдЯ рдХрд░ рд╕рдХрддреЗ рд╣реИрдВ рддрд╛рдХрд┐ INT8-рдХреНрд╡рд╛рдВрдЯрд╛рдЗрдЬрд╝реНрдб ONNX рдореЙрдбрд▓ рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд┐рдпрд╛ рдЬрд╛ рд╕рдХреЗред рдзреНрдпрд╛рди рджреЗрдВ рдХрд┐ рдХреНрд╡рд╛рдВрдЯрд╛рдЗрдЬрд╝реНрдб рдореЙрдбрд▓ рд╕реЗ рднрд╛рд╖рдг рдЧреБрдгрд╡рддреНрддрд╛ рдореЗрдВ рдХреБрдЫ рдЧрд┐рд░рд╛рд╡рдЯ рдЖ рд╕рдХрддреА рд╣реИред **GPU рдкрд░ ONNX рдХрд╛ рдЙрдкрдпреЛрдЧ рди рдХрд░реЗрдВ**, рдХреНрдпреЛрдВрдХрд┐ GPU рдкрд░ рдпрд╣ PyTorch рд╕реЗ рдзреАрдорд╛ рд╣реИред\n\n- **NVIDIA TensorRT рдХреЗ рд╕рд╛рде GPU рдПрдХреНрд╕реЗрд▓реЗрд░реЗрд╢рди**: NVIDIA GPU рдкрд░ рдорд╣рддреНрд╡рдкреВрд░реНрдг рдкреНрд░рджрд░реНрд╢рди рдмрдврд╝рд╛рдиреЗ рдХреЗ рд▓рд┐рдП, рдкрд╣рд▓реЗ zipvoice.bin.tensorrt_export рдХреЗ рд╕рд╛рде рдореЙрдбрд▓ рдХреЛ TensorRT рдЗрдВрдЬрди рдореЗрдВ рдПрдХреНрд╕рдкреЛрд░реНрдЯ рдХрд░реЗрдВред рдлрд┐рд░, рдЕрдкрдиреЗ рдбреЗрдЯрд╛рд╕реЗрдЯ (рдЬреИрд╕реЗ, Hugging Face рдбреЗрдЯрд╛рд╕реЗрдЯ) рдкрд░ zipvoice.bin.infer_zipvoice рдХреЗ рд╕рд╛рде рдЗрдирдлреЗрд░реЗрдВрд╕ рдЪрд▓рд╛рдПрдБред рдпрд╣ GPU рдкрд░ рд╕реНрдЯреИрдВрдбрд░реНрдб PyTorch рдЗрдореНрдкреНрд▓реАрдореЗрдВрдЯреЗрд╢рди рдХреА рддреБрд▓рдирд╛ рдореЗрдВ рд▓рдЧрднрдЧ 2x рдереНрд░реВрдкреБрдЯ рдкреНрд░рд╛рдкреНрдд рдХрд░ рд╕рдХрддрд╛ рд╣реИред\n\n#### 3.3 рдореЗрдореЛрд░реА рдирд┐рдпрдВрддреНрд░рдг\n\nрджрд┐рдпрд╛ рдЧрдпрд╛ рдЯреЗрдХреНрд╕реНрдЯ рд╡рд┐рд░рд╛рдо рдЪрд┐рд╣реНрди (рдПрдХрд▓-рд╡рдХреНрддрд╛ рднрд╛рд╖рдг рдирд┐рд░реНрдорд╛рдг рдХреЗ рд▓рд┐рдП) рдпрд╛ рд╡рдХреНрддрд╛-рдЯрд░реНрди рдЪрд┐рдиреНрд╣ (рд╕рдВрд╡рд╛рдж рднрд╛рд╖рдг рдирд┐рд░реНрдорд╛рдг рдХреЗ рд▓рд┐рдП) рдХреЗ рдЖрдзрд╛рд░ рдкрд░ рднрд╛рдЧреЛрдВ рдореЗрдВ рд╡рд┐рднрд╛рдЬрд┐рдд рдХрд┐рдпрд╛ рдЬрд╛рдПрдЧрд╛ред рдЗрд╕рдХреЗ рдмрд╛рдж, рдЗрди рднрд╛рдЧреЛрдВ рдХреЛ рдмреИрдЪ рдореЗрдВ рдкреНрд░реЛрд╕реЗрд╕ рдХрд┐рдпрд╛ рдЬрд╛рдПрдЧрд╛ред рдЗрд╕ рдкреНрд░рдХрд╛рд░, рдореЙрдбрд▓ рд▓рдЧрднрдЧ рд╕реНрдерд┐рд░ рдореЗрдореЛрд░реА рдЙрдкрдпреЛрдЧ рдХреЗ рд╕рд╛рде рдХрд┐рд╕реА рднреА рд▓рдВрдмрд╛рдИ рдХрд╛ рдЯреЗрдХреНрд╕реНрдЯ рдкреНрд░реЛрд╕реЗрд╕ рдХрд░ рд╕рдХрддрд╛ рд╣реИред рдЖрдк `--max-duration` рдкреИрд░рд╛рдореАрдЯрд░ рдХреЛ рд╕рдорд╛рдпреЛрдЬрд┐рдд рдХрд░рдХреЗ рдореЗрдореЛрд░реА рдЙрдкрдпреЛрдЧ рдХреЛ рдирд┐рдпрдВрддреНрд░рд┐рдд рдХрд░ рд╕рдХрддреЗ рд╣реИрдВред\n\n#### 3.4 \"рд░реЙ\" рдореВрд▓реНрдпрд╛рдВрдХрди\n\nрдбрд┐рдлрд╝реЙрд▓реНрдЯ рд░реВрдк рд╕реЗ, рд╣рдо рдЗрдирдкреБрдЯреНрд╕ (рдкреНрд░реЙрдореНрдкреНрдЯ wav, рдкреНрд░реЙрдореНрдкреНрдЯ рдЯреНрд░рд╛рдВрд╕рдХреНрд░рд┐рдкреНрд╢рди, рдФрд░ рдЯреЗрдХреНрд╕реНрдЯ) рдХреЛ рдХреБрд╢рд▓ рдЗрдирдлреЗрд░реЗрдВрд╕ рдФрд░ рдмреЗрд╣рддрд░ рдкреНрд░рджрд░реНрд╢рди рдХреЗ рд▓рд┐рдП рдкреВрд░реНрд╡-рдкреНрд░рдХреНрд░рд┐рдпрд╛ рдХрд░рддреЗ рд╣реИрдВред рдпрджрд┐ рдЖрдк рдореЙрдбрд▓ рдХреЗ \"рд░реЙ\" рдкреНрд░рджрд░реНрд╢рди рдХрд╛ рдореВрд▓реНрдпрд╛рдВрдХрди рдХрд░рдирд╛ рдЪрд╛рд╣рддреЗ рд╣реИрдВ, рдЬреИрд╕реЗ рдХрд┐ рд╣рдорд╛рд░реЗ рдкреЗрдкрд░ рдореЗрдВ рджрд┐рдП рдЧрдП рдкрд░рд┐рдгрд╛рдореЛрдВ рдХреЛ рдкреБрдирдГ рдЙрддреНрдкрдиреНрди рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП, рддреЛ рдЖрдк `--raw-evaluation True` рдкрд╛рд╕ рдХрд░ рд╕рдХрддреЗ рд╣реИрдВред\n\n#### 3.5 рдЫреЛрдЯрд╛ рдЯреЗрдХреНрд╕реНрдЯ\n\nрдмрд╣реБрдд рдЫреЛрдЯреЗ рдЯреЗрдХреНрд╕реНрдЯ (рдЬреИрд╕реЗ, рдПрдХ рдпрд╛ рджреЛ рд╢рдмреНрдж) рдХреЗ рд▓рд┐рдП рднрд╛рд╖рдг рдЬреЗрдирд░реЗрдЯ рдХрд░рддреЗ рд╕рдордп, рдХрднреА-рдХрднреА рдХреБрдЫ рдЙрдЪреНрдЪрд╛рд░рдг рдЫреВрдЯ рд╕рдХрддреЗ рд╣реИрдВред рдЗрд╕ рд╕рдорд╕реНрдпрд╛ рдХреЗ рд╕рдорд╛рдзрд╛рди рдХреЗ рд▓рд┐рдП, рдЖрдк `--speed 0.3` (рдЬрд╣рд╛рдБ 0.3 рдПрдХ рд╕рдорд╛рдпреЛрдЬреНрдп рдорд╛рди рд╣реИ) рдкрд╛рд╕ рдХрд░ рд╕рдХрддреЗ рд╣реИрдВ рддрд╛рдХрд┐ рдЬреЗрдирд░реЗрдЯреЗрдб рднрд╛рд╖рдг рдХреА рдЕрд╡рдзрд┐ рдмрдврд╝рд╛рдИ рдЬрд╛ рд╕рдХреЗред\n\n#### 3.6 рдЧрд▓рдд рдЙрдЪреНрдЪрд╛рд░рд┐рдд рдЪреАрдиреА рдмрд╣реБрд╡рд░реНрдгреА рдЕрдХреНрд╖рд░реЛрдВ рдХреЛ рд╕реБрдзрд╛рд░рдирд╛\n\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "- `wav_name` рдЖрдЙрдЯрдкреБрдЯ wav рдлрд╝рд╛рдЗрд▓ рдХрд╛ рдирд╛рдо рд╣реИред"
      },
      {
        "row": 2,
        "rowsha": "6vgIR6WfUAFmULhn8LhxFttPwZEo/YwGhN1DAECwHCQ=",
        "originContent": "- `wav_name` is the name of the output wav file.",
        "translatedContent": "- `spk1_prompt_transcription` рдкрд╣рд▓реЗ рд╡рдХреНрддрд╛ рдХреЗ рдкреНрд░реЙрдореНрдкреНрдЯ wav рдХреА рдЯреНрд░рд╛рдВрд╕рдХреНрд░рд┐рдкреНрд╢рди рд╣реИ, рдЬреИрд╕реЗ, \"Hello\""
      },
      {
        "row": 3,
        "rowsha": "7BNq8UaBvTut4Ow/oJBAgIDTn3EwEZXK7mlUaYdFwqw=",
        "originContent": "- `spk1_prompt_transcription` is the transcription of the first speaker's prompt wav, e.g, \"Hello\"",
        "translatedContent": "- `spk2_prompt_transcription` рджреВрд╕рд░реЗ рд╡рдХреНрддрд╛ рдХреЗ рдкреНрд░реЙрдореНрдкреНрдЯ wav рдХреА рдЯреНрд░рд╛рдВрд╕рдХреНрд░рд┐рдкреНрд╢рди рд╣реИ, рдЬреИрд╕реЗ, \"How are you?\""
      },
      {
        "row": 4,
        "rowsha": "CES8w9dqVdkdJyOJBUVP282aaKeevVWB3d/+59TEsuk=",
        "originContent": "- `spk2_prompt_transcription` is the transcription of the second speaker's prompt wav, e.g, \"How are you?\"",
        "translatedContent": "- `spk1_prompt_wav` рдкрд╣рд▓реЗ рд╡рдХреНрддрд╛ рдХреЗ рдкреНрд░реЙрдореНрдкреНрдЯ wav рдлрд╝рд╛рдЗрд▓ рдХрд╛ рдкрде рд╣реИред"
      },
      {
        "row": 5,
        "rowsha": "gXLLRf4BR7Xko2q2l4nK04KIs/L8CjvZ/UBQaP1+vck=",
        "originContent": "- `spk1_prompt_wav` is the path to the first speaker's prompt wav file.",
        "translatedContent": "- `spk2_prompt_wav` рджреВрд╕рд░реЗ рд╡рдХреНрддрд╛ рдХреЗ рдкреНрд░реЙрдореНрдкреНрдЯ wav рдлрд╝рд╛рдЗрд▓ рдХрд╛ рдкрде рд╣реИред"
      },
      {
        "row": 6,
        "rowsha": "oS1+heJwBnnDtA57WYtG6LbzxK79DOIeb8hwhZQwcDg=",
        "originContent": "- `spk2_prompt_wav` is the path to the second speaker's prompt wav file.",
        "translatedContent": "- `text` рд╡рд╣ рдкрд╛рда рд╣реИ рдЬрд┐рд╕реЗ рд╕рд┐рдВрдереЗрд╕рд╛рдЗрдЬрд╝ рдХрд┐рдпрд╛ рдЬрд╛рдирд╛ рд╣реИ, рдЬреИрд╕реЗ, \"[S1] I'm fine. [S2] What's your name? [S1] I'm Eric. [S2] Hi Eric.\""
      },
      {
        "row": 7,
        "rowsha": "M4Z2DDajNBdyF/JosIaDZ44oyZnjNA7lzfGzEpuoako=",
        "originContent": "- `text` is the text to be synthesized, e.g. \"[S1] I'm fine. [S2] What's your name? [S1] I'm Eric. [S2] Hi Eric.\"",
        "translatedContent": ""
      },
      {
        "row": 8,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "### 3 рдмреЗрд╣рддрд░ рдЙрдкрдпреЛрдЧ рдХреЗ рд▓рд┐рдП рдорд╛рд░реНрдЧрджрд░реНрд╢рди:"
      },
      {
        "row": 9,
        "rowsha": "SdDI3h73wOzKSM3kbrbNrmpigHGer7kumuaZsQgAeao=",
        "originContent": "### 3 Guidance for better usage:",
        "translatedContent": ""
      },
      {
        "row": 10,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "#### 3.1 рдкреНрд░реЙрдореНрдкреНрдЯ рдХреА рд▓рдВрдмрд╛рдИ"
      },
      {
        "row": 11,
        "rowsha": "cVxukE6jyFFOxlNKI5ecOTo/suYYJ8hnYyW2XA2wg+o=",
        "originContent": "#### 3.1 Prompt length",
        "translatedContent": ""
      },
      {
        "row": 12,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "рд╣рдо рдПрдХ рдЫреЛрдЯрд╛ рдкреНрд░реЙрдореНрдкреНрдЯ wav рдлрд╝рд╛рдЗрд▓ (рдЬреИрд╕реЗ, рдПрдХрд▓-рд╡рдХреНрддрд╛ рднрд╛рд╖рдг рдирд┐рд░реНрдорд╛рдг рдХреЗ рд▓рд┐рдП 3 рд╕реЗрдХрдВрдб рд╕реЗ рдХрдо, рд╕рдВрд╡рд╛рдж рднрд╛рд╖рдг рдирд┐рд░реНрдорд╛рдг рдХреЗ рд▓рд┐рдП 10 рд╕реЗрдХрдВрдб рд╕реЗ рдХрдо) рдХреА рд╕рд▓рд╛рд╣ рджреЗрддреЗ рд╣реИрдВ рддрд╛рдХрд┐ рдЗрдирдлреЗрд░реЗрдВрд╕ рдЧрддрд┐ рддреЗрдЬ рд╣реЛред рдмрд╣реБрдд рд▓рдВрдмрд╛ рдкреНрд░реЙрдореНрдкреНрдЯ рдЗрдирдлреЗрд░реЗрдВрд╕ рдХреЛ рдзреАрдорд╛ рдХрд░ рджреЗрдЧрд╛ рдФрд░ рднрд╛рд╖рдг рдХреА рдЧреБрдгрд╡рддреНрддрд╛ рдХреЛ рдШрдЯрд╛ рд╕рдХрддрд╛ рд╣реИред"
      },
      {
        "row": 13,
        "rowsha": "f19zq78QrLul7wiVSlCSojGS7qNEvtef9GFg6AA8eMY=",
        "originContent": "We recommand a short prompt wav file (e.g., less than 3 seconds for single-speaker speech generation, less than 10 seconds for dialogue speech generation) for faster inference speed. A very long prompt will slow down the inference and degenerate the speech quality.",
        "translatedContent": ""
      },
      {
        "row": 14,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "#### 3.2 рдЧрддрд┐ рдЕрдиреБрдХреВрд▓рди"
      },
      {
        "row": 15,
        "rowsha": "lpgNpm20ulCcTiEU/xfEVVgMZhjiQjymkdljF8dD/vw=",
        "originContent": "#### 3.2 Speed optimization",
        "translatedContent": ""
      },
      {
        "row": 16,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "рдпрджрд┐ рдЗрдирдлреЗрд░реЗрдВрд╕ рдЧрддрд┐ рдЕрд╕рдВрддреЛрд╖рдЬрдирдХ рд╣реИ, рддреЛ рдЖрдк рдЗрд╕реЗ рдирд┐рдореНрдирд▓рд┐рдЦрд┐рдд рддрд░реАрдХреЛрдВ рд╕реЗ рддреЗрдЬ рдХрд░ рд╕рдХрддреЗ рд╣реИрдВ:"
      },
      {
        "row": 17,
        "rowsha": "iBJxMfYOjV9HvSuRT3p/EsU/iATeDCDAk/wGWLXqQI8=",
        "originContent": "If the inference speed is unsatisfactory, you can speed it up as follows:",
        "translatedContent": ""
      },
      {
        "row": 18,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "- **рдбрд┐рд╕реНрдЯрд┐рд▓ рдореЙрдбрд▓ рдФрд░ рдХрдо рд╕реНрдЯреЗрдкреНрд╕**: рдПрдХрд▓-рд╡рдХреНрддрд╛ рднрд╛рд╖рдг рдирд┐рд░реНрдорд╛рдг рдореЙрдбрд▓ рдХреЗ рд▓рд┐рдП, рд╣рдо рдмреЗрд╣рддрд░ рднрд╛рд╖рдг рдЧреБрдгрд╡рддреНрддрд╛ рдХреЗ рд▓рд┐рдП рдбрд┐рдлрд╝реЙрд▓реНрдЯ рд░реВрдк рд╕реЗ `zipvoice` рдореЙрдбрд▓ рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рддреЗ рд╣реИрдВред рдпрджрд┐ рддреЗрдЬ рдЧрддрд┐ рдкреНрд░рд╛рдердорд┐рдХрддрд╛ рд╣реИ, рддреЛ рдЖрдк `zipvoice_distill` рдкрд░ рд╕реНрд╡рд┐рдЪ рдХрд░ рд╕рдХрддреЗ рд╣реИрдВ рдФрд░ `--num-steps` рдХреЛ рдиреНрдпреВрдирддрдо `4` (рдбрд┐рдлрд╝реЙрд▓реНрдЯ 8) рддрдХ рдХрдо рдХрд░ рд╕рдХрддреЗ рд╣реИрдВред"
      },
      {
        "row": 19,
        "rowsha": "IzTHxzS1e5yJRhHF5d8CsjfqjIzhNX1AeGR4FTjuUCA=",
        "originContent": "- **Distill model and less steps**: For the single-speaker speech generation model, we use the `zipvoice` model by default for better speech quality. If faster speed is a priority, you can switch to the `zipvoice_distill` and can reduce the `--num-steps` to as low as `4` (8 by default).",
        "translatedContent": ""
      },
      {
        "row": 20,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "- **CPU рдорд▓реНрдЯреА-рдереНрд░реЗрдбрд┐рдВрдЧ рдХреЗ рд╕рд╛рде рдЧрддрд┐ рдмрдврд╝рд╛рдирд╛**: рдпрджрд┐ рдЖрдк CPU рдкрд░ рдЪрд▓рд╛ рд░рд╣реЗ рд╣реИрдВ, рддреЛ рдЖрдк рддреЗрдЬ рдЧрддрд┐ рдХреЗ рд▓рд┐рдП `--num-thread` рдкреИрд░рд╛рдореАрдЯрд░ (рдЬреИрд╕реЗ, `--num-thread 4`) рджреЗ рд╕рдХрддреЗ рд╣реИрдВ рддрд╛рдХрд┐ рдереНрд░реЗрдбреНрд╕ рдХреА рд╕рдВрдЦреНрдпрд╛ рдмрдврд╝рд╛рдИ рдЬрд╛ рд╕рдХреЗред рдбрд┐рдлрд╝реЙрд▓реНрдЯ рд░реВрдк рд╕реЗ рд╣рдо 1 рдереНрд░реЗрдб рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рддреЗ рд╣реИрдВред"
      },
      {
        "row": 21,
        "rowsha": "mNiqyHjFr4rbx4boH0cix2peH8Q0+tDTOlzgZeLLDqM=",
        "originContent": "- **CPU speedup with multi-threading**: When running on CPU, you can pass the `--num-thread` parameter (e.g., `--num-thread 4`) to increase the number of threads for faster speed. We use 1 thread by default.",
        "translatedContent": ""
      },
      {
        "row": 22,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "- **CPU рдкрд░ ONNX рдХреЗ рд╕рд╛рде рдЧрддрд┐ рдмрдврд╝рд╛рдирд╛**: CPU рдкрд░ рдЪрд▓рддреЗ рд╕рдордп, рдЖрдк рддреЗрдЬ рдЧрддрд┐ рдХреЗ рд▓рд┐рдП ONNX рдореЙрдбрд▓ рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░ рд╕рдХрддреЗ рд╣реИрдВ `zipvoice.bin.infer_zipvoice_onnx` рдХреЗ рд╕рд╛рде (рд╕рдВрд╡рд╛рдж рдирд┐рд░реНрдорд╛рдг рдореЙрдбрд▓ рдХреЗ рд▓рд┐рдП ONNX рдХрд╛ рд╕рдорд░реНрдерди рдирд╣реАрдВ рд╣реИ)ред рдФрд░ рднреА рддреЗрдЬ рдЧрддрд┐ рдХреЗ рд▓рд┐рдП, рдЖрдк `--onnx-int8 True` рд╕реЗрдЯ рдХрд░ рд╕рдХрддреЗ рд╣реИрдВ рддрд╛рдХрд┐ INT8-рдХреНрд╡рд╛рдВрдЯрд╛рдЗрдЬрд╝реНрдб ONNX рдореЙрдбрд▓ рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд┐рдпрд╛ рдЬрд╛ рд╕рдХреЗред рдзреНрдпрд╛рди рджреЗрдВ рдХрд┐ рдХреНрд╡рд╛рдВрдЯрд╛рдЗрдЬрд╝реНрдб рдореЙрдбрд▓ рд╕реЗ рднрд╛рд╖рдг рдЧреБрдгрд╡рддреНрддрд╛ рдореЗрдВ рдХреБрдЫ рдЧрд┐рд░рд╛рд╡рдЯ рдЖ рд╕рдХрддреА рд╣реИред **GPU рдкрд░ ONNX рдХрд╛ рдЙрдкрдпреЛрдЧ рди рдХрд░реЗрдВ**, рдХреНрдпреЛрдВрдХрд┐ GPU рдкрд░ рдпрд╣ PyTorch рд╕реЗ рдзреАрдорд╛ рд╣реИред"
      },
      {
        "row": 23,
        "rowsha": "YqtmXdPz7OfUIbrIkeeIwyKEPdEZUqn3m5EyTNd967s=",
        "originContent": "- **CPU speedup with ONNX**: When running on CPU, you can use ONNX models with `zipvoice.bin.infer_zipvoice_onnx` for faster speed (haven't supported ONNX for dialogue generation models yet). For even faster speed, you can further set `--onnx-int8 True` to use an INT8-quantized ONNX model. Note that the quantized model will result in a certain degree of speech quality degradation. **Don't use ONNX on GPU**, as it is slower than PyTorch on GPU.",
        "translatedContent": ""
      },
      {
        "row": 24,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "- **NVIDIA TensorRT рдХреЗ рд╕рд╛рде GPU рдПрдХреНрд╕реЗрд▓реЗрд░реЗрд╢рди**: NVIDIA GPU рдкрд░ рдорд╣рддреНрд╡рдкреВрд░реНрдг рдкреНрд░рджрд░реНрд╢рди рдмрдврд╝рд╛рдиреЗ рдХреЗ рд▓рд┐рдП, рдкрд╣рд▓реЗ zipvoice.bin.tensorrt_export рдХреЗ рд╕рд╛рде рдореЙрдбрд▓ рдХреЛ TensorRT рдЗрдВрдЬрди рдореЗрдВ рдПрдХреНрд╕рдкреЛрд░реНрдЯ рдХрд░реЗрдВред рдлрд┐рд░, рдЕрдкрдиреЗ рдбреЗрдЯрд╛рд╕реЗрдЯ (рдЬреИрд╕реЗ, Hugging Face рдбреЗрдЯрд╛рд╕реЗрдЯ) рдкрд░ zipvoice.bin.infer_zipvoice рдХреЗ рд╕рд╛рде рдЗрдирдлреЗрд░реЗрдВрд╕ рдЪрд▓рд╛рдПрдБред рдпрд╣ GPU рдкрд░ рд╕реНрдЯреИрдВрдбрд░реНрдб PyTorch рдЗрдореНрдкреНрд▓реАрдореЗрдВрдЯреЗрд╢рди рдХреА рддреБрд▓рдирд╛ рдореЗрдВ рд▓рдЧрднрдЧ 2x рдереНрд░реВрдкреБрдЯ рдкреНрд░рд╛рдкреНрдд рдХрд░ рд╕рдХрддрд╛ рд╣реИред"
      },
      {
        "row": 25,
        "rowsha": "kj1A4DWWe02Utusq07KI3xRRH55QdxQWRCzFeimIzww=",
        "originContent": "- **GPU Acceleration with NVIDIA TensorRT**: For a significant performance boost on NVIDIA GPUs, first export the model to a TensorRT engine using zipvoice.bin.tensorrt_export. Then, run inference on your dataset (e.g., a Hugging Face dataset) with zipvoice.bin.infer_zipvoice. This can achieve approximately 2x the throughput compared to the standard PyTorch implementation on a GPU.",
        "translatedContent": ""
      },
      {
        "row": 26,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "#### 3.3 рдореЗрдореЛрд░реА рдирд┐рдпрдВрддреНрд░рдг"
      },
      {
        "row": 27,
        "rowsha": "fze8iMUXPcPsZgNFyWFzWSuCffZnzh7SpzLs21tQLtE=",
        "originContent": "#### 3.3 Memory control",
        "translatedContent": ""
      },
      {
        "row": 28,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "рджрд┐рдпрд╛ рдЧрдпрд╛ рдЯреЗрдХреНрд╕реНрдЯ рд╡рд┐рд░рд╛рдо рдЪрд┐рд╣реНрди (рдПрдХрд▓-рд╡рдХреНрддрд╛ рднрд╛рд╖рдг рдирд┐рд░реНрдорд╛рдг рдХреЗ рд▓рд┐рдП) рдпрд╛ рд╡рдХреНрддрд╛-рдЯрд░реНрди рдЪрд┐рдиреНрд╣ (рд╕рдВрд╡рд╛рдж рднрд╛рд╖рдг рдирд┐рд░реНрдорд╛рдг рдХреЗ рд▓рд┐рдП) рдХреЗ рдЖрдзрд╛рд░ рдкрд░ рднрд╛рдЧреЛрдВ рдореЗрдВ рд╡рд┐рднрд╛рдЬрд┐рдд рдХрд┐рдпрд╛ рдЬрд╛рдПрдЧрд╛ред рдЗрд╕рдХреЗ рдмрд╛рдж, рдЗрди рднрд╛рдЧреЛрдВ рдХреЛ рдмреИрдЪ рдореЗрдВ рдкреНрд░реЛрд╕реЗрд╕ рдХрд┐рдпрд╛ рдЬрд╛рдПрдЧрд╛ред рдЗрд╕ рдкреНрд░рдХрд╛рд░, рдореЙрдбрд▓ рд▓рдЧрднрдЧ рд╕реНрдерд┐рд░ рдореЗрдореЛрд░реА рдЙрдкрдпреЛрдЧ рдХреЗ рд╕рд╛рде рдХрд┐рд╕реА рднреА рд▓рдВрдмрд╛рдИ рдХрд╛ рдЯреЗрдХреНрд╕реНрдЯ рдкреНрд░реЛрд╕реЗрд╕ рдХрд░ рд╕рдХрддрд╛ рд╣реИред рдЖрдк `--max-duration` рдкреИрд░рд╛рдореАрдЯрд░ рдХреЛ рд╕рдорд╛рдпреЛрдЬрд┐рдд рдХрд░рдХреЗ рдореЗрдореЛрд░реА рдЙрдкрдпреЛрдЧ рдХреЛ рдирд┐рдпрдВрддреНрд░рд┐рдд рдХрд░ рд╕рдХрддреЗ рд╣реИрдВред"
      },
      {
        "row": 29,
        "rowsha": "uM67TExtHYq7ALHmglqtjLRqv0Xu0OOSx2aFJquZPmw=",
        "originContent": "The given text will be splitted into chunks based on punctuation (for single-speaker speech generation) or speaker-turn symbol (for dialogue speech generation). Then, the chunked texts will be processed in batches. Therefore, the model can process arbitrarily long text with almost constant memory usage. You can control memory usage by adjusting the `--max-duration` parameter.",
        "translatedContent": ""
      },
      {
        "row": 30,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "#### 3.4 \"рд░реЙ\" рдореВрд▓реНрдпрд╛рдВрдХрди"
      },
      {
        "row": 31,
        "rowsha": "foa86E9JcH+Sc/k2OCmyfIKHwggsFBXhSUfHDcmJQA0=",
        "originContent": "#### 3.4 \"Raw\" evaluation",
        "translatedContent": ""
      },
      {
        "row": 32,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "рдбрд┐рдлрд╝реЙрд▓реНрдЯ рд░реВрдк рд╕реЗ, рд╣рдо рдЗрдирдкреБрдЯреНрд╕ (рдкреНрд░реЙрдореНрдкреНрдЯ wav, рдкреНрд░реЙрдореНрдкреНрдЯ рдЯреНрд░рд╛рдВрд╕рдХреНрд░рд┐рдкреНрд╢рди, рдФрд░ рдЯреЗрдХреНрд╕реНрдЯ) рдХреЛ рдХреБрд╢рд▓ рдЗрдирдлреЗрд░реЗрдВрд╕ рдФрд░ рдмреЗрд╣рддрд░ рдкреНрд░рджрд░реНрд╢рди рдХреЗ рд▓рд┐рдП рдкреВрд░реНрд╡-рдкреНрд░рдХреНрд░рд┐рдпрд╛ рдХрд░рддреЗ рд╣реИрдВред рдпрджрд┐ рдЖрдк рдореЙрдбрд▓ рдХреЗ \"рд░реЙ\" рдкреНрд░рджрд░реНрд╢рди рдХрд╛ рдореВрд▓реНрдпрд╛рдВрдХрди рдХрд░рдирд╛ рдЪрд╛рд╣рддреЗ рд╣реИрдВ, рдЬреИрд╕реЗ рдХрд┐ рд╣рдорд╛рд░реЗ рдкреЗрдкрд░ рдореЗрдВ рджрд┐рдП рдЧрдП рдкрд░рд┐рдгрд╛рдореЛрдВ рдХреЛ рдкреБрдирдГ рдЙрддреНрдкрдиреНрди рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП, рддреЛ рдЖрдк `--raw-evaluation True` рдкрд╛рд╕ рдХрд░ рд╕рдХрддреЗ рд╣реИрдВред"
      },
      {
        "row": 33,
        "rowsha": "+2nxKNvXmuxUQpf2Z+hw0Rxydt00FpmK4y4rlK5/8og=",
        "originContent": "By default, we preprocess inputs (prompt wav, prompt transcription, and text) for efficient inference and better performance. If you want to evaluate the modelтАЩs \"raw\" performance using exact provided inputs (e.g., to reproduce the results in our paper), you can pass `--raw-evaluation True`.",
        "translatedContent": ""
      },
      {
        "row": 34,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "#### 3.5 рдЫреЛрдЯрд╛ рдЯреЗрдХреНрд╕реНрдЯ"
      },
      {
        "row": 35,
        "rowsha": "g658opDssPKmJCvr7Jw9N130Xud1IbMHTwMK+S89WO0=",
        "originContent": "#### 3.5 Short text",
        "translatedContent": ""
      },
      {
        "row": 36,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "рдмрд╣реБрдд рдЫреЛрдЯреЗ рдЯреЗрдХреНрд╕реНрдЯ (рдЬреИрд╕реЗ, рдПрдХ рдпрд╛ рджреЛ рд╢рдмреНрдж) рдХреЗ рд▓рд┐рдП рднрд╛рд╖рдг рдЬреЗрдирд░реЗрдЯ рдХрд░рддреЗ рд╕рдордп, рдХрднреА-рдХрднреА рдХреБрдЫ рдЙрдЪреНрдЪрд╛рд░рдг рдЫреВрдЯ рд╕рдХрддреЗ рд╣реИрдВред рдЗрд╕ рд╕рдорд╕реНрдпрд╛ рдХреЗ рд╕рдорд╛рдзрд╛рди рдХреЗ рд▓рд┐рдП, рдЖрдк `--speed 0.3` (рдЬрд╣рд╛рдБ 0.3 рдПрдХ рд╕рдорд╛рдпреЛрдЬреНрдп рдорд╛рди рд╣реИ) рдкрд╛рд╕ рдХрд░ рд╕рдХрддреЗ рд╣реИрдВ рддрд╛рдХрд┐ рдЬреЗрдирд░реЗрдЯреЗрдб рднрд╛рд╖рдг рдХреА рдЕрд╡рдзрд┐ рдмрдврд╝рд╛рдИ рдЬрд╛ рд╕рдХреЗред"
      },
      {
        "row": 37,
        "rowsha": "/IVkHehTtKgVQNwGOgQO/BoRh95RFHVJPH3e0W6Gixs=",
        "originContent": "When generating speech for very short texts (e.g., one or two words), the generated speech may sometimes omit certain pronunciations. To resolve this issue, you can pass `--speed 0.3` (where 0.3 is a tunable value) to extend the duration of the generated speech.",
        "translatedContent": ""
      },
      {
        "row": 38,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "#### 3.6 рдЧрд▓рдд рдЙрдЪреНрдЪрд╛рд░рд┐рдд рдЪреАрдиреА рдмрд╣реБрд╡рд░реНрдгреА рдЕрдХреНрд╖рд░реЛрдВ рдХреЛ рд╕реБрдзрд╛рд░рдирд╛"
      },
      {
        "row": 39,
        "rowsha": "PAPz1JYDhpLF6dsiNH/BVipH4SufvLcqzLiPLACOcK4=",
        "originContent": "#### 3.6 Correcting mispronounced chinese polyphone characters",
        "translatedContent": ""
      },
      {
        "row": 40,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 24,
    "Content": "We use [pypinyin](https://github.com/mozillazg/python-pinyin) to convert Chinese characters to pinyin. However, it can occasionally mispronounce **polyphone characters** (хдЪщЯ│хнЧ).\n\nTo manually correct these mispronunciations, enclose the **corrected pinyin** in angle brackets `< >` and include the **tone mark**.\n\n**Example:**\n\n- Original text: `ш┐ЩцККхЙСщХ┐ф╕ЙхНБхЕмхИЖ`\n- Correct the pinyin of `щХ┐`:  `ш┐ЩцККхЙС<chang2>ф╕ЙхНБхЕмхИЖ`\n\n> **Note:** If you want to manually assign multiple pinyins, enclose each pinyin with `<>`, e.g., `ш┐ЩцКК<jian4><chang2><san1>хНБхЕмхИЖ`\n\n#### 3.7 Remove long silences from the generated speech\n\nModel will automatically determine the positions and lengths of silences in the generated speech. It occasionally has long silence in the middle of the speech. If you don't want this, you can pass `--remove-long-sil` to remove long silences in the middle of the generated speech (edge silences will be removed by default).\n\n#### 3.8 Model downloading\n\nIf you have trouble connecting to HuggingFace when downloading the pre-trained models, try switching endpoint to the mirror site: `export HF_ENDPOINT=https://hf-mirror.com`.\n\n## Train Your Own Model\n\nSee the [egs](egs) directory for training, fine-tuning and evaluation examples.\n\n## Production Deployment\n\n### NVIDIA Triton GPU Runtime\n\nFor production-ready deployment with high performance and scalability, check out the [Triton Inference Server integration](runtime/nvidia_triton/) that provides optimized TensorRT engines, concurrent request handling, and both gRPC/HTTP APIs for enterprise use.\n\n### CPU Deployment\n\nCheck [sherpa-onnx](https://github.com/k2-fsa/sherpa-onnx/pull/2487#issuecomment-3227884498) for the C++ deployment solution on CPU.\n\n## Discussion & Communication\n\nYou can directly discuss on [Github Issues](https://github.com/k2-fsa/ZipVoice/issues).\n\nYou can also scan the QR code to join our wechat group or follow our wechat official account.\n\n| Wechat Group | Wechat Official Account |",
    "ContentSha": "nAAjO+GVPZsjYiLFM/o02EX48i9vuDX4qL4j6+7om6U=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "рд╣рдо [pypinyin](https://github.com/mozillazg/python-pinyin) рдХрд╛ рдЙрдкрдпреЛрдЧ рдЪреАрдиреА рдЕрдХреНрд╖рд░реЛрдВ рдХреЛ рдкрд┐рдирдпрд┐рди рдореЗрдВ рдмрджрд▓рдиреЗ рдХреЗ рд▓рд┐рдП рдХрд░рддреЗ рд╣реИрдВред рд╣рд╛рд▓рд╛рдВрдХрд┐, рдпрд╣ рдХрднреА-рдХрднреА **рдмрд╣реБ-рдзреНрд╡рдирд┐ рдЕрдХреНрд╖рд░реЛрдВ** (хдЪщЯ│хнЧ) рдХрд╛ рдЙрдЪреНрдЪрд╛рд░рдг рдЧрд▓рдд рдХрд░ рд╕рдХрддрд╛ рд╣реИред\n\nрдЗрди рдЙрдЪреНрдЪрд╛рд░рдгреЛрдВ рдХреЛ рдореИрдиреНрдпреБрдЕрд▓реА рдареАрдХ рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП, **рд╕реБрдзрд╛рд░рд╛ рдЧрдпрд╛ рдкрд┐рдирдпрд┐рди** рдХреЛрдг рдмреНрд░реИрдХреЗрдЯ `< >` рдореЗрдВ рд▓рд┐рдЦреЗрдВ рдФрд░ **рд╕реНрд╡рд░ рдЪрд┐рдиреНрд╣** рд╢рд╛рдорд┐рд▓ рдХрд░реЗрдВред\n\n**рдЙрджрд╛рд╣рд░рдг:**\n\n- рдореВрд▓ рдкрд╛рда: `ш┐ЩцККхЙСщХ┐ф╕ЙхНБхЕмхИЖ`\n- `щХ┐` рдХреЗ рдкрд┐рдирдпрд┐рди рдХреЛ рдареАрдХ рдХрд░реЗрдВ:  `ш┐ЩцККхЙС<chang2>ф╕ЙхНБхЕмхИЖ`\n\n> **рдиреЛрдЯ:** рдпрджрд┐ рдЖрдк рдореИрдиреНрдпреБрдЕрд▓ рд░реВрдк рд╕реЗ рдХрдИ рдкрд┐рдирдпрд┐рди рдирд┐рд░реНрдзрд╛рд░рд┐рдд рдХрд░рдирд╛ рдЪрд╛рд╣рддреЗ рд╣реИрдВ, рддреЛ рдкреНрд░рддреНрдпреЗрдХ рдкрд┐рдирдпрд┐рди рдХреЛ `<>` рдореЗрдВ рд▓рд┐рдЦреЗрдВ, рдЬреИрд╕реЗ: `ш┐ЩцКК<jian4><chang2><san1>хНБхЕмхИЖ`\n\n#### 3.7 рдЙрддреНрдкрдиреНрди рдзреНрд╡рдирд┐ рд╕реЗ рд▓рдВрдмреА рдЦрд╛рдореЛрд╢реА рд╣рдЯрд╛рдПрдБ\n\nрдореЙрдбрд▓ рд╕реНрд╡рддрдГ рд╣реА рдЙрддреНрдкрдиреНрди рдзреНрд╡рдирд┐ рдореЗрдВ рдЦрд╛рдореЛрд╢реА рдХреЗ рд╕реНрдерд╛рди рдФрд░ рдЕрд╡рдзрд┐ рдХрд╛ рдирд┐рд░реНрдзрд╛рд░рдг рдХрд░реЗрдЧрд╛ред рдХрднреА-рдХрднреА рдпрд╣ рдмреЛрд▓рдиреЗ рдХреЗ рдмреАрдЪ рдореЗрдВ рд▓рдВрдмреА рдЦрд╛рдореЛрд╢реА рд░рдЦрддрд╛ рд╣реИред рдпрджрд┐ рдЖрдк рдРрд╕рд╛ рдирд╣реАрдВ рдЪрд╛рд╣рддреЗ рд╣реИрдВ, рддреЛ рдЖрдк `--remove-long-sil` рдкрд╛рд╕ рдХрд░ рд╕рдХрддреЗ рд╣реИрдВ рддрд╛рдХрд┐ рдЙрддреНрдкрдиреНрди рдзреНрд╡рдирд┐ рдХреЗ рдмреАрдЪ рдХреА рд▓рдВрдмреА рдЦрд╛рдореЛрд╢реА рд╣рдЯ рдЬрд╛рдП (рдХрд┐рдирд╛рд░реЗ рдХреА рдЦрд╛рдореЛрд╢реА рд╕реНрд╡рддрдГ рд╣рдЯ рдЬрд╛рдПрдЧреА)ред\n\n#### 3.8 рдореЙрдбрд▓ рдбрд╛рдЙрдирд▓реЛрдбрд┐рдВрдЧ\n\nрдпрджрд┐ рдЖрдкрдХреЛ рдкреНрд░реА-рдЯреНрд░реЗрдВрдб рдореЙрдбрд▓ рдбрд╛рдЙрдирд▓реЛрдб рдХрд░рддреЗ рд╕рдордп HuggingFace рд╕реЗ рдХрдиреЗрдХреНрдЯ рд╣реЛрдиреЗ рдореЗрдВ рд╕рдорд╕реНрдпрд╛ рдЖ рд░рд╣реА рд╣реИ, рддреЛ рдПрдВрдбрдкреЙрдЗрдВрдЯ рдХреЛ рдорд┐рд░рд░ рд╕рд╛рдЗрдЯ рдкрд░ рдмрджрд▓рдиреЗ рдХрд╛ рдкреНрд░рдпрд╛рд╕ рдХрд░реЗрдВ: `export HF_ENDPOINT=https://hf-mirror.com`.\n\n## рдЕрдкрдирд╛ рдЦреБрдж рдХрд╛ рдореЙрдбрд▓ рдЯреНрд░реЗрди рдХрд░реЗрдВ\n\nрдЯреНрд░реЗрдирд┐рдВрдЧ, рдлрд╛рдЗрди-рдЯреНрдпреВрдирд┐рдВрдЧ рдФрд░ рдореВрд▓реНрдпрд╛рдВрдХрди рдЙрджрд╛рд╣рд░рдгреЛрдВ рдХреЗ рд▓рд┐рдП [egs](egs) рдбрд╛рдпрд░реЗрдХреНрдЯрд░реА рджреЗрдЦреЗрдВред\n\n## рдкреНрд░реЛрдбрдХреНрд╢рди рдбрд┐рдкреНрд▓реЙрдпрдореЗрдВрдЯ\n\n### NVIDIA Triton GPU рд░рдирдЯрд╛рдЗрдо\n\nрдЙрдЪреНрдЪ рдкреНрд░рджрд░реНрд╢рди рдФрд░ рд╕реНрдХреЗрд▓реЗрдмрд┐рд▓рд┐рдЯреА рдХреЗ рд╕рд╛рде рдкреНрд░реЛрдбрдХреНрд╢рди-рддреИрдпрд╛рд░ рдбрд┐рдкреНрд▓реЙрдпрдореЗрдВрдЯ рдХреЗ рд▓рд┐рдП [Triton Inference Server integration](runtime/nvidia_triton/) рджреЗрдЦреЗрдВ, рдЬреЛ рдСрдкреНрдЯрд┐рдорд╛рдЗрдЬрд╝реНрдб TensorRT рдЗрдВрдЬрди, рдПрдХ рд╕рд╛рде рдЕрдиреБрд░реЛрдз рд╣реИрдВрдбрд▓рд┐рдВрдЧ, рдФрд░ рдПрдВрдЯрд░рдкреНрд░рд╛рдЗрдЬ рдХреЗ рд▓рд┐рдП gRPC/HTTP APIs рдкреНрд░рджрд╛рди рдХрд░рддрд╛ рд╣реИред\n\n### CPU рдбрд┐рдкреНрд▓реЙрдпрдореЗрдВрдЯ\n\nCPU рдкрд░ C++ рдбрд┐рдкреНрд▓реЙрдпрдореЗрдВрдЯ рд╕рдорд╛рдзрд╛рди рдХреЗ рд▓рд┐рдП [sherpa-onnx](https://github.com/k2-fsa/sherpa-onnx/pull/2487#issuecomment-3227884498) рджреЗрдЦреЗрдВред\n\n## рдЪрд░реНрдЪрд╛ рдПрд╡рдВ рд╕рдВрд╡рд╛рдж\n\nрдЖрдк рд╕реАрдзреЗ [Github Issues](https://github.com/k2-fsa/ZipVoice/issues) рдкрд░ рдЪрд░реНрдЪрд╛ рдХрд░ рд╕рдХрддреЗ рд╣реИрдВред\n\nрдЖрдк рд╣рдорд╛рд░рд╛ Wechat рдЧреНрд░реБрдк рдЬреЙрдЗрди рдХрд░рдиреЗ рдпрд╛ рд╣рдорд╛рд░реЗ Wechat рдЖрдзрд┐рдХрд╛рд░рд┐рдХ рдЕрдХрд╛рдЙрдВрдЯ рдХреЛ рдлреЙрд▓реЛ рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП QR рдХреЛрдб рднреА рд╕реНрдХреИрди рдХрд░ рд╕рдХрддреЗ рд╣реИрдВред\n\n| Wechat рдЧреНрд░реБрдк | Wechat рдЖрдзрд┐рдХрд╛рд░рд┐рдХ рдЕрдХрд╛рдЙрдВрдЯ |",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "hF52KZEnGKLuaot2w0AmXt52eB6Y3adYIo2qMJSMx5o=",
        "originContent": "We use [pypinyin](https://github.com/mozillazg/python-pinyin) to convert Chinese characters to pinyin. However, it can occasionally mispronounce **polyphone characters** (хдЪщЯ│хнЧ).",
        "translatedContent": "рд╣рдо [pypinyin](https://github.com/mozillazg/python-pinyin) рдХрд╛ рдЙрдкрдпреЛрдЧ рдЪреАрдиреА рдЕрдХреНрд╖рд░реЛрдВ рдХреЛ рдкрд┐рдирдпрд┐рди рдореЗрдВ рдмрджрд▓рдиреЗ рдХреЗ рд▓рд┐рдП рдХрд░рддреЗ рд╣реИрдВред рд╣рд╛рд▓рд╛рдВрдХрд┐, рдпрд╣ рдХрднреА-рдХрднреА **рдмрд╣реБ-рдзреНрд╡рдирд┐ рдЕрдХреНрд╖рд░реЛрдВ** (хдЪщЯ│хнЧ) рдХрд╛ рдЙрдЪреНрдЪрд╛рд░рдг рдЧрд▓рдд рдХрд░ рд╕рдХрддрд╛ рд╣реИред"
      },
      {
        "row": 2,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 3,
        "rowsha": "h6Qq8AvUPYme90k2BWG054cVE6RHNflr0OwdnKA4BEE=",
        "originContent": "To manually correct these mispronunciations, enclose the **corrected pinyin** in angle brackets `< >` and include the **tone mark**.",
        "translatedContent": "рдЗрди рдЙрдЪреНрдЪрд╛рд░рдгреЛрдВ рдХреЛ рдореИрдиреНрдпреБрдЕрд▓реА рдареАрдХ рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП, **рд╕реБрдзрд╛рд░рд╛ рдЧрдпрд╛ рдкрд┐рдирдпрд┐рди** рдХреЛрдг рдмреНрд░реИрдХреЗрдЯ `< >` рдореЗрдВ рд▓рд┐рдЦреЗрдВ рдФрд░ **рд╕реНрд╡рд░ рдЪрд┐рдиреНрд╣** рд╢рд╛рдорд┐рд▓ рдХрд░реЗрдВред"
      },
      {
        "row": 4,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 5,
        "rowsha": "fP4bnCe7+qhcgDDajGMIv4obksa4WSdUp3hExEbpci0=",
        "originContent": "**Example:**",
        "translatedContent": "**рдЙрджрд╛рд╣рд░рдг:**"
      },
      {
        "row": 6,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 7,
        "rowsha": "ntwz9/IQqGC1ThJXQn9D83h+54cDriyg2snkkrk0KoI=",
        "originContent": "- Original text: `ш┐ЩцККхЙСщХ┐ф╕ЙхНБхЕмхИЖ`",
        "translatedContent": "- рдореВрд▓ рдкрд╛рда: `ш┐ЩцККхЙСщХ┐ф╕ЙхНБхЕмхИЖ`"
      },
      {
        "row": 8,
        "rowsha": "sfnMRvscnvdKs1fvbVePwH0RpAikXkFIi9i7HZK7D9w=",
        "originContent": "- Correct the pinyin of `щХ┐`:  `ш┐ЩцККхЙС<chang2>ф╕ЙхНБхЕмхИЖ`",
        "translatedContent": "- `щХ┐` рдХреЗ рдкрд┐рдирдпрд┐рди рдХреЛ рдареАрдХ рдХрд░реЗрдВ:  `ш┐ЩцККхЙС<chang2>ф╕ЙхНБхЕмхИЖ`"
      },
      {
        "row": 9,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 10,
        "rowsha": "7f45Y23fyK7AQrUO7HdTtPZZzoyRkW6WwoznauYmQew=",
        "originContent": "> **Note:** If you want to manually assign multiple pinyins, enclose each pinyin with `<>`, e.g., `ш┐ЩцКК<jian4><chang2><san1>хНБхЕмхИЖ`",
        "translatedContent": "> **рдиреЛрдЯ:** рдпрджрд┐ рдЖрдк рдореИрдиреНрдпреБрдЕрд▓ рд░реВрдк рд╕реЗ рдХрдИ рдкрд┐рдирдпрд┐рди рдирд┐рд░реНрдзрд╛рд░рд┐рдд рдХрд░рдирд╛ рдЪрд╛рд╣рддреЗ рд╣реИрдВ, рддреЛ рдкреНрд░рддреНрдпреЗрдХ рдкрд┐рдирдпрд┐рди рдХреЛ `<>` рдореЗрдВ рд▓рд┐рдЦреЗрдВ, рдЬреИрд╕реЗ: `ш┐ЩцКК<jian4><chang2><san1>хНБхЕмхИЖ`"
      },
      {
        "row": 11,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 12,
        "rowsha": "FJBRXZnczlB/CZyp0UgEFMr440NrcuTPBheyQJ9lxZI=",
        "originContent": "#### 3.7 Remove long silences from the generated speech",
        "translatedContent": "#### 3.7 рдЙрддреНрдкрдиреНрди рдзреНрд╡рдирд┐ рд╕реЗ рд▓рдВрдмреА рдЦрд╛рдореЛрд╢реА рд╣рдЯрд╛рдПрдБ"
      },
      {
        "row": 13,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 14,
        "rowsha": "9UF5wHdPZ48OWeIPfCnOHPEWzgW4Z6I0e+GaTEZ1GXI=",
        "originContent": "Model will automatically determine the positions and lengths of silences in the generated speech. It occasionally has long silence in the middle of the speech. If you don't want this, you can pass `--remove-long-sil` to remove long silences in the middle of the generated speech (edge silences will be removed by default).",
        "translatedContent": "рдореЙрдбрд▓ рд╕реНрд╡рддрдГ рд╣реА рдЙрддреНрдкрдиреНрди рдзреНрд╡рдирд┐ рдореЗрдВ рдЦрд╛рдореЛрд╢реА рдХреЗ рд╕реНрдерд╛рди рдФрд░ рдЕрд╡рдзрд┐ рдХрд╛ рдирд┐рд░реНрдзрд╛рд░рдг рдХрд░реЗрдЧрд╛ред рдХрднреА-рдХрднреА рдпрд╣ рдмреЛрд▓рдиреЗ рдХреЗ рдмреАрдЪ рдореЗрдВ рд▓рдВрдмреА рдЦрд╛рдореЛрд╢реА рд░рдЦрддрд╛ рд╣реИред рдпрджрд┐ рдЖрдк рдРрд╕рд╛ рдирд╣реАрдВ рдЪрд╛рд╣рддреЗ рд╣реИрдВ, рддреЛ рдЖрдк `--remove-long-sil` рдкрд╛рд╕ рдХрд░ рд╕рдХрддреЗ рд╣реИрдВ рддрд╛рдХрд┐ рдЙрддреНрдкрдиреНрди рдзреНрд╡рдирд┐ рдХреЗ рдмреАрдЪ рдХреА рд▓рдВрдмреА рдЦрд╛рдореЛрд╢реА рд╣рдЯ рдЬрд╛рдП (рдХрд┐рдирд╛рд░реЗ рдХреА рдЦрд╛рдореЛрд╢реА рд╕реНрд╡рддрдГ рд╣рдЯ рдЬрд╛рдПрдЧреА)ред"
      },
      {
        "row": 15,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 16,
        "rowsha": "t3GDCbkkN4PM6Y7xA/ZDAXgu4WdMFfXJ+5E/xKU9AKo=",
        "originContent": "#### 3.8 Model downloading",
        "translatedContent": "#### 3.8 рдореЙрдбрд▓ рдбрд╛рдЙрдирд▓реЛрдбрд┐рдВрдЧ"
      },
      {
        "row": 17,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 18,
        "rowsha": "I2UvthbxkflPXxq8Yy6W9nJCtzb40mZPJbfmDIWQPmA=",
        "originContent": "If you have trouble connecting to HuggingFace when downloading the pre-trained models, try switching endpoint to the mirror site: `export HF_ENDPOINT=https://hf-mirror.com`.",
        "translatedContent": "рдпрджрд┐ рдЖрдкрдХреЛ рдкреНрд░реА-рдЯреНрд░реЗрдВрдб рдореЙрдбрд▓ рдбрд╛рдЙрдирд▓реЛрдб рдХрд░рддреЗ рд╕рдордп HuggingFace рд╕реЗ рдХрдиреЗрдХреНрдЯ рд╣реЛрдиреЗ рдореЗрдВ рд╕рдорд╕реНрдпрд╛ рдЖ рд░рд╣реА рд╣реИ, рддреЛ рдПрдВрдбрдкреЙрдЗрдВрдЯ рдХреЛ рдорд┐рд░рд░ рд╕рд╛рдЗрдЯ рдкрд░ рдмрджрд▓рдиреЗ рдХрд╛ рдкреНрд░рдпрд╛рд╕ рдХрд░реЗрдВ: `export HF_ENDPOINT=https://hf-mirror.com`."
      },
      {
        "row": 19,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 20,
        "rowsha": "SEsrfyGZhBYqHMMdMldgN+tSz6ynJT5BVJeLrTV5lHw=",
        "originContent": "## Train Your Own Model",
        "translatedContent": "## рдЕрдкрдирд╛ рдЦреБрдж рдХрд╛ рдореЙрдбрд▓ рдЯреНрд░реЗрди рдХрд░реЗрдВ"
      },
      {
        "row": 21,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 22,
        "rowsha": "XaSJNyFaxQRx1Xc0mphwUGAxovKELo/54WkMCnFDLyE=",
        "originContent": "See the [egs](egs) directory for training, fine-tuning and evaluation examples.",
        "translatedContent": "рдЯреНрд░реЗрдирд┐рдВрдЧ, рдлрд╛рдЗрди-рдЯреНрдпреВрдирд┐рдВрдЧ рдФрд░ рдореВрд▓реНрдпрд╛рдВрдХрди рдЙрджрд╛рд╣рд░рдгреЛрдВ рдХреЗ рд▓рд┐рдП [egs](egs) рдбрд╛рдпрд░реЗрдХреНрдЯрд░реА рджреЗрдЦреЗрдВред"
      },
      {
        "row": 23,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 24,
        "rowsha": "tfXaiJ7qvaTkZXp5azeYhmiU88iPPhEvLfYayUjE5+g=",
        "originContent": "## Production Deployment",
        "translatedContent": "## рдкреНрд░реЛрдбрдХреНрд╢рди рдбрд┐рдкреНрд▓реЙрдпрдореЗрдВрдЯ"
      },
      {
        "row": 25,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 26,
        "rowsha": "Tv94iSjTAB/OzGKZj2XftoBUCOzD2x+C0/xHRwRVo1c=",
        "originContent": "### NVIDIA Triton GPU Runtime",
        "translatedContent": "### NVIDIA Triton GPU рд░рдирдЯрд╛рдЗрдо"
      },
      {
        "row": 27,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 28,
        "rowsha": "cGPOVgf7Mpi/ILRt8hu96EmjQo85nhgnSfBGLfBqMeM=",
        "originContent": "For production-ready deployment with high performance and scalability, check out the [Triton Inference Server integration](runtime/nvidia_triton/) that provides optimized TensorRT engines, concurrent request handling, and both gRPC/HTTP APIs for enterprise use.",
        "translatedContent": "рдЙрдЪреНрдЪ рдкреНрд░рджрд░реНрд╢рди рдФрд░ рд╕реНрдХреЗрд▓реЗрдмрд┐рд▓рд┐рдЯреА рдХреЗ рд╕рд╛рде рдкреНрд░реЛрдбрдХреНрд╢рди-рддреИрдпрд╛рд░ рдбрд┐рдкреНрд▓реЙрдпрдореЗрдВрдЯ рдХреЗ рд▓рд┐рдП [Triton Inference Server integration](runtime/nvidia_triton/) рджреЗрдЦреЗрдВ, рдЬреЛ рдСрдкреНрдЯрд┐рдорд╛рдЗрдЬрд╝реНрдб TensorRT рдЗрдВрдЬрди, рдПрдХ рд╕рд╛рде рдЕрдиреБрд░реЛрдз рд╣реИрдВрдбрд▓рд┐рдВрдЧ, рдФрд░ рдПрдВрдЯрд░рдкреНрд░рд╛рдЗрдЬ рдХреЗ рд▓рд┐рдП gRPC/HTTP APIs рдкреНрд░рджрд╛рди рдХрд░рддрд╛ рд╣реИред"
      },
      {
        "row": 29,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 30,
        "rowsha": "qR/CeuOSoGV5ipBKRWpnI+ohlytt878WhTEjtxZenks=",
        "originContent": "### CPU Deployment",
        "translatedContent": "### CPU рдбрд┐рдкреНрд▓реЙрдпрдореЗрдВрдЯ"
      },
      {
        "row": 31,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 32,
        "rowsha": "B8jnXFyKu8XRyVw/Pu0Xuj1ted9/BVoBfwJ1WW9LrcE=",
        "originContent": "Check [sherpa-onnx](https://github.com/k2-fsa/sherpa-onnx/pull/2487#issuecomment-3227884498) for the C++ deployment solution on CPU.",
        "translatedContent": "CPU рдкрд░ C++ рдбрд┐рдкреНрд▓реЙрдпрдореЗрдВрдЯ рд╕рдорд╛рдзрд╛рди рдХреЗ рд▓рд┐рдП [sherpa-onnx](https://github.com/k2-fsa/sherpa-onnx/pull/2487#issuecomment-3227884498) рджреЗрдЦреЗрдВред"
      },
      {
        "row": 33,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 34,
        "rowsha": "dEqRbPItUt3FEp1iC+8Ww+A6L57yd6oGeXfxSn5BYzs=",
        "originContent": "## Discussion & Communication",
        "translatedContent": "## рдЪрд░реНрдЪрд╛ рдПрд╡рдВ рд╕рдВрд╡рд╛рдж"
      },
      {
        "row": 35,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 36,
        "rowsha": "wjQUwaDgSP1a6ggLgGx8TWt44Dxu5IlJytNwCAlzZKg=",
        "originContent": "You can directly discuss on [Github Issues](https://github.com/k2-fsa/ZipVoice/issues).",
        "translatedContent": "рдЖрдк рд╕реАрдзреЗ [Github Issues](https://github.com/k2-fsa/ZipVoice/issues) рдкрд░ рдЪрд░реНрдЪрд╛ рдХрд░ рд╕рдХрддреЗ рд╣реИрдВред"
      },
      {
        "row": 37,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 38,
        "rowsha": "WLbsT+slCE72T0wpzVIN8KFxhP+RAw29VxFhJcBEEIo=",
        "originContent": "You can also scan the QR code to join our wechat group or follow our wechat official account.",
        "translatedContent": "рдЖрдк рд╣рдорд╛рд░рд╛ Wechat рдЧреНрд░реБрдк рдЬреЙрдЗрди рдХрд░рдиреЗ рдпрд╛ рд╣рдорд╛рд░реЗ Wechat рдЖрдзрд┐рдХрд╛рд░рд┐рдХ рдЕрдХрд╛рдЙрдВрдЯ рдХреЛ рдлреЙрд▓реЛ рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП QR рдХреЛрдб рднреА рд╕реНрдХреИрди рдХрд░ рд╕рдХрддреЗ рд╣реИрдВред"
      },
      {
        "row": 39,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 40,
        "rowsha": "XMNeg//PyHlCkY1XlL7caNd2vlVOKKoslrNeasADjMY=",
        "originContent": "| Wechat Group | Wechat Official Account |",
        "translatedContent": "| Wechat рдЧреНрд░реБрдк | Wechat рдЖрдзрд┐рдХрд╛рд░рд┐рдХ рдЕрдХрд╛рдЙрдВрдЯ |"
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 25,
    "Content": "| ------------ | ----------------------- |\n|![wechat](https://k2-fsa.org/zh-CN/assets/pic/wechat_group.jpg) |![wechat](https://k2-fsa.org/zh-CN/assets/pic/wechat_account.jpg) |\n\n## Citation\n",
    "ContentSha": "z5P7Ai9AO6w/XhHPT5bFJ00FeUxhB51crq68OHJeIus=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "| ------------ | ----------------------- |\n|![wechat](https://k2-fsa.org/zh-CN/assets/pic/wechat_group.jpg) |![wechat](https://k2-fsa.org/zh-CN/assets/pic/wechat_account.jpg) |\n\n## рд╕рдВрджрд░реНрдн\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "jdP52Pdk9hJ4eEQC1YzC887/bGdD6V25zHK1FxUbFjM=",
        "originContent": "| ------------ | ----------------------- |",
        "translatedContent": "| ------------ | ----------------------- |"
      },
      {
        "row": 2,
        "rowsha": "Q6eYrtLPPuG0fiZxZqhYquTYNk0vlyIOh+CRuwGZVk4=",
        "originContent": "|![wechat](https://k2-fsa.org/zh-CN/assets/pic/wechat_group.jpg) |![wechat](https://k2-fsa.org/zh-CN/assets/pic/wechat_account.jpg) |",
        "translatedContent": "|![wechat](https://k2-fsa.org/zh-CN/assets/pic/wechat_group.jpg) |![wechat](https://k2-fsa.org/zh-CN/assets/pic/wechat_account.jpg) |"
      },
      {
        "row": 3,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 4,
        "rowsha": "ZwTp5ajUmpHTJefyHhIKzXcG2wnB1jv8iv8cvmdcb/g=",
        "originContent": "## Citation",
        "translatedContent": "## рд╕рдВрджрд░реНрдн"
      },
      {
        "row": 5,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 26,
    "Content": "```bibtex\n@article{zhu2025zipvoice,\n      title={ZipVoice: Fast and High-Quality Zero-Shot Text-to-Speech with Flow Matching},\n      author={Zhu, Han and Kang, Wei and Yao, Zengwei and Guo, Liyong and Kuang, Fangjun and Li, Zhaoqing and Zhuang, Weiji and Lin, Long and Povey, Daniel},\n      journal={arXiv preprint arXiv:2506.13053},\n      year={2025}\n}\n\n@article{zhu2025zipvoicedialog,\n      title={ZipVoice-Dialog: Non-Autoregressive Spoken Dialogue Generation with Flow Matching},\n      author={Zhu, Han and Kang, Wei and Guo, Liyong and Yao, Zengwei and Kuang, Fangjun and Zhuang, Weiji and Li, Zhaoqing and Han, Zhifeng and Zhang, Dong and Zhang, Xin and Song, Xingchen and Lin, Long and Povey, Daniel},\n      journal={arXiv preprint arXiv:2507.09318},\n      year={2025}\n}\n```",
    "ContentSha": "4y5htVtgE8qDxiQNpfNmGGVhWO4hKo26DrPCI9N/e9E=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bibtex\n@article{zhu2025zipvoice,\n      title={ZipVoice: Fast and High-Quality Zero-Shot Text-to-Speech with Flow Matching},\n      author={Zhu, Han and Kang, Wei and Yao, Zengwei and Guo, Liyong and Kuang, Fangjun and Li, Zhaoqing and Zhuang, Weiji and Lin, Long and Povey, Daniel},\n      journal={arXiv preprint arXiv:2506.13053},\n      year={2025}\n}\n\n@article{zhu2025zipvoicedialog,\n      title={ZipVoice-Dialog: Non-Autoregressive Spoken Dialogue Generation with Flow Matching},\n      author={Zhu, Han and Kang, Wei and Guo, Liyong and Yao, Zengwei and Kuang, Fangjun and Zhuang, Weiji and Li, Zhaoqing and Han, Zhifeng and Zhang, Dong and Zhang, Xin and Song, Xingchen and Lin, Long and Povey, Daniel},\n      journal={arXiv preprint arXiv:2507.09318},\n      year={2025}\n}\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 27,
    "Content": "",
    "ContentSha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "<translate-content></translate-content>",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  }
]