<div align="right">
  <details>
    <summary >üåê Langue</summary>
    <div>
      <div align="center">
        <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=en">English</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=zh-CN">ÁÆÄ‰Ωì‰∏≠Êñá</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=zh-TW">ÁπÅÈ´î‰∏≠Êñá</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ja">Êó•Êú¨Ë™û</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ko">ÌïúÍµ≠Ïñ¥</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=hi">‡§π‡§ø‡§®‡•ç‡§¶‡•Ä</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=th">‡πÑ‡∏ó‡∏¢</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=fr">Fran√ßais</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=de">Deutsch</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=es">Espa√±ol</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=it">Itapano</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ru">–†—É—Å—Å–∫–∏–π</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=pt">Portugu√™s</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=nl">Nederlands</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=pl">Polski</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ar">ÿßŸÑÿπÿ±ÿ®Ÿäÿ©</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=fa">ŸÅÿßÿ±ÿ≥€å</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=tr">T√ºrk√ße</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=vi">Ti·∫øng Vi·ªát</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=id">Bahasa Indonesia</a>
      </div>
    </div>
  </details>
</div>

<div align="center">

# ZipVoice‚ö°

## Synth√®se vocale rapide et de haute qualit√© z√©ro-shot avec Flow Matching
</div>

## Aper√ßu

ZipVoice est une s√©rie de mod√®les TTS z√©ro-shot rapides et de haute qualit√© bas√©s sur le flow matching.

### 1. Principales fonctionnalit√©s

- Petit et rapide : seulement 123M de param√®tres.

- Clonage vocal de haute qualit√© : performances de pointe en similarit√© de locuteur, intelligibilit√© et naturel.

- Multilingue : prend en charge le chinois et l'anglais.

- Multi-mode : prend en charge la g√©n√©ration de parole √† locuteur unique et de dialogues.

### 2. Variantes du mod√®le

<table>
  <thead>
    <tr>
      <th>Nom du mod√®le</th>
      <th>Description</th>
      <th>Article</th>
      <th>D√©mo</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>ZipVoice</td>
      <td>Le mod√®le de base prenant en charge le TTS z√©ro-shot √† locuteur unique en chinois et en anglais.</td>
      <td rowspan="2"><a href="https://arxiv.org/abs/2506.13053"><img src="https://img.shields.io/badge/arXiv-Paper-COLOR.svg"></a></td>
      <td rowspan="2"><a href="https://zipvoice.github.io"><img src="https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square"></a></td>
    </tr>
    <tr>
      <td>ZipVoice-Distill</td>
      <td>La version distill√©e de ZipVoice, avec une vitesse am√©lior√©e et une d√©gradation minimale des performances.</td>
    </tr>
    <tr>
      <td>ZipVoice-Dialog</td>
      <td>Un mod√®le de g√©n√©ration de dialogues bas√© sur ZipVoice, capable de g√©n√©rer des dialogues parl√©s √† deux voix sur un seul canal.</td>
      <td rowspan="2"><a href="https://arxiv.org/abs/2507.09318"><img src="https://img.shields.io/badge/arXiv-Paper-COLOR.svg"></a></td>
      <td rowspan="2"><a href="https://zipvoice-dialog.github.io"><img src="https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square"></a></td>
    </tr>
    <tr>
      <td>ZipVoice-Dialog-Stereo</td>
      <td>La variante st√©r√©o de ZipVoice-Dialog, permettant la g√©n√©ration de dialogues √† deux canaux avec chaque locuteur sur un canal distinct.</td>
    </tr>
  </tbody>
</table>

## Actualit√©s

**2025/07/14** : **ZipVoice-Dialog** et **ZipVoice-Dialog-Stereo**, deux mod√®les de g√©n√©ration de dialogues parl√©s, sont publi√©s. [![arXiv](https://img.shields.io/badge/arXiv-Paper-COLOR.svg)](https://arxiv.org/abs/2507.09318) [![demo page](https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square)](https://zipvoice-dialog.github.io)

**2025/07/14** : Le jeu de donn√©es **OpenDialog**, un jeu de donn√©es de dialogues parl√©s de 6,8k heures, est disponible. T√©l√©chargez-le sur [![hf](https://img.shields.io/badge/%F0%9F%A4%97%20HuggingFace-Dataset-yellow)](https://huggingface.co/datasets/k2-fsa/OpenDialog), [![ms](https://img.shields.io/badge/ModelScope-Dataset-blue?logo=data)](https://www.modelscope.cn/datasets/k2-fsa/OpenDialog). D√©tails sur [![arXiv](https://img.shields.io/badge/arXiv-Paper-COLOR.svg)](https://arxiv.org/abs/2507.09318).

**2025/06/16** : **ZipVoice** et **ZipVoice-Distill** sont publi√©s. [![arXiv](https://img.shields.io/badge/arXiv-Paper-COLOR.svg)](https://arxiv.org/abs/2506.13053) [![demo page](https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square)](https://zipvoice.github.io)

## Installation

### 1. Clonez le d√©p√¥t ZipVoice


```bash
git clone https://github.com/k2-fsa/ZipVoice.git
```
### 2. (Optionnel) Cr√©ez un environnement virtuel Python


```bash
python3 -m venv zipvoice
source zipvoice/bin/activate
```
### 3. Installez les paquets requis


```bash
pip install -r requirements.txt
```
### 4. Installer k2 pour l'entra√Ænement ou l'inf√©rence efficace

**k2 est n√©cessaire pour l'entra√Ænement** et peut acc√©l√©rer l'inf√©rence. N√©anmoins, vous pouvez toujours utiliser le mode inf√©rence de ZipVoice sans installer k2.

> **Remarque :** Assurez-vous d'installer la version de k2 qui correspond √† votre version de PyTorch et CUDA. Par exemple, si vous utilisez pytorch 2.5.1 et CUDA 12.1, vous pouvez installer k2 comme suit :


```bash
pip install k2==1.24.4.dev20250208+cuda12.1.torch2.5.1 -f https://k2-fsa.github.io/k2/cuda.html
```
Veuillez consulter https://k2-fsa.org/get-started/k2/ pour plus de d√©tails.
Les utilisateurs en Chine continentale peuvent consulter https://k2-fsa.org/zh-CN/get-started/k2/.

- Pour v√©rifier l'installation de k2 :


```
python3 -c "import k2; print(k2.__file__)"
```
## Utilisation

### 1. G√©n√©ration de parole √† un seul locuteur

Pour g√©n√©rer de la parole √† un seul locuteur avec nos mod√®les ZipVoice ou ZipVoice-Distill pr√©-entra√Æn√©s, utilisez les commandes suivantes (Les mod√®les requis seront t√©l√©charg√©s depuis HuggingFace) :

#### 1.1 Inf√©rence d'une seule phrase


```bash
python3 -m zipvoice.bin.infer_zipvoice \
    --model-name zipvoice \
    --prompt-wav prompt.wav \
    --prompt-text "I am the transcription of the prompt wav." \
    --text "I am the text to be synthesized." \
    --res-wav-path result.wav
```
- `--model-name` peut √™tre `zipvoice` ou `zipvoice_distill`, qui sont respectivement les mod√®les avant et apr√®s distillation.
- Si `<>` ou `[]` apparaissent dans le texte, les cha√Ænes qu'ils entourent seront trait√©es comme des jetons sp√©ciaux. `<>` d√©signe le pinyin chinois et `[]` d√©signe d'autres balises sp√©ciales.
- Il est possible d'ex√©cuter les mod√®les ONNX plus rapidement sur le CPU avec `zipvoice.bin.infer_zipvoice_onnx`.

> **Remarque :** Si vous avez des difficult√©s √† vous connecter √† HuggingFace, essayez :
> ```bash
> export HF_ENDPOINT=https://hf-mirror.com
> ```

#### 1.2 Inf√©rence d'une liste de phrases


```bash
python3 -m zipvoice.bin.infer_zipvoice \
    --model-name zipvoice \
    --test-list test.tsv \
    --res-dir results
```
- Chaque ligne de `test.tsv` est au format `{wav_name}\t{prompt_transcription}\t{prompt_wav}\t{text}`.

### 2. G√©n√©ration de la parole en dialogue

#### 2.1 Commande d'inf√©rence

Pour g√©n√©rer des dialogues parl√©s √† deux voix avec nos mod√®les pr√©-entra√Æn√©s ZipVoice-Dialogue ou ZipVoice-Dialogue-Stereo, utilisez les commandes suivantes (les mod√®les requis seront t√©l√©charg√©s depuis HuggingFace) :


```bash
python3 -m zipvoice.bin.infer_zipvoice_dialog \
    --model-name "zipvoice_dialog" \
    --test-list test.tsv \
    --res-dir results
```
- `--model-name` peut √™tre `zipvoice_dialog` ou `zipvoice_dialog_stereo`,
    qui g√©n√®rent respectivement des dialogues mono et st√©r√©o.

#### 2.2 Formats d'entr√©e

Chaque ligne de `test.tsv` est dans l'un des formats suivants :

(1) **Format de prompt fusionn√©** o√π les audios et transcriptions des prompts des deux locuteurs sont fusionn√©s en un seul fichier wav de prompt :

```
{wav_name}\t{prompt_transcription}\t{prompt_wav}\t{text}
```
- `wav_name` est le nom du fichier wav de sortie.
- `prompt_transcription` est la transcription du fichier wav du prompt conversationnel, par exemple, "[S1] Bonjour. [S2] Comment √ßa va ?"
- `prompt_wav` est le chemin vers le fichier wav du prompt.
- `text` est le texte √† synth√©tiser, par exemple, "[S1] Je vais bien. [S2] Comment tu t'appelles ?"

(2) **Format de prompt s√©par√©** o√π les audios et les transcriptions des deux intervenants existent dans des fichiers distincts :


```
{wav_name}\t{spk1_prompt_transcription}\t{spk2_prompt_transcription}\t{spk1_prompt_wav}\t{spk2_prompt_wav}\t{text}'
```
- `wav_name` est le nom du fichier wav de sortie.
- `spk1_prompt_transcription` est la transcription du prompt wav du premier locuteur, par exemple, "Bonjour"
- `spk2_prompt_transcription` est la transcription du prompt wav du deuxi√®me locuteur, par exemple, "Comment √ßa va ?"
- `spk1_prompt_wav` est le chemin du fichier wav du prompt du premier locuteur.
- `spk2_prompt_wav` est le chemin du fichier wav du prompt du deuxi√®me locuteur.
- `text` est le texte √† synth√©tiser, par exemple, "[S1] Je vais bien. [S2] Comment tu t'appelles ?"

### 3. Autres fonctionnalit√©s

#### 3.1 Correction des caract√®res chinois polyphoniques mal prononc√©s

Nous utilisons [pypinyin](https://github.com/mozillazg/python-pinyin) pour convertir les caract√®res chinois en pinyin. Cependant, il peut parfois mal prononcer les **caract√®res polyphoniques** (Â§öÈü≥Â≠ó).

Pour corriger manuellement ces erreurs de prononciation, entourez le **pinyin corrig√©** avec des chevrons `< >` et incluez la **marque de ton**.

**Exemple :**

- Texte original : `ËøôÊääÂâëÈïø‰∏âÂçÅÂÖ¨ÂàÜ`
- Corrigez le pinyin de `Èïø` :  `ËøôÊääÂâë<chang2>‰∏âÂçÅÂÖ¨ÂàÜ`

> **Remarque :** Si vous souhaitez attribuer manuellement plusieurs pinyins, entourez chaque pinyin avec `<>`, par exemple, `ËøôÊää<jian4><chang2><san1>ÂçÅÂÖ¨ÂàÜ`

## Entra√Ænez votre propre mod√®le

Consultez le r√©pertoire [egs](egs) pour des exemples d'entra√Ænement, de fine-tuning et d'√©valuation.

## Discussion & Communication

Vous pouvez discuter directement sur [Github Issues](https://github.com/k2-fsa/ZipVoice/issues).

Vous pouvez √©galement scanner le code QR pour rejoindre notre groupe wechat ou suivre notre compte officiel wechat.

| Groupe Wechat | Compte officiel Wechat |
| ------------- | ---------------------- |
|![wechat](https://k2-fsa.org/zh-CN/assets/pic/wechat_group.jpg) |![wechat](https://k2-fsa.org/zh-CN/assets/pic/wechat_account.jpg) |

## Citation


```bibtex
@article{zhu2025zipvoice,
      title={ZipVoice: Fast and High-Quality Zero-Shot Text-to-Speech with Flow Matching},
      author={Zhu, Han and Kang, Wei and Yao, Zengwei and Guo, Liyong and Kuang, Fangjun and Li, Zhaoqing and Zhuang, Weiji and Lin, Long and Povey, Daniel},
      journal={arXiv preprint arXiv:2506.13053},
      year={2025}
}

@article{zhu2025zipvoicedialog,
      title={ZipVoice-Dialog: Non-Autoregressive Spoken Dialogue Generation with Flow Matching},
      author={Zhu, Han and Kang, Wei and Guo, Liyong and Yao, Zengwei and Kuang, Fangjun and Zhuang, Weiji and Li, Zhaoqing and Han, Zhifeng and Zhang, Dong and Zhang, Xin and Song, Xingchen and Lin, Long and Povey, Daniel},
      journal={arXiv preprint arXiv:2507.09318},
      year={2025}
}
```
<translate-content></translate-content>

---

Tranlated By [Open Ai Tx](https://github.com/OpenAiTx/OpenAiTx) | Last indexed: 2025-07-22

---