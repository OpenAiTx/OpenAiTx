[
  {
    "row": 1,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "- `wav_name`는 출력 wav 파일의 이름입니다."
  },
  {
    "row": 2,
    "rowsha": "6vgIR6WfUAFmULhn8LhxFttPwZEo/YwGhN1DAECwHCQ=",
    "originContent": "- `wav_name` is the name of the output wav file.",
    "translatedContent": "- `spk1_prompt_transcription`은 첫 번째 화자의 프롬프트 wav의 전사본입니다. 예: \"Hello\""
  },
  {
    "row": 3,
    "rowsha": "7BNq8UaBvTut4Ow/oJBAgIDTn3EwEZXK7mlUaYdFwqw=",
    "originContent": "- `spk1_prompt_transcription` is the transcription of the first speaker's prompt wav, e.g, \"Hello\"",
    "translatedContent": "- `spk2_prompt_transcription`은 두 번째 화자의 프롬프트 wav의 전사본입니다. 예: \"How are you?\""
  },
  {
    "row": 4,
    "rowsha": "CES8w9dqVdkdJyOJBUVP282aaKeevVWB3d/+59TEsuk=",
    "originContent": "- `spk2_prompt_transcription` is the transcription of the second speaker's prompt wav, e.g, \"How are you?\"",
    "translatedContent": "- `spk1_prompt_wav`는 첫 번째 화자의 프롬프트 wav 파일 경로입니다."
  },
  {
    "row": 5,
    "rowsha": "gXLLRf4BR7Xko2q2l4nK04KIs/L8CjvZ/UBQaP1+vck=",
    "originContent": "- `spk1_prompt_wav` is the path to the first speaker's prompt wav file.",
    "translatedContent": "- `spk2_prompt_wav`는 두 번째 화자의 프롬프트 wav 파일 경로입니다."
  },
  {
    "row": 6,
    "rowsha": "oS1+heJwBnnDtA57WYtG6LbzxK79DOIeb8hwhZQwcDg=",
    "originContent": "- `spk2_prompt_wav` is the path to the second speaker's prompt wav file.",
    "translatedContent": "- `text`는 합성할 텍스트입니다. 예: \"[S1] I'm fine. [S2] What's your name? [S1] I'm Eric. [S2] Hi Eric.\""
  },
  {
    "row": 7,
    "rowsha": "M4Z2DDajNBdyF/JosIaDZ44oyZnjNA7lzfGzEpuoako=",
    "originContent": "- `text` is the text to be synthesized, e.g. \"[S1] I'm fine. [S2] What's your name? [S1] I'm Eric. [S2] Hi Eric.\"",
    "translatedContent": ""
  },
  {
    "row": 8,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "### 3 더 나은 사용을 위한 가이드:"
  },
  {
    "row": 9,
    "rowsha": "SdDI3h73wOzKSM3kbrbNrmpigHGer7kumuaZsQgAeao=",
    "originContent": "### 3 Guidance for better usage:",
    "translatedContent": ""
  },
  {
    "row": 10,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "#### 3.1 프롬프트 길이"
  },
  {
    "row": 11,
    "rowsha": "cVxukE6jyFFOxlNKI5ecOTo/suYYJ8hnYyW2XA2wg+o=",
    "originContent": "#### 3.1 Prompt length",
    "translatedContent": ""
  },
  {
    "row": 12,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "더 빠른 추론 속도를 위해 짧은 프롬프트 wav 파일(예: 단일 화자 음성 생성의 경우 3초 미만, 대화 음성 생성의 경우 10초 미만)을 권장합니다. 너무 긴 프롬프트는 추론 속도를 느리게 하고 음성 품질을 저하시킬 수 있습니다."
  },
  {
    "row": 13,
    "rowsha": "f19zq78QrLul7wiVSlCSojGS7qNEvtef9GFg6AA8eMY=",
    "originContent": "We recommand a short prompt wav file (e.g., less than 3 seconds for single-speaker speech generation, less than 10 seconds for dialogue speech generation) for faster inference speed. A very long prompt will slow down the inference and degenerate the speech quality.",
    "translatedContent": ""
  },
  {
    "row": 14,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "#### 3.2 속도 최적화"
  },
  {
    "row": 15,
    "rowsha": "lpgNpm20ulCcTiEU/xfEVVgMZhjiQjymkdljF8dD/vw=",
    "originContent": "#### 3.2 Speed optimization",
    "translatedContent": ""
  },
  {
    "row": 16,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "추론 속도가 만족스럽지 않다면 다음과 같이 속도를 높일 수 있습니다:"
  },
  {
    "row": 17,
    "rowsha": "iBJxMfYOjV9HvSuRT3p/EsU/iATeDCDAk/wGWLXqQI8=",
    "originContent": "If the inference speed is unsatisfactory, you can speed it up as follows:",
    "translatedContent": ""
  },
  {
    "row": 18,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "- **모델 디스틸 및 스텝 수 감소**: 단일 화자 음성 생성 모델의 경우, 기본적으로 더 나은 음성 품질을 위해 `zipvoice` 모델을 사용합니다. 더 빠른 속도가 우선이라면 `zipvoice_distill`로 변경하고 `--num-steps`를 최소 `4`(기본값 8)까지 줄일 수 있습니다."
  },
  {
    "row": 19,
    "rowsha": "IzTHxzS1e5yJRhHF5d8CsjfqjIzhNX1AeGR4FTjuUCA=",
    "originContent": "- **Distill model and less steps**: For the single-speaker speech generation model, we use the `zipvoice` model by default for better speech quality. If faster speed is a priority, you can switch to the `zipvoice_distill` and can reduce the `--num-steps` to as low as `4` (8 by default).",
    "translatedContent": ""
  },
  {
    "row": 20,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "- **멀티스레딩을 통한 CPU 속도 향상**: CPU에서 실행할 때, `--num-thread` 파라미터(예: `--num-thread 4`)를 지정하여 스레드 수를 늘려 속도를 높일 수 있습니다. 기본적으로 1개의 스레드를 사용합니다."
  },
  {
    "row": 21,
    "rowsha": "mNiqyHjFr4rbx4boH0cix2peH8Q0+tDTOlzgZeLLDqM=",
    "originContent": "- **CPU speedup with multi-threading**: When running on CPU, you can pass the `--num-thread` parameter (e.g., `--num-thread 4`) to increase the number of threads for faster speed. We use 1 thread by default.",
    "translatedContent": ""
  },
  {
    "row": 22,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "- **ONNX를 통한 CPU 속도 향상**: CPU에서 실행할 때, ONNX 모델을 `zipvoice.bin.infer_zipvoice_onnx`와 함께 사용하면 더 빠른 속도를 얻을 수 있습니다(아직 대화 생성 모델에서는 ONNX를 지원하지 않음). 추가로 `--onnx-int8 True`를 설정하면 INT8 양자화된 ONNX 모델을 사용할 수 있습니다. 양자화된 모델은 어느 정도 음성 품질 저하가 발생할 수 있습니다. **GPU에서는 ONNX를 사용하지 마세요.** GPU에서는 PyTorch보다 느립니다."
  },
  {
    "row": 23,
    "rowsha": "YqtmXdPz7OfUIbrIkeeIwyKEPdEZUqn3m5EyTNd967s=",
    "originContent": "- **CPU speedup with ONNX**: When running on CPU, you can use ONNX models with `zipvoice.bin.infer_zipvoice_onnx` for faster speed (haven't supported ONNX for dialogue generation models yet). For even faster speed, you can further set `--onnx-int8 True` to use an INT8-quantized ONNX model. Note that the quantized model will result in a certain degree of speech quality degradation. **Don't use ONNX on GPU**, as it is slower than PyTorch on GPU.",
    "translatedContent": ""
  },
  {
    "row": 24,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "- **NVIDIA TensorRT를 이용한 GPU 가속**: NVIDIA GPU에서 성능을 대폭 향상시키려면, 먼저 zipvoice.bin.tensorrt_export로 모델을 TensorRT 엔진으로 내보냅니다. 그런 다음 zipvoice.bin.infer_zipvoice로 데이터셋(예: Hugging Face 데이터셋)에서 추론을 실행합니다. 이 방법은 GPU에서 표준 PyTorch 구현 대비 약 2배의 처리량을 달성할 수 있습니다."
  },
  {
    "row": 25,
    "rowsha": "kj1A4DWWe02Utusq07KI3xRRH55QdxQWRCzFeimIzww=",
    "originContent": "- **GPU Acceleration with NVIDIA TensorRT**: For a significant performance boost on NVIDIA GPUs, first export the model to a TensorRT engine using zipvoice.bin.tensorrt_export. Then, run inference on your dataset (e.g., a Hugging Face dataset) with zipvoice.bin.infer_zipvoice. This can achieve approximately 2x the throughput compared to the standard PyTorch implementation on a GPU.",
    "translatedContent": ""
  },
  {
    "row": 26,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "#### 3.3 메모리 제어"
  },
  {
    "row": 27,
    "rowsha": "fze8iMUXPcPsZgNFyWFzWSuCffZnzh7SpzLs21tQLtE=",
    "originContent": "#### 3.3 Memory control",
    "translatedContent": ""
  },
  {
    "row": 28,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "주어진 텍스트는 구두점(단일 화자 음성 생성의 경우) 또는 화자 전환 기호(대화 음성 생성의 경우)를 기준으로 청크로 분할됩니다. 이후 분할된 텍스트는 배치로 처리됩니다. 따라서 모델은 거의 일정한 메모리 사용량으로 임의의 길이의 텍스트를 처리할 수 있습니다. `--max-duration` 파라미터를 조정하여 메모리 사용량을 제어할 수 있습니다."
  },
  {
    "row": 29,
    "rowsha": "uM67TExtHYq7ALHmglqtjLRqv0Xu0OOSx2aFJquZPmw=",
    "originContent": "The given text will be splitted into chunks based on punctuation (for single-speaker speech generation) or speaker-turn symbol (for dialogue speech generation). Then, the chunked texts will be processed in batches. Therefore, the model can process arbitrarily long text with almost constant memory usage. You can control memory usage by adjusting the `--max-duration` parameter.",
    "translatedContent": ""
  },
  {
    "row": 30,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "#### 3.4 \"Raw\" 평가"
  },
  {
    "row": 31,
    "rowsha": "foa86E9JcH+Sc/k2OCmyfIKHwggsFBXhSUfHDcmJQA0=",
    "originContent": "#### 3.4 \"Raw\" evaluation",
    "translatedContent": ""
  },
  {
    "row": 32,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "기본적으로 효율적인 추론과 더 나은 성능을 위해 입력(프롬프트 wav, 프롬프트 전사, 텍스트)을 전처리합니다. 모델의 \"원본\" 성능을 정확히 제공된 입력으로 평가하고 싶다면(예: 논문 결과 재현 목적), `--raw-evaluation True`를 사용할 수 있습니다."
  },
  {
    "row": 33,
    "rowsha": "+2nxKNvXmuxUQpf2Z+hw0Rxydt00FpmK4y4rlK5/8og=",
    "originContent": "By default, we preprocess inputs (prompt wav, prompt transcription, and text) for efficient inference and better performance. If you want to evaluate the model’s \"raw\" performance using exact provided inputs (e.g., to reproduce the results in our paper), you can pass `--raw-evaluation True`.",
    "translatedContent": ""
  },
  {
    "row": 34,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "#### 3.5 짧은 텍스트"
  },
  {
    "row": 35,
    "rowsha": "g658opDssPKmJCvr7Jw9N130Xud1IbMHTwMK+S89WO0=",
    "originContent": "#### 3.5 Short text",
    "translatedContent": ""
  },
  {
    "row": 36,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "아주 짧은 텍스트(예: 한두 단어)에 대해 음성을 생성할 때, 생성된 음성에서 일부 발음이 누락될 수 있습니다. 이 문제를 해결하려면 `--speed 0.3`(0.3은 조정 가능한 값)을 지정하여 생성된 음성의 길이를 늘릴 수 있습니다."
  },
  {
    "row": 37,
    "rowsha": "/IVkHehTtKgVQNwGOgQO/BoRh95RFHVJPH3e0W6Gixs=",
    "originContent": "When generating speech for very short texts (e.g., one or two words), the generated speech may sometimes omit certain pronunciations. To resolve this issue, you can pass `--speed 0.3` (where 0.3 is a tunable value) to extend the duration of the generated speech.",
    "translatedContent": ""
  },
  {
    "row": 38,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "#### 3.6 잘못 발음된 중국어 다음자(다음음) 교정"
  },
  {
    "row": 39,
    "rowsha": "PAPz1JYDhpLF6dsiNH/BVipH4SufvLcqzLiPLACOcK4=",
    "originContent": "#### 3.6 Correcting mispronounced chinese polyphone characters",
    "translatedContent": ""
  },
  {
    "row": 40,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 41,
    "rowsha": "hF52KZEnGKLuaot2w0AmXt52eB6Y3adYIo2qMJSMx5o=",
    "originContent": "We use [pypinyin](https://github.com/mozillazg/python-pinyin) to convert Chinese characters to pinyin. However, it can occasionally mispronounce **polyphone characters** (多音字).",
    "translatedContent": "중국어 문자를 병음으로 변환하기 위해 [pypinyin](https://github.com/mozillazg/python-pinyin)을 사용합니다. 하지만, 이 도구는 때때로 **다음자(多音字)**의 발음을 잘못 표기할 수 있습니다."
  },
  {
    "row": 42,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 43,
    "rowsha": "h6Qq8AvUPYme90k2BWG054cVE6RHNflr0OwdnKA4BEE=",
    "originContent": "To manually correct these mispronunciations, enclose the **corrected pinyin** in angle brackets `< >` and include the **tone mark**.",
    "translatedContent": "이러한 잘못된 발음을 수동으로 수정하려면, **수정된 병음**을 꺾쇠 괄호 `< >`로 감싸고 **성조 표시**를 포함하세요."
  },
  {
    "row": 44,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 45,
    "rowsha": "fP4bnCe7+qhcgDDajGMIv4obksa4WSdUp3hExEbpci0=",
    "originContent": "**Example:**",
    "translatedContent": "**예시:**"
  },
  {
    "row": 46,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 47,
    "rowsha": "ntwz9/IQqGC1ThJXQn9D83h+54cDriyg2snkkrk0KoI=",
    "originContent": "- Original text: `这把剑长三十公分`",
    "translatedContent": "- 원문: `这把剑长三十公分`"
  },
  {
    "row": 48,
    "rowsha": "sfnMRvscnvdKs1fvbVePwH0RpAikXkFIi9i7HZK7D9w=",
    "originContent": "- Correct the pinyin of `长`:  `这把剑<chang2>三十公分`",
    "translatedContent": "- `长`의 병음을 수정:  `这把剑<chang2>三十公分`"
  },
  {
    "row": 49,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 50,
    "rowsha": "7f45Y23fyK7AQrUO7HdTtPZZzoyRkW6WwoznauYmQew=",
    "originContent": "> **Note:** If you want to manually assign multiple pinyins, enclose each pinyin with `<>`, e.g., `这把<jian4><chang2><san1>十公分`",
    "translatedContent": "> **참고:** 여러 병음을 수동으로 지정하려면, 각 병음을 `<>`로 감싸세요. 예: `这把<jian4><chang2><san1>十公分`"
  },
  {
    "row": 51,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 52,
    "rowsha": "FJBRXZnczlB/CZyp0UgEFMr440NrcuTPBheyQJ9lxZI=",
    "originContent": "#### 3.7 Remove long silences from the generated speech",
    "translatedContent": "#### 3.7 생성된 음성에서 긴 무음 제거"
  },
  {
    "row": 53,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 54,
    "rowsha": "9UF5wHdPZ48OWeIPfCnOHPEWzgW4Z6I0e+GaTEZ1GXI=",
    "originContent": "Model will automatically determine the positions and lengths of silences in the generated speech. It occasionally has long silence in the middle of the speech. If you don't want this, you can pass `--remove-long-sil` to remove long silences in the middle of the generated speech (edge silences will be removed by default).",
    "translatedContent": "모델은 생성된 음성에서 무음의 위치와 길이를 자동으로 결정합니다. 때때로 음성 중간에 긴 무음이 포함될 수 있습니다. 이를 원하지 않을 경우, `--remove-long-sil` 옵션을 사용하여 생성된 음성의 중간에 있는 긴 무음을 제거할 수 있습니다(가장자리 무음은 기본적으로 제거됨)."
  },
  {
    "row": 55,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 56,
    "rowsha": "t3GDCbkkN4PM6Y7xA/ZDAXgu4WdMFfXJ+5E/xKU9AKo=",
    "originContent": "#### 3.8 Model downloading",
    "translatedContent": "#### 3.8 모델 다운로드"
  },
  {
    "row": 57,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 58,
    "rowsha": "I2UvthbxkflPXxq8Yy6W9nJCtzb40mZPJbfmDIWQPmA=",
    "originContent": "If you have trouble connecting to HuggingFace when downloading the pre-trained models, try switching endpoint to the mirror site: `export HF_ENDPOINT=https://hf-mirror.com`.",
    "translatedContent": "사전학습된 모델을 다운로드할 때 HuggingFace 연결에 문제가 있다면, 엔드포인트를 미러 사이트로 변경해보세요: `export HF_ENDPOINT=https://hf-mirror.com`."
  },
  {
    "row": 59,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 60,
    "rowsha": "SEsrfyGZhBYqHMMdMldgN+tSz6ynJT5BVJeLrTV5lHw=",
    "originContent": "## Train Your Own Model",
    "translatedContent": "## 나만의 모델 학습"
  },
  {
    "row": 61,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 62,
    "rowsha": "XaSJNyFaxQRx1Xc0mphwUGAxovKELo/54WkMCnFDLyE=",
    "originContent": "See the [egs](egs) directory for training, fine-tuning and evaluation examples.",
    "translatedContent": "학습, 파인튜닝 및 평가 예시는 [egs](egs) 디렉터리를 참고하세요."
  },
  {
    "row": 63,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 64,
    "rowsha": "tfXaiJ7qvaTkZXp5azeYhmiU88iPPhEvLfYayUjE5+g=",
    "originContent": "## Production Deployment",
    "translatedContent": "## 프로덕션 배포"
  },
  {
    "row": 65,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 66,
    "rowsha": "Tv94iSjTAB/OzGKZj2XftoBUCOzD2x+C0/xHRwRVo1c=",
    "originContent": "### NVIDIA Triton GPU Runtime",
    "translatedContent": "### NVIDIA Triton GPU 런타임"
  },
  {
    "row": 67,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 68,
    "rowsha": "cGPOVgf7Mpi/ILRt8hu96EmjQo85nhgnSfBGLfBqMeM=",
    "originContent": "For production-ready deployment with high performance and scalability, check out the [Triton Inference Server integration](runtime/nvidia_triton/) that provides optimized TensorRT engines, concurrent request handling, and both gRPC/HTTP APIs for enterprise use.",
    "translatedContent": "엔터프라이즈용 고성능 및 확장성 있는 배포를 위해 [Triton Inference Server 통합](runtime/nvidia_triton/)을 확인하세요. 이 통합은 최적화된 TensorRT 엔진, 동시 요청 처리, 그리고 gRPC/HTTP API를 제공합니다."
  },
  {
    "row": 69,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 70,
    "rowsha": "qR/CeuOSoGV5ipBKRWpnI+ohlytt878WhTEjtxZenks=",
    "originContent": "### CPU Deployment",
    "translatedContent": "### CPU 배포"
  },
  {
    "row": 71,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 72,
    "rowsha": "B8jnXFyKu8XRyVw/Pu0Xuj1ted9/BVoBfwJ1WW9LrcE=",
    "originContent": "Check [sherpa-onnx](https://github.com/k2-fsa/sherpa-onnx/pull/2487#issuecomment-3227884498) for the C++ deployment solution on CPU.",
    "translatedContent": "CPU에서의 C++ 배포 솔루션은 [sherpa-onnx](https://github.com/k2-fsa/sherpa-onnx/pull/2487#issuecomment-3227884498)를 참고하세요."
  },
  {
    "row": 73,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 74,
    "rowsha": "dEqRbPItUt3FEp1iC+8Ww+A6L57yd6oGeXfxSn5BYzs=",
    "originContent": "## Discussion & Communication",
    "translatedContent": "## 토론 및 소통"
  },
  {
    "row": 75,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 76,
    "rowsha": "wjQUwaDgSP1a6ggLgGx8TWt44Dxu5IlJytNwCAlzZKg=",
    "originContent": "You can directly discuss on [Github Issues](https://github.com/k2-fsa/ZipVoice/issues).",
    "translatedContent": "[Github Issues](https://github.com/k2-fsa/ZipVoice/issues)에서 직접 토론할 수 있습니다."
  },
  {
    "row": 77,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 78,
    "rowsha": "WLbsT+slCE72T0wpzVIN8KFxhP+RAw29VxFhJcBEEIo=",
    "originContent": "You can also scan the QR code to join our wechat group or follow our wechat official account.",
    "translatedContent": "QR 코드를 스캔하여 위챗 그룹에 참여하거나 공식 위챗 계정을 팔로우할 수도 있습니다."
  },
  {
    "row": 79,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 80,
    "rowsha": "XMNeg//PyHlCkY1XlL7caNd2vlVOKKoslrNeasADjMY=",
    "originContent": "| Wechat Group | Wechat Official Account |",
    "translatedContent": "| 위챗 그룹 | 공식 위챗 계정 |"
  },
  {
    "row": 81,
    "rowsha": "jdP52Pdk9hJ4eEQC1YzC887/bGdD6V25zHK1FxUbFjM=",
    "originContent": "| ------------ | ----------------------- |",
    "translatedContent": "| ------------ | ----------------------- |"
  },
  {
    "row": 82,
    "rowsha": "Q6eYrtLPPuG0fiZxZqhYquTYNk0vlyIOh+CRuwGZVk4=",
    "originContent": "|![wechat](https://k2-fsa.org/zh-CN/assets/pic/wechat_group.jpg) |![wechat](https://k2-fsa.org/zh-CN/assets/pic/wechat_account.jpg) |",
    "translatedContent": "|![wechat](https://k2-fsa.org/zh-CN/assets/pic/wechat_group.jpg) |![wechat](https://k2-fsa.org/zh-CN/assets/pic/wechat_account.jpg) |"
  },
  {
    "row": 83,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 84,
    "rowsha": "ZwTp5ajUmpHTJefyHhIKzXcG2wnB1jv8iv8cvmdcb/g=",
    "originContent": "## Citation",
    "translatedContent": "## 인용"
  },
  {
    "row": 85,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  }
]