[
  {
    "Id": 1,
    "Content": "\n<div align=\"right\">\n  <details>\n    <summary >ğŸŒ Language</summary>\n    <div>\n      <div align=\"center\">\n        <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=en\">English</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=zh-CN\">ç®€ä½“ä¸­æ–‡</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=zh-TW\">ç¹é«”ä¸­æ–‡</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ja\">æ—¥æœ¬èª</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ko\">í•œêµ­ì–´</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=hi\">à¤¹à¤¿à¤¨à¥à¤¦à¥€</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=th\">à¹„à¸—à¸¢</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=fr\">FranÃ§ais</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=de\">Deutsch</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=es\">EspaÃ±ol</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=it\">Itapano</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ru\">Ğ ÑƒÑÑĞºĞ¸Ğ¹</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=pt\">PortuguÃªs</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=nl\">Nederlands</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=pl\">Polski</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ar\">Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=fa\">ÙØ§Ø±Ø³ÛŒ</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=tr\">TÃ¼rkÃ§e</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=vi\">Tiáº¿ng Viá»‡t</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=id\">Bahasa Indonesia</a>\n      </div>\n    </div>\n  </details>\n</div>\n\n<div align=\"center\">\n\n# ZipVoiceâš¡\n\n## Fast and High-Quality Zero-Shot Text-to-Speech with Flow Matching\n</div>\n\n## Overview\n",
    "ContentSha": "4yvqxrt72y1T/XJlpvF5+w536K1FZVvNlGdllJQl3D8=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "\n<div align=\"right\">\n  <details>\n    <summary >ğŸŒ è¨€èª</summary>\n    <div>\n      <div align=\"center\">\n        <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=en\">English</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=zh-CN\">ç®€ä½“ä¸­æ–‡</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=zh-TW\">ç¹é«”ä¸­æ–‡</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ja\">æ—¥æœ¬èª</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ko\">í•œêµ­ì–´</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=hi\">à¤¹à¤¿à¤¨à¥à¤¦à¥€</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=th\">à¹„à¸—à¸¢</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=fr\">FranÃ§ais</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=de\">Deutsch</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=es\">EspaÃ±ol</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=it\">ã‚¤ã‚¿ãƒªã‚¢èª</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ru\">ãƒ­ã‚·ã‚¢èª</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=pt\">ãƒãƒ«ãƒˆã‚¬ãƒ«èª</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=nl\">ã‚ªãƒ©ãƒ³ãƒ€èª</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=pl\">ãƒãƒ¼ãƒ©ãƒ³ãƒ‰èª</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ar\">ã‚¢ãƒ©ãƒ“ã‚¢èª</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=fa\">ãƒšãƒ«ã‚·ãƒ£èª</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=tr\">ãƒˆãƒ«ã‚³èª</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=vi\">ãƒ™ãƒˆãƒŠãƒ èª</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=id\">ã‚¤ãƒ³ãƒ‰ãƒã‚·ã‚¢èª</a>\n      </div>\n    </div>\n  </details>\n</div>\n\n<div align=\"center\">\n\n# ZipVoiceâš¡\n\n## Flow Matchingã«ã‚ˆã‚‹é«˜é€Ÿãƒ»é«˜å“è³ªã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆéŸ³å£°åˆæˆ\n</div>\n\n## æ¦‚è¦\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 2,
        "rowsha": "cWgam+tnnXudu7i74+ahMEGk/A9dQS+EwWLAIfi3dHk=",
        "originContent": "<div align=\"right\">",
        "translatedContent": "<div align=\"right\">"
      },
      {
        "row": 3,
        "rowsha": "orOcu5ARna/hb3RUkj6dBI8pHTM3WHeTvby17l5E0h0=",
        "originContent": "  <details>",
        "translatedContent": "  <details>"
      },
      {
        "row": 4,
        "rowsha": "TtgkLzblnvP0q9aAIVXt6s2LczXjy5k+QvHKcU0/5Ms=",
        "originContent": "    <summary >ğŸŒ Language</summary>",
        "translatedContent": "    <summary >ğŸŒ è¨€èª</summary>"
      },
      {
        "row": 5,
        "rowsha": "fZtk4rPTAJEEslnbhSVkHEcPlsctYSzAV7CDPL3rJmA=",
        "originContent": "    <div>",
        "translatedContent": "    <div>"
      },
      {
        "row": 6,
        "rowsha": "9KQxOeJSigvTmGWO+mtnl8kZY9zQfueoy8sk4lYm09Q=",
        "originContent": "      <div align=\"center\">",
        "translatedContent": "      <div align=\"center\">"
      },
      {
        "row": 7,
        "rowsha": "CcXpQm1/9iKvN+A/uJNpETB0rQK265sk/3d1b8LJQvw=",
        "originContent": "        <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=en\">English</a>",
        "translatedContent": "        <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=en\">English</a>"
      },
      {
        "row": 8,
        "rowsha": "2ehWvRtwvqGgM54qlLoitqATfwSTpMIFoXVVk/tTbZk=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=zh-CN\">ç®€ä½“ä¸­æ–‡</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=zh-CN\">ç®€ä½“ä¸­æ–‡</a>"
      },
      {
        "row": 9,
        "rowsha": "1Tvr2tQAiIWOxk8K1sahQkXFaTfirEHUjC6CllQsguU=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=zh-TW\">ç¹é«”ä¸­æ–‡</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=zh-TW\">ç¹é«”ä¸­æ–‡</a>"
      },
      {
        "row": 10,
        "rowsha": "viezuYRV23r39DGnn2fqOoF8t4QQbZ3lGyQ4E/gKw50=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ja\">æ—¥æœ¬èª</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ja\">æ—¥æœ¬èª</a>"
      },
      {
        "row": 11,
        "rowsha": "58406DeYvrKlvqudebrWq+GPeIz8UsbceVEMZSbjPfo=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ko\">í•œêµ­ì–´</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ko\">í•œêµ­ì–´</a>"
      },
      {
        "row": 12,
        "rowsha": "v5RXbnVfWV0Tg1ipPFatAoRHQuK6otAxURhh9EL6oDI=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=hi\">à¤¹à¤¿à¤¨à¥à¤¦à¥€</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=hi\">à¤¹à¤¿à¤¨à¥à¤¦à¥€</a>"
      },
      {
        "row": 13,
        "rowsha": "WDhcLwM8wmfLsLyFOnzsTQ4H2X2S7KkNz897OsHtDa4=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=th\">à¹„à¸—à¸¢</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=th\">à¹„à¸—à¸¢</a>"
      },
      {
        "row": 14,
        "rowsha": "720JVKr0dHx3FSQCXiSfarWZShlzQL9HzYaW4cRQOSE=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=fr\">FranÃ§ais</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=fr\">FranÃ§ais</a>"
      },
      {
        "row": 15,
        "rowsha": "1DtWHtMk7/aAwtrrxeFamTGgcASobQlMfFoWQwsVKgc=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=de\">Deutsch</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=de\">Deutsch</a>"
      },
      {
        "row": 16,
        "rowsha": "H+5dK1gegkmcz74mwWxfH0NM5j9vtNmcVh9n3bhYBZs=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=es\">EspaÃ±ol</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=es\">EspaÃ±ol</a>"
      },
      {
        "row": 17,
        "rowsha": "f3xikpvVpOqPqS0kyScUlycc8Zt+diO9Zsw9FgLmd/Q=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=it\">Itapano</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=it\">ã‚¤ã‚¿ãƒªã‚¢èª</a>"
      },
      {
        "row": 18,
        "rowsha": "1+LH4k3BSN/Gkx95+faUF9zhlMy65p97wcjIXEw4dUg=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ru\">Ğ ÑƒÑÑĞºĞ¸Ğ¹</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ru\">ãƒ­ã‚·ã‚¢èª</a>"
      },
      {
        "row": 19,
        "rowsha": "JwE8Np2ImgiLGwhoGlsXFKpsgI9EU68Mjs8pysrvz9s=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=pt\">PortuguÃªs</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=pt\">ãƒãƒ«ãƒˆã‚¬ãƒ«èª</a>"
      },
      {
        "row": 20,
        "rowsha": "0eaTuNvMrL1d1tHfXDuGbl4NwHpIqSCOYgyWn+DeCd8=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=nl\">Nederlands</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=nl\">ã‚ªãƒ©ãƒ³ãƒ€èª</a>"
      },
      {
        "row": 21,
        "rowsha": "OD8ikjviedFkX4Kx5kNhXmU45dL9qIxmcf2cgTGhqlM=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=pl\">Polski</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=pl\">ãƒãƒ¼ãƒ©ãƒ³ãƒ‰èª</a>"
      },
      {
        "row": 22,
        "rowsha": "iYQFhiOJcKRK727JftPgQg0wEibC4UGYoysohgY4ZkE=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ar\">Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ar\">ã‚¢ãƒ©ãƒ“ã‚¢èª</a>"
      },
      {
        "row": 23,
        "rowsha": "bZuriOvMlwwmbrlK623agOuY9pyTAfsswef0LRsT3tU=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=fa\">ÙØ§Ø±Ø³ÛŒ</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=fa\">ãƒšãƒ«ã‚·ãƒ£èª</a>"
      },
      {
        "row": 24,
        "rowsha": "b7kL+KXfHE4Tqjt5V/TAEJQhMqU1SNWf9VVdfYkTrWY=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=tr\">TÃ¼rkÃ§e</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=tr\">ãƒˆãƒ«ã‚³èª</a>"
      },
      {
        "row": 25,
        "rowsha": "j0cS+2vemRltrd4DFNjdvu5Ad+ZpSR763x+uEnlcxks=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=vi\">Tiáº¿ng Viá»‡t</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=vi\">ãƒ™ãƒˆãƒŠãƒ èª</a>"
      },
      {
        "row": 26,
        "rowsha": "BI82Vx/H9f+weopSKKN3mOM7UAihcqzf7CfJbkigJ2A=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=id\">Bahasa Indonesia</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=id\">ã‚¤ãƒ³ãƒ‰ãƒã‚·ã‚¢èª</a>"
      },
      {
        "row": 27,
        "rowsha": "0OM5wNEm0TO56MEBvQzL7AUZM7/3OpgIeqRf2zFre3Q=",
        "originContent": "      </div>",
        "translatedContent": "      </div>"
      },
      {
        "row": 28,
        "rowsha": "fcjTfY+fs8YnY5slBs1sZvWPAqEQR7tzaBDO54skkGQ=",
        "originContent": "    </div>",
        "translatedContent": "    </div>"
      },
      {
        "row": 29,
        "rowsha": "+fQNH2ldI7UM/rqRscP3hUSWAmw1HvQ2wEKDN8JagT0=",
        "originContent": "  </details>",
        "translatedContent": "  </details>"
      },
      {
        "row": 30,
        "rowsha": "qsMmUbEPVnxGG5tPJV1vsfpoWbU2jYvZpRr5IKshzyM=",
        "originContent": "</div>",
        "translatedContent": "</div>"
      },
      {
        "row": 31,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 32,
        "rowsha": "94MDjHJY1ZLwHNTLIEUIfk7TMc9cq1L/1FmwhqBTe/k=",
        "originContent": "<div align=\"center\">",
        "translatedContent": "<div align=\"center\">"
      },
      {
        "row": 33,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 34,
        "rowsha": "43x8VXS2NIrGxEvJGcd03L2DM5gZshFS9vGXAT/nWoY=",
        "originContent": "# ZipVoiceâš¡",
        "translatedContent": "# ZipVoiceâš¡"
      },
      {
        "row": 35,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 36,
        "rowsha": "8cGkXE2E2Lj/nZFTwxIMm6gFZ5z+nFFHUz8ryL9qi64=",
        "originContent": "## Fast and High-Quality Zero-Shot Text-to-Speech with Flow Matching",
        "translatedContent": "## Flow Matchingã«ã‚ˆã‚‹é«˜é€Ÿãƒ»é«˜å“è³ªã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆéŸ³å£°åˆæˆ"
      },
      {
        "row": 37,
        "rowsha": "qsMmUbEPVnxGG5tPJV1vsfpoWbU2jYvZpRr5IKshzyM=",
        "originContent": "</div>",
        "translatedContent": "</div>"
      },
      {
        "row": 38,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 39,
        "rowsha": "czfz0Kop6agrjxZQt0Opju+QeUYx+nY6MZaG5pxUaCE=",
        "originContent": "## Overview",
        "translatedContent": "## æ¦‚è¦"
      },
      {
        "row": 40,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 2,
    "Content": "ZipVoice is a series of fast and high-quality zero-shot TTS models based on flow matching.\n\n### 1. Key features\n\n- Small and fast: only 123M parameters.\n\n- High-quality voice cloning: state-of-the-art performance in speaker similarity, intelligibility, and naturalness.\n\n- Multi-lingual: support Chinese and English.\n\n- Multi-mode: support both single-speaker and dialogue speech generation.\n\n### 2. Model variants\n\n<table>\n  <thead>\n    <tr>\n      <th>Model Name</th>\n      <th>Description</th>\n      <th>Paper</th>\n      <th>Demo</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>ZipVoice</td>\n      <td>The basic model supporting zero-shot single-speaker TTS in both Chinese and English.</td>\n      <td rowspan=\"2\"><a href=\"https://arxiv.org/abs/2506.13053\"><img src=\"https://img.shields.io/badge/arXiv-Paper-COLOR.svg\"></a></td>\n      <td rowspan=\"2\"><a href=\"https://zipvoice.github.io\"><img src=\"https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square\"></a></td>\n    </tr>\n    <tr>\n      <td>ZipVoice-Distill</td>\n      <td>The distilled version of ZipVoice, featuring improved speed with minimal performance degradation.</td>\n    </tr>\n    <tr>\n      <td>ZipVoice-Dialog</td>\n      <td>A dialogue generation model built on ZipVoice, capable of generating single-channel two-party spoken dialogues.</td>\n      <td rowspan=\"2\"><a href=\"https://arxiv.org/abs/2507.09318\"><img src=\"https://img.shields.io/badge/arXiv-Paper-COLOR.svg\"></a></td>\n      <td rowspan=\"2\"><a href=\"https://zipvoice-dialog.github.io\"><img src=\"https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square\"></a></td>\n    </tr>",
    "ContentSha": "qUZer10kkUVucN3aqovgCkJ059aWMO67vNYjNUfJcJw=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "ZipVoiceã¯ã€ãƒ•ãƒ­ãƒ¼ãƒãƒƒãƒãƒ³ã‚°ã«åŸºã¥ãé«˜é€Ÿã‹ã¤é«˜å“è³ªãªã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆTTSãƒ¢ãƒ‡ãƒ«ã‚·ãƒªãƒ¼ã‚ºã§ã™ã€‚\n\n### 1. ä¸»ãªç‰¹å¾´\n\n- å°å‹ã‹ã¤é«˜é€Ÿï¼šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã¯123Mã®ã¿ã€‚\n\n- é«˜å“è³ªãªéŸ³å£°ã‚¯ãƒ­ãƒ¼ãƒ³ï¼šè©±è€…é¡ä¼¼æ€§ã€å¯è´æ€§ã€è‡ªç„¶ã•ã§æœ€å…ˆç«¯ã®æ€§èƒ½ã€‚\n\n- å¤šè¨€èªå¯¾å¿œï¼šä¸­å›½èªã¨è‹±èªã‚’ã‚µãƒãƒ¼ãƒˆã€‚\n\n- ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ‰å¯¾å¿œï¼šå˜ä¸€è©±è€…ãŠã‚ˆã³å¯¾è©±éŸ³å£°ç”Ÿæˆã‚’ã‚µãƒãƒ¼ãƒˆã€‚\n\n### 2. ãƒ¢ãƒ‡ãƒ«ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³\n\n<table>\n  <thead>\n    <tr>\n      <th>ãƒ¢ãƒ‡ãƒ«å</th>\n      <th>èª¬æ˜</th>\n      <th>è«–æ–‡</th>\n      <th>ãƒ‡ãƒ¢</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>ZipVoice</td>\n      <td>ä¸­å›½èªã¨è‹±èªã®ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆå˜ä¸€è©±è€…TTSã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹åŸºæœ¬ãƒ¢ãƒ‡ãƒ«ã€‚</td>\n      <td rowspan=\"2\"><a href=\"https://arxiv.org/abs/2506.13053\"><img src=\"https://img.shields.io/badge/arXiv-Paper-COLOR.svg\"></a></td>\n      <td rowspan=\"2\"><a href=\"https://zipvoice.github.io\"><img src=\"https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square\"></a></td>\n    </tr>\n    <tr>\n      <td>ZipVoice-Distill</td>\n      <td>ZipVoiceã®è’¸ç•™ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã§ã€æ€§èƒ½ä½ä¸‹ã‚’æœ€å°é™ã«æŠ‘ãˆã¤ã¤é€Ÿåº¦ã‚’å‘ä¸Šã€‚</td>\n    </tr>\n    <tr>\n      <td>ZipVoice-Dialog</td>\n      <td>ZipVoiceä¸Šã«æ§‹ç¯‰ã•ã‚ŒãŸå¯¾è©±ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã§ã€å˜ä¸€ãƒãƒ£ãƒãƒ«ã®äºŒè€…ä¼šè©±éŸ³å£°ç”ŸæˆãŒå¯èƒ½ã€‚</td>\n      <td rowspan=\"2\"><a href=\"https://arxiv.org/abs/2507.09318\"><img src=\"https://img.shields.io/badge/arXiv-Paper-COLOR.svg\"></a></td>\n      <td rowspan=\"2\"><a href=\"https://zipvoice-dialog.github.io\"><img src=\"https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square\"></a></td>\n    </tr>",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "nQS2T1vCMqJruAgLkxb46w0hSAkEn/IM3WAyxZjZ41Q=",
        "originContent": "ZipVoice is a series of fast and high-quality zero-shot TTS models based on flow matching.",
        "translatedContent": "ZipVoiceã¯ã€ãƒ•ãƒ­ãƒ¼ãƒãƒƒãƒãƒ³ã‚°ã«åŸºã¥ãé«˜é€Ÿã‹ã¤é«˜å“è³ªãªã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆTTSãƒ¢ãƒ‡ãƒ«ã‚·ãƒªãƒ¼ã‚ºã§ã™ã€‚"
      },
      {
        "row": 2,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 3,
        "rowsha": "ucC7hUEIiT/76texV2ocUEuEh3ipUzSv7QRGCII6ZzM=",
        "originContent": "### 1. Key features",
        "translatedContent": "### 1. ä¸»ãªç‰¹å¾´"
      },
      {
        "row": 4,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 5,
        "rowsha": "mnMSMs6GmKRNnNbe05VmoRtRBkZF0/KoDIo2RGx2miQ=",
        "originContent": "- Small and fast: only 123M parameters.",
        "translatedContent": "- å°å‹ã‹ã¤é«˜é€Ÿï¼šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã¯123Mã®ã¿ã€‚"
      },
      {
        "row": 6,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 7,
        "rowsha": "DTc6Shc7YIXhauUP00lzZgJfeGsA8b/7jnpoWq4PK0U=",
        "originContent": "- High-quality voice cloning: state-of-the-art performance in speaker similarity, intelligibility, and naturalness.",
        "translatedContent": "- é«˜å“è³ªãªéŸ³å£°ã‚¯ãƒ­ãƒ¼ãƒ³ï¼šè©±è€…é¡ä¼¼æ€§ã€å¯è´æ€§ã€è‡ªç„¶ã•ã§æœ€å…ˆç«¯ã®æ€§èƒ½ã€‚"
      },
      {
        "row": 8,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 9,
        "rowsha": "yt9ntJffC7kC7o3urvP30pUjjiFSCTNvFa2IsukbVDE=",
        "originContent": "- Multi-lingual: support Chinese and English.",
        "translatedContent": "- å¤šè¨€èªå¯¾å¿œï¼šä¸­å›½èªã¨è‹±èªã‚’ã‚µãƒãƒ¼ãƒˆã€‚"
      },
      {
        "row": 10,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 11,
        "rowsha": "zxFH2T15/GT24QXdR/3+MTlLcndjhW81in4fA6q/NqI=",
        "originContent": "- Multi-mode: support both single-speaker and dialogue speech generation.",
        "translatedContent": "- ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ‰å¯¾å¿œï¼šå˜ä¸€è©±è€…ãŠã‚ˆã³å¯¾è©±éŸ³å£°ç”Ÿæˆã‚’ã‚µãƒãƒ¼ãƒˆã€‚"
      },
      {
        "row": 12,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 13,
        "rowsha": "euhnPJYVS9UO65MqpSJ6SGItveAQx/PEyxlOhvoL7gQ=",
        "originContent": "### 2. Model variants",
        "translatedContent": "### 2. ãƒ¢ãƒ‡ãƒ«ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³"
      },
      {
        "row": 14,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 15,
        "rowsha": "kq0DFTS69SZCm3Odp9SwOmLuj08yYNkZvbhcRxtdMkQ=",
        "originContent": "<table>",
        "translatedContent": "<table>"
      },
      {
        "row": 16,
        "rowsha": "fVeZa2zHTj+GejNZeOMEq73p8lrPy91L7a2SAORQGww=",
        "originContent": "  <thead>",
        "translatedContent": "  <thead>"
      },
      {
        "row": 17,
        "rowsha": "mQe8Du3ITIgeK5HrAaAmVDg4p8IDxaiLEnVYSpNSPoQ=",
        "originContent": "    <tr>",
        "translatedContent": "    <tr>"
      },
      {
        "row": 18,
        "rowsha": "z4Rwl4uu63uzLboduV7OD40QtA50BzuyfDCtbD3ZuGA=",
        "originContent": "      <th>Model Name</th>",
        "translatedContent": "      <th>ãƒ¢ãƒ‡ãƒ«å</th>"
      },
      {
        "row": 19,
        "rowsha": "O/DS90B9w8GpepemJkQp634TTVY3fEDiLIPL5Ltaq78=",
        "originContent": "      <th>Description</th>",
        "translatedContent": "      <th>èª¬æ˜</th>"
      },
      {
        "row": 20,
        "rowsha": "YGp5skEXJ0tuyZL/KspO3fgVUV+H1ijs8hRaS27I9zg=",
        "originContent": "      <th>Paper</th>",
        "translatedContent": "      <th>è«–æ–‡</th>"
      },
      {
        "row": 21,
        "rowsha": "nq0QdUA8EPB/UZOofw7s5hdITABnq7ZhH3chJk3iFow=",
        "originContent": "      <th>Demo</th>",
        "translatedContent": "      <th>ãƒ‡ãƒ¢</th>"
      },
      {
        "row": 22,
        "rowsha": "qMXSfcecmgpTcWjU4/DonhxZrtbJe20/4kuvSQqv9HU=",
        "originContent": "    </tr>",
        "translatedContent": "    </tr>"
      },
      {
        "row": 23,
        "rowsha": "QAgj2Ue5ZqUAelXIN3OwGwnCFXD2scHVIkAz9iHowbw=",
        "originContent": "  </thead>",
        "translatedContent": "  </thead>"
      },
      {
        "row": 24,
        "rowsha": "V8SoadU3qlQEyQXfcDO5Evu+vSduzv+IQXpGHlNEQ4M=",
        "originContent": "  <tbody>",
        "translatedContent": "  <tbody>"
      },
      {
        "row": 25,
        "rowsha": "mQe8Du3ITIgeK5HrAaAmVDg4p8IDxaiLEnVYSpNSPoQ=",
        "originContent": "    <tr>",
        "translatedContent": "    <tr>"
      },
      {
        "row": 26,
        "rowsha": "ndVKgIyPesKKyqCb1fPiiBsMn4f9r+E9zy2h+rEQMEg=",
        "originContent": "      <td>ZipVoice</td>",
        "translatedContent": "      <td>ZipVoice</td>"
      },
      {
        "row": 27,
        "rowsha": "V4nOcrSY1j7m4uPd0Q3jKJV5OYsg3vveAhj2uXuDYpo=",
        "originContent": "      <td>The basic model supporting zero-shot single-speaker TTS in both Chinese and English.</td>",
        "translatedContent": "      <td>ä¸­å›½èªã¨è‹±èªã®ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆå˜ä¸€è©±è€…TTSã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹åŸºæœ¬ãƒ¢ãƒ‡ãƒ«ã€‚</td>"
      },
      {
        "row": 28,
        "rowsha": "oYsdnyALg8AzIa9SQc6g12SHxZsEaAnuMNKRixdVEOI=",
        "originContent": "      <td rowspan=\"2\"><a href=\"https://arxiv.org/abs/2506.13053\"><img src=\"https://img.shields.io/badge/arXiv-Paper-COLOR.svg\"></a></td>",
        "translatedContent": "      <td rowspan=\"2\"><a href=\"https://arxiv.org/abs/2506.13053\"><img src=\"https://img.shields.io/badge/arXiv-Paper-COLOR.svg\"></a></td>"
      },
      {
        "row": 29,
        "rowsha": "D4+fblzP0Ay8rjWW7tpMeTQtV1brxxngEj2VRAwXeG4=",
        "originContent": "      <td rowspan=\"2\"><a href=\"https://zipvoice.github.io\"><img src=\"https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square\"></a></td>",
        "translatedContent": "      <td rowspan=\"2\"><a href=\"https://zipvoice.github.io\"><img src=\"https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square\"></a></td>"
      },
      {
        "row": 30,
        "rowsha": "qMXSfcecmgpTcWjU4/DonhxZrtbJe20/4kuvSQqv9HU=",
        "originContent": "    </tr>",
        "translatedContent": "    </tr>"
      },
      {
        "row": 31,
        "rowsha": "mQe8Du3ITIgeK5HrAaAmVDg4p8IDxaiLEnVYSpNSPoQ=",
        "originContent": "    <tr>",
        "translatedContent": "    <tr>"
      },
      {
        "row": 32,
        "rowsha": "O5M2zS2wTgQ/tb2NGv9Zwg2M/p4ap3H3QEscfDprkLY=",
        "originContent": "      <td>ZipVoice-Distill</td>",
        "translatedContent": "      <td>ZipVoice-Distill</td>"
      },
      {
        "row": 33,
        "rowsha": "+GY4P77oZKf2OE98WJt+uHde+9Pfx5adwPX/hgBXv/0=",
        "originContent": "      <td>The distilled version of ZipVoice, featuring improved speed with minimal performance degradation.</td>",
        "translatedContent": "      <td>ZipVoiceã®è’¸ç•™ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã§ã€æ€§èƒ½ä½ä¸‹ã‚’æœ€å°é™ã«æŠ‘ãˆã¤ã¤é€Ÿåº¦ã‚’å‘ä¸Šã€‚</td>"
      },
      {
        "row": 34,
        "rowsha": "qMXSfcecmgpTcWjU4/DonhxZrtbJe20/4kuvSQqv9HU=",
        "originContent": "    </tr>",
        "translatedContent": "    </tr>"
      },
      {
        "row": 35,
        "rowsha": "mQe8Du3ITIgeK5HrAaAmVDg4p8IDxaiLEnVYSpNSPoQ=",
        "originContent": "    <tr>",
        "translatedContent": "    <tr>"
      },
      {
        "row": 36,
        "rowsha": "AokiHqhaQvuU9KuEm8+8XFm12AAfehl/iUS5IKh25hg=",
        "originContent": "      <td>ZipVoice-Dialog</td>",
        "translatedContent": "      <td>ZipVoice-Dialog</td>"
      },
      {
        "row": 37,
        "rowsha": "VyLj//yzuicS9drxTtHyEb23TlyYimyWqSLjKnhiPRI=",
        "originContent": "      <td>A dialogue generation model built on ZipVoice, capable of generating single-channel two-party spoken dialogues.</td>",
        "translatedContent": "      <td>ZipVoiceä¸Šã«æ§‹ç¯‰ã•ã‚ŒãŸå¯¾è©±ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã§ã€å˜ä¸€ãƒãƒ£ãƒãƒ«ã®äºŒè€…ä¼šè©±éŸ³å£°ç”ŸæˆãŒå¯èƒ½ã€‚</td>"
      },
      {
        "row": 38,
        "rowsha": "52missEFmjbF4iX2P0jQNQNcxMRdvKLCWURi53zHj9c=",
        "originContent": "      <td rowspan=\"2\"><a href=\"https://arxiv.org/abs/2507.09318\"><img src=\"https://img.shields.io/badge/arXiv-Paper-COLOR.svg\"></a></td>",
        "translatedContent": "      <td rowspan=\"2\"><a href=\"https://arxiv.org/abs/2507.09318\"><img src=\"https://img.shields.io/badge/arXiv-Paper-COLOR.svg\"></a></td>"
      },
      {
        "row": 39,
        "rowsha": "cDPQ2lSV0MvAN7W5vsgpUGdH0r3KovLhGy8iNUb891g=",
        "originContent": "      <td rowspan=\"2\"><a href=\"https://zipvoice-dialog.github.io\"><img src=\"https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square\"></a></td>",
        "translatedContent": "      <td rowspan=\"2\"><a href=\"https://zipvoice-dialog.github.io\"><img src=\"https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square\"></a></td>"
      },
      {
        "row": 40,
        "rowsha": "qMXSfcecmgpTcWjU4/DonhxZrtbJe20/4kuvSQqv9HU=",
        "originContent": "    </tr>",
        "translatedContent": "    </tr>"
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 3,
    "Content": "    <tr>\n      <td>ZipVoice-Dialog-Stereo</td>\n      <td>The stereo variant of ZipVoice-Dialog, enabling two-channel dialogue generation with each speaker assigned to a distinct channel.</td>\n    </tr>\n  </tbody>\n</table>\n\n## News\n\n**2025/07/14**: **ZipVoice-Dialog** and **ZipVoice-Dialog-Stereo**, two spoken dialogue generation models, are released. [![arXiv](https://img.shields.io/badge/arXiv-Paper-COLOR.svg)](https://arxiv.org/abs/2507.09318) [![demo page](https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square)](https://zipvoice-dialog.github.io)\n\n**2025/07/14**: **OpenDialog** dataset, a 6.8k-hour spoken dialogue dataset, is released. Download at [![hf](https://img.shields.io/badge/%F0%9F%A4%97%20HuggingFace-Dataset-yellow)](https://huggingface.co/datasets/k2-fsa/OpenDialog), [![ms](https://img.shields.io/badge/ModelScope-Dataset-blue?logo=data)](https://www.modelscope.cn/datasets/k2-fsa/OpenDialog). Check details at [![arXiv](https://img.shields.io/badge/arXiv-Paper-COLOR.svg)](https://arxiv.org/abs/2507.09318).\n\n**2025/06/16**: **ZipVoice** and **ZipVoice-Distill** are released. [![arXiv](https://img.shields.io/badge/arXiv-Paper-COLOR.svg)](https://arxiv.org/abs/2506.13053) [![demo page](https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square)](https://zipvoice.github.io)\n\n## Installation\n\n### 1. Clone the ZipVoice repository\n",
    "ContentSha": "qyykZIxy9KKTHUZalqgKJAhZ9ZS/CaAb/vbLISMH1+E=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "    <tr>\n      <td>ZipVoice-Dialog-Stereo</td>\n      <td>ZipVoice-Dialogã®ã‚¹ãƒ†ãƒ¬ã‚ªãƒãƒªã‚¢ãƒ³ãƒˆã§ã‚ã‚Šã€å„è©±è€…ãŒç•°ãªã‚‹ãƒãƒ£ãƒ³ãƒãƒ«ã«å‰²ã‚Šå½“ã¦ã‚‰ã‚Œã‚‹2ãƒãƒ£ãƒ³ãƒãƒ«å¯¾è©±ç”Ÿæˆã‚’å®Ÿç¾ã—ã¾ã™ã€‚</td>\n    </tr>\n  </tbody>\n</table>\n\n## ãƒ‹ãƒ¥ãƒ¼ã‚¹\n\n**2025/07/14**: **ZipVoice-Dialog**ãŠã‚ˆã³**ZipVoice-Dialog-Stereo**ã€2ã¤ã®éŸ³å£°å¯¾è©±ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã‚’ãƒªãƒªãƒ¼ã‚¹ã—ã¾ã—ãŸã€‚[![arXiv](https://img.shields.io/badge/arXiv-Paper-COLOR.svg)](https://arxiv.org/abs/2507.09318) [![demo page](https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square)](https://zipvoice-dialog.github.io)\n\n**2025/07/14**: **OpenDialog**ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆ6.8kæ™‚é–“ã®éŸ³å£°å¯¾è©±ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼‰ã‚’å…¬é–‹ã—ã¾ã—ãŸã€‚ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã¯[![hf](https://img.shields.io/badge/%F0%9F%A4%97%20HuggingFace-Dataset-yellow)](https://huggingface.co/datasets/k2-fsa/OpenDialog), [![ms](https://img.shields.io/badge/ModelScope-Dataset-blue?logo=data)](https://www.modelscope.cn/datasets/k2-fsa/OpenDialog)ã€‚è©³ç´°ã¯[![arXiv](https://img.shields.io/badge/arXiv-Paper-COLOR.svg)](https://arxiv.org/abs/2507.09318)ã‚’ã”è¦§ãã ã•ã„ã€‚\n\n**2025/06/16**: **ZipVoice**ãŠã‚ˆã³**ZipVoice-Distill**ã‚’ãƒªãƒªãƒ¼ã‚¹ã—ã¾ã—ãŸã€‚[![arXiv](https://img.shields.io/badge/arXiv-Paper-COLOR.svg)](https://arxiv.org/abs/2506.13053) [![demo page](https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square)](https://zipvoice.github.io)\n\n## ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n\n### 1. ZipVoiceãƒªãƒã‚¸ãƒˆãƒªã‚’ã‚¯ãƒ­ãƒ¼ãƒ³ã™ã‚‹\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "mQe8Du3ITIgeK5HrAaAmVDg4p8IDxaiLEnVYSpNSPoQ=",
        "originContent": "    <tr>",
        "translatedContent": "    <tr>"
      },
      {
        "row": 2,
        "rowsha": "5wxh9pzh0ath/did6Y4bnHT5G0oknzB4REIMmmpbrWc=",
        "originContent": "      <td>ZipVoice-Dialog-Stereo</td>",
        "translatedContent": "      <td>ZipVoice-Dialog-Stereo</td>"
      },
      {
        "row": 3,
        "rowsha": "4zPgKHyoRGqee2hEpKE1kawe5id33R887ovyXGFAikU=",
        "originContent": "      <td>The stereo variant of ZipVoice-Dialog, enabling two-channel dialogue generation with each speaker assigned to a distinct channel.</td>",
        "translatedContent": "      <td>ZipVoice-Dialogã®ã‚¹ãƒ†ãƒ¬ã‚ªãƒãƒªã‚¢ãƒ³ãƒˆã§ã‚ã‚Šã€å„è©±è€…ãŒç•°ãªã‚‹ãƒãƒ£ãƒ³ãƒãƒ«ã«å‰²ã‚Šå½“ã¦ã‚‰ã‚Œã‚‹2ãƒãƒ£ãƒ³ãƒãƒ«å¯¾è©±ç”Ÿæˆã‚’å®Ÿç¾ã—ã¾ã™ã€‚</td>"
      },
      {
        "row": 4,
        "rowsha": "qMXSfcecmgpTcWjU4/DonhxZrtbJe20/4kuvSQqv9HU=",
        "originContent": "    </tr>",
        "translatedContent": "    </tr>"
      },
      {
        "row": 5,
        "rowsha": "HgAQR47u7qD0p8NwuwwZJ7dDJg35+B/lslvDHWuZaBU=",
        "originContent": "  </tbody>",
        "translatedContent": "  </tbody>"
      },
      {
        "row": 6,
        "rowsha": "H+dtb55ry3VN2CLvAetudgE9ICnYQdUralLHuIqMdZM=",
        "originContent": "</table>",
        "translatedContent": "</table>"
      },
      {
        "row": 7,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 8,
        "rowsha": "4SzYJwNNDn2R2kkHsB4X4H4ZhUVuQo9QZvhInidlbxE=",
        "originContent": "## News",
        "translatedContent": "## ãƒ‹ãƒ¥ãƒ¼ã‚¹"
      },
      {
        "row": 9,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 10,
        "rowsha": "DfOZSiFY93Zgx5ovWAl3CGk0WussCMIUOrJfiCw6Ul0=",
        "originContent": "**2025/07/14**: **ZipVoice-Dialog** and **ZipVoice-Dialog-Stereo**, two spoken dialogue generation models, are released. [![arXiv](https://img.shields.io/badge/arXiv-Paper-COLOR.svg)](https://arxiv.org/abs/2507.09318) [![demo page](https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square)](https://zipvoice-dialog.github.io)",
        "translatedContent": "**2025/07/14**: **ZipVoice-Dialog**ãŠã‚ˆã³**ZipVoice-Dialog-Stereo**ã€2ã¤ã®éŸ³å£°å¯¾è©±ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã‚’ãƒªãƒªãƒ¼ã‚¹ã—ã¾ã—ãŸã€‚[![arXiv](https://img.shields.io/badge/arXiv-Paper-COLOR.svg)](https://arxiv.org/abs/2507.09318) [![demo page](https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square)](https://zipvoice-dialog.github.io)"
      },
      {
        "row": 11,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 12,
        "rowsha": "HdUKrlzAn5/ebTtUoBeZCSvFc7yoA+bUx9wm05BLIyI=",
        "originContent": "**2025/07/14**: **OpenDialog** dataset, a 6.8k-hour spoken dialogue dataset, is released. Download at [![hf](https://img.shields.io/badge/%F0%9F%A4%97%20HuggingFace-Dataset-yellow)](https://huggingface.co/datasets/k2-fsa/OpenDialog), [![ms](https://img.shields.io/badge/ModelScope-Dataset-blue?logo=data)](https://www.modelscope.cn/datasets/k2-fsa/OpenDialog). Check details at [![arXiv](https://img.shields.io/badge/arXiv-Paper-COLOR.svg)](https://arxiv.org/abs/2507.09318).",
        "translatedContent": "**2025/07/14**: **OpenDialog**ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆ6.8kæ™‚é–“ã®éŸ³å£°å¯¾è©±ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼‰ã‚’å…¬é–‹ã—ã¾ã—ãŸã€‚ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã¯[![hf](https://img.shields.io/badge/%F0%9F%A4%97%20HuggingFace-Dataset-yellow)](https://huggingface.co/datasets/k2-fsa/OpenDialog), [![ms](https://img.shields.io/badge/ModelScope-Dataset-blue?logo=data)](https://www.modelscope.cn/datasets/k2-fsa/OpenDialog)ã€‚è©³ç´°ã¯[![arXiv](https://img.shields.io/badge/arXiv-Paper-COLOR.svg)](https://arxiv.org/abs/2507.09318)ã‚’ã”è¦§ãã ã•ã„ã€‚"
      },
      {
        "row": 13,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 14,
        "rowsha": "0OIq3Ae2KEaqpQCFjIP/3rxyTxS6RICMJWSmPyeMdA8=",
        "originContent": "**2025/06/16**: **ZipVoice** and **ZipVoice-Distill** are released. [![arXiv](https://img.shields.io/badge/arXiv-Paper-COLOR.svg)](https://arxiv.org/abs/2506.13053) [![demo page](https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square)](https://zipvoice.github.io)",
        "translatedContent": "**2025/06/16**: **ZipVoice**ãŠã‚ˆã³**ZipVoice-Distill**ã‚’ãƒªãƒªãƒ¼ã‚¹ã—ã¾ã—ãŸã€‚[![arXiv](https://img.shields.io/badge/arXiv-Paper-COLOR.svg)](https://arxiv.org/abs/2506.13053) [![demo page](https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square)](https://zipvoice.github.io)"
      },
      {
        "row": 15,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 16,
        "rowsha": "oV0SUDvwD2VN8Gi9nlr2JZ2xcDrASmE2W5kc5SVX5eo=",
        "originContent": "## Installation",
        "translatedContent": "## ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«"
      },
      {
        "row": 17,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 18,
        "rowsha": "3s/0urTHhRlVIuxHnj5ytcB39gCSsfn6y5cYocnuTIs=",
        "originContent": "### 1. Clone the ZipVoice repository",
        "translatedContent": "### 1. ZipVoiceãƒªãƒã‚¸ãƒˆãƒªã‚’ã‚¯ãƒ­ãƒ¼ãƒ³ã™ã‚‹"
      },
      {
        "row": 19,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 4,
    "Content": "```bash\ngit clone https://github.com/k2-fsa/ZipVoice.git\n```",
    "ContentSha": "JJo1EP7bWO0BWMfBMdp5X937bp3+DWhl7nAOm71R7lA=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\ngit clone https://github.com/k2-fsa/ZipVoice.git\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 5,
    "Content": "\n### 2. (Optional) Create a Python virtual environment\n",
    "ContentSha": "SdfmTQw39ITwBrkeETcUaJ4CPFr6cQ+HCqumZ483/iY=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "### 2. ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰Pythonã®ä»®æƒ³ç’°å¢ƒã‚’ä½œæˆã™ã‚‹\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 6,
    "Content": "```bash\npython3 -m venv zipvoice\nsource zipvoice/bin/activate\n```",
    "ContentSha": "glR0Rdvd5rjEtSF3LycYEtxGB8VzT68abW/ywL40bxw=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\npython3 -m venv zipvoice\nsource zipvoice/bin/activate\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 7,
    "Content": "\n### 3. Install the required packages\n",
    "ContentSha": "97VTTWuamYvk4THPyO5Ex48XMRIdHtV0dBXABNHe3qQ=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "### 3. å¿…è¦ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 8,
    "Content": "```bash\npip install -r requirements.txt\n```",
    "ContentSha": "TxMa9uJC0PmBOnm3/TRl4YDLNvSwCWaRNjyXpFhndHU=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\npip install -r requirements.txt\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 9,
    "Content": "\n### 4. Install k2 for training or efficient inference\n\n**k2 is necessary for training** and can speed up inference. Nevertheless, you can still use the inference mode of ZipVoice without installing k2.\n\n> **Note:**  Make sure to install the k2 version that matches your PyTorch and CUDA version. For example, if you are using pytorch 2.5.1 and CUDA 12.1, you can install k2 as follows:\n",
    "ContentSha": "it0kOYkTtKi6ipV/r+Px+BHDpullJx7ZxRNyR9UNc40=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "### 4. å­¦ç¿’ã¾ãŸã¯åŠ¹ç‡çš„ãªæ¨è«–ã®ãŸã‚ã«k2ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹\n\n**k2ã¯å­¦ç¿’ã«å¿…è¦**ã§ã‚ã‚Šã€æ¨è«–ã‚‚é«˜é€ŸåŒ–ã§ãã¾ã™ã€‚ãŸã ã—ã€k2ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ãªãã¦ã‚‚ZipVoiceã®æ¨è«–ãƒ¢ãƒ¼ãƒ‰ã¯åˆ©ç”¨å¯èƒ½ã§ã™ã€‚\n\n> **æ³¨æ„:** PyTorchã¨CUDAã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã«åˆã£ãŸk2ã‚’å¿…ãšã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„ã€‚ä¾‹ãˆã°ã€pytorch 2.5.1ã¨CUDA 12.1ã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹å ´åˆã€ä»¥ä¸‹ã®ã‚ˆã†ã«k2ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§ãã¾ã™ã€‚\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 10,
    "Content": "```bash\npip install k2==1.24.4.dev20250208+cuda12.1.torch2.5.1 -f https://k2-fsa.github.io/k2/cuda.html\n```",
    "ContentSha": "ScZHk5YUmlVP9WL5ZgwHsvBVbwTCenfwKc3cJb6nrWo=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\npip install k2==1.24.4.dev20250208+cuda12.1.torch2.5.1 -f https://k2-fsa.github.io/k2/cuda.html\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 11,
    "Content": "\nPlease refer to https://k2-fsa.org/get-started/k2/ for details.\nUsers in China mainland can refer to https://k2-fsa.org/zh-CN/get-started/k2/.\n\n- To check the k2 installation:\n",
    "ContentSha": "rY1Zhq3aduWMw4XQSft+r2qBy7l8kqnHBs8cs4FGpZ4=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "è©³ç´°ã«ã¤ã„ã¦ã¯ã€https://k2-fsa.org/get-started/k2/ ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚\nä¸­å›½æœ¬åœŸã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ https://k2-fsa.org/zh-CN/get-started/k2/ ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚\n\n- k2 ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã‚’ç¢ºèªã™ã‚‹ã«ã¯:\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 12,
    "Content": "```bash\npython3 -c \"import k2; print(k2.__file__)\"\n```",
    "ContentSha": "PH4E7oc9yWRIVi2n1L4BiFuChpCHjHuJ65gAwNBxvHE=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\npython3 -c \"import k2; print(k2.__file__)\"\n```",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "rTMjNc+qNIxb1xXDR5hEYiJw1fc4muBwuBsTXVIaIho=",
        "originContent": "```bash",
        "translatedContent": "```bash"
      },
      {
        "row": 2,
        "rowsha": "7yHd9AwCS2R/DPcwaogfIhkKXz9t9u3yeddGTQpSgnE=",
        "originContent": "python3 -c \"import k2; print(k2.__file__)\"",
        "translatedContent": "python3 -c \"import k2; print(k2.__file__)\""
      },
      {
        "row": 3,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      }
    ],
    "IsCodeBlock": true
  },
  {
    "Id": 13,
    "Content": "\n## Usage\n\n### 1. Single-speaker speech generation\n\nTo generate single-speaker speech with our pre-trained ZipVoice or ZipVoice-Distill models, use the following commands (Required models will be downloaded from HuggingFace):\n\n#### 1.1 Inference of a single sentence\n",
    "ContentSha": "B4h5YyIywYfr2neMM1PwmS6nY8/eY48N4jkDeP3wG+Y=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "## ä½¿ç”¨æ–¹æ³•\n\n### 1. å˜ä¸€è©±è€…éŸ³å£°ç”Ÿæˆ\n\näº‹å‰å­¦ç¿’æ¸ˆã¿ã®ZipVoiceã¾ãŸã¯ZipVoice-Distillãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦å˜ä¸€è©±è€…ã®éŸ³å£°ã‚’ç”Ÿæˆã™ã‚‹ã«ã¯ã€ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’ä½¿ç”¨ã—ã¾ã™ï¼ˆå¿…è¦ãªãƒ¢ãƒ‡ãƒ«ã¯HuggingFaceã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã™ï¼‰:\n\n#### 1.1 å˜ä¸€æ–‡ã®æ¨è«–\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 14,
    "Content": "```bash\npython3 -m zipvoice.bin.infer_zipvoice \\\n    --model-name zipvoice \\\n    --prompt-wav prompt.wav \\\n    --prompt-text \"I am the transcription of the prompt wav.\" \\\n    --text \"I am the text to be synthesized.\" \\\n    --res-wav-path result.wav\n```",
    "ContentSha": "s3L0IUGcm9ppsQesBx8AKaxAjpRhRDaqb8rE/HLRinc=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\npython3 -m zipvoice.bin.infer_zipvoice \\\n    --model-name zipvoice \\\n    --prompt-wav prompt.wav \\\n    --prompt-text \"I am the transcription of the prompt wav.\" \\\n    --text \"I am the text to be synthesized.\" \\\n    --res-wav-path result.wav\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 15,
    "Content": "- `--model-name` can be `zipvoice` or `zipvoice_distill`, which are models before and after distillation, respectively.\n- If `<>` or `[]` appear in the text, strings enclosed by them will be treated as special tokens. `<>` denotes Chinese pinyin and `[]` denotes other special tags.\n\n#### 1.2 Inference of a list of sentences\n",
    "ContentSha": "9gu4tqRbp3LNcYk2S6twKEix9A9CPCJP4IQ8qVja+jw=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "- `--model-name` ã¯ `zipvoice` ã¾ãŸã¯ `zipvoice_distill` ã‚’æŒ‡å®šã§ãã€ãã‚Œãã‚Œè’¸ç•™å‰ãŠã‚ˆã³è’¸ç•™å¾Œã®ãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚\n- ãƒ†ã‚­ã‚¹ãƒˆã« `<>` ã‚„ `[]` ãŒç¾ã‚Œã‚‹å ´åˆã€ãã‚Œã‚‰ã§å›²ã¾ã‚ŒãŸæ–‡å­—åˆ—ã¯ç‰¹æ®Šãƒˆãƒ¼ã‚¯ãƒ³ã¨ã—ã¦æ‰±ã‚ã‚Œã¾ã™ã€‚`<>` ã¯ä¸­å›½èªã®ãƒ”ãƒ³ã‚¤ãƒ³ã‚’ã€`[]` ã¯ãã®ä»–ã®ç‰¹æ®Šã‚¿ã‚°ã‚’è¡¨ã—ã¾ã™ã€‚\n\n#### 1.2 è¤‡æ•°æ–‡ã®æ¨è«–\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "Vk0m6NrE3gMzFw6jIUmVS2xf8e53UPorfjw3hnyoR8g=",
        "originContent": "- `--model-name` can be `zipvoice` or `zipvoice_distill`, which are models before and after distillation, respectively.",
        "translatedContent": "- `--model-name` ã¯ `zipvoice` ã¾ãŸã¯ `zipvoice_distill` ã‚’æŒ‡å®šã§ãã€ãã‚Œãã‚Œè’¸ç•™å‰ãŠã‚ˆã³è’¸ç•™å¾Œã®ãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚"
      },
      {
        "row": 2,
        "rowsha": "l7kUz5yeNN2aq8iILGY4UuGx9dvsTL+VIkCcGFxqaHc=",
        "originContent": "- If `<>` or `[]` appear in the text, strings enclosed by them will be treated as special tokens. `<>` denotes Chinese pinyin and `[]` denotes other special tags.",
        "translatedContent": "- ãƒ†ã‚­ã‚¹ãƒˆã« `<>` ã‚„ `[]` ãŒç¾ã‚Œã‚‹å ´åˆã€ãã‚Œã‚‰ã§å›²ã¾ã‚ŒãŸæ–‡å­—åˆ—ã¯ç‰¹æ®Šãƒˆãƒ¼ã‚¯ãƒ³ã¨ã—ã¦æ‰±ã‚ã‚Œã¾ã™ã€‚`<>` ã¯ä¸­å›½èªã®ãƒ”ãƒ³ã‚¤ãƒ³ã‚’ã€`[]` ã¯ãã®ä»–ã®ç‰¹æ®Šã‚¿ã‚°ã‚’è¡¨ã—ã¾ã™ã€‚"
      },
      {
        "row": 3,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 4,
        "rowsha": "8zUs0xdKItgiKM1ReiXt8Pbmo0PrH0yE33PZ24pLLIw=",
        "originContent": "#### 1.2 Inference of a list of sentences",
        "translatedContent": "#### 1.2 è¤‡æ•°æ–‡ã®æ¨è«–"
      },
      {
        "row": 5,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 16,
    "Content": "```bash\npython3 -m zipvoice.bin.infer_zipvoice \\\n    --model-name zipvoice \\\n    --test-list test.tsv \\\n    --res-dir results\n```",
    "ContentSha": "wVKNQBx9Qf3wuIvCUTrQwDyZzDuqDpC7W9a1psJg5Ds=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\npython3 -m zipvoice.bin.infer_zipvoice \\\n    --model-name zipvoice \\\n    --test-list test.tsv \\\n    --res-dir results\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 17,
    "Content": "\n- Each line of `test.tsv` is in the format of `{wav_name}\\t{prompt_transcription}\\t{prompt_wav}\\t{text}`.\n\n### 2. Dialogue speech generation\n\n#### 2.1 Inference command\n\nTo generate two-party spoken dialogues with our pre-trained ZipVoice-Dialogue or ZipVoice-Dialogue-Stereo models, use the following commands (Required models will be downloaded from HuggingFace):\n",
    "ContentSha": "bkRixLiKF8JLzfAqriyk1UZSkb5qCPhJVvI3VACgZos=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "- `test.tsv` ã®å„è¡Œã¯ `{wav_name}\\t{prompt_transcription}\\t{prompt_wav}\\t{text}` ã®å½¢å¼ã«ãªã£ã¦ã„ã¾ã™ã€‚\n\n### 2. å¯¾è©±éŸ³å£°ç”Ÿæˆ\n\n#### 2.1 æ¨è«–ã‚³ãƒãƒ³ãƒ‰\n\näº‹å‰å­¦ç¿’æ¸ˆã¿ã® ZipVoice-Dialogue ã¾ãŸã¯ ZipVoice-Dialogue-Stereo ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦äºŒè€…é–“ã®å¯¾è©±éŸ³å£°ã‚’ç”Ÿæˆã™ã‚‹ã«ã¯ã€ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’ä½¿ç”¨ã—ã¾ã™ï¼ˆå¿…è¦ãªãƒ¢ãƒ‡ãƒ«ã¯ HuggingFace ã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã™ï¼‰ï¼š\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 18,
    "Content": "```bash\npython3 -m zipvoice.bin.infer_zipvoice_dialog \\\n    --model-name \"zipvoice_dialog\" \\\n    --test-list test.tsv \\\n    --res-dir results\n```",
    "ContentSha": "SmNrjO7IvCsVTs0ROGG3evCMgCtj54DYGkGCZbRdz8k=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\npython3 -m zipvoice.bin.infer_zipvoice_dialog \\\n    --model-name \"zipvoice_dialog\" \\\n    --test-list test.tsv \\\n    --res-dir results\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 19,
    "Content": "\n- `--model-name` can be `zipvoice_dialog` or `zipvoice_dialog_stereo`,\n    which generate mono and stereo dialogues, respectively.\n\n#### 2.2 Input formats\n\nEach line of `test.tsv` is in one of the following formats:\n\n(1) **Merged prompt format** where the audios and transcriptions of two speakers prompts are merged into one prompt wav file:",
    "ContentSha": "e336Qt1qFvFmNefniyPEWJue5A1mLBZUSlD6p1+H8To=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "- `--model-name` ã¯ `zipvoice_dialog` ã¾ãŸã¯ `zipvoice_dialog_stereo` ã§ã‚ã‚Šã€\n    ãã‚Œãã‚Œãƒ¢ãƒãƒ©ãƒ«ãŠã‚ˆã³ã‚¹ãƒ†ãƒ¬ã‚ªã®å¯¾è©±ã‚’ç”Ÿæˆã—ã¾ã™ã€‚\n\n#### 2.2 å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ\n\n`test.tsv` ã®å„è¡Œã¯ã€ä»¥ä¸‹ã®ã„ãšã‚Œã‹ã®å½¢å¼ã§ã™ï¼š\n\n(1) **ãƒãƒ¼ã‚¸ã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå½¢å¼** ã§ã¯ã€2äººã®è©±è€…ã®éŸ³å£°ã¨æ–‡å­—èµ·ã“ã—ãŒ1ã¤ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆwavãƒ•ã‚¡ã‚¤ãƒ«ã«ãƒãƒ¼ã‚¸ã•ã‚Œã¦ã„ã¾ã™ï¼š\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 20,
    "Content": "```\n{wav_name}\\t{prompt_transcription}\\t{prompt_wav}\\t{text}\n```",
    "ContentSha": "F8c2S4lpByZ5Nhd693ESYvOeDT7lT7vF2Txm3q64ync=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```\n{wav_name}\\t{prompt_transcription}\\t{prompt_wav}\\t{text}\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 21,
    "Content": "\n- `wav_name` is the name of the output wav file.\n- `prompt_transcription` is the transcription of the conversational prompt wav, e.g, \"[S1] Hello. [S2] How are you?\"\n- `prompt_wav` is the path to the prompt wav.\n- `text` is the text to be synthesized, e.g. \"[S1] I'm fine. [S2] What's your name? [S1] I'm Eric. [S2] Hi Eric.\"\n\n(2) **Splitted prompt format** where the audios and transciptions of two speakers exist in separate files:\n",
    "ContentSha": "Gj5W4GhLunSOhvyVf7uwdfnNL3DFgIeOvHB01tH9I/A=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "\n- `wav_name` ã¯å‡ºåŠ›ã•ã‚Œã‚‹ wav ãƒ•ã‚¡ã‚¤ãƒ«ã®åå‰ã§ã™ã€‚\n- `prompt_transcription` ã¯ä¼šè©±ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®æ›¸ãèµ·ã“ã—ã§ã‚ã‚Šã€ä¾‹: \"[S1] ã“ã‚“ã«ã¡ã¯ã€‚[S2] ãŠå…ƒæ°—ã§ã™ã‹ï¼Ÿ\"\n- `prompt_wav` ã¯ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã¸ã®ãƒ‘ã‚¹ã§ã™ã€‚\n- `text` ã¯åˆæˆã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆã§ã‚ã‚Šã€ä¾‹: \"[S1] å…ƒæ°—ã§ã™ã€‚[S2] ãŠåå‰ã¯ï¼Ÿ[S1] ã‚¨ãƒªãƒƒã‚¯ã§ã™ã€‚[S2] ã“ã‚“ã«ã¡ã¯ã€ã‚¨ãƒªãƒƒã‚¯ã€‚\"\n\n(2) **åˆ†å‰²ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå½¢å¼** ã§ã¯ã€2äººã®è©±è€…ã®éŸ³å£°ã¨æ›¸ãèµ·ã“ã—ãŒåˆ¥ã€…ã®ãƒ•ã‚¡ã‚¤ãƒ«ã«å­˜åœ¨ã—ã¾ã™ã€‚\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 2,
        "rowsha": "6vgIR6WfUAFmULhn8LhxFttPwZEo/YwGhN1DAECwHCQ=",
        "originContent": "- `wav_name` is the name of the output wav file.",
        "translatedContent": "- `wav_name` ã¯å‡ºåŠ›ã•ã‚Œã‚‹ wav ãƒ•ã‚¡ã‚¤ãƒ«ã®åå‰ã§ã™ã€‚"
      },
      {
        "row": 3,
        "rowsha": "8kGHHZ7ObsZ8uyIBm+8FSBfPWSNEFzO6a4avI5fvxU8=",
        "originContent": "- `prompt_transcription` is the transcription of the conversational prompt wav, e.g, \"[S1] Hello. [S2] How are you?\"",
        "translatedContent": "- `prompt_transcription` ã¯ä¼šè©±ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®æ›¸ãèµ·ã“ã—ã§ã‚ã‚Šã€ä¾‹: \"[S1] ã“ã‚“ã«ã¡ã¯ã€‚[S2] ãŠå…ƒæ°—ã§ã™ã‹ï¼Ÿ\""
      },
      {
        "row": 4,
        "rowsha": "49ZQfEoq6fSJWYpjq6scIFSZl4p3azUAuAfh/UGDXoQ=",
        "originContent": "- `prompt_wav` is the path to the prompt wav.",
        "translatedContent": "- `prompt_wav` ã¯ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã¸ã®ãƒ‘ã‚¹ã§ã™ã€‚"
      },
      {
        "row": 5,
        "rowsha": "M4Z2DDajNBdyF/JosIaDZ44oyZnjNA7lzfGzEpuoako=",
        "originContent": "- `text` is the text to be synthesized, e.g. \"[S1] I'm fine. [S2] What's your name? [S1] I'm Eric. [S2] Hi Eric.\"",
        "translatedContent": "- `text` ã¯åˆæˆã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆã§ã‚ã‚Šã€ä¾‹: \"[S1] å…ƒæ°—ã§ã™ã€‚[S2] ãŠåå‰ã¯ï¼Ÿ[S1] ã‚¨ãƒªãƒƒã‚¯ã§ã™ã€‚[S2] ã“ã‚“ã«ã¡ã¯ã€ã‚¨ãƒªãƒƒã‚¯ã€‚\""
      },
      {
        "row": 6,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 7,
        "rowsha": "cDDd56+0WMPRH7CargkOcXZpCX+wGZvzj4Pws7l8G8M=",
        "originContent": "(2) **Splitted prompt format** where the audios and transciptions of two speakers exist in separate files:",
        "translatedContent": "(2) **åˆ†å‰²ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå½¢å¼** ã§ã¯ã€2äººã®è©±è€…ã®éŸ³å£°ã¨æ›¸ãèµ·ã“ã—ãŒåˆ¥ã€…ã®ãƒ•ã‚¡ã‚¤ãƒ«ã«å­˜åœ¨ã—ã¾ã™ã€‚"
      },
      {
        "row": 8,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 22,
    "Content": "```\n{wav_name}\\t{spk1_prompt_transcription}\\t{spk2_prompt_transcription}\\t{spk1_prompt_wav}\\t{spk2_prompt_wav}\\t{text}\n```",
    "ContentSha": "zPaMLy5mnnAP5WeOve+uEMlDenRN6Anuru4V4waQX9w=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```\n{wav_name}\\t{spk1_prompt_transcription}\\t{spk2_prompt_transcription}\\t{spk1_prompt_wav}\\t{spk2_prompt_wav}\\t{text}\n```",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      },
      {
        "row": 2,
        "rowsha": "hHgFoD5R+Rt1H2Gp8j7APyv0GrmZvViGd4j3PLgnJuE=",
        "originContent": "{wav_name}\\t{spk1_prompt_transcription}\\t{spk2_prompt_transcription}\\t{spk1_prompt_wav}\\t{spk2_prompt_wav}\\t{text}",
        "translatedContent": "{wav_name}\\t{spk1_prompt_transcription}\\t{spk2_prompt_transcription}\\t{spk1_prompt_wav}\\t{spk2_prompt_wav}\\t{text}"
      },
      {
        "row": 3,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      }
    ],
    "IsCodeBlock": true
  },
  {
    "Id": 23,
    "Content": "\n- `wav_name` is the name of the output wav file.\n- `spk1_prompt_transcription` is the transcription of the first speaker's prompt wav, e.g, \"Hello\"\n- `spk2_prompt_transcription` is the transcription of the second speaker's prompt wav, e.g, \"How are you?\"\n- `spk1_prompt_wav` is the path to the first speaker's prompt wav file.\n- `spk2_prompt_wav` is the path to the second speaker's prompt wav file.\n- `text` is the text to be synthesized, e.g. \"[S1] I'm fine. [S2] What's your name? [S1] I'm Eric. [S2] Hi Eric.\"\n\n### 3 Guidance for better usage:\n\n#### 3.1 Prompt length\n\nWe recommand a short prompt wav file (e.g., less than 3 seconds for single-speaker speech generation, less than 10 seconds for dialogue speech generation) for faster inference speed. A very long prompt will slow down the inference and degenerate the speech quality.\n\n#### 3.2 Speed optimization\n\nIf the inference speed is unsatisfactory, you can speed it up as follows:\n\n- **Distill model and less steps**: For the single-speaker speech generation model, we use the `zipvoice` model by default for better speech quality. If faster speed is a priority, you can switch to the `zipvoice_distill` and can reduce the `--num-steps` to as low as `4` (8 by default).\n\n- **CPU speedup with multi-threading**: When running on CPU, you can pass the `--num-thread` parameter (e.g., `--num-thread 4`) to increase the number of threads for faster speed. We use 1 thread by default.\n\n- **CPU speedup with ONNX**: When running on CPU, you can use ONNX models with `zipvoice.bin.infer_zipvoice_onnx` for faster speed (haven't supported ONNX for dialogue generation models yet). For even faster speed, you can further set `--onnx-int8 True` to use an INT8-quantized ONNX model. Note that the quantized model will result in a certain degree of speech quality degradation. **Don't use ONNX on GPU**, as it is slower than PyTorch on GPU.\n\n#### 3.3 Memory control\n\nThe given text will be splitted into chunks based on punctuation (for single-speaker speech generation) or speaker-turn symbol (for dialogue speech generation). Then, the chunked texts will be processed in batches. Therefore, the model can process arbitrarily long text with almost constant memory usage. You can control memory usage by adjusting the `--max-duration` parameter.\n\n#### 3.4 \"Raw\" evaluation\n\nBy default, we preprocess inputs (prompt wav, prompt transcription, and text) for efficient inference and better performance. If you want to evaluate the modelâ€™s \"raw\" performance using exact provided inputs (e.g., to reproduce the results in our paper), you can pass `--raw-evaluation True`.\n\n#### 3.5 Short text\n\nWhen generating speech for very short texts (e.g., one or two words), the generated speech may sometimes omit certain pronunciations. To resolve this issue, you can pass `--speed 0.3` (where 0.3 is a tunable value) to extend the duration of the generated speech.\n\n#### 3.6 Correcting mispronounced chinese polyphone characters\n\nWe use [pypinyin](https://github.com/mozillazg/python-pinyin) to convert Chinese characters to pinyin. However, it can occasionally mispronounce **polyphone characters** (å¤šéŸ³å­—).\n",
    "ContentSha": "UWr/j4Eh3KpiD5yu2h2lngpeAgJev3NJrlmr/VCcZUc=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "- `wav_name` ã¯å‡ºåŠ›ã•ã‚Œã‚‹ wav ãƒ•ã‚¡ã‚¤ãƒ«ã®åå‰ã§ã™ã€‚\n- `spk1_prompt_transcription` ã¯æœ€åˆã®è©±è€…ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ wav ã®æ›¸ãèµ·ã“ã—ä¾‹ã§ã™ã€‚ä¾‹:ã€ŒHelloã€\n- `spk2_prompt_transcription` ã¯2ç•ªç›®ã®è©±è€…ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ wav ã®æ›¸ãèµ·ã“ã—ä¾‹ã§ã™ã€‚ä¾‹:ã€ŒHow are you?ã€\n- `spk1_prompt_wav` ã¯æœ€åˆã®è©±è€…ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ wav ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã§ã™ã€‚\n- `spk2_prompt_wav` ã¯2ç•ªç›®ã®è©±è€…ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ wav ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã§ã™ã€‚\n- `text` ã¯åˆæˆã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆã§ã™ã€‚ä¾‹:ã€Œ[S1] I'm fine. [S2] What's your name? [S1] I'm Eric. [S2] Hi Eric.ã€\n\n### 3 ã‚ˆã‚Šè‰¯ã„åˆ©ç”¨ã®ãŸã‚ã®ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹:\n\n#### 3.1 ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®é•·ã•\n\næ¨è«–é€Ÿåº¦ã‚’é€Ÿãã™ã‚‹ãŸã‚ã«ã€çŸ­ã„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ wav ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆä¾‹: å˜ä¸€è©±è€…éŸ³å£°ç”Ÿæˆã®å ´åˆã¯3ç§’æœªæº€ã€å¯¾è©±éŸ³å£°ç”Ÿæˆã®å ´åˆã¯10ç§’æœªæº€ï¼‰ã‚’æ¨å¥¨ã—ã¾ã™ã€‚éå¸¸ã«é•·ã„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¯æ¨è«–ã‚’é…ãã—ã€éŸ³å£°å“è³ªã‚’ä½ä¸‹ã•ã›ã¾ã™ã€‚\n\n#### 3.2 é€Ÿåº¦æœ€é©åŒ–\n\næ¨è«–é€Ÿåº¦ãŒæº€è¶³ã§ããªã„å ´åˆã¯ã€ä»¥ä¸‹ã®æ–¹æ³•ã§é«˜é€ŸåŒ–ã§ãã¾ã™ã€‚\n\n- **è’¸ç•™ãƒ¢ãƒ‡ãƒ«ãŠã‚ˆã³ã‚¹ãƒ†ãƒƒãƒ—æ•°å‰Šæ¸›**: å˜ä¸€è©±è€…éŸ³å£°ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã§ã¯ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ `zipvoice` ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã€é«˜å“è³ªãªéŸ³å£°ç”Ÿæˆã‚’å®Ÿç¾ã—ã¦ã„ã¾ã™ã€‚é€Ÿåº¦ã‚’å„ªå…ˆã™ã‚‹å ´åˆã¯ã€`zipvoice_distill` ã«åˆ‡ã‚Šæ›¿ãˆã€`--num-steps` ã‚’æœ€ä½ `4`ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯8ï¼‰ã¾ã§æ¸›ã‚‰ã™ã“ã¨ãŒã§ãã¾ã™ã€‚\n\n- **CPUã®ãƒãƒ«ãƒã‚¹ãƒ¬ãƒƒãƒ‰ã«ã‚ˆã‚‹é«˜é€ŸåŒ–**: CPUä¸Šã§å‹•ä½œã•ã›ã‚‹å ´åˆã€`--num-thread` ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆä¾‹: `--num-thread 4`ï¼‰ã‚’æŒ‡å®šã™ã‚‹ã“ã¨ã§ã€ã‚¹ãƒ¬ãƒƒãƒ‰æ•°ã‚’å¢—ã‚„ã—é«˜é€ŸåŒ–ã§ãã¾ã™ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯1ã‚¹ãƒ¬ãƒƒãƒ‰ã§ã™ã€‚\n\n- **CPUã§ONNXã«ã‚ˆã‚‹é«˜é€ŸåŒ–**: CPUä¸Šã§å‹•ä½œã•ã›ã‚‹å ´åˆã€ONNXãƒ¢ãƒ‡ãƒ«ã‚’ `zipvoice.bin.infer_zipvoice_onnx` ã§åˆ©ç”¨ã™ã‚‹ã“ã¨ã§é«˜é€ŸåŒ–ã§ãã¾ã™ï¼ˆå¯¾è©±ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã¯ã¾ã ONNXæœªå¯¾å¿œï¼‰ã€‚ã•ã‚‰ã«é«˜é€ŸåŒ–ã—ãŸã„å ´åˆã¯ã€`--onnx-int8 True` ã‚’æŒ‡å®šã—ã¦ INT8 é‡å­åŒ– ONNX ãƒ¢ãƒ‡ãƒ«ã‚’åˆ©ç”¨ã§ãã¾ã™ã€‚ãŸã ã—ã€é‡å­åŒ–ãƒ¢ãƒ‡ãƒ«ã¯éŸ³å£°å“è³ªãŒè‹¥å¹²ä½ä¸‹ã—ã¾ã™ã€‚**GPUä¸Šã§ã¯ONNXã‚’ä½¿ç”¨ã—ãªã„ã§ãã ã•ã„**ã€‚GPUä¸Šã§ã¯PyTorchã‚ˆã‚Šé…ããªã‚Šã¾ã™ã€‚\n\n#### 3.3 ãƒ¡ãƒ¢ãƒªåˆ¶å¾¡\n\næŒ‡å®šã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã¯ã€å¥èª­ç‚¹ï¼ˆå˜ä¸€è©±è€…éŸ³å£°ç”Ÿæˆã®å ´åˆï¼‰ã‚„è©±è€…äº¤ä»£è¨˜å·ï¼ˆå¯¾è©±éŸ³å£°ç”Ÿæˆã®å ´åˆï¼‰ã§åˆ†å‰²ã•ã‚Œã¾ã™ã€‚ãã®å¾Œã€åˆ†å‰²ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆãŒãƒãƒƒãƒå‡¦ç†ã•ã‚Œã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒ¢ãƒ‡ãƒ«ã¯ã»ã¼ä¸€å®šã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã§ä»»æ„ã®é•·ã•ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’å‡¦ç†ã§ãã¾ã™ã€‚`--max-duration` ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’èª¿æ•´ã™ã‚‹ã“ã¨ã§ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’åˆ¶å¾¡ã§ãã¾ã™ã€‚\n\n#### 3.4 ã€ŒRawã€è©•ä¾¡\n\nãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã¯ã€åŠ¹ç‡çš„ãªæ¨è«–ã¨æ€§èƒ½å‘ä¸Šã®ãŸã‚ã«ï¼ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆwavã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ›¸ãèµ·ã“ã—ã€ãƒ†ã‚­ã‚¹ãƒˆï¼‰ã‚’å‰å‡¦ç†ã—ã¦ã„ã¾ã™ã€‚ãƒ¢ãƒ‡ãƒ«ã®ã€Œç”Ÿã€ã®æ€§èƒ½ã‚’å³å¯†ã«è©•ä¾¡ã—ãŸã„å ´åˆï¼ˆä¾‹: è«–æ–‡ã®çµæœã‚’å†ç¾ã™ã‚‹å ´åˆï¼‰ã¯ã€`--raw-evaluation True` ã‚’æŒ‡å®šã§ãã¾ã™ã€‚\n\n#### 3.5 çŸ­ã„ãƒ†ã‚­ã‚¹ãƒˆ\n\néå¸¸ã«çŸ­ã„ãƒ†ã‚­ã‚¹ãƒˆï¼ˆä¾‹: 1ï½2å˜èªï¼‰ã®éŸ³å£°ã‚’ç”Ÿæˆã™ã‚‹éš›ã€ç”ŸæˆéŸ³å£°ãŒä¸€éƒ¨ã®ç™ºéŸ³ã‚’çœç•¥ã—ã¦ã—ã¾ã†ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚ã“ã®å•é¡Œã‚’è§£æ±ºã™ã‚‹ã«ã¯ã€`--speed 0.3`ï¼ˆ0.3ã¯èª¿æ•´å¯èƒ½ãªå€¤ï¼‰ã‚’æŒ‡å®šã—ã¦ã€ç”ŸæˆéŸ³å£°ã®æŒç¶šæ™‚é–“ã‚’å»¶é•·ã§ãã¾ã™ã€‚\n\n#### 3.6 ä¸­å›½èªã®å¤šéŸ³å­—ã®ç™ºéŸ³ä¿®æ­£\n\nä¸­å›½èªæ–‡å­—ã‚’ãƒ”ãƒ³ã‚¤ãƒ³ã«å¤‰æ›ã™ã‚‹ãŸã‚ã« [pypinyin](https://github.com/mozillazg/python-pinyin) ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚ãŸã ã—ã€**å¤šéŸ³å­—**ï¼ˆè¤‡æ•°ã®èª­ã¿æ–¹ãŒã‚ã‚‹æ¼¢å­—ï¼‰ã®ç™ºéŸ³ã‚’èª¤ã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚\n\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "- `wav_name` ã¯å‡ºåŠ›ã•ã‚Œã‚‹ wav ãƒ•ã‚¡ã‚¤ãƒ«ã®åå‰ã§ã™ã€‚"
      },
      {
        "row": 2,
        "rowsha": "6vgIR6WfUAFmULhn8LhxFttPwZEo/YwGhN1DAECwHCQ=",
        "originContent": "- `wav_name` is the name of the output wav file.",
        "translatedContent": "- `spk1_prompt_transcription` ã¯æœ€åˆã®è©±è€…ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ wav ã®æ›¸ãèµ·ã“ã—ä¾‹ã§ã™ã€‚ä¾‹:ã€ŒHelloã€"
      },
      {
        "row": 3,
        "rowsha": "7BNq8UaBvTut4Ow/oJBAgIDTn3EwEZXK7mlUaYdFwqw=",
        "originContent": "- `spk1_prompt_transcription` is the transcription of the first speaker's prompt wav, e.g, \"Hello\"",
        "translatedContent": "- `spk2_prompt_transcription` ã¯2ç•ªç›®ã®è©±è€…ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ wav ã®æ›¸ãèµ·ã“ã—ä¾‹ã§ã™ã€‚ä¾‹:ã€ŒHow are you?ã€"
      },
      {
        "row": 4,
        "rowsha": "CES8w9dqVdkdJyOJBUVP282aaKeevVWB3d/+59TEsuk=",
        "originContent": "- `spk2_prompt_transcription` is the transcription of the second speaker's prompt wav, e.g, \"How are you?\"",
        "translatedContent": "- `spk1_prompt_wav` ã¯æœ€åˆã®è©±è€…ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ wav ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã§ã™ã€‚"
      },
      {
        "row": 5,
        "rowsha": "gXLLRf4BR7Xko2q2l4nK04KIs/L8CjvZ/UBQaP1+vck=",
        "originContent": "- `spk1_prompt_wav` is the path to the first speaker's prompt wav file.",
        "translatedContent": "- `spk2_prompt_wav` ã¯2ç•ªç›®ã®è©±è€…ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ wav ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã§ã™ã€‚"
      },
      {
        "row": 6,
        "rowsha": "oS1+heJwBnnDtA57WYtG6LbzxK79DOIeb8hwhZQwcDg=",
        "originContent": "- `spk2_prompt_wav` is the path to the second speaker's prompt wav file.",
        "translatedContent": "- `text` ã¯åˆæˆã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆã§ã™ã€‚ä¾‹:ã€Œ[S1] I'm fine. [S2] What's your name? [S1] I'm Eric. [S2] Hi Eric.ã€"
      },
      {
        "row": 7,
        "rowsha": "M4Z2DDajNBdyF/JosIaDZ44oyZnjNA7lzfGzEpuoako=",
        "originContent": "- `text` is the text to be synthesized, e.g. \"[S1] I'm fine. [S2] What's your name? [S1] I'm Eric. [S2] Hi Eric.\"",
        "translatedContent": ""
      },
      {
        "row": 8,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "### 3 ã‚ˆã‚Šè‰¯ã„åˆ©ç”¨ã®ãŸã‚ã®ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹:"
      },
      {
        "row": 9,
        "rowsha": "SdDI3h73wOzKSM3kbrbNrmpigHGer7kumuaZsQgAeao=",
        "originContent": "### 3 Guidance for better usage:",
        "translatedContent": ""
      },
      {
        "row": 10,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "#### 3.1 ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®é•·ã•"
      },
      {
        "row": 11,
        "rowsha": "cVxukE6jyFFOxlNKI5ecOTo/suYYJ8hnYyW2XA2wg+o=",
        "originContent": "#### 3.1 Prompt length",
        "translatedContent": ""
      },
      {
        "row": 12,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "æ¨è«–é€Ÿåº¦ã‚’é€Ÿãã™ã‚‹ãŸã‚ã«ã€çŸ­ã„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ wav ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆä¾‹: å˜ä¸€è©±è€…éŸ³å£°ç”Ÿæˆã®å ´åˆã¯3ç§’æœªæº€ã€å¯¾è©±éŸ³å£°ç”Ÿæˆã®å ´åˆã¯10ç§’æœªæº€ï¼‰ã‚’æ¨å¥¨ã—ã¾ã™ã€‚éå¸¸ã«é•·ã„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¯æ¨è«–ã‚’é…ãã—ã€éŸ³å£°å“è³ªã‚’ä½ä¸‹ã•ã›ã¾ã™ã€‚"
      },
      {
        "row": 13,
        "rowsha": "f19zq78QrLul7wiVSlCSojGS7qNEvtef9GFg6AA8eMY=",
        "originContent": "We recommand a short prompt wav file (e.g., less than 3 seconds for single-speaker speech generation, less than 10 seconds for dialogue speech generation) for faster inference speed. A very long prompt will slow down the inference and degenerate the speech quality.",
        "translatedContent": ""
      },
      {
        "row": 14,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "#### 3.2 é€Ÿåº¦æœ€é©åŒ–"
      },
      {
        "row": 15,
        "rowsha": "lpgNpm20ulCcTiEU/xfEVVgMZhjiQjymkdljF8dD/vw=",
        "originContent": "#### 3.2 Speed optimization",
        "translatedContent": ""
      },
      {
        "row": 16,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "æ¨è«–é€Ÿåº¦ãŒæº€è¶³ã§ããªã„å ´åˆã¯ã€ä»¥ä¸‹ã®æ–¹æ³•ã§é«˜é€ŸåŒ–ã§ãã¾ã™ã€‚"
      },
      {
        "row": 17,
        "rowsha": "iBJxMfYOjV9HvSuRT3p/EsU/iATeDCDAk/wGWLXqQI8=",
        "originContent": "If the inference speed is unsatisfactory, you can speed it up as follows:",
        "translatedContent": ""
      },
      {
        "row": 18,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "- **è’¸ç•™ãƒ¢ãƒ‡ãƒ«ãŠã‚ˆã³ã‚¹ãƒ†ãƒƒãƒ—æ•°å‰Šæ¸›**: å˜ä¸€è©±è€…éŸ³å£°ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã§ã¯ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ `zipvoice` ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã€é«˜å“è³ªãªéŸ³å£°ç”Ÿæˆã‚’å®Ÿç¾ã—ã¦ã„ã¾ã™ã€‚é€Ÿåº¦ã‚’å„ªå…ˆã™ã‚‹å ´åˆã¯ã€`zipvoice_distill` ã«åˆ‡ã‚Šæ›¿ãˆã€`--num-steps` ã‚’æœ€ä½ `4`ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯8ï¼‰ã¾ã§æ¸›ã‚‰ã™ã“ã¨ãŒã§ãã¾ã™ã€‚"
      },
      {
        "row": 19,
        "rowsha": "IzTHxzS1e5yJRhHF5d8CsjfqjIzhNX1AeGR4FTjuUCA=",
        "originContent": "- **Distill model and less steps**: For the single-speaker speech generation model, we use the `zipvoice` model by default for better speech quality. If faster speed is a priority, you can switch to the `zipvoice_distill` and can reduce the `--num-steps` to as low as `4` (8 by default).",
        "translatedContent": ""
      },
      {
        "row": 20,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "- **CPUã®ãƒãƒ«ãƒã‚¹ãƒ¬ãƒƒãƒ‰ã«ã‚ˆã‚‹é«˜é€ŸåŒ–**: CPUä¸Šã§å‹•ä½œã•ã›ã‚‹å ´åˆã€`--num-thread` ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆä¾‹: `--num-thread 4`ï¼‰ã‚’æŒ‡å®šã™ã‚‹ã“ã¨ã§ã€ã‚¹ãƒ¬ãƒƒãƒ‰æ•°ã‚’å¢—ã‚„ã—é«˜é€ŸåŒ–ã§ãã¾ã™ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯1ã‚¹ãƒ¬ãƒƒãƒ‰ã§ã™ã€‚"
      },
      {
        "row": 21,
        "rowsha": "mNiqyHjFr4rbx4boH0cix2peH8Q0+tDTOlzgZeLLDqM=",
        "originContent": "- **CPU speedup with multi-threading**: When running on CPU, you can pass the `--num-thread` parameter (e.g., `--num-thread 4`) to increase the number of threads for faster speed. We use 1 thread by default.",
        "translatedContent": ""
      },
      {
        "row": 22,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "- **CPUã§ONNXã«ã‚ˆã‚‹é«˜é€ŸåŒ–**: CPUä¸Šã§å‹•ä½œã•ã›ã‚‹å ´åˆã€ONNXãƒ¢ãƒ‡ãƒ«ã‚’ `zipvoice.bin.infer_zipvoice_onnx` ã§åˆ©ç”¨ã™ã‚‹ã“ã¨ã§é«˜é€ŸåŒ–ã§ãã¾ã™ï¼ˆå¯¾è©±ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã¯ã¾ã ONNXæœªå¯¾å¿œï¼‰ã€‚ã•ã‚‰ã«é«˜é€ŸåŒ–ã—ãŸã„å ´åˆã¯ã€`--onnx-int8 True` ã‚’æŒ‡å®šã—ã¦ INT8 é‡å­åŒ– ONNX ãƒ¢ãƒ‡ãƒ«ã‚’åˆ©ç”¨ã§ãã¾ã™ã€‚ãŸã ã—ã€é‡å­åŒ–ãƒ¢ãƒ‡ãƒ«ã¯éŸ³å£°å“è³ªãŒè‹¥å¹²ä½ä¸‹ã—ã¾ã™ã€‚**GPUä¸Šã§ã¯ONNXã‚’ä½¿ç”¨ã—ãªã„ã§ãã ã•ã„**ã€‚GPUä¸Šã§ã¯PyTorchã‚ˆã‚Šé…ããªã‚Šã¾ã™ã€‚"
      },
      {
        "row": 23,
        "rowsha": "YqtmXdPz7OfUIbrIkeeIwyKEPdEZUqn3m5EyTNd967s=",
        "originContent": "- **CPU speedup with ONNX**: When running on CPU, you can use ONNX models with `zipvoice.bin.infer_zipvoice_onnx` for faster speed (haven't supported ONNX for dialogue generation models yet). For even faster speed, you can further set `--onnx-int8 True` to use an INT8-quantized ONNX model. Note that the quantized model will result in a certain degree of speech quality degradation. **Don't use ONNX on GPU**, as it is slower than PyTorch on GPU.",
        "translatedContent": ""
      },
      {
        "row": 24,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "#### 3.3 ãƒ¡ãƒ¢ãƒªåˆ¶å¾¡"
      },
      {
        "row": 25,
        "rowsha": "fze8iMUXPcPsZgNFyWFzWSuCffZnzh7SpzLs21tQLtE=",
        "originContent": "#### 3.3 Memory control",
        "translatedContent": ""
      },
      {
        "row": 26,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "æŒ‡å®šã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã¯ã€å¥èª­ç‚¹ï¼ˆå˜ä¸€è©±è€…éŸ³å£°ç”Ÿæˆã®å ´åˆï¼‰ã‚„è©±è€…äº¤ä»£è¨˜å·ï¼ˆå¯¾è©±éŸ³å£°ç”Ÿæˆã®å ´åˆï¼‰ã§åˆ†å‰²ã•ã‚Œã¾ã™ã€‚ãã®å¾Œã€åˆ†å‰²ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆãŒãƒãƒƒãƒå‡¦ç†ã•ã‚Œã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒ¢ãƒ‡ãƒ«ã¯ã»ã¼ä¸€å®šã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã§ä»»æ„ã®é•·ã•ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’å‡¦ç†ã§ãã¾ã™ã€‚`--max-duration` ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’èª¿æ•´ã™ã‚‹ã“ã¨ã§ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’åˆ¶å¾¡ã§ãã¾ã™ã€‚"
      },
      {
        "row": 27,
        "rowsha": "uM67TExtHYq7ALHmglqtjLRqv0Xu0OOSx2aFJquZPmw=",
        "originContent": "The given text will be splitted into chunks based on punctuation (for single-speaker speech generation) or speaker-turn symbol (for dialogue speech generation). Then, the chunked texts will be processed in batches. Therefore, the model can process arbitrarily long text with almost constant memory usage. You can control memory usage by adjusting the `--max-duration` parameter.",
        "translatedContent": ""
      },
      {
        "row": 28,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "#### 3.4 ã€ŒRawã€è©•ä¾¡"
      },
      {
        "row": 29,
        "rowsha": "foa86E9JcH+Sc/k2OCmyfIKHwggsFBXhSUfHDcmJQA0=",
        "originContent": "#### 3.4 \"Raw\" evaluation",
        "translatedContent": ""
      },
      {
        "row": 30,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã¯ã€åŠ¹ç‡çš„ãªæ¨è«–ã¨æ€§èƒ½å‘ä¸Šã®ãŸã‚ã«ï¼ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆwavã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ›¸ãèµ·ã“ã—ã€ãƒ†ã‚­ã‚¹ãƒˆï¼‰ã‚’å‰å‡¦ç†ã—ã¦ã„ã¾ã™ã€‚ãƒ¢ãƒ‡ãƒ«ã®ã€Œç”Ÿã€ã®æ€§èƒ½ã‚’å³å¯†ã«è©•ä¾¡ã—ãŸã„å ´åˆï¼ˆä¾‹: è«–æ–‡ã®çµæœã‚’å†ç¾ã™ã‚‹å ´åˆï¼‰ã¯ã€`--raw-evaluation True` ã‚’æŒ‡å®šã§ãã¾ã™ã€‚"
      },
      {
        "row": 31,
        "rowsha": "+2nxKNvXmuxUQpf2Z+hw0Rxydt00FpmK4y4rlK5/8og=",
        "originContent": "By default, we preprocess inputs (prompt wav, prompt transcription, and text) for efficient inference and better performance. If you want to evaluate the modelâ€™s \"raw\" performance using exact provided inputs (e.g., to reproduce the results in our paper), you can pass `--raw-evaluation True`.",
        "translatedContent": ""
      },
      {
        "row": 32,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "#### 3.5 çŸ­ã„ãƒ†ã‚­ã‚¹ãƒˆ"
      },
      {
        "row": 33,
        "rowsha": "g658opDssPKmJCvr7Jw9N130Xud1IbMHTwMK+S89WO0=",
        "originContent": "#### 3.5 Short text",
        "translatedContent": ""
      },
      {
        "row": 34,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "éå¸¸ã«çŸ­ã„ãƒ†ã‚­ã‚¹ãƒˆï¼ˆä¾‹: 1ï½2å˜èªï¼‰ã®éŸ³å£°ã‚’ç”Ÿæˆã™ã‚‹éš›ã€ç”ŸæˆéŸ³å£°ãŒä¸€éƒ¨ã®ç™ºéŸ³ã‚’çœç•¥ã—ã¦ã—ã¾ã†ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚ã“ã®å•é¡Œã‚’è§£æ±ºã™ã‚‹ã«ã¯ã€`--speed 0.3`ï¼ˆ0.3ã¯èª¿æ•´å¯èƒ½ãªå€¤ï¼‰ã‚’æŒ‡å®šã—ã¦ã€ç”ŸæˆéŸ³å£°ã®æŒç¶šæ™‚é–“ã‚’å»¶é•·ã§ãã¾ã™ã€‚"
      },
      {
        "row": 35,
        "rowsha": "/IVkHehTtKgVQNwGOgQO/BoRh95RFHVJPH3e0W6Gixs=",
        "originContent": "When generating speech for very short texts (e.g., one or two words), the generated speech may sometimes omit certain pronunciations. To resolve this issue, you can pass `--speed 0.3` (where 0.3 is a tunable value) to extend the duration of the generated speech.",
        "translatedContent": ""
      },
      {
        "row": 36,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "#### 3.6 ä¸­å›½èªã®å¤šéŸ³å­—ã®ç™ºéŸ³ä¿®æ­£"
      },
      {
        "row": 37,
        "rowsha": "PAPz1JYDhpLF6dsiNH/BVipH4SufvLcqzLiPLACOcK4=",
        "originContent": "#### 3.6 Correcting mispronounced chinese polyphone characters",
        "translatedContent": ""
      },
      {
        "row": 38,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "ä¸­å›½èªæ–‡å­—ã‚’ãƒ”ãƒ³ã‚¤ãƒ³ã«å¤‰æ›ã™ã‚‹ãŸã‚ã« [pypinyin](https://github.com/mozillazg/python-pinyin) ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚ãŸã ã—ã€**å¤šéŸ³å­—**ï¼ˆè¤‡æ•°ã®èª­ã¿æ–¹ãŒã‚ã‚‹æ¼¢å­—ï¼‰ã®ç™ºéŸ³ã‚’èª¤ã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚"
      },
      {
        "row": 39,
        "rowsha": "hF52KZEnGKLuaot2w0AmXt52eB6Y3adYIo2qMJSMx5o=",
        "originContent": "We use [pypinyin](https://github.com/mozillazg/python-pinyin) to convert Chinese characters to pinyin. However, it can occasionally mispronounce **polyphone characters** (å¤šéŸ³å­—).",
        "translatedContent": ""
      },
      {
        "row": 40,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 24,
    "Content": "To manually correct these mispronunciations, enclose the **corrected pinyin** in angle brackets `< >` and include the **tone mark**.\n\n**Example:**\n\n- Original text: `è¿™æŠŠå‰‘é•¿ä¸‰åå…¬åˆ†`\n- Correct the pinyin of `é•¿`:  `è¿™æŠŠå‰‘<chang2>ä¸‰åå…¬åˆ†`\n\n> **Note:** If you want to manually assign multiple pinyins, enclose each pinyin with `<>`, e.g., `è¿™æŠŠ<jian4><chang2><san1>åå…¬åˆ†`\n\n#### 3.7 Remove long silences from the generated speech\n\nModel will automatically determine the positions and lengths of silences in the generated speech. It occasionally has long silence in the middle of the speech. If you don't want this, you can pass `--remove-long-sil` to remove long silences in the middle of the generated speech (edge silences will be removed by default).\n\n#### 3.8 Model downloading\n\nIf you have trouble connecting to HuggingFace when downloading the pre-trained models, try switching endpoint to the mirror site: `export HF_ENDPOINT=https://hf-mirror.com`.\n\n## Train Your Own Model\n\nSee the [egs](egs) directory for training, fine-tuning and evaluation examples.\n\n## C++ Deployment\n\nCheck [sherpa-onnx](https://github.com/k2-fsa/sherpa-onnx/pull/2487#issuecomment-3227884498) for the C++ deployment solution on CPU.\n\n## Discussion & Communication\n\nYou can directly discuss on [Github Issues](https://github.com/k2-fsa/ZipVoice/issues).\n\nYou can also scan the QR code to join our wechat group or follow our wechat official account.\n\n| Wechat Group | Wechat Official Account |\n| ------------ | ----------------------- |\n|![wechat](https://k2-fsa.org/zh-CN/assets/pic/wechat_group.jpg) |![wechat](https://k2-fsa.org/zh-CN/assets/pic/wechat_account.jpg) |\n\n## Citation\n",
    "ContentSha": "4XVNGS5kZAhMaOVNNfOEa6tjINlsa4d7Tmrgr+cYo9w=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "ã“ã‚Œã‚‰ã®èª¤ç™ºéŸ³ã‚’æ‰‹å‹•ã§ä¿®æ­£ã™ã‚‹ã«ã¯ã€**ä¿®æ­£ã—ãŸãƒ”ãƒ³ã‚¤ãƒ³**ã‚’å±±æ‹¬å¼§ `< >` ã§å›²ã¿ã€**å£°èª¿è¨˜å·**ã‚’å«ã‚ã¦ãã ã•ã„ã€‚\n\n**ä¾‹ï¼š**\n\n- å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆ: `è¿™æŠŠå‰‘é•¿ä¸‰åå…¬åˆ†`\n- `é•¿` ã®ãƒ”ãƒ³ã‚¤ãƒ³ã‚’ä¿®æ­£:  `è¿™æŠŠå‰‘<chang2>ä¸‰åå…¬åˆ†`\n\n> **æ³¨æ„:** è¤‡æ•°ã®ãƒ”ãƒ³ã‚¤ãƒ³ã‚’æ‰‹å‹•ã§å‰²ã‚Šå½“ã¦ãŸã„å ´åˆã¯ã€ãã‚Œãã‚Œã‚’ `<>` ã§å›²ã‚“ã§ãã ã•ã„ã€‚ä¾‹: `è¿™æŠŠ<jian4><chang2><san1>åå…¬åˆ†`\n\n#### 3.7 ç”ŸæˆéŸ³å£°ã‹ã‚‰é•·ã„ç„¡éŸ³éƒ¨åˆ†ã‚’é™¤å»\n\nãƒ¢ãƒ‡ãƒ«ã¯ç”Ÿæˆã•ã‚ŒãŸéŸ³å£°ã®ç„¡éŸ³éƒ¨åˆ†ã®ä½ç½®ã¨é•·ã•ã‚’è‡ªå‹•çš„ã«åˆ¤å®šã—ã¾ã™ã€‚æ™‚æŠ˜ã€éŸ³å£°ã®é€”ä¸­ã«é•·ã„ç„¡éŸ³ãŒç™ºç”Ÿã—ã¾ã™ã€‚ã“ã‚Œã‚’é¿ã‘ãŸã„å ´åˆã¯ã€`--remove-long-sil` ã‚’æŒ‡å®šã™ã‚‹ã“ã¨ã§ã€ç”ŸæˆéŸ³å£°ã®é€”ä¸­ã®é•·ã„ç„¡éŸ³ã‚’é™¤å»ã§ãã¾ã™ï¼ˆç«¯ã®ç„¡éŸ³ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§é™¤å»ã•ã‚Œã¾ã™ï¼‰ã€‚\n\n#### 3.8 ãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n\näº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ™‚ã« HuggingFace ã¸ã®æ¥ç¶šãŒã†ã¾ãã„ã‹ãªã„å ´åˆã¯ã€ãƒŸãƒ©ãƒ¼ã‚µã‚¤ãƒˆã¸ã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆåˆ‡ã‚Šæ›¿ãˆã‚’ãŠè©¦ã—ãã ã•ã„: `export HF_ENDPOINT=https://hf-mirror.com`\n\n## ç‹¬è‡ªãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’\n\nãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã€è©•ä¾¡ã®ä¾‹ã«ã¤ã„ã¦ã¯ [egs](egs) ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ã”è¦§ãã ã•ã„ã€‚\n\n## C++ ãƒ‡ãƒ—ãƒ­ã‚¤\n\nCPU ä¸Šã§ã® C++ ãƒ‡ãƒ—ãƒ­ã‚¤ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã«ã¤ã„ã¦ã¯ [sherpa-onnx](https://github.com/k2-fsa/sherpa-onnx/pull/2487#issuecomment-3227884498) ã‚’ã”ç¢ºèªãã ã•ã„ã€‚\n\n## ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³ & ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³\n\n[Github Issues](https://github.com/k2-fsa/ZipVoice/issues) ã§ç›´æ¥ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³ã§ãã¾ã™ã€‚\n\nQRã‚³ãƒ¼ãƒ‰ã‚’ã‚¹ã‚­ãƒ£ãƒ³ã—ã¦ WeChat ã‚°ãƒ«ãƒ¼ãƒ—ã«å‚åŠ ã—ãŸã‚Šã€å…¬å¼ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’ãƒ•ã‚©ãƒ­ãƒ¼ã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚\n\n| WeChat ã‚°ãƒ«ãƒ¼ãƒ— | WeChat å…¬å¼ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ |\n| ------------ | ----------------------- |\n|![wechat](https://k2-fsa.org/zh-CN/assets/pic/wechat_group.jpg) |![wechat](https://k2-fsa.org/zh-CN/assets/pic/wechat_account.jpg) |\n\n## å¼•ç”¨\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "h6Qq8AvUPYme90k2BWG054cVE6RHNflr0OwdnKA4BEE=",
        "originContent": "To manually correct these mispronunciations, enclose the **corrected pinyin** in angle brackets `< >` and include the **tone mark**.",
        "translatedContent": "ã“ã‚Œã‚‰ã®èª¤ç™ºéŸ³ã‚’æ‰‹å‹•ã§ä¿®æ­£ã™ã‚‹ã«ã¯ã€**ä¿®æ­£ã—ãŸãƒ”ãƒ³ã‚¤ãƒ³**ã‚’å±±æ‹¬å¼§ `< >` ã§å›²ã¿ã€**å£°èª¿è¨˜å·**ã‚’å«ã‚ã¦ãã ã•ã„ã€‚"
      },
      {
        "row": 2,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 3,
        "rowsha": "fP4bnCe7+qhcgDDajGMIv4obksa4WSdUp3hExEbpci0=",
        "originContent": "**Example:**",
        "translatedContent": "**ä¾‹ï¼š**"
      },
      {
        "row": 4,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 5,
        "rowsha": "ntwz9/IQqGC1ThJXQn9D83h+54cDriyg2snkkrk0KoI=",
        "originContent": "- Original text: `è¿™æŠŠå‰‘é•¿ä¸‰åå…¬åˆ†`",
        "translatedContent": "- å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆ: `è¿™æŠŠå‰‘é•¿ä¸‰åå…¬åˆ†`"
      },
      {
        "row": 6,
        "rowsha": "sfnMRvscnvdKs1fvbVePwH0RpAikXkFIi9i7HZK7D9w=",
        "originContent": "- Correct the pinyin of `é•¿`:  `è¿™æŠŠå‰‘<chang2>ä¸‰åå…¬åˆ†`",
        "translatedContent": "- `é•¿` ã®ãƒ”ãƒ³ã‚¤ãƒ³ã‚’ä¿®æ­£:  `è¿™æŠŠå‰‘<chang2>ä¸‰åå…¬åˆ†`"
      },
      {
        "row": 7,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 8,
        "rowsha": "7f45Y23fyK7AQrUO7HdTtPZZzoyRkW6WwoznauYmQew=",
        "originContent": "> **Note:** If you want to manually assign multiple pinyins, enclose each pinyin with `<>`, e.g., `è¿™æŠŠ<jian4><chang2><san1>åå…¬åˆ†`",
        "translatedContent": "> **æ³¨æ„:** è¤‡æ•°ã®ãƒ”ãƒ³ã‚¤ãƒ³ã‚’æ‰‹å‹•ã§å‰²ã‚Šå½“ã¦ãŸã„å ´åˆã¯ã€ãã‚Œãã‚Œã‚’ `<>` ã§å›²ã‚“ã§ãã ã•ã„ã€‚ä¾‹: `è¿™æŠŠ<jian4><chang2><san1>åå…¬åˆ†`"
      },
      {
        "row": 9,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 10,
        "rowsha": "FJBRXZnczlB/CZyp0UgEFMr440NrcuTPBheyQJ9lxZI=",
        "originContent": "#### 3.7 Remove long silences from the generated speech",
        "translatedContent": "#### 3.7 ç”ŸæˆéŸ³å£°ã‹ã‚‰é•·ã„ç„¡éŸ³éƒ¨åˆ†ã‚’é™¤å»"
      },
      {
        "row": 11,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 12,
        "rowsha": "9UF5wHdPZ48OWeIPfCnOHPEWzgW4Z6I0e+GaTEZ1GXI=",
        "originContent": "Model will automatically determine the positions and lengths of silences in the generated speech. It occasionally has long silence in the middle of the speech. If you don't want this, you can pass `--remove-long-sil` to remove long silences in the middle of the generated speech (edge silences will be removed by default).",
        "translatedContent": "ãƒ¢ãƒ‡ãƒ«ã¯ç”Ÿæˆã•ã‚ŒãŸéŸ³å£°ã®ç„¡éŸ³éƒ¨åˆ†ã®ä½ç½®ã¨é•·ã•ã‚’è‡ªå‹•çš„ã«åˆ¤å®šã—ã¾ã™ã€‚æ™‚æŠ˜ã€éŸ³å£°ã®é€”ä¸­ã«é•·ã„ç„¡éŸ³ãŒç™ºç”Ÿã—ã¾ã™ã€‚ã“ã‚Œã‚’é¿ã‘ãŸã„å ´åˆã¯ã€`--remove-long-sil` ã‚’æŒ‡å®šã™ã‚‹ã“ã¨ã§ã€ç”ŸæˆéŸ³å£°ã®é€”ä¸­ã®é•·ã„ç„¡éŸ³ã‚’é™¤å»ã§ãã¾ã™ï¼ˆç«¯ã®ç„¡éŸ³ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§é™¤å»ã•ã‚Œã¾ã™ï¼‰ã€‚"
      },
      {
        "row": 13,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 14,
        "rowsha": "t3GDCbkkN4PM6Y7xA/ZDAXgu4WdMFfXJ+5E/xKU9AKo=",
        "originContent": "#### 3.8 Model downloading",
        "translatedContent": "#### 3.8 ãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"
      },
      {
        "row": 15,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 16,
        "rowsha": "I2UvthbxkflPXxq8Yy6W9nJCtzb40mZPJbfmDIWQPmA=",
        "originContent": "If you have trouble connecting to HuggingFace when downloading the pre-trained models, try switching endpoint to the mirror site: `export HF_ENDPOINT=https://hf-mirror.com`.",
        "translatedContent": "äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ™‚ã« HuggingFace ã¸ã®æ¥ç¶šãŒã†ã¾ãã„ã‹ãªã„å ´åˆã¯ã€ãƒŸãƒ©ãƒ¼ã‚µã‚¤ãƒˆã¸ã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆåˆ‡ã‚Šæ›¿ãˆã‚’ãŠè©¦ã—ãã ã•ã„: `export HF_ENDPOINT=https://hf-mirror.com`"
      },
      {
        "row": 17,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 18,
        "rowsha": "SEsrfyGZhBYqHMMdMldgN+tSz6ynJT5BVJeLrTV5lHw=",
        "originContent": "## Train Your Own Model",
        "translatedContent": "## ç‹¬è‡ªãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’"
      },
      {
        "row": 19,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 20,
        "rowsha": "XaSJNyFaxQRx1Xc0mphwUGAxovKELo/54WkMCnFDLyE=",
        "originContent": "See the [egs](egs) directory for training, fine-tuning and evaluation examples.",
        "translatedContent": "ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã€è©•ä¾¡ã®ä¾‹ã«ã¤ã„ã¦ã¯ [egs](egs) ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ã”è¦§ãã ã•ã„ã€‚"
      },
      {
        "row": 21,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 22,
        "rowsha": "ESfW2TcYQsyWp1w1J57QxpfNXtuvVGrf4Amg7ahWfYI=",
        "originContent": "## C++ Deployment",
        "translatedContent": "## C++ ãƒ‡ãƒ—ãƒ­ã‚¤"
      },
      {
        "row": 23,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 24,
        "rowsha": "B8jnXFyKu8XRyVw/Pu0Xuj1ted9/BVoBfwJ1WW9LrcE=",
        "originContent": "Check [sherpa-onnx](https://github.com/k2-fsa/sherpa-onnx/pull/2487#issuecomment-3227884498) for the C++ deployment solution on CPU.",
        "translatedContent": "CPU ä¸Šã§ã® C++ ãƒ‡ãƒ—ãƒ­ã‚¤ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã«ã¤ã„ã¦ã¯ [sherpa-onnx](https://github.com/k2-fsa/sherpa-onnx/pull/2487#issuecomment-3227884498) ã‚’ã”ç¢ºèªãã ã•ã„ã€‚"
      },
      {
        "row": 25,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 26,
        "rowsha": "dEqRbPItUt3FEp1iC+8Ww+A6L57yd6oGeXfxSn5BYzs=",
        "originContent": "## Discussion & Communication",
        "translatedContent": "## ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³ & ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³"
      },
      {
        "row": 27,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 28,
        "rowsha": "wjQUwaDgSP1a6ggLgGx8TWt44Dxu5IlJytNwCAlzZKg=",
        "originContent": "You can directly discuss on [Github Issues](https://github.com/k2-fsa/ZipVoice/issues).",
        "translatedContent": "[Github Issues](https://github.com/k2-fsa/ZipVoice/issues) ã§ç›´æ¥ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³ã§ãã¾ã™ã€‚"
      },
      {
        "row": 29,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 30,
        "rowsha": "WLbsT+slCE72T0wpzVIN8KFxhP+RAw29VxFhJcBEEIo=",
        "originContent": "You can also scan the QR code to join our wechat group or follow our wechat official account.",
        "translatedContent": "QRã‚³ãƒ¼ãƒ‰ã‚’ã‚¹ã‚­ãƒ£ãƒ³ã—ã¦ WeChat ã‚°ãƒ«ãƒ¼ãƒ—ã«å‚åŠ ã—ãŸã‚Šã€å…¬å¼ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’ãƒ•ã‚©ãƒ­ãƒ¼ã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚"
      },
      {
        "row": 31,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 32,
        "rowsha": "XMNeg//PyHlCkY1XlL7caNd2vlVOKKoslrNeasADjMY=",
        "originContent": "| Wechat Group | Wechat Official Account |",
        "translatedContent": "| WeChat ã‚°ãƒ«ãƒ¼ãƒ— | WeChat å…¬å¼ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ |"
      },
      {
        "row": 33,
        "rowsha": "jdP52Pdk9hJ4eEQC1YzC887/bGdD6V25zHK1FxUbFjM=",
        "originContent": "| ------------ | ----------------------- |",
        "translatedContent": "| ------------ | ----------------------- |"
      },
      {
        "row": 34,
        "rowsha": "Q6eYrtLPPuG0fiZxZqhYquTYNk0vlyIOh+CRuwGZVk4=",
        "originContent": "|![wechat](https://k2-fsa.org/zh-CN/assets/pic/wechat_group.jpg) |![wechat](https://k2-fsa.org/zh-CN/assets/pic/wechat_account.jpg) |",
        "translatedContent": "|![wechat](https://k2-fsa.org/zh-CN/assets/pic/wechat_group.jpg) |![wechat](https://k2-fsa.org/zh-CN/assets/pic/wechat_account.jpg) |"
      },
      {
        "row": 35,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 36,
        "rowsha": "ZwTp5ajUmpHTJefyHhIKzXcG2wnB1jv8iv8cvmdcb/g=",
        "originContent": "## Citation",
        "translatedContent": "## å¼•ç”¨"
      },
      {
        "row": 37,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 25,
    "Content": "```bibtex\n@article{zhu2025zipvoice,\n      title={ZipVoice: Fast and High-Quality Zero-Shot Text-to-Speech with Flow Matching},\n      author={Zhu, Han and Kang, Wei and Yao, Zengwei and Guo, Liyong and Kuang, Fangjun and Li, Zhaoqing and Zhuang, Weiji and Lin, Long and Povey, Daniel},\n      journal={arXiv preprint arXiv:2506.13053},\n      year={2025}\n}\n\n@article{zhu2025zipvoicedialog,\n      title={ZipVoice-Dialog: Non-Autoregressive Spoken Dialogue Generation with Flow Matching},\n      author={Zhu, Han and Kang, Wei and Guo, Liyong and Yao, Zengwei and Kuang, Fangjun and Zhuang, Weiji and Li, Zhaoqing and Han, Zhifeng and Zhang, Dong and Zhang, Xin and Song, Xingchen and Lin, Long and Povey, Daniel},\n      journal={arXiv preprint arXiv:2507.09318},\n      year={2025}\n}\n```",
    "ContentSha": "4y5htVtgE8qDxiQNpfNmGGVhWO4hKo26DrPCI9N/e9E=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bibtex\n@article{zhu2025zipvoice,\n      title={ZipVoice: Fast and High-Quality Zero-Shot Text-to-Speech with Flow Matching},\n      author={Zhu, Han and Kang, Wei and Yao, Zengwei and Guo, Liyong and Kuang, Fangjun and Li, Zhaoqing and Zhuang, Weiji and Lin, Long and Povey, Daniel},\n      journal={arXiv preprint arXiv:2506.13053},\n      year={2025}\n}\n\n@article{zhu2025zipvoicedialog,\n      title={ZipVoice-Dialog: Non-Autoregressive Spoken Dialogue Generation with Flow Matching},\n      author={Zhu, Han and Kang, Wei and Guo, Liyong and Yao, Zengwei and Kuang, Fangjun and Zhuang, Weiji and Li, Zhaoqing and Han, Zhifeng and Zhang, Dong and Zhang, Xin and Song, Xingchen and Lin, Long and Povey, Daniel},\n      journal={arXiv preprint arXiv:2507.09318},\n      year={2025}\n}\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 26,
    "Content": "",
    "ContentSha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "<translate-content></translate-content>",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  }
]