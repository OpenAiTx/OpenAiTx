[
  {
    "Id": 1,
    "Content": "\n<div align=\"right\">\n  <details>\n    <summary >ğŸŒ Language</summary>\n    <div>\n      <div align=\"center\">\n        <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=en\">English</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=zh-CN\">ç®€ä½“ä¸­æ–‡</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=zh-TW\">ç¹é«”ä¸­æ–‡</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ja\">æ—¥æœ¬èª</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ko\">í•œêµ­ì–´</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=hi\">à¤¹à¤¿à¤¨à¥à¤¦à¥€</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=th\">à¹„à¸—à¸¢</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=fr\">FranÃ§ais</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=de\">Deutsch</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=es\">EspaÃ±ol</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=it\">Itapano</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ru\">Ğ ÑƒÑÑĞºĞ¸Ğ¹</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=pt\">PortuguÃªs</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=nl\">Nederlands</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=pl\">Polski</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ar\">Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=fa\">ÙØ§Ø±Ø³ÛŒ</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=tr\">TÃ¼rkÃ§e</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=vi\">Tiáº¿ng Viá»‡t</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=id\">Bahasa Indonesia</a>\n      </div>\n    </div>\n  </details>\n</div>\n\n<div align=\"center\">\n\n# ZipVoiceâš¡\n\n## Fast and High-Quality Zero-Shot Text-to-Speech with Flow Matching\n</div>\n\n## Overview\n\nZipVoice is a series of fast and high-quality zero-shot TTS models based on flow matching.\n\n### 1. Key features\n\n- Small and fast: only 123M parameters.\n\n- High-quality voice cloning: state-of-the-art performance in speaker similarity, intelligibility, and naturalness.\n\n- Multi-lingual: support Chinese and English.\n\n- Multi-mode: support both single-speaker and dialogue speech generation.\n\n### 2. Model variants\n\n<table>\n  <thead>\n    <tr>\n      <th>Model Name</th>\n      <th>Description</th>\n      <th>Paper</th>\n      <th>Demo</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>ZipVoice</td>\n      <td>The basic model supporting zero-shot single-speaker TTS in both Chinese and English.</td>\n      <td rowspan=\"2\"><a href=\"https://arxiv.org/abs/2506.13053\"><img src=\"https://img.shields.io/badge/arXiv-Paper-COLOR.svg\"></a></td>\n      <td rowspan=\"2\"><a href=\"https://zipvoice.github.io\"><img src=\"https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square\"></a></td>\n    </tr>\n    <tr>\n      <td>ZipVoice-Distill</td>\n      <td>The distilled version of ZipVoice, featuring improved speed with minimal performance degradation.</td>\n    </tr>\n    <tr>\n      <td>ZipVoice-Dialog</td>\n      <td>A dialogue generation model built on ZipVoice, capable of generating single-channel two-party spoken dialogues.</td>\n      <td rowspan=\"2\"><a href=\"https://arxiv.org/abs/2507.09318\"><img src=\"https://img.shields.io/badge/arXiv-Paper-COLOR.svg\"></a></td>\n      <td rowspan=\"2\"><a href=\"https://zipvoice-dialog.github.io\"><img src=\"https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square\"></a></td>\n    </tr>\n    <tr>\n      <td>ZipVoice-Dialog-Stereo</td>\n      <td>The stereo variant of ZipVoice-Dialog, enabling two-channel dialogue generation with each speaker assigned to a distinct channel.</td>\n    </tr>\n  </tbody>\n</table>\n\n## News\n\n**2025/07/14**: **ZipVoice-Dialog** and **ZipVoice-Dialog-Stereo**, two spoken dialogue generation models, are released. [![arXiv](https://img.shields.io/badge/arXiv-Paper-COLOR.svg)](https://arxiv.org/abs/2507.09318) [![demo page](https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square)](https://zipvoice-dialog.github.io)\n\n**2025/07/14**: **OpenDialog** dataset, a 6.8k-hour spoken dialogue dataset, is realeased. Download at [![hf](https://img.shields.io/badge/%F0%9F%A4%97%20HuggingFace-Dataset-yellow)](https://huggingface.co/datasets/k2-fsa/OpenDialog), [![ms](https://img.shields.io/badge/ModelScope-Dataset-blue?logo=data)](https://www.modelscope.cn/datasets/k2-fsa/OpenDialog). Check details at [![arXiv](https://img.shields.io/badge/arXiv-Paper-COLOR.svg)](https://arxiv.org/abs/2507.09318).\n\n**2025/06/16**: **ZipVoice** and **ZipVoice-Distill** are released. [![arXiv](https://img.shields.io/badge/arXiv-Paper-COLOR.svg)](https://arxiv.org/abs/2506.13053) [![demo page](https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square)](https://zipvoice.github.io)\n\n## Installation\n\n### 1. Clone the ZipVoice repository\n",
    "ContentSha": "2Cv2+EPeiMsBEYKPgCwphU1GsGMjk9biBRANZ8dJ9GQ=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "<div align=\"right\">\n  <details>\n    <summary >ğŸŒ è¨€èª</summary>\n    <div>\n      <div align=\"center\">\n        <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=en\">English</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=zh-CN\">ç®€ä½“ä¸­æ–‡</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=zh-TW\">ç¹é«”ä¸­æ–‡</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ja\">æ—¥æœ¬èª</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ko\">í•œêµ­ì–´</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=hi\">à¤¹à¤¿à¤¨à¥à¤¦à¥€</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=th\">à¹„à¸—à¸¢</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=fr\">FranÃ§ais</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=de\">Deutsch</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=es\">EspaÃ±ol</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=it\">Itapano</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ru\">Ğ ÑƒÑÑĞºĞ¸Ğ¹</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=pt\">PortuguÃªs</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=nl\">Nederlands</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=pl\">Polski</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ar\">Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=fa\">ÙØ§Ø±Ø³ÛŒ</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=tr\">TÃ¼rkÃ§e</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=vi\">Tiáº¿ng Viá»‡t</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=id\">Bahasa Indonesia</a>\n      </div>\n    </div>\n  </details>\n</div>\n\n<div align=\"center\">\n\n# ZipVoiceâš¡\n\n## Flow Matchingã«ã‚ˆã‚‹é«˜é€Ÿãƒ»é«˜å“è³ªã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆéŸ³å£°åˆæˆ\n</div>\n\n## æ¦‚è¦\n\nZipVoiceã¯ã€flow matchingã«åŸºã¥ãé«˜é€Ÿã‹ã¤é«˜å“è³ªãªã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆTTSï¼ˆéŸ³å£°åˆæˆï¼‰ãƒ¢ãƒ‡ãƒ«ã®ã‚·ãƒªãƒ¼ã‚ºã§ã™ã€‚\n\n### 1. ä¸»ãªç‰¹å¾´\n\n- å°å‹ã‹ã¤é«˜é€Ÿï¼šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã‚ãšã‹123Mã€‚\n\n- é«˜å“è³ªãªéŸ³å£°ã‚¯ãƒ­ãƒ¼ãƒ³ï¼šè©±è€…é¡ä¼¼æ€§ãƒ»æ˜ç­æ€§ãƒ»è‡ªç„¶ã•ã§æœ€å…ˆç«¯ã®æ€§èƒ½ã€‚\n\n- å¤šè¨€èªå¯¾å¿œï¼šä¸­å›½èªãŠã‚ˆã³è‹±èªã‚’ã‚µãƒãƒ¼ãƒˆã€‚\n\n- ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ‰ï¼šå˜ä¸€è©±è€…ãƒ»å¯¾è©±éŸ³å£°ç”Ÿæˆã®ä¸¡æ–¹ã«å¯¾å¿œã€‚\n\n### 2. ãƒ¢ãƒ‡ãƒ«ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³\n\n<table>\n  <thead>\n    <tr>\n      <th>ãƒ¢ãƒ‡ãƒ«å</th>\n      <th>èª¬æ˜</th>\n      <th>è«–æ–‡</th>\n      <th>ãƒ‡ãƒ¢</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>ZipVoice</td>\n      <td>ä¸­å›½èªãŠã‚ˆã³è‹±èªã§ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆå˜ä¸€è©±è€…TTSã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹åŸºæœ¬ãƒ¢ãƒ‡ãƒ«ã€‚</td>\n      <td rowspan=\"2\"><a href=\"https://arxiv.org/abs/2506.13053\"><img src=\"https://img.shields.io/badge/arXiv-Paper-COLOR.svg\"></a></td>\n      <td rowspan=\"2\"><a href=\"https://zipvoice.github.io\"><img src=\"https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square\"></a></td>\n    </tr>\n    <tr>\n      <td>ZipVoice-Distill</td>\n      <td>ZipVoiceã®è’¸ç•™ç‰ˆã€‚é€Ÿåº¦ãŒå‘ä¸Šã—ã€æ€§èƒ½åŠ£åŒ–ã¯æœ€å°é™ã€‚</td>\n    </tr>\n    <tr>\n      <td>ZipVoice-Dialog</td>\n      <td>ZipVoiceã‚’åŸºç›¤ã¨ã—ãŸå¯¾è©±ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã€‚å˜ä¸€ãƒãƒ£ãƒ³ãƒãƒ«ã§2è€…å¯¾è©±éŸ³å£°ã‚’ç”Ÿæˆå¯èƒ½ã€‚</td>\n      <td rowspan=\"2\"><a href=\"https://arxiv.org/abs/2507.09318\"><img src=\"https://img.shields.io/badge/arXiv-Paper-COLOR.svg\"></a></td>\n      <td rowspan=\"2\"><a href=\"https://zipvoice-dialog.github.io\"><img src=\"https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square\"></a></td>\n    </tr>\n    <tr>\n      <td>ZipVoice-Dialog-Stereo</td>\n      <td>ZipVoice-Dialogã®ã‚¹ãƒ†ãƒ¬ã‚ªç‰ˆã€‚2ãƒãƒ£ãƒ³ãƒãƒ«å‡ºåŠ›ã§ã€å„è©±è€…ã‚’åˆ¥ãƒãƒ£ãƒ³ãƒãƒ«ã«å‰²ã‚Šå½“ã¦ãŸå¯¾è©±ç”ŸæˆãŒå¯èƒ½ã€‚</td>\n    </tr>\n  </tbody>\n</table>\n\n## ãƒ‹ãƒ¥ãƒ¼ã‚¹\n\n**2025/07/14**: **ZipVoice-Dialog**ãŠã‚ˆã³**ZipVoice-Dialog-Stereo**ã®2ã¤ã®å¯¾è©±éŸ³å£°ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã‚’å…¬é–‹ã€‚[![arXiv](https://img.shields.io/badge/arXiv-Paper-COLOR.svg)](https://arxiv.org/abs/2507.09318) [![demo page](https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square)](https://zipvoice-dialog.github.io)\n\n**2025/07/14**: 6.8kæ™‚é–“ã®å¯¾è©±éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ**OpenDialog**ã‚’å…¬é–‹ã€‚ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã¯[![hf](https://img.shields.io/badge/%F0%9F%A4%97%20HuggingFace-Dataset-yellow)](https://huggingface.co/datasets/k2-fsa/OpenDialog)ã€[![ms](https://img.shields.io/badge/ModelScope-Dataset-blue?logo=data)](https://www.modelscope.cn/datasets/k2-fsa/OpenDialog)ã‹ã‚‰ã€‚è©³ç´°ã¯[![arXiv](https://img.shields.io/badge/arXiv-Paper-COLOR.svg)](https://arxiv.org/abs/2507.09318)ã€‚\n\n**2025/06/16**: **ZipVoice**ãŠã‚ˆã³**ZipVoice-Distill**ã‚’å…¬é–‹ã€‚[![arXiv](https://img.shields.io/badge/arXiv-Paper-COLOR.svg)](https://arxiv.org/abs/2506.13053) [![demo page](https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square)](https://zipvoice.github.io)\n\n## ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n\n### 1. ZipVoiceãƒªãƒã‚¸ãƒˆãƒªã®ã‚¯ãƒ­ãƒ¼ãƒ³\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 2,
    "Content": "```bash\ngit clone https://github.com/k2-fsa/ZipVoice.git\n```",
    "ContentSha": "JJo1EP7bWO0BWMfBMdp5X937bp3+DWhl7nAOm71R7lA=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\ngit clone https://github.com/k2-fsa/ZipVoice.git\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 3,
    "Content": "\n### 2. (Optional) Create a Python virtual environment\n",
    "ContentSha": "SdfmTQw39ITwBrkeETcUaJ4CPFr6cQ+HCqumZ483/iY=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "### 2. ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰Pythonã®ä»®æƒ³ç’°å¢ƒã‚’ä½œæˆã™ã‚‹\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 4,
    "Content": "```bash\npython3 -m venv zipvoice\nsource zipvoice/bin/activate\n```",
    "ContentSha": "glR0Rdvd5rjEtSF3LycYEtxGB8VzT68abW/ywL40bxw=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\npython3 -m venv zipvoice\nsource zipvoice/bin/activate\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 5,
    "Content": "\n### 3. Install the required packages\n",
    "ContentSha": "97VTTWuamYvk4THPyO5Ex48XMRIdHtV0dBXABNHe3qQ=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "### 3. å¿…è¦ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 6,
    "Content": "```bash\npip install -r requirements.txt\n```",
    "ContentSha": "TxMa9uJC0PmBOnm3/TRl4YDLNvSwCWaRNjyXpFhndHU=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\npip install -r requirements.txt\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 7,
    "Content": "\n### 4. Install k2 for training or efficient inference\n\n**k2 is necessary for training** and can speed up inference. Nevertheless, you can still use the inference mode of ZipVoice without installing k2.\n\n> **Note:**  Make sure to install the k2 version that matches your PyTorch and CUDA version. For example, if you are using pytorch 2.5.1 and CUDA 12.1, you can install k2 as follows:\n",
    "ContentSha": "it0kOYkTtKi6ipV/r+Px+BHDpullJx7ZxRNyR9UNc40=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "### 4. å­¦ç¿’ã¾ãŸã¯åŠ¹ç‡çš„ãªæ¨è«–ã®ãŸã‚ã«k2ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹\n\n**k2ã¯å­¦ç¿’ã«å¿…è¦**ã§ã‚ã‚Šã€æ¨è«–ã‚‚é«˜é€ŸåŒ–ã§ãã¾ã™ã€‚ãŸã ã—ã€k2ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ãªãã¦ã‚‚ZipVoiceã®æ¨è«–ãƒ¢ãƒ¼ãƒ‰ã¯åˆ©ç”¨å¯èƒ½ã§ã™ã€‚\n\n> **æ³¨æ„:** PyTorchã¨CUDAã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã«åˆã£ãŸk2ã‚’å¿…ãšã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„ã€‚ä¾‹ãˆã°ã€pytorch 2.5.1ã¨CUDA 12.1ã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹å ´åˆã€ä»¥ä¸‹ã®ã‚ˆã†ã«k2ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§ãã¾ã™ã€‚\n\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "### 4. å­¦ç¿’ã¾ãŸã¯åŠ¹ç‡çš„ãªæ¨è«–ã®ãŸã‚ã«k2ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹"
      },
      {
        "row": 2,
        "rowsha": "qwKY3J6LIDPN5bvfNcsfa7HzlDfSC8pp1zLydrb31ow=",
        "originContent": "### 4. Install k2 for training or efficient inference",
        "translatedContent": ""
      },
      {
        "row": 3,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "**k2ã¯å­¦ç¿’ã«å¿…è¦**ã§ã‚ã‚Šã€æ¨è«–ã‚‚é«˜é€ŸåŒ–ã§ãã¾ã™ã€‚ãŸã ã—ã€k2ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ãªãã¦ã‚‚ZipVoiceã®æ¨è«–ãƒ¢ãƒ¼ãƒ‰ã¯åˆ©ç”¨å¯èƒ½ã§ã™ã€‚"
      },
      {
        "row": 4,
        "rowsha": "PnE26/HhKrLBlqwOytzo8AXDMZltiqCBhDPquqlBz1Q=",
        "originContent": "**k2 is necessary for training** and can speed up inference. Nevertheless, you can still use the inference mode of ZipVoice without installing k2.",
        "translatedContent": ""
      },
      {
        "row": 5,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "> **æ³¨æ„:** PyTorchã¨CUDAã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã«åˆã£ãŸk2ã‚’å¿…ãšã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„ã€‚ä¾‹ãˆã°ã€pytorch 2.5.1ã¨CUDA 12.1ã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹å ´åˆã€ä»¥ä¸‹ã®ã‚ˆã†ã«k2ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§ãã¾ã™ã€‚"
      },
      {
        "row": 6,
        "rowsha": "0o8wvlsFqH2ISITN/AfAXfphj/eMJ25P5fCr9RdsQLc=",
        "originContent": "> **Note:**  Make sure to install the k2 version that matches your PyTorch and CUDA version. For example, if you are using pytorch 2.5.1 and CUDA 12.1, you can install k2 as follows:",
        "translatedContent": ""
      },
      {
        "row": 7,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 8,
    "Content": "```bash\npip install k2==1.24.4.dev20250208+cuda12.1.torch2.5.1 -f https://k2-fsa.github.io/k2/cuda.html\n```",
    "ContentSha": "ScZHk5YUmlVP9WL5ZgwHsvBVbwTCenfwKc3cJb6nrWo=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\npip install k2==1.24.4.dev20250208+cuda12.1.torch2.5.1 -f https://k2-fsa.github.io/k2/cuda.html\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 9,
    "Content": "\nPlease refer to https://k2-fsa.org/get-started/k2/ for details.\nUsers in China mainland can refer to https://k2-fsa.org/zh-CN/get-started/k2/.\n\n- To check the k2 installation:\n",
    "ContentSha": "rY1Zhq3aduWMw4XQSft+r2qBy7l8kqnHBs8cs4FGpZ4=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "è©³ç´°ã«ã¤ã„ã¦ã¯ã€https://k2-fsa.org/get-started/k2/ ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚\nä¸­å›½æœ¬åœŸã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ https://k2-fsa.org/zh-CN/get-started/k2/ ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚\n\n- k2 ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã‚’ç¢ºèªã™ã‚‹ã«ã¯:\n\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "è©³ç´°ã«ã¤ã„ã¦ã¯ã€https://k2-fsa.org/get-started/k2/ ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚"
      },
      {
        "row": 2,
        "rowsha": "fQFpgsJ7mNlMNjhxTiYJs1Z/7sz/HT0cJBgpwPNTWmI=",
        "originContent": "Please refer to https://k2-fsa.org/get-started/k2/ for details.",
        "translatedContent": "ä¸­å›½æœ¬åœŸã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ https://k2-fsa.org/zh-CN/get-started/k2/ ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚"
      },
      {
        "row": 3,
        "rowsha": "4kaasrII6Lz/xQvY7Es2gbLgiz7hFJSQblnvV1ie+Ow=",
        "originContent": "Users in China mainland can refer to https://k2-fsa.org/zh-CN/get-started/k2/.",
        "translatedContent": ""
      },
      {
        "row": 4,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "- k2 ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã‚’ç¢ºèªã™ã‚‹ã«ã¯:"
      },
      {
        "row": 5,
        "rowsha": "TK216NwSS6FDBRTvEinT+anoHssluQypjpVPkdbA8Yk=",
        "originContent": "- To check the k2 installation:",
        "translatedContent": ""
      },
      {
        "row": 6,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 10,
    "Content": "```\npython3 -c \"import k2; print(k2.__file__)\"\n```",
    "ContentSha": "ANBInWuMF6f8U3Ern+vXgJsPY6heEQDzrpLQwWst+/Y=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```\npython3 -c \"import k2; print(k2.__file__)\"\n```",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      },
      {
        "row": 2,
        "rowsha": "7yHd9AwCS2R/DPcwaogfIhkKXz9t9u3yeddGTQpSgnE=",
        "originContent": "python3 -c \"import k2; print(k2.__file__)\"",
        "translatedContent": "python3 -c \"import k2; print(k2.__file__)\""
      },
      {
        "row": 3,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      }
    ],
    "IsCodeBlock": true
  },
  {
    "Id": 11,
    "Content": "\n## Usage\n\n### 1. Single-speaker speech generation\n\nTo generate single-speaker speech with our pre-trained ZipVoice or ZipVoice-Distill models, use the following commands (Required models will be downloaded from HuggingFace):\n\n#### 1.1 Inference of a single sentence\n",
    "ContentSha": "B4h5YyIywYfr2neMM1PwmS6nY8/eY48N4jkDeP3wG+Y=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "## ä½¿ç”¨æ–¹æ³•\n\n### 1. å˜ä¸€è©±è€…éŸ³å£°ç”Ÿæˆ\n\näº‹å‰å­¦ç¿’æ¸ˆã¿ã®ZipVoiceã¾ãŸã¯ZipVoice-Distillãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦å˜ä¸€è©±è€…ã®éŸ³å£°ã‚’ç”Ÿæˆã™ã‚‹ã«ã¯ã€ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’ä½¿ç”¨ã—ã¾ã™ï¼ˆå¿…è¦ãªãƒ¢ãƒ‡ãƒ«ã¯HuggingFaceã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã™ï¼‰:\n\n#### 1.1 å˜ä¸€æ–‡ã®æ¨è«–\n\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "## ä½¿ç”¨æ–¹æ³•"
      },
      {
        "row": 2,
        "rowsha": "Y7/WGgVhslWiyqCi463Qkcp+Mn8voGpAfLsv80G4WNg=",
        "originContent": "## Usage",
        "translatedContent": ""
      },
      {
        "row": 3,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "### 1. å˜ä¸€è©±è€…éŸ³å£°ç”Ÿæˆ"
      },
      {
        "row": 4,
        "rowsha": "nYUkNidMAwY0rOZOPCjiBmmdqfUjG8WhERZjR4/0KYE=",
        "originContent": "### 1. Single-speaker speech generation",
        "translatedContent": ""
      },
      {
        "row": 5,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "äº‹å‰å­¦ç¿’æ¸ˆã¿ã®ZipVoiceã¾ãŸã¯ZipVoice-Distillãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦å˜ä¸€è©±è€…ã®éŸ³å£°ã‚’ç”Ÿæˆã™ã‚‹ã«ã¯ã€ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’ä½¿ç”¨ã—ã¾ã™ï¼ˆå¿…è¦ãªãƒ¢ãƒ‡ãƒ«ã¯HuggingFaceã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã™ï¼‰:"
      },
      {
        "row": 6,
        "rowsha": "P9InJLuCjXsRXnIqzXrzTLGFxdKU/ix347WZtNhmgWs=",
        "originContent": "To generate single-speaker speech with our pre-trained ZipVoice or ZipVoice-Distill models, use the following commands (Required models will be downloaded from HuggingFace):",
        "translatedContent": ""
      },
      {
        "row": 7,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "#### 1.1 å˜ä¸€æ–‡ã®æ¨è«–"
      },
      {
        "row": 8,
        "rowsha": "EHn70pw6zQn4Rlh44saEbf07w9vL1G089E1jcoF/mh0=",
        "originContent": "#### 1.1 Inference of a single sentence",
        "translatedContent": ""
      },
      {
        "row": 9,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 12,
    "Content": "```bash\npython3 -m zipvoice.bin.infer_zipvoice \\\n    --model-name zipvoice \\\n    --prompt-wav prompt.wav \\\n    --prompt-text \"I am the transcription of the prompt wav.\" \\\n    --text \"I am the text to be synthesized.\" \\\n    --res-wav-path result.wav\n```",
    "ContentSha": "s3L0IUGcm9ppsQesBx8AKaxAjpRhRDaqb8rE/HLRinc=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\npython3 -m zipvoice.bin.infer_zipvoice \\\n    --model-name zipvoice \\\n    --prompt-wav prompt.wav \\\n    --prompt-text \"I am the transcription of the prompt wav.\" \\\n    --text \"I am the text to be synthesized.\" \\\n    --res-wav-path result.wav\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 13,
    "Content": "\n- `--model-name` can be `zipvoice` or `zipvoice_distill`, which are models before and after distillation, respectively.\n- If `<>` or `[]` appear in the text, strings enclosed by them will be treated as special tokens. `<>` denotes Chinese pinyin and `[]` denotes other special tags.\n- Could run ONNX models on CPU faster with `zipvoice.bin.infer_zipvoice_onnx`.\n\n> **Note:** If you have trouble connecting to HuggingFace, try:\n> ```bash\n> export HF_ENDPOINT=https://hf-mirror.com\n> ```\n\n#### 1.2 Inference of a list of sentences\n",
    "ContentSha": "Vumq5D+pC+8EhfN7hqWz4R4OvZRh+cnBXbyMF5CYM9g=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "- `--model-name` ã¯ `zipvoice` ã¾ãŸã¯ `zipvoice_distill` ã§ã€å‰è€…ãŒè’¸ç•™å‰ã®ãƒ¢ãƒ‡ãƒ«ã€å¾Œè€…ãŒè’¸ç•™å¾Œã®ãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚  \n- ãƒ†ã‚­ã‚¹ãƒˆå†…ã« `<>` ã¾ãŸã¯ `[]` ãŒå‡ºç¾ã—ãŸå ´åˆã€ãã‚Œã‚‰ã§å›²ã¾ã‚ŒãŸæ–‡å­—åˆ—ã¯ç‰¹æ®Šãƒˆãƒ¼ã‚¯ãƒ³ã¨ã—ã¦æ‰±ã‚ã‚Œã¾ã™ã€‚`<>` ã¯ä¸­å›½èªã®ãƒ”ãƒ³ã‚¤ãƒ³ã‚’ç¤ºã—ã€`[]` ã¯ãã®ä»–ã®ç‰¹æ®Šã‚¿ã‚°ã‚’ç¤ºã—ã¾ã™ã€‚  \n- `zipvoice.bin.infer_zipvoice_onnx` ã‚’ä½¿ç”¨ã™ã‚‹ã¨ã€CPUä¸Šã§ONNXãƒ¢ãƒ‡ãƒ«ã‚’ã‚ˆã‚Šé«˜é€Ÿã«å®Ÿè¡Œå¯èƒ½ã§ã™ã€‚  \n\n> **æ³¨æ„ï¼š** HuggingFaceã¸ã®æ¥ç¶šã«å•é¡ŒãŒã‚ã‚‹å ´åˆã¯ã€ä»¥ä¸‹ã‚’è©¦ã—ã¦ãã ã•ã„ï¼š  \n> ```bash  \n> export HF_ENDPOINT=https://hf-mirror.com  \n> ```  \n\n#### 1.2 æ–‡ã®ãƒªã‚¹ãƒˆã®æ¨è«–  \n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 14,
    "Content": "```bash\npython3 -m zipvoice.bin.infer_zipvoice \\\n    --model-name zipvoice \\\n    --test-list test.tsv \\\n    --res-dir results\n```",
    "ContentSha": "wVKNQBx9Qf3wuIvCUTrQwDyZzDuqDpC7W9a1psJg5Ds=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\npython3 -m zipvoice.bin.infer_zipvoice \\\n    --model-name zipvoice \\\n    --test-list test.tsv \\\n    --res-dir results\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 15,
    "Content": "\n- Each line of `test.tsv` is in the format of `{wav_name}\\t{prompt_transcription}\\t{prompt_wav}\\t{text}`.\n\n### 2. Dialogue speech generation\n\n#### 2.1 Inference command\n\nTo generate two-party spoken dialogues with our pre-trained ZipVoice-Dialogue or ZipVoice-Dialogue-Stereo models, use the following commands (Required models will be downloaded from HuggingFace):\n",
    "ContentSha": "bkRixLiKF8JLzfAqriyk1UZSkb5qCPhJVvI3VACgZos=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "- `test.tsv` ã®å„è¡Œã¯ `{wav_name}\\t{prompt_transcription}\\t{prompt_wav}\\t{text}` ã®å½¢å¼ã«ãªã£ã¦ã„ã¾ã™ã€‚\n\n### 2. å¯¾è©±éŸ³å£°ç”Ÿæˆ\n\n#### 2.1 æ¨è«–ã‚³ãƒãƒ³ãƒ‰\n\näº‹å‰å­¦ç¿’æ¸ˆã¿ã® ZipVoice-Dialogue ã¾ãŸã¯ ZipVoice-Dialogue-Stereo ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦äºŒè€…é–“ã®å¯¾è©±éŸ³å£°ã‚’ç”Ÿæˆã™ã‚‹ã«ã¯ã€ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’ä½¿ç”¨ã—ã¾ã™ï¼ˆå¿…è¦ãªãƒ¢ãƒ‡ãƒ«ã¯ HuggingFace ã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã™ï¼‰ï¼š\n\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "- `test.tsv` ã®å„è¡Œã¯ `{wav_name}\\t{prompt_transcription}\\t{prompt_wav}\\t{text}` ã®å½¢å¼ã«ãªã£ã¦ã„ã¾ã™ã€‚"
      },
      {
        "row": 2,
        "rowsha": "kxdv3BjjUgNnuZKZ/3FvXTMF1EE7frXvLVqJUlAcwV0=",
        "originContent": "- Each line of `test.tsv` is in the format of `{wav_name}\\t{prompt_transcription}\\t{prompt_wav}\\t{text}`.",
        "translatedContent": ""
      },
      {
        "row": 3,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "### 2. å¯¾è©±éŸ³å£°ç”Ÿæˆ"
      },
      {
        "row": 4,
        "rowsha": "bvcLOhmoedTyLZfj2JhiFWHLaVG/oixY/37D6xadfYc=",
        "originContent": "### 2. Dialogue speech generation",
        "translatedContent": ""
      },
      {
        "row": 5,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "#### 2.1 æ¨è«–ã‚³ãƒãƒ³ãƒ‰"
      },
      {
        "row": 6,
        "rowsha": "SSCcvT3TkdgOK/lPlidT5W4KUx0rdPdikJqjEI6F7Bs=",
        "originContent": "#### 2.1 Inference command",
        "translatedContent": ""
      },
      {
        "row": 7,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "äº‹å‰å­¦ç¿’æ¸ˆã¿ã® ZipVoice-Dialogue ã¾ãŸã¯ ZipVoice-Dialogue-Stereo ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦äºŒè€…é–“ã®å¯¾è©±éŸ³å£°ã‚’ç”Ÿæˆã™ã‚‹ã«ã¯ã€ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’ä½¿ç”¨ã—ã¾ã™ï¼ˆå¿…è¦ãªãƒ¢ãƒ‡ãƒ«ã¯ HuggingFace ã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã™ï¼‰ï¼š"
      },
      {
        "row": 8,
        "rowsha": "VQWeYFjmrejLDTvLE1dLDgVDTrkGgbT9dVjCuEGdOVs=",
        "originContent": "To generate two-party spoken dialogues with our pre-trained ZipVoice-Dialogue or ZipVoice-Dialogue-Stereo models, use the following commands (Required models will be downloaded from HuggingFace):",
        "translatedContent": ""
      },
      {
        "row": 9,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 16,
    "Content": "```bash\npython3 -m zipvoice.bin.infer_zipvoice_dialog \\\n    --model-name \"zipvoice_dialog\" \\\n    --test-list test.tsv \\\n    --res-dir results\n```",
    "ContentSha": "SmNrjO7IvCsVTs0ROGG3evCMgCtj54DYGkGCZbRdz8k=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\npython3 -m zipvoice.bin.infer_zipvoice_dialog \\\n    --model-name \"zipvoice_dialog\" \\\n    --test-list test.tsv \\\n    --res-dir results\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 17,
    "Content": "\n- `--model-name` can be `zipvoice_dialog` or `zipvoice_dialog_stereo`,\n    which generate mono and stereo dialogues, respectively.\n\n#### 2.2 Input formats\n\nEach line of `test.tsv` is in one of the following formats:\n\n(1) **Merged prompt format** where the audios and transcriptions of two speakers prompts are merged into one prompt wav file:",
    "ContentSha": "e336Qt1qFvFmNefniyPEWJue5A1mLBZUSlD6p1+H8To=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "- `--model-name` ã¯ `zipvoice_dialog` ã¾ãŸã¯ `zipvoice_dialog_stereo` ã§ã‚ã‚Šã€\n    ãã‚Œãã‚Œãƒ¢ãƒãƒ©ãƒ«ãŠã‚ˆã³ã‚¹ãƒ†ãƒ¬ã‚ªã®å¯¾è©±ã‚’ç”Ÿæˆã—ã¾ã™ã€‚\n\n#### 2.2 å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ\n\n`test.tsv` ã®å„è¡Œã¯ã€ä»¥ä¸‹ã®ã„ãšã‚Œã‹ã®å½¢å¼ã§ã™ï¼š\n\n(1) **ãƒãƒ¼ã‚¸ã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå½¢å¼** ã§ã¯ã€2äººã®è©±è€…ã®éŸ³å£°ã¨æ–‡å­—èµ·ã“ã—ãŒ1ã¤ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆwavãƒ•ã‚¡ã‚¤ãƒ«ã«ãƒãƒ¼ã‚¸ã•ã‚Œã¦ã„ã¾ã™ï¼š\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 18,
    "Content": "```\n{wav_name}\\t{prompt_transcription}\\t{prompt_wav}\\t{text}\n```",
    "ContentSha": "F8c2S4lpByZ5Nhd693ESYvOeDT7lT7vF2Txm3q64ync=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```\n{wav_name}\\t{prompt_transcription}\\t{prompt_wav}\\t{text}\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 19,
    "Content": "\n- `wav_name` is the name of the output wav file.\n- `prompt_transcription` is the transcription of the conversational prompt wav, e.g, \"[S1] Hello. [S2] How are you?\"\n- `prompt_wav` is the path to the prompt wav.\n- `text` is the text to be synthesized, e.g. \"[S1] I'm fine. [S2] What's your name?\"\n\n(2) **Splitted prompt format** where the audios and transciptions of two speakers exist in separate files:\n",
    "ContentSha": "TBRCtw89LyrvgbFLTn2V5gCeA8mTF6rda1jpE44BfzQ=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "- `wav_name` ã¯å‡ºåŠ›ã•ã‚Œã‚‹wavãƒ•ã‚¡ã‚¤ãƒ«ã®åå‰ã§ã™ã€‚\n- `prompt_transcription` ã¯ä¼šè©±ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆwavã®æ–‡å­—èµ·ã“ã—ã§ã€ä¾‹: \"[S1] ã“ã‚“ã«ã¡ã¯ã€‚ [S2] ãŠå…ƒæ°—ã§ã™ã‹ï¼Ÿ\"\n- `prompt_wav` ã¯ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆwavã¸ã®ãƒ‘ã‚¹ã§ã™ã€‚\n- `text` ã¯åˆæˆã•ã‚Œã‚‹ãƒ†ã‚­ã‚¹ãƒˆã§ã€ä¾‹: \"[S1] å…ƒæ°—ã§ã™ã€‚ [S2] ã‚ãªãŸã®åå‰ã¯ï¼Ÿ\"\n\n(2) **åˆ†å‰²ã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå½¢å¼** ã§ã¯ã€2äººã®è©±è€…ã®éŸ³å£°ã¨æ–‡å­—èµ·ã“ã—ãŒåˆ¥ã€…ã®ãƒ•ã‚¡ã‚¤ãƒ«ã«å­˜åœ¨ã—ã¾ã™:\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 20,
    "Content": "```\n{wav_name}\\t{spk1_prompt_transcription}\\t{spk2_prompt_transcription}\\t{spk1_prompt_wav}\\t{spk2_prompt_wav}\\t{text}'\n```",
    "ContentSha": "8abqUXM7QkQlDEHBZFgyWhBL8Q9g5cBW+peshcgqbdE=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```\n{wav_name}\\t{spk1_prompt_transcription}\\t{spk2_prompt_transcription}\\t{spk1_prompt_wav}\\t{spk2_prompt_wav}\\t{text}'\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 21,
    "Content": "\n- `wav_name` is the name of the output wav file.\n- `spk1_prompt_transcription` is the transcription of the first speaker's prompt wav, e.g, \"Hello\"\n- `spk2_prompt_transcription` is the transcription of the second speaker's prompt wav, e.g, \"How are you?\"\n- `spk1_prompt_wav` is the path to the first speaker's prompt wav file.\n- `spk2_prompt_wav` is the path to the second speaker's prompt wav file.\n- `text` is the text to be synthesized, e.g. \"[S1] I'm fine. [S2] What's your name?\"\n\n### 3. Other features\n\n#### 3.1 Correcting mispronounced chinese polyphone characters\n\nWe use [pypinyin](https://github.com/mozillazg/python-pinyin) to convert Chinese characters to pinyin. However, it can occasionally mispronounce **polyphone characters** (å¤šéŸ³å­—).\n\nTo manually correct these mispronunciations, enclose the **corrected pinyin** in angle brackets `< >` and include the **tone mark**.\n\n**Example:**\n\n- Original text: `è¿™æŠŠå‰‘é•¿ä¸‰åå…¬åˆ†`\n- Correct the pinyin of `é•¿`:  `è¿™æŠŠå‰‘<chang2>ä¸‰åå…¬åˆ†`\n\n> **Note:** If you want to manually assign multiple pinyins, enclose each pinyin with `<>`, e.g., `è¿™æŠŠ<jian4><chang2><san1>åå…¬åˆ†`\n\n## Train Your Own Model\n\nSee the [egs](egs) directory for training, fine-tuning and evaluation examples.\n\n## Discussion & Communication\n\nYou can directly discuss on [Github Issues](https://github.com/k2-fsa/ZipVoice/issues).\n\nYou can also scan the QR code to join our wechat group or follow our wechat official account.\n\n| Wechat Group | Wechat Official Account |\n| ------------ | ----------------------- |\n|![wechat](https://k2-fsa.org/zh-CN/assets/pic/wechat_group.jpg) |![wechat](https://k2-fsa.org/zh-CN/assets/pic/wechat_account.jpg) |\n\n## Citation\n",
    "ContentSha": "/LS3gvdPdMzlHSPEpvFMbWw4k50ufMpVkq9GYClPmR8=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "- `wav_name` ã¯å‡ºåŠ›ã•ã‚Œã‚‹wavãƒ•ã‚¡ã‚¤ãƒ«ã®åå‰ã§ã™ã€‚\n- `spk1_prompt_transcription` ã¯æœ€åˆã®è©±è€…ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆwavã®æ›¸ãèµ·ã“ã—ã§ã™ã€‚ä¾‹:ã€ŒHelloã€\n- `spk2_prompt_transcription` ã¯2ç•ªç›®ã®è©±è€…ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆwavã®æ›¸ãèµ·ã“ã—ã§ã™ã€‚ä¾‹:ã€ŒHow are you?ã€\n- `spk1_prompt_wav` ã¯æœ€åˆã®è©±è€…ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆwavãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã§ã™ã€‚\n- `spk2_prompt_wav` ã¯2ç•ªç›®ã®è©±è€…ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆwavãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã§ã™ã€‚\n- `text` ã¯åˆæˆã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆã§ã™ã€‚ä¾‹:ã€Œ[S1] I'm fine. [S2] What's your name?ã€\n\n### 3. ãã®ä»–ã®æ©Ÿèƒ½\n\n#### 3.1 ä¸­å›½èªå¤šéŸ³å­—ã®èª¤ç™ºéŸ³ä¿®æ­£\n\nä¸­å›½èªã®æ–‡å­—ã‚’ãƒ”ãƒ³ã‚¤ãƒ³ã«å¤‰æ›ã™ã‚‹ãŸã‚ã« [pypinyin](https://github.com/mozillazg/python-pinyin) ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚ãŸã ã—ã€**å¤šéŸ³å­—**ï¼ˆå¤šéŸ³ç¯€æ–‡å­—ï¼‰ã‚’èª¤ã£ã¦ç™ºéŸ³ã™ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ã€‚\n\nã“ã‚Œã‚‰ã®èª¤ç™ºéŸ³ã‚’æ‰‹å‹•ã§ä¿®æ­£ã™ã‚‹ã«ã¯ã€**ä¿®æ­£ã—ãŸãƒ”ãƒ³ã‚¤ãƒ³**ã‚’å±±æ‹¬å¼§ `< >` ã§å›²ã¿ã€**å£°èª¿è¨˜å·**ã‚‚å«ã‚ã¾ã™ã€‚\n\n**ä¾‹:**\n\n- å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆ: `è¿™æŠŠå‰‘é•¿ä¸‰åå…¬åˆ†`\n- `é•¿` ã®ãƒ”ãƒ³ã‚¤ãƒ³ã‚’ä¿®æ­£:  `è¿™æŠŠå‰‘<chang2>ä¸‰åå…¬åˆ†`\n\n> **æ³¨æ„:** è¤‡æ•°ã®ãƒ”ãƒ³ã‚¤ãƒ³ã‚’æ‰‹å‹•ã§å‰²ã‚Šå½“ã¦ãŸã„å ´åˆã¯ã€ãã‚Œãã‚Œã®ãƒ”ãƒ³ã‚¤ãƒ³ã‚’ `<>` ã§å›²ã¿ã¾ã™ã€‚ä¾‹: `è¿™æŠŠ<jian4><chang2><san1>åå…¬åˆ†`\n\n## ç‹¬è‡ªãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’\n\nãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã€ãŠã‚ˆã³è©•ä¾¡ã®ä¾‹ã«ã¤ã„ã¦ã¯ [egs](egs) ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚\n\n## è­°è«–ã¨ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³\n\n[Github Issues](https://github.com/k2-fsa/ZipVoice/issues) ã§ç›´æ¥è­°è«–ã§ãã¾ã™ã€‚\n\nã¾ãŸã€QRã‚³ãƒ¼ãƒ‰ã‚’ã‚¹ã‚­ãƒ£ãƒ³ã—ã¦WeChatã‚°ãƒ«ãƒ¼ãƒ—ã«å‚åŠ ã—ãŸã‚Šã€WeChatå…¬å¼ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’ãƒ•ã‚©ãƒ­ãƒ¼ã—ãŸã‚Šã§ãã¾ã™ã€‚\n\n| Wechatã‚°ãƒ«ãƒ¼ãƒ— | Wechatå…¬å¼ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ |\n| ------------ | ----------------------- |\n|![wechat](https://k2-fsa.org/zh-CN/assets/pic/wechat_group.jpg) |![wechat](https://k2-fsa.org/zh-CN/assets/pic/wechat_account.jpg) |\n\n## å¼•ç”¨\n\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "- `wav_name` ã¯å‡ºåŠ›ã•ã‚Œã‚‹wavãƒ•ã‚¡ã‚¤ãƒ«ã®åå‰ã§ã™ã€‚"
      },
      {
        "row": 2,
        "rowsha": "6vgIR6WfUAFmULhn8LhxFttPwZEo/YwGhN1DAECwHCQ=",
        "originContent": "- `wav_name` is the name of the output wav file.",
        "translatedContent": "- `spk1_prompt_transcription` ã¯æœ€åˆã®è©±è€…ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆwavã®æ›¸ãèµ·ã“ã—ã§ã™ã€‚ä¾‹:ã€ŒHelloã€"
      },
      {
        "row": 3,
        "rowsha": "7BNq8UaBvTut4Ow/oJBAgIDTn3EwEZXK7mlUaYdFwqw=",
        "originContent": "- `spk1_prompt_transcription` is the transcription of the first speaker's prompt wav, e.g, \"Hello\"",
        "translatedContent": "- `spk2_prompt_transcription` ã¯2ç•ªç›®ã®è©±è€…ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆwavã®æ›¸ãèµ·ã“ã—ã§ã™ã€‚ä¾‹:ã€ŒHow are you?ã€"
      },
      {
        "row": 4,
        "rowsha": "CES8w9dqVdkdJyOJBUVP282aaKeevVWB3d/+59TEsuk=",
        "originContent": "- `spk2_prompt_transcription` is the transcription of the second speaker's prompt wav, e.g, \"How are you?\"",
        "translatedContent": "- `spk1_prompt_wav` ã¯æœ€åˆã®è©±è€…ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆwavãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã§ã™ã€‚"
      },
      {
        "row": 5,
        "rowsha": "gXLLRf4BR7Xko2q2l4nK04KIs/L8CjvZ/UBQaP1+vck=",
        "originContent": "- `spk1_prompt_wav` is the path to the first speaker's prompt wav file.",
        "translatedContent": "- `spk2_prompt_wav` ã¯2ç•ªç›®ã®è©±è€…ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆwavãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã§ã™ã€‚"
      },
      {
        "row": 6,
        "rowsha": "oS1+heJwBnnDtA57WYtG6LbzxK79DOIeb8hwhZQwcDg=",
        "originContent": "- `spk2_prompt_wav` is the path to the second speaker's prompt wav file.",
        "translatedContent": "- `text` ã¯åˆæˆã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆã§ã™ã€‚ä¾‹:ã€Œ[S1] I'm fine. [S2] What's your name?ã€"
      },
      {
        "row": 7,
        "rowsha": "bllORZskiCR9fU5bX9yk0xZyqribcNFIl5OGst+H9hs=",
        "originContent": "- `text` is the text to be synthesized, e.g. \"[S1] I'm fine. [S2] What's your name?\"",
        "translatedContent": ""
      },
      {
        "row": 8,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "### 3. ãã®ä»–ã®æ©Ÿèƒ½"
      },
      {
        "row": 9,
        "rowsha": "+vzcq8TvUX4BjMVko7bsMy3OssEdCDf3naG5aF1NHpU=",
        "originContent": "### 3. Other features",
        "translatedContent": ""
      },
      {
        "row": 10,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "#### 3.1 ä¸­å›½èªå¤šéŸ³å­—ã®èª¤ç™ºéŸ³ä¿®æ­£"
      },
      {
        "row": 11,
        "rowsha": "QGugzKoPQgvq7BRzlyCe2HPMZG0+T/EtMivjaWTAk7M=",
        "originContent": "#### 3.1 Correcting mispronounced chinese polyphone characters",
        "translatedContent": ""
      },
      {
        "row": 12,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "ä¸­å›½èªã®æ–‡å­—ã‚’ãƒ”ãƒ³ã‚¤ãƒ³ã«å¤‰æ›ã™ã‚‹ãŸã‚ã« [pypinyin](https://github.com/mozillazg/python-pinyin) ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚ãŸã ã—ã€**å¤šéŸ³å­—**ï¼ˆå¤šéŸ³ç¯€æ–‡å­—ï¼‰ã‚’èª¤ã£ã¦ç™ºéŸ³ã™ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ã€‚"
      },
      {
        "row": 13,
        "rowsha": "hF52KZEnGKLuaot2w0AmXt52eB6Y3adYIo2qMJSMx5o=",
        "originContent": "We use [pypinyin](https://github.com/mozillazg/python-pinyin) to convert Chinese characters to pinyin. However, it can occasionally mispronounce **polyphone characters** (å¤šéŸ³å­—).",
        "translatedContent": ""
      },
      {
        "row": 14,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "ã“ã‚Œã‚‰ã®èª¤ç™ºéŸ³ã‚’æ‰‹å‹•ã§ä¿®æ­£ã™ã‚‹ã«ã¯ã€**ä¿®æ­£ã—ãŸãƒ”ãƒ³ã‚¤ãƒ³**ã‚’å±±æ‹¬å¼§ `< >` ã§å›²ã¿ã€**å£°èª¿è¨˜å·**ã‚‚å«ã‚ã¾ã™ã€‚"
      },
      {
        "row": 15,
        "rowsha": "h6Qq8AvUPYme90k2BWG054cVE6RHNflr0OwdnKA4BEE=",
        "originContent": "To manually correct these mispronunciations, enclose the **corrected pinyin** in angle brackets `< >` and include the **tone mark**.",
        "translatedContent": ""
      },
      {
        "row": 16,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "**ä¾‹:**"
      },
      {
        "row": 17,
        "rowsha": "fP4bnCe7+qhcgDDajGMIv4obksa4WSdUp3hExEbpci0=",
        "originContent": "**Example:**",
        "translatedContent": ""
      },
      {
        "row": 18,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "- å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆ: `è¿™æŠŠå‰‘é•¿ä¸‰åå…¬åˆ†`"
      },
      {
        "row": 19,
        "rowsha": "ntwz9/IQqGC1ThJXQn9D83h+54cDriyg2snkkrk0KoI=",
        "originContent": "- Original text: `è¿™æŠŠå‰‘é•¿ä¸‰åå…¬åˆ†`",
        "translatedContent": "- `é•¿` ã®ãƒ”ãƒ³ã‚¤ãƒ³ã‚’ä¿®æ­£:  `è¿™æŠŠå‰‘<chang2>ä¸‰åå…¬åˆ†`"
      },
      {
        "row": 20,
        "rowsha": "sfnMRvscnvdKs1fvbVePwH0RpAikXkFIi9i7HZK7D9w=",
        "originContent": "- Correct the pinyin of `é•¿`:  `è¿™æŠŠå‰‘<chang2>ä¸‰åå…¬åˆ†`",
        "translatedContent": ""
      },
      {
        "row": 21,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "> **æ³¨æ„:** è¤‡æ•°ã®ãƒ”ãƒ³ã‚¤ãƒ³ã‚’æ‰‹å‹•ã§å‰²ã‚Šå½“ã¦ãŸã„å ´åˆã¯ã€ãã‚Œãã‚Œã®ãƒ”ãƒ³ã‚¤ãƒ³ã‚’ `<>` ã§å›²ã¿ã¾ã™ã€‚ä¾‹: `è¿™æŠŠ<jian4><chang2><san1>åå…¬åˆ†`"
      },
      {
        "row": 22,
        "rowsha": "7f45Y23fyK7AQrUO7HdTtPZZzoyRkW6WwoznauYmQew=",
        "originContent": "> **Note:** If you want to manually assign multiple pinyins, enclose each pinyin with `<>`, e.g., `è¿™æŠŠ<jian4><chang2><san1>åå…¬åˆ†`",
        "translatedContent": ""
      },
      {
        "row": 23,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "## ç‹¬è‡ªãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’"
      },
      {
        "row": 24,
        "rowsha": "SEsrfyGZhBYqHMMdMldgN+tSz6ynJT5BVJeLrTV5lHw=",
        "originContent": "## Train Your Own Model",
        "translatedContent": ""
      },
      {
        "row": 25,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã€ãŠã‚ˆã³è©•ä¾¡ã®ä¾‹ã«ã¤ã„ã¦ã¯ [egs](egs) ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚"
      },
      {
        "row": 26,
        "rowsha": "XaSJNyFaxQRx1Xc0mphwUGAxovKELo/54WkMCnFDLyE=",
        "originContent": "See the [egs](egs) directory for training, fine-tuning and evaluation examples.",
        "translatedContent": ""
      },
      {
        "row": 27,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "## è­°è«–ã¨ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³"
      },
      {
        "row": 28,
        "rowsha": "dEqRbPItUt3FEp1iC+8Ww+A6L57yd6oGeXfxSn5BYzs=",
        "originContent": "## Discussion & Communication",
        "translatedContent": ""
      },
      {
        "row": 29,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "[Github Issues](https://github.com/k2-fsa/ZipVoice/issues) ã§ç›´æ¥è­°è«–ã§ãã¾ã™ã€‚"
      },
      {
        "row": 30,
        "rowsha": "wjQUwaDgSP1a6ggLgGx8TWt44Dxu5IlJytNwCAlzZKg=",
        "originContent": "You can directly discuss on [Github Issues](https://github.com/k2-fsa/ZipVoice/issues).",
        "translatedContent": ""
      },
      {
        "row": 31,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "ã¾ãŸã€QRã‚³ãƒ¼ãƒ‰ã‚’ã‚¹ã‚­ãƒ£ãƒ³ã—ã¦WeChatã‚°ãƒ«ãƒ¼ãƒ—ã«å‚åŠ ã—ãŸã‚Šã€WeChatå…¬å¼ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’ãƒ•ã‚©ãƒ­ãƒ¼ã—ãŸã‚Šã§ãã¾ã™ã€‚"
      },
      {
        "row": 32,
        "rowsha": "WLbsT+slCE72T0wpzVIN8KFxhP+RAw29VxFhJcBEEIo=",
        "originContent": "You can also scan the QR code to join our wechat group or follow our wechat official account.",
        "translatedContent": ""
      },
      {
        "row": 33,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "| Wechatã‚°ãƒ«ãƒ¼ãƒ— | Wechatå…¬å¼ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ |"
      },
      {
        "row": 34,
        "rowsha": "XMNeg//PyHlCkY1XlL7caNd2vlVOKKoslrNeasADjMY=",
        "originContent": "| Wechat Group | Wechat Official Account |",
        "translatedContent": "| ------------ | ----------------------- |"
      },
      {
        "row": 35,
        "rowsha": "jdP52Pdk9hJ4eEQC1YzC887/bGdD6V25zHK1FxUbFjM=",
        "originContent": "| ------------ | ----------------------- |",
        "translatedContent": "|![wechat](https://k2-fsa.org/zh-CN/assets/pic/wechat_group.jpg) |![wechat](https://k2-fsa.org/zh-CN/assets/pic/wechat_account.jpg) |"
      },
      {
        "row": 36,
        "rowsha": "Q6eYrtLPPuG0fiZxZqhYquTYNk0vlyIOh+CRuwGZVk4=",
        "originContent": "|![wechat](https://k2-fsa.org/zh-CN/assets/pic/wechat_group.jpg) |![wechat](https://k2-fsa.org/zh-CN/assets/pic/wechat_account.jpg) |",
        "translatedContent": ""
      },
      {
        "row": 37,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "## å¼•ç”¨"
      },
      {
        "row": 38,
        "rowsha": "ZwTp5ajUmpHTJefyHhIKzXcG2wnB1jv8iv8cvmdcb/g=",
        "originContent": "## Citation",
        "translatedContent": ""
      },
      {
        "row": 39,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 22,
    "Content": "```bibtex\n@article{zhu2025zipvoice,\n      title={ZipVoice: Fast and High-Quality Zero-Shot Text-to-Speech with Flow Matching},\n      author={Zhu, Han and Kang, Wei and Yao, Zengwei and Guo, Liyong and Kuang, Fangjun and Li, Zhaoqing and Zhuang, Weiji and Lin, Long and Povey, Daniel},\n      journal={arXiv preprint arXiv:2506.13053},\n      year={2025}\n}\n\n@article{zhu2025zipvoicedialog,\n      title={ZipVoice-Dialog: Non-Autoregressive Spoken Dialogue Generation with Flow Matching},\n      author={Zhu, Han and Kang, Wei and Guo, Liyong and Yao, Zengwei and Kuang, Fangjun and Zhuang, Weiji and Li, Zhaoqing and Han, Zhifeng and Zhang, Dong and Zhang, Xin and Song, Xingchen and Lin, Long and Povey, Daniel},\n      journal={arXiv preprint arXiv:2507.09318},\n      year={2025}\n}\n```",
    "ContentSha": "4y5htVtgE8qDxiQNpfNmGGVhWO4hKo26DrPCI9N/e9E=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bibtex\n@article{zhu2025zipvoice,\n      title={ZipVoice: Fast and High-Quality Zero-Shot Text-to-Speech with Flow Matching},\n      author={Zhu, Han and Kang, Wei and Yao, Zengwei and Guo, Liyong and Kuang, Fangjun and Li, Zhaoqing and Zhuang, Weiji and Lin, Long and Povey, Daniel},\n      journal={arXiv preprint arXiv:2506.13053},\n      year={2025}\n}\n\n@article{zhu2025zipvoicedialog,\n      title={ZipVoice-Dialog: Non-Autoregressive Spoken Dialogue Generation with Flow Matching},\n      author={Zhu, Han and Kang, Wei and Guo, Liyong and Yao, Zengwei and Kuang, Fangjun and Zhuang, Weiji and Li, Zhaoqing and Han, Zhifeng and Zhang, Dong and Zhang, Xin and Song, Xingchen and Lin, Long and Povey, Daniel},\n      journal={arXiv preprint arXiv:2507.09318},\n      year={2025}\n}\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 23,
    "Content": "",
    "ContentSha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "<translate-content></translate-content>",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  }
]