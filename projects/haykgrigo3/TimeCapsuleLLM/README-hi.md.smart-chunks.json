[
  {
    "Id": 1,
    "Content": "\n<div align=\"right\">\n  <details>\n    <summary >ЁЯМР Language</summary>\n    <div>\n      <div align=\"center\">\n        <a href=\"https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=en\">English</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=zh-CN\">чоАф╜Уф╕нцЦЗ</a>\n        | <a href=\"#\" title=\"Coming soon\">ч╣БщлФф╕нцЦЗ (coming soon)</a> |\n        | <a href=\"https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=ja\">цЧецЬмшкЮ</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=ko\">эХЬъ╡ньЦ┤</a>\n        | <a href=\"#\" title=\"Coming soon\">рд╣рд┐рдиреНрджреА (coming soon)</a> |\n        | <a href=\"#\" title=\"Coming soon\">р╣Др╕Чр╕в (coming soon)</a> |\n        | <a href=\"#\" title=\"Coming soon\">Fran├зais (coming soon)</a>\n        | <a href=\"#\" title=\"Coming soon\">Deutsch (coming soon)</a>\n        | <a href=\"#\" title=\"Coming soon\">Espa├▒ol (coming soon)</a>\n        | <a href=\"#\" title=\"Coming soon\">Italiano (coming soon)</a>\n        | <a href=\"#\" title=\"Coming soon\">╨а╤Г╤Б╤Б╨║╨╕╨╣ (coming soon)</a>\n        | <a href=\"#\" title=\"Coming soon\">Portugu├кs (coming soon)</a>\n        | <a href=\"#\" title=\"Coming soon\">Nederlands (coming soon)</a>\n        | <a href=\"#\" title=\"Coming soon\">Polski (coming soon)</a>\n        | <a href=\"#\" title=\"Coming soon\">╪з┘Д╪╣╪▒╪и┘К╪й (coming soon)</a>\n        | <a href=\"#\" title=\"Coming soon\">┘Б╪з╪▒╪│█М (coming soon)</a>\n        | <a href=\"#\" title=\"Coming soon\">T├╝rk├зe (coming soon)</a>\n        | <a href=\"#\" title=\"Coming soon\">Tiс║┐ng Viс╗Зt (coming soon)</a>\n        | <a href=\"#\" title=\"Coming soon\">Bahasa Indonesia (coming soon)</a>\n\n      </div>\n    </div>\n  </details>\n</div>\n\n# TimeCapsule LLM\nAn LLM trained only on data from certain time periods to reduce modern bias.\n\nImagine if an AI model didnt just pretend to be historical but actually was.\n\nBuilt on [nanoGPT by Andrej Karpathy](https://github.com/karpathy/nanoGPT) Core training scripts and model architecture are his work. \n\n# Project Goals \n\nTimeCapsule LLM is an expirimental project that will only be trained on texts written during certain time periods. The goal is to simulate the worldview and language of specific historical eras.\n\n# Why fine tuning isn't enough \n\nIf you just fine tune a pre-trained model, your LLM is still gonna know modern concepts. Of course achieving zero modern bias is difficult but I want to get as close as possible to this. Getting no modern bias requires training a model from scratch.\n\n# Expected outcomes \n\nHopefully when finished, this model will not know modern concepts and will not be able to reason beyond what it's been trained on. It shouldnt recognize modern concepts/vocab and I hope it doesn't hallucinate modern knowledge.\n\n# Progress Updates\n\n## July 9th, 2025\n\nI've set my time period for 1800-1850 and region: London \n\nI've gathered a list of texts, books, documents \n\nSo far I've gotten 50 as txt files and will begin training NanoGPT soon \n\nWill update this as long as progress is made\n\n## July 13th, 2025\n\nTrained nanoGPT with 187MB of historial text data. \n\n## July 15th, 2025\n\nI started downloading texts for the second training run. I'm getting everything from Internet Archive and I've expanded the time period to 1800-1875. To get a diverse range of texts, you can use subject and search filters for publication location, time period and subjects on Internet Archive. \n\n![Search Filters](https://raw.githubusercontent.com/haykgrigo3/TimeCapsuleLLM/main/searchfilter.jpg)\n\n## July 16th, 2025\n\nI downloaded around 500 txt files from Internet Archive and after cleaning them (just deleting whitespaces, Gutenberg headers, etc) I have around 500MB of data. It's a tiny dataset but last time I trained off of 187MB so there should be at least some kind of noticable difference in the output after I train the second model. I'm hoping this model can at least produce more coherent sentences that kind of make sense. It's not a guarantee of course since this is still a tiny tiny dataset, but it's more than what I used last time. \n\nThis should be doable on my own hardware, it's good too because I can hopefully see some kind of improvements before I jump to a bigger dataset which would require me to rent a GPU. But don't worry I still plan on renting a GPU soon, but before I do that I wanna make sure my dataset is as curated and clean as possible. One of the issues I have is cleaning, a lot of these txt files have gibberish mixed in. The scripts I've used for cleaning do work but they're not 100% effective. \n\nI will train this dataset today and it should take around 4-5 hours. Once it's done and I test it, I will give updates. Thank you again to everyone whos checking out my project, I've even had some people even giving me links to OCR resources so Thank you! I hope more people try this out and expirement with they're own datasets. \n\n\n### Training Update \n\nI started training on a 435MB (108 M tokens) corpus, it's going pretty smooth right now. Train loss dropped from 10.9 to 4.9 in the first 2800 iterations. I expect it'll take around 8 or 9 hours to complete. I'll post another update once it's done.\n\n## July 17th, 2025\n\nThe training is done for the second model, it took my 4060 around 8 hours and 40 minutes (3,900 iters/hr) for 33,000 iters (5 epochs). Final train loss was 3.73. The outputs were suprisingly good it genuinely generates coherent 19th century style sentences now. \n\n## July 28th, 2025 \n\nI've gone ahead and uploaded v0.5 to Hugging Face, [Check it out](https://huggingface.co/haykgrigorian/TimeCapsuleLLM) if youd like. You can now download my repo and run it locally. Unfortunately nanoGPT doesn't work natively with HuggingFace, so you'll have to download and run the model locally. \n\nAlso I will begin curating data for my next training run, I believe I'll need maybe 5-10x more data to achieve reasoning capabilities. \n\n## August 2nd, 2025\n\nI'm going to start work on Version 1 soon. I will need to transition from nanoGPT's architecture to soemthing more modern. I have several open-source LLM archictectures in mind, including: OpenLLaMA v3, Phi-2 and Qwen 1.5B. And to support the jump to V1, I'll need to carefully curate a much bigger and diverse dataset. I'll need at least 5GB of clean training data.\n",
    "ContentSha": "Z4lrWCPpmldV96aKhnoN6jgtj/ymSgREkn/oYev+490=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "<div align=\"right\">\n  <details>\n    <summary >ЁЯМР рднрд╛рд╖рд╛</summary>\n    <div>\n      <div align=\"center\">\n        <a href=\"https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=en\">рдЕрдВрдЧреНрд░реЗрдЬрд╝реА</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=zh-CN\">чоАф╜Уф╕нцЦЗ</a>\n        | <a href=\"#\" title=\"Coming soon\">ч╣БщлФф╕нцЦЗ (рдЬрд▓реНрдж рдЖ рд░рд╣рд╛ рд╣реИ)</a> |\n        | <a href=\"https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=ja\">цЧецЬмшкЮ</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=ko\">эХЬъ╡ньЦ┤</a>\n        | <a href=\"#\" title=\"Coming soon\">рд╣рд┐рдиреНрджреА (рдЬрд▓реНрдж рдЖ рд░рд╣рд╛ рд╣реИ)</a> |\n        | <a href=\"#\" title=\"Coming soon\">р╣Др╕Чр╕в (рдЬрд▓реНрдж рдЖ рд░рд╣рд╛ рд╣реИ)</a> |\n        | <a href=\"#\" title=\"Coming soon\">Fran├зais (рдЬрд▓реНрдж рдЖ рд░рд╣рд╛ рд╣реИ)</a>\n        | <a href=\"#\" title=\"Coming soon\">Deutsch (рдЬрд▓реНрдж рдЖ рд░рд╣рд╛ рд╣реИ)</a>\n        | <a href=\"#\" title=\"Coming soon\">Espa├▒ol (рдЬрд▓реНрдж рдЖ рд░рд╣рд╛ рд╣реИ)</a>\n        | <a href=\"#\" title=\"Coming soon\">Italiano (рдЬрд▓реНрдж рдЖ рд░рд╣рд╛ рд╣реИ)</a>\n        | <a href=\"#\" title=\"Coming soon\">╨а╤Г╤Б╤Б╨║╨╕╨╣ (рдЬрд▓реНрдж рдЖ рд░рд╣рд╛ рд╣реИ)</a>\n        | <a href=\"#\" title=\"Coming soon\">Portugu├кs (рдЬрд▓реНрдж рдЖ рд░рд╣рд╛ рд╣реИ)</a>\n        | <a href=\"#\" title=\"Coming soon\">Nederlands (рдЬрд▓реНрдж рдЖ рд░рд╣рд╛ рд╣реИ)</a>\n        | <a href=\"#\" title=\"Coming soon\">Polski (рдЬрд▓реНрдж рдЖ рд░рд╣рд╛ рд╣реИ)</a>\n        | <a href=\"#\" title=\"Coming soon\">╪з┘Д╪╣╪▒╪и┘К╪й (рдЬрд▓реНрдж рдЖ рд░рд╣рд╛ рд╣реИ)</a>\n        | <a href=\"#\" title=\"Coming soon\">┘Б╪з╪▒╪│█М (рдЬрд▓реНрдж рдЖ рд░рд╣рд╛ рд╣реИ)</a>\n        | <a href=\"#\" title=\"Coming soon\">T├╝rk├зe (рдЬрд▓реНрдж рдЖ рд░рд╣рд╛ рд╣реИ)</a>\n        | <a href=\"#\" title=\"Coming soon\">Tiс║┐ng Viс╗Зt (рдЬрд▓реНрдж рдЖ рд░рд╣рд╛ рд╣реИ)</a>\n        | <a href=\"#\" title=\"Coming soon\">Bahasa Indonesia (рдЬрд▓реНрдж рдЖ рд░рд╣рд╛ рд╣реИ)</a>\n\n      </div>\n    </div>\n  </details>\n</div>\n\n# рдЯрд╛рдЗрдордХреИрдкреНрд╕реВрд▓ LLM\nрдПрдХ LLM рдЬрд┐рд╕реЗ рдХреЗрд╡рд▓ рдХреБрдЫ рд╡рд┐рд╢реЗрд╖ рд╕рдордп рдЕрд╡рдзрд┐рдпреЛрдВ рдХреЗ рдбреЗрдЯрд╛ рдкрд░ рдкреНрд░рд╢рд┐рдХреНрд╖рд┐рдд рдХрд┐рдпрд╛ рдЧрдпрд╛ рд╣реИ рддрд╛рдХрд┐ рдЖрдзреБрдирд┐рдХ рдкрдХреНрд╖рдкрд╛рдд рдХрдо рд╣реЛ рд╕рдХреЗред\n\nрдХрд▓реНрдкрдирд╛ рдХреАрдЬрд┐рдП рдпрджрд┐ рдПрдХ рдПрдЖрдИ рдореЙрдбрд▓ рдХреЗрд╡рд▓ рдРрддрд┐рд╣рд╛рд╕рд┐рдХ рд╣реЛрдиреЗ рдХрд╛ рджрд┐рдЦрд╛рд╡рд╛ рди рдХрд░реЗ рдмрд▓реНрдХрд┐ рд╡рд╛рд╕реНрддрд╡ рдореЗрдВ рд╣реЛред\n\n[Andrej Karpathy рджреНрд╡рд╛рд░рд╛ nanoGPT](https://github.com/karpathy/nanoGPT) рдкрд░ рдЖрдзрд╛рд░рд┐рддред рдореБрдЦреНрдп рдкреНрд░рд╢рд┐рдХреНрд╖рдг рд╕реНрдХреНрд░рд┐рдкреНрдЯреНрд╕ рдФрд░ рдореЙрдбрд▓ рдЖрд░реНрдХрд┐рдЯреЗрдХреНрдЪрд░ рдЙрдиреНрд╣реАрдВ рдХрд╛ рдХрд╛рд░реНрдп рд╣реИред\n\n# рдкрд░рд┐рдпреЛрдЬрдирд╛ рдХреЗ рд▓рдХреНрд╖реНрдп\n\nрдЯрд╛рдЗрдордХреИрдкреНрд╕реВрд▓ LLM рдПрдХ рдкреНрд░рдпреЛрдЧрд╛рддреНрдордХ рдкрд░рд┐рдпреЛрдЬрдирд╛ рд╣реИ рдЬрд┐рд╕реЗ рдХреЗрд╡рд▓ рдХреБрдЫ рдирд┐рд╢реНрдЪрд┐рдд рд╕рдордп рдЕрд╡рдзрд┐рдпреЛрдВ рдореЗрдВ рд▓рд┐рдЦреЗ рдЧрдП рдкрд╛рдареЛрдВ рдкрд░ рдкреНрд░рд╢рд┐рдХреНрд╖рд┐рдд рдХрд┐рдпрд╛ рдЬрд╛рдПрдЧрд╛ред рдЗрд╕рдХрд╛ рдЙрджреНрджреЗрд╢реНрдп рд╡рд┐рд╢рд┐рд╖реНрдЯ рдРрддрд┐рд╣рд╛рд╕рд┐рдХ рдпреБрдЧреЛрдВ рдХреА рд╡рд┐рд╢реНрд╡рджреГрд╖реНрдЯрд┐ рдФрд░ рднрд╛рд╖рд╛ рдХрд╛ рдЕрдиреБрдХрд░рдг рдХрд░рдирд╛ рд╣реИред\n\n# рдХреЗрд╡рд▓ рдлрд╛рдЗрди рдЯреНрдпреВрдирд┐рдВрдЧ рдХреНрдпреЛрдВ рдкрд░реНрдпрд╛рдкреНрдд рдирд╣реАрдВ рд╣реИ\n\nрдпрджрд┐ рдЖрдк рдХреЗрд╡рд▓ рдПрдХ рдкреВрд░реНрд╡-рдкреНрд░рд╢рд┐рдХреНрд╖рд┐рдд рдореЙрдбрд▓ рдХреЛ рдлрд╛рдЗрди рдЯреНрдпреВрди рдХрд░рддреЗ рд╣реИрдВ, рддреЛ рднреА рдЖрдкрдХрд╛ LLM рдЖрдзреБрдирд┐рдХ рдЕрд╡рдзрд╛рд░рдгрд╛рдУрдВ рдХреЛ рдЬрд╛рдирддрд╛ рд░рд╣реЗрдЧрд╛ред рдмреЗрд╢рдХ рд╢реВрдиреНрдп рдЖрдзреБрдирд┐рдХ рдкрдХреНрд╖рдкрд╛рдд рдкреНрд░рд╛рдкреНрдд рдХрд░рдирд╛ рдХрдард┐рди рд╣реИ рд▓реЗрдХрд┐рди рдореИрдВ рдЗрд╕рдХреЗ рдЬрд┐рддрдирд╛ рдХрд░реАрдм рд╣реЛ рд╕рдХрддрд╛ рд╣реВрдВ, рд╣реЛрдирд╛ рдЪрд╛рд╣рддрд╛ рд╣реВрдВред рдХреЛрдИ рдЖрдзреБрдирд┐рдХ рдкрдХреНрд╖рдкрд╛рдд рди рд╣реЛрдиреЗ рдХреЗ рд▓рд┐рдП рдореЙрдбрд▓ рдХреЛ рд╢реБрд░реВ рд╕реЗ рдкреНрд░рд╢рд┐рдХреНрд╖рд┐рдд рдХрд░рдирд╛ рдЖрд╡рд╢реНрдпрдХ рд╣реИред\n\n# рдЕрдкреЗрдХреНрд╖рд┐рдд рдкрд░рд┐рдгрд╛рдо\n\nрдЖрд╢рд╛ рд╣реИ рдХрд┐ рдЬрдм рдпрд╣ рдореЙрдбрд▓ рддреИрдпрд╛рд░ рд╣реЛ рдЬрд╛рдПрдЧрд╛, рддреЛ рдЗрд╕реЗ рдЖрдзреБрдирд┐рдХ рдЕрд╡рдзрд╛рд░рдгрд╛рдУрдВ рдХрд╛ рдЬреНрдЮрд╛рди рдирд╣реАрдВ рд╣реЛрдЧрд╛ рдФрд░ рдпрд╣ рдХреЗрд╡рд▓ рдЙрд╕реА рдкрд░ рд╡рд┐рдЪрд╛рд░ рдХрд░ рд╕рдХреЗрдЧрд╛ рдЬреЛ рдЗрд╕реЗ рд╕рд┐рдЦрд╛рдпрд╛ рдЧрдпрд╛ рд╣реИред рдЗрд╕реЗ рдЖрдзреБрдирд┐рдХ рд╢рдмреНрджрд╛рд╡рд▓реА/рдЕрд╡рдзрд╛рд░рдгрд╛рдПрдВ рдирд╣реАрдВ рдкрд╣рдЪрд╛рдирдиреА рдЪрд╛рд╣рд┐рдП рдФрд░ рдореИрдВ рдЖрд╢рд╛ рдХрд░рддрд╛ рд╣реВрдБ рдХрд┐ рдпрд╣ рдЖрдзреБрдирд┐рдХ рдЬреНрдЮрд╛рди рдХрд╛ рдХрд╛рд▓реНрдкрдирд┐рдХ рдирд┐рд░реНрдорд╛рдг рди рдХрд░реЗред\n\n# рдкреНрд░рдЧрддрд┐ рдЕрдкрдбреЗрдЯ\n\n## 9 рдЬреБрд▓рд╛рдИ, 2025\n\nрдореИрдВрдиреЗ рдЕрдкрдиреА рд╕рдордп рдЕрд╡рдзрд┐ 1800-1850 рдФрд░ рдХреНрд╖реЗрддреНрд░: рд▓рдВрджрди рдирд┐рд░реНрдзрд╛рд░рд┐рдд рдХрд░ рд▓рд┐рдпрд╛ рд╣реИ\n\nрдореИрдВрдиреЗ рдЧреНрд░рдВрдереЛрдВ, рдкреБрд╕реНрддрдХреЛрдВ, рджрд╕реНрддрд╛рд╡реЗрдЬреЛрдВ рдХреА рдПрдХ рд╕реВрдЪреА рдПрдХрддреНрд░ рдХреА рд╣реИ\n\nрдЕрдм рддрдХ рдореЗрд░реЗ рдкрд╛рд╕ 50 txt рдлрд╛рдЗрд▓реЗрдВ рд╣реИрдВ рдФрд░ рдЬрд▓реНрдж рд╣реА NanoGPT рдкрд░ рдкреНрд░рд╢рд┐рдХреНрд╖рдг рд╢реБрд░реВ рдХрд░реВрдВрдЧрд╛\n\nрдЬреИрд╕реЗ рд╣реА рдкреНрд░рдЧрддрд┐ рд╣реЛрдЧреА, рдореИрдВ рдЗрд╕рдореЗрдВ рдЕрдкрдбреЗрдЯ рдХрд░рддрд╛ рд░рд╣реВрдВрдЧрд╛\n\n## 13 рдЬреБрд▓рд╛рдИ, 2025\n\nрдореИрдВрдиреЗ nanoGPT рдХреЛ 187MB рдРрддрд┐рд╣рд╛рд╕рд┐рдХ рдкрд╛рда рдбреЗрдЯрд╛ рдХреЗ рд╕рд╛рде рдкреНрд░рд╢рд┐рдХреНрд╖рд┐рдд рдХрд┐рдпрд╛ред\n\n## 15 рдЬреБрд▓рд╛рдИ, 2025\n\nрдореИрдВрдиреЗ рджреВрд╕рд░реЗ рдкреНрд░рд╢рд┐рдХреНрд╖рдг рд░рди рдХреЗ рд▓рд┐рдП рдЧреНрд░рдВрде рдбрд╛рдЙрдирд▓реЛрдб рдХрд░рдирд╛ рд╢реБрд░реВ рдХрд░ рджрд┐рдпрд╛ рд╣реИред рдореИрдВ рд╕рдм рдХреБрдЫ Internet Archive рд╕реЗ рд▓реЗ рд░рд╣рд╛ рд╣реВрдБ рдФрд░ рдореИрдВрдиреЗ рд╕рдордпрд╛рд╡рдзрд┐ 1800-1875 рддрдХ рдмрдврд╝рд╛ рджреА рд╣реИред рд╡рд┐рд╡рд┐рдз рдкреНрд░рдХрд╛рд░ рдХреЗ рдЧреНрд░рдВрде рдкреНрд░рд╛рдкреНрдд рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП, рдЖрдк Internet Archive рдкрд░ рд╡рд┐рд╖рдп рдФрд░ рдЦреЛрдЬ рдлрд╝рд┐рд▓реНрдЯрд░ рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░ рд╕рдХрддреЗ рд╣реИрдВ рдЬреИрд╕реЗ рдкреНрд░рдХрд╛рд╢рди рд╕реНрдерд╛рди, рд╕рдордпрд╛рд╡рдзрд┐ рдФрд░ рд╡рд┐рд╖рдпред\n\n![Search Filters](https://raw.githubusercontent.com/haykgrigo3/TimeCapsuleLLM/main/searchfilter.jpg)\n\n## 16 рдЬреБрд▓рд╛рдИ, 2025\n\nрдореИрдВрдиреЗ Internet Archive рд╕реЗ рд▓рдЧрднрдЧ 500 txt рдлрд╛рдЗрд▓реЗрдВ рдбрд╛рдЙрдирд▓реЛрдб рдХреАрдВ рдФрд░ рдЙрдиреНрд╣реЗрдВ рд╕рд╛рдл рдХрд░рдиреЗ рдХреЗ рдмрд╛рдж (рд╕рд┐рд░реНрдл рд╡реНрд╣рд╛рдЗрдЯрд╕реНрдкреЗрд╕, рдЧреБрдЯреЗрдирдмрд░реНрдЧ рд╣реИрдбрд░ рдЖрджрд┐ рд╣рдЯрд╛рдХрд░) рдореЗрд░реЗ рдкрд╛рд╕ рд▓рдЧрднрдЧ 500MB рдбреЗрдЯрд╛ рдмрдЪрд╛ рд╣реИред рдпрд╣ рдПрдХ рдЫреЛрдЯрд╛ рд╕рд╛ рдбреЗрдЯрд╛рд╕реЗрдЯ рд╣реИ рд▓реЗрдХрд┐рди рдкрд┐рдЫрд▓реА рдмрд╛рд░ рдореИрдВрдиреЗ 187MB рд╕реЗ рдкреНрд░рд╢рд┐рдХреНрд╖рдг рд▓рд┐рдпрд╛ рдерд╛, рддреЛ рдкреНрд░рд╢рд┐рдХреНрд╖рдг рдХреЗ рдмрд╛рдж рдЖрдЙрдЯрдкреБрдЯ рдореЗрдВ рдХреБрдЫ рди рдХреБрдЫ рдЙрд▓реНрд▓реЗрдЦрдиреАрдп рдЕрдВрддрд░ рд╣реЛрдирд╛ рдЪрд╛рд╣рд┐рдПред рдореБрдЭреЗ рдЙрдореНрдореАрдж рд╣реИ рдХрд┐ рдпрд╣ рдореЙрдбрд▓ рдХрдо рд╕реЗ рдХрдо рдЕрдзрд┐рдХ рд╕реБрд╕рдВрдЧрдд рд╡рд╛рдХреНрдп рдЙрддреНрдкрдиреНрди рдХрд░ рд╕рдХреЗрдЧрд╛ рдЬреЛ рдХреБрдЫ рд╣рдж рддрдХ рдЕрд░реНрдердкреВрд░реНрдг рд╣реЛрдВред рдмреЗрд╢рдХ рдпрд╣ рдХреЛрдИ рдЧрд╛рд░рдВрдЯреА рдирд╣реАрдВ рд╣реИ рдХреНрдпреЛрдВрдХрд┐ рдпрд╣ рдЕрднреА рднреА рдПрдХ рдмрд╣реБрдд рд╣реА рдЫреЛрдЯрд╛ рдбреЗрдЯрд╛рд╕реЗрдЯ рд╣реИ, рд▓реЗрдХрд┐рди рдпрд╣ рдкрд┐рдЫрд▓реА рдмрд╛рд░ рд╕реЗ рдЕрдзрд┐рдХ рд╣реИред\n\nрдпрд╣ рдореЗрд░реЗ рдЕрдкрдиреЗ рд╣рд╛рд░реНрдбрд╡реЗрдпрд░ рдкрд░ рд╕рдВрднрд╡ рд╣реЛрдирд╛ рдЪрд╛рд╣рд┐рдП, рдпрд╣ рдЕрдЪреНрдЫрд╛ рднреА рд╣реИ рдХреНрдпреЛрдВрдХрд┐ рдореИрдВ рдХрд┐рд╕реА рдмрдбрд╝реЗ рдбреЗрдЯрд╛рд╕реЗрдЯ рдкрд░ рдЬрд╛рдиреЗ рд╕реЗ рдкрд╣рд▓реЗ рдХреБрдЫ рд╕реБрдзрд╛рд░ рджреЗрдЦ рд╕рдХреВрдВ, рдЬрд┐рд╕рдореЗрдВ рдореБрдЭреЗ GPU рдХрд┐рд░рд╛рдП рдкрд░ рд▓реЗрдирд╛ рдкрдбрд╝реЗрдЧрд╛ред рд▓реЗрдХрд┐рди рдЪрд┐рдВрддрд╛ рди рдХрд░реЗрдВ рдореИрдВ рдЬрд▓реНрдж рд╣реА GPU рдХрд┐рд░рд╛рдП рдкрд░ рд▓реЗрдиреЗ рдХреА рдпреЛрдЬрдирд╛ рдмрдирд╛ рд░рд╣рд╛ рд╣реВрдВ, рд▓реЗрдХрд┐рди рдЗрд╕рд╕реЗ рдкрд╣рд▓реЗ рдореИрдВ рдЪрд╛рд╣реВрдВрдЧрд╛ рдХрд┐ рдореЗрд░рд╛ рдбреЗрдЯрд╛рд╕реЗрдЯ рдЬрд┐рддрдирд╛ рд╣реЛ рд╕рдХреЗ рдЙрддрдирд╛ рд╕рдВрдХрд▓рд┐рдд рдФрд░ рд╕рд╛рдл рд╣реЛред рдореЗрд░реА рдПрдХ рд╕рдорд╕реНрдпрд╛ рд╕рдлрд╛рдИ рд╣реИ, рдЗрди txt рдлрд╛рдЗрд▓реЛрдВ рдореЗрдВ рдмрд╣реБрдд рд╕рд╛рд░рд╛ рдмреЗрдорддрд▓рдм рдХрд╛ рдХрдВрдЯреЗрдВрдЯ рдорд┐рд▓рд╛ рд╣реЛрддрд╛ рд╣реИред рдореИрдВрдиреЗ рд╕рдлрд╛рдИ рдХреЗ рд▓рд┐рдП рдЬреЛ рд╕реНрдХреНрд░рд┐рдкреНрдЯреНрд╕ рдЗрд╕реНрддреЗрдорд╛рд▓ рдХреА рд╣реИрдВ рд╡реЗ рдХрд╛рдо рдХрд░рддреА рд╣реИрдВ рд▓реЗрдХрд┐рди 100% рдкреНрд░рднрд╛рд╡реА рдирд╣реАрдВ рд╣реИрдВред\n\nрдореИрдВ рдЖрдЬ рд╣реА рдЗрд╕ рдбреЗрдЯрд╛рд╕реЗрдЯ рдХреЛ рдкреНрд░рд╢рд┐рдХреНрд╖рд┐рдд рдХрд░реВрдВрдЧрд╛ рдФрд░ рдЗрд╕рдореЗрдВ рд▓рдЧрднрдЧ 4-5 рдШрдВрдЯреЗ рд▓рдЧрдиреЗ рдЪрд╛рд╣рд┐рдПред рдЬрдм рдпрд╣ рд╣реЛ рдЬрд╛рдПрдЧрд╛ рдФрд░ рдореИрдВ рдЗрд╕рдХрд╛ рдкрд░реАрдХреНрд╖рдг рдХрд░реВрдВрдЧрд╛, рддреЛ рдЕрдкрдбреЗрдЯ рджреВрдВрдЧрд╛ред рдореЗрд░реЗ рдкреНрд░реЛрдЬреЗрдХреНрдЯ рдХреЛ рджреЗрдЦрдиреЗ рдХреЗ рд▓рд┐рдП рд╕рднреА рдХрд╛ рдзрдиреНрдпрд╡рд╛рдж, рдореБрдЭреЗ рдХреБрдЫ рд▓реЛрдЧреЛрдВ рдиреЗ OCR рд╕рдВрд╕рд╛рдзрдиреЛрдВ рдХреЗ рд▓рд┐рдВрдХ рднреА рджрд┐рдП рд╣реИрдВ, рдЗрд╕рдХреЗ рд▓рд┐рдП рднреА рдзрдиреНрдпрд╡рд╛рдж! рдореБрдЭреЗ рдЙрдореНрдореАрдж рд╣реИ рдХрд┐ рдФрд░ рд▓реЛрдЧ рдЗрд╕реЗ рдЖрдЬрдорд╛рдПрдВ рдФрд░ рдЕрдкрдиреЗ-рдЕрдкрдиреЗ рдбреЗрдЯрд╛рд╕реЗрдЯ рдХреЗ рд╕рд╛рде рдкреНрд░рдпреЛрдЧ рдХрд░реЗрдВред\n\n\n### рдкреНрд░рд╢рд┐рдХреНрд╖рдг рдЕрдкрдбреЗрдЯ\n\nрдореИрдВрдиреЗ 435MB (108 рдорд┐рд▓рд┐рдпрди рдЯреЛрдХрди) рдХреЙрд░реНрдкрд╕ рдкрд░ рдкреНрд░рд╢рд┐рдХреНрд╖рдг рд╢реБрд░реВ рдХрд┐рдпрд╛, рдпрд╣ рдЕрднреА рдХрд╛рдлреА рдЕрдЪреНрдЫрд╛ рдЪрд▓ рд░рд╣рд╛ рд╣реИред рдкрд╣рд▓реЗ 2800 рдЗрдЯрд░реЗрд╢рди рдореЗрдВ рдЯреНрд░реЗрди рд▓реЙрд╕ 10.9 рд╕реЗ рдШрдЯрдХрд░ 4.9 рд╣реЛ рдЧрдпрд╛ред рдореБрдЭреЗ рдЙрдореНрдореАрдж рд╣реИ рдХрд┐ рдкреВрд░рд╛ рд╣реЛрдиреЗ рдореЗрдВ рд▓рдЧрднрдЧ 8 рдпрд╛ 9 рдШрдВрдЯреЗ рд▓рдЧреЗрдВрдЧреЗред рдкреВрд░рд╛ рд╣реЛрдиреЗ рдХреЗ рдмрд╛рдж рдореИрдВ рдПрдХ рдФрд░ рдЕрдкрдбреЗрдЯ рдкреЛрд╕реНрдЯ рдХрд░реВрдВрдЧрд╛ред\n\n## 17 рдЬреБрд▓рд╛рдИ, 2025\n\nрджреВрд╕рд░реЗ рдореЙрдбрд▓ рдХрд╛ рдкреНрд░рд╢рд┐рдХреНрд╖рдг рдкреВрд░рд╛ рд╣реЛ рдЧрдпрд╛ рд╣реИ, рдореЗрд░реЗ 4060 рдиреЗ рд▓рдЧрднрдЧ 8 рдШрдВрдЯреЗ 40 рдорд┐рдирдЯ (3,900 рдЗрдЯрд░реЗрд╢рди/рдШрдВрдЯрд╛) рдореЗрдВ 33,000 рдЗрдЯрд░реЗрд╢рди (5 рдИрдкреЛрдХреНрд╕) рдкреВрд░реЗ рдХрд┐рдПред рдЕрдВрддрд┐рдо рдЯреНрд░реЗрди рд▓реЙрд╕ 3.73 рдерд╛ред рдЖрдЙрдЯрдкреБрдЯ рдЖрд╢реНрдЪрд░реНрдпрдЬрдирдХ рд░реВрдк рд╕реЗ рдЕрдЪреНрдЫреЗ рдереЗ, рдЕрдм рдпрд╣ рд╕рдЪ рдореЗрдВ 19рд╡реАрдВ рд╕рджреА рдХреА рд╢реИрд▓реА рдХреЗ рд╕реБрд╕рдВрдЧрдд рд╡рд╛рдХреНрдп рдЙрддреНрдкрдиреНрди рдХрд░рддрд╛ рд╣реИред\n\n## 28 рдЬреБрд▓рд╛рдИ, 2025\n\nрдореИрдВрдиреЗ v0.5 рдХреЛ Hugging Face рдкрд░ рдЕрдкрд▓реЛрдб рдХрд░ рджрд┐рдпрд╛ рд╣реИ, [рдпрд╣рд╛рдВ рджреЗрдЦреЗрдВ](https://huggingface.co/haykgrigorian/TimeCapsuleLLM) рдЕрдЧрд░ рдЖрдк рдЪрд╛рд╣реЗрдВред рдЕрдм рдЖрдк рдореЗрд░рд╛ рд░рд┐рдкреЙрдЬрд┐рдЯрд░реА рдбрд╛рдЙрдирд▓реЛрдб рдХрд░ рд╕рдХрддреЗ рд╣реИрдВ рдФрд░ рдЗрд╕реЗ рд▓реЛрдХрд▓реА рдЪрд▓рд╛ рд╕рдХрддреЗ рд╣реИрдВред рджреБрд░реНрднрд╛рдЧреНрдпрд╡рд╢ nanoGPT HuggingFace рдХреЗ рд╕рд╛рде рд╕реАрдзреЗ рдХрд╛рдо рдирд╣реАрдВ рдХрд░рддрд╛, рдЗрд╕рд▓рд┐рдП рдЖрдкрдХреЛ рдореЙрдбрд▓ рдбрд╛рдЙрдирд▓реЛрдб рдХрд░рдХреЗ рд▓реЛрдХрд▓реА рдЪрд▓рд╛рдирд╛ рд╣реЛрдЧрд╛ред\n\nрд╕рд╛рде рд╣реА, рдореИрдВ рдЕрдкрдиреЗ рдЕрдЧрд▓реЗ рдкреНрд░рд╢рд┐рдХреНрд╖рдг рд░рди рдХреЗ рд▓рд┐рдП рдбреЗрдЯрд╛ рд╕рдВрдХрд▓рд┐рдд рдХрд░рдирд╛ рд╢реБрд░реВ рдХрд░реВрдВрдЧрд╛, рдореБрдЭреЗ рд▓рдЧрддрд╛ рд╣реИ рдХрд┐ рддрд░реНрдХ рдХреНрд╖рдорддрд╛ рд╣рд╛рд╕рд┐рд▓ рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП рд╢рд╛рдпрдж 5-10 рдЧреБрдирд╛ рдЕрдзрд┐рдХ рдбреЗрдЯрд╛ рдЪрд╛рд╣рд┐рдП рд╣реЛрдЧрд╛ред\n\n## 2 рдЕрдЧрд╕реНрдд, 2025\n\nрдореИрдВ рдЬрд▓реНрдж рд╣реА Version 1 рдкрд░ рдХрд╛рдо рд╢реБрд░реВ рдХрд░рдиреЗ рдЬрд╛ рд░рд╣рд╛ рд╣реВрдВред рдореБрдЭреЗ nanoGPT рдХреА рдЖрд░реНрдХрд┐рдЯреЗрдХреНрдЪрд░ рд╕реЗ рдХреБрдЫ рдЕрдзрд┐рдХ рдЖрдзреБрдирд┐рдХ рдкрд░ рд╕реНрд╡рд┐рдЪ рдХрд░рдирд╛ рд╣реЛрдЧрд╛ред рдореЗрд░реЗ рджрд┐рдорд╛рдЧ рдореЗрдВ рдХрдИ рдУрдкрди-рд╕реЛрд░реНрд╕ LLM рдЖрд░реНрдХрд┐рдЯреЗрдХреНрдЪрд░ рд╣реИрдВ, рдЬреИрд╕реЗ: OpenLLaMA v3, Phi-2 рдФрд░ Qwen 1.5Bред рдФрд░ V1 рдХреЗ рд▓рд┐рдП, рдореБрдЭреЗ рдФрд░ рдмрдбрд╝рд╛ рд╡ рд╡рд┐рд╡рд┐рдз рдбреЗрдЯрд╛рд╕реЗрдЯ рд╕рд╛рд╡рдзрд╛рдиреА рд╕реЗ рд╕рдВрдХрд▓рд┐рдд рдХрд░рдирд╛ рд╣реЛрдЧрд╛ред рдореБрдЭреЗ рдХрдо рд╕реЗ рдХрдо 5GB рд╕рд╛рдл рдкреНрд░рд╢рд┐рдХреНрд╖рдг рдбреЗрдЯрд╛ рдХреА рдЖрд╡рд╢реНрдпрдХрддрд╛ рд╣реЛрдЧреАред\n\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "<div align=\"right\">"
      },
      {
        "row": 2,
        "rowsha": "cWgam+tnnXudu7i74+ahMEGk/A9dQS+EwWLAIfi3dHk=",
        "originContent": "<div align=\"right\">",
        "translatedContent": "  <details>"
      },
      {
        "row": 3,
        "rowsha": "orOcu5ARna/hb3RUkj6dBI8pHTM3WHeTvby17l5E0h0=",
        "originContent": "  <details>",
        "translatedContent": "    <summary >ЁЯМР рднрд╛рд╖рд╛</summary>"
      },
      {
        "row": 4,
        "rowsha": "TtgkLzblnvP0q9aAIVXt6s2LczXjy5k+QvHKcU0/5Ms=",
        "originContent": "    <summary >ЁЯМР Language</summary>",
        "translatedContent": "    <div>"
      },
      {
        "row": 5,
        "rowsha": "fZtk4rPTAJEEslnbhSVkHEcPlsctYSzAV7CDPL3rJmA=",
        "originContent": "    <div>",
        "translatedContent": "      <div align=\"center\">"
      },
      {
        "row": 6,
        "rowsha": "9KQxOeJSigvTmGWO+mtnl8kZY9zQfueoy8sk4lYm09Q=",
        "originContent": "      <div align=\"center\">",
        "translatedContent": "        <a href=\"https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=en\">рдЕрдВрдЧреНрд░реЗрдЬрд╝реА</a>"
      },
      {
        "row": 7,
        "rowsha": "CeOhdpchZBoZSEUDtSE417JEcMBSZw18jeJuHJBKB2Y=",
        "originContent": "        <a href=\"https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=en\">English</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=zh-CN\">чоАф╜Уф╕нцЦЗ</a>"
      },
      {
        "row": 8,
        "rowsha": "ToO7MFa3QrNNljdQWIagsnOPxe8cXuuA2m5msIm+Kbs=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=zh-CN\">чоАф╜Уф╕нцЦЗ</a>",
        "translatedContent": "        | <a href=\"#\" title=\"Coming soon\">ч╣БщлФф╕нцЦЗ (рдЬрд▓реНрдж рдЖ рд░рд╣рд╛ рд╣реИ)</a> |"
      },
      {
        "row": 9,
        "rowsha": "MRATmWdRMRw0JU4u9h5pMb6GU17lQFgG9v/bpGLr9pM=",
        "originContent": "        | <a href=\"#\" title=\"Coming soon\">ч╣БщлФф╕нцЦЗ (coming soon)</a> |",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=ja\">цЧецЬмшкЮ</a>"
      },
      {
        "row": 10,
        "rowsha": "GY7LXxG3rk5eFh9itcqM0cTtmHybyjLTf1icB3jN31I=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=ja\">цЧецЬмшкЮ</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=ko\">эХЬъ╡ньЦ┤</a>"
      },
      {
        "row": 11,
        "rowsha": "b5TwunGJh+gsAe7aQU3dkfobXF/nknCEta1msDa7XBU=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=ko\">эХЬъ╡ньЦ┤</a>",
        "translatedContent": "        | <a href=\"#\" title=\"Coming soon\">рд╣рд┐рдиреНрджреА (рдЬрд▓реНрдж рдЖ рд░рд╣рд╛ рд╣реИ)</a> |"
      },
      {
        "row": 12,
        "rowsha": "1/HCgPsVh2ChqMY+k/VVxEWHPRRmWWCjy5nDRibi3mM=",
        "originContent": "        | <a href=\"#\" title=\"Coming soon\">рд╣рд┐рдиреНрджреА (coming soon)</a> |",
        "translatedContent": "        | <a href=\"#\" title=\"Coming soon\">р╣Др╕Чр╕в (рдЬрд▓реНрдж рдЖ рд░рд╣рд╛ рд╣реИ)</a> |"
      },
      {
        "row": 13,
        "rowsha": "3lfEHT+5HYFEvbE5cl+xujQPYjtVmzTifT37iqPTWII=",
        "originContent": "        | <a href=\"#\" title=\"Coming soon\">р╣Др╕Чр╕в (coming soon)</a> |",
        "translatedContent": "        | <a href=\"#\" title=\"Coming soon\">Fran├зais (рдЬрд▓реНрдж рдЖ рд░рд╣рд╛ рд╣реИ)</a>"
      },
      {
        "row": 14,
        "rowsha": "KmG3P0px2E3bt1lU/w3eGop+zeA1j8xL0k280Zd9m2s=",
        "originContent": "        | <a href=\"#\" title=\"Coming soon\">Fran├зais (coming soon)</a>",
        "translatedContent": "        | <a href=\"#\" title=\"Coming soon\">Deutsch (рдЬрд▓реНрдж рдЖ рд░рд╣рд╛ рд╣реИ)</a>"
      },
      {
        "row": 15,
        "rowsha": "CSdHSEXgIs3M2Q/6zIIJ8NbKkZWhydhBqNus94qrPvg=",
        "originContent": "        | <a href=\"#\" title=\"Coming soon\">Deutsch (coming soon)</a>",
        "translatedContent": "        | <a href=\"#\" title=\"Coming soon\">Espa├▒ol (рдЬрд▓реНрдж рдЖ рд░рд╣рд╛ рд╣реИ)</a>"
      },
      {
        "row": 16,
        "rowsha": "8wz7pDuXc3dk+ZcqZ1jmmh8zh6xN3Wb6qWbCjxAj7dA=",
        "originContent": "        | <a href=\"#\" title=\"Coming soon\">Espa├▒ol (coming soon)</a>",
        "translatedContent": "        | <a href=\"#\" title=\"Coming soon\">Italiano (рдЬрд▓реНрдж рдЖ рд░рд╣рд╛ рд╣реИ)</a>"
      },
      {
        "row": 17,
        "rowsha": "op/NqIZs7OjCSpNgpXk8RnqDnTegVPyWUQhuQxvTR7U=",
        "originContent": "        | <a href=\"#\" title=\"Coming soon\">Italiano (coming soon)</a>",
        "translatedContent": "        | <a href=\"#\" title=\"Coming soon\">╨а╤Г╤Б╤Б╨║╨╕╨╣ (рдЬрд▓реНрдж рдЖ рд░рд╣рд╛ рд╣реИ)</a>"
      },
      {
        "row": 18,
        "rowsha": "tAvlfwut/Ad9q1huxc8EREZGv7vYHbrEujzUS8xoaQo=",
        "originContent": "        | <a href=\"#\" title=\"Coming soon\">╨а╤Г╤Б╤Б╨║╨╕╨╣ (coming soon)</a>",
        "translatedContent": "        | <a href=\"#\" title=\"Coming soon\">Portugu├кs (рдЬрд▓реНрдж рдЖ рд░рд╣рд╛ рд╣реИ)</a>"
      },
      {
        "row": 19,
        "rowsha": "WhhSpeeCUUAqJiVTS4Fvyc6A2c+24Jnj3MW7XLQuIcI=",
        "originContent": "        | <a href=\"#\" title=\"Coming soon\">Portugu├кs (coming soon)</a>",
        "translatedContent": "        | <a href=\"#\" title=\"Coming soon\">Nederlands (рдЬрд▓реНрдж рдЖ рд░рд╣рд╛ рд╣реИ)</a>"
      },
      {
        "row": 20,
        "rowsha": "0yPXPrWh+Vzc6FBE9iiciw5HwpOSmo05HNe36wfTWCI=",
        "originContent": "        | <a href=\"#\" title=\"Coming soon\">Nederlands (coming soon)</a>",
        "translatedContent": "        | <a href=\"#\" title=\"Coming soon\">Polski (рдЬрд▓реНрдж рдЖ рд░рд╣рд╛ рд╣реИ)</a>"
      },
      {
        "row": 21,
        "rowsha": "mdW6YUUXf5KzI4CwZxrE08ofaLonUOMnJpN3vPR7Y2A=",
        "originContent": "        | <a href=\"#\" title=\"Coming soon\">Polski (coming soon)</a>",
        "translatedContent": "        | <a href=\"#\" title=\"Coming soon\">╪з┘Д╪╣╪▒╪и┘К╪й (рдЬрд▓реНрдж рдЖ рд░рд╣рд╛ рд╣реИ)</a>"
      },
      {
        "row": 22,
        "rowsha": "sw1AXxAGQNvn4eSG9enTWNkwKH0yr6LlVtXBH1j9z8s=",
        "originContent": "        | <a href=\"#\" title=\"Coming soon\">╪з┘Д╪╣╪▒╪и┘К╪й (coming soon)</a>",
        "translatedContent": "        | <a href=\"#\" title=\"Coming soon\">┘Б╪з╪▒╪│█М (рдЬрд▓реНрдж рдЖ рд░рд╣рд╛ рд╣реИ)</a>"
      },
      {
        "row": 23,
        "rowsha": "I8dh9zmXisU0+CpddA55QQgvujH03J/dEnXgj5aFtQM=",
        "originContent": "        | <a href=\"#\" title=\"Coming soon\">┘Б╪з╪▒╪│█М (coming soon)</a>",
        "translatedContent": "        | <a href=\"#\" title=\"Coming soon\">T├╝rk├зe (рдЬрд▓реНрдж рдЖ рд░рд╣рд╛ рд╣реИ)</a>"
      },
      {
        "row": 24,
        "rowsha": "7VFv8o6de72ciJrbh3mctfrEgCJhNvuKGWJNOmCaPdM=",
        "originContent": "        | <a href=\"#\" title=\"Coming soon\">T├╝rk├зe (coming soon)</a>",
        "translatedContent": "        | <a href=\"#\" title=\"Coming soon\">Tiс║┐ng Viс╗Зt (рдЬрд▓реНрдж рдЖ рд░рд╣рд╛ рд╣реИ)</a>"
      },
      {
        "row": 25,
        "rowsha": "C+XRvFz/D3o9/JyPqwitsxtskFZleJC/oFUr4SEeiHA=",
        "originContent": "        | <a href=\"#\" title=\"Coming soon\">Tiс║┐ng Viс╗Зt (coming soon)</a>",
        "translatedContent": "        | <a href=\"#\" title=\"Coming soon\">Bahasa Indonesia (рдЬрд▓реНрдж рдЖ рд░рд╣рд╛ рд╣реИ)</a>"
      },
      {
        "row": 26,
        "rowsha": "ntGI5B+n9x96pV3ZG5GG83nmocQbxTJjKY7VVwa6Rq8=",
        "originContent": "        | <a href=\"#\" title=\"Coming soon\">Bahasa Indonesia (coming soon)</a>",
        "translatedContent": ""
      },
      {
        "row": 27,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "      </div>"
      },
      {
        "row": 28,
        "rowsha": "0OM5wNEm0TO56MEBvQzL7AUZM7/3OpgIeqRf2zFre3Q=",
        "originContent": "      </div>",
        "translatedContent": "    </div>"
      },
      {
        "row": 29,
        "rowsha": "fcjTfY+fs8YnY5slBs1sZvWPAqEQR7tzaBDO54skkGQ=",
        "originContent": "    </div>",
        "translatedContent": "  </details>"
      },
      {
        "row": 30,
        "rowsha": "+fQNH2ldI7UM/rqRscP3hUSWAmw1HvQ2wEKDN8JagT0=",
        "originContent": "  </details>",
        "translatedContent": "</div>"
      },
      {
        "row": 31,
        "rowsha": "qsMmUbEPVnxGG5tPJV1vsfpoWbU2jYvZpRr5IKshzyM=",
        "originContent": "</div>",
        "translatedContent": ""
      },
      {
        "row": 32,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "# рдЯрд╛рдЗрдордХреИрдкреНрд╕реВрд▓ LLM"
      },
      {
        "row": 33,
        "rowsha": "VRGjp0FtfvQ89lbX/wJLis2ypCRtNJwe8ViIi29+Rko=",
        "originContent": "# TimeCapsule LLM",
        "translatedContent": "рдПрдХ LLM рдЬрд┐рд╕реЗ рдХреЗрд╡рд▓ рдХреБрдЫ рд╡рд┐рд╢реЗрд╖ рд╕рдордп рдЕрд╡рдзрд┐рдпреЛрдВ рдХреЗ рдбреЗрдЯрд╛ рдкрд░ рдкреНрд░рд╢рд┐рдХреНрд╖рд┐рдд рдХрд┐рдпрд╛ рдЧрдпрд╛ рд╣реИ рддрд╛рдХрд┐ рдЖрдзреБрдирд┐рдХ рдкрдХреНрд╖рдкрд╛рдд рдХрдо рд╣реЛ рд╕рдХреЗред"
      },
      {
        "row": 34,
        "rowsha": "XGlykErifWX9oIzV4ZXDc4AUnsuesz8LvpruG76e6uY=",
        "originContent": "An LLM trained only on data from certain time periods to reduce modern bias.",
        "translatedContent": ""
      },
      {
        "row": 35,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "рдХрд▓реНрдкрдирд╛ рдХреАрдЬрд┐рдП рдпрджрд┐ рдПрдХ рдПрдЖрдИ рдореЙрдбрд▓ рдХреЗрд╡рд▓ рдРрддрд┐рд╣рд╛рд╕рд┐рдХ рд╣реЛрдиреЗ рдХрд╛ рджрд┐рдЦрд╛рд╡рд╛ рди рдХрд░реЗ рдмрд▓реНрдХрд┐ рд╡рд╛рд╕реНрддрд╡ рдореЗрдВ рд╣реЛред"
      },
      {
        "row": 36,
        "rowsha": "06wDXO9Un3ot9kUKAGg7CaRsIVSkfS1d2m+EQ6HOFog=",
        "originContent": "Imagine if an AI model didnt just pretend to be historical but actually was.",
        "translatedContent": ""
      },
      {
        "row": 37,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "[Andrej Karpathy рджреНрд╡рд╛рд░рд╛ nanoGPT](https://github.com/karpathy/nanoGPT) рдкрд░ рдЖрдзрд╛рд░рд┐рддред рдореБрдЦреНрдп рдкреНрд░рд╢рд┐рдХреНрд╖рдг рд╕реНрдХреНрд░рд┐рдкреНрдЯреНрд╕ рдФрд░ рдореЙрдбрд▓ рдЖрд░реНрдХрд┐рдЯреЗрдХреНрдЪрд░ рдЙрдиреНрд╣реАрдВ рдХрд╛ рдХрд╛рд░реНрдп рд╣реИред"
      },
      {
        "row": 38,
        "rowsha": "2773v/qIXSAsW4pN2HtYcVltfzG1vzgVbHgfjStBQIY=",
        "originContent": "Built on [nanoGPT by Andrej Karpathy](https://github.com/karpathy/nanoGPT) Core training scripts and model architecture are his work. ",
        "translatedContent": ""
      },
      {
        "row": 39,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "# рдкрд░рд┐рдпреЛрдЬрдирд╛ рдХреЗ рд▓рдХреНрд╖реНрдп"
      },
      {
        "row": 40,
        "rowsha": "wITJJBD/4abiy4E37iMdOcGmifkmz4dALLyk6AhA1kc=",
        "originContent": "# Project Goals ",
        "translatedContent": ""
      },
      {
        "row": 41,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "рдЯрд╛рдЗрдордХреИрдкреНрд╕реВрд▓ LLM рдПрдХ рдкреНрд░рдпреЛрдЧрд╛рддреНрдордХ рдкрд░рд┐рдпреЛрдЬрдирд╛ рд╣реИ рдЬрд┐рд╕реЗ рдХреЗрд╡рд▓ рдХреБрдЫ рдирд┐рд╢реНрдЪрд┐рдд рд╕рдордп рдЕрд╡рдзрд┐рдпреЛрдВ рдореЗрдВ рд▓рд┐рдЦреЗ рдЧрдП рдкрд╛рдареЛрдВ рдкрд░ рдкреНрд░рд╢рд┐рдХреНрд╖рд┐рдд рдХрд┐рдпрд╛ рдЬрд╛рдПрдЧрд╛ред рдЗрд╕рдХрд╛ рдЙрджреНрджреЗрд╢реНрдп рд╡рд┐рд╢рд┐рд╖реНрдЯ рдРрддрд┐рд╣рд╛рд╕рд┐рдХ рдпреБрдЧреЛрдВ рдХреА рд╡рд┐рд╢реНрд╡рджреГрд╖реНрдЯрд┐ рдФрд░ рднрд╛рд╖рд╛ рдХрд╛ рдЕрдиреБрдХрд░рдг рдХрд░рдирд╛ рд╣реИред"
      },
      {
        "row": 42,
        "rowsha": "LlW7r/H8NhftFgGAHce1f4KThGgsoT8aJ88/IsiLntc=",
        "originContent": "TimeCapsule LLM is an expirimental project that will only be trained on texts written during certain time periods. The goal is to simulate the worldview and language of specific historical eras.",
        "translatedContent": ""
      },
      {
        "row": 43,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "# рдХреЗрд╡рд▓ рдлрд╛рдЗрди рдЯреНрдпреВрдирд┐рдВрдЧ рдХреНрдпреЛрдВ рдкрд░реНрдпрд╛рдкреНрдд рдирд╣реАрдВ рд╣реИ"
      },
      {
        "row": 44,
        "rowsha": "obYFMCTDj8qHZGo0BQtA2AlwA8JgNcjDK9WlMRI4eq8=",
        "originContent": "# Why fine tuning isn't enough ",
        "translatedContent": ""
      },
      {
        "row": 45,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "рдпрджрд┐ рдЖрдк рдХреЗрд╡рд▓ рдПрдХ рдкреВрд░реНрд╡-рдкреНрд░рд╢рд┐рдХреНрд╖рд┐рдд рдореЙрдбрд▓ рдХреЛ рдлрд╛рдЗрди рдЯреНрдпреВрди рдХрд░рддреЗ рд╣реИрдВ, рддреЛ рднреА рдЖрдкрдХрд╛ LLM рдЖрдзреБрдирд┐рдХ рдЕрд╡рдзрд╛рд░рдгрд╛рдУрдВ рдХреЛ рдЬрд╛рдирддрд╛ рд░рд╣реЗрдЧрд╛ред рдмреЗрд╢рдХ рд╢реВрдиреНрдп рдЖрдзреБрдирд┐рдХ рдкрдХреНрд╖рдкрд╛рдд рдкреНрд░рд╛рдкреНрдд рдХрд░рдирд╛ рдХрдард┐рди рд╣реИ рд▓реЗрдХрд┐рди рдореИрдВ рдЗрд╕рдХреЗ рдЬрд┐рддрдирд╛ рдХрд░реАрдм рд╣реЛ рд╕рдХрддрд╛ рд╣реВрдВ, рд╣реЛрдирд╛ рдЪрд╛рд╣рддрд╛ рд╣реВрдВред рдХреЛрдИ рдЖрдзреБрдирд┐рдХ рдкрдХреНрд╖рдкрд╛рдд рди рд╣реЛрдиреЗ рдХреЗ рд▓рд┐рдП рдореЙрдбрд▓ рдХреЛ рд╢реБрд░реВ рд╕реЗ рдкреНрд░рд╢рд┐рдХреНрд╖рд┐рдд рдХрд░рдирд╛ рдЖрд╡рд╢реНрдпрдХ рд╣реИред"
      },
      {
        "row": 46,
        "rowsha": "yNEBOKV/RnG7CvDjiWhkXKK6vqbwki9QKC+Zs+8PzbM=",
        "originContent": "If you just fine tune a pre-trained model, your LLM is still gonna know modern concepts. Of course achieving zero modern bias is difficult but I want to get as close as possible to this. Getting no modern bias requires training a model from scratch.",
        "translatedContent": ""
      },
      {
        "row": 47,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "# рдЕрдкреЗрдХреНрд╖рд┐рдд рдкрд░рд┐рдгрд╛рдо"
      },
      {
        "row": 48,
        "rowsha": "SdJkrN/DUD4+aOCh9lfDM3AAqMxlyukDfye/nzXzxN0=",
        "originContent": "# Expected outcomes ",
        "translatedContent": ""
      },
      {
        "row": 49,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "рдЖрд╢рд╛ рд╣реИ рдХрд┐ рдЬрдм рдпрд╣ рдореЙрдбрд▓ рддреИрдпрд╛рд░ рд╣реЛ рдЬрд╛рдПрдЧрд╛, рддреЛ рдЗрд╕реЗ рдЖрдзреБрдирд┐рдХ рдЕрд╡рдзрд╛рд░рдгрд╛рдУрдВ рдХрд╛ рдЬреНрдЮрд╛рди рдирд╣реАрдВ рд╣реЛрдЧрд╛ рдФрд░ рдпрд╣ рдХреЗрд╡рд▓ рдЙрд╕реА рдкрд░ рд╡рд┐рдЪрд╛рд░ рдХрд░ рд╕рдХреЗрдЧрд╛ рдЬреЛ рдЗрд╕реЗ рд╕рд┐рдЦрд╛рдпрд╛ рдЧрдпрд╛ рд╣реИред рдЗрд╕реЗ рдЖрдзреБрдирд┐рдХ рд╢рдмреНрджрд╛рд╡рд▓реА/рдЕрд╡рдзрд╛рд░рдгрд╛рдПрдВ рдирд╣реАрдВ рдкрд╣рдЪрд╛рдирдиреА рдЪрд╛рд╣рд┐рдП рдФрд░ рдореИрдВ рдЖрд╢рд╛ рдХрд░рддрд╛ рд╣реВрдБ рдХрд┐ рдпрд╣ рдЖрдзреБрдирд┐рдХ рдЬреНрдЮрд╛рди рдХрд╛ рдХрд╛рд▓реНрдкрдирд┐рдХ рдирд┐рд░реНрдорд╛рдг рди рдХрд░реЗред"
      },
      {
        "row": 50,
        "rowsha": "bsSMnG6qSBf/pVtCQNGFlaKye8GxBKV660amPA/pINE=",
        "originContent": "Hopefully when finished, this model will not know modern concepts and will not be able to reason beyond what it's been trained on. It shouldnt recognize modern concepts/vocab and I hope it doesn't hallucinate modern knowledge.",
        "translatedContent": ""
      },
      {
        "row": 51,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "# рдкреНрд░рдЧрддрд┐ рдЕрдкрдбреЗрдЯ"
      },
      {
        "row": 52,
        "rowsha": "8EWRxPaogE2BaXxVJE1VFNAXNdS6KUYPLDFN8xlQ9LE=",
        "originContent": "# Progress Updates",
        "translatedContent": ""
      },
      {
        "row": 53,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "## 9 рдЬреБрд▓рд╛рдИ, 2025"
      },
      {
        "row": 54,
        "rowsha": "oq91hnNV5WwmrEF0amya8kSN7gu21MN5nOcR2dPRBZ0=",
        "originContent": "## July 9th, 2025",
        "translatedContent": ""
      },
      {
        "row": 55,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "рдореИрдВрдиреЗ рдЕрдкрдиреА рд╕рдордп рдЕрд╡рдзрд┐ 1800-1850 рдФрд░ рдХреНрд╖реЗрддреНрд░: рд▓рдВрджрди рдирд┐рд░реНрдзрд╛рд░рд┐рдд рдХрд░ рд▓рд┐рдпрд╛ рд╣реИ"
      },
      {
        "row": 56,
        "rowsha": "yU3u8taDdAaD23tJB9+n/2wmry0GfF+KXqADT4YLuJ8=",
        "originContent": "I've set my time period for 1800-1850 and region: London ",
        "translatedContent": ""
      },
      {
        "row": 57,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "рдореИрдВрдиреЗ рдЧреНрд░рдВрдереЛрдВ, рдкреБрд╕реНрддрдХреЛрдВ, рджрд╕реНрддрд╛рд╡реЗрдЬреЛрдВ рдХреА рдПрдХ рд╕реВрдЪреА рдПрдХрддреНрд░ рдХреА рд╣реИ"
      },
      {
        "row": 58,
        "rowsha": "uQe95shOfOi8NA0M2/CQCXlOjNsiSmGrt5dZbeP4ANs=",
        "originContent": "I've gathered a list of texts, books, documents ",
        "translatedContent": ""
      },
      {
        "row": 59,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "рдЕрдм рддрдХ рдореЗрд░реЗ рдкрд╛рд╕ 50 txt рдлрд╛рдЗрд▓реЗрдВ рд╣реИрдВ рдФрд░ рдЬрд▓реНрдж рд╣реА NanoGPT рдкрд░ рдкреНрд░рд╢рд┐рдХреНрд╖рдг рд╢реБрд░реВ рдХрд░реВрдВрдЧрд╛"
      },
      {
        "row": 60,
        "rowsha": "i9Kzka7MMa5yKjfdslauZFzKk+gAcnyILwscFoaepYs=",
        "originContent": "So far I've gotten 50 as txt files and will begin training NanoGPT soon ",
        "translatedContent": ""
      },
      {
        "row": 61,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "рдЬреИрд╕реЗ рд╣реА рдкреНрд░рдЧрддрд┐ рд╣реЛрдЧреА, рдореИрдВ рдЗрд╕рдореЗрдВ рдЕрдкрдбреЗрдЯ рдХрд░рддрд╛ рд░рд╣реВрдВрдЧрд╛"
      },
      {
        "row": 62,
        "rowsha": "Wov5RgnyTA0P0gtJKLL0GTcSf7t8WrgFcAzDufE5Xh4=",
        "originContent": "Will update this as long as progress is made",
        "translatedContent": ""
      },
      {
        "row": 63,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "## 13 рдЬреБрд▓рд╛рдИ, 2025"
      },
      {
        "row": 64,
        "rowsha": "FSOOW2G6pyPozg+3u76To6E4Pthd9lRoZE396fwY2I4=",
        "originContent": "## July 13th, 2025",
        "translatedContent": ""
      },
      {
        "row": 65,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "рдореИрдВрдиреЗ nanoGPT рдХреЛ 187MB рдРрддрд┐рд╣рд╛рд╕рд┐рдХ рдкрд╛рда рдбреЗрдЯрд╛ рдХреЗ рд╕рд╛рде рдкреНрд░рд╢рд┐рдХреНрд╖рд┐рдд рдХрд┐рдпрд╛ред"
      },
      {
        "row": 66,
        "rowsha": "GszU76q+4dgDkDO4uNZpx/9WhQTTCZlq4VYIt0ZdgD0=",
        "originContent": "Trained nanoGPT with 187MB of historial text data. ",
        "translatedContent": ""
      },
      {
        "row": 67,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "## 15 рдЬреБрд▓рд╛рдИ, 2025"
      },
      {
        "row": 68,
        "rowsha": "pGPL3z/t2hDtXa67ubNgmRC/+b4O2Yp/0ff3R/9mraE=",
        "originContent": "## July 15th, 2025",
        "translatedContent": ""
      },
      {
        "row": 69,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "рдореИрдВрдиреЗ рджреВрд╕рд░реЗ рдкреНрд░рд╢рд┐рдХреНрд╖рдг рд░рди рдХреЗ рд▓рд┐рдП рдЧреНрд░рдВрде рдбрд╛рдЙрдирд▓реЛрдб рдХрд░рдирд╛ рд╢реБрд░реВ рдХрд░ рджрд┐рдпрд╛ рд╣реИред рдореИрдВ рд╕рдм рдХреБрдЫ Internet Archive рд╕реЗ рд▓реЗ рд░рд╣рд╛ рд╣реВрдБ рдФрд░ рдореИрдВрдиреЗ рд╕рдордпрд╛рд╡рдзрд┐ 1800-1875 рддрдХ рдмрдврд╝рд╛ рджреА рд╣реИред рд╡рд┐рд╡рд┐рдз рдкреНрд░рдХрд╛рд░ рдХреЗ рдЧреНрд░рдВрде рдкреНрд░рд╛рдкреНрдд рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП, рдЖрдк Internet Archive рдкрд░ рд╡рд┐рд╖рдп рдФрд░ рдЦреЛрдЬ рдлрд╝рд┐рд▓реНрдЯрд░ рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░ рд╕рдХрддреЗ рд╣реИрдВ рдЬреИрд╕реЗ рдкреНрд░рдХрд╛рд╢рди рд╕реНрдерд╛рди, рд╕рдордпрд╛рд╡рдзрд┐ рдФрд░ рд╡рд┐рд╖рдпред"
      },
      {
        "row": 70,
        "rowsha": "+jwjqBw9Cr+lRnmxUzCQ0SnVBfXYeJDycuYf/p0JJgg=",
        "originContent": "I started downloading texts for the second training run. I'm getting everything from Internet Archive and I've expanded the time period to 1800-1875. To get a diverse range of texts, you can use subject and search filters for publication location, time period and subjects on Internet Archive. ",
        "translatedContent": ""
      },
      {
        "row": 71,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "![Search Filters](https://raw.githubusercontent.com/haykgrigo3/TimeCapsuleLLM/main/searchfilter.jpg)"
      },
      {
        "row": 72,
        "rowsha": "XE9Xts6Q8wsZVZHg8uD/1ZXBQ/j2uFLsR9HwsiaqMds=",
        "originContent": "![Search Filters](https://raw.githubusercontent.com/haykgrigo3/TimeCapsuleLLM/main/searchfilter.jpg)",
        "translatedContent": ""
      },
      {
        "row": 73,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "## 16 рдЬреБрд▓рд╛рдИ, 2025"
      },
      {
        "row": 74,
        "rowsha": "iREIjirFxs+ic0QmjQG1FQYKHC5brQaZ5JjPaEto+lU=",
        "originContent": "## July 16th, 2025",
        "translatedContent": ""
      },
      {
        "row": 75,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "рдореИрдВрдиреЗ Internet Archive рд╕реЗ рд▓рдЧрднрдЧ 500 txt рдлрд╛рдЗрд▓реЗрдВ рдбрд╛рдЙрдирд▓реЛрдб рдХреАрдВ рдФрд░ рдЙрдиреНрд╣реЗрдВ рд╕рд╛рдл рдХрд░рдиреЗ рдХреЗ рдмрд╛рдж (рд╕рд┐рд░реНрдл рд╡реНрд╣рд╛рдЗрдЯрд╕реНрдкреЗрд╕, рдЧреБрдЯреЗрдирдмрд░реНрдЧ рд╣реИрдбрд░ рдЖрджрд┐ рд╣рдЯрд╛рдХрд░) рдореЗрд░реЗ рдкрд╛рд╕ рд▓рдЧрднрдЧ 500MB рдбреЗрдЯрд╛ рдмрдЪрд╛ рд╣реИред рдпрд╣ рдПрдХ рдЫреЛрдЯрд╛ рд╕рд╛ рдбреЗрдЯрд╛рд╕реЗрдЯ рд╣реИ рд▓реЗрдХрд┐рди рдкрд┐рдЫрд▓реА рдмрд╛рд░ рдореИрдВрдиреЗ 187MB рд╕реЗ рдкреНрд░рд╢рд┐рдХреНрд╖рдг рд▓рд┐рдпрд╛ рдерд╛, рддреЛ рдкреНрд░рд╢рд┐рдХреНрд╖рдг рдХреЗ рдмрд╛рдж рдЖрдЙрдЯрдкреБрдЯ рдореЗрдВ рдХреБрдЫ рди рдХреБрдЫ рдЙрд▓реНрд▓реЗрдЦрдиреАрдп рдЕрдВрддрд░ рд╣реЛрдирд╛ рдЪрд╛рд╣рд┐рдПред рдореБрдЭреЗ рдЙрдореНрдореАрдж рд╣реИ рдХрд┐ рдпрд╣ рдореЙрдбрд▓ рдХрдо рд╕реЗ рдХрдо рдЕрдзрд┐рдХ рд╕реБрд╕рдВрдЧрдд рд╡рд╛рдХреНрдп рдЙрддреНрдкрдиреНрди рдХрд░ рд╕рдХреЗрдЧрд╛ рдЬреЛ рдХреБрдЫ рд╣рдж рддрдХ рдЕрд░реНрдердкреВрд░реНрдг рд╣реЛрдВред рдмреЗрд╢рдХ рдпрд╣ рдХреЛрдИ рдЧрд╛рд░рдВрдЯреА рдирд╣реАрдВ рд╣реИ рдХреНрдпреЛрдВрдХрд┐ рдпрд╣ рдЕрднреА рднреА рдПрдХ рдмрд╣реБрдд рд╣реА рдЫреЛрдЯрд╛ рдбреЗрдЯрд╛рд╕реЗрдЯ рд╣реИ, рд▓реЗрдХрд┐рди рдпрд╣ рдкрд┐рдЫрд▓реА рдмрд╛рд░ рд╕реЗ рдЕрдзрд┐рдХ рд╣реИред"
      },
      {
        "row": 76,
        "rowsha": "c1Ww8CUkqpg5TNm17QY7m130dQycuSFaAia2gfx/uLw=",
        "originContent": "I downloaded around 500 txt files from Internet Archive and after cleaning them (just deleting whitespaces, Gutenberg headers, etc) I have around 500MB of data. It's a tiny dataset but last time I trained off of 187MB so there should be at least some kind of noticable difference in the output after I train the second model. I'm hoping this model can at least produce more coherent sentences that kind of make sense. It's not a guarantee of course since this is still a tiny tiny dataset, but it's more than what I used last time. ",
        "translatedContent": ""
      },
      {
        "row": 77,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "рдпрд╣ рдореЗрд░реЗ рдЕрдкрдиреЗ рд╣рд╛рд░реНрдбрд╡реЗрдпрд░ рдкрд░ рд╕рдВрднрд╡ рд╣реЛрдирд╛ рдЪрд╛рд╣рд┐рдП, рдпрд╣ рдЕрдЪреНрдЫрд╛ рднреА рд╣реИ рдХреНрдпреЛрдВрдХрд┐ рдореИрдВ рдХрд┐рд╕реА рдмрдбрд╝реЗ рдбреЗрдЯрд╛рд╕реЗрдЯ рдкрд░ рдЬрд╛рдиреЗ рд╕реЗ рдкрд╣рд▓реЗ рдХреБрдЫ рд╕реБрдзрд╛рд░ рджреЗрдЦ рд╕рдХреВрдВ, рдЬрд┐рд╕рдореЗрдВ рдореБрдЭреЗ GPU рдХрд┐рд░рд╛рдП рдкрд░ рд▓реЗрдирд╛ рдкрдбрд╝реЗрдЧрд╛ред рд▓реЗрдХрд┐рди рдЪрд┐рдВрддрд╛ рди рдХрд░реЗрдВ рдореИрдВ рдЬрд▓реНрдж рд╣реА GPU рдХрд┐рд░рд╛рдП рдкрд░ рд▓реЗрдиреЗ рдХреА рдпреЛрдЬрдирд╛ рдмрдирд╛ рд░рд╣рд╛ рд╣реВрдВ, рд▓реЗрдХрд┐рди рдЗрд╕рд╕реЗ рдкрд╣рд▓реЗ рдореИрдВ рдЪрд╛рд╣реВрдВрдЧрд╛ рдХрд┐ рдореЗрд░рд╛ рдбреЗрдЯрд╛рд╕реЗрдЯ рдЬрд┐рддрдирд╛ рд╣реЛ рд╕рдХреЗ рдЙрддрдирд╛ рд╕рдВрдХрд▓рд┐рдд рдФрд░ рд╕рд╛рдл рд╣реЛред рдореЗрд░реА рдПрдХ рд╕рдорд╕реНрдпрд╛ рд╕рдлрд╛рдИ рд╣реИ, рдЗрди txt рдлрд╛рдЗрд▓реЛрдВ рдореЗрдВ рдмрд╣реБрдд рд╕рд╛рд░рд╛ рдмреЗрдорддрд▓рдм рдХрд╛ рдХрдВрдЯреЗрдВрдЯ рдорд┐рд▓рд╛ рд╣реЛрддрд╛ рд╣реИред рдореИрдВрдиреЗ рд╕рдлрд╛рдИ рдХреЗ рд▓рд┐рдП рдЬреЛ рд╕реНрдХреНрд░рд┐рдкреНрдЯреНрд╕ рдЗрд╕реНрддреЗрдорд╛рд▓ рдХреА рд╣реИрдВ рд╡реЗ рдХрд╛рдо рдХрд░рддреА рд╣реИрдВ рд▓реЗрдХрд┐рди 100% рдкреНрд░рднрд╛рд╡реА рдирд╣реАрдВ рд╣реИрдВред"
      },
      {
        "row": 78,
        "rowsha": "h/hyxvgOlOm5er9sn3CL2wmktMoq2q+qZi5Vi7upXGI=",
        "originContent": "This should be doable on my own hardware, it's good too because I can hopefully see some kind of improvements before I jump to a bigger dataset which would require me to rent a GPU. But don't worry I still plan on renting a GPU soon, but before I do that I wanna make sure my dataset is as curated and clean as possible. One of the issues I have is cleaning, a lot of these txt files have gibberish mixed in. The scripts I've used for cleaning do work but they're not 100% effective. ",
        "translatedContent": ""
      },
      {
        "row": 79,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "рдореИрдВ рдЖрдЬ рд╣реА рдЗрд╕ рдбреЗрдЯрд╛рд╕реЗрдЯ рдХреЛ рдкреНрд░рд╢рд┐рдХреНрд╖рд┐рдд рдХрд░реВрдВрдЧрд╛ рдФрд░ рдЗрд╕рдореЗрдВ рд▓рдЧрднрдЧ 4-5 рдШрдВрдЯреЗ рд▓рдЧрдиреЗ рдЪрд╛рд╣рд┐рдПред рдЬрдм рдпрд╣ рд╣реЛ рдЬрд╛рдПрдЧрд╛ рдФрд░ рдореИрдВ рдЗрд╕рдХрд╛ рдкрд░реАрдХреНрд╖рдг рдХрд░реВрдВрдЧрд╛, рддреЛ рдЕрдкрдбреЗрдЯ рджреВрдВрдЧрд╛ред рдореЗрд░реЗ рдкреНрд░реЛрдЬреЗрдХреНрдЯ рдХреЛ рджреЗрдЦрдиреЗ рдХреЗ рд▓рд┐рдП рд╕рднреА рдХрд╛ рдзрдиреНрдпрд╡рд╛рдж, рдореБрдЭреЗ рдХреБрдЫ рд▓реЛрдЧреЛрдВ рдиреЗ OCR рд╕рдВрд╕рд╛рдзрдиреЛрдВ рдХреЗ рд▓рд┐рдВрдХ рднреА рджрд┐рдП рд╣реИрдВ, рдЗрд╕рдХреЗ рд▓рд┐рдП рднреА рдзрдиреНрдпрд╡рд╛рдж! рдореБрдЭреЗ рдЙрдореНрдореАрдж рд╣реИ рдХрд┐ рдФрд░ рд▓реЛрдЧ рдЗрд╕реЗ рдЖрдЬрдорд╛рдПрдВ рдФрд░ рдЕрдкрдиреЗ-рдЕрдкрдиреЗ рдбреЗрдЯрд╛рд╕реЗрдЯ рдХреЗ рд╕рд╛рде рдкреНрд░рдпреЛрдЧ рдХрд░реЗрдВред"
      },
      {
        "row": 80,
        "rowsha": "8LYxYjHwrXnU59N+13Fd9m653Tgyom3yQQAWGIrSPSc=",
        "originContent": "I will train this dataset today and it should take around 4-5 hours. Once it's done and I test it, I will give updates. Thank you again to everyone whos checking out my project, I've even had some people even giving me links to OCR resources so Thank you! I hope more people try this out and expirement with they're own datasets. ",
        "translatedContent": ""
      },
      {
        "row": 81,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 82,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "### рдкреНрд░рд╢рд┐рдХреНрд╖рдг рдЕрдкрдбреЗрдЯ"
      },
      {
        "row": 83,
        "rowsha": "mNjt3ebwxfwyPM2/AK7E/GDTFM6i95HG8GZ/8TZs9EA=",
        "originContent": "### Training Update ",
        "translatedContent": ""
      },
      {
        "row": 84,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "рдореИрдВрдиреЗ 435MB (108 рдорд┐рд▓рд┐рдпрди рдЯреЛрдХрди) рдХреЙрд░реНрдкрд╕ рдкрд░ рдкреНрд░рд╢рд┐рдХреНрд╖рдг рд╢реБрд░реВ рдХрд┐рдпрд╛, рдпрд╣ рдЕрднреА рдХрд╛рдлреА рдЕрдЪреНрдЫрд╛ рдЪрд▓ рд░рд╣рд╛ рд╣реИред рдкрд╣рд▓реЗ 2800 рдЗрдЯрд░реЗрд╢рди рдореЗрдВ рдЯреНрд░реЗрди рд▓реЙрд╕ 10.9 рд╕реЗ рдШрдЯрдХрд░ 4.9 рд╣реЛ рдЧрдпрд╛ред рдореБрдЭреЗ рдЙрдореНрдореАрдж рд╣реИ рдХрд┐ рдкреВрд░рд╛ рд╣реЛрдиреЗ рдореЗрдВ рд▓рдЧрднрдЧ 8 рдпрд╛ 9 рдШрдВрдЯреЗ рд▓рдЧреЗрдВрдЧреЗред рдкреВрд░рд╛ рд╣реЛрдиреЗ рдХреЗ рдмрд╛рдж рдореИрдВ рдПрдХ рдФрд░ рдЕрдкрдбреЗрдЯ рдкреЛрд╕реНрдЯ рдХрд░реВрдВрдЧрд╛ред"
      },
      {
        "row": 85,
        "rowsha": "RxsWSGTgM12Md9v3+GBLg3PyoUxQ9kl1AglpanRmZqE=",
        "originContent": "I started training on a 435MB (108 M tokens) corpus, it's going pretty smooth right now. Train loss dropped from 10.9 to 4.9 in the first 2800 iterations. I expect it'll take around 8 or 9 hours to complete. I'll post another update once it's done.",
        "translatedContent": ""
      },
      {
        "row": 86,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "## 17 рдЬреБрд▓рд╛рдИ, 2025"
      },
      {
        "row": 87,
        "rowsha": "+KGe6w5lIW875VBdo8dnngqlaSzfoN0zFImo+SuVZ3k=",
        "originContent": "## July 17th, 2025",
        "translatedContent": ""
      },
      {
        "row": 88,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "рджреВрд╕рд░реЗ рдореЙрдбрд▓ рдХрд╛ рдкреНрд░рд╢рд┐рдХреНрд╖рдг рдкреВрд░рд╛ рд╣реЛ рдЧрдпрд╛ рд╣реИ, рдореЗрд░реЗ 4060 рдиреЗ рд▓рдЧрднрдЧ 8 рдШрдВрдЯреЗ 40 рдорд┐рдирдЯ (3,900 рдЗрдЯрд░реЗрд╢рди/рдШрдВрдЯрд╛) рдореЗрдВ 33,000 рдЗрдЯрд░реЗрд╢рди (5 рдИрдкреЛрдХреНрд╕) рдкреВрд░реЗ рдХрд┐рдПред рдЕрдВрддрд┐рдо рдЯреНрд░реЗрди рд▓реЙрд╕ 3.73 рдерд╛ред рдЖрдЙрдЯрдкреБрдЯ рдЖрд╢реНрдЪрд░реНрдпрдЬрдирдХ рд░реВрдк рд╕реЗ рдЕрдЪреНрдЫреЗ рдереЗ, рдЕрдм рдпрд╣ рд╕рдЪ рдореЗрдВ 19рд╡реАрдВ рд╕рджреА рдХреА рд╢реИрд▓реА рдХреЗ рд╕реБрд╕рдВрдЧрдд рд╡рд╛рдХреНрдп рдЙрддреНрдкрдиреНрди рдХрд░рддрд╛ рд╣реИред"
      },
      {
        "row": 89,
        "rowsha": "Q0uM34dBNqytALNUZSPxoBQZT3LxqlwyioEi3nTshXQ=",
        "originContent": "The training is done for the second model, it took my 4060 around 8 hours and 40 minutes (3,900 iters/hr) for 33,000 iters (5 epochs). Final train loss was 3.73. The outputs were suprisingly good it genuinely generates coherent 19th century style sentences now. ",
        "translatedContent": ""
      },
      {
        "row": 90,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "## 28 рдЬреБрд▓рд╛рдИ, 2025"
      },
      {
        "row": 91,
        "rowsha": "13xzxThQO3iEGB5PU51V1kYgK85//yEFbCkwtu07a2U=",
        "originContent": "## July 28th, 2025 ",
        "translatedContent": ""
      },
      {
        "row": 92,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "рдореИрдВрдиреЗ v0.5 рдХреЛ Hugging Face рдкрд░ рдЕрдкрд▓реЛрдб рдХрд░ рджрд┐рдпрд╛ рд╣реИ, [рдпрд╣рд╛рдВ рджреЗрдЦреЗрдВ](https://huggingface.co/haykgrigorian/TimeCapsuleLLM) рдЕрдЧрд░ рдЖрдк рдЪрд╛рд╣реЗрдВред рдЕрдм рдЖрдк рдореЗрд░рд╛ рд░рд┐рдкреЙрдЬрд┐рдЯрд░реА рдбрд╛рдЙрдирд▓реЛрдб рдХрд░ рд╕рдХрддреЗ рд╣реИрдВ рдФрд░ рдЗрд╕реЗ рд▓реЛрдХрд▓реА рдЪрд▓рд╛ рд╕рдХрддреЗ рд╣реИрдВред рджреБрд░реНрднрд╛рдЧреНрдпрд╡рд╢ nanoGPT HuggingFace рдХреЗ рд╕рд╛рде рд╕реАрдзреЗ рдХрд╛рдо рдирд╣реАрдВ рдХрд░рддрд╛, рдЗрд╕рд▓рд┐рдП рдЖрдкрдХреЛ рдореЙрдбрд▓ рдбрд╛рдЙрдирд▓реЛрдб рдХрд░рдХреЗ рд▓реЛрдХрд▓реА рдЪрд▓рд╛рдирд╛ рд╣реЛрдЧрд╛ред"
      },
      {
        "row": 93,
        "rowsha": "R6HmXRpR+7izGCE6kI9wyELs4kYvAtLMWO75nOXAf1M=",
        "originContent": "I've gone ahead and uploaded v0.5 to Hugging Face, [Check it out](https://huggingface.co/haykgrigorian/TimeCapsuleLLM) if youd like. You can now download my repo and run it locally. Unfortunately nanoGPT doesn't work natively with HuggingFace, so you'll have to download and run the model locally. ",
        "translatedContent": ""
      },
      {
        "row": 94,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "рд╕рд╛рде рд╣реА, рдореИрдВ рдЕрдкрдиреЗ рдЕрдЧрд▓реЗ рдкреНрд░рд╢рд┐рдХреНрд╖рдг рд░рди рдХреЗ рд▓рд┐рдП рдбреЗрдЯрд╛ рд╕рдВрдХрд▓рд┐рдд рдХрд░рдирд╛ рд╢реБрд░реВ рдХрд░реВрдВрдЧрд╛, рдореБрдЭреЗ рд▓рдЧрддрд╛ рд╣реИ рдХрд┐ рддрд░реНрдХ рдХреНрд╖рдорддрд╛ рд╣рд╛рд╕рд┐рд▓ рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП рд╢рд╛рдпрдж 5-10 рдЧреБрдирд╛ рдЕрдзрд┐рдХ рдбреЗрдЯрд╛ рдЪрд╛рд╣рд┐рдП рд╣реЛрдЧрд╛ред"
      },
      {
        "row": 95,
        "rowsha": "3/uUOOHuCoxdKkQ6c+1J96AfmOsQ59aZxo/FYGK9OlI=",
        "originContent": "Also I will begin curating data for my next training run, I believe I'll need maybe 5-10x more data to achieve reasoning capabilities. ",
        "translatedContent": ""
      },
      {
        "row": 96,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "## 2 рдЕрдЧрд╕реНрдд, 2025"
      },
      {
        "row": 97,
        "rowsha": "UXyL9heEocaX5oRp2rVKQgcRB28wVdVl+Kl7/DqbKLc=",
        "originContent": "## August 2nd, 2025",
        "translatedContent": ""
      },
      {
        "row": 98,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "рдореИрдВ рдЬрд▓реНрдж рд╣реА Version 1 рдкрд░ рдХрд╛рдо рд╢реБрд░реВ рдХрд░рдиреЗ рдЬрд╛ рд░рд╣рд╛ рд╣реВрдВред рдореБрдЭреЗ nanoGPT рдХреА рдЖрд░реНрдХрд┐рдЯреЗрдХреНрдЪрд░ рд╕реЗ рдХреБрдЫ рдЕрдзрд┐рдХ рдЖрдзреБрдирд┐рдХ рдкрд░ рд╕реНрд╡рд┐рдЪ рдХрд░рдирд╛ рд╣реЛрдЧрд╛ред рдореЗрд░реЗ рджрд┐рдорд╛рдЧ рдореЗрдВ рдХрдИ рдУрдкрди-рд╕реЛрд░реНрд╕ LLM рдЖрд░реНрдХрд┐рдЯреЗрдХреНрдЪрд░ рд╣реИрдВ, рдЬреИрд╕реЗ: OpenLLaMA v3, Phi-2 рдФрд░ Qwen 1.5Bред рдФрд░ V1 рдХреЗ рд▓рд┐рдП, рдореБрдЭреЗ рдФрд░ рдмрдбрд╝рд╛ рд╡ рд╡рд┐рд╡рд┐рдз рдбреЗрдЯрд╛рд╕реЗрдЯ рд╕рд╛рд╡рдзрд╛рдиреА рд╕реЗ рд╕рдВрдХрд▓рд┐рдд рдХрд░рдирд╛ рд╣реЛрдЧрд╛ред рдореБрдЭреЗ рдХрдо рд╕реЗ рдХрдо 5GB рд╕рд╛рдл рдкреНрд░рд╢рд┐рдХреНрд╖рдг рдбреЗрдЯрд╛ рдХреА рдЖрд╡рд╢реНрдпрдХрддрд╛ рд╣реЛрдЧреАред"
      },
      {
        "row": 99,
        "rowsha": "PTcIrGtJ33LlUO6TFsGwvV/mCnbcxmmcYIasCuuLx40=",
        "originContent": "I'm going to start work on Version 1 soon. I will need to transition from nanoGPT's architecture to soemthing more modern. I have several open-source LLM archictectures in mind, including: OpenLLaMA v3, Phi-2 and Qwen 1.5B. And to support the jump to V1, I'll need to carefully curate a much bigger and diverse dataset. I'll need at least 5GB of clean training data.",
        "translatedContent": ""
      },
      {
        "row": 100,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 2,
    "Content": "# V0 Model Behavior & Limitations \n\nEarly prompts show the model responding with 1800's language and behavior. For example, I prompted it with \"Who art Henry?\" and it replied \"I know that man, I have did not a black, the storm.\" and yeah that sentence makes no sense but the LLM is recognizing I'm asking about a person. \n\n![TimeLockLLM Sample Output](https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1850_v0/timelockllm_sample_output.png?raw=true)\n\nThere is no mention of modern concetps, outputs contain mostly words and phrasing from the 1800's.\n\nIt still needs alot of work, training off of 187MB will not give you a model that produces text with complex reasoning. \n\nRight now it produces sentences that lack full sentence structure and overall just make no sense but this is normal for the training size. \n\n# V0.5 Model Behavior & Limitations\n\nThis is a nice improvement compared to the last model. The writing style and vocab is Victorian and almost every sentence is grammatically correct with proper punctuation. And again this is trained from scratch so it sticks to 1800's subjects. \n\n![TimeLockLLM Sample Output](https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1875_v0.5/fellowcitizens.png?raw=true)\n\nThere are a lot of factual hallucinations. A lot (like 100%) of the details (dates, events, historical figures)  are made up. Also the sentences don't really have connections to each other, sometimes maybe 2 sentences will relate to each other but beyond that they dont. Another issue is sometimes a stray тАЬDigitized by GoogleтАЭ footer shows up, so the next time I train I really have to make sure the texts are cleaned well. Overall I'm very happy with the results, it's nowhere near an LLM yet but definitely a sentence generator. \n\nI'm learning a lot and will start figuring out what I need to do better in the coming weeks. I will upload files soon! \n\n# Upcoming Plans \n\n(Completed) I'm going to start work on version 0.5 , instead of training using 50 books, I'll train using ideally 500-600. Right now I'm training nanoGPT using books from 1800-1850 and specifically from London. There is some challeneges like making sure the books I find are not updated or have modern interpretations but untouched books published withtin my chosen time period.\n\nI want to train a new model (v1) with a much larger corpus, maybe 5-10x larger than the one I used for v0.5. My goal is to see if I can get reasoning abilities to emerge from Selective Temporal Training alone, this will be a more difficult task and I'm not even entirely sure if it's possible due to the fact that there is historical data limitations. In the upcoming weeks I will try to curate enough data for a 5-10GB corpus. I believe If I can get clean clean high quality data and rent a GPU, there will be progress.\n\n# How to Use This Project \n\nThis project focuses mostly on curating historical data, preparing it for training and building a tokenizer. I am not going to cover the full LLM training process, for that refer to nanoGPT by Andrej Karpathy.\n\n# Step 1: Gather and Prepare Historical Texts \n\nCollect .txt files of public domain books, documents, etc from your chosen time period (e.g., London 1800-1850)\n\nYou can use download_texts_improved.py to download books for you if you need to.\n\nClean the text files using a script or manually remove headers/footer from Project Gutenberg, Modern annotations or things like OCR errors.\n\nprepare_dataset.py should work fine.\n\n# Step 2: Build a Custom Tokenizer\n\nRun train_tokenizer.py or train_tokenizer_hf.py on the cleaned data.\nThis will give you vocab.json and merges.txt\n\nThes files define vocab and merge rules for your model\n\n# Step 3: Train Your Model (nanoGPT) \n\nRefer to [nanoGPT by Andrej Karpathy](https://github.com/karpathy/nanoGPT) for the training process.\n\nYou can train a different LLM if you want, but I used nanoGPT \n\n# FAQ\n\n## What is Selective Temporal Training ?\n\nSelective Temporal Training (STT) is a machine learning methodology where all training data is specifically curated to fall within a specific historical time period. It's done in order to model the language and knowledge of that era without influence from modern concepts. For example, the current model I have now (v0.5) is trained on data exclusively from 1800-1875, it's not fine tuned but trained from scratch resulting in output that reflects the linguistic style and historical context of that time period.\n\n## Why not just use fine-tuning or LoRA?\n\nFor this project I'm trying to create a language model that is unclouded from modern bias. If I fine-tune something like GPT-2, it's already pre-trained and that information won't go away. If I train from scratch the language model won't pretend to be old, it just will be. The Goal for this project right now is to create something can reason exclusively using knowledge from London books published between 1800 and 1850.\n\n## What kind of data did you use for training?\n\nI'm using books, legal documents, newspapers, and other writings from 1800тАУ1850 London. The list I linked has like 200 but for the first training I just used 50 files about ~187 MB. You can view a list of the documents:\nhttps://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/Copy%20of%20London%20Documents%20for%20Time%20Capsule%20LLM.txt\n\n## How large is the Version 0 model ?\n\nThis model is very small right now, I'm just doing this for fun and following a strict training rule of no modern sources. It has almost 16 million parameters but I'm gonna start gathering more old texts to begin another model training. Will give updates as I go.\n\n## Training Specs ? \n\nGPU: Geforce rtx 4060\nCPU: i5-13400F \nRam: 16GB DDR5.\n\n",
    "ContentSha": "1O9bISPjfcAedK04vF2sjVw9/KhuDIsXO+LMoNirAto=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "# V0 рдореЙрдбрд▓ рд╡реНрдпрд╡рд╣рд╛рд░ рдФрд░ рд╕реАрдорд╛рдПрдБ\n\nрдкреНрд░рд╛рд░рдВрднрд┐рдХ рдкреНрд░реЙрдореНрдкреНрдЯреНрд╕ рдореЗрдВ рдореЙрдбрд▓ 1800 рдХреЗ рджрд╢рдХ рдХреА рднрд╛рд╖рд╛ рдФрд░ рд╡реНрдпрд╡рд╣рд╛рд░ рдореЗрдВ рдкреНрд░рддрд┐рдХреНрд░рд┐рдпрд╛ рджреЗрддрд╛ рд╣реИред рдЙрджрд╛рд╣рд░рдг рдХреЗ рд▓рд┐рдП, рдореИрдВрдиреЗ рдЗрд╕реЗ \"Who art Henry?\" рдкреВрдЫрд╛ рдФрд░ рдЗрд╕рдиреЗ рдЙрддреНрддрд░ рджрд┐рдпрд╛ \"I know that man, I have did not a black, the storm.\" рдФрд░ рд╣рд╛рдБ, рдЙрд╕ рд╡рд╛рдХреНрдп рдХрд╛ рдХреЛрдИ рдЕрд░реНрде рдирд╣реАрдВ рд╣реИ рд▓реЗрдХрд┐рди LLM рд╕рдордЭ рд░рд╣рд╛ рд╣реИ рдХрд┐ рдореИрдВ рдХрд┐рд╕реА рд╡реНрдпрдХреНрддрд┐ рдХреЗ рдмрд╛рд░реЗ рдореЗрдВ рдкреВрдЫ рд░рд╣рд╛ рд╣реВрдБред\n\n![TimeLockLLM Sample Output](https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1850_v0/timelockllm_sample_output.png?raw=true)\n\nрдпрд╣рд╛рдБ рдЖрдзреБрдирд┐рдХ рдЕрд╡рдзрд╛рд░рдгрд╛рдУрдВ рдХрд╛ рдХреЛрдИ рдЙрд▓реНрд▓реЗрдЦ рдирд╣реАрдВ рд╣реИ, рдЖрдЙрдЯрдкреБрдЯ рдореЗрдВ рдЕрдзрд┐рдХрд╛рдВрд╢ рд╢рдмреНрдж рдФрд░ рд╡рд╛рдХреНрдпрд╛рдВрд╢ 1800 рдХреЗ рджрд╢рдХ рдХреЗ рд╣реИрдВред\n\nрдЗрд╕реЗ рдЕрднреА рднреА рдмрд╣реБрдд рдХрд╛рдо рдХреА рдЬрд░реВрд░рдд рд╣реИ, 187MB рдбреЗрдЯрд╛ рд╕реЗ рдЯреНрд░реЗрдирд┐рдВрдЧ рдХрд░рдиреЗ рд╕реЗ рдЖрдкрдХреЛ рдЬрдЯрд┐рд▓ рддрд░реНрдХ рд╡рд╛рд▓реА рдЯреЗрдХреНрд╕реНрдЯ рдЙрддреНрдкрдиреНрди рдХрд░рдиреЗ рд╡рд╛рд▓рд╛ рдореЙрдбрд▓ рдирд╣реАрдВ рдорд┐рд▓реЗрдЧрд╛ред\n\nрдЕрднреА рдпрд╣ рдРрд╕реЗ рд╡рд╛рдХреНрдп рдмрдирд╛рддрд╛ рд╣реИ рдЬрд┐рдирдореЗрдВ рдкреВрд░реА рд╡рд╛рдХреНрдп рд╕рдВрд░рдЪрдирд╛ рдирд╣реАрдВ рд╣реЛрддреА рдФрд░ рдХреБрд▓ рдорд┐рд▓рд╛рдХрд░ рдХреЛрдИ рдЕрд░реНрде рдирд╣реАрдВ рдмрдирддрд╛, рд▓реЗрдХрд┐рди рдпрд╣ рдЗрд╕ рдЯреНрд░реЗрдирд┐рдВрдЧ рд╕рд╛рдЗрдЬ рдХреЗ рд▓рд┐рдП рд╕рд╛рдорд╛рдиреНрдп рд╣реИред\n\n# V0.5 рдореЙрдбрд▓ рд╡реНрдпрд╡рд╣рд╛рд░ рдФрд░ рд╕реАрдорд╛рдПрдБ\n\nрдпрд╣ рдкрд┐рдЫрд▓реЗ рдореЙрдбрд▓ рдХреА рддреБрд▓рдирд╛ рдореЗрдВ рдЕрдЪреНрдЫрд╛ рд╕реБрдзрд╛рд░ рд╣реИред рд▓реЗрдЦрди рд╢реИрд▓реА рдФрд░ рд╢рдмреНрджрд╛рд╡рд▓реА рд╡рд┐рдХреНрдЯреЛрд░рд┐рдпрди рд╣реИ рдФрд░ рд▓рдЧрднрдЧ рд╣рд░ рд╡рд╛рдХреНрдп рд╡реНрдпрд╛рдХрд░рдгрд┐рдХ рд░реВрдк рд╕реЗ рд╕рд╣реА рд╣реИ рдФрд░ рдЙрдЪрд┐рдд рд╡рд┐рд░рд╛рдо рдЪрд┐рд╣реНрдиреЛрдВ рдХреЗ рд╕рд╛рде рд╣реИред рдФрд░ рдлрд┐рд░, рдпрд╣ рд╢реБрд░реВ рд╕реЗ рдЯреНрд░реЗрди рдХрд┐рдпрд╛ рдЧрдпрд╛ рд╣реИ рдЗрд╕рд▓рд┐рдП рдпрд╣ 1800 рдХреЗ рджрд╢рдХ рдХреЗ рд╡рд┐рд╖рдпреЛрдВ рддрдХ рд╣реА рд╕реАрдорд┐рдд рд░рд╣рддрд╛ рд╣реИред\n\n![TimeLockLLM Sample Output](https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1875_v0.5/fellowcitizens.png?raw=true)\n\nрдпрд╣рд╛рдБ рдмрд╣реБрдд рд╕рд╛рд░реА рддрдереНрдпреЛрдВ рдХреА рдХрд▓реНрдкрдирд╛рдПрдБ рд╣реИрдВред рдЕрдзрд┐рдХрд╛рдВрд╢ (рд▓рдЧрднрдЧ 100%) рд╡рд┐рд╡рд░рдг (рддрд┐рдерд┐рдпрд╛рдБ, рдШрдЯрдирд╛рдПрдБ, рдРрддрд┐рд╣рд╛рд╕рд┐рдХ рд╡реНрдпрдХреНрддрд┐) рдХрд╛рд▓реНрдкрдирд┐рдХ рд╣реИрдВред рдЗрд╕рдХреЗ рдЕрд▓рд╛рд╡рд╛ рд╡рд╛рдХреНрдп рдЖрдкрд╕ рдореЗрдВ рдЬреБрдбрд╝рддреЗ рдирд╣реАрдВ рд╣реИрдВ, рдХрднреА-рдХрднреА рд╢рд╛рдпрдж 2 рд╡рд╛рдХреНрдп рдЬреБрдбрд╝реЗ рд╣реБрдП рд▓рдЧ рд╕рдХрддреЗ рд╣реИрдВ рд▓реЗрдХрд┐рди рдЙрд╕рд╕реЗ рдЖрдЧреЗ рдирд╣реАрдВред рдПрдХ рдФрд░ рд╕рдорд╕реНрдпрд╛ рд╣реИ рдХрд┐ рдХрднреА-рдХрднреА тАЬDigitized by GoogleтАЭ рдлреБрдЯрд░ рдЖ рдЬрд╛рддрд╛ рд╣реИ, рддреЛ рдЕрдЧрд▓реА рдмрд╛рд░ рдореБрдЭреЗ рдЯреНрд░реЗрдирд┐рдВрдЧ рд╕реЗ рдкрд╣рд▓реЗ рдЯреЗрдХреНрд╕реНрдЯ рдХреЛ рдЕрдЪреНрдЫреЗ рд╕реЗ рд╕рд╛рдлрд╝ рдХрд░рдирд╛ рд╣реЛрдЧрд╛ред рдХреБрд▓ рдорд┐рд▓рд╛рдХрд░ рдореИрдВ рдкрд░рд┐рдгрд╛рдореЛрдВ рд╕реЗ рдмрд╣реБрдд рдЦреБрд╢ рд╣реВрдБ, рдпрд╣ LLM рдХреЗ рд╕реНрддрд░ рдкрд░ рдирд╣реАрдВ рд╣реИ рд▓реЗрдХрд┐рди рдирд┐рд╢реНрдЪрд┐рдд рд░реВрдк рд╕реЗ рдПрдХ рд╡рд╛рдХреНрдп рдЬрдирд░реЗрдЯрд░ рд╣реИред\n\nрдореИрдВ рдмрд╣реБрдд рдХреБрдЫ рд╕реАрдЦ рд░рд╣рд╛ рд╣реВрдБ рдФрд░ рдЖрдиреЗ рд╡рд╛рд▓реЗ рд╣рдлреНрддреЛрдВ рдореЗрдВ рдкрддрд╛ рдХрд░реВрдВрдЧрд╛ рдХрд┐ рдореБрдЭреЗ рдХреНрдпрд╛ рдмреЗрд╣рддрд░ рдХрд░рдирд╛ рд╣реИред рдореИрдВ рдЬрд▓реНрдж рд╣реА рдлрд╛рдЗрд▓реЗрдВ рдЕрдкрд▓реЛрдб рдХрд░реВрдВрдЧрд╛!\n\n# рдЖрдЧрд╛рдореА рдпреЛрдЬрдирд╛рдПрдБ\n\n(рдкреВрд░рд╛ рд╣реБрдЖ) рдореИрдВ рд╡рд░реНрд╢рди 0.5 рдкрд░ рдХрд╛рдо рд╢реБрд░реВ рдХрд░рдиреЗ рдЬрд╛ рд░рд╣рд╛ рд╣реВрдБ, 50 рдХрд┐рддрд╛рдмреЛрдВ рдХреА рдЬрдЧрд╣ рдореИрдВ рдЖрджрд░реНрд╢ рд░реВрдк рд╕реЗ 500-600 рдХрд┐рддрд╛рдмреЛрдВ рд╕реЗ рдЯреНрд░реЗрди рдХрд░реВрдВрдЧрд╛ред рдЕрднреА рдореИрдВ nanoGPT рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рдХреЗ 1800-1850 рдХреА рдХрд┐рддрд╛рдмреЗрдВ рдЯреНрд░реЗрди рдХрд░ рд░рд╣рд╛ рд╣реВрдБ, рдФрд░ рдЦрд╛рд╕рдХрд░ рд▓рдВрджрди рд╕реЗред рдЗрд╕рдореЗрдВ рдХреБрдЫ рдЪреБрдиреМрддрд┐рдпрд╛рдБ рд╣реИрдВ рдЬреИрд╕реЗ рдпрд╣ рд╕реБрдирд┐рд╢реНрдЪрд┐рдд рдХрд░рдирд╛ рдХрд┐ рдЬреЛ рдХрд┐рддрд╛рдмреЗрдВ рдореБрдЭреЗ рдорд┐рд▓реЗрдВ рд╡реЗ рдЕрдкрдбреЗрдЯреЗрдб рдпрд╛ рдЖрдзреБрдирд┐рдХ рд╡реНрдпрд╛рдЦреНрдпрд╛рдУрдВ рд╡рд╛рд▓реА рди рд╣реЛрдВ рдмрд▓реНрдХрд┐ рдореЗрд░реА рдЪреБрдиреА рд╣реБрдИ рд╕рдордп рд╕реАрдорд╛ рдХреЗ рднреАрддрд░ рдкреНрд░рдХрд╛рд╢рд┐рдд рдЕрд╕рдВрдкрд╛рджрд┐рдд рдХрд┐рддрд╛рдмреЗрдВ рд╣реЛрдВред\n\nрдореИрдВ рдПрдХ рдирдпрд╛ рдореЙрдбрд▓ (v1) рдПрдХ рдмрдбрд╝реЗ рдХреЙрд░реНрдкрд╕ рдХреЗ рд╕рд╛рде рдЯреНрд░реЗрди рдХрд░рдирд╛ рдЪрд╛рд╣рддрд╛ рд╣реВрдБ, рд╢рд╛рдпрдж v0.5 рдХреЗ рдореБрдХрд╛рдмрд▓реЗ 5-10 рдЧреБрдирд╛ рдмрдбрд╝рд╛ред рдореЗрд░рд╛ рд▓рдХреНрд╖реНрдп рд╣реИ рдХрд┐ рдХреНрдпрд╛ рдХреЗрд╡рд▓ Selective Temporal Training рд╕реЗ рддрд░реНрдХ рдХреНрд╖рдорддрд╛рдПрдБ рдЙрддреНрдкрдиреНрди рд╣реЛ рд╕рдХрддреА рд╣реИрдВ, рдпрд╣ рдЕрдзрд┐рдХ рдХрдард┐рди рдХрд╛рд░реНрдп рд╣реЛрдЧрд╛ рдФрд░ рдореИрдВ рдкреВрд░реА рддрд░рд╣ рдирд┐рд╢реНрдЪрд┐рдд рдирд╣реАрдВ рд╣реВрдБ рдХрд┐ рдпрд╣ рдРрддрд┐рд╣рд╛рд╕рд┐рдХ рдбреЗрдЯрд╛ рд╕реАрдорд╛рдУрдВ рдХреЗ рдХрд╛рд░рдг рд╕рдВрднрд╡ рд╣реИ рдпрд╛ рдирд╣реАрдВред рдЖрдиреЗ рд╡рд╛рд▓реЗ рд╣рдлреНрддреЛрдВ рдореЗрдВ рдореИрдВ 5-10GB рдХрд╛ рдХреЙрд░реНрдкрд╕ рддреИрдпрд╛рд░ рдХрд░рдиреЗ рдХреА рдХреЛрд╢рд┐рд╢ рдХрд░реВрдВрдЧрд╛ред рдореБрдЭреЗ рд╡рд┐рд╢реНрд╡рд╛рд╕ рд╣реИ рдХрд┐ рдпрджрд┐ рдореБрдЭреЗ рд╕рд╛рдл, рдЙрдЪреНрдЪ рдЧреБрдгрд╡рддреНрддрд╛ рд╡рд╛рд▓рд╛ рдбреЗрдЯрд╛ рдорд┐рд▓ рдЬрд╛рдП рдФрд░ GPU рдХрд┐рд░рд╛рдП рдкрд░ рд▓реЗ рд╕рдХреВрдВ, рддреЛ рдкреНрд░рдЧрддрд┐ рд╣реЛрдЧреАред\n\n# рдЗрд╕ рдкреНрд░реЛрдЬреЗрдХреНрдЯ рдХрд╛ рдЙрдкрдпреЛрдЧ рдХреИрд╕реЗ рдХрд░реЗрдВ\n\nрдпрд╣ рдкреНрд░реЛрдЬреЗрдХреНрдЯ рдореБрдЦреНрдп рд░реВрдк рд╕реЗ рдРрддрд┐рд╣рд╛рд╕рд┐рдХ рдбреЗрдЯрд╛ рдПрдХрддреНрд░ рдХрд░рдиреЗ, рдЙрд╕реЗ рдЯреНрд░реЗрдирд┐рдВрдЧ рдХреЗ рд▓рд┐рдП рддреИрдпрд╛рд░ рдХрд░рдиреЗ рдФрд░ рдЯреЛрдХрдирд╛рдЗрдЬрд╝рд░ рдмрдирд╛рдиреЗ рдкрд░ рдХреЗрдВрджреНрд░рд┐рдд рд╣реИред рдореИрдВ рдпрд╣рд╛рдБ рдкреВрд░реА LLM рдЯреНрд░реЗрдирд┐рдВрдЧ рдкреНрд░рдХреНрд░рд┐рдпрд╛ рдирд╣реАрдВ рдмрддрд╛рдКрдВрдЧрд╛, рдЙрд╕рдХреЗ рд▓рд┐рдП Andrej Karpathy рдХрд╛ nanoGPT рджреЗрдЦреЗрдВред\n\n# рдЪрд░рдг 1: рдРрддрд┐рд╣рд╛рд╕рд┐рдХ рдЧреНрд░рдВрде рдПрдХрддреНрд░рд┐рдд рдФрд░ рддреИрдпрд╛рд░ рдХрд░реЗрдВ\n\nрдЕрдкрдиреЗ рдЪреБрдиреЗ рд╣реБрдП рд╕рдордп рдЕрд╡рдзрд┐ (рдЬреИрд╕реЗ, рд▓рдВрджрди 1800-1850) рдХреЗ рд╕рд╛рд░реНрд╡рдЬрдирд┐рдХ рдбреЛрдореЗрди рдХреА рдХрд┐рддрд╛рдмреЗрдВ, рджрд╕реНрддрд╛рд╡реЗрдЬрд╝ рдЖрджрд┐ рдХреА .txt рдлрд╛рдЗрд▓реЗрдВ рдЗрдХрдЯреНрдард╛ рдХрд░реЗрдВред\n\nрдпрджрд┐ рдЖрд╡рд╢реНрдпрдХрддрд╛ рд╣реЛ рддреЛ рдЖрдк download_texts_improved.py рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рдХреЗ рдХрд┐рддрд╛рдмреЗрдВ рдбрд╛рдЙрдирд▓реЛрдб рдХрд░ рд╕рдХрддреЗ рд╣реИрдВред\n\nрдЯреЗрдХреНрд╕реНрдЯ рдлрд╛рдЗрд▓реЛрдВ рдХреЛ рд╕реНрдХреНрд░рд┐рдкреНрдЯ рдпрд╛ рдореИрдиреНрдпреБрдЕрд▓реА рд╕рд╛рдл рдХрд░реЗрдВ, рдЬреИрд╕реЗ рдкреНрд░реЛрдЬреЗрдХреНрдЯ рдЧреБрдЯреЗрдирдмрд░реНрдЧ рдХреЗ рд╣реЗрдбрд░/рдлреБрдЯрд░, рдЖрдзреБрдирд┐рдХ рдЯрд┐рдкреНрдкрдгрд┐рдпрд╛рдБ рдпрд╛ OCR рдХреА рдЧрд▓рддрд┐рдпрд╛рдБ рд╣рдЯрд╛рдПрдБред\n\nprepare_dataset.py рдареАрдХ рд╕реЗ рдХрд╛рдо рдХрд░рдирд╛ рдЪрд╛рд╣рд┐рдПред\n\n# рдЪрд░рдг 2: рдХрд╕реНрдЯрдо рдЯреЛрдХрдирд╛рдЗрдЬрд╝рд░ рдмрдирд╛рдПрдБ\n\nрд╕рд╛рдл рдХреА рдЧрдИ рдбреЗрдЯрд╛ рдкрд░ train_tokenizer.py рдпрд╛ train_tokenizer_hf.py рдЪрд▓рд╛рдПрдБред\nрдпрд╣ рдЖрдкрдХреЛ vocab.json рдФрд░ merges.txt рджреЗрдЧрд╛ред\n\nрдпреЗ рдлрд╛рдЗрд▓реЗрдВ рдЖрдкрдХреЗ рдореЙрдбрд▓ рдХреЗ рд▓рд┐рдП рд╢рдмреНрджрд╛рд╡рд▓реА рдФрд░ рдорд░реНрдЬ рдирд┐рдпрдо рдкрд░рд┐рднрд╛рд╖рд┐рдд рдХрд░рддреА рд╣реИрдВред\n\n# рдЪрд░рдг 3: рдЕрдкрдирд╛ рдореЙрдбрд▓ рдЯреНрд░реЗрди рдХрд░реЗрдВ (nanoGPT)\n\nрдЯреНрд░реЗрдирд┐рдВрдЧ рдкреНрд░рдХреНрд░рд┐рдпрд╛ рдХреЗ рд▓рд┐рдП [Andrej Karpathy рдХрд╛ nanoGPT](https://github.com/karpathy/nanoGPT) рджреЗрдЦреЗрдВред\n\nрдЕрдЧрд░ рдЪрд╛рд╣реЗрдВ рддреЛ рдЖрдк рдХреЛрдИ рдФрд░ LLM рдЯреНрд░реЗрди рдХрд░ рд╕рдХрддреЗ рд╣реИрдВ, рд▓реЗрдХрд┐рди рдореИрдВрдиреЗ nanoGPT рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд┐рдпрд╛ред\n\n# рд╕рд╛рдорд╛рдиреНрдп рдкреНрд░рд╢реНрди\n\n## Selective Temporal Training рдХреНрдпрд╛ рд╣реИ?\n\nSelective Temporal Training (STT) рдПрдХ рдорд╢реАрди рд▓рд░реНрдирд┐рдВрдЧ рдкрджреНрдзрддрд┐ рд╣реИ рдЬрд┐рд╕рдореЗрдВ рд╕рднреА рдЯреНрд░реЗрдирд┐рдВрдЧ рдбреЗрдЯрд╛ рд╡рд┐рд╢реЗрд╖ рд░реВрдк рд╕реЗ рдПрдХ рдирд┐рд╢реНрдЪрд┐рдд рдРрддрд┐рд╣рд╛рд╕рд┐рдХ рд╕рдордпрд╛рд╡рдзрд┐ рдХреЗ рднреАрддрд░ рдЪреБрдирд╛ рдЬрд╛рддрд╛ рд╣реИред рдЗрд╕рдХрд╛ рдЙрджреНрджреЗрд╢реНрдп рдЙрд╕ рдпреБрдЧ рдХреА рднрд╛рд╖рд╛ рдФрд░ рдЬреНрдЮрд╛рди рдХреЛ рдмрд┐рдирд╛ рдЖрдзреБрдирд┐рдХ рдкреНрд░рднрд╛рд╡ рдХреЗ рдореЙрдбрд▓ рдХрд░рдирд╛ рд╣реИред рдЙрджрд╛рд╣рд░рдг рдХреЗ рд▓рд┐рдП, рдореЗрд░рд╛ рд╡рд░реНрддрдорд╛рди рдореЙрдбрд▓ (v0.5) рдкреВрд░реА рддрд░рд╣ 1800-1875 рдХреА рдбреЗрдЯрд╛ рдкрд░ рдЯреНрд░реЗрди рд╣реИ, рдпрд╣ рдлрд╛рдЗрди рдЯреНрдпреВрди рдирд╣реАрдВ рдХрд┐рдпрд╛ рдЧрдпрд╛ рдмрд▓реНрдХрд┐ рд╢реБрд░реВ рд╕реЗ рдЯреНрд░реЗрди рд╣реИ, рдЬрд┐рд╕рд╕реЗ рдЖрдЙрдЯрдкреБрдЯ рдЙрд╕ рд╕рдордп рдХреА рднрд╛рд╖рд╛рд╢реИрд▓реА рдФрд░ рдРрддрд┐рд╣рд╛рд╕рд┐рдХ рд╕рдВрджрд░реНрдн рдХреЛ рджрд░реНрд╢рд╛рддрд╛ рд╣реИред\n\n## рдлрд╛рдЗрди-рдЯреНрдпреВрдирд┐рдВрдЧ рдпрд╛ LoRA рдХрд╛ рдЙрдкрдпреЛрдЧ рдХреНрдпреЛрдВ рдирд╣реАрдВ?\n\nрдЗрд╕ рдкреНрд░реЛрдЬреЗрдХреНрдЯ рдХреЗ рд▓рд┐рдП рдореИрдВ рдРрд╕рд╛ рднрд╛рд╖рд╛ рдореЙрдбрд▓ рдмрдирд╛рдирд╛ рдЪрд╛рд╣рддрд╛ рд╣реВрдБ рдЬрд┐рд╕рдореЗрдВ рдЖрдзреБрдирд┐рдХ рдкреВрд░реНрд╡рд╛рдЧреНрд░рд╣ рди рд╣реЛред рдЕрдЧрд░ рдореИрдВ GPT-2 рдЬреИрд╕рд╛ рдХреБрдЫ рдлрд╛рдЗрди-рдЯреНрдпреВрди рдХрд░рддрд╛ рд╣реВрдБ, рддреЛ рд╡рд╣ рдкрд╣рд▓реЗ рд╕реЗ рд╣реА рдкреНрд░реА-рдЯреНрд░реЗрдВрдб рд╣реИ рдФрд░ рд╡рд╣ рдЬрд╛рдирдХрд╛рд░реА рд╣рдЯрд╛рдИ рдирд╣реАрдВ рдЬрд╛ рд╕рдХрддреАред рдЕрдЧрд░ рдореИрдВ рд╢реБрд░реВ рд╕реЗ рдЯреНрд░реЗрди рдХрд░рддрд╛ рд╣реВрдБ рддреЛ рднрд╛рд╖рд╛ рдореЙрдбрд▓ рд╕рд┐рд░реНрдл рдкреБрд░рд╛рдирд╛ рд╣реЛрдиреЗ рдХрд╛ рджрд┐рдЦрд╛рд╡рд╛ рдирд╣реАрдВ рдХрд░реЗрдЧрд╛, рд╡рд╣ рд╕рдЪ рдореЗрдВ рд╡рд╣реА рд╣реЛрдЧрд╛ред рдЗрд╕ рдкреНрд░реЛрдЬреЗрдХреНрдЯ рдХрд╛ рд▓рдХреНрд╖реНрдп рдлрд┐рд▓рд╣рд╛рд▓ рдпрд╣реА рд╣реИ рдХрд┐ рдпрд╣ рдХреЗрд╡рд▓ 1800 рд╕реЗ 1850 рдХреЗ рдмреАрдЪ рд▓рдВрджрди рдореЗрдВ рдкреНрд░рдХрд╛рд╢рд┐рдд рдХрд┐рддрд╛рдмреЛрдВ рдХреЗ рдЬреНрдЮрд╛рди рд╕реЗ рд╣реА рддрд░реНрдХ рдХрд░ рд╕рдХреЗред\n\n## рдЯреНрд░реЗрдирд┐рдВрдЧ рдХреЗ рд▓рд┐рдП рдЖрдкрдиреЗ рдХрд┐рд╕ рддрд░рд╣ рдХрд╛ рдбреЗрдЯрд╛ рдЗрд╕реНрддреЗрдорд╛рд▓ рдХрд┐рдпрд╛?\n\nрдореИрдВ рдХрд┐рддрд╛рдмреЗрдВ, рдХрд╛рдиреВрдиреА рджрд╕реНрддрд╛рд╡реЗрдЬрд╝, рдЕрдЦрдмрд╛рд░, рдФрд░ рдЕрдиреНрдп рд▓реЗрдЦрди 1800тАУ1850 рдХреЗ рд▓рдВрджрди рд╕реЗ рдЗрд╕реНрддреЗрдорд╛рд▓ рдХрд░ рд░рд╣рд╛ рд╣реВрдБред рдЬреЛ рд╕реВрдЪреА рдореИрдВрдиреЗ рд▓рд┐рдВрдХ рдХреА рд╣реИ рдЙрд╕рдореЗрдВ рд▓рдЧрднрдЧ 200 рджрд╕реНрддрд╛рд╡реЗрдЬрд╝ рд╣реИрдВ рд▓реЗрдХрд┐рди рдкрд╣рд▓реА рдЯреНрд░реЗрдирд┐рдВрдЧ рдХреЗ рд▓рд┐рдП рдореИрдВрдиреЗ рд╕рд┐рд░реНрдл 50 рдлрд╛рдЗрд▓реЗрдВ (~187 MB) рдЗрд╕реНрддреЗрдорд╛рд▓ рдХреАрдВред рдЖрдк рджрд╕реНрддрд╛рд╡реЗрдЬрд╝реЛрдВ рдХреА рд╕реВрдЪреА рджреЗрдЦ рд╕рдХрддреЗ рд╣реИрдВ:\nhttps://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/Copy%20of%20London%20Documents%20for%20Time%20Capsule%20LLM.txt\n\n## рд╡рд░реНрд╢рди 0 рдореЙрдбрд▓ рдХрд┐рддрдирд╛ рдмрдбрд╝рд╛ рд╣реИ?\n\nрдпрд╣ рдореЙрдбрд▓ рдЕрднреА рдмрд╣реБрдд рдЫреЛрдЯрд╛ рд╣реИ, рдореИрдВ рдпрд╣ рд╕рд┐рд░реНрдл рдордЬрд╝реЗ рдХреЗ рд▓рд┐рдП рдХрд░ рд░рд╣рд╛ рд╣реВрдБ рдФрд░ рдмрд┐рдирд╛ рдЖрдзреБрдирд┐рдХ рд╕реНрд░реЛрддреЛрдВ рдХреЗ рд╕рдЦреНрдд рдЯреНрд░реЗрдирд┐рдВрдЧ рдирд┐рдпрдо рдХрд╛ рдкрд╛рд▓рди рдХрд░ рд░рд╣рд╛ рд╣реВрдБред рдЗрд╕рдореЗрдВ рд▓рдЧрднрдЧ 16 рдорд┐рд▓рд┐рдпрди рдкреИрд░рд╛рдореАрдЯрд░ рд╣реИрдВ рд▓реЗрдХрд┐рди рдореИрдВ рдФрд░ рдкреБрд░рд╛рдиреЗ рдЧреНрд░рдВрде рдПрдХрддреНрд░ рдХрд░рдирд╛ рд╢реБрд░реВ рдХрд░реВрдВрдЧрд╛ рддрд╛рдХрд┐ рдЕрдЧрд▓рд╛ рдореЙрдбрд▓ рдЯреНрд░реЗрди рдХрд░ рд╕рдХреВрдВред рдЬреИрд╕реЗ-рдЬреИрд╕реЗ рдЖрдЧреЗ рдмрдврд╝реВрдВрдЧрд╛ рдЕрдкрдбреЗрдЯ рджреВрдВрдЧрд╛ред\n\n## рдЯреНрд░реЗрдирд┐рдВрдЧ рд╕реНрдкреЗрдХреНрд╕?\n\nGPU: Geforce rtx 4060\nCPU: i5-13400F\nрд░реИрдо: 16GB DDR5.\n\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "YbYVsndAe75CgxPU/J34HsXOaqcQlIjTCm06o4eVQIg=",
        "originContent": "# V0 Model Behavior & Limitations ",
        "translatedContent": "# V0 рдореЙрдбрд▓ рд╡реНрдпрд╡рд╣рд╛рд░ рдФрд░ рд╕реАрдорд╛рдПрдБ"
      },
      {
        "row": 2,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 3,
        "rowsha": "OCh97kyOITXqFpKyZsol6voS+nrzc9n9flpDpNyf35w=",
        "originContent": "Early prompts show the model responding with 1800's language and behavior. For example, I prompted it with \"Who art Henry?\" and it replied \"I know that man, I have did not a black, the storm.\" and yeah that sentence makes no sense but the LLM is recognizing I'm asking about a person. ",
        "translatedContent": "рдкреНрд░рд╛рд░рдВрднрд┐рдХ рдкреНрд░реЙрдореНрдкреНрдЯреНрд╕ рдореЗрдВ рдореЙрдбрд▓ 1800 рдХреЗ рджрд╢рдХ рдХреА рднрд╛рд╖рд╛ рдФрд░ рд╡реНрдпрд╡рд╣рд╛рд░ рдореЗрдВ рдкреНрд░рддрд┐рдХреНрд░рд┐рдпрд╛ рджреЗрддрд╛ рд╣реИред рдЙрджрд╛рд╣рд░рдг рдХреЗ рд▓рд┐рдП, рдореИрдВрдиреЗ рдЗрд╕реЗ \"Who art Henry?\" рдкреВрдЫрд╛ рдФрд░ рдЗрд╕рдиреЗ рдЙрддреНрддрд░ рджрд┐рдпрд╛ \"I know that man, I have did not a black, the storm.\" рдФрд░ рд╣рд╛рдБ, рдЙрд╕ рд╡рд╛рдХреНрдп рдХрд╛ рдХреЛрдИ рдЕрд░реНрде рдирд╣реАрдВ рд╣реИ рд▓реЗрдХрд┐рди LLM рд╕рдордЭ рд░рд╣рд╛ рд╣реИ рдХрд┐ рдореИрдВ рдХрд┐рд╕реА рд╡реНрдпрдХреНрддрд┐ рдХреЗ рдмрд╛рд░реЗ рдореЗрдВ рдкреВрдЫ рд░рд╣рд╛ рд╣реВрдБред"
      },
      {
        "row": 4,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 5,
        "rowsha": "yKIR0teTc66wVDG+jdIyNmAzItXb2JH2ld3D7tm4qnM=",
        "originContent": "![TimeLockLLM Sample Output](https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1850_v0/timelockllm_sample_output.png?raw=true)",
        "translatedContent": "![TimeLockLLM Sample Output](https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1850_v0/timelockllm_sample_output.png?raw=true)"
      },
      {
        "row": 6,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 7,
        "rowsha": "/GR84OQ/Xp3d+Yv3/vVIIQFyl8ExKQLgjT1Go5rPplE=",
        "originContent": "There is no mention of modern concetps, outputs contain mostly words and phrasing from the 1800's.",
        "translatedContent": "рдпрд╣рд╛рдБ рдЖрдзреБрдирд┐рдХ рдЕрд╡рдзрд╛рд░рдгрд╛рдУрдВ рдХрд╛ рдХреЛрдИ рдЙрд▓реНрд▓реЗрдЦ рдирд╣реАрдВ рд╣реИ, рдЖрдЙрдЯрдкреБрдЯ рдореЗрдВ рдЕрдзрд┐рдХрд╛рдВрд╢ рд╢рдмреНрдж рдФрд░ рд╡рд╛рдХреНрдпрд╛рдВрд╢ 1800 рдХреЗ рджрд╢рдХ рдХреЗ рд╣реИрдВред"
      },
      {
        "row": 8,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 9,
        "rowsha": "aojQk3KjkX8shkLnJSZvUZBo0vk4tKDT9aysMfY9yK4=",
        "originContent": "It still needs alot of work, training off of 187MB will not give you a model that produces text with complex reasoning. ",
        "translatedContent": "рдЗрд╕реЗ рдЕрднреА рднреА рдмрд╣реБрдд рдХрд╛рдо рдХреА рдЬрд░реВрд░рдд рд╣реИ, 187MB рдбреЗрдЯрд╛ рд╕реЗ рдЯреНрд░реЗрдирд┐рдВрдЧ рдХрд░рдиреЗ рд╕реЗ рдЖрдкрдХреЛ рдЬрдЯрд┐рд▓ рддрд░реНрдХ рд╡рд╛рд▓реА рдЯреЗрдХреНрд╕реНрдЯ рдЙрддреНрдкрдиреНрди рдХрд░рдиреЗ рд╡рд╛рд▓рд╛ рдореЙрдбрд▓ рдирд╣реАрдВ рдорд┐рд▓реЗрдЧрд╛ред"
      },
      {
        "row": 10,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 11,
        "rowsha": "SzQ3fs08W+JGBPGw6+aEzLsm/vGfQNDJ6YZnfFE0F4I=",
        "originContent": "Right now it produces sentences that lack full sentence structure and overall just make no sense but this is normal for the training size. ",
        "translatedContent": "рдЕрднреА рдпрд╣ рдРрд╕реЗ рд╡рд╛рдХреНрдп рдмрдирд╛рддрд╛ рд╣реИ рдЬрд┐рдирдореЗрдВ рдкреВрд░реА рд╡рд╛рдХреНрдп рд╕рдВрд░рдЪрдирд╛ рдирд╣реАрдВ рд╣реЛрддреА рдФрд░ рдХреБрд▓ рдорд┐рд▓рд╛рдХрд░ рдХреЛрдИ рдЕрд░реНрде рдирд╣реАрдВ рдмрдирддрд╛, рд▓реЗрдХрд┐рди рдпрд╣ рдЗрд╕ рдЯреНрд░реЗрдирд┐рдВрдЧ рд╕рд╛рдЗрдЬ рдХреЗ рд▓рд┐рдП рд╕рд╛рдорд╛рдиреНрдп рд╣реИред"
      },
      {
        "row": 12,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 13,
        "rowsha": "eeaXlcgOJhwk4liDhaA6/6S4URmAdV8vj9hlqGr3LFw=",
        "originContent": "# V0.5 Model Behavior & Limitations",
        "translatedContent": "# V0.5 рдореЙрдбрд▓ рд╡реНрдпрд╡рд╣рд╛рд░ рдФрд░ рд╕реАрдорд╛рдПрдБ"
      },
      {
        "row": 14,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 15,
        "rowsha": "tII9OX/M7KpPoQKPIphmQBWtsSVucUevvTnzVsTXcaI=",
        "originContent": "This is a nice improvement compared to the last model. The writing style and vocab is Victorian and almost every sentence is grammatically correct with proper punctuation. And again this is trained from scratch so it sticks to 1800's subjects. ",
        "translatedContent": "рдпрд╣ рдкрд┐рдЫрд▓реЗ рдореЙрдбрд▓ рдХреА рддреБрд▓рдирд╛ рдореЗрдВ рдЕрдЪреНрдЫрд╛ рд╕реБрдзрд╛рд░ рд╣реИред рд▓реЗрдЦрди рд╢реИрд▓реА рдФрд░ рд╢рдмреНрджрд╛рд╡рд▓реА рд╡рд┐рдХреНрдЯреЛрд░рд┐рдпрди рд╣реИ рдФрд░ рд▓рдЧрднрдЧ рд╣рд░ рд╡рд╛рдХреНрдп рд╡реНрдпрд╛рдХрд░рдгрд┐рдХ рд░реВрдк рд╕реЗ рд╕рд╣реА рд╣реИ рдФрд░ рдЙрдЪрд┐рдд рд╡рд┐рд░рд╛рдо рдЪрд┐рд╣реНрдиреЛрдВ рдХреЗ рд╕рд╛рде рд╣реИред рдФрд░ рдлрд┐рд░, рдпрд╣ рд╢реБрд░реВ рд╕реЗ рдЯреНрд░реЗрди рдХрд┐рдпрд╛ рдЧрдпрд╛ рд╣реИ рдЗрд╕рд▓рд┐рдП рдпрд╣ 1800 рдХреЗ рджрд╢рдХ рдХреЗ рд╡рд┐рд╖рдпреЛрдВ рддрдХ рд╣реА рд╕реАрдорд┐рдд рд░рд╣рддрд╛ рд╣реИред"
      },
      {
        "row": 16,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 17,
        "rowsha": "8DhXpgpVtg05XdyplRHf49EFOQNCJVzXA9RpmJQ+y9U=",
        "originContent": "![TimeLockLLM Sample Output](https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1875_v0.5/fellowcitizens.png?raw=true)",
        "translatedContent": "![TimeLockLLM Sample Output](https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1875_v0.5/fellowcitizens.png?raw=true)"
      },
      {
        "row": 18,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 19,
        "rowsha": "YgdLunUOAWWHsq+eAfyWcDz1fCc0rCcobnRpEXHoK94=",
        "originContent": "There are a lot of factual hallucinations. A lot (like 100%) of the details (dates, events, historical figures)  are made up. Also the sentences don't really have connections to each other, sometimes maybe 2 sentences will relate to each other but beyond that they dont. Another issue is sometimes a stray тАЬDigitized by GoogleтАЭ footer shows up, so the next time I train I really have to make sure the texts are cleaned well. Overall I'm very happy with the results, it's nowhere near an LLM yet but definitely a sentence generator. ",
        "translatedContent": "рдпрд╣рд╛рдБ рдмрд╣реБрдд рд╕рд╛рд░реА рддрдереНрдпреЛрдВ рдХреА рдХрд▓реНрдкрдирд╛рдПрдБ рд╣реИрдВред рдЕрдзрд┐рдХрд╛рдВрд╢ (рд▓рдЧрднрдЧ 100%) рд╡рд┐рд╡рд░рдг (рддрд┐рдерд┐рдпрд╛рдБ, рдШрдЯрдирд╛рдПрдБ, рдРрддрд┐рд╣рд╛рд╕рд┐рдХ рд╡реНрдпрдХреНрддрд┐) рдХрд╛рд▓реНрдкрдирд┐рдХ рд╣реИрдВред рдЗрд╕рдХреЗ рдЕрд▓рд╛рд╡рд╛ рд╡рд╛рдХреНрдп рдЖрдкрд╕ рдореЗрдВ рдЬреБрдбрд╝рддреЗ рдирд╣реАрдВ рд╣реИрдВ, рдХрднреА-рдХрднреА рд╢рд╛рдпрдж 2 рд╡рд╛рдХреНрдп рдЬреБрдбрд╝реЗ рд╣реБрдП рд▓рдЧ рд╕рдХрддреЗ рд╣реИрдВ рд▓реЗрдХрд┐рди рдЙрд╕рд╕реЗ рдЖрдЧреЗ рдирд╣реАрдВред рдПрдХ рдФрд░ рд╕рдорд╕реНрдпрд╛ рд╣реИ рдХрд┐ рдХрднреА-рдХрднреА тАЬDigitized by GoogleтАЭ рдлреБрдЯрд░ рдЖ рдЬрд╛рддрд╛ рд╣реИ, рддреЛ рдЕрдЧрд▓реА рдмрд╛рд░ рдореБрдЭреЗ рдЯреНрд░реЗрдирд┐рдВрдЧ рд╕реЗ рдкрд╣рд▓реЗ рдЯреЗрдХреНрд╕реНрдЯ рдХреЛ рдЕрдЪреНрдЫреЗ рд╕реЗ рд╕рд╛рдлрд╝ рдХрд░рдирд╛ рд╣реЛрдЧрд╛ред рдХреБрд▓ рдорд┐рд▓рд╛рдХрд░ рдореИрдВ рдкрд░рд┐рдгрд╛рдореЛрдВ рд╕реЗ рдмрд╣реБрдд рдЦреБрд╢ рд╣реВрдБ, рдпрд╣ LLM рдХреЗ рд╕реНрддрд░ рдкрд░ рдирд╣реАрдВ рд╣реИ рд▓реЗрдХрд┐рди рдирд┐рд╢реНрдЪрд┐рдд рд░реВрдк рд╕реЗ рдПрдХ рд╡рд╛рдХреНрдп рдЬрдирд░реЗрдЯрд░ рд╣реИред"
      },
      {
        "row": 20,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 21,
        "rowsha": "V44Ne2sN8v7ZVpRZ5vo7B2aUZFjGppYthg0fjsQAqd0=",
        "originContent": "I'm learning a lot and will start figuring out what I need to do better in the coming weeks. I will upload files soon! ",
        "translatedContent": "рдореИрдВ рдмрд╣реБрдд рдХреБрдЫ рд╕реАрдЦ рд░рд╣рд╛ рд╣реВрдБ рдФрд░ рдЖрдиреЗ рд╡рд╛рд▓реЗ рд╣рдлреНрддреЛрдВ рдореЗрдВ рдкрддрд╛ рдХрд░реВрдВрдЧрд╛ рдХрд┐ рдореБрдЭреЗ рдХреНрдпрд╛ рдмреЗрд╣рддрд░ рдХрд░рдирд╛ рд╣реИред рдореИрдВ рдЬрд▓реНрдж рд╣реА рдлрд╛рдЗрд▓реЗрдВ рдЕрдкрд▓реЛрдб рдХрд░реВрдВрдЧрд╛!"
      },
      {
        "row": 22,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 23,
        "rowsha": "iMvQyl++GAiLpFMT+58v3e9/hb7zXnIJauchG5p986Y=",
        "originContent": "# Upcoming Plans ",
        "translatedContent": "# рдЖрдЧрд╛рдореА рдпреЛрдЬрдирд╛рдПрдБ"
      },
      {
        "row": 24,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 25,
        "rowsha": "OIt/QAbIp2G7kt87dbAIf6Ec0U3HnwjOW6LYRmdf68I=",
        "originContent": "(Completed) I'm going to start work on version 0.5 , instead of training using 50 books, I'll train using ideally 500-600. Right now I'm training nanoGPT using books from 1800-1850 and specifically from London. There is some challeneges like making sure the books I find are not updated or have modern interpretations but untouched books published withtin my chosen time period.",
        "translatedContent": "(рдкреВрд░рд╛ рд╣реБрдЖ) рдореИрдВ рд╡рд░реНрд╢рди 0.5 рдкрд░ рдХрд╛рдо рд╢реБрд░реВ рдХрд░рдиреЗ рдЬрд╛ рд░рд╣рд╛ рд╣реВрдБ, 50 рдХрд┐рддрд╛рдмреЛрдВ рдХреА рдЬрдЧрд╣ рдореИрдВ рдЖрджрд░реНрд╢ рд░реВрдк рд╕реЗ 500-600 рдХрд┐рддрд╛рдмреЛрдВ рд╕реЗ рдЯреНрд░реЗрди рдХрд░реВрдВрдЧрд╛ред рдЕрднреА рдореИрдВ nanoGPT рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рдХреЗ 1800-1850 рдХреА рдХрд┐рддрд╛рдмреЗрдВ рдЯреНрд░реЗрди рдХрд░ рд░рд╣рд╛ рд╣реВрдБ, рдФрд░ рдЦрд╛рд╕рдХрд░ рд▓рдВрджрди рд╕реЗред рдЗрд╕рдореЗрдВ рдХреБрдЫ рдЪреБрдиреМрддрд┐рдпрд╛рдБ рд╣реИрдВ рдЬреИрд╕реЗ рдпрд╣ рд╕реБрдирд┐рд╢реНрдЪрд┐рдд рдХрд░рдирд╛ рдХрд┐ рдЬреЛ рдХрд┐рддрд╛рдмреЗрдВ рдореБрдЭреЗ рдорд┐рд▓реЗрдВ рд╡реЗ рдЕрдкрдбреЗрдЯреЗрдб рдпрд╛ рдЖрдзреБрдирд┐рдХ рд╡реНрдпрд╛рдЦреНрдпрд╛рдУрдВ рд╡рд╛рд▓реА рди рд╣реЛрдВ рдмрд▓реНрдХрд┐ рдореЗрд░реА рдЪреБрдиреА рд╣реБрдИ рд╕рдордп рд╕реАрдорд╛ рдХреЗ рднреАрддрд░ рдкреНрд░рдХрд╛рд╢рд┐рдд рдЕрд╕рдВрдкрд╛рджрд┐рдд рдХрд┐рддрд╛рдмреЗрдВ рд╣реЛрдВред"
      },
      {
        "row": 26,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 27,
        "rowsha": "13sW7eekt8pSDdOxr/oKukwKEOVmw/M8xiAJC1VFXZc=",
        "originContent": "I want to train a new model (v1) with a much larger corpus, maybe 5-10x larger than the one I used for v0.5. My goal is to see if I can get reasoning abilities to emerge from Selective Temporal Training alone, this will be a more difficult task and I'm not even entirely sure if it's possible due to the fact that there is historical data limitations. In the upcoming weeks I will try to curate enough data for a 5-10GB corpus. I believe If I can get clean clean high quality data and rent a GPU, there will be progress.",
        "translatedContent": "рдореИрдВ рдПрдХ рдирдпрд╛ рдореЙрдбрд▓ (v1) рдПрдХ рдмрдбрд╝реЗ рдХреЙрд░реНрдкрд╕ рдХреЗ рд╕рд╛рде рдЯреНрд░реЗрди рдХрд░рдирд╛ рдЪрд╛рд╣рддрд╛ рд╣реВрдБ, рд╢рд╛рдпрдж v0.5 рдХреЗ рдореБрдХрд╛рдмрд▓реЗ 5-10 рдЧреБрдирд╛ рдмрдбрд╝рд╛ред рдореЗрд░рд╛ рд▓рдХреНрд╖реНрдп рд╣реИ рдХрд┐ рдХреНрдпрд╛ рдХреЗрд╡рд▓ Selective Temporal Training рд╕реЗ рддрд░реНрдХ рдХреНрд╖рдорддрд╛рдПрдБ рдЙрддреНрдкрдиреНрди рд╣реЛ рд╕рдХрддреА рд╣реИрдВ, рдпрд╣ рдЕрдзрд┐рдХ рдХрдард┐рди рдХрд╛рд░реНрдп рд╣реЛрдЧрд╛ рдФрд░ рдореИрдВ рдкреВрд░реА рддрд░рд╣ рдирд┐рд╢реНрдЪрд┐рдд рдирд╣реАрдВ рд╣реВрдБ рдХрд┐ рдпрд╣ рдРрддрд┐рд╣рд╛рд╕рд┐рдХ рдбреЗрдЯрд╛ рд╕реАрдорд╛рдУрдВ рдХреЗ рдХрд╛рд░рдг рд╕рдВрднрд╡ рд╣реИ рдпрд╛ рдирд╣реАрдВред рдЖрдиреЗ рд╡рд╛рд▓реЗ рд╣рдлреНрддреЛрдВ рдореЗрдВ рдореИрдВ 5-10GB рдХрд╛ рдХреЙрд░реНрдкрд╕ рддреИрдпрд╛рд░ рдХрд░рдиреЗ рдХреА рдХреЛрд╢рд┐рд╢ рдХрд░реВрдВрдЧрд╛ред рдореБрдЭреЗ рд╡рд┐рд╢реНрд╡рд╛рд╕ рд╣реИ рдХрд┐ рдпрджрд┐ рдореБрдЭреЗ рд╕рд╛рдл, рдЙрдЪреНрдЪ рдЧреБрдгрд╡рддреНрддрд╛ рд╡рд╛рд▓рд╛ рдбреЗрдЯрд╛ рдорд┐рд▓ рдЬрд╛рдП рдФрд░ GPU рдХрд┐рд░рд╛рдП рдкрд░ рд▓реЗ рд╕рдХреВрдВ, рддреЛ рдкреНрд░рдЧрддрд┐ рд╣реЛрдЧреАред"
      },
      {
        "row": 28,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 29,
        "rowsha": "sO+voevLpUtEbqum6Gntntle+nPVa66c5GATAMLrgf0=",
        "originContent": "# How to Use This Project ",
        "translatedContent": "# рдЗрд╕ рдкреНрд░реЛрдЬреЗрдХреНрдЯ рдХрд╛ рдЙрдкрдпреЛрдЧ рдХреИрд╕реЗ рдХрд░реЗрдВ"
      },
      {
        "row": 30,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 31,
        "rowsha": "XVoXr9uzZwN09vboETojEQJe057RBzcMUjXmQRCB/jo=",
        "originContent": "This project focuses mostly on curating historical data, preparing it for training and building a tokenizer. I am not going to cover the full LLM training process, for that refer to nanoGPT by Andrej Karpathy.",
        "translatedContent": "рдпрд╣ рдкреНрд░реЛрдЬреЗрдХреНрдЯ рдореБрдЦреНрдп рд░реВрдк рд╕реЗ рдРрддрд┐рд╣рд╛рд╕рд┐рдХ рдбреЗрдЯрд╛ рдПрдХрддреНрд░ рдХрд░рдиреЗ, рдЙрд╕реЗ рдЯреНрд░реЗрдирд┐рдВрдЧ рдХреЗ рд▓рд┐рдП рддреИрдпрд╛рд░ рдХрд░рдиреЗ рдФрд░ рдЯреЛрдХрдирд╛рдЗрдЬрд╝рд░ рдмрдирд╛рдиреЗ рдкрд░ рдХреЗрдВрджреНрд░рд┐рдд рд╣реИред рдореИрдВ рдпрд╣рд╛рдБ рдкреВрд░реА LLM рдЯреНрд░реЗрдирд┐рдВрдЧ рдкреНрд░рдХреНрд░рд┐рдпрд╛ рдирд╣реАрдВ рдмрддрд╛рдКрдВрдЧрд╛, рдЙрд╕рдХреЗ рд▓рд┐рдП Andrej Karpathy рдХрд╛ nanoGPT рджреЗрдЦреЗрдВред"
      },
      {
        "row": 32,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 33,
        "rowsha": "kDK7XtqFkTiZvD804yYG4VEojvLrRbdEhmHEBzDAQz4=",
        "originContent": "# Step 1: Gather and Prepare Historical Texts ",
        "translatedContent": "# рдЪрд░рдг 1: рдРрддрд┐рд╣рд╛рд╕рд┐рдХ рдЧреНрд░рдВрде рдПрдХрддреНрд░рд┐рдд рдФрд░ рддреИрдпрд╛рд░ рдХрд░реЗрдВ"
      },
      {
        "row": 34,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 35,
        "rowsha": "oRoOYaG+mx3SqTnhGcOKeH7W3W4wSRQmhZS4jPGMH8s=",
        "originContent": "Collect .txt files of public domain books, documents, etc from your chosen time period (e.g., London 1800-1850)",
        "translatedContent": "рдЕрдкрдиреЗ рдЪреБрдиреЗ рд╣реБрдП рд╕рдордп рдЕрд╡рдзрд┐ (рдЬреИрд╕реЗ, рд▓рдВрджрди 1800-1850) рдХреЗ рд╕рд╛рд░реНрд╡рдЬрдирд┐рдХ рдбреЛрдореЗрди рдХреА рдХрд┐рддрд╛рдмреЗрдВ, рджрд╕реНрддрд╛рд╡реЗрдЬрд╝ рдЖрджрд┐ рдХреА .txt рдлрд╛рдЗрд▓реЗрдВ рдЗрдХрдЯреНрдард╛ рдХрд░реЗрдВред"
      },
      {
        "row": 36,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 37,
        "rowsha": "EBDhZvTogrL4hqRuH095O7/tXXoy2OEskLQlang/pOA=",
        "originContent": "You can use download_texts_improved.py to download books for you if you need to.",
        "translatedContent": "рдпрджрд┐ рдЖрд╡рд╢реНрдпрдХрддрд╛ рд╣реЛ рддреЛ рдЖрдк download_texts_improved.py рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рдХреЗ рдХрд┐рддрд╛рдмреЗрдВ рдбрд╛рдЙрдирд▓реЛрдб рдХрд░ рд╕рдХрддреЗ рд╣реИрдВред"
      },
      {
        "row": 38,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 39,
        "rowsha": "q5OO8x+9kIbzaQRWimI/Vo9ZowzVBtCX+TodObLsQoY=",
        "originContent": "Clean the text files using a script or manually remove headers/footer from Project Gutenberg, Modern annotations or things like OCR errors.",
        "translatedContent": "рдЯреЗрдХреНрд╕реНрдЯ рдлрд╛рдЗрд▓реЛрдВ рдХреЛ рд╕реНрдХреНрд░рд┐рдкреНрдЯ рдпрд╛ рдореИрдиреНрдпреБрдЕрд▓реА рд╕рд╛рдл рдХрд░реЗрдВ, рдЬреИрд╕реЗ рдкреНрд░реЛрдЬреЗрдХреНрдЯ рдЧреБрдЯреЗрдирдмрд░реНрдЧ рдХреЗ рд╣реЗрдбрд░/рдлреБрдЯрд░, рдЖрдзреБрдирд┐рдХ рдЯрд┐рдкреНрдкрдгрд┐рдпрд╛рдБ рдпрд╛ OCR рдХреА рдЧрд▓рддрд┐рдпрд╛рдБ рд╣рдЯрд╛рдПрдБред"
      },
      {
        "row": 40,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 41,
        "rowsha": "N4wsIjC0LRlClodmfCtYX3qswttJnk0psU28/mlCRTw=",
        "originContent": "prepare_dataset.py should work fine.",
        "translatedContent": "prepare_dataset.py рдареАрдХ рд╕реЗ рдХрд╛рдо рдХрд░рдирд╛ рдЪрд╛рд╣рд┐рдПред"
      },
      {
        "row": 42,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 43,
        "rowsha": "jDM2lr7pP+MT0pt+L0cd5nBXI83IPoT27NzIgplt7R8=",
        "originContent": "# Step 2: Build a Custom Tokenizer",
        "translatedContent": "# рдЪрд░рдг 2: рдХрд╕реНрдЯрдо рдЯреЛрдХрдирд╛рдЗрдЬрд╝рд░ рдмрдирд╛рдПрдБ"
      },
      {
        "row": 44,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 45,
        "rowsha": "+90EorsgO/X2bFK2pYJw+vZIpjIbuMm4QR6W/xfj8C8=",
        "originContent": "Run train_tokenizer.py or train_tokenizer_hf.py on the cleaned data.",
        "translatedContent": "рд╕рд╛рдл рдХреА рдЧрдИ рдбреЗрдЯрд╛ рдкрд░ train_tokenizer.py рдпрд╛ train_tokenizer_hf.py рдЪрд▓рд╛рдПрдБред"
      },
      {
        "row": 46,
        "rowsha": "tkP3Eg1rWphTQMNhN2yYg/1+AA1IdcXbGT96aRMpnwc=",
        "originContent": "This will give you vocab.json and merges.txt",
        "translatedContent": "рдпрд╣ рдЖрдкрдХреЛ vocab.json рдФрд░ merges.txt рджреЗрдЧрд╛ред"
      },
      {
        "row": 47,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 48,
        "rowsha": "/wqxgtOu72+x3a2xi7q23jDkx+WQv2SHrJddzpvm1Ys=",
        "originContent": "Thes files define vocab and merge rules for your model",
        "translatedContent": "рдпреЗ рдлрд╛рдЗрд▓реЗрдВ рдЖрдкрдХреЗ рдореЙрдбрд▓ рдХреЗ рд▓рд┐рдП рд╢рдмреНрджрд╛рд╡рд▓реА рдФрд░ рдорд░реНрдЬ рдирд┐рдпрдо рдкрд░рд┐рднрд╛рд╖рд┐рдд рдХрд░рддреА рд╣реИрдВред"
      },
      {
        "row": 49,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 50,
        "rowsha": "vKPAEsPxc9uYtzjTX9/rNADSDnxkKwYcYpX/aiAp8Hc=",
        "originContent": "# Step 3: Train Your Model (nanoGPT) ",
        "translatedContent": "# рдЪрд░рдг 3: рдЕрдкрдирд╛ рдореЙрдбрд▓ рдЯреНрд░реЗрди рдХрд░реЗрдВ (nanoGPT)"
      },
      {
        "row": 51,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 52,
        "rowsha": "tCDY5iXt+Z7YYeTPouMSYDX5uuFnGROxZMvHyTOIblY=",
        "originContent": "Refer to [nanoGPT by Andrej Karpathy](https://github.com/karpathy/nanoGPT) for the training process.",
        "translatedContent": "рдЯреНрд░реЗрдирд┐рдВрдЧ рдкреНрд░рдХреНрд░рд┐рдпрд╛ рдХреЗ рд▓рд┐рдП [Andrej Karpathy рдХрд╛ nanoGPT](https://github.com/karpathy/nanoGPT) рджреЗрдЦреЗрдВред"
      },
      {
        "row": 53,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 54,
        "rowsha": "bLpr9snECDSJ5ejrqDWYNT8VXSupCQKQxyLxvAmQ2Kc=",
        "originContent": "You can train a different LLM if you want, but I used nanoGPT ",
        "translatedContent": "рдЕрдЧрд░ рдЪрд╛рд╣реЗрдВ рддреЛ рдЖрдк рдХреЛрдИ рдФрд░ LLM рдЯреНрд░реЗрди рдХрд░ рд╕рдХрддреЗ рд╣реИрдВ, рд▓реЗрдХрд┐рди рдореИрдВрдиреЗ nanoGPT рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд┐рдпрд╛ред"
      },
      {
        "row": 55,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 56,
        "rowsha": "OoCxyGfPN5TmdzAkaPphtPx303MJJ7vpfWbKrufGH5g=",
        "originContent": "# FAQ",
        "translatedContent": "# рд╕рд╛рдорд╛рдиреНрдп рдкреНрд░рд╢реНрди"
      },
      {
        "row": 57,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 58,
        "rowsha": "+5dDgPw4ILEotxso4tjjjz1cxwUei16yNQPDUKbgxoo=",
        "originContent": "## What is Selective Temporal Training ?",
        "translatedContent": "## Selective Temporal Training рдХреНрдпрд╛ рд╣реИ?"
      },
      {
        "row": 59,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 60,
        "rowsha": "hooEARKH4r/sDPh7JUtZAZ6TYMvBkTLZIcfw3g83xos=",
        "originContent": "Selective Temporal Training (STT) is a machine learning methodology where all training data is specifically curated to fall within a specific historical time period. It's done in order to model the language and knowledge of that era without influence from modern concepts. For example, the current model I have now (v0.5) is trained on data exclusively from 1800-1875, it's not fine tuned but trained from scratch resulting in output that reflects the linguistic style and historical context of that time period.",
        "translatedContent": "Selective Temporal Training (STT) рдПрдХ рдорд╢реАрди рд▓рд░реНрдирд┐рдВрдЧ рдкрджреНрдзрддрд┐ рд╣реИ рдЬрд┐рд╕рдореЗрдВ рд╕рднреА рдЯреНрд░реЗрдирд┐рдВрдЧ рдбреЗрдЯрд╛ рд╡рд┐рд╢реЗрд╖ рд░реВрдк рд╕реЗ рдПрдХ рдирд┐рд╢реНрдЪрд┐рдд рдРрддрд┐рд╣рд╛рд╕рд┐рдХ рд╕рдордпрд╛рд╡рдзрд┐ рдХреЗ рднреАрддрд░ рдЪреБрдирд╛ рдЬрд╛рддрд╛ рд╣реИред рдЗрд╕рдХрд╛ рдЙрджреНрджреЗрд╢реНрдп рдЙрд╕ рдпреБрдЧ рдХреА рднрд╛рд╖рд╛ рдФрд░ рдЬреНрдЮрд╛рди рдХреЛ рдмрд┐рдирд╛ рдЖрдзреБрдирд┐рдХ рдкреНрд░рднрд╛рд╡ рдХреЗ рдореЙрдбрд▓ рдХрд░рдирд╛ рд╣реИред рдЙрджрд╛рд╣рд░рдг рдХреЗ рд▓рд┐рдП, рдореЗрд░рд╛ рд╡рд░реНрддрдорд╛рди рдореЙрдбрд▓ (v0.5) рдкреВрд░реА рддрд░рд╣ 1800-1875 рдХреА рдбреЗрдЯрд╛ рдкрд░ рдЯреНрд░реЗрди рд╣реИ, рдпрд╣ рдлрд╛рдЗрди рдЯреНрдпреВрди рдирд╣реАрдВ рдХрд┐рдпрд╛ рдЧрдпрд╛ рдмрд▓реНрдХрд┐ рд╢реБрд░реВ рд╕реЗ рдЯреНрд░реЗрди рд╣реИ, рдЬрд┐рд╕рд╕реЗ рдЖрдЙрдЯрдкреБрдЯ рдЙрд╕ рд╕рдордп рдХреА рднрд╛рд╖рд╛рд╢реИрд▓реА рдФрд░ рдРрддрд┐рд╣рд╛рд╕рд┐рдХ рд╕рдВрджрд░реНрдн рдХреЛ рджрд░реНрд╢рд╛рддрд╛ рд╣реИред"
      },
      {
        "row": 61,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 62,
        "rowsha": "dVMKQ2mPI1Spc6x6r/jNG0PIR5YKpalU4MXx9JmKp/I=",
        "originContent": "## Why not just use fine-tuning or LoRA?",
        "translatedContent": "## рдлрд╛рдЗрди-рдЯреНрдпреВрдирд┐рдВрдЧ рдпрд╛ LoRA рдХрд╛ рдЙрдкрдпреЛрдЧ рдХреНрдпреЛрдВ рдирд╣реАрдВ?"
      },
      {
        "row": 63,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 64,
        "rowsha": "oNvWlJHtQSyq1TwlqJyGtMzk4Z4mBIn8AW2SudzvUYs=",
        "originContent": "For this project I'm trying to create a language model that is unclouded from modern bias. If I fine-tune something like GPT-2, it's already pre-trained and that information won't go away. If I train from scratch the language model won't pretend to be old, it just will be. The Goal for this project right now is to create something can reason exclusively using knowledge from London books published between 1800 and 1850.",
        "translatedContent": "рдЗрд╕ рдкреНрд░реЛрдЬреЗрдХреНрдЯ рдХреЗ рд▓рд┐рдП рдореИрдВ рдРрд╕рд╛ рднрд╛рд╖рд╛ рдореЙрдбрд▓ рдмрдирд╛рдирд╛ рдЪрд╛рд╣рддрд╛ рд╣реВрдБ рдЬрд┐рд╕рдореЗрдВ рдЖрдзреБрдирд┐рдХ рдкреВрд░реНрд╡рд╛рдЧреНрд░рд╣ рди рд╣реЛред рдЕрдЧрд░ рдореИрдВ GPT-2 рдЬреИрд╕рд╛ рдХреБрдЫ рдлрд╛рдЗрди-рдЯреНрдпреВрди рдХрд░рддрд╛ рд╣реВрдБ, рддреЛ рд╡рд╣ рдкрд╣рд▓реЗ рд╕реЗ рд╣реА рдкреНрд░реА-рдЯреНрд░реЗрдВрдб рд╣реИ рдФрд░ рд╡рд╣ рдЬрд╛рдирдХрд╛рд░реА рд╣рдЯрд╛рдИ рдирд╣реАрдВ рдЬрд╛ рд╕рдХрддреАред рдЕрдЧрд░ рдореИрдВ рд╢реБрд░реВ рд╕реЗ рдЯреНрд░реЗрди рдХрд░рддрд╛ рд╣реВрдБ рддреЛ рднрд╛рд╖рд╛ рдореЙрдбрд▓ рд╕рд┐рд░реНрдл рдкреБрд░рд╛рдирд╛ рд╣реЛрдиреЗ рдХрд╛ рджрд┐рдЦрд╛рд╡рд╛ рдирд╣реАрдВ рдХрд░реЗрдЧрд╛, рд╡рд╣ рд╕рдЪ рдореЗрдВ рд╡рд╣реА рд╣реЛрдЧрд╛ред рдЗрд╕ рдкреНрд░реЛрдЬреЗрдХреНрдЯ рдХрд╛ рд▓рдХреНрд╖реНрдп рдлрд┐рд▓рд╣рд╛рд▓ рдпрд╣реА рд╣реИ рдХрд┐ рдпрд╣ рдХреЗрд╡рд▓ 1800 рд╕реЗ 1850 рдХреЗ рдмреАрдЪ рд▓рдВрджрди рдореЗрдВ рдкреНрд░рдХрд╛рд╢рд┐рдд рдХрд┐рддрд╛рдмреЛрдВ рдХреЗ рдЬреНрдЮрд╛рди рд╕реЗ рд╣реА рддрд░реНрдХ рдХрд░ рд╕рдХреЗред"
      },
      {
        "row": 65,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 66,
        "rowsha": "ByP4WlNmMoG6WIiLJNd6b080/DSciCgWmj9aYSJjAF0=",
        "originContent": "## What kind of data did you use for training?",
        "translatedContent": "## рдЯреНрд░реЗрдирд┐рдВрдЧ рдХреЗ рд▓рд┐рдП рдЖрдкрдиреЗ рдХрд┐рд╕ рддрд░рд╣ рдХрд╛ рдбреЗрдЯрд╛ рдЗрд╕реНрддреЗрдорд╛рд▓ рдХрд┐рдпрд╛?"
      },
      {
        "row": 67,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 68,
        "rowsha": "Kj6EF7wZdUrAFg4ErGmJuh9Q5Xujmb+tunpfssPKXkA=",
        "originContent": "I'm using books, legal documents, newspapers, and other writings from 1800тАУ1850 London. The list I linked has like 200 but for the first training I just used 50 files about ~187 MB. You can view a list of the documents:",
        "translatedContent": "рдореИрдВ рдХрд┐рддрд╛рдмреЗрдВ, рдХрд╛рдиреВрдиреА рджрд╕реНрддрд╛рд╡реЗрдЬрд╝, рдЕрдЦрдмрд╛рд░, рдФрд░ рдЕрдиреНрдп рд▓реЗрдЦрди 1800тАУ1850 рдХреЗ рд▓рдВрджрди рд╕реЗ рдЗрд╕реНрддреЗрдорд╛рд▓ рдХрд░ рд░рд╣рд╛ рд╣реВрдБред рдЬреЛ рд╕реВрдЪреА рдореИрдВрдиреЗ рд▓рд┐рдВрдХ рдХреА рд╣реИ рдЙрд╕рдореЗрдВ рд▓рдЧрднрдЧ 200 рджрд╕реНрддрд╛рд╡реЗрдЬрд╝ рд╣реИрдВ рд▓реЗрдХрд┐рди рдкрд╣рд▓реА рдЯреНрд░реЗрдирд┐рдВрдЧ рдХреЗ рд▓рд┐рдП рдореИрдВрдиреЗ рд╕рд┐рд░реНрдл 50 рдлрд╛рдЗрд▓реЗрдВ (~187 MB) рдЗрд╕реНрддреЗрдорд╛рд▓ рдХреАрдВред рдЖрдк рджрд╕реНрддрд╛рд╡реЗрдЬрд╝реЛрдВ рдХреА рд╕реВрдЪреА рджреЗрдЦ рд╕рдХрддреЗ рд╣реИрдВ:"
      },
      {
        "row": 69,
        "rowsha": "0mxyGiLJxzp9JPCg1oA+nbIwAKJbEC4ei9kSV3Gp84Y=",
        "originContent": "https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/Copy%20of%20London%20Documents%20for%20Time%20Capsule%20LLM.txt",
        "translatedContent": "https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/Copy%20of%20London%20Documents%20for%20Time%20Capsule%20LLM.txt"
      },
      {
        "row": 70,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 71,
        "rowsha": "RiLgksbH2sYLZRyKsFhVyfjC6nNxLsxWsc7XnFS061A=",
        "originContent": "## How large is the Version 0 model ?",
        "translatedContent": "## рд╡рд░реНрд╢рди 0 рдореЙрдбрд▓ рдХрд┐рддрдирд╛ рдмрдбрд╝рд╛ рд╣реИ?"
      },
      {
        "row": 72,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 73,
        "rowsha": "55Ce1mBEzOreC728R5HRfuMIC/nZRg3Zcr87GVkjVVY=",
        "originContent": "This model is very small right now, I'm just doing this for fun and following a strict training rule of no modern sources. It has almost 16 million parameters but I'm gonna start gathering more old texts to begin another model training. Will give updates as I go.",
        "translatedContent": "рдпрд╣ рдореЙрдбрд▓ рдЕрднреА рдмрд╣реБрдд рдЫреЛрдЯрд╛ рд╣реИ, рдореИрдВ рдпрд╣ рд╕рд┐рд░реНрдл рдордЬрд╝реЗ рдХреЗ рд▓рд┐рдП рдХрд░ рд░рд╣рд╛ рд╣реВрдБ рдФрд░ рдмрд┐рдирд╛ рдЖрдзреБрдирд┐рдХ рд╕реНрд░реЛрддреЛрдВ рдХреЗ рд╕рдЦреНрдд рдЯреНрд░реЗрдирд┐рдВрдЧ рдирд┐рдпрдо рдХрд╛ рдкрд╛рд▓рди рдХрд░ рд░рд╣рд╛ рд╣реВрдБред рдЗрд╕рдореЗрдВ рд▓рдЧрднрдЧ 16 рдорд┐рд▓рд┐рдпрди рдкреИрд░рд╛рдореАрдЯрд░ рд╣реИрдВ рд▓реЗрдХрд┐рди рдореИрдВ рдФрд░ рдкреБрд░рд╛рдиреЗ рдЧреНрд░рдВрде рдПрдХрддреНрд░ рдХрд░рдирд╛ рд╢реБрд░реВ рдХрд░реВрдВрдЧрд╛ рддрд╛рдХрд┐ рдЕрдЧрд▓рд╛ рдореЙрдбрд▓ рдЯреНрд░реЗрди рдХрд░ рд╕рдХреВрдВред рдЬреИрд╕реЗ-рдЬреИрд╕реЗ рдЖрдЧреЗ рдмрдврд╝реВрдВрдЧрд╛ рдЕрдкрдбреЗрдЯ рджреВрдВрдЧрд╛ред"
      },
      {
        "row": 74,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 75,
        "rowsha": "A40eQ7ZJiqr+bs9cl0Cb4QKKuS9z7/PA1ZaGn1TSehI=",
        "originContent": "## Training Specs ? ",
        "translatedContent": "## рдЯреНрд░реЗрдирд┐рдВрдЧ рд╕реНрдкреЗрдХреНрд╕?"
      },
      {
        "row": 76,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 77,
        "rowsha": "EH8H1HW/C4Tb7LfJgVUnVGsk4pF9l40Rlev8tAkKhjI=",
        "originContent": "GPU: Geforce rtx 4060",
        "translatedContent": "GPU: Geforce rtx 4060"
      },
      {
        "row": 78,
        "rowsha": "vo3FdN37kY6VUB7PruRKfBPJDgsVJyBHIUCn/g8mt68=",
        "originContent": "CPU: i5-13400F ",
        "translatedContent": "CPU: i5-13400F"
      },
      {
        "row": 79,
        "rowsha": "W8fXPiQKUkoNso0PPfTvjYMy0IYo85j+gNXmB0aERO4=",
        "originContent": "Ram: 16GB DDR5.",
        "translatedContent": "рд░реИрдо: 16GB DDR5."
      },
      {
        "row": 80,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 81,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  }
]