[
  {
    "row": 1,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 2,
    "rowsha": "cWgam+tnnXudu7i74+ahMEGk/A9dQS+EwWLAIfi3dHk=",
    "originContent": "<div align=\"right\">",
    "translatedContent": "<div align=\"right\">"
  },
  {
    "row": 3,
    "rowsha": "orOcu5ARna/hb3RUkj6dBI8pHTM3WHeTvby17l5E0h0=",
    "originContent": "  <details>",
    "translatedContent": "  <details>"
  },
  {
    "row": 4,
    "rowsha": "TtgkLzblnvP0q9aAIVXt6s2LczXjy5k+QvHKcU0/5Ms=",
    "originContent": "    <summary >üåê Language</summary>",
    "translatedContent": "    <summary >üåê Jƒôzyk</summary>"
  },
  {
    "row": 5,
    "rowsha": "fZtk4rPTAJEEslnbhSVkHEcPlsctYSzAV7CDPL3rJmA=",
    "originContent": "    <div>",
    "translatedContent": "    <div>"
  },
  {
    "row": 6,
    "rowsha": "9KQxOeJSigvTmGWO+mtnl8kZY9zQfueoy8sk4lYm09Q=",
    "originContent": "      <div align=\"center\">",
    "translatedContent": "      <div align=\"center\">"
  },
  {
    "row": 7,
    "rowsha": "CeOhdpchZBoZSEUDtSE417JEcMBSZw18jeJuHJBKB2Y=",
    "originContent": "        <a href=\"https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=en\">English</a>",
    "translatedContent": "        <a href=\"https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=en\">English</a>"
  },
  {
    "row": 8,
    "rowsha": "ToO7MFa3QrNNljdQWIagsnOPxe8cXuuA2m5msIm+Kbs=",
    "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=zh-CN\">ÁÆÄ‰Ωì‰∏≠Êñá</a>",
    "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=zh-CN\">ÁÆÄ‰Ωì‰∏≠Êñá</a>"
  },
  {
    "row": 9,
    "rowsha": "MRATmWdRMRw0JU4u9h5pMb6GU17lQFgG9v/bpGLr9pM=",
    "originContent": "        | <a href=\"#\" title=\"Coming soon\">ÁπÅÈ´î‰∏≠Êñá (coming soon)</a> |",
    "translatedContent": "        | <a href=\"#\" title=\"Coming soon\">ÁπÅÈ´î‰∏≠Êñá (wkr√≥tce)</a> |"
  },
  {
    "row": 10,
    "rowsha": "GY7LXxG3rk5eFh9itcqM0cTtmHybyjLTf1icB3jN31I=",
    "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=ja\">Êó•Êú¨Ë™û</a>",
    "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=ja\">Êó•Êú¨Ë™û</a>"
  },
  {
    "row": 11,
    "rowsha": "b5TwunGJh+gsAe7aQU3dkfobXF/nknCEta1msDa7XBU=",
    "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=ko\">ÌïúÍµ≠Ïñ¥</a>",
    "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=ko\">ÌïúÍµ≠Ïñ¥</a>"
  },
  {
    "row": 12,
    "rowsha": "1/HCgPsVh2ChqMY+k/VVxEWHPRRmWWCjy5nDRibi3mM=",
    "originContent": "        | <a href=\"#\" title=\"Coming soon\">‡§π‡§ø‡§®‡•ç‡§¶‡•Ä (coming soon)</a> |",
    "translatedContent": "        | <a href=\"#\" title=\"Coming soon\">‡§π‡§ø‡§®‡•ç‡§¶‡•Ä (wkr√≥tce)</a> |"
  },
  {
    "row": 13,
    "rowsha": "3lfEHT+5HYFEvbE5cl+xujQPYjtVmzTifT37iqPTWII=",
    "originContent": "        | <a href=\"#\" title=\"Coming soon\">‡πÑ‡∏ó‡∏¢ (coming soon)</a> |",
    "translatedContent": "        | <a href=\"#\" title=\"Coming soon\">‡πÑ‡∏ó‡∏¢ (wkr√≥tce)</a> |"
  },
  {
    "row": 14,
    "rowsha": "KmG3P0px2E3bt1lU/w3eGop+zeA1j8xL0k280Zd9m2s=",
    "originContent": "        | <a href=\"#\" title=\"Coming soon\">Fran√ßais (coming soon)</a>",
    "translatedContent": "        | <a href=\"#\" title=\"Coming soon\">Fran√ßais (wkr√≥tce)</a>"
  },
  {
    "row": 15,
    "rowsha": "CSdHSEXgIs3M2Q/6zIIJ8NbKkZWhydhBqNus94qrPvg=",
    "originContent": "        | <a href=\"#\" title=\"Coming soon\">Deutsch (coming soon)</a>",
    "translatedContent": "        | <a href=\"#\" title=\"Coming soon\">Deutsch (wkr√≥tce)</a>"
  },
  {
    "row": 16,
    "rowsha": "8wz7pDuXc3dk+ZcqZ1jmmh8zh6xN3Wb6qWbCjxAj7dA=",
    "originContent": "        | <a href=\"#\" title=\"Coming soon\">Espa√±ol (coming soon)</a>",
    "translatedContent": "        | <a href=\"#\" title=\"Coming soon\">Espa√±ol (wkr√≥tce)</a>"
  },
  {
    "row": 17,
    "rowsha": "op/NqIZs7OjCSpNgpXk8RnqDnTegVPyWUQhuQxvTR7U=",
    "originContent": "        | <a href=\"#\" title=\"Coming soon\">Italiano (coming soon)</a>",
    "translatedContent": "        | <a href=\"#\" title=\"Coming soon\">Italiano (wkr√≥tce)</a>"
  },
  {
    "row": 18,
    "rowsha": "tAvlfwut/Ad9q1huxc8EREZGv7vYHbrEujzUS8xoaQo=",
    "originContent": "        | <a href=\"#\" title=\"Coming soon\">–†—É—Å—Å–∫–∏–π (coming soon)</a>",
    "translatedContent": "        | <a href=\"#\" title=\"Coming soon\">–†—É—Å—Å–∫–∏–π (wkr√≥tce)</a>"
  },
  {
    "row": 19,
    "rowsha": "WhhSpeeCUUAqJiVTS4Fvyc6A2c+24Jnj3MW7XLQuIcI=",
    "originContent": "        | <a href=\"#\" title=\"Coming soon\">Portugu√™s (coming soon)</a>",
    "translatedContent": "        | <a href=\"#\" title=\"Coming soon\">Portugu√™s (wkr√≥tce)</a>"
  },
  {
    "row": 20,
    "rowsha": "0yPXPrWh+Vzc6FBE9iiciw5HwpOSmo05HNe36wfTWCI=",
    "originContent": "        | <a href=\"#\" title=\"Coming soon\">Nederlands (coming soon)</a>",
    "translatedContent": "        | <a href=\"#\" title=\"Coming soon\">Nederlands (wkr√≥tce)</a>"
  },
  {
    "row": 21,
    "rowsha": "mdW6YUUXf5KzI4CwZxrE08ofaLonUOMnJpN3vPR7Y2A=",
    "originContent": "        | <a href=\"#\" title=\"Coming soon\">Polski (coming soon)</a>",
    "translatedContent": "        | <a href=\"#\" title=\"Coming soon\">Polski (wkr√≥tce)</a>"
  },
  {
    "row": 22,
    "rowsha": "sw1AXxAGQNvn4eSG9enTWNkwKH0yr6LlVtXBH1j9z8s=",
    "originContent": "        | <a href=\"#\" title=\"Coming soon\">ÿßŸÑÿπÿ±ÿ®Ÿäÿ© (coming soon)</a>",
    "translatedContent": "        | <a href=\"#\" title=\"Coming soon\">ÿßŸÑÿπÿ±ÿ®Ÿäÿ© (wkr√≥tce)</a>"
  },
  {
    "row": 23,
    "rowsha": "I8dh9zmXisU0+CpddA55QQgvujH03J/dEnXgj5aFtQM=",
    "originContent": "        | <a href=\"#\" title=\"Coming soon\">ŸÅÿßÿ±ÿ≥€å (coming soon)</a>",
    "translatedContent": "        | <a href=\"#\" title=\"Coming soon\">ŸÅÿßÿ±ÿ≥€å (wkr√≥tce)</a>"
  },
  {
    "row": 24,
    "rowsha": "7VFv8o6de72ciJrbh3mctfrEgCJhNvuKGWJNOmCaPdM=",
    "originContent": "        | <a href=\"#\" title=\"Coming soon\">T√ºrk√ße (coming soon)</a>",
    "translatedContent": "        | <a href=\"#\" title=\"Coming soon\">T√ºrk√ße (wkr√≥tce)</a>"
  },
  {
    "row": 25,
    "rowsha": "C+XRvFz/D3o9/JyPqwitsxtskFZleJC/oFUr4SEeiHA=",
    "originContent": "        | <a href=\"#\" title=\"Coming soon\">Ti·∫øng Vi·ªát (coming soon)</a>",
    "translatedContent": "        | <a href=\"#\" title=\"Coming soon\">Ti·∫øng Vi·ªát (wkr√≥tce)</a>"
  },
  {
    "row": 26,
    "rowsha": "ntGI5B+n9x96pV3ZG5GG83nmocQbxTJjKY7VVwa6Rq8=",
    "originContent": "        | <a href=\"#\" title=\"Coming soon\">Bahasa Indonesia (coming soon)</a>",
    "translatedContent": "        | <a href=\"#\" title=\"Coming soon\">Bahasa Indonesia (wkr√≥tce)</a>"
  },
  {
    "row": 27,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 28,
    "rowsha": "0OM5wNEm0TO56MEBvQzL7AUZM7/3OpgIeqRf2zFre3Q=",
    "originContent": "      </div>",
    "translatedContent": "      </div>"
  },
  {
    "row": 29,
    "rowsha": "fcjTfY+fs8YnY5slBs1sZvWPAqEQR7tzaBDO54skkGQ=",
    "originContent": "    </div>",
    "translatedContent": "    </div>"
  },
  {
    "row": 30,
    "rowsha": "+fQNH2ldI7UM/rqRscP3hUSWAmw1HvQ2wEKDN8JagT0=",
    "originContent": "  </details>",
    "translatedContent": "  </details>"
  },
  {
    "row": 31,
    "rowsha": "qsMmUbEPVnxGG5tPJV1vsfpoWbU2jYvZpRr5IKshzyM=",
    "originContent": "</div>",
    "translatedContent": "</div>"
  },
  {
    "row": 32,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 33,
    "rowsha": "VRGjp0FtfvQ89lbX/wJLis2ypCRtNJwe8ViIi29+Rko=",
    "originContent": "# TimeCapsule LLM",
    "translatedContent": "# TimeCapsule LLM"
  },
  {
    "row": 34,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 35,
    "rowsha": "yIU5euPsbVrUOG7MDKF9kStW2M4Bn4BSjmDAEYjCGgg=",
    "originContent": "*A language model trained **from scratch** exclusively on data from certain places and time periods to reduce modern bias and emulate the voice, vocabulary, and worldview of the era.*",
    "translatedContent": "*Model jƒôzykowy wytrenowany **od podstaw** wy≈ÇƒÖcznie na danych z wybranych miejsc i okres√≥w, aby ograniczyƒá wsp√≥≈Çczesne uprzedzenia i odtworzyƒá styl, s≈Çownictwo oraz ≈õwiatopoglƒÖd epoki.*"
  },
  {
    "row": 36,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 37,
    "rowsha": "06wDXO9Un3ot9kUKAGg7CaRsIVSkfS1d2m+EQ6HOFog=",
    "originContent": "Imagine if an AI model didnt just pretend to be historical but actually was.",
    "translatedContent": "Wyobra≈∫ sobie, ≈ºe model AI nie tylko udaje, ≈ºe jest historyczny, ale faktycznie taki jest."
  },
  {
    "row": 38,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 39,
    "rowsha": "FM0UQgFCFucUCjhd6pW/S6IBVnMSJbFjDx5+BItXuUc=",
    "originContent": "v0 and v0.5 built on [nanoGPT by Andrej Karpathy](https://github.com/karpathy/nanoGPT) Core training scripts and model architecture are his work. ",
    "translatedContent": "v0 i v0.5 oparte na [nanoGPT Andreja Karpathy](https://github.com/karpathy/nanoGPT). G≈Ç√≥wne skrypty treningowe oraz architektura modelu to jego dzie≈Ço. "
  },
  {
    "row": 40,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 41,
    "rowsha": "qJUbd5u/iOZOtuM+fYFPZOjgtKDl8iwUfAi1n3MVisI=",
    "originContent": "v1 built on [Phi 1.5 by Microsoft](https://huggingface.co/microsoft/phi-1_5)",
    "translatedContent": "v1 zbudowany na [Phi 1.5 by Microsoft](https://huggingface.co/microsoft/phi-1_5)"
  },
  {
    "row": 42,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 43,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "##  Zachowanie modelu i ograniczenia"
  },
  {
    "row": 44,
    "rowsha": "S8kboQ4LnLUhavjolKrTgNgwVOMJrwpnaY1CWGr6epQ=",
    "originContent": "##  Model Behavior & Limitations",
    "translatedContent": ""
  },
  {
    "row": 45,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "### **v0**  "
  },
  {
    "row": 46,
    "rowsha": "1nqZ1MR/Rxg5du0+tZch+QesCAT+5qMlbhJftBOVqDI=",
    "originContent": "### **v0**  ",
    "translatedContent": ""
  },
  {
    "row": 47,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "Wczesne podpowiedzi pokazujƒÖ, ≈ºe model odpowiada jƒôzykiem i zachowaniem z XIX wieku.  "
  },
  {
    "row": 48,
    "rowsha": "hlawgmI5oFABN37xYPae7PebQq1TP5c6DMT8b78524g=",
    "originContent": "Early prompts show the model responding with 1800's language and behavior. ",
    "translatedContent": "Przyk≈Çad: Podpowied≈∫: \"Who art Henry?\" i odpowied≈∫: \"I know that man, I have did not a black, the storm.\" "
  },
  {
    "row": 49,
    "rowsha": "5eCkvYiGa3VxONgXmVAvuTajgTbveIO0PKy313G2fos=",
    "originContent": "Example: Prompt: \"Who art Henry?\" and it replied \"I know that man, I have did not a black, the storm.\" ",
    "translatedContent": ""
  },
  {
    "row": 50,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "![Przyk≈Çadowy wynik TimeLockLLM](https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1850_v0/timelockllm_sample_output.png?raw=true)"
  },
  {
    "row": 51,
    "rowsha": "yKIR0teTc66wVDG+jdIyNmAzItXb2JH2ld3D7tm4qnM=",
    "originContent": "![TimeLockLLM Sample Output](https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1850_v0/timelockllm_sample_output.png?raw=true)",
    "translatedContent": ""
  },
  {
    "row": 52,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "- Brak wzmianki o nowoczesnych konceptach  "
  },
  {
    "row": 53,
    "rowsha": "iCVdbo9EUfepGTS1z1bOwgFn1wDAa9zhHoBLJxEw1w8=",
    "originContent": "- No mention of modern concepts  ",
    "translatedContent": "- W wiƒôkszo≈õci s≈Çownictwo zgodne z epokƒÖ  "
  },
  {
    "row": 54,
    "rowsha": "khHeh5VmbIuCnyoNCTDAXLsQOpnqbamm8vyOjvWVmLE=",
    "originContent": "- Mostly era-accurate vocabulary  ",
    "translatedContent": "- Zdania sƒÖ w wiƒôkszo≈õci niesp√≥jne (oczekiwane dla ~187MB danych treningowych)"
  },
  {
    "row": 55,
    "rowsha": "UP5LBmH8evd8yPger3Fjvs1PXYiVAALQC0JWmcmlN08=",
    "originContent": "- Sentences are mostly incoherent (expected for ~187MB training data)",
    "translatedContent": ""
  },
  {
    "row": 56,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "### **v0.5** "
  },
  {
    "row": 57,
    "rowsha": "5p60D9yLuB40iACJ6apiWJq8lt1AqZAyvFkG70v4xco=",
    "originContent": "### **v0.5** ",
    "translatedContent": ""
  },
  {
    "row": 58,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "ZnaczƒÖca poprawa w stosunku do v0.  "
  },
  {
    "row": 59,
    "rowsha": "IPr+C8pVE68OvudYYmIOcbEumcoTmjBiq3HmXPghcvU=",
    "originContent": "A significant improvement over v0.  ",
    "translatedContent": "- Wiktoria≈Ñski styl pisania, poprawna interpunkcja, w wiƒôkszo≈õci gramatyczne zdania  "
  },
  {
    "row": 60,
    "rowsha": "VEokY2Qi826s5lAKKkVoOd5hju8hvOxG21P/L2LPz9k=",
    "originContent": "- Victorian writing style, proper punctuation, mostly grammatical sentences  ",
    "translatedContent": "- Nadal wysoki poziom halucynacji fakt√≥w  "
  },
  {
    "row": 61,
    "rowsha": "hkitRVnW6jxtd+R18O5Olb5eqNIJGCKv4Yt2I+yLrWE=",
    "originContent": "- Still high factual hallucination rate  ",
    "translatedContent": "- Szum OCR (‚ÄûDigitized by Google‚Äù) nadal obecny w wynikach"
  },
  {
    "row": 62,
    "rowsha": "qlWBqyQVUBsL120iExHvs0PDrN2m0WeMIyRHeHJ1qhM=",
    "originContent": "- OCR noise (‚ÄúDigitized by Google‚Äù) still present in outputs",
    "translatedContent": ""
  },
  {
    "row": 63,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "![Przyk≈Çadowy wynik TimeLockLLM](https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1875_v0.5/fellowcitizens.png?raw=true)"
  },
  {
    "row": 64,
    "rowsha": "8DhXpgpVtg05XdyplRHf49EFOQNCJVzXA9RpmJQ+y9U=",
    "originContent": "![TimeLockLLM Sample Output](https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1875_v0.5/fellowcitizens.png?raw=true)",
    "translatedContent": ""
  },
  {
    "row": 65,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "### **v1**"
  },
  {
    "row": 66,
    "rowsha": "mQ9MARMITxOHtqSNIP76nXvTlEM8Ope3qbQ/YG1h6/8=",
    "originContent": "### **v1**",
    "translatedContent": ""
  },
  {
    "row": 67,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "Pierwszy model, kt√≥ry przypomina sobie i ≈ÇƒÖczy prawdziwe wydarzenie historyczne z rzeczywistƒÖ postaciƒÖ z zestawu danych."
  },
  {
    "row": 68,
    "rowsha": "sAlnUjWbUBk6czBOHW/IgxyE98WYhX0LrIYmZBr8P2Y=",
    "originContent": "First model to recall and connect a real historical event with an actual figure from the dataset.",
    "translatedContent": ""
  },
  {
    "row": 69,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "Przyk≈Çad: Podpowied≈∫: \"It was the year of our Lord 1834\" "
  },
  {
    "row": 70,
    "rowsha": "Cd0DPnkqItUnSk3fHx9ckSSN6MNcZnsEX3S44GZyxTw=",
    "originContent": "Example: Prompt: \"It was the year of our Lord 1834\" ",
    "translatedContent": ""
  },
  {
    "row": 71,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "Odpowied≈∫: \"It was the year of our Lord 1834 and the streets of London were filled with protest and petition. The cause, as many re counted, was not bound in the way of private, but having taken up the same day in the day of Lord Palmerston, the public will receive a short statement of the difficulties under which the day of law has reached us. It is a matter of deep regret, that the present events in the history of the world are clear, and consequently will be'known. It is not true that the very men who first settled in the Gospel at Jerusalem should have so extensive and so interesting a record of the prosperity and prosperity\" "
  },
  {
    "row": 72,
    "rowsha": "zvm/1tcaMFjcQmuN7y0hczAbbgAwaKRtjBpah5/+kb8=",
    "originContent": "The output: \"It was the year of our Lord 1834 and the streets of London were filled with protest and petition. The cause, as many re counted, was not bound in the way of private, but having taken up the same day in the day of Lord Palmerston, the public will receive a short statement of the difficulties under which the day of law has reached us. It is a matter of deep regret, that the present events in the history of the world are clear, and consequently will be'known. It is not true that the very men who first settled in the Gospel at Jerusalem should have so extensive and so interesting a record of the prosperity and prosperity\" ",
    "translatedContent": ""
  },
  {
    "row": 73,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "Na poczƒÖtku za≈Ço≈ºy≈Çem, ≈ºe protest m√≥g≈Ç przypadkowo mieƒá miejsce w tym samym roku, ale sp√≥jrz na to: ![1834protest](https://raw.githubusercontent.com/haykgrigo3/TimeCapsuleLLM/main/1834protest.png)"
  },
  {
    "row": 74,
    "rowsha": "WfSfj2g4CByfYQWI59s4C3EwGLZuWfz1t4w49a49e+8=",
    "originContent": "At first I assumed that a protest might have coincidentally taken place the same year but take a look at this: ![1834protest](https://raw.githubusercontent.com/haykgrigo3/TimeCapsuleLLM/main/1834protest.png)",
    "translatedContent": ""
  },
  {
    "row": 75,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "### Dlaczego to jest wa≈ºne:"
  },
  {
    "row": 76,
    "rowsha": "qlFf3SlVZpptxE7ExYx9wjs1lBnO/bsCjUl1Q4Sw2ds=",
    "originContent": "### Why this matters:",
    "translatedContent": ""
  },
  {
    "row": 77,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "To pierwszy przyk≈Çad, gdy jeden z moich modeli po≈ÇƒÖczy≈Ç rok z prawdziwym wydarzeniem historycznym i rzeczywistƒÖ osobƒÖ zwiƒÖzanƒÖ z tym wydarzeniem (Lord Palmerston). Wcze≈õniejsze modele (v0 i v0.5) potrafi≈Çy na≈õladowaƒá style pisania z XIX wieku, ale zawsze wymy≈õla≈Çy wydarzenia, osoby i fakty. To pokazuje, ≈ºe model zaczyna zapamiƒôtywaƒá informacje z zestawu danych "
  },
  {
    "row": 78,
    "rowsha": "WdZfxluSvMeRhCl5u8NEkZI+F2o+eDrUIZyWPgHGv6w=",
    "originContent": "This is the first example of one of my models connecting a year to both a real historical event and a real person tied to that event (Lord Palmerston). Earlier models (v0 and v0.5) could mimic writing styles of the 19th century but would always hallucinate events, people and facts. This shows the model is beggining to remember things from the dataset ",
    "translatedContent": ""
  },
  {
    "row": 79,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "## NadchodzƒÖce plany "
  },
  {
    "row": 80,
    "rowsha": "xt81v+AyDswOM8KVPmSYl1lfW4vISpujtQjRWm0mKbA=",
    "originContent": "## Upcoming Plans ",
    "translatedContent": ""
  },
  {
    "row": 81,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "- Na Internet Archive znajduje siƒô prawie 175 000 tekst√≥w opublikowanych w Londynie w latach 1800-1875"
  },
  {
    "row": 82,
    "rowsha": "CulYLHqIw5Hn1cLDvlekSWBe1moOd8QSIirjeM77tlk=",
    "originContent": "- There are nearly 175,000 texts published in London from 1800-1875 on Internet Archive ",
    "translatedContent": "- Planujƒô rozszerzyƒá korpus i bardziej go oczy≈õciƒá, aby uzyskaƒá lepsze zdolno≈õci rozumowania"
  },
  {
    "row": 83,
    "rowsha": "VWINtuHshK3Fs4MeBmv24/pZC0iMQ70HtMIowLnrsAI=",
    "originContent": "- I plan on expanding the corpus and cleaning it more for better reasoning abilities",
    "translatedContent": "- Rozszerzenie na r√≥≈ºne regiony i okresy czasu w celu stworzenia bardziej historycznych modeli"
  },
  {
    "row": 84,
    "rowsha": "3b7jQ1J58CCfC/VV9FWJY23SOlvhzx/vIVth3ZBIPog=",
    "originContent": "- Expanding to different regions and time periods for more historical models",
    "translatedContent": ""
  },
  {
    "row": 85,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 86,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "## Jak korzystaƒá"
  },
  {
    "row": 87,
    "rowsha": "yJlGQKI3p2nVYC1uqNa6eKPSIzUW38uRiGu0PspqvUU=",
    "originContent": "## How to Use",
    "translatedContent": ""
  },
  {
    "row": 88,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "Ten projekt koncentruje siƒô g≈Ç√≥wnie na kuracji danych historycznych, przygotowaniu ich do treningu i budowie tokenizera. Nie bƒôdƒô omawiaƒá pe≈Çnego procesu treningu LLM, w tym celu odsy≈Çam do nanoGPT Andreja Karpathy."
  },
  {
    "row": 89,
    "rowsha": "XVoXr9uzZwN09vboETojEQJe057RBzcMUjXmQRCB/jo=",
    "originContent": "This project focuses mostly on curating historical data, preparing it for training and building a tokenizer. I am not going to cover the full LLM training process, for that refer to nanoGPT by Andrej Karpathy.",
    "translatedContent": ""
  },
  {
    "row": 90,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "### Krok 1: Zbierz i przygotuj teksty historyczne"
  },
  {
    "row": 91,
    "rowsha": "h3A3o0uEgrm0Te8o4iW7R0m1bNwx7jj9Q5iUhhV0iTI=",
    "originContent": "### Step 1: Gather and Prepare Historical Texts ",
    "translatedContent": ""
  },
  {
    "row": 92,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "- Zbierz pliki .txt ksiƒÖ≈ºek, dokument√≥w itd. z domeny publicznej z wybranego okresu (np. Londyn 1800-1850)"
  },
  {
    "row": 93,
    "rowsha": "E60jdnnHtQ07Lgqtx5VBWz6jh3ysKu7LMtZHrIYaQiQ=",
    "originContent": "- Collect .txt files of public domain books, documents, etc from your chosen time period (e.g., London 1800-1850) ",
    "translatedContent": "- Trzymaj siƒô wybranego okna czasowego/miejsca  "
  },
  {
    "row": 94,
    "rowsha": "/VflzaebH3p9kM3YtRzEWV0i/lVdD/pGby0wiJoXoco=",
    "originContent": "- Keep them within your chosen time/place window  ",
    "translatedContent": "- Oczy≈õƒá pliki tekstowe za pomocƒÖ skryptu lub rƒôcznie usu≈Ñ nag≈Ç√≥wki/stopki z Project Gutenberg, nowoczesne adnotacje oraz b≈Çƒôdy OCR."
  },
  {
    "row": 95,
    "rowsha": "6P9O4yLTQNPt+lgfziVbtyNP+4+SBhj6UvzpJ+Br7PM=",
    "originContent": "- Clean the text files using a script or manually remove headers/footer from Project Gutenberg, Modern annotations or things like OCR errors.",
    "translatedContent": ""
  },
  {
    "row": 96,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "### Krok 2: Zbuduj w≈Çasny tokenizer"
  },
  {
    "row": 97,
    "rowsha": "QHGXZGXfahA0jwtugXfFPK3RfnoD/MgGK7KZOEu7Yu0=",
    "originContent": "### Step 2: Build a Custom Tokenizer",
    "translatedContent": ""
  },
  {
    "row": 98,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "- Uruchom train_tokenizer.py lub train_tokenizer_hf.py na oczyszczonych danych."
  },
  {
    "row": 99,
    "rowsha": "hPnDq1u2xQSmYVNea/p6gaqpP4bMQD0lWroth4bud9A=",
    "originContent": "- Run train_tokenizer.py or train_tokenizer_hf.py on the cleaned data.",
    "translatedContent": "- To wygeneruje vocab.json i merges.txt"
  },
  {
    "row": 100,
    "rowsha": "ib4aP51Hu/ktXBqXfyiOtGRLdTUEhyEupPgINhe9JwA=",
    "originContent": "- This will give you vocab.json and merges.txt",
    "translatedContent": "- Te pliki definiujƒÖ s≈Çownik i regu≈Çy ≈ÇƒÖczenia dla Twojego modelu"
  },
  {
    "row": 101,
    "rowsha": "Bit9udkCe0pa2QERa6r17MT8TZN59hctFxW7DQ/7Ka4=",
    "originContent": "- Thes files define vocab and merge rules for your model",
    "translatedContent": ""
  },
  {
    "row": 102,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "### Krok 3: Wytrenuj sw√≥j model"
  },
  {
    "row": 103,
    "rowsha": "NMTP0o8ite3isz8AN3pbJxnD1y/ULsyqoGpOqqCM9k0=",
    "originContent": "### Step 3: Train Your Model ",
    "translatedContent": ""
  },
  {
    "row": 104,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "- Zapoznaj siƒô z [nanoGPT Andreja Karpathy](https://github.com/karpathy/nanoGPT) w celu poznania procesu treningu lub dokumentacjƒÖ wybranej architektury."
  },
  {
    "row": 105,
    "rowsha": "b/wzY4grG20GGDNSiBPVe1mYZhuqNzNEaHz5XhGaZ1I=",
    "originContent": "- Refer to [nanoGPT by Andrej Karpathy](https://github.com/karpathy/nanoGPT) for the training process or your chosen architecture‚Äôs docs.",
    "translatedContent": ""
  },
  {
    "row": 106,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "# FAQ"
  },
  {
    "row": 107,
    "rowsha": "OoCxyGfPN5TmdzAkaPphtPx303MJJ7vpfWbKrufGH5g=",
    "originContent": "# FAQ",
    "translatedContent": ""
  },
  {
    "row": 108,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "## Czym jest Selektywne Trening Temporalny?"
  },
  {
    "row": 109,
    "rowsha": "+5dDgPw4ILEotxso4tjjjz1cxwUei16yNQPDUKbgxoo=",
    "originContent": "## What is Selective Temporal Training ?",
    "translatedContent": ""
  },
  {
    "row": 110,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "Selektywne Trening Temporalny (STT) to metodologia uczenia maszynowego, w kt√≥rej wszystkie dane treningowe sƒÖ specjalnie dobrane, aby mie≈õci≈Çy siƒô w okre≈õlonym okresie historycznym. Robi siƒô to, aby modelowaƒá jƒôzyk i wiedzƒô z danej epoki bez wp≈Çywu nowoczesnych koncepcji. Na przyk≈Çad, obecny model (v0.5) jest wytrenowany wy≈ÇƒÖcznie na danych z lat 1800-1875, nie jest dostrajany, lecz trenowany od zera, co skutkuje wynikami odzwierciedlajƒÖcymi styl jƒôzykowy i kontekst historyczny tamtego okresu."
  },
  {
    "row": 111,
    "rowsha": "hooEARKH4r/sDPh7JUtZAZ6TYMvBkTLZIcfw3g83xos=",
    "originContent": "Selective Temporal Training (STT) is a machine learning methodology where all training data is specifically curated to fall within a specific historical time period. It's done in order to model the language and knowledge of that era without influence from modern concepts. For example, the current model I have now (v0.5) is trained on data exclusively from 1800-1875, it's not fine tuned but trained from scratch resulting in output that reflects the linguistic style and historical context of that time period.",
    "translatedContent": ""
  },
  {
    "row": 112,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "## Dlaczego nie u≈ºyƒá po prostu fine-tuningu lub LoRA?"
  },
  {
    "row": 113,
    "rowsha": "dVMKQ2mPI1Spc6x6r/jNG0PIR5YKpalU4MXx9JmKp/I=",
    "originContent": "## Why not just use fine-tuning or LoRA?",
    "translatedContent": ""
  },
  {
    "row": 114,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "W tym projekcie staram siƒô stworzyƒá model jƒôzykowy wolny od wsp√≥≈Çczesnych uprzedze≈Ñ. Je≈õli dostrojƒô co≈õ takiego jak GPT-2, to jest ju≈º wstƒôpnie wytrenowane i tych informacji nie da siƒô usunƒÖƒá. Je≈õli wytrenujƒô od zera, model jƒôzykowy nie bƒôdzie udawa≈Ç starego, po prostu nim bƒôdzie. Celem projektu jest obecnie stworzenie czego≈õ, co potrafi rozumowaƒá wy≈ÇƒÖcznie na podstawie wiedzy z londy≈Ñskich ksiƒÖ≈ºek wydanych w latach 1800-1875."
  },
  {
    "row": 115,
    "rowsha": "uUg17WnHfiRHAiHJTO+5TIAJlkny2eH+Ov6Lm0GmrJQ=",
    "originContent": "For this project I'm trying to create a language model that is unclouded from modern bias. If I fine-tune something like GPT-2, it's already pre-trained and that information won't go away. If I train from scratch the language model won't pretend to be old, it just will be. The Goal for this project right now is to create something can reason exclusively using knowledge from London books published between 1800 and 1875.",
    "translatedContent": ""
  },
  {
    "row": 116,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "## Jakie dane wykorzysta≈Çe≈õ do treningu?"
  },
  {
    "row": 117,
    "rowsha": "ByP4WlNmMoG6WIiLJNd6b080/DSciCgWmj9aYSJjAF0=",
    "originContent": "## What kind of data did you use for training?",
    "translatedContent": ""
  },
  {
    "row": 118,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "Korzystam z ksiƒÖ≈ºek, dokument√≥w prawnych, gazet i innych pism z Londynu z lat 1800‚Äì1875. Lista, kt√≥rƒÖ podlinkowa≈Çem (dla v0), zawiera oko≈Ço 200 pozycji, ale do pierwszego treningu u≈ºy≈Çem tylko 50 plik√≥w o ≈ÇƒÖcznej wielko≈õci ~187 MB. Mo≈ºesz zobaczyƒá listƒô dokument√≥w:"
  },
  {
    "row": 119,
    "rowsha": "TiKmhaEUee3SRrWijVMwW3s/qbNf2ziThQdK9PtiW9M=",
    "originContent": "I'm using books, legal documents, newspapers, and other writings from 1800‚Äì1875 London. The list I linked (for v0) has like 200 but for the first training I just used 50 files about ~187 MB. You can view a list of the documents:",
    "translatedContent": "https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/Copy%20of%20London%20Documents%20for%20Time%20Capsule%20LLM.txt"
  },
  {
    "row": 120,
    "rowsha": "0mxyGiLJxzp9JPCg1oA+nbIwAKJbEC4ei9kSV3Gp84Y=",
    "originContent": "https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/Copy%20of%20London%20Documents%20for%20Time%20Capsule%20LLM.txt",
    "translatedContent": ""
  },
  {
    "row": 121,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 122,
    "rowsha": "m08SxkUzMWecQCroTF6uw3RhQ50sDm4BaoM0Ql/huS0=",
    "originContent": "Dataset sizes:",
    "translatedContent": "Rozmiary zbior√≥w danych:"
  },
  {
    "row": 123,
    "rowsha": "uah9doEnpRGciSUsNDHMkbOxtzCOyu4QuAM07AAUp1o=",
    "originContent": "v0: ~187MB",
    "translatedContent": "v0: ~187MB"
  },
  {
    "row": 124,
    "rowsha": "4bhyzflpyjgeXMXaoAIxXATaPQqBpKaX945kxvp1ewE=",
    "originContent": "v0.5: ~435MB ",
    "translatedContent": "v0.5: ~435MB "
  },
  {
    "row": 125,
    "rowsha": "thwQOIv1UCJQK/UZwcFrVR5tZmLvXp7mbQYGfpiFTN8=",
    "originContent": "v1: ~6.25GB ",
    "translatedContent": "v1: ~6,25GB "
  },
  {
    "row": 126,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 127,
    "rowsha": "rrsRMYLHKsjbkzYRKilseYJKKApHSgo9buiBkZFSvlY=",
    "originContent": "## How large are the models ?",
    "translatedContent": "## Jak du≈ºe sƒÖ modele?"
  },
  {
    "row": 128,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 129,
    "rowsha": "MVeUG+6lIlH89E699W2WfE+eQmKEul25KNMIY8AtB6M=",
    "originContent": "V0: 16M Parameters",
    "translatedContent": "V0: 16M parametr√≥w"
  },
  {
    "row": 130,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 131,
    "rowsha": "hQIpZXf/UvJi3QFJEM6jrjG7vnb9cvTFg/cvKv0buqM=",
    "originContent": "V0.5 123M Parameters",
    "translatedContent": "V0.5 123M parametr√≥w"
  },
  {
    "row": 132,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 133,
    "rowsha": "26WDqv9Q/x8glaWZTkjUWL5VNwuuXgUuXs51BhKEskk=",
    "originContent": "V1: 700M Parameters",
    "translatedContent": "V1: 700M parametr√≥w"
  },
  {
    "row": 134,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 135,
    "rowsha": "zaP9HMP5oBcc9MGTkbFGzMO2XxeWWl+QlS9Yz9nfNXc=",
    "originContent": "# Training Specs ? ",
    "translatedContent": "# Specyfikacje treningu?"
  },
  {
    "row": 136,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 137,
    "rowsha": "7TPD+AUCDeUFol0fzwax1DEgBjstPoRauQ1zQAHJdc8=",
    "originContent": "# V0/V0.5",
    "translatedContent": "# V0/V0.5"
  },
  {
    "row": 138,
    "rowsha": "EH8H1HW/C4Tb7LfJgVUnVGsk4pF9l40Rlev8tAkKhjI=",
    "originContent": "GPU: Geforce rtx 4060",
    "translatedContent": "GPU: Geforce rtx 4060"
  },
  {
    "row": 139,
    "rowsha": "vo3FdN37kY6VUB7PruRKfBPJDgsVJyBHIUCn/g8mt68=",
    "originContent": "CPU: i5-13400F ",
    "translatedContent": "CPU: i5-13400F "
  },
  {
    "row": 140,
    "rowsha": "W8fXPiQKUkoNso0PPfTvjYMy0IYo85j+gNXmB0aERO4=",
    "originContent": "Ram: 16GB DDR5.",
    "translatedContent": "Ram: 16GB DDR5."
  },
  {
    "row": 141,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 142,
    "rowsha": "xpPrp95oVxh/XiVWlKlS072VerOoQbJEFU46i3XD2mk=",
    "originContent": "# V1",
    "translatedContent": "# V1"
  },
  {
    "row": 143,
    "rowsha": "cBfLeLi5ORliO9eNHlkjuWbV5U2y03sn/wFBoChMpoc=",
    "originContent": "GPU: A100 rented",
    "translatedContent": "GPU: A100 wynajƒôty"
  },
  {
    "row": 144,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 145,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 146,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 147,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 148,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 149,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 150,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 151,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 152,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 153,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 154,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 155,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 156,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  }
]