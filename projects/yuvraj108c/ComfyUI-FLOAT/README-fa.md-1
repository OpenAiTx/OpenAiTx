{
  "id": 1,
  "origin": "<div align=\"center\">\n\n# ComfyUI FLOAT \n\n[![python](https://img.shields.io/badge/python-3.10.12-green)](https://www.python.org/downloads/release/python-31012/)\n[![arXiv](https://img.shields.io/badge/arXiv%20paper-2412.09013-b31b1b.svg)](https://arxiv.org/abs/2412.01064) \n[![by-nc-sa/4.0](https://img.shields.io/badge/license-CC--BY--NC--SA--4.0-lightgrey)](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en)\n\n</div>\n\nThis project provides a ComfyUI wrapper of [FLOAT](https://github.com/deepbrainai-research/float) for Generative Motion Latent Flow Matching for Audio-driven Talking Portrait\n\nFor a more advanced and maintained version, check out: [ComfyUI-FLOAT_Optimized](https://github.com/set-soft/ComfyUI-FLOAT_Optimized)\n\n<div align=\"center\">\n  <video src=\"https://github.com/user-attachments/assets/36626b4a-d3e5-4db9-87a7-ca0e949daee0\" />\n</div> \n\n\n## â­ Support\nIf you like my projects and wish to see updates and new features, please consider supporting me. It helps a lot! \n\n[![ComfyUI-Depth-Anything-Tensorrt](https://img.shields.io/badge/ComfyUI--Depth--Anything--Tensorrt-blue?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-Depth-Anything-Tensorrt)\n[![ComfyUI-Upscaler-Tensorrt](https://img.shields.io/badge/ComfyUI--Upscaler--Tensorrt-blue?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-Upscaler-Tensorrt)\n[![ComfyUI-Dwpose-Tensorrt](https://img.shields.io/badge/ComfyUI--Dwpose--Tensorrt-blue?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-Dwpose-Tensorrt)\n[![ComfyUI-Rife-Tensorrt](https://img.shields.io/badge/ComfyUI--Rife--Tensorrt-blue?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-Rife-Tensorrt)\n\n[![ComfyUI-Whisper](https://img.shields.io/badge/ComfyUI--Whisper-gray?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-Whisper)\n[![ComfyUI_InvSR](https://img.shields.io/badge/ComfyUI__InvSR-gray?style=flat-square)](https://github.com/yuvraj108c/ComfyUI_InvSR)\n[![ComfyUI-FLOAT](https://img.shields.io/badge/ComfyUI--FLOAT-gray?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-FLOAT)\n[![ComfyUI-Thera](https://img.shields.io/badge/ComfyUI--Thera-gray?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-Thera)\n[![ComfyUI-Video-Depth-Anything](https://img.shields.io/badge/ComfyUI--Video--Depth--Anything-gray?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-Video-Depth-Anything)\n[![ComfyUI-PiperTTS](https://img.shields.io/badge/ComfyUI--PiperTTS-gray?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-PiperTTS)\n\n[![buy-me-coffees](https://i.imgur.com/3MDbAtw.png)](https://www.buymeacoffee.com/yuvraj108cZ)\n[![paypal-donation](https://i.imgur.com/w5jjubk.png)](https://paypal.me/yuvraj108c)\n---\n\n## ğŸš€ Installation\n\n```bash\ngit clone https://github.com/yuvraj108c/ComfyUI-FLOAT.git\ncd ./ComfyUI-FLOAT\npip install -r requirements.txt\n```\n\n## â˜€ï¸ Usage\n\n- Load [example workflow](https://raw.githubusercontent.com/yuvraj108c/ComfyUI-FLOAT/master/float_workflow.json) \n- Upload driving image and audio, click queue\n- [Models](https://huggingface.co/yuvraj108c/float/tree/main) autodownload to `/ComfyUI/models/float`\n- The models are organized as follows:\n    ```.bash\n    |-- float.pth                                       # main model\n    |-- wav2vec2-base-960h/                             # audio encoder\n    |   |-- config.json\n    |   |-- model.safetensors\n    |   |-- preprocessor_config.json\n    |-- wav2vec-english-speech-emotion-recognition/     # emotion encoder\n        |-- config.json\n        |-- preprocessor_config.json\n        |-- pytorch_model.bin\n\n## ğŸ› ï¸ Parameters\n- `ref_image`: Reference image with a face (must have batch size 1)\n- `ref_audio`: Reference audio (For long audios (e.g 3+ minutes), ensure that you have enough ram/vram)\n- `a_cfg_scale`: Audio classifier-free guidance scale (default:2)\n- `r_cfg_scale`: Reference classifier-free guidance scale (default:1)\n- `emotion`: none, angry, disgust, fear, happy, neutral, sad, surprise (default:none)\n- `e_cfg_scale`: Intensity of emotion (default:1). For more emotion intensive video, try large value from 5 to 10\n- `crop`: Enable only if the reference image does not have a centered face\n- `fps`: Frame rate of the output video (default:25)\n\n   \n## Citation\n```bibtex\n@article{ki2024float,\n  title={FLOAT: Generative Motion Latent Flow Matching for Audio-driven Talking Portrait},\n  author={Ki, Taekyung and Min, Dongchan and Chae, Gyeongsu},\n  journal={arXiv preprint arXiv:2412.01064},\n  year={2024}\n}\n```\n\n## Acknowledgments\nThanks to [simplepod.ai](https://simplepod.ai/) for providing GPU servers\n\n## License\n\n[Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)](https://creativecommons.org/licenses/by-nc-sa/4.0/)\n",
  "origin_sha": "J1w6fzZLWGVxXZ6uzQqWxdmD+gFnLFEp9FPER7LLsj4=",
  "translate": "<div align=\"center\">\n\n# ComfyUI FLOAT \n\n[![python](https://img.shields.io/badge/python-3.10.12-green)](https://www.python.org/downloads/release/python-31012/)\n[![arXiv](https://img.shields.io/badge/arXiv%20paper-2412.09013-b31b1b.svg)](https://arxiv.org/abs/2412.01064) \n[![by-nc-sa/4.0](https://img.shields.io/badge/license-CC--BY--NC--SA--4.0-lightgrey)](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en)\n\n</div>\n\nØ§ÛŒÙ† Ù¾Ø±ÙˆÚ˜Ù‡ ÛŒÚ© Ø¨Ø³ØªÙ‡â€ŒÛŒ Ø±Ø§Ø¨Ø· ComfyUI Ø¨Ø±Ø§ÛŒ [FLOAT](https://github.com/deepbrainai-research/float) Ø¬Ù‡Øª Â«ØªØ·Ø¨ÛŒÙ‚ Ø¬Ø±ÛŒØ§Ù† Ù†Ù‡ÙØªÙ‡ Ø­Ø±Ú©ØªÛŒ Ù…ÙˆÙ„Ø¯ Ø¨Ø±Ø§ÛŒ Ù¾Ø±ØªØ±Ù‡ Ø³Ø®Ù†Ú¯Ùˆ Ø¨Ø± Ø§Ø³Ø§Ø³ ØµÙˆØªÂ» Ø§Ø±Ø§Ø¦Ù‡ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯.\n\nØ¨Ø±Ø§ÛŒ Ù†Ø³Ø®Ù‡â€ŒØ§ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡â€ŒØªØ± Ùˆ Ø¨Ù‡â€ŒØ±ÙˆØ²ØªØ±ØŒ Ø¨Ù‡ Ø§ÛŒÙ†Ø¬Ø§ Ù…Ø±Ø§Ø¬Ø¹Ù‡ Ú©Ù†ÛŒØ¯: [ComfyUI-FLOAT_Optimized](https://github.com/set-soft/ComfyUI-FLOAT_Optimized)\n\n<div align=\"center\">\n  <video src=\"https://github.com/user-attachments/assets/36626b4a-d3e5-4db9-87a7-ca0e949daee0\" />\n</div> \n\n\n## â­ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ\nØ§Ú¯Ø± Ù¾Ø±ÙˆÚ˜Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ù† Ø±Ø§ Ø¯ÙˆØ³Øª Ø¯Ø§Ø±ÛŒØ¯ Ùˆ Ù…Ø§ÛŒÙ„ Ø¨Ù‡ Ù…Ø´Ø§Ù‡Ø¯Ù‡ Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒâ€ŒÙ‡Ø§ Ùˆ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯ Ù‡Ø³ØªÛŒØ¯ØŒ Ù„Ø·ÙØ§Ù‹ Ø§Ø² Ù…Ù† Ø­Ù…Ø§ÛŒØª Ú©Ù†ÛŒØ¯. Ø§ÛŒÙ† Ú©Ø§Ø± Ø¨Ø³ÛŒØ§Ø± Ú©Ù…Ú©â€ŒÚ©Ù†Ù†Ø¯Ù‡ Ø§Ø³Øª!\n\n[![ComfyUI-Depth-Anything-Tensorrt](https://img.shields.io/badge/ComfyUI--Depth--Anything--Tensorrt-blue?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-Depth-Anything-Tensorrt)\n[![ComfyUI-Upscaler-Tensorrt](https://img.shields.io/badge/ComfyUI--Upscaler--Tensorrt-blue?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-Upscaler-Tensorrt)\n[![ComfyUI-Dwpose-Tensorrt](https://img.shields.io/badge/ComfyUI--Dwpose--Tensorrt-blue?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-Dwpose-Tensorrt)\n[![ComfyUI-Rife-Tensorrt](https://img.shields.io/badge/ComfyUI--Rife--Tensorrt-blue?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-Rife-Tensorrt)\n\n[![ComfyUI-Whisper](https://img.shields.io/badge/ComfyUI--Whisper-gray?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-Whisper)\n[![ComfyUI_InvSR](https://img.shields.io/badge/ComfyUI__InvSR-gray?style=flat-square)](https://github.com/yuvraj108c/ComfyUI_InvSR)\n[![ComfyUI-FLOAT](https://img.shields.io/badge/ComfyUI--FLOAT-gray?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-FLOAT)\n[![ComfyUI-Thera](https://img.shields.io/badge/ComfyUI--Thera-gray?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-Thera)\n[![ComfyUI-Video-Depth-Anything](https://img.shields.io/badge/ComfyUI--Video--Depth--Anything-gray?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-Video-Depth-Anything)\n[![ComfyUI-PiperTTS](https://img.shields.io/badge/ComfyUI--PiperTTS-gray?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-PiperTTS)\n\n[![buy-me-coffees](https://i.imgur.com/3MDbAtw.png)](https://www.buymeacoffee.com/yuvraj108cZ)\n[![paypal-donation](https://i.imgur.com/w5jjubk.png)](https://paypal.me/yuvraj108c)\n---\n\n## ğŸš€ Ù†ØµØ¨\n\n```bash\ngit clone https://github.com/yuvraj108c/ComfyUI-FLOAT.git\ncd ./ComfyUI-FLOAT\npip install -r requirements.txt\n```\n\n## â˜€ï¸ Ø§Ø³ØªÙØ§Ø¯Ù‡\n\n- [Ù†Ù…ÙˆÙ†Ù‡ Ø¬Ø±ÛŒØ§Ù† Ú©Ø§Ø±ÛŒ](https://raw.githubusercontent.com/yuvraj108c/ComfyUI-FLOAT/master/float_workflow.json) Ø±Ø§ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ú©Ù†ÛŒØ¯\n- ØªØµÙˆÛŒØ± Ùˆ ØµÙˆØª Ø±Ø§Ù‡Ø¨Ø± Ø±Ø§ Ø¢Ù¾Ù„ÙˆØ¯ Ú©Ø±Ø¯Ù‡ Ùˆ Ø±ÙˆÛŒ ØµÙ Ú©Ù„ÛŒÚ© Ú©Ù†ÛŒØ¯\n- [Ù…Ø¯Ù„â€ŒÙ‡Ø§](https://huggingface.co/yuvraj108c/float/tree/main) Ø¨Ù‡â€ŒØµÙˆØ±Øª Ø®ÙˆØ¯Ú©Ø§Ø± Ø¯Ø± Ù…Ø³ÛŒØ± `/ComfyUI/models/float` Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯\n- Ø³Ø§Ø®ØªØ§Ø± Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ø¨Ù‡ Ø´Ø±Ø­ Ø²ÛŒØ± Ø§Ø³Øª:\n    ```.bash\n    |-- float.pth                                       # Ù…Ø¯Ù„ Ø§ØµÙ„ÛŒ\n    |-- wav2vec2-base-960h/                             # Ø±Ù…Ø²Ú¯Ø°Ø§Ø± ØµÙˆØª\n    |   |-- config.json\n    |   |-- model.safetensors\n    |   |-- preprocessor_config.json\n    |-- wav2vec-english-speech-emotion-recognition/     # Ø±Ù…Ø²Ú¯Ø°Ø§Ø± Ø§Ø­Ø³Ø§Ø³Ø§Øª\n        |-- config.json\n        |-- preprocessor_config.json\n        |-- pytorch_model.bin\n\n## ğŸ› ï¸ Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§\n- `ref_image`: ØªØµÙˆÛŒØ± Ù…Ø±Ø¬Ø¹ Ø¨Ø§ Ú†Ù‡Ø±Ù‡ (Ø¨Ø§ÛŒØ¯ Ø¯Ø§Ø±Ø§ÛŒ batch size Ø¨Ø±Ø§Ø¨Ø± Û± Ø¨Ø§Ø´Ø¯)\n- `ref_audio`: ØµÙˆØª Ù…Ø±Ø¬Ø¹ (Ø¨Ø±Ø§ÛŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ ØµÙˆØªÛŒ Ø·ÙˆÙ„Ø§Ù†ÛŒ (Ù…Ø«Ù„Ø§Ù‹ Ø¨ÛŒØ´ Ø§Ø² Û³ Ø¯Ù‚ÛŒÙ‚Ù‡)ØŒ Ù…Ø·Ù…Ø¦Ù† Ø´ÙˆÛŒØ¯ Ú©Ù‡ RAM/VRAM Ú©Ø§ÙÛŒ Ø¯Ø§Ø±ÛŒØ¯)\n- `a_cfg_scale`: Ù…Ù‚ÛŒØ§Ø³ Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ø¨Ø¯ÙˆÙ† Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ÛŒ ØµÙˆØª (Ù¾ÛŒØ´â€ŒÙØ±Ø¶:Û²)\n- `r_cfg_scale`: Ù…Ù‚ÛŒØ§Ø³ Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ø¨Ø¯ÙˆÙ† Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ù…Ø±Ø¬Ø¹ (Ù¾ÛŒØ´â€ŒÙØ±Ø¶:Û±)\n- `emotion`: Ù‡ÛŒÚ†ØŒ Ø¹ØµØ¨ÛŒØŒ Ø¨ÛŒØ²Ø§Ø±ØŒ ØªØ±Ø³ØŒ Ø®ÙˆØ´Ø­Ø§Ù„ØŒ Ø®Ù†Ø«ÛŒØŒ ØºÙ…Ú¯ÛŒÙ†ØŒ Ù…ØªØ¹Ø¬Ø¨ (Ù¾ÛŒØ´â€ŒÙØ±Ø¶:Ù‡ÛŒÚ†)\n- `e_cfg_scale`: Ø´Ø¯Øª Ø§Ø­Ø³Ø§Ø³Ø§Øª (Ù¾ÛŒØ´â€ŒÙØ±Ø¶:Û±). Ø¨Ø±Ø§ÛŒ ÙˆÛŒØ¯ÛŒÙˆÛŒ Ø¨Ø§ Ø§Ø­Ø³Ø§Ø³Ø§Øª Ù‚ÙˆÛŒâ€ŒØªØ±ØŒ Ø¹Ø¯Ø¯ Ø¨Ø²Ø±Ú¯â€ŒØªØ± Ø¨ÛŒÙ† Ûµ ØªØ§ Û±Û° Ø±Ø§ Ø§Ù…ØªØ­Ø§Ù† Ú©Ù†ÛŒØ¯\n- `crop`: ÙÙ‚Ø· Ø²Ù…Ø§Ù†ÛŒ ÙØ¹Ø§Ù„ Ø´ÙˆØ¯ Ú©Ù‡ ØªØµÙˆÛŒØ± Ù…Ø±Ø¬Ø¹ Ú†Ù‡Ø±Ù‡ Ø¯Ø± Ù…Ø±Ú©Ø² Ù†Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯\n- `fps`: Ù†Ø±Ø® ÙØ±ÛŒÙ… ÙˆÛŒØ¯ÛŒÙˆÛŒ Ø®Ø±ÙˆØ¬ÛŒ (Ù¾ÛŒØ´â€ŒÙØ±Ø¶:Û²Ûµ)\n\n   \n## Ø§Ø³ØªÙ†Ø§Ø¯\n```bibtex\n@article{ki2024float,\n  title={FLOAT: Generative Motion Latent Flow Matching for Audio-driven Talking Portrait},\n  author={Ki, Taekyung and Min, Dongchan and Chae, Gyeongsu},\n  journal={arXiv preprint arXiv:2412.01064},\n  year={2024}\n}\n```\n\n## Ø³Ù¾Ø§Ø³Ú¯Ø²Ø§Ø±ÛŒ\nØ³Ù¾Ø§Ø³ Ø§Ø² [simplepod.ai](https://simplepod.ai/) Ø¨Ø§Ø¨Øª ÙØ±Ø§Ù‡Ù…â€ŒÚ©Ø±Ø¯Ù† Ø³Ø±ÙˆØ±Ù‡Ø§ÛŒ GPU\n\n## Ù…Ø¬ÙˆØ²\n\n[Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)](https://creativecommons.org/licenses/by-nc-sa/4.0/)",
  "status": "ok"
}