<div align="center">

# ComfyUI FLOAT 

[![python](https://img.shields.io/badge/python-3.10.12-green)](https://www.python.org/downloads/release/python-31012/)
[![arXiv](https://img.shields.io/badge/arXiv%20paper-2412.09013-b31b1b.svg)](https://arxiv.org/abs/2412.01064) 
[![by-nc-sa/4.0](https://img.shields.io/badge/license-CC--BY--NC--SA--4.0-lightgrey)](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en)

</div>

Ce projet fournit un wrapper ComfyUI de [FLOAT](https://github.com/deepbrainai-research/float) pour le flux latent de mouvement g√©n√©ratif pilot√© par l‚Äôaudio pour portrait parlant.

Pour une version plus avanc√©e et maintenue, consultez : [ComfyUI-FLOAT_Optimized](https://github.com/set-soft/ComfyUI-FLOAT_Optimized)

<div align="center">
  <video src="https://github.com/user-attachments/assets/36626b4a-d3e5-4db9-87a7-ca0e949daee0" />
</div> 


## ‚≠ê Soutien
Si vous aimez mes projets et souhaitez voir des mises √† jour et de nouvelles fonctionnalit√©s, merci de me soutenir. Cela aide beaucoup ! 

[![ComfyUI-Depth-Anything-Tensorrt](https://img.shields.io/badge/ComfyUI--Depth--Anything--Tensorrt-blue?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-Depth-Anything-Tensorrt)
[![ComfyUI-Upscaler-Tensorrt](https://img.shields.io/badge/ComfyUI--Upscaler--Tensorrt-blue?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-Upscaler-Tensorrt)
[![ComfyUI-Dwpose-Tensorrt](https://img.shields.io/badge/ComfyUI--Dwpose--Tensorrt-blue?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-Dwpose-Tensorrt)
[![ComfyUI-Rife-Tensorrt](https://img.shields.io/badge/ComfyUI--Rife--Tensorrt-blue?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-Rife-Tensorrt)

[![ComfyUI-Whisper](https://img.shields.io/badge/ComfyUI--Whisper-gray?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-Whisper)
[![ComfyUI_InvSR](https://img.shields.io/badge/ComfyUI__InvSR-gray?style=flat-square)](https://github.com/yuvraj108c/ComfyUI_InvSR)
[![ComfyUI-FLOAT](https://img.shields.io/badge/ComfyUI--FLOAT-gray?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-FLOAT)
[![ComfyUI-Thera](https://img.shields.io/badge/ComfyUI--Thera-gray?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-Thera)
[![ComfyUI-Video-Depth-Anything](https://img.shields.io/badge/ComfyUI--Video--Depth--Anything-gray?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-Video-Depth-Anything)
[![ComfyUI-PiperTTS](https://img.shields.io/badge/ComfyUI--PiperTTS-gray?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-PiperTTS)

[![buy-me-coffees](https://i.imgur.com/3MDbAtw.png)](https://www.buymeacoffee.com/yuvraj108cZ)
[![paypal-donation](https://i.imgur.com/w5jjubk.png)](https://paypal.me/yuvraj108c)
---

## üöÄ Installation

```bash
git clone https://github.com/yuvraj108c/ComfyUI-FLOAT.git
cd ./ComfyUI-FLOAT
pip install -r requirements.txt
```

## ‚òÄÔ∏è Utilisation

- Charger le [workflow d'exemple](https://raw.githubusercontent.com/yuvraj108c/ComfyUI-FLOAT/master/float_workflow.json)
- T√©l√©versez l'image de r√©f√©rence et l'audio, cliquez sur queue
- [Les mod√®les](https://huggingface.co/yuvraj108c/float/tree/main) se t√©l√©chargent automatiquement dans `/ComfyUI/models/float`
- Les mod√®les sont organis√©s comme suit :
    ```.bash
    |-- float.pth                                       # mod√®le principal
    |-- wav2vec2-base-960h/                             # encodeur audio
    |   |-- config.json
    |   |-- model.safetensors
    |   |-- preprocessor_config.json
    |-- wav2vec-english-speech-emotion-recognition/     # encodeur d'√©motions
        |-- config.json
        |-- preprocessor_config.json
        |-- pytorch_model.bin

## üõ†Ô∏è Param√®tres
- `ref_image` : Image de r√©f√©rence avec un visage (doit avoir une taille de lot de 1)
- `ref_audio` : Audio de r√©f√©rence (Pour les audios longs (par ex. 3+ minutes), assurez-vous d‚Äôavoir suffisamment de ram/vram)
- `a_cfg_scale` : √âchelle de guidance audio classifier-free (d√©faut : 2)
- `r_cfg_scale` : √âchelle de guidance classifier-free de r√©f√©rence (d√©faut : 1)
- `emotion` : none, angry, disgust, fear, happy, neutral, sad, surprise (d√©faut : none)
- `e_cfg_scale` : Intensit√© de l‚Äô√©motion (d√©faut : 1). Pour une vid√©o avec des √©motions plus intenses, essayez une valeur √©lev√©e de 5 √† 10
- `crop` : Activez uniquement si l‚Äôimage de r√©f√©rence n‚Äôa pas un visage centr√©
- `fps` : Taux d‚Äôimages par seconde de la vid√©o de sortie (d√©faut : 25)

   
## Citation
```bibtex
@article{ki2024float,
  title={FLOAT: Generative Motion Latent Flow Matching for Audio-driven Talking Portrait},
  author={Ki, Taekyung et Min, Dongchan and Chae, Gyeongsu},
  journal={arXiv preprint arXiv:2412.01064},
  year={2024}
}
```

## Remerciements
Merci √† [simplepod.ai](https://simplepod.ai/) pour la mise √† disposition des serveurs GPU

## Licence

[Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)](https://creativecommons.org/licenses/by-nc-sa/4.0/)

---

Tranlated By [Open Ai Tx](https://github.com/OpenAiTx/OpenAiTx) | Last indexed: 2025-07-08

---