{
  "id": 1,
  "origin": "<div align=\"center\">\n\n# ComfyUI FLOAT \n\n[![python](https://img.shields.io/badge/python-3.10.12-green)](https://www.python.org/downloads/release/python-31012/)\n[![arXiv](https://img.shields.io/badge/arXiv%20paper-2412.09013-b31b1b.svg)](https://arxiv.org/abs/2412.01064) \n[![by-nc-sa/4.0](https://img.shields.io/badge/license-CC--BY--NC--SA--4.0-lightgrey)](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en)\n\n</div>\n\nThis project provides a ComfyUI wrapper of [FLOAT](https://github.com/deepbrainai-research/float) for Generative Motion Latent Flow Matching for Audio-driven Talking Portrait\n\nFor a more advanced and maintained version, check out: [ComfyUI-FLOAT_Optimized](https://github.com/set-soft/ComfyUI-FLOAT_Optimized)\n\n<div align=\"center\">\n  <video src=\"https://github.com/user-attachments/assets/36626b4a-d3e5-4db9-87a7-ca0e949daee0\" />\n</div> \n\n\n## ‚≠ê Support\nIf you like my projects and wish to see updates and new features, please consider supporting me. It helps a lot! \n\n[![ComfyUI-Depth-Anything-Tensorrt](https://img.shields.io/badge/ComfyUI--Depth--Anything--Tensorrt-blue?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-Depth-Anything-Tensorrt)\n[![ComfyUI-Upscaler-Tensorrt](https://img.shields.io/badge/ComfyUI--Upscaler--Tensorrt-blue?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-Upscaler-Tensorrt)\n[![ComfyUI-Dwpose-Tensorrt](https://img.shields.io/badge/ComfyUI--Dwpose--Tensorrt-blue?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-Dwpose-Tensorrt)\n[![ComfyUI-Rife-Tensorrt](https://img.shields.io/badge/ComfyUI--Rife--Tensorrt-blue?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-Rife-Tensorrt)\n\n[![ComfyUI-Whisper](https://img.shields.io/badge/ComfyUI--Whisper-gray?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-Whisper)\n[![ComfyUI_InvSR](https://img.shields.io/badge/ComfyUI__InvSR-gray?style=flat-square)](https://github.com/yuvraj108c/ComfyUI_InvSR)\n[![ComfyUI-FLOAT](https://img.shields.io/badge/ComfyUI--FLOAT-gray?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-FLOAT)\n[![ComfyUI-Thera](https://img.shields.io/badge/ComfyUI--Thera-gray?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-Thera)\n[![ComfyUI-Video-Depth-Anything](https://img.shields.io/badge/ComfyUI--Video--Depth--Anything-gray?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-Video-Depth-Anything)\n[![ComfyUI-PiperTTS](https://img.shields.io/badge/ComfyUI--PiperTTS-gray?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-PiperTTS)\n\n[![buy-me-coffees](https://i.imgur.com/3MDbAtw.png)](https://www.buymeacoffee.com/yuvraj108cZ)\n[![paypal-donation](https://i.imgur.com/w5jjubk.png)](https://paypal.me/yuvraj108c)\n---\n\n## üöÄ Installation\n\n```bash\ngit clone https://github.com/yuvraj108c/ComfyUI-FLOAT.git\ncd ./ComfyUI-FLOAT\npip install -r requirements.txt\n```\n\n## ‚òÄÔ∏è Usage\n\n- Load [example workflow](https://raw.githubusercontent.com/yuvraj108c/ComfyUI-FLOAT/master/float_workflow.json) \n- Upload driving image and audio, click queue\n- [Models](https://huggingface.co/yuvraj108c/float/tree/main) autodownload to `/ComfyUI/models/float`\n- The models are organized as follows:\n    ```.bash\n    |-- float.pth                                       # main model\n    |-- wav2vec2-base-960h/                             # audio encoder\n    |   |-- config.json\n    |   |-- model.safetensors\n    |   |-- preprocessor_config.json\n    |-- wav2vec-english-speech-emotion-recognition/     # emotion encoder\n        |-- config.json\n        |-- preprocessor_config.json\n        |-- pytorch_model.bin\n\n## üõ†Ô∏è Parameters\n- `ref_image`: Reference image with a face (must have batch size 1)\n- `ref_audio`: Reference audio (For long audios (e.g 3+ minutes), ensure that you have enough ram/vram)\n- `a_cfg_scale`: Audio classifier-free guidance scale (default:2)\n- `r_cfg_scale`: Reference classifier-free guidance scale (default:1)\n- `emotion`: none, angry, disgust, fear, happy, neutral, sad, surprise (default:none)\n- `e_cfg_scale`: Intensity of emotion (default:1). For more emotion intensive video, try large value from 5 to 10\n- `crop`: Enable only if the reference image does not have a centered face\n- `fps`: Frame rate of the output video (default:25)\n\n   \n## Citation\n```bibtex\n@article{ki2024float,\n  title={FLOAT: Generative Motion Latent Flow Matching for Audio-driven Talking Portrait},\n  author={Ki, Taekyung and Min, Dongchan and Chae, Gyeongsu},\n  journal={arXiv preprint arXiv:2412.01064},\n  year={2024}\n}\n```\n\n## Acknowledgments\nThanks to [simplepod.ai](https://simplepod.ai/) for providing GPU servers\n\n## License\n\n[Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)](https://creativecommons.org/licenses/by-nc-sa/4.0/)\n",
  "origin_sha": "J1w6fzZLWGVxXZ6uzQqWxdmD+gFnLFEp9FPER7LLsj4=",
  "translate": "<div align=\"center\">\n\n# ComfyUI FLOAT \n\n[![python](https://img.shields.io/badge/python-3.10.12-green)](https://www.python.org/downloads/release/python-31012/)\n[![arXiv](https://img.shields.io/badge/arXiv%20paper-2412.09013-b31b1b.svg)](https://arxiv.org/abs/2412.01064) \n[![by-nc-sa/4.0](https://img.shields.io/badge/license-CC--BY--NC--SA--4.0-lightgrey)](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en)\n\n</div>\n\n–≠—Ç–æ—Ç –ø—Ä–æ–µ–∫—Ç –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –æ–±—ë—Ä—Ç–∫—É ComfyUI –¥–ª—è [FLOAT](https://github.com/deepbrainai-research/float) ‚Äî –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω–æ–≥–æ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è –ª–∞—Ç–µ–Ω—Ç–Ω–æ–≥–æ –ø–æ—Ç–æ–∫–∞ –¥–≤–∏–∂–µ–Ω–∏–π –¥–ª—è –∞—É–¥–∏–æ—É–ø—Ä–∞–≤–ª—è–µ–º—ã—Ö –≥–æ–≤–æ—Ä—è—â–∏—Ö –ø–æ—Ä—Ç—Ä–µ—Ç–æ–≤\n\n–ë–æ–ª–µ–µ –ø—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è –∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º–∞—è –≤–µ—Ä—Å–∏—è –¥–æ—Å—Ç—É–ø–Ω–∞ –∑–¥–µ—Å—å: [ComfyUI-FLOAT_Optimized](https://github.com/set-soft/ComfyUI-FLOAT_Optimized)\n\n<div align=\"center\">\n  <video src=\"https://github.com/user-attachments/assets/36626b4a-d3e5-4db9-87a7-ca0e949daee0\" />\n</div> \n\n\n## ‚≠ê –ü–æ–¥–¥–µ—Ä–∂–∫–∞\n–ï—Å–ª–∏ –≤–∞–º –Ω—Ä–∞–≤—è—Ç—Å—è –º–æ–∏ –ø—Ä–æ–µ–∫—Ç—ã –∏ –≤—ã —Ö–æ—Ç–∏—Ç–µ –≤–∏–¥–µ—Ç—å –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∏ –Ω–æ–≤—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–¥–¥–µ—Ä–∂–∏—Ç–µ –º–µ–Ω—è. –≠—Ç–æ –æ—á–µ–Ω—å –ø–æ–º–æ–∂–µ—Ç! \n\n[![ComfyUI-Depth-Anything-Tensorrt](https://img.shields.io/badge/ComfyUI--Depth--Anything--Tensorrt-blue?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-Depth-Anything-Tensorrt)\n[![ComfyUI-Upscaler-Tensorrt](https://img.shields.io/badge/ComfyUI--Upscaler--Tensorrt-blue?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-Upscaler-Tensorrt)\n[![ComfyUI-Dwpose-Tensorrt](https://img.shields.io/badge/ComfyUI--Dwpose--Tensorrt-blue?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-Dwpose-Tensorrt)\n[![ComfyUI-Rife-Tensorrt](https://img.shields.io/badge/ComfyUI--Rife--Tensorrt-blue?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-Rife-Tensorrt)\n\n[![ComfyUI-Whisper](https://img.shields.io/badge/ComfyUI--Whisper-gray?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-Whisper)\n[![ComfyUI_InvSR](https://img.shields.io/badge/ComfyUI__InvSR-gray?style=flat-square)](https://github.com/yuvraj108c/ComfyUI_InvSR)\n[![ComfyUI-FLOAT](https://img.shields.io/badge/ComfyUI--FLOAT-gray?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-FLOAT)\n[![ComfyUI-Thera](https://img.shields.io/badge/ComfyUI--Thera-gray?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-Thera)\n[![ComfyUI-Video-Depth-Anything](https://img.shields.io/badge/ComfyUI--Video--Depth--Anything-gray?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-Video-Depth-Anything)\n[![ComfyUI-PiperTTS](https://img.shields.io/badge/ComfyUI--PiperTTS-gray?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-PiperTTS)\n\n[![buy-me-coffees](https://i.imgur.com/3MDbAtw.png)](https://www.buymeacoffee.com/yuvraj108cZ)\n[![paypal-donation](https://i.imgur.com/w5jjubk.png)](https://paypal.me/yuvraj108c)\n---\n\n## üöÄ –£—Å—Ç–∞–Ω–æ–≤–∫–∞\n\n```bash\ngit clone https://github.com/yuvraj108c/ComfyUI-FLOAT.git\ncd ./ComfyUI-FLOAT\npip install -r requirements.txt\n```\n\n## ‚òÄÔ∏è –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ\n\n- –ó–∞–≥—Ä—É–∑–∏—Ç–µ [–ø—Ä–∏–º–µ—Ä workflow](https://raw.githubusercontent.com/yuvraj108c/ComfyUI-FLOAT/master/float_workflow.json) \n- –ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏—Å—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏ –∞—É–¥–∏–æ, –Ω–∞–∂–º–∏—Ç–µ –æ—á–µ—Ä–µ–¥—å\n- [–ú–æ–¥–µ–ª–∏](https://huggingface.co/yuvraj108c/float/tree/main) –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–∫–∞—á–∏–≤–∞—é—Ç—Å—è –≤ `/ComfyUI/models/float`\n- –ú–æ–¥–µ–ª–∏ –æ—Ä–≥–∞–Ω–∏–∑–æ–≤–∞–Ω—ã —Å–ª–µ–¥—É—é—â–∏–º –æ–±—Ä–∞–∑–æ–º:\n    ```.bash\n    |-- float.pth                                       # –æ—Å–Ω–æ–≤–Ω–∞—è –º–æ–¥–µ–ª—å\n    |-- wav2vec2-base-960h/                             # –∞—É–¥–∏–æ–∫–æ–¥–∏—Ä–æ–≤—â–∏–∫\n    |   |-- config.json\n    |   |-- model.safetensors\n    |   |-- preprocessor_config.json\n    |-- wav2vec-english-speech-emotion-recognition/     # –∫–æ–¥–∏—Ä–æ–≤—â–∏–∫ —ç–º–æ—Ü–∏–π\n        |-- config.json\n        |-- preprocessor_config.json\n        |-- pytorch_model.bin\n\n## üõ†Ô∏è –ü–∞—Ä–∞–º–µ—Ç—Ä—ã\n- `ref_image`: –†–µ—Ñ–µ—Ä–µ–Ω—Å–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –ª–∏—Ü–æ–º (–¥–æ–ª–∂–Ω–æ –∏–º–µ—Ç—å —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ 1)\n- `ref_audio`: –†–µ—Ñ–µ—Ä–µ–Ω—Å–Ω–æ–µ –∞—É–¥–∏–æ (–¥–ª—è –¥–ª–∏–Ω–Ω—ã—Ö –∞—É–¥–∏–æ—Ñ–∞–π–ª–æ–≤ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 3+ –º–∏–Ω—É—Ç—ã) —É–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —É –≤–∞—Å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ ram/vram)\n- `a_cfg_scale`: –ú–∞—Å—à—Ç–∞–± –∞—É–¥–∏–æ-–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ –±–µ–∑ —É—á–∏—Ç–µ–ª—è (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 2)\n- `r_cfg_scale`: –ú–∞—Å—à—Ç–∞–± —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω–æ–≥–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ –±–µ–∑ —É—á–∏—Ç–µ–ª—è (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 1)\n- `emotion`: none, angry, disgust, fear, happy, neutral, sad, surprise (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: none)\n- `e_cfg_scale`: –ò–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ—Å—Ç—å —ç–º–æ—Ü–∏–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 1). –î–ª—è –±–æ–ª–µ–µ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–≥–æ –≤–∏–¥–µ–æ –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –∑–Ω–∞—á–µ–Ω–∏–µ –æ—Ç 5 –¥–æ 10\n- `crop`: –í–∫–ª—é—á–∞–π—Ç–µ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω–∞ —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ –ª–∏—Ü–æ –Ω–µ –ø–æ —Ü–µ–Ω—Ç—Ä—É\n- `fps`: –ß–∞—Å—Ç–æ—Ç–∞ –∫–∞–¥—Ä–æ–≤ –∏—Ç–æ–≥–æ–≤–æ–≥–æ –≤–∏–¥–µ–æ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 25)\n\n   \n## –¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ\n```bibtex\n@article{ki2024float,\n  title={FLOAT: Generative Motion Latent Flow Matching for Audio-driven Talking Portrait},\n  author={Ki, Taekyung and Min, Dongchan and Chae, Gyeongsu},\n  journal={arXiv preprint arXiv:2412.01064},\n  year={2024}\n}\n```\n\n## –ë–ª–∞–≥–æ–¥–∞—Ä–Ω–æ—Å—Ç–∏\n–ë–ª–∞–≥–æ–¥–∞—Ä–∏–º [simplepod.ai](https://simplepod.ai/) –∑–∞ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ GPU-—Å–µ—Ä–≤–µ—Ä–æ–≤\n\n## –õ–∏—Ü–µ–Ω–∑–∏—è\n\n[Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)](https://creativecommons.org/licenses/by-nc-sa/4.0/)",
  "status": "ok"
}