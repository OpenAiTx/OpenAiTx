<div align="center">

# ComfyUI FLOAT 

[![python](https://img.shields.io/badge/python-3.10.12-green)](https://www.python.org/downloads/release/python-31012/)
[![arXiv](https://img.shields.io/badge/arXiv%20paper-2412.09013-b31b1b.svg)](https://arxiv.org/abs/2412.01064) 
[![by-nc-sa/4.0](https://img.shields.io/badge/license-CC--BY--NC--SA--4.0-lightgrey)](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en)

</div>

æœ¬ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯ã€ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªé§†å‹•å‹ãƒˆãƒ¼ã‚­ãƒ³ã‚°ãƒãƒ¼ãƒˆãƒ¬ãƒ¼ãƒˆã®ãŸã‚ã®[Generative Motion Latent Flow Matching for Audio-driven Talking Portraitï¼ˆFLOATï¼‰](https://github.com/deepbrainai-research/float) ã®ComfyUIãƒ©ãƒƒãƒ‘ãƒ¼ã‚’æä¾›ã—ã¾ã™ã€‚

ã‚ˆã‚Šé«˜åº¦ã§ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ã•ã‚Œã¦ã„ã‚‹ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã¯ã€ã“ã¡ã‚‰ã‚’ã”è¦§ãã ã•ã„: [ComfyUI-FLOAT_Optimized](https://github.com/set-soft/ComfyUI-FLOAT_Optimized)

<div align="center">
  <video src="https://github.com/user-attachments/assets/36626b4a-d3e5-4db9-87a7-ca0e949daee0" />
</div> 


## â­ ã‚µãƒãƒ¼ãƒˆ
ç§ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãŒæ°—ã«å…¥ã£ãŸã‚Šã€ä»Šå¾Œã®ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã‚„æ–°æ©Ÿèƒ½ã‚’è¦‹ãŸã„ã¨æ€ã£ãŸå ´åˆã¯ã€ãœã²ã‚µãƒãƒ¼ãƒˆã‚’ã”æ¤œè¨ãã ã•ã„ã€‚å¤§ããªåŠ©ã‘ã«ãªã‚Šã¾ã™ï¼

[![ComfyUI-Depth-Anything-Tensorrt](https://img.shields.io/badge/ComfyUI--Depth--Anything--Tensorrt-blue?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-Depth-Anything-Tensorrt)
[![ComfyUI-Upscaler-Tensorrt](https://img.shields.io/badge/ComfyUI--Upscaler--Tensorrt-blue?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-Upscaler-Tensorrt)
[![ComfyUI-Dwpose-Tensorrt](https://img.shields.io/badge/ComfyUI--Dwpose--Tensorrt-blue?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-Dwpose-Tensorrt)
[![ComfyUI-Rife-Tensorrt](https://img.shields.io/badge/ComfyUI--Rife--Tensorrt-blue?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-Rife-Tensorrt)

[![ComfyUI-Whisper](https://img.shields.io/badge/ComfyUI--Whisper-gray?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-Whisper)
[![ComfyUI_InvSR](https://img.shields.io/badge/ComfyUI__InvSR-gray?style=flat-square)](https://github.com/yuvraj108c/ComfyUI_InvSR)
[![ComfyUI-FLOAT](https://img.shields.io/badge/ComfyUI--FLOAT-gray?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-FLOAT)
[![ComfyUI-Thera](https://img.shields.io/badge/ComfyUI--Thera-gray?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-Thera)
[![ComfyUI-Video-Depth-Anything](https://img.shields.io/badge/ComfyUI--Video--Depth--Anything-gray?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-Video-Depth-Anything)
[![ComfyUI-PiperTTS](https://img.shields.io/badge/ComfyUI--PiperTTS-gray?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-PiperTTS)

[![buy-me-coffees](https://i.imgur.com/3MDbAtw.png)](https://www.buymeacoffee.com/yuvraj108cZ)
[![paypal-donation](https://i.imgur.com/w5jjubk.png)](https://paypal.me/yuvraj108c)
---

## ğŸš€ ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

```bash
git clone https://github.com/yuvraj108c/ComfyUI-FLOAT.git
cd ./ComfyUI-FLOAT
pip install -r requirements.txt
```

## â˜€ï¸ ä½¿ã„æ–¹

- [ã‚µãƒ³ãƒ—ãƒ«ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼](https://raw.githubusercontent.com/yuvraj108c/ComfyUI-FLOAT/master/float_workflow.json) ã‚’ãƒ­ãƒ¼ãƒ‰
- ãƒ‰ãƒ©ã‚¤ãƒ“ãƒ³ã‚°ç”»åƒã¨éŸ³å£°ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€ã‚­ãƒ¥ãƒ¼ã‚’ã‚¯ãƒªãƒƒã‚¯
- [ãƒ¢ãƒ‡ãƒ«](https://huggingface.co/yuvraj108c/float/tree/main)ã¯ `/ComfyUI/models/float` ã«è‡ªå‹•ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã™
- ãƒ¢ãƒ‡ãƒ«ã®æ§‹æˆã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™:
    ```.bash
    |-- float.pth                                       # ãƒ¡ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«
    |-- wav2vec2-base-960h/                             # éŸ³å£°ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€
    |   |-- config.json
    |   |-- model.safetensors
    |   |-- preprocessor_config.json
    |-- wav2vec-english-speech-emotion-recognition/     # æ„Ÿæƒ…ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€
        |-- config.json
        |-- preprocessor_config.json
        |-- pytorch_model.bin

## ğŸ› ï¸ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
- `ref_image`: é¡”ãŒå†™ã£ã¦ã„ã‚‹å‚ç…§ç”»åƒï¼ˆãƒãƒƒãƒã‚µã‚¤ã‚º1ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ï¼‰
- `ref_audio`: å‚ç…§éŸ³å£°ï¼ˆé•·å°ºã®éŸ³å£°ï¼ˆä¾‹ï¼š3åˆ†ä»¥ä¸Šï¼‰ã®å ´åˆã¯ååˆ†ãªRAM/VRAMãŒå¿…è¦ã§ã™ï¼‰
- `a_cfg_scale`: éŸ³å£°åˆ†é¡ãƒ•ãƒªãƒ¼ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹ã‚¹ã‚±ãƒ¼ãƒ«ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ:2ï¼‰
- `r_cfg_scale`: å‚ç…§åˆ†é¡ãƒ•ãƒªãƒ¼ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹ã‚¹ã‚±ãƒ¼ãƒ«ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ:1ï¼‰
- `emotion`: none, angry, disgust, fear, happy, neutral, sad, surpriseï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ:noneï¼‰
- `e_cfg_scale`: æ„Ÿæƒ…ã®å¼·ã•ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ:1ï¼‰ã€‚ã‚ˆã‚Šå¼·ã„æ„Ÿæƒ…è¡¨ç¾ã®å‹•ç”»ã‚’ä½œã‚ŠãŸã„å ´åˆã¯5ï½10ã®å¤§ããªå€¤ã‚’è©¦ã—ã¦ãã ã•ã„
- `crop`: å‚ç…§ç”»åƒã®é¡”ãŒä¸­å¤®ã«ãªã„å ´åˆã®ã¿æœ‰åŠ¹åŒ–
- `fps`: å‡ºåŠ›å‹•ç”»ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¬ãƒ¼ãƒˆï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ:25ï¼‰

   
## å¼•ç”¨
```bibtex
@article{ki2024float,
  title={FLOAT: Generative Motion Latent Flow Matching for Audio-driven Talking Portrait},
  author={Ki, Taekyung and Min, Dongchan and Chae, Gyeongsu},
  journal={arXiv preprint arXiv:2412.01064},
  year={2024}
}
```

## è¬è¾
GPUã‚µãƒ¼ãƒãƒ¼ã‚’ã”æä¾›ã„ãŸã ã„ãŸ [simplepod.ai](https://simplepod.ai/) ã«æ„Ÿè¬ã„ãŸã—ã¾ã™ã€‚

## ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

[ã‚¯ãƒªã‚¨ã‚¤ãƒ†ã‚£ãƒ–ãƒ»ã‚³ãƒ¢ãƒ³ã‚º è¡¨ç¤º-éå–¶åˆ©-ç¶™æ‰¿ 4.0 å›½éš›ï¼ˆCC BY-NC-SA 4.0ï¼‰](https://creativecommons.org/licenses/by-nc-sa/4.0/)

---

Tranlated By [Open Ai Tx](https://github.com/OpenAiTx/OpenAiTx) | Last indexed: 2025-07-08

---