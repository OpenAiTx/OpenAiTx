{
  "id": 1,
  "origin": "<div align=\"center\">\n\n# ComfyUI FLOAT \n\n[![python](https://img.shields.io/badge/python-3.10.12-green)](https://www.python.org/downloads/release/python-31012/)\n[![arXiv](https://img.shields.io/badge/arXiv%20paper-2412.09013-b31b1b.svg)](https://arxiv.org/abs/2412.01064) \n[![by-nc-sa/4.0](https://img.shields.io/badge/license-CC--BY--NC--SA--4.0-lightgrey)](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en)\n\n</div>\n\nThis project provides a ComfyUI wrapper of [FLOAT](https://github.com/deepbrainai-research/float) for Generative Motion Latent Flow Matching for Audio-driven Talking Portrait\n\nFor a more advanced and maintained version, check out: [ComfyUI-FLOAT_Optimized](https://github.com/set-soft/ComfyUI-FLOAT_Optimized)\n\n<div align=\"center\">\n  <video src=\"https://github.com/user-attachments/assets/36626b4a-d3e5-4db9-87a7-ca0e949daee0\" />\n</div> \n\n\n## â­ Support\nIf you like my projects and wish to see updates and new features, please consider supporting me. It helps a lot! \n\n[![ComfyUI-Depth-Anything-Tensorrt](https://img.shields.io/badge/ComfyUI--Depth--Anything--Tensorrt-blue?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-Depth-Anything-Tensorrt)\n[![ComfyUI-Upscaler-Tensorrt](https://img.shields.io/badge/ComfyUI--Upscaler--Tensorrt-blue?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-Upscaler-Tensorrt)\n[![ComfyUI-Dwpose-Tensorrt](https://img.shields.io/badge/ComfyUI--Dwpose--Tensorrt-blue?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-Dwpose-Tensorrt)\n[![ComfyUI-Rife-Tensorrt](https://img.shields.io/badge/ComfyUI--Rife--Tensorrt-blue?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-Rife-Tensorrt)\n\n[![ComfyUI-Whisper](https://img.shields.io/badge/ComfyUI--Whisper-gray?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-Whisper)\n[![ComfyUI_InvSR](https://img.shields.io/badge/ComfyUI__InvSR-gray?style=flat-square)](https://github.com/yuvraj108c/ComfyUI_InvSR)\n[![ComfyUI-FLOAT](https://img.shields.io/badge/ComfyUI--FLOAT-gray?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-FLOAT)\n[![ComfyUI-Thera](https://img.shields.io/badge/ComfyUI--Thera-gray?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-Thera)\n[![ComfyUI-Video-Depth-Anything](https://img.shields.io/badge/ComfyUI--Video--Depth--Anything-gray?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-Video-Depth-Anything)\n[![ComfyUI-PiperTTS](https://img.shields.io/badge/ComfyUI--PiperTTS-gray?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-PiperTTS)\n\n[![buy-me-coffees](https://i.imgur.com/3MDbAtw.png)](https://www.buymeacoffee.com/yuvraj108cZ)\n[![paypal-donation](https://i.imgur.com/w5jjubk.png)](https://paypal.me/yuvraj108c)\n---\n\n## ğŸš€ Installation\n\n```bash\ngit clone https://github.com/yuvraj108c/ComfyUI-FLOAT.git\ncd ./ComfyUI-FLOAT\npip install -r requirements.txt\n```\n\n## â˜€ï¸ Usage\n\n- Load [example workflow](https://raw.githubusercontent.com/yuvraj108c/ComfyUI-FLOAT/master/float_workflow.json) \n- Upload driving image and audio, click queue\n- [Models](https://huggingface.co/yuvraj108c/float/tree/main) autodownload to `/ComfyUI/models/float`\n- The models are organized as follows:\n    ```.bash\n    |-- float.pth                                       # main model\n    |-- wav2vec2-base-960h/                             # audio encoder\n    |   |-- config.json\n    |   |-- model.safetensors\n    |   |-- preprocessor_config.json\n    |-- wav2vec-english-speech-emotion-recognition/     # emotion encoder\n        |-- config.json\n        |-- preprocessor_config.json\n        |-- pytorch_model.bin\n\n## ğŸ› ï¸ Parameters\n- `ref_image`: Reference image with a face (must have batch size 1)\n- `ref_audio`: Reference audio (For long audios (e.g 3+ minutes), ensure that you have enough ram/vram)\n- `a_cfg_scale`: Audio classifier-free guidance scale (default:2)\n- `r_cfg_scale`: Reference classifier-free guidance scale (default:1)\n- `emotion`: none, angry, disgust, fear, happy, neutral, sad, surprise (default:none)\n- `e_cfg_scale`: Intensity of emotion (default:1). For more emotion intensive video, try large value from 5 to 10\n- `crop`: Enable only if the reference image does not have a centered face\n- `fps`: Frame rate of the output video (default:25)\n\n   \n## Citation\n```bibtex\n@article{ki2024float,\n  title={FLOAT: Generative Motion Latent Flow Matching for Audio-driven Talking Portrait},\n  author={Ki, Taekyung and Min, Dongchan and Chae, Gyeongsu},\n  journal={arXiv preprint arXiv:2412.01064},\n  year={2024}\n}\n```\n\n## Acknowledgments\nThanks to [simplepod.ai](https://simplepod.ai/) for providing GPU servers\n\n## License\n\n[Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)](https://creativecommons.org/licenses/by-nc-sa/4.0/)\n",
  "origin_sha": "J1w6fzZLWGVxXZ6uzQqWxdmD+gFnLFEp9FPER7LLsj4=",
  "translate": "<div align=\"center\">\n\n# ComfyUI FLOAT \n\n[![python](https://img.shields.io/badge/python-3.10.12-green)](https://www.python.org/downloads/release/python-31012/)\n[![arXiv](https://img.shields.io/badge/arXiv%20paper-2412.09013-b31b1b.svg)](https://arxiv.org/abs/2412.01064) \n[![by-nc-sa/4.0](https://img.shields.io/badge/license-CC--BY--NC--SA--4.0-lightgrey)](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en)\n\n</div>\n\nì´ í”„ë¡œì íŠ¸ëŠ” ì˜¤ë””ì˜¤ ê¸°ë°˜ í† í‚¹ í¬íŠ¸ë ˆì´íŠ¸ë¥¼ ìœ„í•œ ìƒì„±ì  ëª¨ì…˜ ì ë³µ íë¦„ ë§¤ì¹­ [FLOAT](https://github.com/deepbrainai-research/float)ì˜ ComfyUI ë˜í¼ë¥¼ ì œê³µí•©ë‹ˆë‹¤.\n\në” ë°œì „ë˜ê³  ìœ ì§€ ê´€ë¦¬ë˜ëŠ” ë²„ì „ì€ ë‹¤ìŒì„ ì°¸ê³ í•˜ì„¸ìš”: [ComfyUI-FLOAT_Optimized](https://github.com/set-soft/ComfyUI-FLOAT_Optimized)\n\n<div align=\"center\">\n  <video src=\"https://github.com/user-attachments/assets/36626b4a-d3e5-4db9-87a7-ca0e949daee0\" />\n</div> \n\n\n## â­ í›„ì›\nì œ í”„ë¡œì íŠ¸ë¥¼ ì¢‹ì•„í•˜ì‹œê³  ì—…ë°ì´íŠ¸ ë° ìƒˆë¡œìš´ ê¸°ëŠ¥ì„ ë³´ê³  ì‹¶ìœ¼ì‹œë‹¤ë©´, í›„ì›ì„ ê³ ë ¤í•´ ì£¼ì„¸ìš”. í° ë„ì›€ì´ ë©ë‹ˆë‹¤! \n\n[![ComfyUI-Depth-Anything-Tensorrt](https://img.shields.io/badge/ComfyUI--Depth--Anything--Tensorrt-blue?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-Depth-Anything-Tensorrt)\n[![ComfyUI-Upscaler-Tensorrt](https://img.shields.io/badge/ComfyUI--Upscaler--Tensorrt-blue?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-Upscaler-Tensorrt)\n[![ComfyUI-Dwpose-Tensorrt](https://img.shields.io/badge/ComfyUI--Dwpose--Tensorrt-blue?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-Dwpose-Tensorrt)\n[![ComfyUI-Rife-Tensorrt](https://img.shields.io/badge/ComfyUI--Rife--Tensorrt-blue?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-Rife-Tensorrt)\n\n[![ComfyUI-Whisper](https://img.shields.io/badge/ComfyUI--Whisper-gray?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-Whisper)\n[![ComfyUI_InvSR](https://img.shields.io/badge/ComfyUI__InvSR-gray?style=flat-square)](https://github.com/yuvraj108c/ComfyUI_InvSR)\n[![ComfyUI-FLOAT](https://img.shields.io/badge/ComfyUI--FLOAT-gray?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-FLOAT)\n[![ComfyUI-Thera](https://img.shields.io/badge/ComfyUI--Thera-gray?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-Thera)\n[![ComfyUI-Video-Depth-Anything](https://img.shields.io/badge/ComfyUI--Video--Depth--Anything-gray?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-Video-Depth-Anything)\n[![ComfyUI-PiperTTS](https://img.shields.io/badge/ComfyUI--PiperTTS-gray?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-PiperTTS)\n\n[![buy-me-coffees](https://i.imgur.com/3MDbAtw.png)](https://www.buymeacoffee.com/yuvraj108cZ)\n[![paypal-donation](https://i.imgur.com/w5jjubk.png)](https://paypal.me/yuvraj108c)\n---\n\n## ğŸš€ ì„¤ì¹˜\n\n```bash\ngit clone https://github.com/yuvraj108c/ComfyUI-FLOAT.git\ncd ./ComfyUI-FLOAT\npip install -r requirements.txt\n```\n\n## â˜€ï¸ ì‚¬ìš©ë²•\n\n- [ì˜ˆì‹œ ì›Œí¬í”Œë¡œìš°](https://raw.githubusercontent.com/yuvraj108c/ComfyUI-FLOAT/master/float_workflow.json) ë¶ˆëŸ¬ì˜¤ê¸°\n- êµ¬ë™ ì´ë¯¸ì§€ì™€ ì˜¤ë””ì˜¤ ì—…ë¡œë“œ í›„, í(Queue) í´ë¦­\n- [ëª¨ë¸](https://huggingface.co/yuvraj108c/float/tree/main)ì´ `/ComfyUI/models/float`ì— ìë™ ë‹¤ìš´ë¡œë“œë¨\n- ëª¨ë¸ì€ ë‹¤ìŒê³¼ ê°™ì´ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤:\n    ```.bash\n    |-- float.pth                                       # ë©”ì¸ ëª¨ë¸\n    |-- wav2vec2-base-960h/                             # ì˜¤ë””ì˜¤ ì¸ì½”ë”\n    |   |-- config.json\n    |   |-- model.safetensors\n    |   |-- preprocessor_config.json\n    |-- wav2vec-english-speech-emotion-recognition/     # ê°ì • ì¸ì½”ë”\n        |-- config.json\n        |-- preprocessor_config.json\n        |-- pytorch_model.bin\n\n## ğŸ› ï¸ íŒŒë¼ë¯¸í„°\n- `ref_image`: ì–¼êµ´ì´ í¬í•¨ëœ ì°¸ì¡° ì´ë¯¸ì§€ (ë°°ì¹˜ í¬ê¸° 1ì´ì–´ì•¼ í•¨)\n- `ref_audio`: ì°¸ì¡° ì˜¤ë””ì˜¤ (ì˜¤ë””ì˜¤ê°€ ê¸¸ ê²½ìš°(ì˜ˆ: 3ë¶„ ì´ìƒ), ì¶©ë¶„í•œ RAM/VRAMì´ ìˆëŠ”ì§€ í™•ì¸)\n- `a_cfg_scale`: ì˜¤ë””ì˜¤ ë¶„ë¥˜ê¸° í”„ë¦¬ ê°€ì´ë˜ìŠ¤ ìŠ¤ì¼€ì¼ (ê¸°ë³¸ê°’:2)\n- `r_cfg_scale`: ì°¸ì¡° ë¶„ë¥˜ê¸° í”„ë¦¬ ê°€ì´ë˜ìŠ¤ ìŠ¤ì¼€ì¼ (ê¸°ë³¸ê°’:1)\n- `emotion`: ì—†ìŒ(none), í™”ë‚¨(angry), í˜ì˜¤(disgust), ë‘ë ¤ì›€(fear), í–‰ë³µ(happy), ì¤‘ë¦½(neutral), ìŠ¬í””(sad), ë†€ëŒ(surprise) (ê¸°ë³¸ê°’:none)\n- `e_cfg_scale`: ê°ì • ê°•ë„ (ê¸°ë³¸ê°’:1). ë” ê°•í•œ ê°ì •ì˜ ì˜ìƒì„ ì›í•  ê²½ìš° 5~10ì˜ í° ê°’ì„ ì‹œë„\n- `crop`: ì°¸ì¡° ì´ë¯¸ì§€ì— ì–¼êµ´ì´ ì¤‘ì•™ì— ì—†ì„ ë•Œë§Œ í™œì„±í™”\n- `fps`: ì¶œë ¥ ì˜ìƒì˜ í”„ë ˆì„ë ˆì´íŠ¸ (ê¸°ë³¸ê°’:25)\n\n   \n## ì¸ìš©\n```bibtex\n@article{ki2024float,\n  title={FLOAT: Generative Motion Latent Flow Matching for Audio-driven Talking Portrait},\n  author={Ki, Taekyung and Min, Dongchan and Chae, Gyeongsu},\n  journal={arXiv preprint arXiv:2412.01064},\n  year={2024}\n}\n```\n\n## ê°ì‚¬ì˜ ê¸€\nGPU ì„œë²„ë¥¼ ì œê³µí•´ì£¼ì‹  [simplepod.ai](https://simplepod.ai/)ì— ê°ì‚¬ë“œë¦½ë‹ˆë‹¤.\n\n## ë¼ì´ì„ ìŠ¤\n\n[í¬ë¦¬ì—ì´í‹°ë¸Œ ì»¤ë¨¼ì¦ˆ ì €ì‘ìí‘œì‹œ-ë¹„ì˜ë¦¬-ë™ì¼ì¡°ê±´ë³€ê²½í—ˆë½ 4.0 êµ­ì œ(CC BY-NC-SA 4.0)](https://creativecommons.org/licenses/by-nc-sa/4.0/)",
  "status": "ok"
}