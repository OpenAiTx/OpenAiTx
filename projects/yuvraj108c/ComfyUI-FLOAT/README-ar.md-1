{
  "id": 1,
  "origin": "<div align=\"center\">\n\n# ComfyUI FLOAT \n\n[![python](https://img.shields.io/badge/python-3.10.12-green)](https://www.python.org/downloads/release/python-31012/)\n[![arXiv](https://img.shields.io/badge/arXiv%20paper-2412.09013-b31b1b.svg)](https://arxiv.org/abs/2412.01064) \n[![by-nc-sa/4.0](https://img.shields.io/badge/license-CC--BY--NC--SA--4.0-lightgrey)](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en)\n\n</div>\n\nThis project provides a ComfyUI wrapper of [FLOAT](https://github.com/deepbrainai-research/float) for Generative Motion Latent Flow Matching for Audio-driven Talking Portrait\n\nFor a more advanced and maintained version, check out: [ComfyUI-FLOAT_Optimized](https://github.com/set-soft/ComfyUI-FLOAT_Optimized)\n\n<div align=\"center\">\n  <video src=\"https://github.com/user-attachments/assets/36626b4a-d3e5-4db9-87a7-ca0e949daee0\" />\n</div> \n\n\n## â­ Support\nIf you like my projects and wish to see updates and new features, please consider supporting me. It helps a lot! \n\n[![ComfyUI-Depth-Anything-Tensorrt](https://img.shields.io/badge/ComfyUI--Depth--Anything--Tensorrt-blue?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-Depth-Anything-Tensorrt)\n[![ComfyUI-Upscaler-Tensorrt](https://img.shields.io/badge/ComfyUI--Upscaler--Tensorrt-blue?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-Upscaler-Tensorrt)\n[![ComfyUI-Dwpose-Tensorrt](https://img.shields.io/badge/ComfyUI--Dwpose--Tensorrt-blue?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-Dwpose-Tensorrt)\n[![ComfyUI-Rife-Tensorrt](https://img.shields.io/badge/ComfyUI--Rife--Tensorrt-blue?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-Rife-Tensorrt)\n\n[![ComfyUI-Whisper](https://img.shields.io/badge/ComfyUI--Whisper-gray?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-Whisper)\n[![ComfyUI_InvSR](https://img.shields.io/badge/ComfyUI__InvSR-gray?style=flat-square)](https://github.com/yuvraj108c/ComfyUI_InvSR)\n[![ComfyUI-FLOAT](https://img.shields.io/badge/ComfyUI--FLOAT-gray?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-FLOAT)\n[![ComfyUI-Thera](https://img.shields.io/badge/ComfyUI--Thera-gray?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-Thera)\n[![ComfyUI-Video-Depth-Anything](https://img.shields.io/badge/ComfyUI--Video--Depth--Anything-gray?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-Video-Depth-Anything)\n[![ComfyUI-PiperTTS](https://img.shields.io/badge/ComfyUI--PiperTTS-gray?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-PiperTTS)\n\n[![buy-me-coffees](https://i.imgur.com/3MDbAtw.png)](https://www.buymeacoffee.com/yuvraj108cZ)\n[![paypal-donation](https://i.imgur.com/w5jjubk.png)](https://paypal.me/yuvraj108c)\n---\n\n## ğŸš€ Installation\n\n```bash\ngit clone https://github.com/yuvraj108c/ComfyUI-FLOAT.git\ncd ./ComfyUI-FLOAT\npip install -r requirements.txt\n```\n\n## â˜€ï¸ Usage\n\n- Load [example workflow](https://raw.githubusercontent.com/yuvraj108c/ComfyUI-FLOAT/master/float_workflow.json) \n- Upload driving image and audio, click queue\n- [Models](https://huggingface.co/yuvraj108c/float/tree/main) autodownload to `/ComfyUI/models/float`\n- The models are organized as follows:\n    ```.bash\n    |-- float.pth                                       # main model\n    |-- wav2vec2-base-960h/                             # audio encoder\n    |   |-- config.json\n    |   |-- model.safetensors\n    |   |-- preprocessor_config.json\n    |-- wav2vec-english-speech-emotion-recognition/     # emotion encoder\n        |-- config.json\n        |-- preprocessor_config.json\n        |-- pytorch_model.bin\n\n## ğŸ› ï¸ Parameters\n- `ref_image`: Reference image with a face (must have batch size 1)\n- `ref_audio`: Reference audio (For long audios (e.g 3+ minutes), ensure that you have enough ram/vram)\n- `a_cfg_scale`: Audio classifier-free guidance scale (default:2)\n- `r_cfg_scale`: Reference classifier-free guidance scale (default:1)\n- `emotion`: none, angry, disgust, fear, happy, neutral, sad, surprise (default:none)\n- `e_cfg_scale`: Intensity of emotion (default:1). For more emotion intensive video, try large value from 5 to 10\n- `crop`: Enable only if the reference image does not have a centered face\n- `fps`: Frame rate of the output video (default:25)\n\n   \n## Citation\n```bibtex\n@article{ki2024float,\n  title={FLOAT: Generative Motion Latent Flow Matching for Audio-driven Talking Portrait},\n  author={Ki, Taekyung and Min, Dongchan and Chae, Gyeongsu},\n  journal={arXiv preprint arXiv:2412.01064},\n  year={2024}\n}\n```\n\n## Acknowledgments\nThanks to [simplepod.ai](https://simplepod.ai/) for providing GPU servers\n\n## License\n\n[Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)](https://creativecommons.org/licenses/by-nc-sa/4.0/)\n",
  "origin_sha": "J1w6fzZLWGVxXZ6uzQqWxdmD+gFnLFEp9FPER7LLsj4=",
  "translate": "<div align=\"center\">\n\n# ComfyUI FLOAT \n\n[![python](https://img.shields.io/badge/python-3.10.12-green)](https://www.python.org/downloads/release/python-31012/)\n[![arXiv](https://img.shields.io/badge/arXiv%20paper-2412.09013-b31b1b.svg)](https://arxiv.org/abs/2412.01064) \n[![by-nc-sa/4.0](https://img.shields.io/badge/license-CC--BY--NC--SA--4.0-lightgrey)](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en)\n\n</div>\n\nÙŠÙˆÙØ± Ù‡Ø°Ø§ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ ØºÙ„Ø§Ù ComfyUI Ù„Ù…Ø´Ø±ÙˆØ¹ [FLOAT](https://github.com/deepbrainai-research/float) Ù„ØªÙˆÙ„ÙŠØ¯ Ø­Ø±ÙƒØ© ØªØ¯ÙÙ‚ ÙƒØ§Ù…Ù†Ø© Ù…ØªØ·Ø§Ø¨Ù‚Ø© Ù„Ù„ØµÙˆØ± Ø§Ù„Ù…ØªØ­Ø±ÙƒØ© Ø§Ù„Ù…Ù†Ø·ÙˆÙ‚Ø© Ø§Ù„Ù…Ø¯ÙÙˆØ¹Ø© Ø¨Ø§Ù„ØµÙˆØª.\n\nÙ„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù†Ø³Ø®Ø© Ø£ÙƒØ«Ø± ØªÙ‚Ø¯Ù…Ø§Ù‹ ÙˆÙŠØªÙ… ØµÙŠØ§Ù†ØªÙ‡Ø§ Ø¨Ø§Ø³ØªÙ…Ø±Ø§Ø±ØŒ Ø±Ø§Ø¬Ø¹: [ComfyUI-FLOAT_Optimized](https://github.com/set-soft/ComfyUI-FLOAT_Optimized)\n\n<div align=\"center\">\n  <video src=\"https://github.com/user-attachments/assets/36626b4a-d3e5-4db9-87a7-ca0e949daee0\" />\n</div> \n\n\n## â­ Ø§Ù„Ø¯Ø¹Ù…\nØ¥Ø°Ø§ Ø£Ø¹Ø¬Ø¨ØªÙƒ Ù…Ø´Ø§Ø±ÙŠØ¹ÙŠ ÙˆØªØ±ØºØ¨ ÙÙŠ Ø±Ø¤ÙŠØ© ØªØ­Ø¯ÙŠØ«Ø§Øª ÙˆÙ…ÙŠØ²Ø§Øª Ø¬Ø¯ÙŠØ¯Ø©ØŒ ÙŠØ±Ø¬Ù‰ Ø§Ù„ØªÙÙƒÙŠØ± ÙÙŠ Ø¯Ø¹Ù…ÙŠ. Ù‡Ø°Ø§ ÙŠØ³Ø§Ø¹Ø¯ ÙƒØ«ÙŠØ±Ø§Ù‹!\n\n[![ComfyUI-Depth-Anything-Tensorrt](https://img.shields.io/badge/ComfyUI--Depth--Anything--Tensorrt-blue?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-Depth-Anything-Tensorrt)\n[![ComfyUI-Upscaler-Tensorrt](https://img.shields.io/badge/ComfyUI--Upscaler--Tensorrt-blue?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-Upscaler-Tensorrt)\n[![ComfyUI-Dwpose-Tensorrt](https://img.shields.io/badge/ComfyUI--Dwpose--Tensorrt-blue?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-Dwpose-Tensorrt)\n[![ComfyUI-Rife-Tensorrt](https://img.shields.io/badge/ComfyUI--Rife--Tensorrt-blue?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-Rife-Tensorrt)\n\n[![ComfyUI-Whisper](https://img.shields.io/badge/ComfyUI--Whisper-gray?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-Whisper)\n[![ComfyUI_InvSR](https://img.shields.io/badge/ComfyUI__InvSR-gray?style=flat-square)](https://github.com/yuvraj108c/ComfyUI_InvSR)\n[![ComfyUI-FLOAT](https://img.shields.io/badge/ComfyUI--FLOAT-gray?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-FLOAT)\n[![ComfyUI-Thera](https://img.shields.io/badge/ComfyUI--Thera-gray?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-Thera)\n[![ComfyUI-Video-Depth-Anything](https://img.shields.io/badge/ComfyUI--Video--Depth--Anything-gray?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-Video-Depth-Anything)\n[![ComfyUI-PiperTTS](https://img.shields.io/badge/ComfyUI--PiperTTS-gray?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-PiperTTS)\n\n[![buy-me-coffees](https://i.imgur.com/3MDbAtw.png)](https://www.buymeacoffee.com/yuvraj108cZ)\n[![paypal-donation](https://i.imgur.com/w5jjubk.png)](https://paypal.me/yuvraj108c)\n---\n\n## ğŸš€ Ø§Ù„ØªØ«Ø¨ÙŠØª\n\n```bash\ngit clone https://github.com/yuvraj108c/ComfyUI-FLOAT.git\ncd ./ComfyUI-FLOAT\npip install -r requirements.txt\n```\n\n## â˜€ï¸ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…\n\n- Ø­Ù…Ù‘Ù„ [Ø³ÙŠØ± Ø§Ù„Ø¹Ù…Ù„ Ø§Ù„ØªØ¬Ø±ÙŠØ¨ÙŠØ©](https://raw.githubusercontent.com/yuvraj108c/ComfyUI-FLOAT/master/float_workflow.json) \n- Ù‚Ù… Ø¨ØªØ­Ù…ÙŠÙ„ ØµÙˆØ±Ø© Ø§Ù„Ù‚ÙŠØ§Ø¯Ø© ÙˆØ§Ù„ØµÙˆØªØŒ Ø«Ù… Ø§Ø¶ØºØ· Ø¹Ù„Ù‰ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø±\n- [Ø§Ù„Ù†Ù…Ø§Ø°Ø¬](https://huggingface.co/yuvraj108c/float/tree/main) ØªÙØ­Ù…Ù‘Ù„ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ Ø¥Ù„Ù‰ `/ComfyUI/models/float`\n- ÙŠØªÙ… ØªÙ†Ø¸ÙŠÙ… Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ ÙƒÙ…Ø§ ÙŠÙ„ÙŠ:\n    ```.bash\n    |-- float.pth                                       # Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ\n    |-- wav2vec2-base-960h/                             # Ù…Ø´ÙØ± Ø§Ù„ØµÙˆØª\n    |   |-- config.json\n    |   |-- model.safetensors\n    |   |-- preprocessor_config.json\n    |-- wav2vec-english-speech-emotion-recognition/     # Ù…Ø´ÙØ± Ø§Ù„Ø¹Ø§Ø·ÙØ©\n        |-- config.json\n        |-- preprocessor_config.json\n        |-- pytorch_model.bin\n\n## ğŸ› ï¸ Ø§Ù„Ù…Ø¹Ù„Ù…Ø§Øª\n- `ref_image`: ØµÙˆØ±Ø© Ù…Ø±Ø¬Ø¹ÙŠØ© ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ ÙˆØ¬Ù‡ (ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† Ø­Ø¬Ù… Ø§Ù„Ø¯ÙÙØ¹Ø© 1)\n- `ref_audio`: ØµÙˆØª Ù…Ø±Ø¬Ø¹ÙŠ (Ù„Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØµÙˆØªÙŠØ© Ø§Ù„Ø·ÙˆÙŠÙ„Ø© (Ù…Ø«Ù„Ø§Ù‹ Ø£ÙƒØ«Ø± Ù…Ù† 3 Ø¯Ù‚Ø§Ø¦Ù‚)ØŒ ØªØ£ÙƒØ¯ Ù…Ù† ØªÙˆÙØ± Ø°Ø§ÙƒØ±Ø© RAM/VRAM ÙƒØ§ÙÙŠØ©)\n- `a_cfg_scale`: Ù…Ù‚ÙŠØ§Ø³ Ø§Ù„ØªÙˆØ¬ÙŠÙ‡ Ø§Ù„Ø®Ø§Ù„ÙŠ Ù…Ù† Ø§Ù„Ù…ØµÙ†Ù Ù„Ù„ØµÙˆØª (Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ:2)\n- `r_cfg_scale`: Ù…Ù‚ÙŠØ§Ø³ Ø§Ù„ØªÙˆØ¬ÙŠÙ‡ Ø§Ù„Ø®Ø§Ù„ÙŠ Ù…Ù† Ø§Ù„Ù…ØµÙ†Ù Ù„Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠØ© (Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ:1)\n- `emotion`: Ù„Ø§ ÙŠÙˆØ¬Ø¯ØŒ ØºØ¶Ø¨ØŒ Ø§Ø´Ù…Ø¦Ø²Ø§Ø²ØŒ Ø®ÙˆÙØŒ Ø³Ø¹Ø§Ø¯Ø©ØŒ Ø­ÙŠØ§Ø¯ÙŠØŒ Ø­Ø²Ù†ØŒ Ù…ÙØ§Ø¬Ø£Ø© (Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ: Ù„Ø§ ÙŠÙˆØ¬Ø¯)\n- `e_cfg_scale`: Ø´Ø¯Ø© Ø§Ù„Ø¹Ø§Ø·ÙØ© (Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ:1). Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ÙÙŠØ¯ÙŠÙˆ Ø£ÙƒØ«Ø± ÙƒØ«Ø§ÙØ© Ø¹Ø§Ø·ÙÙŠØ©ØŒ Ø¬Ø±Ø¨ Ù‚ÙŠÙ…Ø© ÙƒØ¨ÙŠØ±Ø© Ù…Ù† 5 Ø¥Ù„Ù‰ 10\n- `crop`: ÙØ¹Ù‘Ù„ ÙÙ‚Ø· Ø¥Ø°Ø§ Ù„Ù… ØªÙƒÙ† Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠØ© ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ ÙˆØ¬Ù‡ ÙÙŠ Ø§Ù„ÙˆØ³Ø·\n- `fps`: Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø¥Ø·Ø§Ø±Ø§Øª Ù„Ù„ÙÙŠØ¯ÙŠÙˆ Ø§Ù„Ù†Ø§ØªØ¬ (Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ:25)\n\n   \n## Ø§Ù„Ø§Ø³ØªØ´Ù‡Ø§Ø¯\n```bibtex\n@article{ki2024float,\n  title={FLOAT: Generative Motion Latent Flow Matching for Audio-driven Talking Portrait},\n  author={Ki, Taekyung and Min, Dongchan and Chae, Gyeongsu},\n  journal={arXiv preprint arXiv:2412.01064},\n  year={2024}\n}\n```\n\n## Ø§Ù„Ø´ÙƒØ± ÙˆØ§Ù„ØªÙ‚Ø¯ÙŠØ±\nØ´ÙƒØ± Ø®Ø§Øµ Ù„Ù€ [simplepod.ai](https://simplepod.ai/) Ù„ØªÙˆÙÙŠØ± Ø®ÙˆØ§Ø¯Ù… GPU\n\n## Ø§Ù„Ø±Ø®ØµØ©\n\n[Ø±Ø®ØµØ© Ø§Ù„Ù…Ø´Ø§Ø¹ Ø§Ù„Ø¥Ø¨Ø¯Ø§Ø¹ÙŠ Ø§Ù„Ù†Ø³Ø¨ÙŠØ©-ØºÙŠØ± ØªØ¬Ø§Ø±ÙŠØ©-Ø¨Ø§Ù„Ù…Ø«Ù„ 4.0 Ø§Ù„Ø¯ÙˆÙ„ÙŠØ© (CC BY-NC-SA 4.0)](https://creativecommons.org/licenses/by-nc-sa/4.0/)",
  "status": "ok"
}