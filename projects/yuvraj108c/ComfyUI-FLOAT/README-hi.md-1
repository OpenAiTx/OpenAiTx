{
  "id": 1,
  "origin": "<div align=\"center\">\n\n# ComfyUI FLOAT \n\n[![python](https://img.shields.io/badge/python-3.10.12-green)](https://www.python.org/downloads/release/python-31012/)\n[![arXiv](https://img.shields.io/badge/arXiv%20paper-2412.09013-b31b1b.svg)](https://arxiv.org/abs/2412.01064) \n[![by-nc-sa/4.0](https://img.shields.io/badge/license-CC--BY--NC--SA--4.0-lightgrey)](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en)\n\n</div>\n\nThis project provides a ComfyUI wrapper of [FLOAT](https://github.com/deepbrainai-research/float) for Generative Motion Latent Flow Matching for Audio-driven Talking Portrait\n\nFor a more advanced and maintained version, check out: [ComfyUI-FLOAT_Optimized](https://github.com/set-soft/ComfyUI-FLOAT_Optimized)\n\n<div align=\"center\">\n  <video src=\"https://github.com/user-attachments/assets/36626b4a-d3e5-4db9-87a7-ca0e949daee0\" />\n</div> \n\n\n## ‚≠ê Support\nIf you like my projects and wish to see updates and new features, please consider supporting me. It helps a lot! \n\n[![ComfyUI-Depth-Anything-Tensorrt](https://img.shields.io/badge/ComfyUI--Depth--Anything--Tensorrt-blue?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-Depth-Anything-Tensorrt)\n[![ComfyUI-Upscaler-Tensorrt](https://img.shields.io/badge/ComfyUI--Upscaler--Tensorrt-blue?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-Upscaler-Tensorrt)\n[![ComfyUI-Dwpose-Tensorrt](https://img.shields.io/badge/ComfyUI--Dwpose--Tensorrt-blue?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-Dwpose-Tensorrt)\n[![ComfyUI-Rife-Tensorrt](https://img.shields.io/badge/ComfyUI--Rife--Tensorrt-blue?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-Rife-Tensorrt)\n\n[![ComfyUI-Whisper](https://img.shields.io/badge/ComfyUI--Whisper-gray?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-Whisper)\n[![ComfyUI_InvSR](https://img.shields.io/badge/ComfyUI__InvSR-gray?style=flat-square)](https://github.com/yuvraj108c/ComfyUI_InvSR)\n[![ComfyUI-FLOAT](https://img.shields.io/badge/ComfyUI--FLOAT-gray?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-FLOAT)\n[![ComfyUI-Thera](https://img.shields.io/badge/ComfyUI--Thera-gray?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-Thera)\n[![ComfyUI-Video-Depth-Anything](https://img.shields.io/badge/ComfyUI--Video--Depth--Anything-gray?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-Video-Depth-Anything)\n[![ComfyUI-PiperTTS](https://img.shields.io/badge/ComfyUI--PiperTTS-gray?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-PiperTTS)\n\n[![buy-me-coffees](https://i.imgur.com/3MDbAtw.png)](https://www.buymeacoffee.com/yuvraj108cZ)\n[![paypal-donation](https://i.imgur.com/w5jjubk.png)](https://paypal.me/yuvraj108c)\n---\n\n## üöÄ Installation\n\n```bash\ngit clone https://github.com/yuvraj108c/ComfyUI-FLOAT.git\ncd ./ComfyUI-FLOAT\npip install -r requirements.txt\n```\n\n## ‚òÄÔ∏è Usage\n\n- Load [example workflow](https://raw.githubusercontent.com/yuvraj108c/ComfyUI-FLOAT/master/float_workflow.json) \n- Upload driving image and audio, click queue\n- [Models](https://huggingface.co/yuvraj108c/float/tree/main) autodownload to `/ComfyUI/models/float`\n- The models are organized as follows:\n    ```.bash\n    |-- float.pth                                       # main model\n    |-- wav2vec2-base-960h/                             # audio encoder\n    |   |-- config.json\n    |   |-- model.safetensors\n    |   |-- preprocessor_config.json\n    |-- wav2vec-english-speech-emotion-recognition/     # emotion encoder\n        |-- config.json\n        |-- preprocessor_config.json\n        |-- pytorch_model.bin\n\n## üõ†Ô∏è Parameters\n- `ref_image`: Reference image with a face (must have batch size 1)\n- `ref_audio`: Reference audio (For long audios (e.g 3+ minutes), ensure that you have enough ram/vram)\n- `a_cfg_scale`: Audio classifier-free guidance scale (default:2)\n- `r_cfg_scale`: Reference classifier-free guidance scale (default:1)\n- `emotion`: none, angry, disgust, fear, happy, neutral, sad, surprise (default:none)\n- `e_cfg_scale`: Intensity of emotion (default:1). For more emotion intensive video, try large value from 5 to 10\n- `crop`: Enable only if the reference image does not have a centered face\n- `fps`: Frame rate of the output video (default:25)\n\n   \n## Citation\n```bibtex\n@article{ki2024float,\n  title={FLOAT: Generative Motion Latent Flow Matching for Audio-driven Talking Portrait},\n  author={Ki, Taekyung and Min, Dongchan and Chae, Gyeongsu},\n  journal={arXiv preprint arXiv:2412.01064},\n  year={2024}\n}\n```\n\n## Acknowledgments\nThanks to [simplepod.ai](https://simplepod.ai/) for providing GPU servers\n\n## License\n\n[Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)](https://creativecommons.org/licenses/by-nc-sa/4.0/)\n",
  "origin_sha": "J1w6fzZLWGVxXZ6uzQqWxdmD+gFnLFEp9FPER7LLsj4=",
  "translate": "<div align=\"center\">\n\n# ComfyUI FLOAT \n\n[![python](https://img.shields.io/badge/python-3.10.12-green)](https://www.python.org/downloads/release/python-31012/)\n[![arXiv](https://img.shields.io/badge/arXiv%20paper-2412.09013-b31b1b.svg)](https://arxiv.org/abs/2412.01064) \n[![by-nc-sa/4.0](https://img.shields.io/badge/license-CC--BY--NC--SA--4.0-lightgrey)](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en)\n\n</div>\n\n‡§Ø‡§π ‡§™‡§∞‡§ø‡§Ø‡•ã‡§ú‡§®‡§æ ‡§ë‡§°‡§ø‡§Ø‡•ã-‡§°‡•ç‡§∞‡§ø‡§µ‡§® ‡§ü‡•â‡§ï‡§ø‡§Ç‡§ó ‡§™‡•ã‡§∞‡•ç‡§ü‡•ç‡§∞‡•á‡§ü ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ú‡§®‡§∞‡•á‡§ü‡§ø‡§µ ‡§Æ‡•ã‡§∂‡§® ‡§≤‡•à‡§ü‡•á‡§Ç‡§ü ‡§´‡•ç‡§≤‡•ã ‡§Æ‡•à‡§ö‡§ø‡§Ç‡§ó ‡§π‡•á‡§§‡•Å [FLOAT](https://github.com/deepbrainai-research/float) ‡§ï‡§æ ComfyUI ‡§∞‡•à‡§™‡§∞ ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡§∞‡§§‡•Ä ‡§π‡•à‡•§\n\n‡§Ö‡§ß‡§ø‡§ï ‡§â‡§®‡•ç‡§®‡§§ ‡§î‡§∞ ‡§Ö‡§®‡•Å‡§∞‡§ï‡•ç‡§∑‡§ø‡§§ ‡§∏‡§Ç‡§∏‡•ç‡§ï‡§∞‡§£ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§¶‡•á‡§ñ‡•á‡§Ç: [ComfyUI-FLOAT_Optimized](https://github.com/set-soft/ComfyUI-FLOAT_Optimized)\n\n<div align=\"center\">\n  <video src=\"https://github.com/user-attachments/assets/36626b4a-d3e5-4db9-87a7-ca0e949daee0\" />\n</div> \n\n\n## ‚≠ê ‡§∏‡§Æ‡§∞‡•ç‡§•‡§® ‡§ï‡§∞‡•á‡§Ç\n‡§Ø‡§¶‡§ø ‡§Ü‡§™‡§ï‡•ã ‡§Æ‡•á‡§∞‡•á ‡§™‡•ç‡§∞‡•ã‡§ú‡•á‡§ï‡•ç‡§ü‡•ç‡§∏ ‡§™‡§∏‡§Ç‡§¶ ‡§π‡•à‡§Ç ‡§î‡§∞ ‡§Ü‡§™ ‡§Ö‡§™‡§°‡•á‡§ü‡•ç‡§∏ ‡§§‡§•‡§æ ‡§®‡§à ‡§∏‡•Å‡§µ‡§ø‡§ß‡§æ‡§è‡§Å ‡§¶‡•á‡§ñ‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡•á ‡§π‡•à‡§Ç, ‡§§‡•ã ‡§ï‡•É‡§™‡§Ø‡§æ ‡§Æ‡•Å‡§ù‡•á ‡§∏‡§Æ‡§∞‡•ç‡§•‡§® ‡§¶‡•á‡§®‡•á ‡§™‡§∞ ‡§µ‡§ø‡§ö‡§æ‡§∞ ‡§ï‡§∞‡•á‡§Ç‡•§ ‡§á‡§∏‡§∏‡•á ‡§¨‡§π‡•Å‡§§ ‡§Æ‡§¶‡§¶ ‡§Æ‡§ø‡§≤‡§§‡•Ä ‡§π‡•à! \n\n[![ComfyUI-Depth-Anything-Tensorrt](https://img.shields.io/badge/ComfyUI--Depth--Anything--Tensorrt-blue?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-Depth-Anything-Tensorrt)\n[![ComfyUI-Upscaler-Tensorrt](https://img.shields.io/badge/ComfyUI--Upscaler--Tensorrt-blue?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-Upscaler-Tensorrt)\n[![ComfyUI-Dwpose-Tensorrt](https://img.shields.io/badge/ComfyUI--Dwpose--Tensorrt-blue?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-Dwpose-Tensorrt)\n[![ComfyUI-Rife-Tensorrt](https://img.shields.io/badge/ComfyUI--Rife--Tensorrt-blue?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-Rife-Tensorrt)\n\n[![ComfyUI-Whisper](https://img.shields.io/badge/ComfyUI--Whisper-gray?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-Whisper)\n[![ComfyUI_InvSR](https://img.shields.io/badge/ComfyUI__InvSR-gray?style=flat-square)](https://github.com/yuvraj108c/ComfyUI_InvSR)\n[![ComfyUI-FLOAT](https://img.shields.io/badge/ComfyUI--FLOAT-gray?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-FLOAT)\n[![ComfyUI-Thera](https://img.shields.io/badge/ComfyUI--Thera-gray?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-Thera)\n[![ComfyUI-Video-Depth-Anything](https://img.shields.io/badge/ComfyUI--Video--Depth--Anything-gray?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-Video-Depth-Anything)\n[![ComfyUI-PiperTTS](https://img.shields.io/badge/ComfyUI--PiperTTS-gray?style=flat-square)](https://github.com/yuvraj108c/ComfyUI-PiperTTS)\n\n[![buy-me-coffees](https://i.imgur.com/3MDbAtw.png)](https://www.buymeacoffee.com/yuvraj108cZ)\n[![paypal-donation](https://i.imgur.com/w5jjubk.png)](https://paypal.me/yuvraj108c)\n---\n\n## üöÄ ‡§∏‡•ç‡§•‡§æ‡§™‡§®‡§æ\n\n```bash\ngit clone https://github.com/yuvraj108c/ComfyUI-FLOAT.git\ncd ./ComfyUI-FLOAT\npip install -r requirements.txt\n```\n\n## ‚òÄÔ∏è ‡§â‡§™‡§Ø‡•ã‡§ó\n\n- [example workflow](https://raw.githubusercontent.com/yuvraj108c/ComfyUI-FLOAT/master/float_workflow.json) ‡§≤‡•ã‡§° ‡§ï‡§∞‡•á‡§Ç \n- ‡§°‡•ç‡§∞‡§æ‡§á‡§µ‡§ø‡§Ç‡§ó ‡§á‡§Æ‡•á‡§ú ‡§î‡§∞ ‡§ë‡§°‡§ø‡§Ø‡•ã ‡§Ö‡§™‡§≤‡•ã‡§° ‡§ï‡§∞‡•á‡§Ç, ‡§´‡§ø‡§∞ queue ‡§™‡§∞ ‡§ï‡•ç‡§≤‡§ø‡§ï ‡§ï‡§∞‡•á‡§Ç\n- [‡§Æ‡•â‡§°‡§≤‡•ç‡§∏](https://huggingface.co/yuvraj108c/float/tree/main) ‡§∏‡•ç‡§µ‡§§‡§É `/ComfyUI/models/float` ‡§Æ‡•á‡§Ç ‡§°‡§æ‡§â‡§®‡§≤‡•ã‡§° ‡§π‡•ã ‡§ú‡§æ‡§§‡•á ‡§π‡•à‡§Ç\n- ‡§Æ‡•â‡§°‡§≤‡•ç‡§∏ ‡§®‡§ø‡§Æ‡•ç‡§®‡§≤‡§ø‡§ñ‡§ø‡§§ ‡§∞‡•Ç‡§™ ‡§Æ‡•á‡§Ç ‡§µ‡•ç‡§Ø‡§µ‡§∏‡•ç‡§•‡§ø‡§§ ‡§π‡•à‡§Ç:\n    ```.bash\n    |-- float.pth                                       # ‡§Æ‡•Å‡§ñ‡•ç‡§Ø ‡§Æ‡•â‡§°‡§≤\n    |-- wav2vec2-base-960h/                             # ‡§ë‡§°‡§ø‡§Ø‡•ã ‡§è‡§®‡§ï‡•ã‡§°‡§∞\n    |   |-- config.json\n    |   |-- model.safetensors\n    |   |-- preprocessor_config.json\n    |-- wav2vec-english-speech-emotion-recognition/     # ‡§á‡§Æ‡•ã‡§∂‡§® ‡§è‡§®‡§ï‡•ã‡§°‡§∞\n        |-- config.json\n        |-- preprocessor_config.json\n        |-- pytorch_model.bin\n\n## üõ†Ô∏è ‡§™‡•à‡§∞‡§æ‡§Æ‡•Ä‡§ü‡§∞‡•ç‡§∏\n- `ref_image`: ‡§è‡§ï ‡§ö‡•á‡§π‡§∞‡§æ ‡§µ‡§æ‡§≤‡§æ ‡§∏‡§Ç‡§¶‡§∞‡•ç‡§≠ ‡§ö‡§ø‡§§‡•ç‡§∞ (‡§¨‡•à‡§ö ‡§∏‡§æ‡§á‡§ú 1 ‡§π‡•ã‡§®‡§æ ‡§Ö‡§®‡§ø‡§µ‡§æ‡§∞‡•ç‡§Ø)\n- `ref_audio`: ‡§∏‡§Ç‡§¶‡§∞‡•ç‡§≠ ‡§ë‡§°‡§ø‡§Ø‡•ã (‡§≤‡§Ç‡§¨‡•á ‡§ë‡§°‡§ø‡§Ø‡•ã ‡§ï‡•á ‡§≤‡§ø‡§è (‡§ú‡•à‡§∏‡•á 3+ ‡§Æ‡§ø‡§®‡§ü), ‡§Ø‡§π ‡§∏‡•Å‡§®‡§ø‡§∂‡•ç‡§ö‡§ø‡§§ ‡§ï‡§∞‡•á‡§Ç ‡§ï‡§ø ‡§Ü‡§™‡§ï‡•á ‡§™‡§æ‡§∏ ‡§™‡§∞‡•ç‡§Ø‡§æ‡§™‡•ç‡§§ RAM/VRAM ‡§π‡•ã)\n- `a_cfg_scale`: ‡§ë‡§°‡§ø‡§Ø‡•ã ‡§ï‡•ç‡§≤‡§æ‡§∏‡§ø‡§´‡§æ‡§Ø‡§∞-‡§´‡•ç‡§∞‡•Ä ‡§ó‡§æ‡§á‡§°‡•á‡§Ç‡§∏ ‡§∏‡•ç‡§ï‡•á‡§≤ (‡§°‡§ø‡§´‡•â‡§≤‡•ç‡§ü:2)\n- `r_cfg_scale`: ‡§∞‡•á‡§´‡§∞‡•á‡§Ç‡§∏ ‡§ï‡•ç‡§≤‡§æ‡§∏‡§ø‡§´‡§æ‡§Ø‡§∞-‡§´‡•ç‡§∞‡•Ä ‡§ó‡§æ‡§á‡§°‡•á‡§Ç‡§∏ ‡§∏‡•ç‡§ï‡•á‡§≤ (‡§°‡§ø‡§´‡•â‡§≤‡•ç‡§ü:1)\n- `emotion`: none, angry, disgust, fear, happy, neutral, sad, surprise (‡§°‡§ø‡§´‡•â‡§≤‡•ç‡§ü:none)\n- `e_cfg_scale`: ‡§á‡§Æ‡•ã‡§∂‡§® ‡§ï‡•Ä ‡§§‡•Ä‡§µ‡•ç‡§∞‡§§‡§æ (‡§°‡§ø‡§´‡•â‡§≤‡•ç‡§ü:1)‡•§ ‡§Ö‡§ß‡§ø‡§ï ‡§á‡§Æ‡•ã‡§∂‡§® ‡§á‡§Ç‡§ü‡•á‡§Ç‡§∏‡§ø‡§µ ‡§µ‡•Ä‡§°‡§ø‡§Ø‡•ã ‡§ï‡•á ‡§≤‡§ø‡§è 5 ‡§∏‡•á 10 ‡§§‡§ï ‡§¨‡§°‡§º‡§æ ‡§Æ‡§æ‡§® ‡§Ü‡§ú‡§Æ‡§æ‡§è‡§Ç\n- `crop`: ‡§ï‡•á‡§µ‡§≤ ‡§§‡§≠‡•Ä ‡§∏‡§ï‡•ç‡§∑‡§Æ ‡§ï‡§∞‡•á‡§Ç ‡§ú‡§¨ ‡§∏‡§Ç‡§¶‡§∞‡•ç‡§≠ ‡§ö‡§ø‡§§‡•ç‡§∞ ‡§Æ‡•á‡§Ç ‡§ö‡•á‡§π‡§∞‡§æ ‡§ï‡•á‡§Ç‡§¶‡•ç‡§∞‡§ø‡§§ ‡§® ‡§π‡•ã\n- `fps`: ‡§Ü‡§â‡§ü‡§™‡•Å‡§ü ‡§µ‡•Ä‡§°‡§ø‡§Ø‡•ã ‡§ï‡§æ ‡§´‡•ç‡§∞‡•á‡§Æ ‡§∞‡•á‡§ü (‡§°‡§ø‡§´‡•â‡§≤‡•ç‡§ü:25)\n\n   \n## ‡§∏‡§Ç‡§¶‡§∞‡•ç‡§≠\n```bibtex\n@article{ki2024float,\n  title={FLOAT: Generative Motion Latent Flow Matching for Audio-driven Talking Portrait},\n  author={Ki, Taekyung and Min, Dongchan and Chae, Gyeongsu},\n  journal={arXiv preprint arXiv:2412.01064},\n  year={2024}\n}\n```\n\n## ‡§Ü‡§≠‡§æ‡§∞\nGPU ‡§∏‡§∞‡•ç‡§µ‡§∞ ‡§â‡§™‡§≤‡§¨‡•ç‡§ß ‡§ï‡§∞‡§æ‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è [simplepod.ai](https://simplepod.ai/) ‡§ï‡§æ ‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ‡§¶\n\n## ‡§≤‡§æ‡§á‡§∏‡•á‡§Ç‡§∏\n\n[‡§ï‡•ç‡§∞‡§ø‡§è‡§ü‡§ø‡§µ ‡§ï‡•â‡§Æ‡§®‡•ç‡§∏ ‡§è‡§ü‡•ç‡§∞‡§ø‡§¨‡•ç‡§Ø‡•Ç‡§∂‡§®-‡§®‡•â‡§®‡§ï‡§Æ‡§∞‡•ç‡§∂‡§ø‡§Ø‡§≤-‡§∂‡•á‡§Ø‡§∞‡§Ö‡§≤‡§æ‡§á‡§ï 4.0 ‡§á‡§Ç‡§ü‡§∞‡§®‡•á‡§∂‡§®‡§≤ (CC BY-NC-SA 4.0)](https://creativecommons.org/licenses/by-nc-sa/4.0/)",
  "status": "ok"
}