[
  {
    "row": 1,
    "rowsha": "JxESpSOemcOHL7YK3E5sXNUt0UcsbKqLYX+tuvsu7P4=",
    "originContent": "<h1 align=\"center\">ThinkSound</h1>",
    "translatedContent": "<h1 align=\"center\">ThinkSound</h1>"
  },
  {
    "row": 2,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 3,
    "rowsha": "+/a9XmPwQixGFroME/GMEOLpReZZV4ARosR9orAplJY=",
    "originContent": "<p align=\"center\">",
    "translatedContent": "<p align=\"center\">"
  },
  {
    "row": 4,
    "rowsha": "CSeo6S41hUQEjrndf6ijg79FX29RUxiFJUVIA3cYsNQ=",
    "originContent": "  🌐",
    "translatedContent": "  🌐"
  },
  {
    "row": 5,
    "rowsha": "IJLGqpRt+7ez3r1WoZz6fvh/rC+8KZ5K3FP2xs/0LNM=",
    "originContent": "  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=en\">English</a> |",
    "translatedContent": "  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=en\">English</a> |"
  },
  {
    "row": 6,
    "rowsha": "hhbPoa8bqBB7SPpAAUVT30o77g3w0Ky5ywfQeyLf1j4=",
    "originContent": "  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=zh-CN\">简体中文</a> |",
    "translatedContent": "  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=zh-CN\">简体中文</a> |"
  },
  {
    "row": 7,
    "rowsha": "tRfgQgD9d867JyLy4SUrBX76D1lWSxv43P6AXFC6S+E=",
    "originContent": "  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=zh-TW\">繁體中文</a> |",
    "translatedContent": "  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=zh-TW\">繁體中文</a> |"
  },
  {
    "row": 8,
    "rowsha": "6wLn1diFukrW2YDUESRE3YVcqNY3dxojo6fHTtwy5Pw=",
    "originContent": "  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=es\">Español</a> |",
    "translatedContent": "  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=es\">Español</a> |"
  },
  {
    "row": 9,
    "rowsha": "evSE8XG0v3qXaLIwGU0C7m+8gbYGsKYAemuq5Tn6Xog=",
    "originContent": "  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=fr\">Français</a> |",
    "translatedContent": "  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=fr\">Français</a> |"
  },
  {
    "row": 10,
    "rowsha": "9f+fFClA7BNYID46cHbx1rrKXWcVW5LDZW5Zy7DVZ+w=",
    "originContent": "  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=ja\">日本語</a>",
    "translatedContent": "  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=ja\">日本語</a>"
  },
  {
    "row": 11,
    "rowsha": "bBefIeb2K2KQVdirQPRU7QLki2hWORNHO4V9NjjiOyg=",
    "originContent": "  ",
    "translatedContent": "  "
  },
  {
    "row": 12,
    "rowsha": "dSdvPNAZSmR86FDDSF6tkQUCVfI9qmACHOR5tThOetY=",
    "originContent": "</p>",
    "translatedContent": "</p>"
  },
  {
    "row": 13,
    "rowsha": "+/a9XmPwQixGFroME/GMEOLpReZZV4ARosR9orAplJY=",
    "originContent": "<p align=\"center\">",
    "translatedContent": "<p align=\"center\">"
  },
  {
    "row": 14,
    "rowsha": "u6qveIBtgMElVk/Aw6sAj4eJ8Fk+KrPya5ZyECHKRqA=",
    "originContent": "  <img src=\"https://img.shields.io/badge/NeurIPS 2025-Main Conference-blue.svg\" alt=\"NeurIPS 2025\"/>",
    "translatedContent": "  <img src=\"https://img.shields.io/badge/NeurIPS 2025-Main Conference-blue.svg\" alt=\"NeurIPS 2025\"/>"
  },
  {
    "row": 15,
    "rowsha": "+/a9XmPwQixGFroME/GMEOLpReZZV4ARosR9orAplJY=",
    "originContent": "<p align=\"center\">",
    "translatedContent": "<p align=\"center\">"
  },
  {
    "row": 16,
    "rowsha": "U41oE9v936BfSGDgJuMB1g3jQTqsJtmJPQUhVonUNHI=",
    "originContent": "  <a href=\"https://arxiv.org/pdf/2506.21448\">",
    "translatedContent": "  <a href=\"https://arxiv.org/pdf/2506.21448\">"
  },
  {
    "row": 17,
    "rowsha": "ynIImIY0Z2jVqizQykbwGTP/PcL0XGIQs5BslFVtz58=",
    "originContent": "    <img src=\"https://img.shields.io/badge/arXiv-2506.21448-b31b1b.svg\" alt=\"arXiv\"/>",
    "translatedContent": "    <img src=\"https://img.shields.io/badge/arXiv-2506.21448-b31b1b.svg\" alt=\"arXiv\"/>"
  },
  {
    "row": 18,
    "rowsha": "7Sl5c7caJ7+Yt222Hl2I2PLtk1UIeh8Qfn02MNONw0Y=",
    "originContent": "  </a>",
    "translatedContent": "  </a>"
  },
  {
    "row": 19,
    "rowsha": "robEj93GNR0ga47/E63BGVUMman0bHA00TiujTzIdqs=",
    "originContent": "  &nbsp;",
    "translatedContent": "  &nbsp;"
  },
  {
    "row": 20,
    "rowsha": "Yff0X0Mje5Jr8Vv7MEJie2CoYJL+UpE7RrCgKgVeN0c=",
    "originContent": "  <a href=\"https://thinksound-project.github.io/\">",
    "translatedContent": "  <a href=\"https://thinksound-project.github.io/\">"
  },
  {
    "row": 21,
    "rowsha": "H+PqZbUh0elg8uffxX9z5kKKpS5/odGusuxfm7oCW7w=",
    "originContent": "    <img src=\"https://img.shields.io/badge/Online%20Demo-🌐-blue\" alt=\"Online Demo\"/>",
    "translatedContent": "    <img src=\"https://img.shields.io/badge/Online%20Demo-🌐-blue\" alt=\"Online Demo\"/>"
  },
  {
    "row": 22,
    "rowsha": "7Sl5c7caJ7+Yt222Hl2I2PLtk1UIeh8Qfn02MNONw0Y=",
    "originContent": "  </a>",
    "translatedContent": "  </a>"
  },
  {
    "row": 23,
    "rowsha": "robEj93GNR0ga47/E63BGVUMman0bHA00TiujTzIdqs=",
    "originContent": "  &nbsp;",
    "translatedContent": "  &nbsp;"
  },
  {
    "row": 24,
    "rowsha": "8w8i7BBaV0MFFj9oV8SQ9+mUcgmT0lDsYIGPYBRMK4k=",
    "originContent": "  <a href=\"https://huggingface.co/spaces/FunAudioLLM/ThinkSound\">",
    "translatedContent": "  <a href=\"https://huggingface.co/spaces/FunAudioLLM/ThinkSound\">"
  },
  {
    "row": 25,
    "rowsha": "MShdQrgDW0rCwuvHGbK9UiqT/w2XoWfU6MCC4EQ8Oo0=",
    "originContent": "    <img src=\"https://img.shields.io/badge/HuggingFace-Spaces-orange?logo=huggingface\" alt=\"Hugging Face\"/>",
    "translatedContent": "    <img src=\"https://img.shields.io/badge/HuggingFace-Spaces-orange?logo=huggingface\" alt=\"Hugging Face\"/>"
  },
  {
    "row": 26,
    "rowsha": "7Sl5c7caJ7+Yt222Hl2I2PLtk1UIeh8Qfn02MNONw0Y=",
    "originContent": "  </a>",
    "translatedContent": "  </a>"
  },
  {
    "row": 27,
    "rowsha": "robEj93GNR0ga47/E63BGVUMman0bHA00TiujTzIdqs=",
    "originContent": "  &nbsp;",
    "translatedContent": "  &nbsp;"
  },
  {
    "row": 28,
    "rowsha": "ycu3inIAlcQNI/CFyarNMwyiRfw4GtBsvcc/0LcD3c0=",
    "originContent": "  <a href=\"https://modelscope.cn/studios/iic/ThinkSound\">",
    "translatedContent": "  <a href=\"https://modelscope.cn/studios/iic/ThinkSound\">"
  },
  {
    "row": 29,
    "rowsha": "4Z9FQa2ROL8/O+DmziXnhj/aKyTxS9GGOmocWYnVJ6g=",
    "originContent": "    <img src=\"https://img.shields.io/badge/ModelScope-在线体验-green\" alt=\"ModelScope\"/>",
    "translatedContent": "    <img src=\"https://img.shields.io/badge/ModelScope-在线体验-green\" alt=\"ModelScope\"/>"
  },
  {
    "row": 30,
    "rowsha": "7Sl5c7caJ7+Yt222Hl2I2PLtk1UIeh8Qfn02MNONw0Y=",
    "originContent": "  </a>",
    "translatedContent": "  </a>"
  },
  {
    "row": 31,
    "rowsha": "dSdvPNAZSmR86FDDSF6tkQUCVfI9qmACHOR5tThOetY=",
    "originContent": "</p>",
    "translatedContent": "</p>"
  },
  {
    "row": 32,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 33,
    "rowsha": "+/a9XmPwQixGFroME/GMEOLpReZZV4ARosR9orAplJY=",
    "originContent": "<p align=\"center\">",
    "translatedContent": "<p align=\"center\">"
  },
  {
    "row": 34,
    "rowsha": "fxEtxfqHrh5PDQ2L/Ev2ea69zRukpezpCLPOHXsEpDw=",
    "originContent": "  If you find this project useful,<br>",
    "translatedContent": "  如果你觉得这个项目有用，<br>"
  },
  {
    "row": 35,
    "rowsha": "oOAWVtx09WaVCvchPgX0GhZlzuPjXH1p6nhjfyZ2aS8=",
    "originContent": "  a star ⭐ on GitHub would be greatly appreciated!",
    "translatedContent": "  欢迎在 GitHub 上点个星 ⭐！"
  },
  {
    "row": 36,
    "rowsha": "dSdvPNAZSmR86FDDSF6tkQUCVfI9qmACHOR5tThOetY=",
    "originContent": "</p>",
    "translatedContent": "</p>"
  },
  {
    "row": 37,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 38,
    "rowsha": "yz+R1U7uMOU+NbK5mQX3Dxae1Un9eJCdPawt78ntjTs=",
    "originContent": "---",
    "translatedContent": "---"
  },
  {
    "row": 39,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 40,
    "rowsha": "FQA4zA43MxvNXTogMO1WpS71bCSxerCOM1e/tmSmotg=",
    "originContent": "**ThinkSound** is a unified Any2Audio generation framework with flow matching guided by Chain-of-Thought (CoT) reasoning.",
    "translatedContent": "**ThinkSound** 是一个统一的 Any2Audio 生成框架，结合了由思维链（Chain-of-Thought, CoT）推理指导的流匹配方法。"
  },
  {
    "row": 41,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 42,
    "rowsha": "eexREJOMCITdo96Iwg4N4PQqu1ux/UwupfjVRj0l/L8=",
    "originContent": "PyTorch implementation for multimodal audio generation and editing: generate or edit audio from video, text, and audio, powered by step-by-step reasoning from Multimodal Large Language Models (MLLMs).",
    "translatedContent": "用于多模态音频生成与编辑的 PyTorch 实现：可根据视频、文本和音频生成或编辑音频，由多模态大语言模型（MLLM）逐步推理驱动。"
  },
  {
    "row": 43,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 44,
    "rowsha": "+7Cx1rdpWiIOeWRA/RM6HsKf7pNA3hHsQk2Bpadt4II=",
    "originContent": "![Teaser](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig1_teaser.png)",
    "translatedContent": "![Teaser](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig1_teaser.png)"
  },
  {
    "row": 45,
    "rowsha": "yz+R1U7uMOU+NbK5mQX3Dxae1Un9eJCdPawt78ntjTs=",
    "originContent": "---",
    "translatedContent": "---"
  },
  {
    "row": 46,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 47,
    "rowsha": "0YeCyxpcm7/4RDbaM+OQoI8YfqEHQzDkpGW15VZdi1U=",
    "originContent": "## 📰 News",
    "translatedContent": "## 📰 新闻"
  },
  {
    "row": 48,
    "rowsha": "vj2hbV/6MacDcxRmFA0AtTog5xU6CHoqBFO3YMO+yJo=",
    "originContent": "- **2025.09.19** &nbsp; 🎉 ThinkSound has been accepted to the **NeurIPS 2025 Main Conference**!",
    "translatedContent": "- **2025.09.19** &nbsp; 🎉 ThinkSound 已被 **NeurIPS 2025 主会场** 接收！"
  },
  {
    "row": 49,
    "rowsha": "cowWEeVmTC64/Cn+su00RYaecArXegbIhiQxYHzseg4=",
    "originContent": "- **2025.09.01** &nbsp; 🔥 Our AudioCoT dataset is now open-sourced and available on [Hugging Face](https://huggingface.co/datasets/liuhuadai/AudioCoT)!",
    "translatedContent": "- **2025.09.01** &nbsp; 🔥 我们的 AudioCoT 数据集已开源并在 [Hugging Face](https://huggingface.co/datasets/liuhuadai/AudioCoT) 上可用！"
  },
  {
    "row": 50,
    "rowsha": "4Jq9g83O8cYV4fVKsetfTpI+JrSepLrjK6J7Xg9tSqo=",
    "originContent": "- **2025.07.17** &nbsp; 🧠 Finetuning enabled: training and finetuning code is now publicly available, along with clear usage instructions to help you customize and extend ThinkSound with your own data.",
    "translatedContent": "- **2025.07.17** &nbsp; 🧠 支持微调：训练与微调代码现已公开，附带详细使用说明，助您用自有数据定制和扩展 ThinkSound。"
  },
  {
    "row": 51,
    "rowsha": "Ae5w+cTrCd9E8qidC11IWJAgg+LuOgUxA4czDPNG/G0=",
    "originContent": "- **2025.07.15** &nbsp; 📦 Simplified installation and usability: dependencies on PyPI for easy cross-platform setup; Windows `.bat` scripts automate environment creation and script running.",
    "translatedContent": "- **2025.07.15** &nbsp; 📦 安装与使用更简化：PyPI 依赖实现跨平台便捷部署；Windows `.bat` 脚本自动创建环境并运行脚本。"
  },
  {
    "row": 52,
    "rowsha": "nYxNhwgSqjwYLuWsfHAqP5sx2PnzYwoFrwcf9U+Fdss=",
    "originContent": "- **2025.07.08** &nbsp;  🔧 Major update: model lightweighted and optimized memory and GPU usage, now supports high-throughput audio generation at scale!",
    "translatedContent": "- **2025.07.08** &nbsp;  🔧 重大更新：模型轻量化，并优化内存与 GPU 使用，现已支持大规模高吞吐音频生成！"
  },
  {
    "row": 53,
    "rowsha": "xuARkITJMc1ABOl8/xX47dORDInuxwAsk8O1r5dvfpc=",
    "originContent": "- **2025.07.01** &nbsp; 🔥Online demo on [Hugging Face Spaces](https://huggingface.co/spaces/FunAudioLLM/ThinkSound) and [ModelScope](https://modelscope.cn/studios/iic/ThinkSound) for interactive experience!",
    "translatedContent": "- **2025.07.01** &nbsp; 🔥在线演示在 [Hugging Face Spaces](https://huggingface.co/spaces/FunAudioLLM/ThinkSound) 和 [ModelScope](https://modelscope.cn/studios/iic/ThinkSound) 上可交互体验！"
  },
  {
    "row": 54,
    "rowsha": "aIpa8g7qqXl8Iq8shRpiY5Ha5WD8c9Pd9PWybZ+wr18=",
    "originContent": "- **2025.07.01** &nbsp; 🔥Released inference scripts and web interface; ",
    "translatedContent": "- **2025.07.01** &nbsp; 🔥推理脚本与网页界面已发布；"
  },
  {
    "row": 55,
    "rowsha": "ynCJTuWmfRd3D7hcoW1WvIQ482zzFcdaXc8pgOG02Tw=",
    "originContent": "- **2025.06** &nbsp; 🔥[ThinkSound paper](https://arxiv.org/pdf/2506.21448) released on arXiv!",
    "translatedContent": "- **2025.06** &nbsp; 🔥[ThinkSound 论文](https://arxiv.org/pdf/2506.21448) 已在 arXiv 发布！"
  },
  {
    "row": 56,
    "rowsha": "se+rRi5CpnStAflq7OZvd/2mN+51ezQQaBeYckrGFCk=",
    "originContent": "- **2025.06** &nbsp; 🔥[Online Demo](http://thinksound-project.github.io/) is live - try it now!",
    "translatedContent": "- **2025.06** &nbsp; 🔥[在线演示](http://thinksound-project.github.io/)已上线 - 立即体验！"
  },
  {
    "row": 57,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 58,
    "rowsha": "yz+R1U7uMOU+NbK5mQX3Dxae1Un9eJCdPawt78ntjTs=",
    "originContent": "---",
    "translatedContent": "---"
  },
  {
    "row": 59,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 60,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 61,
    "rowsha": "f4oQIFLM2EJQxJ65F4oMEA7yWOIqs0eBtiIvGxI+GgI=",
    "originContent": "## 🚀 Features",
    "translatedContent": "## 🚀 主要功能"
  },
  {
    "row": 62,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 63,
    "rowsha": "8TbVluJJPR3C0fX41HklpO/vH9/k/rHC+jlvmHHfzQU=",
    "originContent": "- **Any2Audio**: Generate audio from arbitrary modalities — video, text, audio, or their combinations.",
    "translatedContent": "- **Any2Audio**：可从任意模态生成音频——视频、文本、音频或它们的组合。"
  },
  {
    "row": 64,
    "rowsha": "+Jf5LrYz+d1ShYCuQe8UF9taEJUpuGhDk6fAlYK3Kj4=",
    "originContent": "- **Video-to-Audio SOTA**: Achieves state-of-the-art results on multiple V2A benchmarks.",
    "translatedContent": "- **视频转音频 SOTA**：在多项 V2A 基准上取得最先进成果。"
  },
  {
    "row": 65,
    "rowsha": "mU7qXkjW1YifKoYXJedYo9l64NsTBaiXsgoGFRF/g+E=",
    "originContent": "- **CoT-Driven Reasoning**: Chain-of-Thought reasoning for compositional and controllable audio generation via MLLMs.",
    "translatedContent": "- **CoT 推理驱动**：通过 MLLM 实现可组合、可控的音频生成链式思维推理。"
  },
  {
    "row": 66,
    "rowsha": "RComOCBBrXsZf9RHmLginqKTh9eI/bKUZuUunQEmD5M=",
    "originContent": "- **Interactive Object-centric Editing**: Refine or edit specific sound events by clicking on visual objects or using text instructions.",
    "translatedContent": "- **交互式面向对象编辑**：点击视觉对象或使用文本指令，细化或编辑特定声音事件。"
  },
  {
    "row": 67,
    "rowsha": "C3sf87sy73G/XZft+TDo5NjXo5XcrtJB805ayHRAXoQ=",
    "originContent": "- **Unified Framework**: One foundation model supports generation, editing, and interactive workflow.",
    "translatedContent": "- **统一框架**：一个基础模型支持生成、编辑和交互式流程。"
  },
  {
    "row": 68,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 69,
    "rowsha": "yz+R1U7uMOU+NbK5mQX3Dxae1Un9eJCdPawt78ntjTs=",
    "originContent": "---",
    "translatedContent": "---"
  },
  {
    "row": 70,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 71,
    "rowsha": "gjgLOIAU2x83BBZdLUdgEB+F64ajt/QuLYQXM1hDBLE=",
    "originContent": "## ✨ Method Overview",
    "translatedContent": "## ✨ 方法概览"
  },
  {
    "row": 72,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 73,
    "rowsha": "v5//GqG/smYIGoUpN+12k+9/3GWH3GdYD+jLqScb7AM=",
    "originContent": "ThinkSound decomposes audio generation and editing into three interactive stages, all guided by MLLM-based Chain-of-Thought (CoT) reasoning:",
    "translatedContent": "ThinkSound 将音频生成与编辑分为三个交互阶段，全部由 MLLM 基于链式思维（CoT）推理驱动："
  },
  {
    "row": 74,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 75,
    "rowsha": "vTObEWb7f5gCU681X3dTkwqhsaSW89TLw3GgMJ5I3bo=",
    "originContent": "1. **Foley Generation:** Generate foundational, semantically and temporally aligned soundscapes from video.",
    "translatedContent": "1. **拟音生成：** 从视频生成基础、语义和时间对齐的声景。"
  },
  {
    "row": 76,
    "rowsha": "LTBpIQQHtEkNF8StAa+ZEDASGmRhmHIKDQOdZ4ExJWM=",
    "originContent": "2. **Object-Centric Refinement:** Refine or add sounds for user-specified objects via clicks or regions in the video.",
    "translatedContent": "2. **面向对象精细化：** 通过点击或选取视频区域，为用户指定的对象细化或添加声音。"
  },
  {
    "row": 77,
    "rowsha": "8wrAo7X7dPC6Sgpfrlq2ziv/Wg/3+JnlFYvO+RMxADQ=",
    "originContent": "3. **Targeted Audio Editing:** Modify generated audio using high-level natural language instructions.",
    "translatedContent": "3. **定向音频编辑：** 使用高级自然语言指令修改生成的音频。"
  },
  {
    "row": 78,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 79,
    "rowsha": "4UKlvFW3Xb0bSAVjcBNeekH/MMiYS0XDg9w4mCuPy/Q=",
    "originContent": "![ThinkSound Overview](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig3_model.png)",
    "translatedContent": "![ThinkSound Overview](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig3_model.png)"
  },
  {
    "row": 80,
    "rowsha": "GaujeIM3x7+YcFy07LNNyITlujhkgpgeIaOiKHJkYnE=",
    "originContent": "<!-- A large-scale CoT-annotated dataset (**AudioCoT**) is used to train both the reasoning module and the unified audio foundation model.",
    "translatedContent": "<!-- 一个大规模 CoT 注释数据集（**AudioCoT**）用于训练推理模块和统一音频基础模型。"
  },
  {
    "row": 81,
    "rowsha": "qYOXaaTiYkoaPFcpTXE5xdSqqiW3ebi//EW/RfSXd9g=",
    "originContent": "![AudioCoT Pipeline](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig2_dataset.png) -->",
    "translatedContent": "![AudioCoT Pipeline](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig2_dataset.png) -->"
  },
  {
    "row": 82,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 83,
    "rowsha": "yz+R1U7uMOU+NbK5mQX3Dxae1Un9eJCdPawt78ntjTs=",
    "originContent": "---",
    "translatedContent": "---"
  },
  {
    "row": 84,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 85,
    "rowsha": "PrY/jc4yAHdS+Sr+s+Yhab477/BDp3GAzMJ8+WyumyI=",
    "originContent": "## ⚡ Quick Start",
    "translatedContent": "## ⚡ 快速开始"
  },
  {
    "row": 86,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 87,
    "rowsha": "mD63DGEpdc7FlccTEps0KPAiwsJpO/C3yjV+SKIi/vE=",
    "originContent": "**Environment Preparation:**",
    "translatedContent": "**环境准备：**"
  },
  {
    "row": 88,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 89,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 90,
    "rowsha": "gqXeKd562+SIhV8X5lKkIq9fmYls0JvenYq/r5leqGU=",
    "originContent": "## 🏋️ Train the Model",
    "translatedContent": "## 🏋️ 训练模型"
  },
  {
    "row": 91,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 92,
    "rowsha": "2tP4BwaoybodWdJJ8ZupmDbf3ea5A0f+lD6kd0qGru8=",
    "originContent": "See [`Training.md`](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/docs/Training.md)",
    "translatedContent": "请参阅 [`Training.md`](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/docs/Training.md)"
  },
  {
    "row": 93,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 94,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 95,
    "rowsha": "yz+R1U7uMOU+NbK5mQX3Dxae1Un9eJCdPawt78ntjTs=",
    "originContent": "---",
    "translatedContent": "---"
  },
  {
    "row": 96,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 97,
    "rowsha": "21hoBW2Chiv9qZT66tUvbTf1cEdQjWTP1PUgVsUkdFY=",
    "originContent": "## 📝 TODO & Future Plans",
    "translatedContent": "## 📝 待办事项与未来规划"
  },
  {
    "row": 98,
    "rowsha": "FrwO0jQkAGelT7Z0nxH1R9qrULhNLkTE9mkwOhdMPY8=",
    "originContent": "* - [ ] Release a more powerful foundation model covering multiple domains to provide more engaging and immersive foley creation",
    "translatedContent": "* - [ ] 发布更强大的基础模型，覆盖多个领域，提供更具吸引力和沉浸感的拟音创作"
  },
  {
    "row": 99,
    "rowsha": "UkxbZFENzZPvcMheOeyohEptbnVaOGv9G4R6F65rAUA=",
    "originContent": "* - [ ] Add support for additional modalities and downstream tasks",
    "translatedContent": "* - [ ] 增加对更多模态和下游任务的支持"
  },
  {
    "row": 100,
    "rowsha": "E0/ATBXmq5Z+04AptdW37Wxd5y8GSQNsoEWooX9af6s=",
    "originContent": "* - [ ] Release models at different scales",
    "translatedContent": "* - [ ] 发布不同规模的模型"
  },
  {
    "row": 101,
    "rowsha": "fjIAroioQtu6rLpfZfLu7D1x79s4hnPI+ZQSINXiAVk=",
    "originContent": "* - [x] Open-source AudioCoT dataset and automated pipeline",
    "translatedContent": "* - [x] 开源 AudioCoT 数据集和自动化流程"
  },
  {
    "row": 102,
    "rowsha": "k5iXHel4EfGgiGsMDCE6yv2H9ETcLNi9lRuB8gaPbt4=",
    "originContent": "* - [x] Release training scripts for ThinkSound models",
    "translatedContent": "* - [x] 发布 ThinkSound 模型的训练脚本"
  },
  {
    "row": 103,
    "rowsha": "AKQD74q/2r77sZrB6i/RNuvdN/QOzatiPxneZX2CGJY=",
    "originContent": "* - [x] A beginner-friendly Windows quick-start README",
    "translatedContent": "* - [x] 提供面向初学者的 Windows 快速入门 README"
  },
  {
    "row": 104,
    "rowsha": "yz+R1U7uMOU+NbK5mQX3Dxae1Un9eJCdPawt78ntjTs=",
    "originContent": "---",
    "translatedContent": "---"
  },
  {
    "row": 105,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 106,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 107,
    "rowsha": "qdzKI50RqHyAaNHbQuVekCMXyk/TfGfppMlRPvlONC4=",
    "originContent": "## 📄 License",
    "translatedContent": "## 📄 许可证"
  },
  {
    "row": 108,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 109,
    "rowsha": "aXzA1Vml4g3VpeAQHojytlHw5gMbI/HCXkxCOreR8fk=",
    "originContent": "This project is released under the Apache 2.0 License.",
    "translatedContent": "本项目采用 Apache 2.0 许可证发布。"
  },
  {
    "row": 110,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 111,
    "rowsha": "q6szrCjtQrp9SVd3O6pmLDmi4BNjrSJj5JAz5iOimGA=",
    "originContent": "> **Note:**",
    "translatedContent": "> **注意：**"
  },
  {
    "row": 112,
    "rowsha": "rOuOE29N380ZQ7xL0jH7/C5Wx2byuzA8mLZWbrRiPMU=",
    "originContent": "> The code, models, and dataset are **for research and educational purposes only**.",
    "translatedContent": "> 代码、模型和数据集仅用于**科研和教育目的**。"
  },
  {
    "row": 113,
    "rowsha": "FEb26wdcJZ+QYdFQmEiYYJyI1m7dr8KnrT/jJ+mJJ9E=",
    "originContent": "> **Commercial use is NOT permitted.**",
    "translatedContent": "> **禁止商业用途。**"
  },
  {
    "row": 114,
    "rowsha": "YQDz0urnAm3iQlKVm+90x6BIEceDXonnoA+1AGDIxUo=",
    "originContent": "> For commercial licensing, please contact the authors.",
    "translatedContent": "> 如需商业授权，请联系作者。"
  },
  {
    "row": 115,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 116,
    "rowsha": "idCvsL23+SgGxeiktrTl5Y+r1XCJFcD6eO3243OaAPY=",
    "originContent": "**📦 Third-Party Components**",
    "translatedContent": "**📦 第三方组件**"
  },
  {
    "row": 117,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 118,
    "rowsha": "WE7FE/+7lXbNs5ENH4uLy9/fzMNY1H60uSJ7lRbBD0o=",
    "originContent": "* **Stable Audio Open VAE** (by Stability AI):",
    "translatedContent": "* **Stable Audio Open VAE**（由 Stability AI 提供）："
  },
  {
    "row": 119,
    "rowsha": "n8R1JiNonohwAL0UGMf3R1xgnYRnz5fdUI6ZtkdzKnU=",
    "originContent": "  This repository includes a fine-tuned VAE from [Stable Audio Open](https://huggingface.co/stabilityai/stable-audio-open-1.0/), licensed under the [Stability AI Community License](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/./third_party/LICENSE_StabilityAI.md).",
    "translatedContent": "  本仓库包含来自 [Stable Audio Open](https://huggingface.co/stabilityai/stable-audio-open-1.0/) 的微调 VAE，遵循 [Stability AI Community License](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/./third_party/LICENSE_StabilityAI.md) 授权。"
  },
  {
    "row": 120,
    "rowsha": "z1nrjZCTFkfKVpjvRtVTCvLJ3eIRc/0lYZ6q1FAyF9Y=",
    "originContent": "  **Commercial use and redistribution require prior permission from Stability AI.**",
    "translatedContent": "  **商业使用和再分发需事先获得 Stability AI 的许可。**"
  },
  {
    "row": 121,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 122,
    "rowsha": "Rc/58q3GXX1uj9YQLKADnw6rI9fXJsB3qr7SgcFxhJQ=",
    "originContent": "* 📘 **All other code and models** are released under the Apache License 2.0.",
    "translatedContent": "* 📘 **所有其他代码和模型**均采用 Apache License 2.0 许可发布。"
  },
  {
    "row": 123,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 124,
    "rowsha": "yz+R1U7uMOU+NbK5mQX3Dxae1Un9eJCdPawt78ntjTs=",
    "originContent": "---",
    "translatedContent": "---"
  },
  {
    "row": 125,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 126,
    "rowsha": "HvkwNudYOlwL8j/t4djBVF3hUJwHWa2r5QjmSxgq3AA=",
    "originContent": "## Acknowledgements",
    "translatedContent": "## 致谢"
  },
  {
    "row": 127,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 128,
    "rowsha": "nrozD4yXZdvCdVDGRjdO303ENLy2DrpELvY0lV8DjU4=",
    "originContent": "Many thanks to:",
    "translatedContent": "特别感谢："
  },
  {
    "row": 129,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 130,
    "rowsha": "7poAa5FddcjiBYp6TtQpLbB4qN57dBa/V6Oc1d6Ak1c=",
    "originContent": "* **stable-audio-tools** (by Stability AI):",
    "translatedContent": "* **stable-audio-tools**（由 Stability AI 提供）："
  },
  {
    "row": 131,
    "rowsha": "ChUiuc0nNLek0lyZz64pXvYp23+nJyAL95/UOo1ez4U=",
    "originContent": "For providing an easy-to-use framework for audio generation, as well as the VAE module and weights.",
    "translatedContent": "为音频生成提供了易用的框架，以及 VAE 模块和权重。"
  },
  {
    "row": 132,
    "rowsha": "nn9Ut2wJSSgxPicEUDiiTuEnuQK99h2v5Ue5JFAtHN0=",
    "originContent": "* **MMAudio**:",
    "translatedContent": "* **MMAudio**："
  },
  {
    "row": 133,
    "rowsha": "3yv6rAm2+j4agcTG/gcAtQLX1Kv0n/+YvFmBsObWoYo=",
    "originContent": "  For the implementation of the MM-DiT backbone in the audio domain.",
    "translatedContent": "  在音频领域实现了 MM-DiT 主干网络。"
  },
  {
    "row": 134,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 135,
    "rowsha": "yz+R1U7uMOU+NbK5mQX3Dxae1Un9eJCdPawt78ntjTs=",
    "originContent": "---",
    "translatedContent": "---"
  },
  {
    "row": 136,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 137,
    "rowsha": "syomH5Of+YY9KSCalKtADVZFMa9lRWCIOiYIqbfDgKI=",
    "originContent": "## 📖 Citation",
    "translatedContent": "## 📖 引用"
  },
  {
    "row": 138,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 139,
    "rowsha": "o5GEZn4azbbEeVodFzyyGdWtJ79JPcZQcPI33OuhB4o=",
    "originContent": "If you find ThinkSound useful in your research or work, please cite our paper:",
    "translatedContent": "如果您在研究或工作中发现 ThinkSound 有用，请引用我们的论文："
  },
  {
    "row": 140,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 141,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 142,
    "rowsha": "yz+R1U7uMOU+NbK5mQX3Dxae1Un9eJCdPawt78ntjTs=",
    "originContent": "---",
    "translatedContent": "---"
  },
  {
    "row": 143,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 144,
    "rowsha": "V0ea1xQLKG+cGj5kHVv5f15HDd+yj0ulkcBQnvErdJc=",
    "originContent": "## 📬 Contact",
    "translatedContent": "## 📬 Contact"
  },
  {
    "row": 145,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 146,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 147,
    "rowsha": "QsDuVwX1DXlTNejKuNftx4k1x7yNHjfP9/1HS85hJng=",
    "originContent": "✨ Feel free to [open an issue](https://github.com/liuhuadai/ThinkSound/issues) or contact us via email ([liuhuadai@zju.edu.cn](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/mailto:liuhuadai@zju.edu.cn)) if you have any questions or suggestions!",
    "translatedContent": "✨ Feel free to [open an issue](https://github.com/liuhuadai/ThinkSound/issues) or contact us via email ([liuhuadai@zju.edu.cn](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/mailto:liuhuadai@zju.edu.cn)) if you have any questions or suggestions!"
  },
  {
    "row": 148,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 149,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  }
]