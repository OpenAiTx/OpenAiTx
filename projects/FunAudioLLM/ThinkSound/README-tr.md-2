{
  "id": 2,
  "origin": "## ğŸ“ TODO\n\n- â˜ Release training scripts for ThinkSound models\n- â˜ Open-source AudioCoT dataset and automated pipeline\n- â˜ Provide detailed documentation and API reference\n- â˜ Add support for additional modalities and downstream tasks\n\n---\n\n## ğŸ“„ License\n\nThis project is released under the [Apache 2.0 License](LICENSE).\n\n> **Note:**  \n> The code, models, and dataset are **for research and educational purposes only**.  \n> **Commercial use is NOT permitted.**\n>\n> For commercial licensing, please contact the authors.\n\n---\n\n## ğŸ“– Citation\n\nIf you find ThinkSound useful in your research or work, please cite our paper:\n\n```bibtex\n@misc{liu2025thinksoundchainofthoughtreasoningmultimodal,\n      title={ThinkSound: Chain-of-Thought Reasoning in Multimodal Large Language Models for Audio Generation and Editing}, \n      author={Huadai Liu and Jialei Wang and Kaicheng Luo and Wen Wang and Qian Chen and Zhou Zhao and Wei Xue},\n      year={2025},\n      eprint={2506.21448},\n      archivePrefix={arXiv},\n      primaryClass={eess.AS},\n      url={https://arxiv.org/abs/2506.21448}, \n}\n```\n\n---\n\n## ğŸ“¬ Contact\n\nâœ¨ Feel free to [open an issue](https://github.com/liuhuadai/ThinkSound/issues) or contact us via email ([liuhuadai@zju.edu.cn](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/mailto:liuhuadai@zju.edu.cn)) if you have any questions or suggestions!\n",
  "origin_sha": "NEFlwyN+fN3dUarHAXDiIoJazYSSuWRByH696fda+qA=",
  "translate": "## ğŸ“ YAPILACAKLAR\n\n- â˜ ThinkSound modelleri iÃ§in eÄŸitim betiklerini yayÄ±mla\n- â˜ AudioCoT veri setini ve otomatikleÅŸtirilmiÅŸ hattÄ± aÃ§Ä±k kaynak yap\n- â˜ AyrÄ±ntÄ±lÄ± dokÃ¼mantasyon ve API referansÄ± saÄŸla\n- â˜ Ek modallikler ve ardÄ±l gÃ¶revler iÃ§in destek ekle\n\n---\n\n## ğŸ“„ Lisans\n\nBu proje [Apache 2.0 LisansÄ±](LICENSE) altÄ±nda yayÄ±mlanmÄ±ÅŸtÄ±r.\n\n> **Not:**  \n> Kod, modeller ve veri seti **yalnÄ±zca araÅŸtÄ±rma ve eÄŸitim amaÃ§lÄ±dÄ±r**.  \n> **Ticari kullanÄ±m Ä°ZÄ°N VERÄ°LMEMEKTEDÄ°R.**\n>\n> Ticari lisanslama iÃ§in lÃ¼tfen yazarlarla iletiÅŸime geÃ§in.\n\n---\n\n## ğŸ“– AtÄ±f\n\nThinkSound'u araÅŸtÄ±rmanÄ±zda veya Ã§alÄ±ÅŸmalarÄ±nÄ±zda faydalÄ± bulursanÄ±z, lÃ¼tfen makalemizi kaynak gÃ¶sterin:\n\n```bibtex\n@misc{liu2025thinksoundchainofthoughtreasoningmultimodal,\n      title={ThinkSound: Chain-of-Thought Reasoning in Multimodal Large Language Models for Audio Generation and Editing}, \n      author={Huadai Liu and Jialei Wang and Kaicheng Luo and Wen Wang and Qian Chen and Zhou Zhao and Wei Xue},\n      year={2025},\n      eprint={2506.21448},\n      archivePrefix={arXiv},\n      primaryClass={eess.AS},\n      url={https://arxiv.org/abs/2506.21448}, \n}\n```\n\n---\n\n## ğŸ“¬ Ä°letiÅŸim\n\nâœ¨ Herhangi bir sorunuz veya Ã¶neriniz varsa [bir issue aÃ§maktan](https://github.com/liuhuadai/ThinkSound/issues) veya e-posta yoluyla bizimle iletiÅŸime geÃ§mekten ([liuhuadai@zju.edu.cn](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/mailto:liuhuadai@zju.edu.cn)) Ã§ekinmeyin!",
  "status": "ok"
}