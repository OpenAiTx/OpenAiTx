{
  "id": 2,
  "origin": "## ğŸ“ TODO\n\n- â˜ Release training scripts for ThinkSound models\n- â˜ Open-source AudioCoT dataset and automated pipeline\n- â˜ Provide detailed documentation and API reference\n- â˜ Add support for additional modalities and downstream tasks\n\n---\n\n## ğŸ“„ License\n\nThis project is released under the [Apache 2.0 License](LICENSE).\n\n> **Note:**  \n> The code, models, and dataset are **for research and educational purposes only**.  \n> **Commercial use is NOT permitted.**\n>\n> For commercial licensing, please contact the authors.\n\n---\n\n## ğŸ“– Citation\n\nIf you find ThinkSound useful in your research or work, please cite our paper:\n\n```bibtex\n@misc{liu2025thinksoundchainofthoughtreasoningmultimodal,\n      title={ThinkSound: Chain-of-Thought Reasoning in Multimodal Large Language Models for Audio Generation and Editing}, \n      author={Huadai Liu and Jialei Wang and Kaicheng Luo and Wen Wang and Qian Chen and Zhou Zhao and Wei Xue},\n      year={2025},\n      eprint={2506.21448},\n      archivePrefix={arXiv},\n      primaryClass={eess.AS},\n      url={https://arxiv.org/abs/2506.21448}, \n}\n```\n\n---\n\n## ğŸ“¬ Contact\n\nâœ¨ Feel free to [open an issue](https://github.com/liuhuadai/ThinkSound/issues) or contact us via email ([liuhuadai@zju.edu.cn](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/mailto:liuhuadai@zju.edu.cn)) if you have any questions or suggestions!\n",
  "origin_sha": "NEFlwyN+fN3dUarHAXDiIoJazYSSuWRByH696fda+qA=",
  "translate": "## ğŸ“ VIá»†C Cáº¦N LÃ€M\n\n- â˜ PhÃ¡t hÃ nh cÃ¡c script huáº¥n luyá»‡n cho cÃ¡c mÃ´ hÃ¬nh ThinkSound\n- â˜ MÃ£ nguá»“n má»Ÿ bá»™ dá»¯ liá»‡u AudioCoT vÃ  quy trÃ¬nh tá»± Ä‘á»™ng hÃ³a\n- â˜ Cung cáº¥p tÃ i liá»‡u chi tiáº¿t vÃ  tham kháº£o API\n- â˜ ThÃªm há»— trá»£ cho cÃ¡c kiá»ƒu dá»¯ liá»‡u vÃ  tÃ¡c vá»¥ háº­u ká»³ khÃ¡c\n\n---\n\n## ğŸ“„ Giáº¥y phÃ©p\n\nDá»± Ã¡n nÃ y Ä‘Æ°á»£c phÃ¡t hÃ nh theo [Giáº¥y phÃ©p Apache 2.0](LICENSE).\n\n> **LÆ°u Ã½:**  \n> MÃ£ nguá»“n, mÃ´ hÃ¬nh vÃ  bá»™ dá»¯ liá»‡u **chá»‰ dÃ nh cho má»¥c Ä‘Ã­ch nghiÃªn cá»©u vÃ  giÃ¡o dá»¥c**.  \n> **KHÃ”NG Ä‘Æ°á»£c phÃ©p sá»­ dá»¥ng cho má»¥c Ä‘Ã­ch thÆ°Æ¡ng máº¡i.**\n>\n> Äá»ƒ xin giáº¥y phÃ©p thÆ°Æ¡ng máº¡i, vui lÃ²ng liÃªn há»‡ tÃ¡c giáº£.\n\n---\n\n## ğŸ“– TrÃ­ch dáº«n\n\nNáº¿u báº¡n tháº¥y ThinkSound há»¯u Ã­ch trong nghiÃªn cá»©u hoáº·c cÃ´ng viá»‡c cá»§a mÃ¬nh, vui lÃ²ng trÃ­ch dáº«n bÃ i bÃ¡o cá»§a chÃºng tÃ´i:\n\n```bibtex\n@misc{liu2025thinksoundchainofthoughtreasoningmultimodal,\n      title={ThinkSound: Chain-of-Thought Reasoning in Multimodal Large Language Models for Audio Generation and Editing}, \n      author={Huadai Liu and Jialei Wang and Kaicheng Luo and Wen Wang and Qian Chen and Zhou Zhao and Wei Xue},\n      year={2025},\n      eprint={2506.21448},\n      archivePrefix={arXiv},\n      primaryClass={eess.AS},\n      url={https://arxiv.org/abs/2506.21448}, \n}\n```\n\n---\n\n## ğŸ“¬ LiÃªn há»‡\n\nâœ¨ HÃ£y [táº¡o issue má»›i](https://github.com/liuhuadai/ThinkSound/issues) hoáº·c liÃªn há»‡ vá»›i chÃºng tÃ´i qua email ([liuhuadai@zju.edu.cn](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/mailto:liuhuadai@zju.edu.cn)) náº¿u báº¡n cÃ³ báº¥t ká»³ cÃ¢u há»i hoáº·c gÃ³p Ã½ nÃ o!",
  "status": "ok"
}