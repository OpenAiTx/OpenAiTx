{
  "id": 2,
  "origin": "## 📝 TODO\n\n- ☐ Release training scripts for ThinkSound models\n- ☐ Open-source AudioCoT dataset and automated pipeline\n- ☐ Provide detailed documentation and API reference\n- ☐ Add support for additional modalities and downstream tasks\n\n---\n\n## 📄 License\n\nThis project is released under the [Apache 2.0 License](LICENSE).\n\n> **Note:**  \n> The code, models, and dataset are **for research and educational purposes only**.  \n> **Commercial use is NOT permitted.**\n>\n> For commercial licensing, please contact the authors.\n\n---\n\n## 📖 Citation\n\nIf you find ThinkSound useful in your research or work, please cite our paper:\n\n```bibtex\n@misc{liu2025thinksoundchainofthoughtreasoningmultimodal,\n      title={ThinkSound: Chain-of-Thought Reasoning in Multimodal Large Language Models for Audio Generation and Editing}, \n      author={Huadai Liu and Jialei Wang and Kaicheng Luo and Wen Wang and Qian Chen and Zhou Zhao and Wei Xue},\n      year={2025},\n      eprint={2506.21448},\n      archivePrefix={arXiv},\n      primaryClass={eess.AS},\n      url={https://arxiv.org/abs/2506.21448}, \n}\n```\n\n---\n\n## 📬 Contact\n\n✨ Feel free to [open an issue](https://github.com/liuhuadai/ThinkSound/issues) or contact us via email ([liuhuadai@zju.edu.cn](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/mailto:liuhuadai@zju.edu.cn)) if you have any questions or suggestions!\n",
  "origin_sha": "NEFlwyN+fN3dUarHAXDiIoJazYSSuWRByH696fda+qA=",
  "translate": "## 📝 VIỆC CẦN LÀM\n\n- ☐ Phát hành các script huấn luyện cho các mô hình ThinkSound\n- ☐ Mã nguồn mở bộ dữ liệu AudioCoT và quy trình tự động hóa\n- ☐ Cung cấp tài liệu chi tiết và tham khảo API\n- ☐ Thêm hỗ trợ cho các kiểu dữ liệu và tác vụ hậu kỳ khác\n\n---\n\n## 📄 Giấy phép\n\nDự án này được phát hành theo [Giấy phép Apache 2.0](LICENSE).\n\n> **Lưu ý:**  \n> Mã nguồn, mô hình và bộ dữ liệu **chỉ dành cho mục đích nghiên cứu và giáo dục**.  \n> **KHÔNG được phép sử dụng cho mục đích thương mại.**\n>\n> Để xin giấy phép thương mại, vui lòng liên hệ tác giả.\n\n---\n\n## 📖 Trích dẫn\n\nNếu bạn thấy ThinkSound hữu ích trong nghiên cứu hoặc công việc của mình, vui lòng trích dẫn bài báo của chúng tôi:\n\n```bibtex\n@misc{liu2025thinksoundchainofthoughtreasoningmultimodal,\n      title={ThinkSound: Chain-of-Thought Reasoning in Multimodal Large Language Models for Audio Generation and Editing}, \n      author={Huadai Liu and Jialei Wang and Kaicheng Luo and Wen Wang and Qian Chen and Zhou Zhao and Wei Xue},\n      year={2025},\n      eprint={2506.21448},\n      archivePrefix={arXiv},\n      primaryClass={eess.AS},\n      url={https://arxiv.org/abs/2506.21448}, \n}\n```\n\n---\n\n## 📬 Liên hệ\n\n✨ Hãy [tạo issue mới](https://github.com/liuhuadai/ThinkSound/issues) hoặc liên hệ với chúng tôi qua email ([liuhuadai@zju.edu.cn](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/mailto:liuhuadai@zju.edu.cn)) nếu bạn có bất kỳ câu hỏi hoặc góp ý nào!",
  "status": "ok"
}