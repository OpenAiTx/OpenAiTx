[
  {
    "row": 1,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "PyTorchã«ã‚ˆã‚‹ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«éŸ³å£°ç”ŸæˆãŠã‚ˆã³ç·¨é›†ã®å®Ÿè£…ï¼šå‹•ç”»ã€ãƒ†ã‚­ã‚¹ãƒˆã€éŸ³å£°ã‹ã‚‰éŸ³å£°ã‚’ç”Ÿæˆãƒ»ç·¨é›†å¯èƒ½ã€‚ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆMLLMï¼‰ã®æ®µéšçš„ãªæ¨è«–ã«ã‚ˆã£ã¦å¼·åŒ–ã•ã‚Œã¦ã„ã¾ã™ã€‚"
  },
  {
    "row": 2,
    "rowsha": "eexREJOMCITdo96Iwg4N4PQqu1ux/UwupfjVRj0l/L8=",
    "originContent": "PyTorch implementation for multimodal audio generation and editing: generate or edit audio from video, text, and audio, powered by step-by-step reasoning from Multimodal Large Language Models (MLLMs).",
    "translatedContent": ""
  },
  {
    "row": 3,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "![Teaser](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig1_teaser.png)"
  },
  {
    "row": 4,
    "rowsha": "+7Cx1rdpWiIOeWRA/RM6HsKf7pNA3hHsQk2Bpadt4II=",
    "originContent": "![Teaser](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig1_teaser.png)",
    "translatedContent": "---"
  },
  {
    "row": 5,
    "rowsha": "yz+R1U7uMOU+NbK5mQX3Dxae1Un9eJCdPawt78ntjTs=",
    "originContent": "---",
    "translatedContent": ""
  },
  {
    "row": 6,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "## ğŸ“° ãƒ‹ãƒ¥ãƒ¼ã‚¹"
  },
  {
    "row": 7,
    "rowsha": "0YeCyxpcm7/4RDbaM+OQoI8YfqEHQzDkpGW15VZdi1U=",
    "originContent": "## ğŸ“° News",
    "translatedContent": "- **2025.11.25** &nbsp; ğŸ”¥[ã‚ªãƒ³ãƒ©ã‚¤ãƒ³PrismAudioãƒ‡ãƒ¢](http://prismaudio-project.github.io/)å…¬é–‹ - ä»Šã™ããŠè©¦ã—ãã ã•ã„ï¼"
  },
  {
    "row": 8,
    "rowsha": "EeDKxV0PYB9iw6GxOqwnsP3C385ykbqk8PtEVoVhAcc=",
    "originContent": "- **2025.11.25** &nbsp; ğŸ”¥[Online PrismAudio Demo](http://prismaudio-project.github.io/) is live - try it now!",
    "translatedContent": "- **2025.11.25** &nbsp; ğŸ”¥[PrismAudioè«–æ–‡](https://arxiv.org/pdf/2511.18833)ãŒarXivã«å…¬é–‹ã€åˆã®å¤šæ¬¡å…ƒCoT-RLãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã«ã‚ˆã‚‹Video-to-Audioç”Ÿæˆï¼"
  },
  {
    "row": 9,
    "rowsha": "Q6c68QE34xLPSZ5xAL4zofEn/u8umRYYiH3ddCcy5vk=",
    "originContent": "- **2025.11.25** &nbsp; ğŸ”¥[PrismAudio paper](https://arxiv.org/pdf/2511.18833) released on arXiv, the first multi-dimensional CoT-RL framework for Video-to-Audio Generation!",
    "translatedContent": "- **2025.09.19** &nbsp; ğŸ‰ ThinkSoundãŒ**NeurIPS 2025æœ¬ä¼šè­°**ã«æ¡æŠã•ã‚Œã¾ã—ãŸï¼"
  },
  {
    "row": 10,
    "rowsha": "vj2hbV/6MacDcxRmFA0AtTog5xU6CHoqBFO3YMO+yJo=",
    "originContent": "- **2025.09.19** &nbsp; ğŸ‰ ThinkSound has been accepted to the **NeurIPS 2025 Main Conference**!",
    "translatedContent": "- **2025.09.01** &nbsp; AudioCoTãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹åŒ–ã•ã‚Œã€[Hugging Face](https://huggingface.co/datasets/liuhuadai/AudioCoT)ã§å…¥æ‰‹å¯èƒ½ã«ãªã‚Šã¾ã—ãŸï¼"
  },
  {
    "row": 11,
    "rowsha": "+guVQwDlJDqR1pBGMGc4FQ11nryItaEtKQ3etaCBcn0=",
    "originContent": "- **2025.09.01** &nbsp; Our AudioCoT dataset is now open-sourced and available on [Hugging Face](https://huggingface.co/datasets/liuhuadai/AudioCoT)!",
    "translatedContent": "- **2025.07.17** &nbsp; ğŸ§  ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å¯¾å¿œï¼šãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãŠã‚ˆã³ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚³ãƒ¼ãƒ‰ã‚’å…¬é–‹ã€ç‹¬è‡ªãƒ‡ãƒ¼ã‚¿ã§ThinkSoundã‚’ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºãƒ»æ‹¡å¼µã™ã‚‹ãŸã‚ã®æ˜ç¢ºãªä½¿ç”¨æ–¹æ³•ã‚‚æä¾›ã€‚"
  },
  {
    "row": 12,
    "rowsha": "4Jq9g83O8cYV4fVKsetfTpI+JrSepLrjK6J7Xg9tSqo=",
    "originContent": "- **2025.07.17** &nbsp; ğŸ§  Finetuning enabled: training and finetuning code is now publicly available, along with clear usage instructions to help you customize and extend ThinkSound with your own data.",
    "translatedContent": "- **2025.07.15** &nbsp; ğŸ“¦ ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãƒ»åˆ©ç”¨ãŒç°¡å˜ã«ï¼šPyPIä¾å­˜é–¢ä¿‚ã§ã‚¯ãƒ­ã‚¹ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ç’°å¢ƒæ§‹ç¯‰ãŒå®¹æ˜“ã«ã€‚Windowsç”¨`.bat`ã‚¹ã‚¯ãƒªãƒ—ãƒˆã§ç’°å¢ƒä½œæˆãƒ»ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œã‚’è‡ªå‹•åŒ–ã€‚"
  },
  {
    "row": 13,
    "rowsha": "Ae5w+cTrCd9E8qidC11IWJAgg+LuOgUxA4czDPNG/G0=",
    "originContent": "- **2025.07.15** &nbsp; ğŸ“¦ Simplified installation and usability: dependencies on PyPI for easy cross-platform setup; Windows `.bat` scripts automate environment creation and script running.",
    "translatedContent": "- **2025.07.08** &nbsp;Â  ğŸ”§ å¤§å¹…ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆï¼šãƒ¢ãƒ‡ãƒ«ã®è»½é‡åŒ–ã€ãƒ¡ãƒ¢ãƒªãƒ»GPUä½¿ç”¨æœ€é©åŒ–ã«ã‚ˆã‚Šã€å¤§è¦æ¨¡ãªé«˜ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆéŸ³å£°ç”Ÿæˆã‚’å®Ÿç¾ï¼"
  },
  {
    "row": 14,
    "rowsha": "nYxNhwgSqjwYLuWsfHAqP5sx2PnzYwoFrwcf9U+Fdss=",
    "originContent": "- **2025.07.08** &nbsp;Â  ğŸ”§ Major update: model lightweighted and optimized memory and GPU usage, now supports high-throughput audio generation at scale!",
    "translatedContent": "- **2025.07.01** &nbsp; [Hugging Face Spaces](https://huggingface.co/spaces/FunAudioLLM/ThinkSound)ãŠã‚ˆã³[ModelScope](https://modelscope.cn/studios/iic/ThinkSound)ã§ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ãƒ‡ãƒ¢å…¬é–‹ã€ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ä½“é¨“ãŒå¯èƒ½ï¼"
  },
  {
    "row": 15,
    "rowsha": "RPL6cU3/Jgu90ib4PkeN5Q/ALrnjq9hK0ZUCranb/PA=",
    "originContent": "- **2025.07.01** &nbsp; Online demo on [Hugging Face Spaces](https://huggingface.co/spaces/FunAudioLLM/ThinkSound) and [ModelScope](https://modelscope.cn/studios/iic/ThinkSound) for interactive experience!",
    "translatedContent": "- **2025.07.01** &nbsp; æ¨è«–ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¨Webã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹å…¬é–‹ï¼› "
  },
  {
    "row": 16,
    "rowsha": "0PEL3eOyUmX2U56FPEPvYfaltZ/P/wbH0uO6GcLPlUE=",
    "originContent": "- **2025.07.01** &nbsp; Released inference scripts and web interface; ",
    "translatedContent": "- **2025.06** &nbsp; [ThinkSoundè«–æ–‡](https://arxiv.org/pdf/2506.21448)ãŒarXivã«å…¬é–‹ï¼"
  },
  {
    "row": 17,
    "rowsha": "XNdJ/DN741rXoJAruiGiRueQILXIUHRXzBlp+HVWM88=",
    "originContent": "- **2025.06** &nbsp; [ThinkSound paper](https://arxiv.org/pdf/2506.21448) released on arXiv!",
    "translatedContent": "- **2025.06** &nbsp; [ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ãƒ‡ãƒ¢](http://thinksound-project.github.io/)å…¬é–‹ - ä»Šã™ããŠè©¦ã—ãã ã•ã„ï¼"
  },
  {
    "row": 18,
    "rowsha": "W45oflUmoUAksoDc1WjcR2hErqh9UIi738PFVipiDg0=",
    "originContent": "- **2025.06** &nbsp; [Online Demo](http://thinksound-project.github.io/) is live - try it now!",
    "translatedContent": ""
  },
  {
    "row": 19,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "---"
  },
  {
    "row": 20,
    "rowsha": "yz+R1U7uMOU+NbK5mQX3Dxae1Un9eJCdPawt78ntjTs=",
    "originContent": "---",
    "translatedContent": ""
  },
  {
    "row": 21,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 22,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "## ğŸš€ ç‰¹å¾´"
  },
  {
    "row": 23,
    "rowsha": "f4oQIFLM2EJQxJ65F4oMEA7yWOIqs0eBtiIvGxI+GgI=",
    "originContent": "## ğŸš€ Features",
    "translatedContent": ""
  },
  {
    "row": 24,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "- **Any2Audio**: ä»»æ„ã®ãƒ¢ãƒ€ãƒªãƒ†ã‚£ï¼ˆå‹•ç”»ã€ãƒ†ã‚­ã‚¹ãƒˆã€éŸ³å£°ã¾ãŸã¯çµ„ã¿åˆã‚ã›ï¼‰ã‹ã‚‰éŸ³å£°ã‚’ç”Ÿæˆã€‚"
  },
  {
    "row": 25,
    "rowsha": "8TbVluJJPR3C0fX41HklpO/vH9/k/rHC+jlvmHHfzQU=",
    "originContent": "- **Any2Audio**: Generate audio from arbitrary modalities â€” video, text, audio, or their combinations.",
    "translatedContent": "- **Video-to-Audio SOTA**: è¤‡æ•°ã®V2Aãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§æœ€å…ˆç«¯ã®çµæœã‚’é”æˆã€‚"
  },
  {
    "row": 26,
    "rowsha": "+Jf5LrYz+d1ShYCuQe8UF9taEJUpuGhDk6fAlYK3Kj4=",
    "originContent": "- **Video-to-Audio SOTA**: Achieves state-of-the-art results on multiple V2A benchmarks.",
    "translatedContent": "- **CoTé§†å‹•æ¨è«–**: MLLMã‚’åˆ©ç”¨ã—ãŸChain-of-Thoughtæ¨è«–ã«ã‚ˆã‚‹æ§‹æˆçš„ã‹ã¤åˆ¶å¾¡å¯èƒ½ãªéŸ³å£°ç”Ÿæˆã€‚"
  },
  {
    "row": 27,
    "rowsha": "mU7qXkjW1YifKoYXJedYo9l64NsTBaiXsgoGFRF/g+E=",
    "originContent": "- **CoT-Driven Reasoning**: Chain-of-Thought reasoning for compositional and controllable audio generation via MLLMs.",
    "translatedContent": "- **ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆä¸­å¿ƒç·¨é›†**: è¦–è¦šã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ã‚¯ãƒªãƒƒã‚¯ã‚„ãƒ†ã‚­ã‚¹ãƒˆæŒ‡ç¤ºã§ç‰¹å®šã®éŸ³ã‚¤ãƒ™ãƒ³ãƒˆã‚’ç·¨é›†ãƒ»æ”¹è‰¯ã€‚"
  },
  {
    "row": 28,
    "rowsha": "RComOCBBrXsZf9RHmLginqKTh9eI/bKUZuUunQEmD5M=",
    "originContent": "- **Interactive Object-centric Editing**: Refine or edit specific sound events by clicking on visual objects or using text instructions.",
    "translatedContent": "- **çµ±ä¸€ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯**: ã²ã¨ã¤ã®åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã§ç”Ÿæˆã€ç·¨é›†ã€ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’ã‚µãƒãƒ¼ãƒˆã€‚"
  },
  {
    "row": 29,
    "rowsha": "C3sf87sy73G/XZft+TDo5NjXo5XcrtJB805ayHRAXoQ=",
    "originContent": "- **Unified Framework**: One foundation model supports generation, editing, and interactive workflow.",
    "translatedContent": ""
  },
  {
    "row": 30,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "---"
  },
  {
    "row": 31,
    "rowsha": "yz+R1U7uMOU+NbK5mQX3Dxae1Un9eJCdPawt78ntjTs=",
    "originContent": "---",
    "translatedContent": ""
  },
  {
    "row": 32,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "## âœ¨ æ‰‹æ³•æ¦‚è¦"
  },
  {
    "row": 33,
    "rowsha": "gjgLOIAU2x83BBZdLUdgEB+F64ajt/QuLYQXM1hDBLE=",
    "originContent": "## âœ¨ Method Overview",
    "translatedContent": ""
  },
  {
    "row": 34,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "ThinkSoundã¯éŸ³å£°ç”Ÿæˆã¨ç·¨é›†ã‚’ã€MLLMãƒ™ãƒ¼ã‚¹ã®Chain-of-Thoughtï¼ˆCoTï¼‰æ¨è«–ã§å°ã‹ã‚Œã‚‹3ã¤ã®ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªæ®µéšã«åˆ†è§£ã—ã¾ã™ï¼š"
  },
  {
    "row": 35,
    "rowsha": "v5//GqG/smYIGoUpN+12k+9/3GWH3GdYD+jLqScb7AM=",
    "originContent": "ThinkSound decomposes audio generation and editing into three interactive stages, all guided by MLLM-based Chain-of-Thought (CoT) reasoning:",
    "translatedContent": ""
  },
  {
    "row": 36,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "1. **ãƒ•ã‚©ãƒ¼ãƒªãƒ¼ç”Ÿæˆ:** å‹•ç”»ã‹ã‚‰æ„å‘³çš„ãƒ»æ™‚é–“çš„ã«æ•´åˆã—ãŸåŸºç¤çš„ãªã‚µã‚¦ãƒ³ãƒ‰ã‚¹ã‚±ãƒ¼ãƒ—ã‚’ç”Ÿæˆã€‚"
  },
  {
    "row": 37,
    "rowsha": "vTObEWb7f5gCU681X3dTkwqhsaSW89TLw3GgMJ5I3bo=",
    "originContent": "1. **Foley Generation:** Generate foundational, semantically and temporally aligned soundscapes from video.",
    "translatedContent": "2. **ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆä¸­å¿ƒã®æ”¹è‰¯:** å‹•ç”»å†…ã®ã‚¯ãƒªãƒƒã‚¯ã‚„é ˜åŸŸæŒ‡å®šã§ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼æŒ‡å®šã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®éŸ³ã‚’è¿½åŠ ãƒ»æ”¹è‰¯ã€‚"
  },
  {
    "row": 38,
    "rowsha": "LTBpIQQHtEkNF8StAa+ZEDASGmRhmHIKDQOdZ4ExJWM=",
    "originContent": "2. **Object-Centric Refinement:** Refine or add sounds for user-specified objects via clicks or regions in the video.",
    "translatedContent": "3. **ã‚¿ãƒ¼ã‚²ãƒƒãƒˆéŸ³å£°ç·¨é›†:** é«˜ãƒ¬ãƒ™ãƒ«ãªè‡ªç„¶è¨€èªæŒ‡ç¤ºã§ç”Ÿæˆæ¸ˆã¿éŸ³å£°ã‚’ä¿®æ­£ã€‚"
  },
  {
    "row": 39,
    "rowsha": "8wrAo7X7dPC6Sgpfrlq2ziv/Wg/3+JnlFYvO+RMxADQ=",
    "originContent": "3. **Targeted Audio Editing:** Modify generated audio using high-level natural language instructions.",
    "translatedContent": ""
  },
  {
    "row": 40,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 41,
    "rowsha": "4UKlvFW3Xb0bSAVjcBNeekH/MMiYS0XDg9w4mCuPy/Q=",
    "originContent": "![ThinkSound Overview](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig3_model.png)",
    "translatedContent": "![ThinkSound æ¦‚è¦](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig3_model.png)"
  },
  {
    "row": 42,
    "rowsha": "GaujeIM3x7+YcFy07LNNyITlujhkgpgeIaOiKHJkYnE=",
    "originContent": "<!-- A large-scale CoT-annotated dataset (**AudioCoT**) is used to train both the reasoning module and the unified audio foundation model.",
    "translatedContent": "<!-- å¤§è¦æ¨¡ãªCoTã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆ**AudioCoT**ï¼‰ã‚’ä½¿ç”¨ã—ã¦ã€æ¨è«–ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¨çµ±åˆéŸ³å£°åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã®ä¸¡æ–¹ã‚’è¨“ç·´ã—ã¾ã™ã€‚"
  },
  {
    "row": 43,
    "rowsha": "qYOXaaTiYkoaPFcpTXE5xdSqqiW3ebi//EW/RfSXd9g=",
    "originContent": "![AudioCoT Pipeline](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig2_dataset.png) -->",
    "translatedContent": "![AudioCoT ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig2_dataset.png) -->"
  },
  {
    "row": 44,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 45,
    "rowsha": "yz+R1U7uMOU+NbK5mQX3Dxae1Un9eJCdPawt78ntjTs=",
    "originContent": "---",
    "translatedContent": "---"
  },
  {
    "row": 46,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 47,
    "rowsha": "PrY/jc4yAHdS+Sr+s+Yhab477/BDp3GAzMJ8+WyumyI=",
    "originContent": "## âš¡ Quick Start",
    "translatedContent": "## âš¡ ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ"
  },
  {
    "row": 48,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 49,
    "rowsha": "mD63DGEpdc7FlccTEps0KPAiwsJpO/C3yjV+SKIi/vE=",
    "originContent": "**Environment Preparation:**",
    "translatedContent": "**ç’°å¢ƒæº–å‚™ï¼š**"
  },
  {
    "row": 50,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 51,
    "rowsha": "yz+R1U7uMOU+NbK5mQX3Dxae1Un9eJCdPawt78ntjTs=",
    "originContent": "---",
    "translatedContent": "---"
  },
  {
    "row": 52,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 53,
    "rowsha": "V0ea1xQLKG+cGj5kHVv5f15HDd+yj0ulkcBQnvErdJc=",
    "originContent": "## ğŸ“¬ Contact",
    "translatedContent": "## ğŸ“¬ Contact"
  },
  {
    "row": 54,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 55,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 56,
    "rowsha": "QsDuVwX1DXlTNejKuNftx4k1x7yNHjfP9/1HS85hJng=",
    "originContent": "âœ¨ Feel free to [open an issue](https://github.com/liuhuadai/ThinkSound/issues) or contact us via email ([liuhuadai@zju.edu.cn](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/mailto:liuhuadai@zju.edu.cn)) if you have any questions or suggestions!",
    "translatedContent": "âœ¨ Feel free to [open an issue](https://github.com/liuhuadai/ThinkSound/issues) or contact us via email ([liuhuadai@zju.edu.cn](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/mailto:liuhuadai@zju.edu.cn)) if you have any questions or suggestions!"
  },
  {
    "row": 57,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 58,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 59,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  }
]