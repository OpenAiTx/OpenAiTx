{
  "id": 1,
  "origin": "# üé∂ ThinkSound\n\n<p align=\"center\">\n  If you find this project useful, a star ‚≠ê on GitHub would be greatly appreciated!\n</p>\n\n<p align=\"center\">\n  <a href=\"https://arxiv.org/pdf/2506.21448\">\n    <img src=\"https://img.shields.io/badge/arXiv-2506.21448-b31b1b.svg\" alt=\"arXiv\"/>\n  </a>\n  &nbsp;\n  <a href=\"https://thinksound-project.github.io/\">\n    <img src=\"https://img.shields.io/badge/Online%20Demo-üåê-blue\" alt=\"Online Demo\"/>\n  </a>\n  &nbsp;\n  <a href=\"https://huggingface.co/spaces/FunAudioLLM/ThinkSound\">\n    <img src=\"https://img.shields.io/badge/HuggingFace-Spaces-orange?logo=huggingface\" alt=\"Hugging Face\"/>\n  </a>\n  &nbsp;\n  <a href=\"https://modelscope.cn/studios/iic/ThinkSound\">\n    <img src=\"https://img.shields.io/badge/ModelScope-Âú®Á∫ø‰ΩìÈ™å-green\" alt=\"ModelScope\"/>\n  </a>\n</p>\n\n---\n\n**ThinkSound** is a unified Any2Audio generation framework with flow matching guided by Chain-of-Thought (CoT) reasoning.\n\nPyTorch implementation for multimodal audio generation and editing: generate or edit audio from video, text, and audio, powered by step-by-step reasoning from Multimodal Large Language Models (MLLMs).\n\n![Teaser](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig1_teaser.png)\n---\n\n## üì∞ News\n- **2025.07** &nbsp; üî•Online demo on [Hugging Face Spaces](https://huggingface.co/spaces/FunAudioLLM/ThinkSound) and [ModelScope](https://modelscope.cn/studios/iic/ThinkSound) for interactive experience!\n- **2025.07** &nbsp; üî•Released inference scripts and web interface; \n- **2025.06** &nbsp; üî•[ThinkSound paper](https://arxiv.org/pdf/2506.21448) released on arXiv!\n- **2025.06** &nbsp; üî•[Online Demo](http://thinksound-project.github.io/) is live - try it now!\n\n---\n\n## üöÄ Features\n\n- **Any2Audio**: Generate audio from arbitrary modalities ‚Äî video, text, audio, or their combinations.\n- **Video-to-Audio SOTA**: Achieves state-of-the-art results on multiple V2A benchmarks.\n- **CoT-Driven Reasoning**: Chain-of-Thought reasoning for compositional and controllable audio generation via MLLMs.\n- **Interactive Object-centric Editing**: Refine or edit specific sound events by clicking on visual objects or using text instructions.\n- **Unified Framework**: One foundation model supports generation, editing, and interactive workflow.\n\n---\n\n## ‚ú® Method Overview\n\nThinkSound decomposes audio generation and editing into three interactive stages, all guided by MLLM-based Chain-of-Thought (CoT) reasoning:\n\n1. **Foley Generation:** Generate foundational, semantically and temporally aligned soundscapes from video.\n2. **Object-Centric Refinement:** Refine or add sounds for user-specified objects via clicks or regions in the video.\n3. **Targeted Audio Editing:** Modify generated audio using high-level natural language instructions.\n\n![ThinkSound Overview](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig3_model.png)\n<!-- A large-scale CoT-annotated dataset (**AudioCoT**) is used to train both the reasoning module and the unified audio foundation model.\n![AudioCoT Pipeline](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig2_dataset.png) -->\n\n---\n\n## ‚ö° Quick Start\n\n**Environment Preparation:**\n```bash\ngit clone https://github.com/liuhuadai/ThinkSound.git\ncd ThinkSound\npip install -r requirements.txt\nconda install -y -c conda-forge 'ffmpeg<7'\n# Download pretrained weights https://huggingface.co/liuhuadai/ThinkSound to Directory ckpts/\n# model weights can be also downloaded from https://www.modelscope.cn/models/iic/ThinkSound\ngit lfs install\ngit clone https://huggingface.co/liuhuadai/ThinkSound ckpts\n```\n\n**Make it executable**\n```bash\nchmod +x scripts/demo.sh\n```\n\n**Run the script**\n```bash\n./scripts/demo.sh <video_path> <caption> <CoT description>\n```\n\n\n### Web Interface Usage\n\nFor an interactive experience, launch the Gradio web interface:\n\n```bash\npython app.py\n```\n\n---\n",
  "origin_sha": "vYi4X/38TyDFihDOfSBGZIgKnu2bd0a73Iz5+m+7pd0=",
  "translate": "# üé∂ ThinkSound\n\n<p align=\"center\">\n  –ï—Å–ª–∏ —ç—Ç–æ—Ç –ø—Ä–æ–µ–∫—Ç –æ–∫–∞–∑–∞–ª—Å—è –¥–ª—è –≤–∞—Å –ø–æ–ª–µ–∑–Ω—ã–º, –±—É–¥—É –ø—Ä–∏–∑–Ω–∞—Ç–µ–ª–µ–Ω –∑–∞ –∑–≤–µ–∑–¥—É ‚≠ê –Ω–∞ GitHub!\n</p>\n\n<p align=\"center\">\n  <a href=\"https://arxiv.org/pdf/2506.21448\">\n    <img src=\"https://img.shields.io/badge/arXiv-2506.21448-b31b1b.svg\" alt=\"arXiv\"/>\n  </a>\n  &nbsp;\n  <a href=\"https://thinksound-project.github.io/\">\n    <img src=\"https://img.shields.io/badge/Online%20Demo-üåê-blue\" alt=\"Online Demo\"/>\n  </a>\n  &nbsp;\n  <a href=\"https://huggingface.co/spaces/FunAudioLLM/ThinkSound\">\n    <img src=\"https://img.shields.io/badge/HuggingFace-Spaces-orange?logo=huggingface\" alt=\"Hugging Face\"/>\n  </a>\n  &nbsp;\n  <a href=\"https://modelscope.cn/studios/iic/ThinkSound\">\n    <img src=\"https://img.shields.io/badge/ModelScope-Âú®Á∫ø‰ΩìÈ™å-green\" alt=\"ModelScope\"/>\n  </a>\n</p>\n\n---\n\n**ThinkSound** ‚Äî —ç—Ç–æ —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ Any2Audio —Å —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–∏–µ–º –ø–æ—Ç–æ–∫–æ–≤, —É–ø—Ä–∞–≤–ª—è–µ–º–∞—è —Ü–µ–ø–æ—á–∫–æ–π —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π (Chain-of-Thought, CoT).\n\n–†–µ–∞–ª–∏–∑–∞—Ü–∏—è –Ω–∞ PyTorch –¥–ª—è –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∞—É–¥–∏–æ: —Å–æ–∑–¥–∞–Ω–∏–µ –∏–ª–∏ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∞—É–¥–∏–æ –ø–æ –≤–∏–¥–µ–æ, —Ç–µ–∫—Å—Ç—É –∏ –∞—É–¥–∏–æ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –ø–æ—à–∞–≥–æ–≤–æ–≥–æ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (MLLMs).\n\n![Teaser](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig1_teaser.png)\n---\n\n## üì∞ –ù–æ–≤–æ—Å—Ç–∏\n- **2025.07** &nbsp; üî•–û–Ω–ª–∞–π–Ω-–¥–µ–º–æ –Ω–∞ [Hugging Face Spaces](https://huggingface.co/spaces/FunAudioLLM/ThinkSound) –∏ [ModelScope](https://modelscope.cn/studios/iic/ThinkSound) –¥–ª—è –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–≥–æ –æ–ø—ã—Ç–∞!\n- **2025.07** &nbsp; üî•–í—ã–ø—É—â–µ–Ω—ã —Å–∫—Ä–∏–ø—Ç—ã –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ –∏ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å;\n- **2025.06** &nbsp; üî•[–°—Ç–∞—Ç—å—è –æ ThinkSound](https://arxiv.org/pdf/2506.21448) –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–∞ –Ω–∞ arXiv!\n- **2025.06** &nbsp; üî•[–û–Ω–ª–∞–π–Ω-–¥–µ–º–æ](http://thinksound-project.github.io/) –¥–æ—Å—Ç—É–ø–Ω–æ ‚Äî –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –ø—Ä—è–º–æ —Å–µ–π—á–∞—Å!\n\n---\n\n## üöÄ –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏\n\n- **Any2Audio**: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∞—É–¥–∏–æ –∏–∑ –ª—é–±—ã—Ö –º–æ–¥–∞–ª—å–Ω–æ—Å—Ç–µ–π ‚Äî –≤–∏–¥–µ–æ, —Ç–µ–∫—Å—Ç–∞, –∞—É–¥–∏–æ –∏–ª–∏ –∏—Ö –∫–æ–º–±–∏–Ω–∞—Ü–∏–π.\n- **Video-to-Audio SOTA**: –î–æ—Å—Ç–∏–≥–∞–µ—Ç –ø–µ—Ä–µ–¥–æ–≤—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –Ω–∞ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –±–µ–Ω—á–º–∞—Ä–∫–∞—Ö V2A.\n- **CoT-—É–ø—Ä–∞–≤–ª—è–µ–º–æ–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ**: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∞—É–¥–∏–æ —Å —Ü–µ–ø–æ—á–∫–æ–π —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π –¥–ª—è –∫–æ–º–ø–æ–∑–∏—Ü–∏–æ–Ω–Ω–æ–≥–æ –∏ —É–ø—Ä–∞–≤–ª—è–µ–º–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞ –Ω–∞ –±–∞–∑–µ MLLM.\n- **–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–µ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–±—ä–µ–∫—Ç–æ–≤**: –£–ª—É—á—à–∞–π—Ç–µ –∏–ª–∏ —Ä–µ–¥–∞–∫—Ç–∏—Ä—É–π—Ç–µ –æ—Ç–¥–µ–ª—å–Ω—ã–µ –∑–≤—É–∫–æ–≤—ã–µ —Å–æ–±—ã—Ç–∏—è, –∫–ª–∏–∫–∞—è –ø–æ –≤–∏–∑—É–∞–ª—å–Ω—ã–º –æ–±—ä–µ–∫—Ç–∞–º –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É—è —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏.\n- **–£–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ñ—Ä–µ–π–º–≤–æ—Ä–∫**: –û–¥–Ω–∞ –±–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏—é, —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—É—é —Ä–∞–±–æ—Ç—É.\n\n---\n\n## ‚ú® –û–±–∑–æ—Ä –º–µ—Ç–æ–¥–∞\n\nThinkSound —Ä–∞–∑–¥–µ–ª—è–µ—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –∏ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∞—É–¥–∏–æ –Ω–∞ —Ç—Ä–∏ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–µ —Å—Ç–∞–¥–∏–∏, –≤—Å–µ –æ–Ω–∏ —É–ø—Ä–∞–≤–ª—è—é—Ç—Å—è —Ü–µ–ø–æ—á–∫–æ–π —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ MLLM (CoT):\n\n1. **–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ñ–æ–ª–∏**: –°–æ–∑–¥–∞–Ω–∏–µ –±–∞–∑–æ–≤—ã—Ö, —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏ –∏ –≤—Ä–µ–º–µ–Ω–Ω–æ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω—ã—Ö –∑–≤—É–∫–æ–≤—ã—Ö –ª–∞–Ω–¥—à–∞—Ñ—Ç–æ–≤ –ø–æ –≤–∏–¥–µ–æ.\n2. **–û–±—ä–µ–∫—Ç–Ω–æ-–æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –¥–æ—Ä–∞–±–æ—Ç–∫–∞**: –£—Ç–æ—á–Ω–µ–Ω–∏–µ –∏–ª–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –∑–≤—É–∫–æ–≤ –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º –æ–±—ä–µ–∫—Ç–æ–≤ —á–µ—Ä–µ–∑ –∫–ª–∏–∫–∏ –∏–ª–∏ –≤—ã–¥–µ–ª–µ–Ω–∏–µ –æ–±–ª–∞—Å—Ç–µ–π –Ω–∞ –≤–∏–¥–µ–æ.\n3. **–¢–∞—Ä–≥–µ—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∞—É–¥–∏–æ—Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ**: –ú–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏—è —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∞—É–¥–∏–æ —Å –ø–æ–º–æ—â—å—é –≤—ã—Å–æ–∫–æ—É—Ä–æ–≤–Ω–µ–≤—ã—Ö –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π –Ω–∞ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–º —è–∑—ã–∫–µ.\n\n![ThinkSound Overview](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig3_model.png)\n<!-- –î–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥—É–ª—è —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è –∏ —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –±–∞–∑–æ–≤–æ–π –∞—É–¥–∏–æ–º–æ–¥–µ–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫—Ä—É–ø–Ω–æ–º–∞—Å—à—Ç–∞–±–Ω—ã–π CoT-–∞–Ω–Ω–æ—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç (**AudioCoT**).\n![AudioCoT Pipeline](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig2_dataset.png) -->\n\n---\n\n## ‚ö° –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç\n\n**–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Å—Ä–µ–¥—ã:**\n```bash\ngit clone https://github.com/liuhuadai/ThinkSound.git\ncd ThinkSound\npip install -r requirements.txt\nconda install -y -c conda-forge 'ffmpeg<7'\n# –°–∫–∞—á–∞–π—Ç–µ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–µ –≤–µ—Å–∞ https://huggingface.co/liuhuadai/ThinkSound –≤ –ø–∞–ø–∫—É ckpts/\n# –≤–µ—Å–∞ –º–æ–¥–µ–ª–∏ —Ç–∞–∫–∂–µ –º–æ–∂–Ω–æ —Å–∫–∞—á–∞—Ç—å —Å https://www.modelscope.cn/models/iic/ThinkSound\ngit lfs install\ngit clone https://huggingface.co/liuhuadai/ThinkSound ckpts\n```\n\n**–°–¥–µ–ª–∞–π—Ç–µ —Ñ–∞–π–ª –∏—Å–ø–æ–ª–Ω—è–µ–º—ã–º**\n```bash\nchmod +x scripts/demo.sh\n```\n\n**–ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å–∫—Ä–∏–ø—Ç**\n```bash\n./scripts/demo.sh <video_path> <caption> <CoT description>\n```\n\n\n### –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞\n\n–î–ª—è –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–π —Ä–∞–±–æ—Ç—ã –∑–∞–ø—É—Å—Ç–∏—Ç–µ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å Gradio:\n\n```bash\npython app.py\n```\n\n---",
  "status": "ok"
}