{
  "id": 1,
  "origin": "# ğŸ¶ ThinkSound\n\n<p align=\"center\">\n  If you find this project useful, a star â­ on GitHub would be greatly appreciated!\n</p>\n\n<p align=\"center\">\n  <a href=\"https://arxiv.org/pdf/2506.21448\">\n    <img src=\"https://img.shields.io/badge/arXiv-2506.21448-b31b1b.svg\" alt=\"arXiv\"/>\n  </a>\n  &nbsp;\n  <a href=\"https://thinksound-project.github.io/\">\n    <img src=\"https://img.shields.io/badge/Online%20Demo-ğŸŒ-blue\" alt=\"Online Demo\"/>\n  </a>\n  &nbsp;\n  <a href=\"https://huggingface.co/spaces/FunAudioLLM/ThinkSound\">\n    <img src=\"https://img.shields.io/badge/HuggingFace-Spaces-orange?logo=huggingface\" alt=\"Hugging Face\"/>\n  </a>\n  &nbsp;\n  <a href=\"https://modelscope.cn/studios/iic/ThinkSound\">\n    <img src=\"https://img.shields.io/badge/ModelScope-åœ¨çº¿ä½“éªŒ-green\" alt=\"ModelScope\"/>\n  </a>\n</p>\n\n---\n\n**ThinkSound** is a unified Any2Audio generation framework with flow matching guided by Chain-of-Thought (CoT) reasoning.\n\nPyTorch implementation for multimodal audio generation and editing: generate or edit audio from video, text, and audio, powered by step-by-step reasoning from Multimodal Large Language Models (MLLMs).\n\n![Teaser](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig1_teaser.png)\n---\n\n## ğŸ“° News\n- **2025.07** &nbsp; ğŸ”¥Online demo on [Hugging Face Spaces](https://huggingface.co/spaces/FunAudioLLM/ThinkSound) and [ModelScope](https://modelscope.cn/studios/iic/ThinkSound) for interactive experience!\n- **2025.07** &nbsp; ğŸ”¥Released inference scripts and web interface; \n- **2025.06** &nbsp; ğŸ”¥[ThinkSound paper](https://arxiv.org/pdf/2506.21448) released on arXiv!\n- **2025.06** &nbsp; ğŸ”¥[Online Demo](http://thinksound-project.github.io/) is live - try it now!\n\n---\n\n## ğŸš€ Features\n\n- **Any2Audio**: Generate audio from arbitrary modalities â€” video, text, audio, or their combinations.\n- **Video-to-Audio SOTA**: Achieves state-of-the-art results on multiple V2A benchmarks.\n- **CoT-Driven Reasoning**: Chain-of-Thought reasoning for compositional and controllable audio generation via MLLMs.\n- **Interactive Object-centric Editing**: Refine or edit specific sound events by clicking on visual objects or using text instructions.\n- **Unified Framework**: One foundation model supports generation, editing, and interactive workflow.\n\n---\n\n## âœ¨ Method Overview\n\nThinkSound decomposes audio generation and editing into three interactive stages, all guided by MLLM-based Chain-of-Thought (CoT) reasoning:\n\n1. **Foley Generation:** Generate foundational, semantically and temporally aligned soundscapes from video.\n2. **Object-Centric Refinement:** Refine or add sounds for user-specified objects via clicks or regions in the video.\n3. **Targeted Audio Editing:** Modify generated audio using high-level natural language instructions.\n\n![ThinkSound Overview](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig3_model.png)\n<!-- A large-scale CoT-annotated dataset (**AudioCoT**) is used to train both the reasoning module and the unified audio foundation model.\n![AudioCoT Pipeline](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig2_dataset.png) -->\n\n---\n\n## âš¡ Quick Start\n\n**Environment Preparation:**\n```bash\ngit clone https://github.com/liuhuadai/ThinkSound.git\ncd ThinkSound\npip install -r requirements.txt\nconda install -y -c conda-forge 'ffmpeg<7'\n# Download pretrained weights https://huggingface.co/liuhuadai/ThinkSound to Directory ckpts/\n# model weights can be also downloaded from https://www.modelscope.cn/models/iic/ThinkSound\ngit lfs install\ngit clone https://huggingface.co/liuhuadai/ThinkSound ckpts\n```\n\n**Make it executable**\n```bash\nchmod +x scripts/demo.sh\n```\n\n**Run the script**\n```bash\n./scripts/demo.sh <video_path> <caption> <CoT description>\n```\n\n\n### Web Interface Usage\n\nFor an interactive experience, launch the Gradio web interface:\n\n```bash\npython app.py\n```\n\n---\n",
  "origin_sha": "vYi4X/38TyDFihDOfSBGZIgKnu2bd0a73Iz5+m+7pd0=",
  "translate": "# ğŸ¶ ThinkSound\n\n<p align=\"center\">\n  å¦‚æœæ‚¨è§‰å¾—è¿™ä¸ªé¡¹ç›®æœ‰ç”¨ï¼Œéå¸¸æ„Ÿè°¢åœ¨ GitHub ä¸Šç‚¹ä¸ªæ˜Ÿ â­ï¼\n</p>\n\n<p align=\"center\">\n  <a href=\"https://arxiv.org/pdf/2506.21448\">\n    <img src=\"https://img.shields.io/badge/arXiv-2506.21448-b31b1b.svg\" alt=\"arXiv\"/>\n  </a>\n  &nbsp;\n  <a href=\"https://thinksound-project.github.io/\">\n    <img src=\"https://img.shields.io/badge/Online%20Demo-ğŸŒ-blue\" alt=\"Online Demo\"/>\n  </a>\n  &nbsp;\n  <a href=\"https://huggingface.co/spaces/FunAudioLLM/ThinkSound\">\n    <img src=\"https://img.shields.io/badge/HuggingFace-Spaces-orange?logo=huggingface\" alt=\"Hugging Face\"/>\n  </a>\n  &nbsp;\n  <a href=\"https://modelscope.cn/studios/iic/ThinkSound\">\n    <img src=\"https://img.shields.io/badge/ModelScope-åœ¨çº¿ä½“éªŒ-green\" alt=\"ModelScope\"/>\n  </a>\n</p>\n\n---\n\n**ThinkSound** æ˜¯ä¸€ä¸ªç»Ÿä¸€çš„ Any2Audio ç”Ÿæˆæ¡†æ¶ï¼Œé€šè¿‡é“¾å¼æ€ç»´ï¼ˆChain-of-Thought, CoTï¼‰æ¨ç†è¿›è¡ŒæµåŒ¹é…æŒ‡å¯¼ã€‚\n\nåŸºäº PyTorch çš„å¤šæ¨¡æ€éŸ³é¢‘ç”Ÿæˆä¸ç¼–è¾‘å®ç°ï¼šå¯åŸºäºè§†é¢‘ã€æ–‡æœ¬ã€éŸ³é¢‘åŠå…¶ç»„åˆï¼Œç”Ÿæˆæˆ–ç¼–è¾‘éŸ³é¢‘ï¼Œåº•å±‚ç”±å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰é€æ­¥æ¨ç†é©±åŠ¨ã€‚\n\n![Teaser](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig1_teaser.png)\n---\n\n## ğŸ“° æœ€æ–°åŠ¨æ€\n- **2025.07** &nbsp; ğŸ”¥[Hugging Face Spaces](https://huggingface.co/spaces/FunAudioLLM/ThinkSound) åŠ [ModelScope](https://modelscope.cn/studios/iic/ThinkSound) åœ¨çº¿äº¤äº’ä½“éªŒå‘å¸ƒï¼\n- **2025.07** &nbsp; ğŸ”¥æ¨ç†è„šæœ¬åŠç½‘é¡µç•Œé¢å·²å‘å¸ƒï¼›\n- **2025.06** &nbsp; ğŸ”¥[ThinkSound è®ºæ–‡](https://arxiv.org/pdf/2506.21448) å·²åœ¨ arXiv å‘å¸ƒï¼\n- **2025.06** &nbsp; ğŸ”¥[åœ¨çº¿æ¼”ç¤º](http://thinksound-project.github.io/) ä¸Šçº¿ï¼Œæ¬¢è¿ä½“éªŒï¼\n\n---\n\n## ğŸš€ ä¸»è¦ç‰¹æ€§\n\n- **Any2Audio**ï¼šæ”¯æŒä»»æ„æ¨¡æ€ï¼ˆè§†é¢‘ã€æ–‡æœ¬ã€éŸ³é¢‘æˆ–å…¶ç»„åˆï¼‰ç”ŸæˆéŸ³é¢‘ã€‚\n- **è§†é¢‘è½¬éŸ³é¢‘ SOTA**ï¼šåœ¨å¤šä¸ª V2A åŸºå‡†ä¸Šå–å¾—æœ€æ–°æœ€ä¼˜ç»“æœã€‚\n- **CoT é©±åŠ¨æ¨ç†**ï¼šåŸºäºé“¾å¼æ€ç»´æ¨ç†ï¼Œå®ç°å¯ç»„åˆã€å¯æ§çš„éŸ³é¢‘ç”Ÿæˆã€‚\n- **äº¤äº’å¼é¢å‘å¯¹è±¡ç¼–è¾‘**ï¼šé€šè¿‡ç‚¹å‡»è§†è§‰å¯¹è±¡æˆ–æ–‡æœ¬æŒ‡ä»¤ï¼Œç»†åŒ–æˆ–ç¼–è¾‘ç‰¹å®šå£°éŸ³äº‹ä»¶ã€‚\n- **ç»Ÿä¸€æ¡†æ¶**ï¼šå•ä¸€åŸºç¡€æ¨¡å‹ï¼Œæ”¯æŒç”Ÿæˆã€ç¼–è¾‘ä¸äº¤äº’å¼å·¥ä½œæµã€‚\n\n---\n\n## âœ¨ æ–¹æ³•æ¦‚è¿°\n\nThinkSound å°†éŸ³é¢‘ç”Ÿæˆä¸ç¼–è¾‘åˆ†ä¸ºä¸‰ä¸ªäº¤äº’å¼é˜¶æ®µï¼Œå‡ç”±åŸºäº MLLM çš„é“¾å¼æ€ç»´ï¼ˆCoTï¼‰æ¨ç†æŒ‡å¯¼ï¼š\n\n1. **æ‹ŸéŸ³ç”Ÿæˆï¼ˆFoley Generationï¼‰ï¼š** ä»è§†é¢‘ç”ŸæˆåŸºç¡€ã€è¯­ä¹‰ä¸æ—¶åºå¯¹é½çš„å£°æ™¯ã€‚\n2. **é¢å‘å¯¹è±¡çš„ç»†åŒ–ï¼š** é€šè¿‡ç‚¹å‡»æˆ–é€‰æ‹©è§†é¢‘ä¸­çš„å¯¹è±¡åŒºåŸŸï¼Œå¯¹ç”¨æˆ·æŒ‡å®šå¯¹è±¡çš„å£°éŸ³è¿›è¡Œç»†åŒ–æˆ–æ·»åŠ ã€‚\n3. **å®šå‘éŸ³é¢‘ç¼–è¾‘ï¼š** ä½¿ç”¨é«˜çº§è‡ªç„¶è¯­è¨€æŒ‡ä»¤å¯¹ç”ŸæˆéŸ³é¢‘è¿›è¡Œä¿®æ”¹ã€‚\n\n![ThinkSound Overview](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig3_model.png)\n<!-- å¤§è§„æ¨¡ CoT æ³¨é‡Šæ•°æ®é›†ï¼ˆ**AudioCoT**ï¼‰ç”¨äºè®­ç»ƒæ¨ç†æ¨¡å—å’Œç»Ÿä¸€éŸ³é¢‘åŸºç¡€æ¨¡å‹ã€‚\n![AudioCoT Pipeline](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig2_dataset.png) -->\n\n---\n\n## âš¡ å¿«é€Ÿå¼€å§‹\n\n**ç¯å¢ƒå‡†å¤‡ï¼š**\n```bash\ngit clone https://github.com/liuhuadai/ThinkSound.git\ncd ThinkSound\npip install -r requirements.txt\nconda install -y -c conda-forge 'ffmpeg<7'\n# ä¸‹è½½é¢„è®­ç»ƒæƒé‡ https://huggingface.co/liuhuadai/ThinkSound åˆ°ç›®å½• ckpts/\n# æ¨¡å‹æƒé‡ä¹Ÿå¯ä» https://www.modelscope.cn/models/iic/ThinkSound ä¸‹è½½\ngit lfs install\ngit clone https://huggingface.co/liuhuadai/ThinkSound ckpts\n```\n\n**èµ‹äºˆå¯æ‰§è¡Œæƒé™**\n```bash\nchmod +x scripts/demo.sh\n```\n\n**è¿è¡Œè„šæœ¬**\n```bash\n./scripts/demo.sh <video_path> <caption> <CoT description>\n```\n\n\n### ç½‘é¡µç•Œé¢ä½¿ç”¨\n\nå¦‚éœ€äº¤äº’ä½“éªŒï¼Œå¯å¯åŠ¨ Gradio ç½‘é¡µç•Œé¢ï¼š\n\n```bash\npython app.py\n```\n\n---",
  "status": "ok"
}