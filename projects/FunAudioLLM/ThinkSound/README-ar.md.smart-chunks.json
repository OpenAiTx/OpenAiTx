[
  {
    "Id": 1,
    "Content": "<h1 align=\"center\">ThinkSound</h1>\n\n<p align=\"center\">\n  ğŸŒ\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=en\">English</a> |\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=zh-CN\">ç®€ä½“ä¸­æ–‡</a> |\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=zh-TW\">ç¹é«”ä¸­æ–‡</a> |\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=es\">EspaÃ±ol</a> |\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=fr\">FranÃ§ais</a> |\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=ja\">æ—¥æœ¬èª</a>\n  \n</p>\n<p align=\"center\">\n  <img src=\"https://img.shields.io/badge/NeurIPS 2025-Main Conference-blue.svg\" alt=\"NeurIPS 2025\"/>\n<p align=\"center\">\n  <a href=\"https://arxiv.org/pdf/2506.21448\">\n    <img src=\"https://img.shields.io/badge/arXiv-2506.21448-b31b1b.svg\" alt=\"arXiv\"/>\n  </a>\n  &nbsp;\n  <a href=\"https://thinksound-project.github.io/\">\n    <img src=\"https://img.shields.io/badge/Online%20Demo-ğŸŒ-blue\" alt=\"Online Demo\"/>\n  </a>\n  &nbsp;\n  <a href=\"https://huggingface.co/spaces/FunAudioLLM/ThinkSound\">\n    <img src=\"https://img.shields.io/badge/HuggingFace-Spaces-orange?logo=huggingface\" alt=\"Hugging Face\"/>\n  </a>\n  &nbsp;\n  <a href=\"https://modelscope.cn/studios/iic/ThinkSound\">\n    <img src=\"https://img.shields.io/badge/ModelScope-åœ¨çº¿ä½“éªŒ-green\" alt=\"ModelScope\"/>\n  </a>\n</p>\n\n<p align=\"center\">\n  If you find this project useful,<br>\n  a star â­ on GitHub would be greatly appreciated!\n</p>\n\n---\n\n**ThinkSound** is a unified Any2Audio generation framework with flow matching guided by Chain-of-Thought (CoT) reasoning.",
    "ContentSha": "3764VshEOMedejxsV+uo8k5R5Emk0MLuYfIOX8JadcY=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "<h1 align=\"center\">Ø«ÙŠÙ†Ùƒ Ø³Ø§ÙˆÙ†Ø¯</h1>\n\n<p align=\"center\">\n  ğŸŒ\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=en\">English</a> |\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=zh-CN\">ç®€ä½“ä¸­æ–‡</a> |\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=zh-TW\">ç¹é«”ä¸­æ–‡</a> |\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=es\">EspaÃ±ol</a> |\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=fr\">FranÃ§ais</a> |\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=ja\">æ—¥æœ¬èª</a>\n  \n</p>\n<p align=\"center\">\n  <img src=\"https://img.shields.io/badge/NeurIPS 2025-Main Conference-blue.svg\" alt=\"NeurIPS 2025\"/>\n<p align=\"center\">\n  <a href=\"https://arxiv.org/pdf/2506.21448\">\n    <img src=\"https://img.shields.io/badge/arXiv-2506.21448-b31b1b.svg\" alt=\"arXiv\"/>\n  </a>\n  &nbsp;\n  <a href=\"https://thinksound-project.github.io/\">\n    <img src=\"https://img.shields.io/badge/Online%20Demo-ğŸŒ-blue\" alt=\"Online Demo\"/>\n  </a>\n  &nbsp;\n  <a href=\"https://huggingface.co/spaces/FunAudioLLM/ThinkSound\">\n    <img src=\"https://img.shields.io/badge/HuggingFace-Spaces-orange?logo=huggingface\" alt=\"Hugging Face\"/>\n  </a>\n  &nbsp;\n  <a href=\"https://modelscope.cn/studios/iic/ThinkSound\">\n    <img src=\"https://img.shields.io/badge/ModelScope-åœ¨çº¿ä½“éªŒ-green\" alt=\"ModelScope\"/>\n  </a>\n</p>\n\n<p align=\"center\">\n  Ø¥Ø°Ø§ ÙˆØ¬Ø¯Øª Ù‡Ø°Ø§ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ Ù…ÙÙŠØ¯Ù‹Ø§ØŒ<br>\n  Ø³ÙŠÙƒÙˆÙ† Ù…Ù† Ø§Ù„Ø±Ø§Ø¦Ø¹ ÙˆØ¶Ø¹ Ù†Ø¬Ù…Ø© â­ Ø¹Ù„Ù‰ GitHub!\n</p>\n\n---\n\n**Ø«ÙŠÙ†Ùƒ Ø³Ø§ÙˆÙ†Ø¯** Ù‡Ùˆ Ø¥Ø·Ø§Ø± Ù…ÙˆØ­Ø¯ Ù„ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØª Ù…Ù† Ø£ÙŠ Ù…Ø¯Ø®Ù„Ø§Øª (Any2Audio) Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„ØªØ¯ÙÙ‚ Ø§Ù„Ù…ÙˆØ¬Ù‡Ø© Ø¨ÙˆØ§Ø³Ø·Ø© Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ø³Ù„Ø³Ù„Ø© Ø§Ù„Ø£ÙÙƒØ§Ø± (CoT).",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 2,
    "Content": "\nPyTorch implementation for multimodal audio generation and editing: generate or edit audio from video, text, and audio, powered by step-by-step reasoning from Multimodal Large Language Models (MLLMs).\n\n![Teaser](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig1_teaser.png)\n---\n\n## ğŸ“° News\n- **2025.11.25** &nbsp; ğŸ”¥[Online PrismAudio Demo](http://prismaudio-project.github.io/) is live - try it now!\n- **2025.11.25** &nbsp; ğŸ”¥[PrismAudio paper](https://arxiv.org/pdf/2511.18833) released on arXiv, the first multi-dimensional CoT-RL framework for Video-to-Audio Generation!\n- **2025.09.19** &nbsp; ğŸ‰ ThinkSound has been accepted to the **NeurIPS 2025 Main Conference**!\n- **2025.09.01** &nbsp; Our AudioCoT dataset is now open-sourced and available on [Hugging Face](https://huggingface.co/datasets/liuhuadai/AudioCoT)!\n- **2025.07.17** &nbsp; ğŸ§  Finetuning enabled: training and finetuning code is now publicly available, along with clear usage instructions to help you customize and extend ThinkSound with your own data.\n- **2025.07.15** &nbsp; ğŸ“¦ Simplified installation and usability: dependencies on PyPI for easy cross-platform setup; Windows `.bat` scripts automate environment creation and script running.\n- **2025.07.08** &nbsp;Â  ğŸ”§ Major update: model lightweighted and optimized memory and GPU usage, now supports high-throughput audio generation at scale!\n- **2025.07.01** &nbsp; Online demo on [Hugging Face Spaces](https://huggingface.co/spaces/FunAudioLLM/ThinkSound) and [ModelScope](https://modelscope.cn/studios/iic/ThinkSound) for interactive experience!\n- **2025.07.01** &nbsp; Released inference scripts and web interface; \n- **2025.06** &nbsp; [ThinkSound paper](https://arxiv.org/pdf/2506.21448) released on arXiv!\n- **2025.06** &nbsp; [Online Demo](http://thinksound-project.github.io/) is live - try it now!\n\n---\n\n\n## ğŸš€ Features\n\n- **Any2Audio**: Generate audio from arbitrary modalities â€” video, text, audio, or their combinations.\n- **Video-to-Audio SOTA**: Achieves state-of-the-art results on multiple V2A benchmarks.\n- **CoT-Driven Reasoning**: Chain-of-Thought reasoning for compositional and controllable audio generation via MLLMs.\n- **Interactive Object-centric Editing**: Refine or edit specific sound events by clicking on visual objects or using text instructions.\n- **Unified Framework**: One foundation model supports generation, editing, and interactive workflow.\n\n---\n\n## âœ¨ Method Overview\n\nThinkSound decomposes audio generation and editing into three interactive stages, all guided by MLLM-based Chain-of-Thought (CoT) reasoning:\n\n1. **Foley Generation:** Generate foundational, semantically and temporally aligned soundscapes from video.\n2. **Object-Centric Refinement:** Refine or add sounds for user-specified objects via clicks or regions in the video.\n3. **Targeted Audio Editing:** Modify generated audio using high-level natural language instructions.\n",
    "ContentSha": "Vp81xeUGr9WCESp62x1lkoIptJHl0dM1R8kleL4V10c=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "ØªÙ†ÙÙŠØ° PyTorch Ù„ØªÙˆÙ„ÙŠØ¯ ÙˆØªØ­Ø±ÙŠØ± Ø§Ù„ØµÙˆØª Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„ÙˆØ³Ø§Ø¦Ø·: ØªÙˆÙ„ÙŠØ¯ Ø£Ùˆ ØªØ­Ø±ÙŠØ± Ø§Ù„ØµÙˆØª Ù…Ù† Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø£Ùˆ Ø§Ù„Ù†Øµ Ø£Ùˆ Ø§Ù„ØµÙˆØªØŒ Ù…Ø¯Ø¹ÙˆÙ… Ø¨Ø®Ø·ÙˆØ§Øª ØªÙÙƒÙŠØ± Ù…ØªØ³Ù„Ø³Ù„Ø© Ù…Ù† Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù„ØºØ© Ø§Ù„ÙƒØ¨ÙŠØ±Ø© Ù…ØªØ¹Ø¯Ø¯Ø© Ø§Ù„ÙˆØ³Ø§Ø¦Ø· (MLLMs).\n\n![Teaser](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig1_teaser.png)\n---\n\n## ğŸ“° Ø§Ù„Ø£Ø®Ø¨Ø§Ø±\n- **2025.11.25** &nbsp; ğŸ”¥[Ø¹Ø±Ø¶ PrismAudio Ø§Ù„ØªØ¬Ø±ÙŠØ¨ÙŠ Ø§Ù„Ù…Ø¨Ø§Ø´Ø±](http://prismaudio-project.github.io/) Ù…ØªÙˆÙØ± Ø§Ù„Ø¢Ù† - Ø¬Ø±Ø¨Ù‡ Ø§Ù„Ø¢Ù†!\n- **2025.11.25** &nbsp; ğŸ”¥[ÙˆØ±Ù‚Ø© PrismAudio](https://arxiv.org/pdf/2511.18833) ØµØ¯Ø±Øª Ø¹Ù„Ù‰ arXivØŒ Ø£ÙˆÙ„ Ø¥Ø·Ø§Ø± CoT-RL Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯ Ù„ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØª Ù…Ù† Ø§Ù„ÙÙŠØ¯ÙŠÙˆ!\n- **2025.09.19** &nbsp; ğŸ‰ ØªÙ… Ù‚Ø¨ÙˆÙ„ ThinkSound ÙÙŠ **Ø§Ù„Ù…Ø¤ØªÙ…Ø± Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ NeurIPS 2025**!\n- **2025.09.01** &nbsp; Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª AudioCoT Ù…ÙØªÙˆØ­Ø© Ø§Ù„Ù…ØµØ¯Ø± ÙˆÙ…ØªØ§Ø­Ø© Ø§Ù„Ø¢Ù† Ø¹Ù„Ù‰ [Hugging Face](https://huggingface.co/datasets/liuhuadai/AudioCoT)!\n- **2025.07.17** &nbsp; ğŸ§  ØªÙØ¹ÙŠÙ„ Ø§Ù„ØªØ®ØµÙŠØµ: Ø§Ù„Ø´ÙŠÙØ±Ø§Øª Ø§Ù„Ø®Ø§ØµØ© Ø¨Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙˆØ§Ù„ØªØ®ØµÙŠØµ Ù…ØªØ§Ø­Ø© Ø§Ù„Ø¢Ù† Ù…Ø¹ ØªØ¹Ù„ÙŠÙ…Ø§Øª ÙˆØ§Ø¶Ø­Ø© Ù„Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ Ø¹Ù„Ù‰ ØªØ®ØµÙŠØµ ÙˆØªÙˆØ³ÙŠØ¹ ThinkSound Ø¨Ø¨ÙŠØ§Ù†Ø§ØªÙƒ Ø§Ù„Ø®Ø§ØµØ©.\n- **2025.07.15** &nbsp; ğŸ“¦ ØªØ¨Ø³ÙŠØ· Ø§Ù„ØªØ«Ø¨ÙŠØª ÙˆØ³Ù‡ÙˆÙ„Ø© Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…: Ø§Ù„Ø§Ø¹ØªÙ…Ø§Ø¯ÙŠØ§Øª Ù…ØªÙˆÙØ±Ø© Ø¹Ù„Ù‰ PyPI Ù„Ø¥Ø¹Ø¯Ø§Ø¯ Ø¹Ø¨Ø± Ø§Ù„Ø£Ù†Ø¸Ù…Ø© Ø¨Ø³Ù‡ÙˆÙ„Ø©Ø› Ø³ÙƒØ±ÙŠØ¨ØªØ§Øª Windows `.bat` Ù„Ø£ØªÙ…ØªØ© Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø¨ÙŠØ¦Ø© ÙˆØªØ´ØºÙŠÙ„ Ø§Ù„Ø³ÙƒØ±ÙŠØ¨ØªØ§Øª.\n- **2025.07.08** &nbsp;Â  ğŸ”§ ØªØ­Ø¯ÙŠØ« Ø±Ø¦ÙŠØ³ÙŠ: ØªÙ… ØªØ®ÙÙŠÙ ÙˆØ²Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØªØ­Ø³ÙŠÙ† Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°Ø§ÙƒØ±Ø© ÙˆÙ…Ø¹Ø§Ù„Ø¬ Ø§Ù„Ø±Ø³ÙˆÙ…ÙŠØ§ØªØŒ ÙŠØ¯Ø¹Ù… Ø§Ù„Ø¢Ù† ØªÙˆÙ„ÙŠØ¯ ØµÙˆØª Ø¹Ø§Ù„ÙŠ Ø§Ù„Ø¥Ù†ØªØ§Ø¬ÙŠØ© Ø¹Ù„Ù‰ Ù†Ø·Ø§Ù‚ ÙˆØ§Ø³Ø¹!\n- **2025.07.01** &nbsp; Ø¹Ø±Ø¶ ØªØ¬Ø±ÙŠØ¨ÙŠ Ù…Ø¨Ø§Ø´Ø± Ø¹Ù„Ù‰ [Hugging Face Spaces](https://huggingface.co/spaces/FunAudioLLM/ThinkSound) Ùˆ [ModelScope](https://modelscope.cn/studios/iic/ThinkSound) Ù„ØªØ¬Ø±Ø¨Ø© ØªÙØ§Ø¹Ù„ÙŠØ©!\n- **2025.07.01** &nbsp; Ø¥ØµØ¯Ø§Ø± Ø³ÙƒØ±ÙŠØ¨ØªØ§Øª Ø§Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„ ÙˆÙˆØ§Ø¬Ù‡Ø© Ø§Ù„ÙˆÙŠØ¨Ø› \n- **2025.06** &nbsp; [ÙˆØ±Ù‚Ø© ThinkSound](https://arxiv.org/pdf/2506.21448) ØµØ¯Ø±Øª Ø¹Ù„Ù‰ arXiv!\n- **2025.06** &nbsp; [Ø§Ù„Ø¹Ø±Ø¶ Ø§Ù„ØªØ¬Ø±ÙŠØ¨ÙŠ Ø§Ù„Ù…Ø¨Ø§Ø´Ø±](http://thinksound-project.github.io/) Ù…ØªÙˆÙØ± Ø§Ù„Ø¢Ù† - Ø¬Ø±Ø¨Ù‡ Ø§Ù„Ø¢Ù†!\n\n---\n\n\n## ğŸš€ Ø§Ù„Ù…ÙŠØ²Ø§Øª\n\n- **Any2Audio**: ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØª Ù…Ù† Ø£ÙŠ Ù†ÙˆØ¹ Ù…Ù† Ø§Ù„ÙˆØ³Ø§Ø¦Ø· â€” ÙÙŠØ¯ÙŠÙˆ Ø£Ùˆ Ù†Øµ Ø£Ùˆ ØµÙˆØª Ø£Ùˆ Ù…Ø²ÙŠØ¬ Ù…Ù†Ù‡Ø§.\n- **Ø§Ù„Ø±ÙŠØ§Ø¯Ø© ÙÙŠ ØªØ­ÙˆÙŠÙ„ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø¥Ù„Ù‰ ØµÙˆØª**: ÙŠØ­Ù‚Ù‚ Ù†ØªØ§Ø¦Ø¬ Ù…ØªÙ‚Ø¯Ù…Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø¹Ø¯ÙŠØ¯ Ù…Ù† Ù…Ø¹Ø§ÙŠÙŠØ± V2A.\n- **ØªÙÙƒÙŠØ± Ù…Ø¯ÙÙˆØ¹ Ø¨Ø³Ù„Ø³Ù„Ø© Ø§Ù„ØªÙÙƒÙŠØ±**: ØªÙˆÙ„ÙŠØ¯ ØµÙˆØª ØªØ±ÙƒÙŠØ¨ÙŠ ÙˆØªØ­ÙƒÙ…ÙŠ Ù…Ø¯ÙÙˆØ¹ Ø¨Ø³Ù„Ø³Ù„Ø© Ø§Ù„ØªÙÙƒÙŠØ± Ø¹Ø¨Ø± MLLMs.\n- **ØªØ­Ø±ÙŠØ± ØªÙØ§Ø¹Ù„ÙŠ Ù…Ø±ÙƒØ² Ø¹Ù„Ù‰ Ø§Ù„ÙƒØ§Ø¦Ù†Ø§Øª**: ØªÙ†Ù‚ÙŠØ­ Ø£Ùˆ ØªØ­Ø±ÙŠØ± Ø£Ø­Ø¯Ø§Ø« ØµÙˆØªÙŠØ© Ù…Ø­Ø¯Ø¯Ø© Ø¨Ø§Ù„Ù†Ù‚Ø± Ø¹Ù„Ù‰ ÙƒØ§Ø¦Ù†Ø§Øª Ù…Ø±Ø¦ÙŠØ© Ø£Ùˆ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… ØªØ¹Ù„ÙŠÙ…Ø§Øª Ù†ØµÙŠØ©.\n- **Ø¥Ø·Ø§Ø± Ù…ÙˆØ­Ø¯**: Ù†Ù…ÙˆØ°Ø¬ Ø£Ø³Ø§Ø³ÙŠ ÙˆØ§Ø­Ø¯ ÙŠØ¯Ø¹Ù… Ø§Ù„ØªÙˆÙ„ÙŠØ¯ ÙˆØ§Ù„ØªØ­Ø±ÙŠØ± ÙˆØ³ÙŠØ± Ø§Ù„Ø¹Ù…Ù„ Ø§Ù„ØªÙØ§Ø¹Ù„ÙŠ.\n\n---\n\n## âœ¨ Ù†Ø¸Ø±Ø© Ø¹Ø§Ù…Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø·Ø±ÙŠÙ‚Ø©\n\nÙŠÙ‚ÙˆÙ… ThinkSound Ø¨ØªÙ‚Ø³ÙŠÙ… ØªÙˆÙ„ÙŠØ¯ ÙˆØªØ­Ø±ÙŠØ± Ø§Ù„ØµÙˆØª Ø¥Ù„Ù‰ Ø«Ù„Ø§Ø« Ù…Ø±Ø§Ø­Ù„ ØªÙØ§Ø¹Ù„ÙŠØ©ØŒ Ø¬Ù…ÙŠØ¹Ù‡Ø§ Ù…ÙˆØ¬Ù‡Ø© Ø¨ØªÙÙƒÙŠØ± Ø³Ù„Ø³Ù„Ø© Ø§Ù„ØªÙÙƒÙŠØ± Ø§Ù„Ù…Ø¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ MLLM:\n\n1. **ØªÙˆÙ„ÙŠØ¯ Foley:** Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø´Ø§Ù‡Ø¯ ØµÙˆØªÙŠØ© Ø£Ø³Ø§Ø³ÙŠØ© Ù…ØªÙˆØ§ÙÙ‚Ø© Ø¯Ù„Ø§Ù„ÙŠØ§Ù‹ ÙˆØ²Ù…Ù†ÙŠØ§Ù‹ Ù…Ø¹ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ.\n2. **ØªÙ†Ù‚ÙŠØ­ Ù…Ø±ÙƒØ² Ø¹Ù„Ù‰ Ø§Ù„ÙƒØ§Ø¦Ù†Ø§Øª:** ØªÙ†Ù‚ÙŠØ­ Ø£Ùˆ Ø¥Ø¶Ø§ÙØ© Ø£ØµÙˆØ§Øª Ù„ÙƒØ§Ø¦Ù†Ø§Øª ÙŠØ­Ø¯Ø¯Ù‡Ø§ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¹Ø¨Ø± Ø§Ù„Ù†Ù‚Ø± Ø£Ùˆ ØªØ­Ø¯ÙŠØ¯ Ù…Ù†Ø§Ø·Ù‚ ÙÙŠ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ.\n3. **ØªØ­Ø±ÙŠØ± ØµÙˆØªÙŠ Ù…ÙˆØ¬Ù‡:** ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„ØµÙˆØª Ø§Ù„Ù†Ø§ØªØ¬ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… ØªØ¹Ù„ÙŠÙ…Ø§Øª Ù„ØºØ© Ø·Ø¨ÙŠØ¹ÙŠØ© Ø¹Ø§Ù„ÙŠØ© Ø§Ù„Ù…Ø³ØªÙˆÙ‰.\n\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "ØªÙ†ÙÙŠØ° PyTorch Ù„ØªÙˆÙ„ÙŠØ¯ ÙˆØªØ­Ø±ÙŠØ± Ø§Ù„ØµÙˆØª Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„ÙˆØ³Ø§Ø¦Ø·: ØªÙˆÙ„ÙŠØ¯ Ø£Ùˆ ØªØ­Ø±ÙŠØ± Ø§Ù„ØµÙˆØª Ù…Ù† Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø£Ùˆ Ø§Ù„Ù†Øµ Ø£Ùˆ Ø§Ù„ØµÙˆØªØŒ Ù…Ø¯Ø¹ÙˆÙ… Ø¨Ø®Ø·ÙˆØ§Øª ØªÙÙƒÙŠØ± Ù…ØªØ³Ù„Ø³Ù„Ø© Ù…Ù† Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù„ØºØ© Ø§Ù„ÙƒØ¨ÙŠØ±Ø© Ù…ØªØ¹Ø¯Ø¯Ø© Ø§Ù„ÙˆØ³Ø§Ø¦Ø· (MLLMs)."
      },
      {
        "row": 2,
        "rowsha": "eexREJOMCITdo96Iwg4N4PQqu1ux/UwupfjVRj0l/L8=",
        "originContent": "PyTorch implementation for multimodal audio generation and editing: generate or edit audio from video, text, and audio, powered by step-by-step reasoning from Multimodal Large Language Models (MLLMs).",
        "translatedContent": ""
      },
      {
        "row": 3,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "![Teaser](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig1_teaser.png)"
      },
      {
        "row": 4,
        "rowsha": "+7Cx1rdpWiIOeWRA/RM6HsKf7pNA3hHsQk2Bpadt4II=",
        "originContent": "![Teaser](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig1_teaser.png)",
        "translatedContent": "---"
      },
      {
        "row": 5,
        "rowsha": "yz+R1U7uMOU+NbK5mQX3Dxae1Un9eJCdPawt78ntjTs=",
        "originContent": "---",
        "translatedContent": ""
      },
      {
        "row": 6,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "## ğŸ“° Ø§Ù„Ø£Ø®Ø¨Ø§Ø±"
      },
      {
        "row": 7,
        "rowsha": "0YeCyxpcm7/4RDbaM+OQoI8YfqEHQzDkpGW15VZdi1U=",
        "originContent": "## ğŸ“° News",
        "translatedContent": "- **2025.11.25** &nbsp; ğŸ”¥[Ø¹Ø±Ø¶ PrismAudio Ø§Ù„ØªØ¬Ø±ÙŠØ¨ÙŠ Ø§Ù„Ù…Ø¨Ø§Ø´Ø±](http://prismaudio-project.github.io/) Ù…ØªÙˆÙØ± Ø§Ù„Ø¢Ù† - Ø¬Ø±Ø¨Ù‡ Ø§Ù„Ø¢Ù†!"
      },
      {
        "row": 8,
        "rowsha": "EeDKxV0PYB9iw6GxOqwnsP3C385ykbqk8PtEVoVhAcc=",
        "originContent": "- **2025.11.25** &nbsp; ğŸ”¥[Online PrismAudio Demo](http://prismaudio-project.github.io/) is live - try it now!",
        "translatedContent": "- **2025.11.25** &nbsp; ğŸ”¥[ÙˆØ±Ù‚Ø© PrismAudio](https://arxiv.org/pdf/2511.18833) ØµØ¯Ø±Øª Ø¹Ù„Ù‰ arXivØŒ Ø£ÙˆÙ„ Ø¥Ø·Ø§Ø± CoT-RL Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯ Ù„ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØª Ù…Ù† Ø§Ù„ÙÙŠØ¯ÙŠÙˆ!"
      },
      {
        "row": 9,
        "rowsha": "Q6c68QE34xLPSZ5xAL4zofEn/u8umRYYiH3ddCcy5vk=",
        "originContent": "- **2025.11.25** &nbsp; ğŸ”¥[PrismAudio paper](https://arxiv.org/pdf/2511.18833) released on arXiv, the first multi-dimensional CoT-RL framework for Video-to-Audio Generation!",
        "translatedContent": "- **2025.09.19** &nbsp; ğŸ‰ ØªÙ… Ù‚Ø¨ÙˆÙ„ ThinkSound ÙÙŠ **Ø§Ù„Ù…Ø¤ØªÙ…Ø± Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ NeurIPS 2025**!"
      },
      {
        "row": 10,
        "rowsha": "vj2hbV/6MacDcxRmFA0AtTog5xU6CHoqBFO3YMO+yJo=",
        "originContent": "- **2025.09.19** &nbsp; ğŸ‰ ThinkSound has been accepted to the **NeurIPS 2025 Main Conference**!",
        "translatedContent": "- **2025.09.01** &nbsp; Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª AudioCoT Ù…ÙØªÙˆØ­Ø© Ø§Ù„Ù…ØµØ¯Ø± ÙˆÙ…ØªØ§Ø­Ø© Ø§Ù„Ø¢Ù† Ø¹Ù„Ù‰ [Hugging Face](https://huggingface.co/datasets/liuhuadai/AudioCoT)!"
      },
      {
        "row": 11,
        "rowsha": "+guVQwDlJDqR1pBGMGc4FQ11nryItaEtKQ3etaCBcn0=",
        "originContent": "- **2025.09.01** &nbsp; Our AudioCoT dataset is now open-sourced and available on [Hugging Face](https://huggingface.co/datasets/liuhuadai/AudioCoT)!",
        "translatedContent": "- **2025.07.17** &nbsp; ğŸ§  ØªÙØ¹ÙŠÙ„ Ø§Ù„ØªØ®ØµÙŠØµ: Ø§Ù„Ø´ÙŠÙØ±Ø§Øª Ø§Ù„Ø®Ø§ØµØ© Ø¨Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙˆØ§Ù„ØªØ®ØµÙŠØµ Ù…ØªØ§Ø­Ø© Ø§Ù„Ø¢Ù† Ù…Ø¹ ØªØ¹Ù„ÙŠÙ…Ø§Øª ÙˆØ§Ø¶Ø­Ø© Ù„Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ Ø¹Ù„Ù‰ ØªØ®ØµÙŠØµ ÙˆØªÙˆØ³ÙŠØ¹ ThinkSound Ø¨Ø¨ÙŠØ§Ù†Ø§ØªÙƒ Ø§Ù„Ø®Ø§ØµØ©."
      },
      {
        "row": 12,
        "rowsha": "4Jq9g83O8cYV4fVKsetfTpI+JrSepLrjK6J7Xg9tSqo=",
        "originContent": "- **2025.07.17** &nbsp; ğŸ§  Finetuning enabled: training and finetuning code is now publicly available, along with clear usage instructions to help you customize and extend ThinkSound with your own data.",
        "translatedContent": "- **2025.07.15** &nbsp; ğŸ“¦ ØªØ¨Ø³ÙŠØ· Ø§Ù„ØªØ«Ø¨ÙŠØª ÙˆØ³Ù‡ÙˆÙ„Ø© Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…: Ø§Ù„Ø§Ø¹ØªÙ…Ø§Ø¯ÙŠØ§Øª Ù…ØªÙˆÙØ±Ø© Ø¹Ù„Ù‰ PyPI Ù„Ø¥Ø¹Ø¯Ø§Ø¯ Ø¹Ø¨Ø± Ø§Ù„Ø£Ù†Ø¸Ù…Ø© Ø¨Ø³Ù‡ÙˆÙ„Ø©Ø› Ø³ÙƒØ±ÙŠØ¨ØªØ§Øª Windows `.bat` Ù„Ø£ØªÙ…ØªØ© Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø¨ÙŠØ¦Ø© ÙˆØªØ´ØºÙŠÙ„ Ø§Ù„Ø³ÙƒØ±ÙŠØ¨ØªØ§Øª."
      },
      {
        "row": 13,
        "rowsha": "Ae5w+cTrCd9E8qidC11IWJAgg+LuOgUxA4czDPNG/G0=",
        "originContent": "- **2025.07.15** &nbsp; ğŸ“¦ Simplified installation and usability: dependencies on PyPI for easy cross-platform setup; Windows `.bat` scripts automate environment creation and script running.",
        "translatedContent": "- **2025.07.08** &nbsp;Â  ğŸ”§ ØªØ­Ø¯ÙŠØ« Ø±Ø¦ÙŠØ³ÙŠ: ØªÙ… ØªØ®ÙÙŠÙ ÙˆØ²Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØªØ­Ø³ÙŠÙ† Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°Ø§ÙƒØ±Ø© ÙˆÙ…Ø¹Ø§Ù„Ø¬ Ø§Ù„Ø±Ø³ÙˆÙ…ÙŠØ§ØªØŒ ÙŠØ¯Ø¹Ù… Ø§Ù„Ø¢Ù† ØªÙˆÙ„ÙŠØ¯ ØµÙˆØª Ø¹Ø§Ù„ÙŠ Ø§Ù„Ø¥Ù†ØªØ§Ø¬ÙŠØ© Ø¹Ù„Ù‰ Ù†Ø·Ø§Ù‚ ÙˆØ§Ø³Ø¹!"
      },
      {
        "row": 14,
        "rowsha": "nYxNhwgSqjwYLuWsfHAqP5sx2PnzYwoFrwcf9U+Fdss=",
        "originContent": "- **2025.07.08** &nbsp;Â  ğŸ”§ Major update: model lightweighted and optimized memory and GPU usage, now supports high-throughput audio generation at scale!",
        "translatedContent": "- **2025.07.01** &nbsp; Ø¹Ø±Ø¶ ØªØ¬Ø±ÙŠØ¨ÙŠ Ù…Ø¨Ø§Ø´Ø± Ø¹Ù„Ù‰ [Hugging Face Spaces](https://huggingface.co/spaces/FunAudioLLM/ThinkSound) Ùˆ [ModelScope](https://modelscope.cn/studios/iic/ThinkSound) Ù„ØªØ¬Ø±Ø¨Ø© ØªÙØ§Ø¹Ù„ÙŠØ©!"
      },
      {
        "row": 15,
        "rowsha": "RPL6cU3/Jgu90ib4PkeN5Q/ALrnjq9hK0ZUCranb/PA=",
        "originContent": "- **2025.07.01** &nbsp; Online demo on [Hugging Face Spaces](https://huggingface.co/spaces/FunAudioLLM/ThinkSound) and [ModelScope](https://modelscope.cn/studios/iic/ThinkSound) for interactive experience!",
        "translatedContent": "- **2025.07.01** &nbsp; Ø¥ØµØ¯Ø§Ø± Ø³ÙƒØ±ÙŠØ¨ØªØ§Øª Ø§Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„ ÙˆÙˆØ§Ø¬Ù‡Ø© Ø§Ù„ÙˆÙŠØ¨Ø› "
      },
      {
        "row": 16,
        "rowsha": "0PEL3eOyUmX2U56FPEPvYfaltZ/P/wbH0uO6GcLPlUE=",
        "originContent": "- **2025.07.01** &nbsp; Released inference scripts and web interface; ",
        "translatedContent": "- **2025.06** &nbsp; [ÙˆØ±Ù‚Ø© ThinkSound](https://arxiv.org/pdf/2506.21448) ØµØ¯Ø±Øª Ø¹Ù„Ù‰ arXiv!"
      },
      {
        "row": 17,
        "rowsha": "XNdJ/DN741rXoJAruiGiRueQILXIUHRXzBlp+HVWM88=",
        "originContent": "- **2025.06** &nbsp; [ThinkSound paper](https://arxiv.org/pdf/2506.21448) released on arXiv!",
        "translatedContent": "- **2025.06** &nbsp; [Ø§Ù„Ø¹Ø±Ø¶ Ø§Ù„ØªØ¬Ø±ÙŠØ¨ÙŠ Ø§Ù„Ù…Ø¨Ø§Ø´Ø±](http://thinksound-project.github.io/) Ù…ØªÙˆÙØ± Ø§Ù„Ø¢Ù† - Ø¬Ø±Ø¨Ù‡ Ø§Ù„Ø¢Ù†!"
      },
      {
        "row": 18,
        "rowsha": "W45oflUmoUAksoDc1WjcR2hErqh9UIi738PFVipiDg0=",
        "originContent": "- **2025.06** &nbsp; [Online Demo](http://thinksound-project.github.io/) is live - try it now!",
        "translatedContent": ""
      },
      {
        "row": 19,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "---"
      },
      {
        "row": 20,
        "rowsha": "yz+R1U7uMOU+NbK5mQX3Dxae1Un9eJCdPawt78ntjTs=",
        "originContent": "---",
        "translatedContent": ""
      },
      {
        "row": 21,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 22,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "## ğŸš€ Ø§Ù„Ù…ÙŠØ²Ø§Øª"
      },
      {
        "row": 23,
        "rowsha": "f4oQIFLM2EJQxJ65F4oMEA7yWOIqs0eBtiIvGxI+GgI=",
        "originContent": "## ğŸš€ Features",
        "translatedContent": ""
      },
      {
        "row": 24,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "- **Any2Audio**: ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØª Ù…Ù† Ø£ÙŠ Ù†ÙˆØ¹ Ù…Ù† Ø§Ù„ÙˆØ³Ø§Ø¦Ø· â€” ÙÙŠØ¯ÙŠÙˆ Ø£Ùˆ Ù†Øµ Ø£Ùˆ ØµÙˆØª Ø£Ùˆ Ù…Ø²ÙŠØ¬ Ù…Ù†Ù‡Ø§."
      },
      {
        "row": 25,
        "rowsha": "8TbVluJJPR3C0fX41HklpO/vH9/k/rHC+jlvmHHfzQU=",
        "originContent": "- **Any2Audio**: Generate audio from arbitrary modalities â€” video, text, audio, or their combinations.",
        "translatedContent": "- **Ø§Ù„Ø±ÙŠØ§Ø¯Ø© ÙÙŠ ØªØ­ÙˆÙŠÙ„ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø¥Ù„Ù‰ ØµÙˆØª**: ÙŠØ­Ù‚Ù‚ Ù†ØªØ§Ø¦Ø¬ Ù…ØªÙ‚Ø¯Ù…Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø¹Ø¯ÙŠØ¯ Ù…Ù† Ù…Ø¹Ø§ÙŠÙŠØ± V2A."
      },
      {
        "row": 26,
        "rowsha": "+Jf5LrYz+d1ShYCuQe8UF9taEJUpuGhDk6fAlYK3Kj4=",
        "originContent": "- **Video-to-Audio SOTA**: Achieves state-of-the-art results on multiple V2A benchmarks.",
        "translatedContent": "- **ØªÙÙƒÙŠØ± Ù…Ø¯ÙÙˆØ¹ Ø¨Ø³Ù„Ø³Ù„Ø© Ø§Ù„ØªÙÙƒÙŠØ±**: ØªÙˆÙ„ÙŠØ¯ ØµÙˆØª ØªØ±ÙƒÙŠØ¨ÙŠ ÙˆØªØ­ÙƒÙ…ÙŠ Ù…Ø¯ÙÙˆØ¹ Ø¨Ø³Ù„Ø³Ù„Ø© Ø§Ù„ØªÙÙƒÙŠØ± Ø¹Ø¨Ø± MLLMs."
      },
      {
        "row": 27,
        "rowsha": "mU7qXkjW1YifKoYXJedYo9l64NsTBaiXsgoGFRF/g+E=",
        "originContent": "- **CoT-Driven Reasoning**: Chain-of-Thought reasoning for compositional and controllable audio generation via MLLMs.",
        "translatedContent": "- **ØªØ­Ø±ÙŠØ± ØªÙØ§Ø¹Ù„ÙŠ Ù…Ø±ÙƒØ² Ø¹Ù„Ù‰ Ø§Ù„ÙƒØ§Ø¦Ù†Ø§Øª**: ØªÙ†Ù‚ÙŠØ­ Ø£Ùˆ ØªØ­Ø±ÙŠØ± Ø£Ø­Ø¯Ø§Ø« ØµÙˆØªÙŠØ© Ù…Ø­Ø¯Ø¯Ø© Ø¨Ø§Ù„Ù†Ù‚Ø± Ø¹Ù„Ù‰ ÙƒØ§Ø¦Ù†Ø§Øª Ù…Ø±Ø¦ÙŠØ© Ø£Ùˆ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… ØªØ¹Ù„ÙŠÙ…Ø§Øª Ù†ØµÙŠØ©."
      },
      {
        "row": 28,
        "rowsha": "RComOCBBrXsZf9RHmLginqKTh9eI/bKUZuUunQEmD5M=",
        "originContent": "- **Interactive Object-centric Editing**: Refine or edit specific sound events by clicking on visual objects or using text instructions.",
        "translatedContent": "- **Ø¥Ø·Ø§Ø± Ù…ÙˆØ­Ø¯**: Ù†Ù…ÙˆØ°Ø¬ Ø£Ø³Ø§Ø³ÙŠ ÙˆØ§Ø­Ø¯ ÙŠØ¯Ø¹Ù… Ø§Ù„ØªÙˆÙ„ÙŠØ¯ ÙˆØ§Ù„ØªØ­Ø±ÙŠØ± ÙˆØ³ÙŠØ± Ø§Ù„Ø¹Ù…Ù„ Ø§Ù„ØªÙØ§Ø¹Ù„ÙŠ."
      },
      {
        "row": 29,
        "rowsha": "C3sf87sy73G/XZft+TDo5NjXo5XcrtJB805ayHRAXoQ=",
        "originContent": "- **Unified Framework**: One foundation model supports generation, editing, and interactive workflow.",
        "translatedContent": ""
      },
      {
        "row": 30,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "---"
      },
      {
        "row": 31,
        "rowsha": "yz+R1U7uMOU+NbK5mQX3Dxae1Un9eJCdPawt78ntjTs=",
        "originContent": "---",
        "translatedContent": ""
      },
      {
        "row": 32,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "## âœ¨ Ù†Ø¸Ø±Ø© Ø¹Ø§Ù…Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø·Ø±ÙŠÙ‚Ø©"
      },
      {
        "row": 33,
        "rowsha": "gjgLOIAU2x83BBZdLUdgEB+F64ajt/QuLYQXM1hDBLE=",
        "originContent": "## âœ¨ Method Overview",
        "translatedContent": ""
      },
      {
        "row": 34,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "ÙŠÙ‚ÙˆÙ… ThinkSound Ø¨ØªÙ‚Ø³ÙŠÙ… ØªÙˆÙ„ÙŠØ¯ ÙˆØªØ­Ø±ÙŠØ± Ø§Ù„ØµÙˆØª Ø¥Ù„Ù‰ Ø«Ù„Ø§Ø« Ù…Ø±Ø§Ø­Ù„ ØªÙØ§Ø¹Ù„ÙŠØ©ØŒ Ø¬Ù…ÙŠØ¹Ù‡Ø§ Ù…ÙˆØ¬Ù‡Ø© Ø¨ØªÙÙƒÙŠØ± Ø³Ù„Ø³Ù„Ø© Ø§Ù„ØªÙÙƒÙŠØ± Ø§Ù„Ù…Ø¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ MLLM:"
      },
      {
        "row": 35,
        "rowsha": "v5//GqG/smYIGoUpN+12k+9/3GWH3GdYD+jLqScb7AM=",
        "originContent": "ThinkSound decomposes audio generation and editing into three interactive stages, all guided by MLLM-based Chain-of-Thought (CoT) reasoning:",
        "translatedContent": ""
      },
      {
        "row": 36,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "1. **ØªÙˆÙ„ÙŠØ¯ Foley:** Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø´Ø§Ù‡Ø¯ ØµÙˆØªÙŠØ© Ø£Ø³Ø§Ø³ÙŠØ© Ù…ØªÙˆØ§ÙÙ‚Ø© Ø¯Ù„Ø§Ù„ÙŠØ§Ù‹ ÙˆØ²Ù…Ù†ÙŠØ§Ù‹ Ù…Ø¹ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ."
      },
      {
        "row": 37,
        "rowsha": "vTObEWb7f5gCU681X3dTkwqhsaSW89TLw3GgMJ5I3bo=",
        "originContent": "1. **Foley Generation:** Generate foundational, semantically and temporally aligned soundscapes from video.",
        "translatedContent": "2. **ØªÙ†Ù‚ÙŠØ­ Ù…Ø±ÙƒØ² Ø¹Ù„Ù‰ Ø§Ù„ÙƒØ§Ø¦Ù†Ø§Øª:** ØªÙ†Ù‚ÙŠØ­ Ø£Ùˆ Ø¥Ø¶Ø§ÙØ© Ø£ØµÙˆØ§Øª Ù„ÙƒØ§Ø¦Ù†Ø§Øª ÙŠØ­Ø¯Ø¯Ù‡Ø§ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¹Ø¨Ø± Ø§Ù„Ù†Ù‚Ø± Ø£Ùˆ ØªØ­Ø¯ÙŠØ¯ Ù…Ù†Ø§Ø·Ù‚ ÙÙŠ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ."
      },
      {
        "row": 38,
        "rowsha": "LTBpIQQHtEkNF8StAa+ZEDASGmRhmHIKDQOdZ4ExJWM=",
        "originContent": "2. **Object-Centric Refinement:** Refine or add sounds for user-specified objects via clicks or regions in the video.",
        "translatedContent": "3. **ØªØ­Ø±ÙŠØ± ØµÙˆØªÙŠ Ù…ÙˆØ¬Ù‡:** ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„ØµÙˆØª Ø§Ù„Ù†Ø§ØªØ¬ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… ØªØ¹Ù„ÙŠÙ…Ø§Øª Ù„ØºØ© Ø·Ø¨ÙŠØ¹ÙŠØ© Ø¹Ø§Ù„ÙŠØ© Ø§Ù„Ù…Ø³ØªÙˆÙ‰."
      },
      {
        "row": 39,
        "rowsha": "8wrAo7X7dPC6Sgpfrlq2ziv/Wg/3+JnlFYvO+RMxADQ=",
        "originContent": "3. **Targeted Audio Editing:** Modify generated audio using high-level natural language instructions.",
        "translatedContent": ""
      },
      {
        "row": 40,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 3,
    "Content": "![ThinkSound Overview](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig3_model.png)\n<!-- A large-scale CoT-annotated dataset (**AudioCoT**) is used to train both the reasoning module and the unified audio foundation model.\n![AudioCoT Pipeline](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig2_dataset.png) -->\n\n---\n\n## âš¡ Quick Start\n\n**Environment Preparation:**",
    "ContentSha": "QpULU62syvvJhbUWGR7NuQMiHmHmeeiFfKqP+ZpqFOk=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "![Ù†Ø¸Ø±Ø© Ø¹Ø§Ù…Ø© Ø¹Ù„Ù‰ ThinkSound](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig3_model.png)\n<!-- ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª ÙƒØ¨ÙŠØ±Ø© Ø§Ù„Ø­Ø¬Ù… Ù…Ø´Ø±ÙˆØ­Ø© Ø¨Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø³Ù„Ø³Ù„Ø© Ø§Ù„ÙÙƒØ±ÙŠØ© (**AudioCoT**) Ù„ØªØ¯Ø±ÙŠØ¨ ÙƒÙ„ Ù…Ù† ÙˆØ­Ø¯Ø© Ø§Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„ ÙˆÙ†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø£Ø³Ø§Ø³ Ø§Ù„Ù…ÙˆØ­Ø¯ Ù„Ù„ØµÙˆØª.\n![Ù…Ø³Ø§Ø± Ø¹Ù…Ù„ AudioCoT](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig2_dataset.png) -->\n\n---\n\n## âš¡ Ø§Ù„Ø¨Ø¯Ø§ÙŠØ© Ø§Ù„Ø³Ø±ÙŠØ¹Ø©\n\n**ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø¨ÙŠØ¦Ø©:**",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "4UKlvFW3Xb0bSAVjcBNeekH/MMiYS0XDg9w4mCuPy/Q=",
        "originContent": "![ThinkSound Overview](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig3_model.png)",
        "translatedContent": "![Ù†Ø¸Ø±Ø© Ø¹Ø§Ù…Ø© Ø¹Ù„Ù‰ ThinkSound](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig3_model.png)"
      },
      {
        "row": 2,
        "rowsha": "GaujeIM3x7+YcFy07LNNyITlujhkgpgeIaOiKHJkYnE=",
        "originContent": "<!-- A large-scale CoT-annotated dataset (**AudioCoT**) is used to train both the reasoning module and the unified audio foundation model.",
        "translatedContent": "<!-- ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª ÙƒØ¨ÙŠØ±Ø© Ø§Ù„Ø­Ø¬Ù… Ù…Ø´Ø±ÙˆØ­Ø© Ø¨Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø³Ù„Ø³Ù„Ø© Ø§Ù„ÙÙƒØ±ÙŠØ© (**AudioCoT**) Ù„ØªØ¯Ø±ÙŠØ¨ ÙƒÙ„ Ù…Ù† ÙˆØ­Ø¯Ø© Ø§Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„ ÙˆÙ†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø£Ø³Ø§Ø³ Ø§Ù„Ù…ÙˆØ­Ø¯ Ù„Ù„ØµÙˆØª."
      },
      {
        "row": 3,
        "rowsha": "qYOXaaTiYkoaPFcpTXE5xdSqqiW3ebi//EW/RfSXd9g=",
        "originContent": "![AudioCoT Pipeline](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig2_dataset.png) -->",
        "translatedContent": "![Ù…Ø³Ø§Ø± Ø¹Ù…Ù„ AudioCoT](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig2_dataset.png) -->"
      },
      {
        "row": 4,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 5,
        "rowsha": "yz+R1U7uMOU+NbK5mQX3Dxae1Un9eJCdPawt78ntjTs=",
        "originContent": "---",
        "translatedContent": "---"
      },
      {
        "row": 6,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 7,
        "rowsha": "PrY/jc4yAHdS+Sr+s+Yhab477/BDp3GAzMJ8+WyumyI=",
        "originContent": "## âš¡ Quick Start",
        "translatedContent": "## âš¡ Ø§Ù„Ø¨Ø¯Ø§ÙŠØ© Ø§Ù„Ø³Ø±ÙŠØ¹Ø©"
      },
      {
        "row": 8,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 9,
        "rowsha": "mD63DGEpdc7FlccTEps0KPAiwsJpO/C3yjV+SKIi/vE=",
        "originContent": "**Environment Preparation:**",
        "translatedContent": "**ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø¨ÙŠØ¦Ø©:**"
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 4,
    "Content": "```bash\ngit clone https://github.com/liuhuadai/ThinkSound.git\ncd ThinkSound\nconda create -n thinksound python=3.10\nconda activate thinksound\npip install thinksound\nconda install -y -c conda-forge 'ffmpeg<7'\n# Download pretrained weights https://huggingface.co/liuhuadai/ThinkSound to Directory ckpts/\n# model weights can be also downloaded from https://www.modelscope.cn/models/iic/ThinkSound\ngit lfs install\ngit clone https://huggingface.co/liuhuadai/ThinkSound ckpts\n# To improve inference and training speed, you may optionally install a FlashAttention backend compatible with your system and PyTorch version.\n```",
    "ContentSha": "CSBCDvBmuatxDa1cNMeHEBTJJzdLjK6wyO9v0LrETM8=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\ngit clone https://github.com/liuhuadai/ThinkSound.git\ncd ThinkSound\nconda create -n thinksound python=3.10\nconda activate thinksound\npip install thinksound\nconda install -y -c conda-forge 'ffmpeg<7'\n# Download pretrained weights https://huggingface.co/liuhuadai/ThinkSound to Directory ckpts/\n# model weights can be also downloaded from https://www.modelscope.cn/models/iic/ThinkSound\ngit lfs install\ngit clone https://huggingface.co/liuhuadai/ThinkSound ckpts\n# To improve inference and training speed, you may optionally install a FlashAttention backend compatible with your system and PyTorch version.\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 5,
    "Content": "\n> âœ… **Windows Tip:**  \n> Windows users can simply run `setup_windows.bat` (or double-click it) to automatically create the conda environment, install all dependencies (including FFmpeg), and download the pretrained model â€” no manual setup required.  \n> Make sure `conda` and `git` are installed and available in your system PATH before running the script.\n\n\n### â–¶ï¸ Run the Demo\n\n#### **Linux/macOS**\n",
    "ContentSha": "YGhm7lbBNPq6xLS6zXlFTPszO8rc4QZCwsScPNskcto=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "> âœ… **Ù†ØµÙŠØ­Ø© Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠ ÙˆÙŠÙ†Ø¯ÙˆØ²:**  \n> ÙŠÙ…ÙƒÙ† Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠ ÙˆÙŠÙ†Ø¯ÙˆØ² Ø¨Ø¨Ø³Ø§Ø·Ø© ØªØ´ØºÙŠÙ„ `setup_windows.bat` (Ø£Ùˆ Ø§Ù„Ù†Ù‚Ø± Ø§Ù„Ù…Ø²Ø¯ÙˆØ¬ Ø¹Ù„ÙŠÙ‡) Ù„Ø¥Ù†Ø´Ø§Ø¡ Ø¨ÙŠØ¦Ø© conda ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§ØŒ ÙˆØªØ«Ø¨ÙŠØª Ø¬Ù…ÙŠØ¹ Ø§Ù„ØªØ¨Ø¹ÙŠØ§Øª (Ø¨Ù…Ø§ ÙÙŠ Ø°Ù„Ùƒ FFmpeg)ØŒ ÙˆØªÙ†Ø²ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø¯Ø±Ø¨ Ù…Ø³Ø¨Ù‚Ù‹Ø§ â€” Ø¯ÙˆÙ† Ø§Ù„Ø­Ø§Ø¬Ø© Ù„Ù„Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ÙŠØ¯ÙˆÙŠ.  \n> ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† `conda` Ùˆ `git` Ù…Ø«Ø¨ØªØ§Ù† ÙˆÙ…ØªÙˆÙØ±Ø§Ù† ÙÙŠ Ù…ØªØºÙŠØ± PATH Ø§Ù„Ø®Ø§Øµ Ø¨Ø§Ù„Ù†Ø¸Ø§Ù… Ù‚Ø¨Ù„ ØªØ´ØºÙŠÙ„ Ø§Ù„Ø³ÙƒØ±Ø¨Øª.\n\n\n### â–¶ï¸ ØªØ´ØºÙŠÙ„ Ø§Ù„Ø¹Ø±Ø¶ Ø§Ù„ØªØ¬Ø±ÙŠØ¨ÙŠ\n\n#### **Ù„ÙŠÙ†ÙƒØ³/Ù…Ø§ÙƒOS**\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 6,
    "Content": "```bash\nchmod +x scripts/demo.sh\n./scripts/demo.sh <path-to-your-demo-video> <title> <CoT description> [use-half]\n```",
    "ContentSha": "EW6OKf+6hdOehT5SO7gfI7wR8oAoMckp60MRfIA1jHc=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\nchmod +x scripts/demo.sh\n./scripts/demo.sh <path-to-your-demo-video> <title> <CoT description> [use-half]\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 7,
    "Content": "\n#### **Windows**\n\nYou can use the provided `.bat` script instead:\n",
    "ContentSha": "zXqRZWTEWOuKZG1GOlqqZff+IH24zUwdPtSfwESqS9E=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "#### **ÙˆÙŠÙ†Ø¯ÙˆØ²**\n\nÙŠÙ…ÙƒÙ†Ùƒ Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ø°Ù„Ùƒ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬ Ø§Ù„Ù†ØµÙŠ `.bat` Ø§Ù„Ù…Ø±ÙÙ‚:\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 8,
    "Content": "```bash\n.\\scripts\\demo.bat <path-to-your-demo-video> <title> <CoT description> [use-half]\n```",
    "ContentSha": "A2a1kVuIPNs8ht1a6LBYTEijJjnfjiTN0r+2n7VEJSg=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\n.\\scripts\\demo.bat <path-to-your-demo-video> <title> <CoT description> [use-half]\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 9,
    "Content": "\n**Note:**\n\n* `<path-to-your-demo-video>`: The path to a single video\n* `[use-half]` (optional): Add use-half at the end to enable half precision feature extraction.\n\n---\n\n### ğŸ“¦ Batch Inference\n\n#### **Linux/macOS**\n",
    "ContentSha": "T7owm3ZZW7sVjKwFivgiuYX2+RVuNBl0RYTSnIcxxbM=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "**Ù…Ù„Ø§Ø­Ø¸Ø©:**\n\n* `<Ù…Ø³Ø§Ø±-ÙÙŠØ¯ÙŠÙˆ-Ø§Ù„Ø¹Ø±Ø¶-Ø§Ù„ØªÙˆØ¶ÙŠØ­ÙŠ-Ø§Ù„Ø®Ø§Øµ-Ø¨Ùƒ>`: Ù…Ø³Ø§Ø± ÙÙŠØ¯ÙŠÙˆ ÙˆØ§Ø­Ø¯\n* `[use-half]` (Ø§Ø®ØªÙŠØ§Ø±ÙŠ): Ø£Ø¶Ù use-half ÙÙŠ Ø§Ù„Ù†Ù‡Ø§ÙŠØ© Ù„ØªÙØ¹ÙŠÙ„ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø¨Ø¯Ù‚Ø© Ù†ØµÙÙŠØ©.\n\n---\n\n### ğŸ“¦ Ø§Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ø¹Ù„Ù‰ Ø¯ÙØ¹Ø§Øª\n\n#### **Ù„ÙŠÙ†ÙƒØ³/Ù…Ø§Ùƒ Ø£Ùˆ Ø¥Ø³**\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 10,
    "Content": "```bash\nchmod +x scripts/eval_batch.sh\n./scripts/eval_batch.sh <video_path> <csv_path> <save_path (optional)> [use-half]\n```",
    "ContentSha": "EQ4HuSYii55aHfgphESvOXMz2+Fq39+Xquxg6Z6uzdU=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\nchmod +x scripts/eval_batch.sh\n./scripts/eval_batch.sh <video_path> <csv_path> <save_path (optional)> [use-half]\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 11,
    "Content": "\n#### **Windows**\n\nUse the equivalent `.bat` script:\n",
    "ContentSha": "njm5i6o3MR7AV4Q3WLctbe3LN1njFn89fPfTlo+zSmc=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "#### **ÙˆÙŠÙ†Ø¯ÙˆØ²**\n\nØ§Ø³ØªØ®Ø¯Ù… Ø³ÙƒØ±Ø¨Øª `.bat` Ø§Ù„Ù…ÙƒØ§ÙØ¦:\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 12,
    "Content": "```bash\n.\\scripts\\eval_batch.bat <video_path> <csv_path> <save_path (optional)> [use-half]\n```",
    "ContentSha": "XLkAqxYBZeJiF6XnpshI6naENFsr5yFAH7af132cgb0=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\n.\\scripts\\eval_batch.bat <video_path> <csv_path> <save_path (optional)> [use-half]\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 13,
    "Content": "\n**Note:**\n\n* `<video_path>`: Path to the root directory containing all .mp4 videos to be processed (all videos must be of equal duration).\n* `<csv_path>`: A CSV file with text prompts for each video (see `demo_test.csv` for format).\n* `<save_path>` (optional): Where to save generated audio. Defaults to `results/features`.\n* `[use-half]` (optional): Add use-half at the end to enable half precision feature extraction.\n\n---\n\n\n### Web Interface Usage\n\nFor an interactive experience, launch the Gradio web interface:\n",
    "ContentSha": "yT/y6PXpYV8wS4qmKJfVNVGDLOwreTxCdCDFDv2VbLo=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "**Ù…Ù„Ø§Ø­Ø¸Ø©:**\n\n* `<video_path>`: Ù…Ø³Ø§Ø± Ø§Ù„Ø¯Ù„ÙŠÙ„ Ø§Ù„Ø¬Ø°Ø±ÙŠ Ø§Ù„Ø°ÙŠ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø¬Ù…ÙŠØ¹ Ù…Ù„ÙØ§Øª Ø§Ù„ÙÙŠØ¯ÙŠÙˆ .mp4 Ø§Ù„Ù…Ø±Ø§Ø¯ Ù…Ø¹Ø§Ù„Ø¬ØªÙ‡Ø§ (ÙŠØ¬Ø¨ Ø£Ù† ØªÙƒÙˆÙ† Ø¬Ù…ÙŠØ¹ Ø§Ù„ÙÙŠØ¯ÙŠÙˆÙ‡Ø§Øª Ø¨Ù†ÙØ³ Ø§Ù„Ù…Ø¯Ø©).\n* `<csv_path>`: Ù…Ù„Ù CSV ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù…Ø·Ø§Ù„Ø¨Ø§Øª Ù†ØµÙŠØ© Ù„ÙƒÙ„ ÙÙŠØ¯ÙŠÙˆ (Ø§Ù†Ø¸Ø± `demo_test.csv` Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„ØªÙ†Ø³ÙŠÙ‚).\n* `<save_path>` (Ø§Ø®ØªÙŠØ§Ø±ÙŠ): Ù…ÙƒØ§Ù† Ø­ÙØ¸ Ø§Ù„ØµÙˆØª Ø§Ù„Ù†Ø§ØªØ¬. Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ Ù‡Ùˆ `results/features`.\n* `[use-half]` (Ø§Ø®ØªÙŠØ§Ø±ÙŠ): Ø£Ø¶Ù use-half ÙÙŠ Ø§Ù„Ù†Ù‡Ø§ÙŠØ© Ù„ØªÙ…ÙƒÙŠÙ† Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø¨Ù†ØµÙ Ø§Ù„Ø¯Ù‚Ø©.\n\n---\n\n\n### Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„ÙˆÙŠØ¨\n\nÙ„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØªØ¬Ø±Ø¨Ø© ØªÙØ§Ø¹Ù„ÙŠØ©ØŒ Ù‚Ù… Ø¨ØªØ´ØºÙŠÙ„ ÙˆØ§Ø¬Ù‡Ø© Gradio Ø¹Ù„Ù‰ Ø§Ù„ÙˆÙŠØ¨:\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 14,
    "Content": "```bash\npython app.py\n```",
    "ContentSha": "2nQFYMHYtsOO4+egbu20DhxqoaxfzoH8CneeM8qTEb0=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\npython app.py\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 15,
    "Content": "\n\n## ğŸ‹ï¸ Train the Model\n\nSee [`Training.md`](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/docs/Training.md)\n\n\n---\n\n## ğŸ“ TODO & Future Plans\n* - [ ] Release a more powerful foundation model covering multiple domains to provide more engaging and immersive foley creation\n* - [ ] Add support for additional modalities and downstream tasks\n* - [ ] Release models at different scales\n* - [x] Open-source AudioCoT dataset and automated pipeline\n* - [x] Release training scripts for ThinkSound models\n* - [x] A beginner-friendly Windows quick-start README\n---\n\n\n## ğŸ“„ License\n\nThis project is released under the Apache 2.0 License.\n\n> **Note:**\n> The code, models, and dataset are **for research and educational purposes only**.\n> **Commercial use is NOT permitted.**\n> For commercial licensing, please contact the authors.\n\n**ğŸ“¦ Third-Party Components**\n\n* **Stable Audio Open VAE** (by Stability AI):\n  This repository includes a fine-tuned VAE from [Stable Audio Open](https://huggingface.co/stabilityai/stable-audio-open-1.0/), licensed under the [Stability AI Community License](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/./third_party/LICENSE_StabilityAI.md).\n  **Commercial use and redistribution require prior permission from Stability AI.**\n\n* ğŸ“˜ **All other code and models** are released under the Apache License 2.0.\n\n---\n\n## Acknowledgements\n",
    "ContentSha": "j3jq6Afpr38oSd7nSvDiMiQ889Z6kSywM0DVVT9ieNA=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "\n\n## ğŸ‹ï¸ ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬\n\nØ±Ø§Ø¬Ø¹ [`Training.md`](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/docs/Training.md)\n\n\n---\n\n## ğŸ“ Ø§Ù„Ù…Ù‡Ø§Ù… Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠØ© ÙˆØ®Ø·Ø· Ø§Ù„Ø¹Ù…Ù„\n* - [ ] Ø¥ØµØ¯Ø§Ø± Ù†Ù…ÙˆØ°Ø¬ Ø£Ø³Ø§Ø³ÙŠ Ø£ÙƒØ«Ø± Ù‚ÙˆØ© ÙŠØºØ·ÙŠ Ù…Ø¬Ø§Ù„Ø§Øª Ù…ØªØ¹Ø¯Ø¯Ø© Ù„ØªÙˆÙÙŠØ± Ø¥Ù†Ø´Ø§Ø¡ ÙÙˆÙ„ÙŠ Ø£ÙƒØ«Ø± Ø¬Ø§Ø°Ø¨ÙŠØ© ÙˆØ§Ù†ØºÙ…Ø§Ø³Ù‹Ø§\n* - [ ] Ø¥Ø¶Ø§ÙØ© Ø¯Ø¹Ù… Ù„Ø£Ù†Ù…Ø§Ø· Ø¥Ø¶Ø§ÙÙŠØ© ÙˆÙ…Ù‡Ø§Ù… Ù„Ø§Ø­Ù‚Ø©\n* - [ ] Ø¥ØµØ¯Ø§Ø± Ù†Ù…Ø§Ø°Ø¬ Ø¨Ù…Ù‚Ø§ÙŠÙŠØ³ Ù…Ø®ØªÙ„ÙØ©\n* - [x] ÙØªØ­ Ù…ØµØ¯Ø± Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª AudioCoT ÙˆØ®Ø· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨ Ø§Ù„Ù…Ø¤ØªÙ…Øª\n* - [x] Ø¥ØµØ¯Ø§Ø± Ù†ØµÙˆØµ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ù„Ù†Ù…Ø§Ø°Ø¬ ThinkSound\n* - [x] Ù…Ù„Ù README Ù„Ù„Ø¨Ø¯Ø¡ Ø§Ù„Ø³Ø±ÙŠØ¹ ÙÙŠ ÙˆÙŠÙ†Ø¯ÙˆØ² Ù„Ù„Ù…Ø¨ØªØ¯Ø¦ÙŠÙ†\n---\n\n\n## ğŸ“„ Ø§Ù„ØªØ±Ø®ÙŠØµ\n\nØªÙ… Ø¥ØµØ¯Ø§Ø± Ù‡Ø°Ø§ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ Ø¨Ù…ÙˆØ¬Ø¨ ØªØ±Ø®ÙŠØµ Ø£Ø¨Ø§ØªØ´ÙŠ 2.0.\n\n> **Ù…Ù„Ø§Ø­Ø¸Ø©:**\n> Ø§Ù„ÙƒÙˆØ¯ØŒ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ØŒ ÙˆÙ…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª **Ù„Ø£ØºØ±Ø§Ø¶ Ø§Ù„Ø¨Ø­Ø« ÙˆØ§Ù„ØªØ¹Ù„ÙŠÙ… ÙÙ‚Ø·**.\n> **Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ØªØ¬Ø§Ø±ÙŠ ØºÙŠØ± Ù…Ø³Ù…ÙˆØ­ Ø¨Ù‡.**\n> Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØªØ±Ø®ÙŠØµ ØªØ¬Ø§Ø±ÙŠØŒ ÙŠØ±Ø¬Ù‰ Ø§Ù„ØªÙˆØ§ØµÙ„ Ù…Ø¹ Ø§Ù„Ù…Ø¤Ù„ÙÙŠÙ†.\n\n**ğŸ“¦ Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª Ø§Ù„Ø®Ø§Ø±Ø¬ÙŠØ©**\n\n* **Stable Audio Open VAE** (Ø¨ÙˆØ§Ø³Ø·Ø© Stability AI):\n  ÙŠØªØ¶Ù…Ù† Ù‡Ø°Ø§ Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹ Ù†Ù…ÙˆØ°Ø¬ VAE Ù…Ø¶Ø¨ÙˆØ· Ø¨Ø¯Ù‚Ø© Ù…Ù† [Stable Audio Open](https://huggingface.co/stabilityai/stable-audio-open-1.0/)ØŒ ÙˆÙ…Ø±Ø®Øµ Ø¨Ù…ÙˆØ¬Ø¨ [ØªØ±Ø®ÙŠØµ Ù…Ø¬ØªÙ…Ø¹ Stability AI](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/./third_party/LICENSE_StabilityAI.md).\n  **Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ØªØ¬Ø§Ø±ÙŠ ÙˆØ¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªÙˆØ²ÙŠØ¹ ÙŠØªØ·Ù„Ø¨Ø§Ù† Ø¥Ø°Ù†Ù‹Ø§ Ù…Ø³Ø¨Ù‚Ù‹Ø§ Ù…Ù† Stability AI.**\n\n* ğŸ“˜ **Ø¬Ù…ÙŠØ¹ Ø§Ù„ÙƒÙˆØ¯Ø§Øª ÙˆØ§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø£Ø®Ø±Ù‰** ØªÙ… Ø¥ØµØ¯Ø§Ø±Ù‡Ø§ Ø¨Ù…ÙˆØ¬Ø¨ ØªØ±Ø®ÙŠØµ Ø£Ø¨Ø§ØªØ´ÙŠ 2.0.\n\n---\n\n## Ø§Ù„Ø´ÙƒØ± ÙˆØ§Ù„ØªÙ‚Ø¯ÙŠØ±\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 16,
    "Content": "Many thanks to:\n\n* **stable-audio-tools** (by Stability AI):\nFor providing an easy-to-use framework for audio generation, as well as the VAE module and weights.\n* **MMAudio**:\n  For the implementation of the MM-DiT backbone in the audio domain.\n\n---\n\n## ğŸ“– Citation\n\nIf you find ThinkSound useful in your research or work, please cite our paper:\n",
    "ContentSha": "FsK5U++tkthvkZ/Gd4G7gn74YKpB282Oxnkt96u9C1k=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "Ø´ÙƒØ±Ø§Ù‹ Ø¬Ø²ÙŠÙ„Ø§Ù‹ Ù„Ù€:\n\n* **stable-audio-tools** (Ù…Ù† Ù‚Ø¨Ù„ Stability AI):\nÙ„ØªÙˆÙÙŠØ± Ø¥Ø·Ø§Ø± Ø¹Ù…Ù„ Ø³Ù‡Ù„ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù„ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØªØŒ Ø¨Ø§Ù„Ø¥Ø¶Ø§ÙØ© Ø¥Ù„Ù‰ ÙˆØ­Ø¯Ø© VAE ÙˆØ§Ù„Ø£ÙˆØ²Ø§Ù†.\n* **MMAudio**:\n  Ù„ØªÙ†ÙÙŠØ° Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„ÙÙ‚Ø±ÙŠ MM-DiT ÙÙŠ Ù…Ø¬Ø§Ù„ Ø§Ù„ØµÙˆØª.\n\n---\n\n## ğŸ“– Ø§Ù„Ø§Ù‚ØªØ¨Ø§Ø³\n\nØ¥Ø°Ø§ ÙˆØ¬Ø¯Øª ThinkSound Ù…ÙÙŠØ¯Ø§Ù‹ ÙÙŠ Ø¨Ø­Ø«Ùƒ Ø£Ùˆ Ø¹Ù…Ù„ÙƒØŒ ÙŠØ±Ø¬Ù‰ Ø§Ù‚ØªØ¨Ø§Ø³ ÙˆØ±Ù‚ØªÙ†Ø§:\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 17,
    "Content": "```bibtex\n@misc{liu2025thinksoundchainofthoughtreasoningmultimodal,\n      title={ThinkSound: Chain-of-Thought Reasoning in Multimodal Large Language Models for Audio Generation and Editing}, \n      author={Huadai Liu and Jialei Wang and Kaicheng Luo and Wen Wang and Qian Chen and Zhou Zhao and Wei Xue},\n      year={2025},\n      eprint={2506.21448},\n      archivePrefix={arXiv},\n      primaryClass={eess.AS},\n      url={https://arxiv.org/abs/2506.21448}, \n}\n```",
    "ContentSha": "KKv35iBt6IDF1ifN04L+6lkh0BHkbObnW/+m50Wufrs=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bibtex\n@misc{liu2025thinksoundchainofthoughtreasoningmultimodal,\n      title={ThinkSound: Chain-of-Thought Reasoning in Multimodal Large Language Models for Audio Generation and Editing}, \n      author={Huadai Liu and Jialei Wang and Kaicheng Luo and Wen Wang and Qian Chen and Zhou Zhao and Wei Xue},\n      year={2025},\n      eprint={2506.21448},\n      archivePrefix={arXiv},\n      primaryClass={eess.AS},\n      url={https://arxiv.org/abs/2506.21448}, \n}\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 18,
    "Content": "\n---\n\n## ğŸ“¬ Contact\n\n\nâœ¨ Feel free to [open an issue](https://github.com/liuhuadai/ThinkSound/issues) or contact us via email ([liuhuadai@zju.edu.cn](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/mailto:liuhuadai@zju.edu.cn)) if you have any questions or suggestions!\n\n\n",
    "ContentSha": "QMNRHPzbmsL2YxrLNEPneJCBrTj4/XiY9XGTX01NZl8=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "\n---\n\n## ğŸ“¬ Contact\n\n\nâœ¨ Feel free to [open an issue](https://github.com/liuhuadai/ThinkSound/issues) or contact us via email ([liuhuadai@zju.edu.cn](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/mailto:liuhuadai@zju.edu.cn)) if you have any questions or suggestions!\n\n\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 2,
        "rowsha": "yz+R1U7uMOU+NbK5mQX3Dxae1Un9eJCdPawt78ntjTs=",
        "originContent": "---",
        "translatedContent": "---"
      },
      {
        "row": 3,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 4,
        "rowsha": "V0ea1xQLKG+cGj5kHVv5f15HDd+yj0ulkcBQnvErdJc=",
        "originContent": "## ğŸ“¬ Contact",
        "translatedContent": "## ğŸ“¬ Contact"
      },
      {
        "row": 5,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 6,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 7,
        "rowsha": "QsDuVwX1DXlTNejKuNftx4k1x7yNHjfP9/1HS85hJng=",
        "originContent": "âœ¨ Feel free to [open an issue](https://github.com/liuhuadai/ThinkSound/issues) or contact us via email ([liuhuadai@zju.edu.cn](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/mailto:liuhuadai@zju.edu.cn)) if you have any questions or suggestions!",
        "translatedContent": "âœ¨ Feel free to [open an issue](https://github.com/liuhuadai/ThinkSound/issues) or contact us via email ([liuhuadai@zju.edu.cn](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/mailto:liuhuadai@zju.edu.cn)) if you have any questions or suggestions!"
      },
      {
        "row": 8,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 9,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 10,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  }
]