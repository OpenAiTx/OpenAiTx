# üé∂ ThinkSound

<p align="center">
  Se voc√™ achar este projeto √∫til, uma estrela ‚≠ê no GitHub ser√° muito apreciada!
</p>

<p align="center">
  <a href="https://arxiv.org/pdf/2506.21448">
    <img src="https://img.shields.io/badge/arXiv-2506.21448-b31b1b.svg" alt="arXiv"/>
  </a>
  &nbsp;
  <a href="https://thinksound-project.github.io/">
    <img src="https://img.shields.io/badge/Online%20Demo-üåê-blue" alt="Online Demo"/>
  </a>
  &nbsp;
  <a href="https://huggingface.co/spaces/FunAudioLLM/ThinkSound">
    <img src="https://img.shields.io/badge/HuggingFace-Spaces-orange?logo=huggingface" alt="Hugging Face"/>
  </a>
  &nbsp;
  <a href="https://modelscope.cn/studios/iic/ThinkSound">
    <img src="https://img.shields.io/badge/ModelScope-Âú®Á∫ø‰ΩìÈ™å-green" alt="ModelScope"/>
  </a>
</p>

---

**ThinkSound** √© uma estrutura unificada de gera√ß√£o Any2Audio com correspond√™ncia de fluxo guiada por racioc√≠nio Chain-of-Thought (CoT).

Implementa√ß√£o em PyTorch para gera√ß√£o e edi√ß√£o de √°udio multimodal: gere ou edite √°udio a partir de v√≠deo, texto e √°udio, impulsionado por racioc√≠nio passo a passo de Grandes Modelos de Linguagem Multimodal (MLLMs).

![Teaser](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig1_teaser.png)
---

## üì∞ Novidades
- **2025.07** &nbsp; üî•Demo online em [Hugging Face Spaces](https://huggingface.co/spaces/FunAudioLLM/ThinkSound) e [ModelScope](https://modelscope.cn/studios/iic/ThinkSound) para experi√™ncia interativa!
- **2025.07** &nbsp; üî•Scripts de infer√™ncia e interface web lan√ßados;
- **2025.06** &nbsp; üî•[Artigo ThinkSound](https://arxiv.org/pdf/2506.21448) publicado no arXiv!
- **2025.06** &nbsp; üî•[Demo Online](http://thinksound-project.github.io/) dispon√≠vel - experimente agora!

---

## üöÄ Funcionalidades

- **Any2Audio**: Gere √°udio a partir de modalidades arbitr√°rias ‚Äî v√≠deo, texto, √°udio ou suas combina√ß√µes.
- **Video-to-Audio SOTA**: Alcan√ßa resultados de ponta em m√∫ltiplos benchmarks V2A.
- **Racioc√≠nio CoT-Driven**: Racioc√≠nio Chain-of-Thought para gera√ß√£o de √°udio composicional e control√°vel via MLLMs.
- **Edi√ß√£o Interativa Centrada em Objetos**: Refine ou edite eventos sonoros espec√≠ficos clicando em objetos visuais ou usando instru√ß√µes de texto.
- **Estrutura Unificada**: Um modelo de base suporta gera√ß√£o, edi√ß√£o e fluxo de trabalho interativo.

---

## ‚ú® Vis√£o Geral do M√©todo

ThinkSound decomp√µe a gera√ß√£o e edi√ß√£o de √°udio em tr√™s etapas interativas, todas guiadas por racioc√≠nio Chain-of-Thought (CoT) baseado em MLLM:

1. **Gera√ß√£o Foley:** Gera√ß√£o de paisagens sonoras fundamentais, semanticamente e temporalmente alinhadas a partir do v√≠deo.
2. **Refinamento Centrado em Objetos:** Refine ou adicione sons para objetos especificados pelo usu√°rio via cliques ou regi√µes no v√≠deo.
3. **Edi√ß√£o de √Åudio Direcionada:** Modifique o √°udio gerado usando instru√ß√µes em linguagem natural de alto n√≠vel.

![ThinkSound Overview](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig3_model.png)
<!-- Um conjunto de dados em larga escala anotado com CoT (**AudioCoT**) √© usado para treinar tanto o m√≥dulo de racioc√≠nio quanto o modelo de base de √°udio unificado.
![AudioCoT Pipeline](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig2_dataset.png) -->

---

## ‚ö° In√≠cio R√°pido

**Prepara√ß√£o do Ambiente:**
```bash
git clone https://github.com/liuhuadai/ThinkSound.git
cd ThinkSound
pip install -r requirements.txt
conda install -y -c conda-forge 'ffmpeg<7'
# Baixe os pesos pr√©-treinados em https://huggingface.co/liuhuadai/ThinkSound para o diret√≥rio ckpts/
# Os pesos do modelo tamb√©m podem ser baixados de https://www.modelscope.cn/models/iic/ThinkSound
git lfs install
git clone https://huggingface.co/liuhuadai/ThinkSound ckpts
```

**Torne execut√°vel**
```bash
chmod +x scripts/demo.sh
```

**Execute o script**
```bash
./scripts/demo.sh <video_path> <caption> <CoT description>
```


### Uso da Interface Web

Para uma experi√™ncia interativa, inicie a interface web Gradio:

```bash
python app.py
```

---
## üìù TODO

- ‚òê Liberar scripts de treinamento para os modelos ThinkSound
- ‚òê Tornar open-source o conjunto de dados AudioCoT e o pipeline automatizado
- ‚òê Fornecer documenta√ß√£o detalhada e refer√™ncia da API
- ‚òê Adicionar suporte para modalidades adicionais e tarefas downstream

---

## üìÑ Licen√ßa

Este projeto √© disponibilizado sob a [Licen√ßa Apache 2.0](LICENSE).

> **Nota:**  
> O c√≥digo, os modelos e o conjunto de dados s√£o **apenas para fins de pesquisa e educa√ß√£o**.  
> **O uso comercial N√ÉO √© permitido.**
>
> Para licenciamento comercial, por favor, entre em contato com os autores.

---

## üìñ Cita√ß√£o

Se voc√™ achar o ThinkSound √∫til em sua pesquisa ou trabalho, por favor cite nosso artigo:

```bibtex
@misc{liu2025thinksoundchainofthoughtreasoningmultimodal,
      title={ThinkSound: Chain-of-Thought Reasoning in Multimodal Large Language Models for Audio Generation and Editing}, 
      author={Huadai Liu and Jialei Wang and Kaicheng Luo and Wen Wang and Qian Chen and Zhou Zhao and Wei Xue},
      year={2025},
      eprint={2506.21448},
      archivePrefix={arXiv},
      primaryClass={eess.AS},
      url={https://arxiv.org/abs/2506.21448}, 
}
```

---

## üì¨ Contato

‚ú® Sinta-se √† vontade para [abrir uma issue](https://github.com/liuhuadai/ThinkSound/issues) ou entrar em contato conosco por e-mail ([liuhuadai@zju.edu.cn](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/mailto:liuhuadai@zju.edu.cn)) se tiver qualquer d√∫vida ou sugest√£o!

---

Tranlated By [Open Ai Tx](https://github.com/OpenAiTx/OpenAiTx) | Last indexed: 2025-07-03

---