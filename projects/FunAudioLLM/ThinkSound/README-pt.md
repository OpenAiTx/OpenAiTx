<h1 align="center">ThinkSound</h1>

<p align="center">
  üåê
  <a href="https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=en">English</a> |
  <a href="https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=zh-CN">ÁÆÄ‰Ωì‰∏≠Êñá</a> |
  <a href="https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=zh-TW">ÁπÅÈ´î‰∏≠Êñá</a> |
  <a href="https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=es">Espa√±ol</a> |
  <a href="https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=fr">Fran√ßais</a> |
  <a href="https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=ja">Êó•Êú¨Ë™û</a>
  
</p>
<p align="center">
  <img src="https://img.shields.io/badge/NeurIPS 2025-Main Conference-blue.svg" alt="NeurIPS 2025"/>
<p align="center">
  <a href="https://arxiv.org/pdf/2506.21448">
    <img src="https://img.shields.io/badge/arXiv-2506.21448-b31b1b.svg" alt="arXiv"/>
  </a>
  &nbsp;
  <a href="https://thinksound-project.github.io/">
    <img src="https://img.shields.io/badge/Online%20Demo-üåê-blue" alt="Online Demo"/>
  </a>
  &nbsp;
  <a href="https://huggingface.co/spaces/FunAudioLLM/ThinkSound">
    <img src="https://img.shields.io/badge/HuggingFace-Spaces-orange?logo=huggingface" alt="Hugging Face"/>
  </a>
  &nbsp;
  <a href="https://modelscope.cn/studios/iic/ThinkSound">
    <img src="https://img.shields.io/badge/ModelScope-Âú®Á∫ø‰ΩìÈ™å-green" alt="ModelScope"/>
  </a>
</p>

<p align="center">
  Se voc√™ achar este projeto √∫til,<br>
  um star ‚≠ê no GitHub seria muito apreciado!
</p>

---

**ThinkSound** √© uma estrutura unificada de gera√ß√£o Any2Audio com fluxo guiado por racioc√≠nio Chain-of-Thought (CoT).

Implementa√ß√£o PyTorch para gera√ß√£o e edi√ß√£o multimodal de √°udio: gere ou edite √°udio a partir de v√≠deo, texto e √°udio, impulsionado por racioc√≠nio passo a passo de Modelos Multimodais de Linguagem de Grande Escala (MLLMs).

![Teaser](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig1_teaser.png)
---

## üì∞ Novidades
- **2025.11.25** &nbsp; üî•[Demo Online do PrismAudio](http://prismaudio-project.github.io/) est√° dispon√≠vel - experimente agora!
- **2025.11.25** &nbsp; üî•[Artigo PrismAudio](https://arxiv.org/pdf/2511.18833) publicado no arXiv, o primeiro framework multi-dimensional CoT-RL para Gera√ß√£o de √Åudio a partir de V√≠deo!
- **2025.09.19** &nbsp; üéâ ThinkSound foi aceito na **Confer√™ncia Principal NeurIPS 2025**!
- **2025.09.01** &nbsp; Nosso conjunto de dados AudioCoT agora √© open-source e est√° dispon√≠vel no [Hugging Face](https://huggingface.co/datasets/liuhuadai/AudioCoT)!
- **2025.07.17** &nbsp; üß† Fine-tuning habilitado: c√≥digo de treinamento e ajuste fino agora dispon√≠vel publicamente, com instru√ß√µes claras para ajudar voc√™ a customizar e expandir o ThinkSound com seus pr√≥prios dados.
- **2025.07.15** &nbsp; üì¶ Instala√ß√£o e usabilidade simplificadas: depend√™ncias no PyPI para f√°cil configura√ß√£o multiplataforma; scripts `.bat` para Windows automatizam a cria√ß√£o do ambiente e execu√ß√£o dos scripts.
- **2025.07.08** &nbsp;¬† üîß Atualiza√ß√£o principal: modelo mais leve e otimiza√ß√£o de mem√≥ria e uso de GPU, agora suporta gera√ß√£o de √°udio em larga escala com alto rendimento!
- **2025.07.01** &nbsp; Demo online no [Hugging Face Spaces](https://huggingface.co/spaces/FunAudioLLM/ThinkSound) e [ModelScope](https://modelscope.cn/studios/iic/ThinkSound) para experi√™ncia interativa!
- **2025.07.01** &nbsp; Scripts de infer√™ncia e interface web lan√ßados; 
- **2025.06** &nbsp; [Artigo ThinkSound](https://arxiv.org/pdf/2506.21448) publicado no arXiv!
- **2025.06** &nbsp; [Demo Online](http://thinksound-project.github.io/) est√° dispon√≠vel - experimente agora!

---


## üöÄ Funcionalidades

- **Any2Audio**: Gere √°udio a partir de modalidades arbitr√°rias ‚Äî v√≠deo, texto, √°udio ou suas combina√ß√µes.
- **Video-para-√Åudio SOTA**: Alcan√ßa resultados de ponta em m√∫ltiplos benchmarks V2A.
- **Racioc√≠nio Guiado por CoT**: Racioc√≠nio Chain-of-Thought para gera√ß√£o de √°udio composicional e control√°vel via MLLMs.
- **Edi√ß√£o Interativa Centrada em Objetos**: Refine ou edite eventos sonoros espec√≠ficos clicando em objetos visuais ou usando instru√ß√µes de texto.
- **Framework Unificado**: Um modelo base suporta gera√ß√£o, edi√ß√£o e fluxo de trabalho interativo.

---

## ‚ú® Vis√£o Geral do M√©todo

ThinkSound decomp√µe a gera√ß√£o e edi√ß√£o de √°udio em tr√™s etapas interativas, todas guiadas por racioc√≠nio Chain-of-Thought (CoT) baseado em MLLM:

1. **Gera√ß√£o Foley:** Gera paisagens sonoras fundamentais, semanticamente e temporalmente alinhadas a partir do v√≠deo.
2. **Refinamento Centrado em Objetos:** Refina ou adiciona sons para objetos especificados pelo usu√°rio via cliques ou regi√µes no v√≠deo.
3. **Edi√ß√£o de √Åudio Direcionada:** Modifica o √°udio gerado usando instru√ß√µes de linguagem natural de alto n√≠vel.

![Vis√£o Geral do ThinkSound](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig3_model.png)
<!-- Um conjunto de dados anotados em larga escala CoT (**AudioCoT**) √© usado para treinar tanto o m√≥dulo de racioc√≠nio quanto o modelo de base unificado de √°udio.
![Pipeline AudioCoT](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig2_dataset.png) -->

---

## ‚ö° In√≠cio R√°pido

**Prepara√ß√£o do Ambiente:**
```bash
git clone https://github.com/liuhuadai/ThinkSound.git
cd ThinkSound
conda create -n thinksound python=3.10
conda activate thinksound
pip install thinksound
conda install -y -c conda-forge 'ffmpeg<7'
# Download pretrained weights https://huggingface.co/liuhuadai/ThinkSound to Directory ckpts/
# model weights can be also downloaded from https://www.modelscope.cn/models/iic/ThinkSound
git lfs install
git clone https://huggingface.co/liuhuadai/ThinkSound ckpts
# To improve inference and training speed, you may optionally install a FlashAttention backend compatible with your system and PyTorch version.
```
> ‚úÖ **Dica para Windows:**  
> Usu√°rios do Windows podem simplesmente executar `setup_windows.bat` (ou dar um duplo clique) para criar automaticamente o ambiente conda, instalar todas as depend√™ncias (incluindo o FFmpeg) e baixar o modelo pr√©-treinado ‚Äî n√£o √© necess√°rio configura√ß√£o manual.  
> Certifique-se de que `conda` e `git` estejam instalados e dispon√≠veis no PATH do sistema antes de executar o script.


### ‚ñ∂Ô∏è Execute a Demonstra√ß√£o

#### **Linux/macOS**


```bash
chmod +x scripts/demo.sh
./scripts/demo.sh <path-to-your-demo-video> <title> <CoT description> [use-half]
```
#### **Windows**

Voc√™ pode usar o script `.bat` fornecido em vez disso:


```bash
.\scripts\demo.bat <path-to-your-demo-video> <title> <CoT description> [use-half]
```
**Nota:**

* `<caminho-para-seu-v√≠deo-demo>`: O caminho para um √∫nico v√≠deo
* `[use-half]` (opcional): Adicione use-half ao final para ativar a extra√ß√£o de recursos em precis√£o reduzida.

---

### üì¶ Infer√™ncia em Lote

#### **Linux/macOS**


```bash
chmod +x scripts/eval_batch.sh
./scripts/eval_batch.sh <video_path> <csv_path> <save_path (optional)> [use-half]
```
#### **Windows**

Use o script `.bat` equivalente:


```bash
.\scripts\eval_batch.bat <video_path> <csv_path> <save_path (optional)> [use-half]
```
**Nota:**

* `<video_path>`: Caminho para o diret√≥rio raiz contendo todos os v√≠deos .mp4 a serem processados (todos os v√≠deos devem ter a mesma dura√ß√£o).
* `<csv_path>`: Um arquivo CSV com prompts de texto para cada v√≠deo (veja `demo_test.csv` para o formato).
* `<save_path>` (opcional): Onde salvar o √°udio gerado. O padr√£o √© `results/features`.
* `[use-half]` (opcional): Adicione use-half ao final para habilitar a extra√ß√£o de recursos em meia precis√£o.

---


### Uso da Interface Web

Para uma experi√™ncia interativa, inicie a interface web do Gradio:


```bash
python app.py
```


## üèãÔ∏è Treinar o Modelo

Veja [`Training.md`](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/docs/Training.md)


---

## üìù TODO & Planos Futuros
* - [ ] Lan√ßar um modelo de funda√ß√£o mais poderoso cobrindo m√∫ltiplos dom√≠nios para oferecer cria√ß√£o de foley mais envolvente e imersiva
* - [ ] Adicionar suporte para modalidades adicionais e tarefas downstream
* - [ ] Lan√ßar modelos em diferentes escalas
* - [x] Open-source do conjunto de dados AudioCoT e pipeline automatizado
* - [x] Lan√ßar scripts de treinamento para os modelos ThinkSound
* - [x] Um README de in√≠cio r√°pido para Windows, amig√°vel para iniciantes
---


## üìÑ Licen√ßa

Este projeto √© lan√ßado sob a Licen√ßa Apache 2.0.

> **Nota:**
> O c√≥digo, modelos e conjunto de dados s√£o **apenas para fins de pesquisa e educa√ß√£o**.
> **Uso comercial N√ÉO √© permitido.**
> Para licenciamento comercial, entre em contato com os autores.

**üì¶ Componentes de Terceiros**

* **Stable Audio Open VAE** (por Stability AI):
  Este reposit√≥rio inclui um VAE ajustado do [Stable Audio Open](https://huggingface.co/stabilityai/stable-audio-open-1.0/), licenciado sob a [Licen√ßa de Comunidade Stability AI](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/./third_party/LICENSE_StabilityAI.md).
  **Uso comercial e redistribui√ß√£o requerem permiss√£o pr√©via da Stability AI.**

* üìò **Todo o restante do c√≥digo e modelos** s√£o lan√ßados sob a Licen√ßa Apache 2.0.

---

## Agradecimentos

Muito obrigado a:

* **stable-audio-tools** (por Stability AI):
Por fornecer uma estrutura de f√°cil utiliza√ß√£o para gera√ß√£o de √°udio, bem como o m√≥dulo VAE e os pesos.
* **MMAudio**:
  Pela implementa√ß√£o do backbone MM-DiT no dom√≠nio de √°udio.

---

## üìñ Cita√ß√£o

Se voc√™ achar o ThinkSound √∫til em sua pesquisa ou trabalho, por favor cite nosso artigo:

```bibtex
@misc{liu2025thinksoundchainofthoughtreasoningmultimodal,
      title={ThinkSound: Chain-of-Thought Reasoning in Multimodal Large Language Models for Audio Generation and Editing}, 
      author={Huadai Liu and Jialei Wang and Kaicheng Luo and Wen Wang and Qian Chen and Zhou Zhao and Wei Xue},
      year={2025},
      eprint={2506.21448},
      archivePrefix={arXiv},
      primaryClass={eess.AS},
      url={https://arxiv.org/abs/2506.21448}, 
}
```

---

## üì¨ Contact


‚ú® Feel free to [open an issue](https://github.com/liuhuadai/ThinkSound/issues) or contact us via email ([liuhuadai@zju.edu.cn](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/mailto:liuhuadai@zju.edu.cn)) if you have any questions or suggestions!




---

Tranlated By [Open Ai Tx](https://github.com/OpenAiTx/OpenAiTx) | Last indexed: 2026-01-07

---