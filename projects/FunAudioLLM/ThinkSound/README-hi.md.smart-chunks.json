[
  {
    "Id": 1,
    "Content": "<h1 align=\"center\">ThinkSound</h1>\n\n<p align=\"center\">\n  ЁЯМР\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=en\">English</a> |\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=zh-CN\">чоАф╜Уф╕нцЦЗ</a> |\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=zh-TW\">ч╣БщлФф╕нцЦЗ</a> |\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=es\">Espa├▒ol</a> |\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=fr\">Fran├зais</a> |\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=ja\">цЧецЬмшкЮ</a>\n  \n</p>\n<p align=\"center\">\n  <img src=\"https://img.shields.io/badge/NeurIPS 2025-Main Conference-blue.svg\" alt=\"NeurIPS 2025\"/>\n<p align=\"center\">\n  <a href=\"https://arxiv.org/pdf/2506.21448\">\n    <img src=\"https://img.shields.io/badge/arXiv-2506.21448-b31b1b.svg\" alt=\"arXiv\"/>\n  </a>\n  &nbsp;\n  <a href=\"https://thinksound-project.github.io/\">\n    <img src=\"https://img.shields.io/badge/Online%20Demo-ЁЯМР-blue\" alt=\"Online Demo\"/>\n  </a>\n  &nbsp;\n  <a href=\"https://huggingface.co/spaces/FunAudioLLM/ThinkSound\">\n    <img src=\"https://img.shields.io/badge/HuggingFace-Spaces-orange?logo=huggingface\" alt=\"Hugging Face\"/>\n  </a>\n  &nbsp;\n  <a href=\"https://modelscope.cn/studios/iic/ThinkSound\">\n    <img src=\"https://img.shields.io/badge/ModelScope-хЬич║┐ф╜УщкМ-green\" alt=\"ModelScope\"/>\n  </a>\n</p>\n\n<p align=\"center\">\n  If you find this project useful,<br>\n  a star тнР on GitHub would be greatly appreciated!\n</p>\n\n---\n\n**ThinkSound** is a unified Any2Audio generation framework with flow matching guided by Chain-of-Thought (CoT) reasoning.",
    "ContentSha": "3764VshEOMedejxsV+uo8k5R5Emk0MLuYfIOX8JadcY=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "<h1 align=\"center\">ThinkSound</h1>\n\n<p align=\"center\">\n  ЁЯМР\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=en\">English</a> |\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=zh-CN\">чоАф╜Уф╕нцЦЗ</a> |\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=zh-TW\">ч╣БщлФф╕нцЦЗ</a> |\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=es\">Espa├▒ol</a> |\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=fr\">Fran├зais</a> |\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=ja\">цЧецЬмшкЮ</a>\n  \n</p>\n<p align=\"center\">\n  <img src=\"https://img.shields.io/badge/NeurIPS 2025-Main Conference-blue.svg\" alt=\"NeurIPS 2025\"/>\n<p align=\"center\">\n  <a href=\"https://arxiv.org/pdf/2506.21448\">\n    <img src=\"https://img.shields.io/badge/arXiv-2506.21448-b31b1b.svg\" alt=\"arXiv\"/>\n  </a>\n  &nbsp;\n  <a href=\"https://thinksound-project.github.io/\">\n    <img src=\"https://img.shields.io/badge/Online%20Demo-ЁЯМР-blue\" alt=\"Online Demo\"/>\n  </a>\n  &nbsp;\n  <a href=\"https://huggingface.co/spaces/FunAudioLLM/ThinkSound\">\n    <img src=\"https://img.shields.io/badge/HuggingFace-Spaces-orange?logo=huggingface\" alt=\"Hugging Face\"/>\n  </a>\n  &nbsp;\n  <a href=\"https://modelscope.cn/studios/iic/ThinkSound\">\n    <img src=\"https://img.shields.io/badge/ModelScope-хЬич║┐ф╜УщкМ-green\" alt=\"ModelScope\"/>\n  </a>\n</p>\n\n<p align=\"center\">\n  рдпрджрд┐ рдЖрдкрдХреЛ рдпрд╣ рдкреНрд░реЛрдЬреЗрдХреНрдЯ рдЙрдкрдпреЛрдЧреА рд▓рдЧреЗ,<br>\n  GitHub рдкрд░ рдПрдХ рд╕реНрдЯрд╛рд░ тнР рджреЗрдирд╛ рдЕрддреНрдпрдВрдд рд╕рд░рд╛рд╣рдиреАрдп рд╣реЛрдЧрд╛!\n</p>\n\n---\n\n**ThinkSound** рдПрдХ рдПрдХреАрдХреГрдд Any2Audio рдЬрдирд░реЗрд╢рди рдлреНрд░реЗрдорд╡рд░реНрдХ рд╣реИ, рдЬрд┐рд╕рдореЗрдВ Chain-of-Thought (CoT) рд░реАрдЬрдирд┐рдВрдЧ рджреНрд╡рд╛рд░рд╛ рдлреНрд▓реЛ рдореИрдЪрд┐рдВрдЧ рдХрд╛ рдорд╛рд░реНрдЧрджрд░реНрд╢рди рдХрд┐рдпрд╛ рдЬрд╛рддрд╛ рд╣реИред",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 2,
    "Content": "\nPyTorch implementation for multimodal audio generation and editing: generate or edit audio from video, text, and audio, powered by step-by-step reasoning from Multimodal Large Language Models (MLLMs).\n\n![Teaser](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig1_teaser.png)\n---\n\n## ЁЯУ░ News\n- **2025.11.25** &nbsp; ЁЯФе[Online PrismAudio Demo](http://prismaudio-project.github.io/) is live - try it now!\n- **2025.11.25** &nbsp; ЁЯФе[PrismAudio paper](https://arxiv.org/pdf/2511.18833) released on arXiv, the first multi-dimensional CoT-RL framework for Video-to-Audio Generation!\n- **2025.09.19** &nbsp; ЁЯОЙ ThinkSound has been accepted to the **NeurIPS 2025 Main Conference**!\n- **2025.09.01** &nbsp; Our AudioCoT dataset is now open-sourced and available on [Hugging Face](https://huggingface.co/datasets/liuhuadai/AudioCoT)!\n- **2025.07.17** &nbsp; ЁЯза Finetuning enabled: training and finetuning code is now publicly available, along with clear usage instructions to help you customize and extend ThinkSound with your own data.\n- **2025.07.15** &nbsp; ЁЯУж Simplified installation and usability: dependencies on PyPI for easy cross-platform setup; Windows `.bat` scripts automate environment creation and script running.\n- **2025.07.08** &nbsp;┬а ЁЯФз Major update: model lightweighted and optimized memory and GPU usage, now supports high-throughput audio generation at scale!\n- **2025.07.01** &nbsp; Online demo on [Hugging Face Spaces](https://huggingface.co/spaces/FunAudioLLM/ThinkSound) and [ModelScope](https://modelscope.cn/studios/iic/ThinkSound) for interactive experience!\n- **2025.07.01** &nbsp; Released inference scripts and web interface; \n- **2025.06** &nbsp; [ThinkSound paper](https://arxiv.org/pdf/2506.21448) released on arXiv!\n- **2025.06** &nbsp; [Online Demo](http://thinksound-project.github.io/) is live - try it now!\n\n---\n\n\n## ЁЯЪА Features\n\n- **Any2Audio**: Generate audio from arbitrary modalities тАФ video, text, audio, or their combinations.\n- **Video-to-Audio SOTA**: Achieves state-of-the-art results on multiple V2A benchmarks.\n- **CoT-Driven Reasoning**: Chain-of-Thought reasoning for compositional and controllable audio generation via MLLMs.\n- **Interactive Object-centric Editing**: Refine or edit specific sound events by clicking on visual objects or using text instructions.\n- **Unified Framework**: One foundation model supports generation, editing, and interactive workflow.\n\n---\n\n## тЬи Method Overview\n\nThinkSound decomposes audio generation and editing into three interactive stages, all guided by MLLM-based Chain-of-Thought (CoT) reasoning:\n\n1. **Foley Generation:** Generate foundational, semantically and temporally aligned soundscapes from video.\n2. **Object-Centric Refinement:** Refine or add sounds for user-specified objects via clicks or regions in the video.\n3. **Targeted Audio Editing:** Modify generated audio using high-level natural language instructions.\n",
    "ContentSha": "Vp81xeUGr9WCESp62x1lkoIptJHl0dM1R8kleL4V10c=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "\nрдорд▓реНрдЯреАрдореЛрдбрд▓ рдСрдбрд┐рдпреЛ рдЬреЗрдирд░реЗрд╢рди рдФрд░ рдПрдбрд┐рдЯрд┐рдВрдЧ рдХреЗ рд▓рд┐рдП PyTorch рдЗрдореНрдкреНрд▓реАрдореЗрдВрдЯреЗрд╢рди: рд╡реАрдбрд┐рдпреЛ, рдЯреЗрдХреНрд╕реНрдЯ рдФрд░ рдСрдбрд┐рдпреЛ рд╕реЗ рдСрдбрд┐рдпреЛ рдЬрдирд░реЗрдЯ рдпрд╛ рдПрдбрд┐рдЯ рдХрд░реЗрдВ, рдорд▓реНрдЯреАрдореЛрдбрд▓ рд▓рд╛рд░реНрдЬ рд▓реИрдВрдЧреНрд╡реЗрдЬ рдореЙрдбрд▓реНрд╕ (MLLMs) рдХреА рд╕реНрдЯреЗрдк-рдмрд╛рдп-рд╕реНрдЯреЗрдк рд░реАрдЬрдирд┐рдВрдЧ рджреНрд╡рд╛рд░рд╛ рд╕рдВрдЪрд╛рд▓рд┐рддред\n\n![рдЯреАрдЬрд╝рд░](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig1_teaser.png)\n---\n\n## ЁЯУ░ рд╕рдорд╛рдЪрд╛рд░\n- **2025.11.25** &nbsp; ЁЯФе[рдСрдирд▓рд╛рдЗрди PrismAudio рдбреЗрдореЛ](http://prismaudio-project.github.io/) рд▓рд╛рдЗрд╡ рд╣реИ - рдЕрднреА рдЖрдЬрд╝рдорд╛рдПрдБ!\n- **2025.11.25** &nbsp; ЁЯФе[PrismAudio рдкреЗрдкрд░](https://arxiv.org/pdf/2511.18833) arXiv рдкрд░ рдЬрд╛рд░реА, рд╡реАрдбрд┐рдпреЛ-рд╕реЗ-рдСрдбрд┐рдпреЛ рдЬреЗрдирд░реЗрд╢рди рдХреЗ рд▓рд┐рдП рдкрд╣рд▓рд╛ рдорд▓реНрдЯреА-рдбрд╛рдпрдореЗрдВрд╢рдирд▓ CoT-RL рдлреНрд░реЗрдорд╡рд░реНрдХ!\n- **2025.09.19** &nbsp; ЁЯОЙ ThinkSound рдХреЛ **NeurIPS 2025 рдореБрдЦреНрдп рд╕рдореНрдореЗрд▓рди** рдореЗрдВ рд╕реНрд╡реАрдХрд╛рд░ рдХрд┐рдпрд╛ рдЧрдпрд╛ рд╣реИ!\n- **2025.09.01** &nbsp; рд╣рдорд╛рд░рд╛ AudioCoT рдбреЗрдЯрд╛рд╕реЗрдЯ рдЕрдм рдУрдкрди-рд╕реЛрд░реНрд╕ рд╣реИ рдФрд░ [Hugging Face](https://huggingface.co/datasets/liuhuadai/AudioCoT) рдкрд░ рдЙрдкрд▓рдмреНрдз рд╣реИ!\n- **2025.07.17** &nbsp; ЁЯза рдлрд╛рдЗрдирдЯреНрдпреВрдирд┐рдВрдЧ рд╕рдХреНрд╖рдо: рдЯреНрд░реЗрдирд┐рдВрдЧ рдФрд░ рдлрд╛рдЗрдирдЯреНрдпреВрдирд┐рдВрдЧ рдХреЛрдб рдЕрдм рд╕рд╛рд░реНрд╡рдЬрдирд┐рдХ рд░реВрдк рд╕реЗ рдЙрдкрд▓рдмреНрдз рд╣реИ, рд╕реНрдкрд╖реНрдЯ рдпреВрд╕реЗрдЬ рдирд┐рд░реНрджреЗрд╢реЛрдВ рдХреЗ рд╕рд╛рде рддрд╛рдХрд┐ рдЖрдк рдЕрдкрдиреЗ рд╕реНрд╡рдпрдВ рдХреЗ рдбреЗрдЯрд╛ рдХреЗ рд╕рд╛рде ThinkSound рдХреЛ рдХрд╕реНрдЯрдорд╛рдЗрдЬрд╝ рдФрд░ рд╡рд┐рд╕реНрддрд╛рд░рд┐рдд рдХрд░ рд╕рдХреЗрдВред\n- **2025.07.15** &nbsp; ЁЯУж рдЖрд╕рд╛рди рдЗрдВрд╕реНрдЯреЙрд▓реЗрд╢рди рдФрд░ рдЙрдкрдпреЛрдЧрд┐рддрд╛: PyPI рдкрд░ рдбрд┐рдкреЗрдВрдбреЗрдВрд╕реАрдЬрд╝ рдХреЗ рд╕рд╛рде рдЖрд╕рд╛рди рдХреНрд░реЙрд╕-рдкреНрд▓реЗрдЯрдлреЙрд░реНрдо рд╕реЗрдЯрдЕрдк; Windows `.bat` рд╕реНрдХреНрд░рд┐рдкреНрдЯреНрд╕ рд╕реЗ рдПрдирд╡рд╛рдпрд░рдирдореЗрдВрдЯ рдмрдирд╛рдирд╛ рдФрд░ рд╕реНрдХреНрд░рд┐рдкреНрдЯ рдЪрд▓рд╛рдирд╛ рд╕реНрд╡рдЪрд╛рд▓рд┐рддред\n- **2025.07.08** &nbsp;┬а ЁЯФз рдореБрдЦреНрдп рдЕрдкрдбреЗрдЯ: рдореЙрдбрд▓ рд╣рд▓реНрдХрд╛ рдХрд┐рдпрд╛ рдЧрдпрд╛ рдФрд░ рдореЗрдореЛрд░реА рд╡ GPU рдЙрдкрдпреЛрдЧ рдХреЛ рдСрдкреНрдЯрд┐рдорд╛рдЗрдЬрд╝ рдХрд┐рдпрд╛ рдЧрдпрд╛, рдЕрдм рдмрдбрд╝реЗ рдкреИрдорд╛рдиреЗ рдкрд░ рд╣рд╛рдИ-рдереНрд░реВрдкреБрдЯ рдСрдбрд┐рдпреЛ рдЬреЗрдирд░реЗрд╢рди рдХреЛ рд╕рдкреЛрд░реНрдЯ рдХрд░рддрд╛ рд╣реИ!\n- **2025.07.01** &nbsp; [Hugging Face Spaces](https://huggingface.co/spaces/FunAudioLLM/ThinkSound) рдФрд░ [ModelScope](https://modelscope.cn/studios/iic/ThinkSound) рдкрд░ рдЗрдВрдЯрд░рдПрдХреНрдЯрд┐рд╡ рдЕрдиреБрднрд╡ рдХреЗ рд▓рд┐рдП рдСрдирд▓рд╛рдЗрди рдбреЗрдореЛ!\n- **2025.07.01** &nbsp; рдЗрдирдлрд░реЗрдВрд╕ рд╕реНрдХреНрд░рд┐рдкреНрдЯреНрд╕ рдФрд░ рд╡реЗрдм рдЗрдВрдЯрд░рдлреЗрд╕ рдЬрд╛рд░реА рдХрд┐рдП рдЧрдП;\n- **2025.06** &nbsp; [ThinkSound рдкреЗрдкрд░](https://arxiv.org/pdf/2506.21448) arXiv рдкрд░ рдЬрд╛рд░реА!\n- **2025.06** &nbsp; [рдСрдирд▓рд╛рдЗрди рдбреЗрдореЛ](http://thinksound-project.github.io/) рд▓рд╛рдЗрд╡ рд╣реИ - рдЕрднреА рдЖрдЬрд╝рдорд╛рдПрдБ!\n\n---\n\n\n## ЁЯЪА рд╡рд┐рд╢реЗрд╖рддрд╛рдПрдБ\n\n- **Any2Audio**: рдХрд┐рд╕реА рднреА рдореЛрдбрд╛рд▓рд┐рдЯреА рд╕реЗ рдСрдбрд┐рдпреЛ рдЬрдирд░реЗрдЯ рдХрд░реЗрдВ тАФ рд╡реАрдбрд┐рдпреЛ, рдЯреЗрдХреНрд╕реНрдЯ, рдСрдбрд┐рдпреЛ рдпрд╛ рдЙрдирдХреЗ рд╕рдВрдпреЛрдЬрдиред\n- **рд╡реАрдбрд┐рдпреЛ-рд╕реЗ-рдСрдбрд┐рдпреЛ SOTA**: рдХрдИ V2A рдмреЗрдВрдЪрдорд╛рд░реНрдХреНрд╕ рдкрд░ рд╕реНрдЯреЗрдЯ-рдСрдл-рдж-рдЖрд░реНрдЯ рдкрд░рд┐рдгрд╛рдо рдкреНрд░рд╛рдкреНрдд рдХрд░рддрд╛ рд╣реИред\n- **CoT-рдбреНрд░рд┐рд╡рди рд░реАрдЬрдирд┐рдВрдЧ**: рд╕рдВрдпреЛрдЬрд┐рдд рдФрд░ рдирд┐рдпрдВрддреНрд░рд┐рдд рдСрдбрд┐рдпреЛ рдЬреЗрдирд░реЗрд╢рди рдХреЗ рд▓рд┐рдП MLLMs рджреНрд╡рд╛рд░рд╛ рдЪреЗрди-рдСрдл-рдереЙрдЯ рд░реАрдЬрдирд┐рдВрдЧред\n- **рдЗрдВрдЯрд░рдПрдХреНрдЯрд┐рд╡ рдСрдмреНрдЬреЗрдХреНрдЯ-рдХреЗрдВрджреНрд░рд┐рдд рдПрдбрд┐рдЯрд┐рдВрдЧ**: рджреГрд╢реНрдп рд╡рд╕реНрддреБрдУрдВ рдкрд░ рдХреНрд▓рд┐рдХ рдХрд░рдХреЗ рдпрд╛ рдЯреЗрдХреНрд╕реНрдЯ рдирд┐рд░реНрджреЗрд╢реЛрдВ рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рдХреЗ рд╡рд┐рд╢рд┐рд╖реНрдЯ рд╕рд╛рдЙрдВрдб рдИрд╡реЗрдВрдЯреНрд╕ рдХреЛ рдкрд░рд┐рд╖реНрдХреГрдд рдпрд╛ рд╕рдВрдкрд╛рджрд┐рдд рдХрд░реЗрдВред\n- **рдпреВрдирд┐рдлрд╛рдЗрдб рдлреНрд░реЗрдорд╡рд░реНрдХ**: рдПрдХ рдлрд╛рдЙрдВрдбреЗрд╢рди рдореЙрдбрд▓ рдЬреЗрдирд░реЗрд╢рди, рдПрдбрд┐рдЯрд┐рдВрдЧ рдФрд░ рдЗрдВрдЯрд░рдПрдХреНрдЯрд┐рд╡ рд╡рд░реНрдХрдлреНрд▓реЛ рдХреЛ рд╕рдкреЛрд░реНрдЯ рдХрд░рддрд╛ рд╣реИред\n\n---\n\n## тЬи рд╡рд┐рдзрд┐ рдХрд╛ рдЕрд╡рд▓реЛрдХрди\n\nThinkSound рдСрдбрд┐рдпреЛ рдЬрдирд░реЗрд╢рди рдФрд░ рдПрдбрд┐рдЯрд┐рдВрдЧ рдХреЛ рддреАрди рдЗрдВрдЯрд░рдПрдХреНрдЯрд┐рд╡ рдЪрд░рдгреЛрдВ рдореЗрдВ рд╡рд┐рднрд╛рдЬрд┐рдд рдХрд░рддрд╛ рд╣реИ, рдЬреЛ рд╕рднреА MLLM-рдЖрдзрд╛рд░рд┐рдд рдЪреЗрди-рдСрдл-рдереЙрдЯ (CoT) рд░реАрдЬрдирд┐рдВрдЧ рджреНрд╡рд╛рд░рд╛ рдирд┐рд░реНрджреЗрд╢рд┐рдд рд╣реЛрддреЗ рд╣реИрдВ:\n\n1. **рдлреЛрд▓реА рдЬреЗрдирд░реЗрд╢рди:** рд╡реАрдбрд┐рдпреЛ рд╕реЗ рдЕрд░реНрдердкреВрд░реНрдг рдФрд░ рд╕рдордп-рд╕рдВрд░реЗрдЦрд┐рдд рдЖрдзрд╛рд░рднреВрдд рд╕рд╛рдЙрдВрдбрд╕реНрдХреЗрдкреНрд╕ рдЬрдирд░реЗрдЯ рдХрд░реЗрдВред\n2. **рдСрдмреНрдЬреЗрдХреНрдЯ-рдХреЗрдВрджреНрд░рд┐рдд рдкрд░рд┐рд╖реНрдХрд░рдг:** рд╡реАрдбрд┐рдпреЛ рдореЗрдВ рдХреНрд▓рд┐рдХ рдпрд╛ рдХреНрд╖реЗрддреНрд░ рджреНрд╡рд╛рд░рд╛ рдпреВрдЬрд░-рдирд┐рд░реНрджрд┐рд╖реНрдЯ рд╡рд╕реНрддреБрдУрдВ рдХреЗ рд▓рд┐рдП рдзреНрд╡рдирд┐рдпреЛрдВ рдХреЛ рдкрд░рд┐рд╖реНрдХреГрдд рдпрд╛ рдЬреЛрдбрд╝реЗрдВред\n3. **рд▓рдХреНрд╖рд┐рдд рдСрдбрд┐рдпреЛ рд╕рдВрдкрд╛рджрди:** рдЙрдЪреНрдЪ-рд╕реНрддрд░реАрдп рдкреНрд░рд╛рдХреГрддрд┐рдХ рднрд╛рд╖рд╛ рдирд┐рд░реНрджреЗрд╢реЛрдВ рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рдХреЗ рдЬрдирд░реЗрдЯреЗрдб рдСрдбрд┐рдпреЛ рдХреЛ рд╕рдВрд╢реЛрдзрд┐рдд рдХрд░реЗрдВред\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 2,
        "rowsha": "eexREJOMCITdo96Iwg4N4PQqu1ux/UwupfjVRj0l/L8=",
        "originContent": "PyTorch implementation for multimodal audio generation and editing: generate or edit audio from video, text, and audio, powered by step-by-step reasoning from Multimodal Large Language Models (MLLMs).",
        "translatedContent": "рдорд▓реНрдЯреАрдореЛрдбрд▓ рдСрдбрд┐рдпреЛ рдЬреЗрдирд░реЗрд╢рди рдФрд░ рдПрдбрд┐рдЯрд┐рдВрдЧ рдХреЗ рд▓рд┐рдП PyTorch рдЗрдореНрдкреНрд▓реАрдореЗрдВрдЯреЗрд╢рди: рд╡реАрдбрд┐рдпреЛ, рдЯреЗрдХреНрд╕реНрдЯ рдФрд░ рдСрдбрд┐рдпреЛ рд╕реЗ рдСрдбрд┐рдпреЛ рдЬрдирд░реЗрдЯ рдпрд╛ рдПрдбрд┐рдЯ рдХрд░реЗрдВ, рдорд▓реНрдЯреАрдореЛрдбрд▓ рд▓рд╛рд░реНрдЬ рд▓реИрдВрдЧреНрд╡реЗрдЬ рдореЙрдбрд▓реНрд╕ (MLLMs) рдХреА рд╕реНрдЯреЗрдк-рдмрд╛рдп-рд╕реНрдЯреЗрдк рд░реАрдЬрдирд┐рдВрдЧ рджреНрд╡рд╛рд░рд╛ рд╕рдВрдЪрд╛рд▓рд┐рддред"
      },
      {
        "row": 3,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 4,
        "rowsha": "+7Cx1rdpWiIOeWRA/RM6HsKf7pNA3hHsQk2Bpadt4II=",
        "originContent": "![Teaser](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig1_teaser.png)",
        "translatedContent": "![рдЯреАрдЬрд╝рд░](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig1_teaser.png)"
      },
      {
        "row": 5,
        "rowsha": "yz+R1U7uMOU+NbK5mQX3Dxae1Un9eJCdPawt78ntjTs=",
        "originContent": "---",
        "translatedContent": "---"
      },
      {
        "row": 6,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 7,
        "rowsha": "0YeCyxpcm7/4RDbaM+OQoI8YfqEHQzDkpGW15VZdi1U=",
        "originContent": "## ЁЯУ░ News",
        "translatedContent": "## ЁЯУ░ рд╕рдорд╛рдЪрд╛рд░"
      },
      {
        "row": 8,
        "rowsha": "EeDKxV0PYB9iw6GxOqwnsP3C385ykbqk8PtEVoVhAcc=",
        "originContent": "- **2025.11.25** &nbsp; ЁЯФе[Online PrismAudio Demo](http://prismaudio-project.github.io/) is live - try it now!",
        "translatedContent": "- **2025.11.25** &nbsp; ЁЯФе[рдСрдирд▓рд╛рдЗрди PrismAudio рдбреЗрдореЛ](http://prismaudio-project.github.io/) рд▓рд╛рдЗрд╡ рд╣реИ - рдЕрднреА рдЖрдЬрд╝рдорд╛рдПрдБ!"
      },
      {
        "row": 9,
        "rowsha": "Q6c68QE34xLPSZ5xAL4zofEn/u8umRYYiH3ddCcy5vk=",
        "originContent": "- **2025.11.25** &nbsp; ЁЯФе[PrismAudio paper](https://arxiv.org/pdf/2511.18833) released on arXiv, the first multi-dimensional CoT-RL framework for Video-to-Audio Generation!",
        "translatedContent": "- **2025.11.25** &nbsp; ЁЯФе[PrismAudio рдкреЗрдкрд░](https://arxiv.org/pdf/2511.18833) arXiv рдкрд░ рдЬрд╛рд░реА, рд╡реАрдбрд┐рдпреЛ-рд╕реЗ-рдСрдбрд┐рдпреЛ рдЬреЗрдирд░реЗрд╢рди рдХреЗ рд▓рд┐рдП рдкрд╣рд▓рд╛ рдорд▓реНрдЯреА-рдбрд╛рдпрдореЗрдВрд╢рдирд▓ CoT-RL рдлреНрд░реЗрдорд╡рд░реНрдХ!"
      },
      {
        "row": 10,
        "rowsha": "vj2hbV/6MacDcxRmFA0AtTog5xU6CHoqBFO3YMO+yJo=",
        "originContent": "- **2025.09.19** &nbsp; ЁЯОЙ ThinkSound has been accepted to the **NeurIPS 2025 Main Conference**!",
        "translatedContent": "- **2025.09.19** &nbsp; ЁЯОЙ ThinkSound рдХреЛ **NeurIPS 2025 рдореБрдЦреНрдп рд╕рдореНрдореЗрд▓рди** рдореЗрдВ рд╕реНрд╡реАрдХрд╛рд░ рдХрд┐рдпрд╛ рдЧрдпрд╛ рд╣реИ!"
      },
      {
        "row": 11,
        "rowsha": "+guVQwDlJDqR1pBGMGc4FQ11nryItaEtKQ3etaCBcn0=",
        "originContent": "- **2025.09.01** &nbsp; Our AudioCoT dataset is now open-sourced and available on [Hugging Face](https://huggingface.co/datasets/liuhuadai/AudioCoT)!",
        "translatedContent": "- **2025.09.01** &nbsp; рд╣рдорд╛рд░рд╛ AudioCoT рдбреЗрдЯрд╛рд╕реЗрдЯ рдЕрдм рдУрдкрди-рд╕реЛрд░реНрд╕ рд╣реИ рдФрд░ [Hugging Face](https://huggingface.co/datasets/liuhuadai/AudioCoT) рдкрд░ рдЙрдкрд▓рдмреНрдз рд╣реИ!"
      },
      {
        "row": 12,
        "rowsha": "4Jq9g83O8cYV4fVKsetfTpI+JrSepLrjK6J7Xg9tSqo=",
        "originContent": "- **2025.07.17** &nbsp; ЁЯза Finetuning enabled: training and finetuning code is now publicly available, along with clear usage instructions to help you customize and extend ThinkSound with your own data.",
        "translatedContent": "- **2025.07.17** &nbsp; ЁЯза рдлрд╛рдЗрдирдЯреНрдпреВрдирд┐рдВрдЧ рд╕рдХреНрд╖рдо: рдЯреНрд░реЗрдирд┐рдВрдЧ рдФрд░ рдлрд╛рдЗрдирдЯреНрдпреВрдирд┐рдВрдЧ рдХреЛрдб рдЕрдм рд╕рд╛рд░реНрд╡рдЬрдирд┐рдХ рд░реВрдк рд╕реЗ рдЙрдкрд▓рдмреНрдз рд╣реИ, рд╕реНрдкрд╖реНрдЯ рдпреВрд╕реЗрдЬ рдирд┐рд░реНрджреЗрд╢реЛрдВ рдХреЗ рд╕рд╛рде рддрд╛рдХрд┐ рдЖрдк рдЕрдкрдиреЗ рд╕реНрд╡рдпрдВ рдХреЗ рдбреЗрдЯрд╛ рдХреЗ рд╕рд╛рде ThinkSound рдХреЛ рдХрд╕реНрдЯрдорд╛рдЗрдЬрд╝ рдФрд░ рд╡рд┐рд╕реНрддрд╛рд░рд┐рдд рдХрд░ рд╕рдХреЗрдВред"
      },
      {
        "row": 13,
        "rowsha": "Ae5w+cTrCd9E8qidC11IWJAgg+LuOgUxA4czDPNG/G0=",
        "originContent": "- **2025.07.15** &nbsp; ЁЯУж Simplified installation and usability: dependencies on PyPI for easy cross-platform setup; Windows `.bat` scripts automate environment creation and script running.",
        "translatedContent": "- **2025.07.15** &nbsp; ЁЯУж рдЖрд╕рд╛рди рдЗрдВрд╕реНрдЯреЙрд▓реЗрд╢рди рдФрд░ рдЙрдкрдпреЛрдЧрд┐рддрд╛: PyPI рдкрд░ рдбрд┐рдкреЗрдВрдбреЗрдВрд╕реАрдЬрд╝ рдХреЗ рд╕рд╛рде рдЖрд╕рд╛рди рдХреНрд░реЙрд╕-рдкреНрд▓реЗрдЯрдлреЙрд░реНрдо рд╕реЗрдЯрдЕрдк; Windows `.bat` рд╕реНрдХреНрд░рд┐рдкреНрдЯреНрд╕ рд╕реЗ рдПрдирд╡рд╛рдпрд░рдирдореЗрдВрдЯ рдмрдирд╛рдирд╛ рдФрд░ рд╕реНрдХреНрд░рд┐рдкреНрдЯ рдЪрд▓рд╛рдирд╛ рд╕реНрд╡рдЪрд╛рд▓рд┐рддред"
      },
      {
        "row": 14,
        "rowsha": "nYxNhwgSqjwYLuWsfHAqP5sx2PnzYwoFrwcf9U+Fdss=",
        "originContent": "- **2025.07.08** &nbsp;┬а ЁЯФз Major update: model lightweighted and optimized memory and GPU usage, now supports high-throughput audio generation at scale!",
        "translatedContent": "- **2025.07.08** &nbsp;┬а ЁЯФз рдореБрдЦреНрдп рдЕрдкрдбреЗрдЯ: рдореЙрдбрд▓ рд╣рд▓реНрдХрд╛ рдХрд┐рдпрд╛ рдЧрдпрд╛ рдФрд░ рдореЗрдореЛрд░реА рд╡ GPU рдЙрдкрдпреЛрдЧ рдХреЛ рдСрдкреНрдЯрд┐рдорд╛рдЗрдЬрд╝ рдХрд┐рдпрд╛ рдЧрдпрд╛, рдЕрдм рдмрдбрд╝реЗ рдкреИрдорд╛рдиреЗ рдкрд░ рд╣рд╛рдИ-рдереНрд░реВрдкреБрдЯ рдСрдбрд┐рдпреЛ рдЬреЗрдирд░реЗрд╢рди рдХреЛ рд╕рдкреЛрд░реНрдЯ рдХрд░рддрд╛ рд╣реИ!"
      },
      {
        "row": 15,
        "rowsha": "RPL6cU3/Jgu90ib4PkeN5Q/ALrnjq9hK0ZUCranb/PA=",
        "originContent": "- **2025.07.01** &nbsp; Online demo on [Hugging Face Spaces](https://huggingface.co/spaces/FunAudioLLM/ThinkSound) and [ModelScope](https://modelscope.cn/studios/iic/ThinkSound) for interactive experience!",
        "translatedContent": "- **2025.07.01** &nbsp; [Hugging Face Spaces](https://huggingface.co/spaces/FunAudioLLM/ThinkSound) рдФрд░ [ModelScope](https://modelscope.cn/studios/iic/ThinkSound) рдкрд░ рдЗрдВрдЯрд░рдПрдХреНрдЯрд┐рд╡ рдЕрдиреБрднрд╡ рдХреЗ рд▓рд┐рдП рдСрдирд▓рд╛рдЗрди рдбреЗрдореЛ!"
      },
      {
        "row": 16,
        "rowsha": "0PEL3eOyUmX2U56FPEPvYfaltZ/P/wbH0uO6GcLPlUE=",
        "originContent": "- **2025.07.01** &nbsp; Released inference scripts and web interface; ",
        "translatedContent": "- **2025.07.01** &nbsp; рдЗрдирдлрд░реЗрдВрд╕ рд╕реНрдХреНрд░рд┐рдкреНрдЯреНрд╕ рдФрд░ рд╡реЗрдм рдЗрдВрдЯрд░рдлреЗрд╕ рдЬрд╛рд░реА рдХрд┐рдП рдЧрдП;"
      },
      {
        "row": 17,
        "rowsha": "XNdJ/DN741rXoJAruiGiRueQILXIUHRXzBlp+HVWM88=",
        "originContent": "- **2025.06** &nbsp; [ThinkSound paper](https://arxiv.org/pdf/2506.21448) released on arXiv!",
        "translatedContent": "- **2025.06** &nbsp; [ThinkSound рдкреЗрдкрд░](https://arxiv.org/pdf/2506.21448) arXiv рдкрд░ рдЬрд╛рд░реА!"
      },
      {
        "row": 18,
        "rowsha": "W45oflUmoUAksoDc1WjcR2hErqh9UIi738PFVipiDg0=",
        "originContent": "- **2025.06** &nbsp; [Online Demo](http://thinksound-project.github.io/) is live - try it now!",
        "translatedContent": "- **2025.06** &nbsp; [рдСрдирд▓рд╛рдЗрди рдбреЗрдореЛ](http://thinksound-project.github.io/) рд▓рд╛рдЗрд╡ рд╣реИ - рдЕрднреА рдЖрдЬрд╝рдорд╛рдПрдБ!"
      },
      {
        "row": 19,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 20,
        "rowsha": "yz+R1U7uMOU+NbK5mQX3Dxae1Un9eJCdPawt78ntjTs=",
        "originContent": "---",
        "translatedContent": "---"
      },
      {
        "row": 21,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 22,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 23,
        "rowsha": "f4oQIFLM2EJQxJ65F4oMEA7yWOIqs0eBtiIvGxI+GgI=",
        "originContent": "## ЁЯЪА Features",
        "translatedContent": "## ЁЯЪА рд╡рд┐рд╢реЗрд╖рддрд╛рдПрдБ"
      },
      {
        "row": 24,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 25,
        "rowsha": "8TbVluJJPR3C0fX41HklpO/vH9/k/rHC+jlvmHHfzQU=",
        "originContent": "- **Any2Audio**: Generate audio from arbitrary modalities тАФ video, text, audio, or their combinations.",
        "translatedContent": "- **Any2Audio**: рдХрд┐рд╕реА рднреА рдореЛрдбрд╛рд▓рд┐рдЯреА рд╕реЗ рдСрдбрд┐рдпреЛ рдЬрдирд░реЗрдЯ рдХрд░реЗрдВ тАФ рд╡реАрдбрд┐рдпреЛ, рдЯреЗрдХреНрд╕реНрдЯ, рдСрдбрд┐рдпреЛ рдпрд╛ рдЙрдирдХреЗ рд╕рдВрдпреЛрдЬрдиред"
      },
      {
        "row": 26,
        "rowsha": "+Jf5LrYz+d1ShYCuQe8UF9taEJUpuGhDk6fAlYK3Kj4=",
        "originContent": "- **Video-to-Audio SOTA**: Achieves state-of-the-art results on multiple V2A benchmarks.",
        "translatedContent": "- **рд╡реАрдбрд┐рдпреЛ-рд╕реЗ-рдСрдбрд┐рдпреЛ SOTA**: рдХрдИ V2A рдмреЗрдВрдЪрдорд╛рд░реНрдХреНрд╕ рдкрд░ рд╕реНрдЯреЗрдЯ-рдСрдл-рдж-рдЖрд░реНрдЯ рдкрд░рд┐рдгрд╛рдо рдкреНрд░рд╛рдкреНрдд рдХрд░рддрд╛ рд╣реИред"
      },
      {
        "row": 27,
        "rowsha": "mU7qXkjW1YifKoYXJedYo9l64NsTBaiXsgoGFRF/g+E=",
        "originContent": "- **CoT-Driven Reasoning**: Chain-of-Thought reasoning for compositional and controllable audio generation via MLLMs.",
        "translatedContent": "- **CoT-рдбреНрд░рд┐рд╡рди рд░реАрдЬрдирд┐рдВрдЧ**: рд╕рдВрдпреЛрдЬрд┐рдд рдФрд░ рдирд┐рдпрдВрддреНрд░рд┐рдд рдСрдбрд┐рдпреЛ рдЬреЗрдирд░реЗрд╢рди рдХреЗ рд▓рд┐рдП MLLMs рджреНрд╡рд╛рд░рд╛ рдЪреЗрди-рдСрдл-рдереЙрдЯ рд░реАрдЬрдирд┐рдВрдЧред"
      },
      {
        "row": 28,
        "rowsha": "RComOCBBrXsZf9RHmLginqKTh9eI/bKUZuUunQEmD5M=",
        "originContent": "- **Interactive Object-centric Editing**: Refine or edit specific sound events by clicking on visual objects or using text instructions.",
        "translatedContent": "- **рдЗрдВрдЯрд░рдПрдХреНрдЯрд┐рд╡ рдСрдмреНрдЬреЗрдХреНрдЯ-рдХреЗрдВрджреНрд░рд┐рдд рдПрдбрд┐рдЯрд┐рдВрдЧ**: рджреГрд╢реНрдп рд╡рд╕реНрддреБрдУрдВ рдкрд░ рдХреНрд▓рд┐рдХ рдХрд░рдХреЗ рдпрд╛ рдЯреЗрдХреНрд╕реНрдЯ рдирд┐рд░реНрджреЗрд╢реЛрдВ рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рдХреЗ рд╡рд┐рд╢рд┐рд╖реНрдЯ рд╕рд╛рдЙрдВрдб рдИрд╡реЗрдВрдЯреНрд╕ рдХреЛ рдкрд░рд┐рд╖реНрдХреГрдд рдпрд╛ рд╕рдВрдкрд╛рджрд┐рдд рдХрд░реЗрдВред"
      },
      {
        "row": 29,
        "rowsha": "C3sf87sy73G/XZft+TDo5NjXo5XcrtJB805ayHRAXoQ=",
        "originContent": "- **Unified Framework**: One foundation model supports generation, editing, and interactive workflow.",
        "translatedContent": "- **рдпреВрдирд┐рдлрд╛рдЗрдб рдлреНрд░реЗрдорд╡рд░реНрдХ**: рдПрдХ рдлрд╛рдЙрдВрдбреЗрд╢рди рдореЙрдбрд▓ рдЬреЗрдирд░реЗрд╢рди, рдПрдбрд┐рдЯрд┐рдВрдЧ рдФрд░ рдЗрдВрдЯрд░рдПрдХреНрдЯрд┐рд╡ рд╡рд░реНрдХрдлреНрд▓реЛ рдХреЛ рд╕рдкреЛрд░реНрдЯ рдХрд░рддрд╛ рд╣реИред"
      },
      {
        "row": 30,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 31,
        "rowsha": "yz+R1U7uMOU+NbK5mQX3Dxae1Un9eJCdPawt78ntjTs=",
        "originContent": "---",
        "translatedContent": "---"
      },
      {
        "row": 32,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 33,
        "rowsha": "gjgLOIAU2x83BBZdLUdgEB+F64ajt/QuLYQXM1hDBLE=",
        "originContent": "## тЬи Method Overview",
        "translatedContent": "## тЬи рд╡рд┐рдзрд┐ рдХрд╛ рдЕрд╡рд▓реЛрдХрди"
      },
      {
        "row": 34,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 35,
        "rowsha": "v5//GqG/smYIGoUpN+12k+9/3GWH3GdYD+jLqScb7AM=",
        "originContent": "ThinkSound decomposes audio generation and editing into three interactive stages, all guided by MLLM-based Chain-of-Thought (CoT) reasoning:",
        "translatedContent": "ThinkSound рдСрдбрд┐рдпреЛ рдЬрдирд░реЗрд╢рди рдФрд░ рдПрдбрд┐рдЯрд┐рдВрдЧ рдХреЛ рддреАрди рдЗрдВрдЯрд░рдПрдХреНрдЯрд┐рд╡ рдЪрд░рдгреЛрдВ рдореЗрдВ рд╡рд┐рднрд╛рдЬрд┐рдд рдХрд░рддрд╛ рд╣реИ, рдЬреЛ рд╕рднреА MLLM-рдЖрдзрд╛рд░рд┐рдд рдЪреЗрди-рдСрдл-рдереЙрдЯ (CoT) рд░реАрдЬрдирд┐рдВрдЧ рджреНрд╡рд╛рд░рд╛ рдирд┐рд░реНрджреЗрд╢рд┐рдд рд╣реЛрддреЗ рд╣реИрдВ:"
      },
      {
        "row": 36,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 37,
        "rowsha": "vTObEWb7f5gCU681X3dTkwqhsaSW89TLw3GgMJ5I3bo=",
        "originContent": "1. **Foley Generation:** Generate foundational, semantically and temporally aligned soundscapes from video.",
        "translatedContent": "1. **рдлреЛрд▓реА рдЬреЗрдирд░реЗрд╢рди:** рд╡реАрдбрд┐рдпреЛ рд╕реЗ рдЕрд░реНрдердкреВрд░реНрдг рдФрд░ рд╕рдордп-рд╕рдВрд░реЗрдЦрд┐рдд рдЖрдзрд╛рд░рднреВрдд рд╕рд╛рдЙрдВрдбрд╕реНрдХреЗрдкреНрд╕ рдЬрдирд░реЗрдЯ рдХрд░реЗрдВред"
      },
      {
        "row": 38,
        "rowsha": "LTBpIQQHtEkNF8StAa+ZEDASGmRhmHIKDQOdZ4ExJWM=",
        "originContent": "2. **Object-Centric Refinement:** Refine or add sounds for user-specified objects via clicks or regions in the video.",
        "translatedContent": "2. **рдСрдмреНрдЬреЗрдХреНрдЯ-рдХреЗрдВрджреНрд░рд┐рдд рдкрд░рд┐рд╖реНрдХрд░рдг:** рд╡реАрдбрд┐рдпреЛ рдореЗрдВ рдХреНрд▓рд┐рдХ рдпрд╛ рдХреНрд╖реЗрддреНрд░ рджреНрд╡рд╛рд░рд╛ рдпреВрдЬрд░-рдирд┐рд░реНрджрд┐рд╖реНрдЯ рд╡рд╕реНрддреБрдУрдВ рдХреЗ рд▓рд┐рдП рдзреНрд╡рдирд┐рдпреЛрдВ рдХреЛ рдкрд░рд┐рд╖реНрдХреГрдд рдпрд╛ рдЬреЛрдбрд╝реЗрдВред"
      },
      {
        "row": 39,
        "rowsha": "8wrAo7X7dPC6Sgpfrlq2ziv/Wg/3+JnlFYvO+RMxADQ=",
        "originContent": "3. **Targeted Audio Editing:** Modify generated audio using high-level natural language instructions.",
        "translatedContent": "3. **рд▓рдХреНрд╖рд┐рдд рдСрдбрд┐рдпреЛ рд╕рдВрдкрд╛рджрди:** рдЙрдЪреНрдЪ-рд╕реНрддрд░реАрдп рдкреНрд░рд╛рдХреГрддрд┐рдХ рднрд╛рд╖рд╛ рдирд┐рд░реНрджреЗрд╢реЛрдВ рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рдХреЗ рдЬрдирд░реЗрдЯреЗрдб рдСрдбрд┐рдпреЛ рдХреЛ рд╕рдВрд╢реЛрдзрд┐рдд рдХрд░реЗрдВред"
      },
      {
        "row": 40,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 3,
    "Content": "![ThinkSound Overview](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig3_model.png)\n<!-- A large-scale CoT-annotated dataset (**AudioCoT**) is used to train both the reasoning module and the unified audio foundation model.\n![AudioCoT Pipeline](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig2_dataset.png) -->\n\n---\n\n## тЪб Quick Start\n\n**Environment Preparation:**",
    "ContentSha": "QpULU62syvvJhbUWGR7NuQMiHmHmeeiFfKqP+ZpqFOk=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "![ThinkSound рдЕрд╡рд▓реЛрдХрди](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig3_model.png)\n<!-- рдПрдХ рдмрдбрд╝реЗ рдкреИрдорд╛рдиреЗ рдкрд░ CoT-рдПрдиреЛрдЯреЗрдЯреЗрдб рдбреЗрдЯрд╛рд╕реЗрдЯ (**AudioCoT**) рдХрд╛ рдЙрдкрдпреЛрдЧ рддрд░реНрдХ рдореЙрдбреНрдпреВрд▓ рдФрд░ рдПрдХреАрдХреГрдд рдСрдбрд┐рдпреЛ рдлрд╛рдЙрдВрдбреЗрд╢рди рдореЙрдбрд▓ рджреЛрдиреЛрдВ рдХреЛ рдкреНрд░рд╢рд┐рдХреНрд╖рд┐рдд рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП рдХрд┐рдпрд╛ рдЬрд╛рддрд╛ рд╣реИред\n![AudioCoT рдкрд╛рдЗрдкрд▓рд╛рдЗрди](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig2_dataset.png) -->\n\n---\n\n## тЪб рддреНрд╡рд░рд┐рдд рд╢реБрд░реБрдЖрдд\n\n**рдкрд░реНрдпрд╛рд╡рд░рдг рддреИрдпрд╛рд░реА:**",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "4UKlvFW3Xb0bSAVjcBNeekH/MMiYS0XDg9w4mCuPy/Q=",
        "originContent": "![ThinkSound Overview](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig3_model.png)",
        "translatedContent": "![ThinkSound рдЕрд╡рд▓реЛрдХрди](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig3_model.png)"
      },
      {
        "row": 2,
        "rowsha": "GaujeIM3x7+YcFy07LNNyITlujhkgpgeIaOiKHJkYnE=",
        "originContent": "<!-- A large-scale CoT-annotated dataset (**AudioCoT**) is used to train both the reasoning module and the unified audio foundation model.",
        "translatedContent": "<!-- рдПрдХ рдмрдбрд╝реЗ рдкреИрдорд╛рдиреЗ рдкрд░ CoT-рдПрдиреЛрдЯреЗрдЯреЗрдб рдбреЗрдЯрд╛рд╕реЗрдЯ (**AudioCoT**) рдХрд╛ рдЙрдкрдпреЛрдЧ рддрд░реНрдХ рдореЙрдбреНрдпреВрд▓ рдФрд░ рдПрдХреАрдХреГрдд рдСрдбрд┐рдпреЛ рдлрд╛рдЙрдВрдбреЗрд╢рди рдореЙрдбрд▓ рджреЛрдиреЛрдВ рдХреЛ рдкреНрд░рд╢рд┐рдХреНрд╖рд┐рдд рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП рдХрд┐рдпрд╛ рдЬрд╛рддрд╛ рд╣реИред"
      },
      {
        "row": 3,
        "rowsha": "qYOXaaTiYkoaPFcpTXE5xdSqqiW3ebi//EW/RfSXd9g=",
        "originContent": "![AudioCoT Pipeline](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig2_dataset.png) -->",
        "translatedContent": "![AudioCoT рдкрд╛рдЗрдкрд▓рд╛рдЗрди](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig2_dataset.png) -->"
      },
      {
        "row": 4,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 5,
        "rowsha": "yz+R1U7uMOU+NbK5mQX3Dxae1Un9eJCdPawt78ntjTs=",
        "originContent": "---",
        "translatedContent": "---"
      },
      {
        "row": 6,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 7,
        "rowsha": "PrY/jc4yAHdS+Sr+s+Yhab477/BDp3GAzMJ8+WyumyI=",
        "originContent": "## тЪб Quick Start",
        "translatedContent": "## тЪб рддреНрд╡рд░рд┐рдд рд╢реБрд░реБрдЖрдд"
      },
      {
        "row": 8,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 9,
        "rowsha": "mD63DGEpdc7FlccTEps0KPAiwsJpO/C3yjV+SKIi/vE=",
        "originContent": "**Environment Preparation:**",
        "translatedContent": "**рдкрд░реНрдпрд╛рд╡рд░рдг рддреИрдпрд╛рд░реА:**"
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 4,
    "Content": "```bash\ngit clone https://github.com/liuhuadai/ThinkSound.git\ncd ThinkSound\nconda create -n thinksound python=3.10\nconda activate thinksound\npip install thinksound\nconda install -y -c conda-forge 'ffmpeg<7'\n# Download pretrained weights https://huggingface.co/liuhuadai/ThinkSound to Directory ckpts/\n# model weights can be also downloaded from https://www.modelscope.cn/models/iic/ThinkSound\ngit lfs install\ngit clone https://huggingface.co/liuhuadai/ThinkSound ckpts\n# To improve inference and training speed, you may optionally install a FlashAttention backend compatible with your system and PyTorch version.\n```",
    "ContentSha": "CSBCDvBmuatxDa1cNMeHEBTJJzdLjK6wyO9v0LrETM8=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\ngit clone https://github.com/liuhuadai/ThinkSound.git\ncd ThinkSound\nconda create -n thinksound python=3.10\nconda activate thinksound\npip install thinksound\nconda install -y -c conda-forge 'ffmpeg<7'\n# Download pretrained weights https://huggingface.co/liuhuadai/ThinkSound to Directory ckpts/\n# model weights can be also downloaded from https://www.modelscope.cn/models/iic/ThinkSound\ngit lfs install\ngit clone https://huggingface.co/liuhuadai/ThinkSound ckpts\n# To improve inference and training speed, you may optionally install a FlashAttention backend compatible with your system and PyTorch version.\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 5,
    "Content": "\n> тЬЕ **Windows Tip:**  \n> Windows users can simply run `setup_windows.bat` (or double-click it) to automatically create the conda environment, install all dependencies (including FFmpeg), and download the pretrained model тАФ no manual setup required.  \n> Make sure `conda` and `git` are installed and available in your system PATH before running the script.\n\n\n### тЦ╢я╕П Run the Demo\n\n#### **Linux/macOS**\n",
    "ContentSha": "YGhm7lbBNPq6xLS6zXlFTPszO8rc4QZCwsScPNskcto=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "> тЬЕ **Windows рдЯрд┐рдк:**  \n> Windows рдЙрдкрдпреЛрдЧрдХрд░реНрддрд╛ рдХреЗрд╡рд▓ `setup_windows.bat` рдЪрд▓рд╛ рд╕рдХрддреЗ рд╣реИрдВ (рдпрд╛ рдЙрд╕ рдкрд░ рдбрдмрд▓-рдХреНрд▓рд┐рдХ рдХрд░ рд╕рдХрддреЗ рд╣реИрдВ) рдЬрд┐рд╕рд╕реЗ рдХреЛрдВрдбрд╛ рд╡рд╛рддрд╛рд╡рд░рдг рдЕрдкрдиреЗ рдЖрдк рдмрди рдЬрд╛рдПрдЧрд╛, рд╕рднреА рдЖрд╡рд╢реНрдпрдХрддрд╛рдПрдБ (FFmpeg рд╕рд╣рд┐рдд) рд╕реНрдерд╛рдкрд┐рдд рд╣реЛ рдЬрд╛рдПрдВрдЧреА, рдФрд░ рдкреНрд░реАрдЯреНрд░реЗрдВрдб рдореЙрдбрд▓ рдбрд╛рдЙрдирд▓реЛрдб рд╣реЛ рдЬрд╛рдПрдЧрд╛ тАФ рдХреЛрдИ рдореИрдиреНрдпреБрдЕрд▓ рд╕реЗрдЯрдЕрдк рдЖрд╡рд╢реНрдпрдХ рдирд╣реАрдВ рд╣реИред  \n> рд╕реНрдХреНрд░рд┐рдкреНрдЯ рдЪрд▓рд╛рдиреЗ рд╕реЗ рдкрд╣рд▓реЗ рд╕реБрдирд┐рд╢реНрдЪрд┐рдд рдХрд░реЗрдВ рдХрд┐ рдЖрдкрдХреЗ рд╕рд┐рд╕реНрдЯрдо PATH рдореЗрдВ `conda` рдФрд░ `git` рдЗрдВрд╕реНрдЯреЙрд▓ рдФрд░ рдЙрдкрд▓рдмреНрдз рд╣реИрдВред\n\n\n### тЦ╢я╕П рдбреЗрдореЛ рдЪрд▓рд╛рдПрдБ\n\n#### **Linux/macOS**\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 6,
    "Content": "```bash\nchmod +x scripts/demo.sh\n./scripts/demo.sh <path-to-your-demo-video> <title> <CoT description> [use-half]\n```",
    "ContentSha": "EW6OKf+6hdOehT5SO7gfI7wR8oAoMckp60MRfIA1jHc=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\nchmod +x scripts/demo.sh\n./scripts/demo.sh <path-to-your-demo-video> <title> <CoT description> [use-half]\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 7,
    "Content": "\n#### **Windows**\n\nYou can use the provided `.bat` script instead:\n",
    "ContentSha": "zXqRZWTEWOuKZG1GOlqqZff+IH24zUwdPtSfwESqS9E=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "#### **Windows**\n\nрдЗрд╕рдХреЗ рдмрдЬрд╛рдп рдЖрдк рдкреНрд░рджрд╛рди рдХреА рдЧрдИ `.bat` рд╕реНрдХреНрд░рд┐рдкреНрдЯ рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░ рд╕рдХрддреЗ рд╣реИрдВ:\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 8,
    "Content": "```bash\n.\\scripts\\demo.bat <path-to-your-demo-video> <title> <CoT description> [use-half]\n```",
    "ContentSha": "A2a1kVuIPNs8ht1a6LBYTEijJjnfjiTN0r+2n7VEJSg=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\n.\\scripts\\demo.bat <path-to-your-demo-video> <title> <CoT description> [use-half]\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 9,
    "Content": "\n**Note:**\n\n* `<path-to-your-demo-video>`: The path to a single video\n* `[use-half]` (optional): Add use-half at the end to enable half precision feature extraction.\n\n---\n\n### ЁЯУж Batch Inference\n\n#### **Linux/macOS**\n",
    "ContentSha": "T7owm3ZZW7sVjKwFivgiuYX2+RVuNBl0RYTSnIcxxbM=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "**рдиреЛрдЯ:**\n\n* `<path-to-your-demo-video>`: рдПрдХрд▓ рд╡реАрдбрд┐рдпреЛ рдХрд╛ рдкрде\n* `[use-half]` (рд╡реИрдХрд▓реНрдкрд┐рдХ): рдЕрдВрддрд┐рдо рдореЗрдВ use-half рдЬреЛрдбрд╝реЗрдВ рддрд╛рдХрд┐ рд╣рд╛рдл рдкреНрд░рд┐рд╕реАрдЬрди рдлреАрдЪрд░ рдПрдХреНрд╕рдЯреНрд░реИрдХреНрд╢рди рд╕рдХреНрд╖рдо рд╣реЛ рд╕рдХреЗред\n\n---\n\n### ЁЯУж рдмреИрдЪ рдЗрдирдлреЗрд░реЗрдВрд╕\n\n#### **Linux/macOS**\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 10,
    "Content": "```bash\nchmod +x scripts/eval_batch.sh\n./scripts/eval_batch.sh <video_path> <csv_path> <save_path (optional)> [use-half]\n```",
    "ContentSha": "EQ4HuSYii55aHfgphESvOXMz2+Fq39+Xquxg6Z6uzdU=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\nchmod +x scripts/eval_batch.sh\n./scripts/eval_batch.sh <video_path> <csv_path> <save_path (optional)> [use-half]\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 11,
    "Content": "\n#### **Windows**\n\nUse the equivalent `.bat` script:\n",
    "ContentSha": "njm5i6o3MR7AV4Q3WLctbe3LN1njFn89fPfTlo+zSmc=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "#### **рд╡рд┐рдВрдбреЛрдЬрд╝**\n\nрд╕рдорд╛рди `.bat` рд╕реНрдХреНрд░рд┐рдкреНрдЯ рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░реЗрдВ:\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 12,
    "Content": "```bash\n.\\scripts\\eval_batch.bat <video_path> <csv_path> <save_path (optional)> [use-half]\n```",
    "ContentSha": "XLkAqxYBZeJiF6XnpshI6naENFsr5yFAH7af132cgb0=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\n.\\scripts\\eval_batch.bat <video_path> <csv_path> <save_path (optional)> [use-half]\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 13,
    "Content": "\n**Note:**\n\n* `<video_path>`: Path to the root directory containing all .mp4 videos to be processed (all videos must be of equal duration).\n* `<csv_path>`: A CSV file with text prompts for each video (see `demo_test.csv` for format).\n* `<save_path>` (optional): Where to save generated audio. Defaults to `results/features`.\n* `[use-half]` (optional): Add use-half at the end to enable half precision feature extraction.\n\n---\n\n\n### Web Interface Usage\n\nFor an interactive experience, launch the Gradio web interface:\n",
    "ContentSha": "yT/y6PXpYV8wS4qmKJfVNVGDLOwreTxCdCDFDv2VbLo=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "**рдиреЛрдЯ:**\n\n* `<video_path>`: рдЙрд╕ рдореВрд▓ рдирд┐рд░реНрджреЗрд╢рд┐рдХрд╛ рдХрд╛ рдкрде рдЬрд┐рд╕рдореЗрдВ рд╕рднреА .mp4 рд╡реАрдбрд┐рдпреЛ рдкреНрд░реЛрд╕реЗрд╕рд┐рдВрдЧ рдХреЗ рд▓рд┐рдП рд░рдЦреЗ рдЧрдП рд╣реИрдВ (рд╕рднреА рд╡реАрдбрд┐рдпреЛ рдХреА рдЕрд╡рдзрд┐ рд╕рдорд╛рди рд╣реЛрдиреА рдЪрд╛рд╣рд┐рдП)ред\n* `<csv_path>`: рдкреНрд░рддреНрдпреЗрдХ рд╡реАрдбрд┐рдпреЛ рдХреЗ рд▓рд┐рдП рдЯреЗрдХреНрд╕реНрдЯ рдкреНрд░реЙрдореНрдкреНрдЯреНрд╕ рд╡рд╛рд▓реА рдПрдХ CSV рдлрд╝рд╛рдЗрд▓ (рдлреЙрд░реНрдореЗрдЯ рдХреЗ рд▓рд┐рдП `demo_test.csv` рджреЗрдЦреЗрдВ)ред\n* `<save_path>` (рд╡реИрдХрд▓реНрдкрд┐рдХ): рдЬрдирд░реЗрдЯреЗрдб рдСрдбрд┐рдпреЛ рдХреЛ рдХрд╣рд╛рдБ рд╕реЗрд╡ рдХрд░рдирд╛ рд╣реИред рдбрд┐рдлрд╝реЙрд▓реНрдЯ рд╣реИ `results/features`ред\n* `[use-half]` (рд╡реИрдХрд▓реНрдкрд┐рдХ): рд╣рд╛рдл рдкреНрд░рд┐рд╕реАрдЬрди рдлрд╝реАрдЪрд░ рдПрдХреНрд╕рдЯреНрд░реИрдХреНрд╢рди рдХреЛ рд╕рдХреНрд╖рдо рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП рдЕрдВрдд рдореЗрдВ use-half рдЬреЛрдбрд╝реЗрдВред\n\n---\n\n\n### рд╡реЗрдм рдЗрдВрдЯрд░рдлреЗрд╕ рдЙрдкрдпреЛрдЧ\n\nрдЗрдВрдЯрд░рдПрдХреНрдЯрд┐рд╡ рдЕрдиреБрднрд╡ рдХреЗ рд▓рд┐рдП, Gradio рд╡реЗрдм рдЗрдВрдЯрд░рдлреЗрд╕ рд▓реЙрдиреНрдЪ рдХрд░реЗрдВ:\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 14,
    "Content": "```bash\npython app.py\n```",
    "ContentSha": "2nQFYMHYtsOO4+egbu20DhxqoaxfzoH8CneeM8qTEb0=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\npython app.py\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 15,
    "Content": "\n\n## ЁЯПЛя╕П Train the Model\n\nSee [`Training.md`](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/docs/Training.md)\n\n\n---\n\n## ЁЯУЭ TODO & Future Plans\n* - [ ] Release a more powerful foundation model covering multiple domains to provide more engaging and immersive foley creation\n* - [ ] Add support for additional modalities and downstream tasks\n* - [ ] Release models at different scales\n* - [x] Open-source AudioCoT dataset and automated pipeline\n* - [x] Release training scripts for ThinkSound models\n* - [x] A beginner-friendly Windows quick-start README\n---\n\n\n## ЁЯУД License\n\nThis project is released under the Apache 2.0 License.\n\n> **Note:**\n> The code, models, and dataset are **for research and educational purposes only**.\n> **Commercial use is NOT permitted.**\n> For commercial licensing, please contact the authors.\n\n**ЁЯУж Third-Party Components**\n\n* **Stable Audio Open VAE** (by Stability AI):\n  This repository includes a fine-tuned VAE from [Stable Audio Open](https://huggingface.co/stabilityai/stable-audio-open-1.0/), licensed under the [Stability AI Community License](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/./third_party/LICENSE_StabilityAI.md).\n  **Commercial use and redistribution require prior permission from Stability AI.**\n\n* ЁЯУШ **All other code and models** are released under the Apache License 2.0.\n\n---\n\n## Acknowledgements\n",
    "ContentSha": "j3jq6Afpr38oSd7nSvDiMiQ889Z6kSywM0DVVT9ieNA=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "\n\n## ЁЯПЛя╕П рдореЙрдбрд▓ рдХреЛ рдкреНрд░рд╢рд┐рдХреНрд╖рд┐рдд рдХрд░реЗрдВ\n\nрджреЗрдЦреЗрдВ [`Training.md`](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/docs/Training.md)\n\n\n---\n\n## ЁЯУЭ TODO рдФрд░ рднрд╡рд┐рд╖реНрдп рдХреА рдпреЛрдЬрдирд╛рдПрдБ\n* - [ ] рдПрдХ рдЕрдзрд┐рдХ рд╢рдХреНрддрд┐рд╢рд╛рд▓реА рдлрд╛рдЙрдВрдбреЗрд╢рди рдореЙрдбрд▓ рдЬрд╛рд░реА рдХрд░реЗрдВ рдЬреЛ рдХрдИ рдХреНрд╖реЗрддреНрд░реЛрдВ рдХреЛ рдХрд╡рд░ рдХрд░реЗ рддрд╛рдХрд┐ рдЕрдзрд┐рдХ рдЖрдХрд░реНрд╖рдХ рдФрд░ рдЗрдорд░реНрд╕рд┐рд╡ рдлреЛрд▓реА рдирд┐рд░реНрдорд╛рдг рдкреНрд░рджрд╛рди рдХрд┐рдпрд╛ рдЬрд╛ рд╕рдХреЗ\n* - [ ] рдЕрддрд┐рд░рд┐рдХреНрдд рдореЛрдбрд╛рд▓рд┐рдЯреА рдФрд░ рдбрд╛рдЙрдирд╕реНрдЯреНрд░реАрдо рдХрд╛рд░реНрдпреЛрдВ рдХреЗ рд▓рд┐рдП рд╕рдорд░реНрдерди рдЬреЛрдбрд╝реЗрдВ\n* - [ ] рд╡рд┐рднрд┐рдиреНрди рд╕реНрддрд░реЛрдВ рдкрд░ рдореЙрдбрд▓ рдЬрд╛рд░реА рдХрд░реЗрдВ\n* - [x] AudioCoT рдбреЗрдЯрд╛рд╕реЗрдЯ рдФрд░ рд╕реНрд╡рдЪрд╛рд▓рд┐рдд рдкрд╛рдЗрдкрд▓рд╛рдЗрди рдХреЛ рдУрдкрди-рд╕реЛрд░реНрд╕ рдХрд░реЗрдВ\n* - [x] ThinkSound рдореЙрдбрд▓ рдХреЗ рд▓рд┐рдП рдкреНрд░рд╢рд┐рдХреНрд╖рдг рд╕реНрдХреНрд░рд┐рдкреНрдЯ рдЬрд╛рд░реА рдХрд░реЗрдВ\n* - [x] рд╢реБрд░реБрдЖрддреА рдХреЗ рд▓рд┐рдП Windows рдХреНрд╡рд┐рдХ-рд╕реНрдЯрд╛рд░реНрдЯ README рдЬрд╛рд░реА рдХрд░реЗрдВ\n---\n\n\n## ЁЯУД рд▓рд╛рдЗрд╕реЗрдВрд╕\n\nрдпрд╣ рдкрд░рд┐рдпреЛрдЬрдирд╛ Apache 2.0 рд▓рд╛рдЗрд╕реЗрдВрд╕ рдХреЗ рддрд╣рдд рдЬрд╛рд░реА рдХреА рдЧрдИ рд╣реИред\n\n> **рдиреЛрдЯ:**\n> рдХреЛрдб, рдореЙрдбрд▓, рдФрд░ рдбреЗрдЯрд╛рд╕реЗрдЯ **рдХреЗрд╡рд▓ рд╢реЛрдз рдФрд░ рд╢реИрдХреНрд╖рд┐рдХ рдЙрджреНрджреЗрд╢реНрдпреЛрдВ рдХреЗ рд▓рд┐рдП рд╣реИрдВ**ред\n> **рд╡реНрдпрд╛рд╡рд╕рд╛рдпрд┐рдХ рдЙрдкрдпреЛрдЧ рдХреА рдЕрдиреБрдорддрд┐ рдирд╣реАрдВ рд╣реИред**\n> рд╡реНрдпрд╛рд╡рд╕рд╛рдпрд┐рдХ рд▓рд╛рдЗрд╕реЗрдВрд╕рд┐рдВрдЧ рдХреЗ рд▓рд┐рдП, рдХреГрдкрдпрд╛ рд▓реЗрдЦрдХреЛрдВ рд╕реЗ рд╕рдВрдкрд░реНрдХ рдХрд░реЗрдВред\n\n**ЁЯУж рддреГрддреАрдп-рдкрдХреНрд╖ рдШрдЯрдХ**\n\n* **Stable Audio Open VAE** (Stability AI рджреНрд╡рд╛рд░рд╛):\n  рдпрд╣ рд░рд┐рдкреЙрдЬрд┐рдЯрд░реА [Stable Audio Open](https://huggingface.co/stabilityai/stable-audio-open-1.0/) рд╕реЗ рдлрд╛рдЗрди-рдЯреНрдпреВрди рдХрд┐рдпрд╛ рдЧрдпрд╛ VAE рд╢рд╛рдорд┐рд▓ рдХрд░рддреА рд╣реИ, рдЬреЛ [Stability AI Community License](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/./third_party/LICENSE_StabilityAI.md) рдХреЗ рдЕрдВрддрд░реНрдЧрдд рд▓рд╛рдЗрд╕реЗрдВрд╕ рдкреНрд░рд╛рдкреНрдд рд╣реИред\n  **рд╡реНрдпрд╛рд╡рд╕рд╛рдпрд┐рдХ рдЙрдкрдпреЛрдЧ рдФрд░ рдкреБрдирд░реНрд╡рд┐рддрд░рдг рдХреЗ рд▓рд┐рдП Stability AI рд╕реЗ рдкреВрд░реНрд╡ рдЕрдиреБрдорддрд┐ рдЖрд╡рд╢реНрдпрдХ рд╣реИред**\n\n* ЁЯУШ **рдЕрдиреНрдп рд╕рднреА рдХреЛрдб рдФрд░ рдореЙрдбрд▓** Apache License 2.0 рдХреЗ рддрд╣рдд рдЬрд╛рд░реА рдХрд┐рдП рдЧрдП рд╣реИрдВред\n\n---\n\n## рдЖрднрд╛рд░\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 16,
    "Content": "Many thanks to:\n\n* **stable-audio-tools** (by Stability AI):\nFor providing an easy-to-use framework for audio generation, as well as the VAE module and weights.\n* **MMAudio**:\n  For the implementation of the MM-DiT backbone in the audio domain.\n\n---\n\n## ЁЯУЦ Citation\n\nIf you find ThinkSound useful in your research or work, please cite our paper:\n",
    "ContentSha": "FsK5U++tkthvkZ/Gd4G7gn74YKpB282Oxnkt96u9C1k=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "рдмрд╣реБрдд рдзрдиреНрдпрд╡рд╛рдж:\n\n* **stable-audio-tools** (Stability AI рджреНрд╡рд╛рд░рд╛):\nрдСрдбрд┐рдпреЛ рдЬрдирд░реЗрд╢рди рдХреЗ рд▓рд┐рдП рдЖрд╕рд╛рди рдлреНрд░реЗрдорд╡рд░реНрдХ рдкреНрд░рджрд╛рди рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП, рд╕рд╛рде рд╣реА VAE рдореЙрдбреНрдпреВрд▓ рдФрд░ рд╡рдЬрд╝рди рдХреЗ рд▓рд┐рдПред\n* **MMAudio**:\n  рдСрдбрд┐рдпреЛ рдбреЛрдореЗрди рдореЗрдВ MM-DiT рдмреИрдХрдмреЛрди рдХреЗ рдХрд╛рд░реНрдпрд╛рдиреНрд╡рдпрди рдХреЗ рд▓рд┐рдПред\n\n---\n\n## ЁЯУЦ рдЙрджреНрдзрд░рдг\n\nрдпрджрд┐ рдЖрдкрдХреЛ ThinkSound рдЕрдкрдиреЗ рд╢реЛрдз рдпрд╛ рдХрд╛рд░реНрдп рдореЗрдВ рдЙрдкрдпреЛрдЧреА рд▓рдЧреЗ, рддреЛ рдХреГрдкрдпрд╛ рд╣рдорд╛рд░реЗ рдкреЗрдкрд░ рдХрд╛ рдЙрд▓реНрд▓реЗрдЦ рдХрд░реЗрдВ:\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 17,
    "Content": "```bibtex\n@misc{liu2025thinksoundchainofthoughtreasoningmultimodal,\n      title={ThinkSound: Chain-of-Thought Reasoning in Multimodal Large Language Models for Audio Generation and Editing}, \n      author={Huadai Liu and Jialei Wang and Kaicheng Luo and Wen Wang and Qian Chen and Zhou Zhao and Wei Xue},\n      year={2025},\n      eprint={2506.21448},\n      archivePrefix={arXiv},\n      primaryClass={eess.AS},\n      url={https://arxiv.org/abs/2506.21448}, \n}\n```",
    "ContentSha": "KKv35iBt6IDF1ifN04L+6lkh0BHkbObnW/+m50Wufrs=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bibtex\n@misc{liu2025thinksoundchainofthoughtreasoningmultimodal,\n      title={ThinkSound: Chain-of-Thought Reasoning in Multimodal Large Language Models for Audio Generation and Editing}, \n      author={Huadai Liu and Jialei Wang and Kaicheng Luo and Wen Wang and Qian Chen and Zhou Zhao and Wei Xue},\n      year={2025},\n      eprint={2506.21448},\n      archivePrefix={arXiv},\n      primaryClass={eess.AS},\n      url={https://arxiv.org/abs/2506.21448}, \n}\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 18,
    "Content": "\n---\n\n## ЁЯУм Contact\n\n\nтЬи Feel free to [open an issue](https://github.com/liuhuadai/ThinkSound/issues) or contact us via email ([liuhuadai@zju.edu.cn](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/mailto:liuhuadai@zju.edu.cn)) if you have any questions or suggestions!\n\n\n",
    "ContentSha": "QMNRHPzbmsL2YxrLNEPneJCBrTj4/XiY9XGTX01NZl8=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "\n---\n\n## ЁЯУм Contact\n\n\nтЬи Feel free to [open an issue](https://github.com/liuhuadai/ThinkSound/issues) or contact us via email ([liuhuadai@zju.edu.cn](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/mailto:liuhuadai@zju.edu.cn)) if you have any questions or suggestions!\n\n\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 2,
        "rowsha": "yz+R1U7uMOU+NbK5mQX3Dxae1Un9eJCdPawt78ntjTs=",
        "originContent": "---",
        "translatedContent": "---"
      },
      {
        "row": 3,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 4,
        "rowsha": "V0ea1xQLKG+cGj5kHVv5f15HDd+yj0ulkcBQnvErdJc=",
        "originContent": "## ЁЯУм Contact",
        "translatedContent": "## ЁЯУм Contact"
      },
      {
        "row": 5,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 6,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 7,
        "rowsha": "QsDuVwX1DXlTNejKuNftx4k1x7yNHjfP9/1HS85hJng=",
        "originContent": "тЬи Feel free to [open an issue](https://github.com/liuhuadai/ThinkSound/issues) or contact us via email ([liuhuadai@zju.edu.cn](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/mailto:liuhuadai@zju.edu.cn)) if you have any questions or suggestions!",
        "translatedContent": "тЬи Feel free to [open an issue](https://github.com/liuhuadai/ThinkSound/issues) or contact us via email ([liuhuadai@zju.edu.cn](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/mailto:liuhuadai@zju.edu.cn)) if you have any questions or suggestions!"
      },
      {
        "row": 8,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 9,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 10,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  }
]