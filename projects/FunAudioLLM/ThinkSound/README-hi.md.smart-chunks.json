[
  {
    "Id": 1,
    "Content": "<h1 align=\"center\">ThinkSound</h1>\n\n<p align=\"center\">\n  üåê\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=en\">English</a> |\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=zh-CN\">ÁÆÄ‰Ωì‰∏≠Êñá</a> |\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=zh-TW\">ÁπÅÈ´î‰∏≠Êñá</a> |\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=es\">Espa√±ol</a> |\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=fr\">Fran√ßais</a> |\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=ja\">Êó•Êú¨Ë™û</a>\n  \n</p>\n<p align=\"center\">\n  <img src=\"https://img.shields.io/badge/NeurIPS 2025-Main Conference-blue.svg\" alt=\"NeurIPS 2025\"/>\n<p align=\"center\">\n  <a href=\"https://arxiv.org/pdf/2506.21448\">\n    <img src=\"https://img.shields.io/badge/arXiv-2506.21448-b31b1b.svg\" alt=\"arXiv\"/>\n  </a>\n  &nbsp;\n  <a href=\"https://thinksound-project.github.io/\">\n    <img src=\"https://img.shields.io/badge/Online%20Demo-üåê-blue\" alt=\"Online Demo\"/>\n  </a>\n  &nbsp;\n  <a href=\"https://huggingface.co/spaces/FunAudioLLM/ThinkSound\">\n    <img src=\"https://img.shields.io/badge/HuggingFace-Spaces-orange?logo=huggingface\" alt=\"Hugging Face\"/>\n  </a>\n  &nbsp;\n  <a href=\"https://modelscope.cn/studios/iic/ThinkSound\">\n    <img src=\"https://img.shields.io/badge/ModelScope-Âú®Á∫ø‰ΩìÈ™å-green\" alt=\"ModelScope\"/>\n  </a>\n</p>\n\n<p align=\"center\">\n  If you find this project useful,<br>\n  a star ‚≠ê on GitHub would be greatly appreciated!\n</p>\n\n---\n\n**ThinkSound** is a unified Any2Audio generation framework with flow matching guided by Chain-of-Thought (CoT) reasoning.",
    "ContentSha": "3764VshEOMedejxsV+uo8k5R5Emk0MLuYfIOX8JadcY=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "<h1 align=\"center\">ThinkSound</h1>\n\n<p align=\"center\">\n  üåê\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=en\">English</a> |\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=zh-CN\">ÁÆÄ‰Ωì‰∏≠Êñá</a> |\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=zh-TW\">ÁπÅÈ´î‰∏≠Êñá</a> |\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=es\">Espa√±ol</a> |\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=fr\">Fran√ßais</a> |\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=ja\">Êó•Êú¨Ë™û</a>\n  \n</p>\n<p align=\"center\">\n  <img src=\"https://img.shields.io/badge/NeurIPS 2025-Main Conference-blue.svg\" alt=\"NeurIPS 2025\"/>\n<p align=\"center\">\n  <a href=\"https://arxiv.org/pdf/2506.21448\">\n    <img src=\"https://img.shields.io/badge/arXiv-2506.21448-b31b1b.svg\" alt=\"arXiv\"/>\n  </a>\n  &nbsp;\n  <a href=\"https://thinksound-project.github.io/\">\n    <img src=\"https://img.shields.io/badge/Online%20Demo-üåê-blue\" alt=\"Online Demo\"/>\n  </a>\n  &nbsp;\n  <a href=\"https://huggingface.co/spaces/FunAudioLLM/ThinkSound\">\n    <img src=\"https://img.shields.io/badge/HuggingFace-Spaces-orange?logo=huggingface\" alt=\"Hugging Face\"/>\n  </a>\n  &nbsp;\n  <a href=\"https://modelscope.cn/studios/iic/ThinkSound\">\n    <img src=\"https://img.shields.io/badge/ModelScope-Âú®Á∫ø‰ΩìÈ™å-green\" alt=\"ModelScope\"/>\n  </a>\n</p>\n\n<p align=\"center\">\n  ‡§Ø‡§¶‡§ø ‡§Ü‡§™‡§ï‡•ã ‡§Ø‡§π ‡§™‡•ç‡§∞‡•ã‡§ú‡•á‡§ï‡•ç‡§ü ‡§â‡§™‡§Ø‡•ã‡§ó‡•Ä ‡§≤‡§ó‡•á,<br>\n  GitHub ‡§™‡§∞ ‡§è‡§ï ‡§∏‡•ç‡§ü‡§æ‡§∞ ‚≠ê ‡§¶‡•á‡§®‡§æ ‡§Ö‡§§‡•ç‡§Ø‡§Ç‡§§ ‡§∏‡§∞‡§æ‡§π‡§®‡•Ä‡§Ø ‡§π‡•ã‡§ó‡§æ!\n</p>\n\n---\n\n**ThinkSound** ‡§è‡§ï ‡§è‡§ï‡•Ä‡§ï‡•É‡§§ Any2Audio ‡§ú‡§®‡§∞‡•á‡§∂‡§® ‡§´‡•ç‡§∞‡•á‡§Æ‡§µ‡§∞‡•ç‡§ï ‡§π‡•à, ‡§ú‡§ø‡§∏‡§Æ‡•á‡§Ç Chain-of-Thought (CoT) ‡§∞‡•Ä‡§ú‡§®‡§ø‡§Ç‡§ó ‡§¶‡•ç‡§µ‡§æ‡§∞‡§æ ‡§´‡•ç‡§≤‡•ã ‡§Æ‡•à‡§ö‡§ø‡§Ç‡§ó ‡§ï‡§æ ‡§Æ‡§æ‡§∞‡•ç‡§ó‡§¶‡§∞‡•ç‡§∂‡§® ‡§ï‡§ø‡§Ø‡§æ ‡§ú‡§æ‡§§‡§æ ‡§π‡•à‡•§",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "JxESpSOemcOHL7YK3E5sXNUt0UcsbKqLYX+tuvsu7P4=",
        "originContent": "<h1 align=\"center\">ThinkSound</h1>",
        "translatedContent": "<h1 align=\"center\">ThinkSound</h1>"
      },
      {
        "row": 2,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 3,
        "rowsha": "+/a9XmPwQixGFroME/GMEOLpReZZV4ARosR9orAplJY=",
        "originContent": "<p align=\"center\">",
        "translatedContent": "<p align=\"center\">"
      },
      {
        "row": 4,
        "rowsha": "CSeo6S41hUQEjrndf6ijg79FX29RUxiFJUVIA3cYsNQ=",
        "originContent": "  üåê",
        "translatedContent": "  üåê"
      },
      {
        "row": 5,
        "rowsha": "IJLGqpRt+7ez3r1WoZz6fvh/rC+8KZ5K3FP2xs/0LNM=",
        "originContent": "  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=en\">English</a> |",
        "translatedContent": "  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=en\">English</a> |"
      },
      {
        "row": 6,
        "rowsha": "hhbPoa8bqBB7SPpAAUVT30o77g3w0Ky5ywfQeyLf1j4=",
        "originContent": "  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=zh-CN\">ÁÆÄ‰Ωì‰∏≠Êñá</a> |",
        "translatedContent": "  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=zh-CN\">ÁÆÄ‰Ωì‰∏≠Êñá</a> |"
      },
      {
        "row": 7,
        "rowsha": "tRfgQgD9d867JyLy4SUrBX76D1lWSxv43P6AXFC6S+E=",
        "originContent": "  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=zh-TW\">ÁπÅÈ´î‰∏≠Êñá</a> |",
        "translatedContent": "  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=zh-TW\">ÁπÅÈ´î‰∏≠Êñá</a> |"
      },
      {
        "row": 8,
        "rowsha": "6wLn1diFukrW2YDUESRE3YVcqNY3dxojo6fHTtwy5Pw=",
        "originContent": "  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=es\">Espa√±ol</a> |",
        "translatedContent": "  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=es\">Espa√±ol</a> |"
      },
      {
        "row": 9,
        "rowsha": "evSE8XG0v3qXaLIwGU0C7m+8gbYGsKYAemuq5Tn6Xog=",
        "originContent": "  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=fr\">Fran√ßais</a> |",
        "translatedContent": "  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=fr\">Fran√ßais</a> |"
      },
      {
        "row": 10,
        "rowsha": "9f+fFClA7BNYID46cHbx1rrKXWcVW5LDZW5Zy7DVZ+w=",
        "originContent": "  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=ja\">Êó•Êú¨Ë™û</a>",
        "translatedContent": "  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=ja\">Êó•Êú¨Ë™û</a>"
      },
      {
        "row": 11,
        "rowsha": "bBefIeb2K2KQVdirQPRU7QLki2hWORNHO4V9NjjiOyg=",
        "originContent": "  ",
        "translatedContent": "  "
      },
      {
        "row": 12,
        "rowsha": "dSdvPNAZSmR86FDDSF6tkQUCVfI9qmACHOR5tThOetY=",
        "originContent": "</p>",
        "translatedContent": "</p>"
      },
      {
        "row": 13,
        "rowsha": "+/a9XmPwQixGFroME/GMEOLpReZZV4ARosR9orAplJY=",
        "originContent": "<p align=\"center\">",
        "translatedContent": "<p align=\"center\">"
      },
      {
        "row": 14,
        "rowsha": "u6qveIBtgMElVk/Aw6sAj4eJ8Fk+KrPya5ZyECHKRqA=",
        "originContent": "  <img src=\"https://img.shields.io/badge/NeurIPS 2025-Main Conference-blue.svg\" alt=\"NeurIPS 2025\"/>",
        "translatedContent": "  <img src=\"https://img.shields.io/badge/NeurIPS 2025-Main Conference-blue.svg\" alt=\"NeurIPS 2025\"/>"
      },
      {
        "row": 15,
        "rowsha": "+/a9XmPwQixGFroME/GMEOLpReZZV4ARosR9orAplJY=",
        "originContent": "<p align=\"center\">",
        "translatedContent": "<p align=\"center\">"
      },
      {
        "row": 16,
        "rowsha": "U41oE9v936BfSGDgJuMB1g3jQTqsJtmJPQUhVonUNHI=",
        "originContent": "  <a href=\"https://arxiv.org/pdf/2506.21448\">",
        "translatedContent": "  <a href=\"https://arxiv.org/pdf/2506.21448\">"
      },
      {
        "row": 17,
        "rowsha": "ynIImIY0Z2jVqizQykbwGTP/PcL0XGIQs5BslFVtz58=",
        "originContent": "    <img src=\"https://img.shields.io/badge/arXiv-2506.21448-b31b1b.svg\" alt=\"arXiv\"/>",
        "translatedContent": "    <img src=\"https://img.shields.io/badge/arXiv-2506.21448-b31b1b.svg\" alt=\"arXiv\"/>"
      },
      {
        "row": 18,
        "rowsha": "7Sl5c7caJ7+Yt222Hl2I2PLtk1UIeh8Qfn02MNONw0Y=",
        "originContent": "  </a>",
        "translatedContent": "  </a>"
      },
      {
        "row": 19,
        "rowsha": "robEj93GNR0ga47/E63BGVUMman0bHA00TiujTzIdqs=",
        "originContent": "  &nbsp;",
        "translatedContent": "  &nbsp;"
      },
      {
        "row": 20,
        "rowsha": "Yff0X0Mje5Jr8Vv7MEJie2CoYJL+UpE7RrCgKgVeN0c=",
        "originContent": "  <a href=\"https://thinksound-project.github.io/\">",
        "translatedContent": "  <a href=\"https://thinksound-project.github.io/\">"
      },
      {
        "row": 21,
        "rowsha": "H+PqZbUh0elg8uffxX9z5kKKpS5/odGusuxfm7oCW7w=",
        "originContent": "    <img src=\"https://img.shields.io/badge/Online%20Demo-üåê-blue\" alt=\"Online Demo\"/>",
        "translatedContent": "    <img src=\"https://img.shields.io/badge/Online%20Demo-üåê-blue\" alt=\"Online Demo\"/>"
      },
      {
        "row": 22,
        "rowsha": "7Sl5c7caJ7+Yt222Hl2I2PLtk1UIeh8Qfn02MNONw0Y=",
        "originContent": "  </a>",
        "translatedContent": "  </a>"
      },
      {
        "row": 23,
        "rowsha": "robEj93GNR0ga47/E63BGVUMman0bHA00TiujTzIdqs=",
        "originContent": "  &nbsp;",
        "translatedContent": "  &nbsp;"
      },
      {
        "row": 24,
        "rowsha": "8w8i7BBaV0MFFj9oV8SQ9+mUcgmT0lDsYIGPYBRMK4k=",
        "originContent": "  <a href=\"https://huggingface.co/spaces/FunAudioLLM/ThinkSound\">",
        "translatedContent": "  <a href=\"https://huggingface.co/spaces/FunAudioLLM/ThinkSound\">"
      },
      {
        "row": 25,
        "rowsha": "MShdQrgDW0rCwuvHGbK9UiqT/w2XoWfU6MCC4EQ8Oo0=",
        "originContent": "    <img src=\"https://img.shields.io/badge/HuggingFace-Spaces-orange?logo=huggingface\" alt=\"Hugging Face\"/>",
        "translatedContent": "    <img src=\"https://img.shields.io/badge/HuggingFace-Spaces-orange?logo=huggingface\" alt=\"Hugging Face\"/>"
      },
      {
        "row": 26,
        "rowsha": "7Sl5c7caJ7+Yt222Hl2I2PLtk1UIeh8Qfn02MNONw0Y=",
        "originContent": "  </a>",
        "translatedContent": "  </a>"
      },
      {
        "row": 27,
        "rowsha": "robEj93GNR0ga47/E63BGVUMman0bHA00TiujTzIdqs=",
        "originContent": "  &nbsp;",
        "translatedContent": "  &nbsp;"
      },
      {
        "row": 28,
        "rowsha": "ycu3inIAlcQNI/CFyarNMwyiRfw4GtBsvcc/0LcD3c0=",
        "originContent": "  <a href=\"https://modelscope.cn/studios/iic/ThinkSound\">",
        "translatedContent": "  <a href=\"https://modelscope.cn/studios/iic/ThinkSound\">"
      },
      {
        "row": 29,
        "rowsha": "4Z9FQa2ROL8/O+DmziXnhj/aKyTxS9GGOmocWYnVJ6g=",
        "originContent": "    <img src=\"https://img.shields.io/badge/ModelScope-Âú®Á∫ø‰ΩìÈ™å-green\" alt=\"ModelScope\"/>",
        "translatedContent": "    <img src=\"https://img.shields.io/badge/ModelScope-Âú®Á∫ø‰ΩìÈ™å-green\" alt=\"ModelScope\"/>"
      },
      {
        "row": 30,
        "rowsha": "7Sl5c7caJ7+Yt222Hl2I2PLtk1UIeh8Qfn02MNONw0Y=",
        "originContent": "  </a>",
        "translatedContent": "  </a>"
      },
      {
        "row": 31,
        "rowsha": "dSdvPNAZSmR86FDDSF6tkQUCVfI9qmACHOR5tThOetY=",
        "originContent": "</p>",
        "translatedContent": "</p>"
      },
      {
        "row": 32,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 33,
        "rowsha": "+/a9XmPwQixGFroME/GMEOLpReZZV4ARosR9orAplJY=",
        "originContent": "<p align=\"center\">",
        "translatedContent": "<p align=\"center\">"
      },
      {
        "row": 34,
        "rowsha": "fxEtxfqHrh5PDQ2L/Ev2ea69zRukpezpCLPOHXsEpDw=",
        "originContent": "  If you find this project useful,<br>",
        "translatedContent": "  ‡§Ø‡§¶‡§ø ‡§Ü‡§™‡§ï‡•ã ‡§Ø‡§π ‡§™‡•ç‡§∞‡•ã‡§ú‡•á‡§ï‡•ç‡§ü ‡§â‡§™‡§Ø‡•ã‡§ó‡•Ä ‡§≤‡§ó‡•á,<br>"
      },
      {
        "row": 35,
        "rowsha": "oOAWVtx09WaVCvchPgX0GhZlzuPjXH1p6nhjfyZ2aS8=",
        "originContent": "  a star ‚≠ê on GitHub would be greatly appreciated!",
        "translatedContent": "  GitHub ‡§™‡§∞ ‡§è‡§ï ‡§∏‡•ç‡§ü‡§æ‡§∞ ‚≠ê ‡§¶‡•á‡§®‡§æ ‡§Ö‡§§‡•ç‡§Ø‡§Ç‡§§ ‡§∏‡§∞‡§æ‡§π‡§®‡•Ä‡§Ø ‡§π‡•ã‡§ó‡§æ!"
      },
      {
        "row": 36,
        "rowsha": "dSdvPNAZSmR86FDDSF6tkQUCVfI9qmACHOR5tThOetY=",
        "originContent": "</p>",
        "translatedContent": "</p>"
      },
      {
        "row": 37,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 38,
        "rowsha": "yz+R1U7uMOU+NbK5mQX3Dxae1Un9eJCdPawt78ntjTs=",
        "originContent": "---",
        "translatedContent": "---"
      },
      {
        "row": 39,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 40,
        "rowsha": "FQA4zA43MxvNXTogMO1WpS71bCSxerCOM1e/tmSmotg=",
        "originContent": "**ThinkSound** is a unified Any2Audio generation framework with flow matching guided by Chain-of-Thought (CoT) reasoning.",
        "translatedContent": "**ThinkSound** ‡§è‡§ï ‡§è‡§ï‡•Ä‡§ï‡•É‡§§ Any2Audio ‡§ú‡§®‡§∞‡•á‡§∂‡§® ‡§´‡•ç‡§∞‡•á‡§Æ‡§µ‡§∞‡•ç‡§ï ‡§π‡•à, ‡§ú‡§ø‡§∏‡§Æ‡•á‡§Ç Chain-of-Thought (CoT) ‡§∞‡•Ä‡§ú‡§®‡§ø‡§Ç‡§ó ‡§¶‡•ç‡§µ‡§æ‡§∞‡§æ ‡§´‡•ç‡§≤‡•ã ‡§Æ‡•à‡§ö‡§ø‡§Ç‡§ó ‡§ï‡§æ ‡§Æ‡§æ‡§∞‡•ç‡§ó‡§¶‡§∞‡•ç‡§∂‡§® ‡§ï‡§ø‡§Ø‡§æ ‡§ú‡§æ‡§§‡§æ ‡§π‡•à‡•§"
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 2,
    "Content": "\nPyTorch implementation for multimodal audio generation and editing: generate or edit audio from video, text, and audio, powered by step-by-step reasoning from Multimodal Large Language Models (MLLMs).\n\n![Teaser](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig1_teaser.png)\n---\n\n## üì∞ News\n- **2025.09.19** &nbsp; üéâ ThinkSound has been accepted to the **NeurIPS 2025 Main Conference**!\n- **2025.09.01** &nbsp; üî• Our AudioCoT dataset is now open-sourced and available on [Hugging Face](https://huggingface.co/datasets/liuhuadai/AudioCoT)!\n- **2025.07.17** &nbsp; üß† Finetuning enabled: training and finetuning code is now publicly available, along with clear usage instructions to help you customize and extend ThinkSound with your own data.\n- **2025.07.15** &nbsp; üì¶ Simplified installation and usability: dependencies on PyPI for easy cross-platform setup; Windows `.bat` scripts automate environment creation and script running.\n- **2025.07.08** &nbsp;¬† üîß Major update: model lightweighted and optimized memory and GPU usage, now supports high-throughput audio generation at scale!\n- **2025.07.01** &nbsp; üî•Online demo on [Hugging Face Spaces](https://huggingface.co/spaces/FunAudioLLM/ThinkSound) and [ModelScope](https://modelscope.cn/studios/iic/ThinkSound) for interactive experience!\n- **2025.07.01** &nbsp; üî•Released inference scripts and web interface; \n- **2025.06** &nbsp; üî•[ThinkSound paper](https://arxiv.org/pdf/2506.21448) released on arXiv!\n- **2025.06** &nbsp; üî•[Online Demo](http://thinksound-project.github.io/) is live - try it now!\n\n---\n\n\n## üöÄ Features\n\n- **Any2Audio**: Generate audio from arbitrary modalities ‚Äî video, text, audio, or their combinations.\n- **Video-to-Audio SOTA**: Achieves state-of-the-art results on multiple V2A benchmarks.\n- **CoT-Driven Reasoning**: Chain-of-Thought reasoning for compositional and controllable audio generation via MLLMs.\n- **Interactive Object-centric Editing**: Refine or edit specific sound events by clicking on visual objects or using text instructions.\n- **Unified Framework**: One foundation model supports generation, editing, and interactive workflow.\n\n---\n\n## ‚ú® Method Overview\n\nThinkSound decomposes audio generation and editing into three interactive stages, all guided by MLLM-based Chain-of-Thought (CoT) reasoning:\n\n1. **Foley Generation:** Generate foundational, semantically and temporally aligned soundscapes from video.\n2. **Object-Centric Refinement:** Refine or add sounds for user-specified objects via clicks or regions in the video.\n3. **Targeted Audio Editing:** Modify generated audio using high-level natural language instructions.\n\n![ThinkSound Overview](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig3_model.png)\n<!-- A large-scale CoT-annotated dataset (**AudioCoT**) is used to train both the reasoning module and the unified audio foundation model.",
    "ContentSha": "xWOsD5dMva4LPU9wVQzeoz92/nlNRN5MfF+aKLc1VuU=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "\n‡§Æ‡§≤‡•ç‡§ü‡•Ä‡§Æ‡•â‡§°‡§≤ ‡§ë‡§°‡§ø‡§Ø‡•ã ‡§ú‡•á‡§®‡§∞‡•á‡§∂‡§® ‡§î‡§∞ ‡§è‡§°‡§ø‡§ü‡§ø‡§Ç‡§ó ‡§ï‡•á ‡§≤‡§ø‡§è PyTorch ‡§á‡§Æ‡•ç‡§™‡•ç‡§≤‡•Ä‡§Æ‡•á‡§Ç‡§ü‡•á‡§∂‡§®: ‡§µ‡•Ä‡§°‡§ø‡§Ø‡•ã, ‡§ü‡•á‡§ï‡•ç‡§∏‡•ç‡§ü ‡§î‡§∞ ‡§ë‡§°‡§ø‡§Ø‡•ã ‡§∏‡•á ‡§ë‡§°‡§ø‡§Ø‡•ã ‡§ú‡§®‡§∞‡•á‡§ü ‡§Ø‡§æ ‡§è‡§°‡§ø‡§ü ‡§ï‡§∞‡•á‡§Ç, ‡§Æ‡§≤‡•ç‡§ü‡•Ä‡§Æ‡•â‡§°‡§≤ ‡§≤‡§æ‡§∞‡•ç‡§ú ‡§≤‡•à‡§Ç‡§ó‡•ç‡§µ‡•á‡§ú ‡§Æ‡•â‡§°‡§≤‡•ç‡§∏ (MLLMs) ‡§ï‡•Ä ‡§∏‡•ç‡§ü‡•á‡§™-‡§¨‡§æ‡§Ø-‡§∏‡•ç‡§ü‡•á‡§™ ‡§∞‡•Ä‡§ú‡§®‡§ø‡§Ç‡§ó ‡§¶‡•ç‡§µ‡§æ‡§∞‡§æ ‡§∏‡§Ç‡§ö‡§æ‡§≤‡§ø‡§§‡•§\n\n![‡§ü‡•Ä‡§ú‡§º‡§∞](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig1_teaser.png)\n---\n\n## üì∞ ‡§∏‡§Æ‡§æ‡§ö‡§æ‡§∞\n- **2025.09.19** &nbsp; üéâ ThinkSound ‡§ï‡•ã **NeurIPS 2025 ‡§Æ‡•Å‡§ñ‡•ç‡§Ø ‡§∏‡§Æ‡•ç‡§Æ‡•á‡§≤‡§®** ‡§Æ‡•á‡§Ç ‡§∏‡•ç‡§µ‡•Ä‡§ï‡•É‡§§‡§ø ‡§Æ‡§ø‡§≤‡•Ä ‡§π‡•à!\n- **2025.09.01** &nbsp; üî• ‡§π‡§Æ‡§æ‡§∞‡§æ AudioCoT ‡§°‡•á‡§ü‡§æ‡§∏‡•á‡§ü ‡§Ö‡§¨ ‡§ì‡§™‡§®-‡§∏‡•ã‡§∞‡•ç‡§∏ ‡§π‡•à ‡§î‡§∞ [Hugging Face](https://huggingface.co/datasets/liuhuadai/AudioCoT) ‡§™‡§∞ ‡§â‡§™‡§≤‡§¨‡•ç‡§ß ‡§π‡•à!\n- **2025.07.17** &nbsp; üß† ‡§´‡§æ‡§á‡§®‡§ü‡•ç‡§Ø‡•Ç‡§®‡§ø‡§Ç‡§ó ‡§∏‡§ï‡•ç‡§∑‡§Æ: ‡§ü‡•ç‡§∞‡•á‡§®‡§ø‡§Ç‡§ó ‡§î‡§∞ ‡§´‡§æ‡§á‡§®‡§ü‡•ç‡§Ø‡•Ç‡§®‡§ø‡§Ç‡§ó ‡§ï‡•ã‡§° ‡§Ö‡§¨ ‡§∏‡§æ‡§∞‡•ç‡§µ‡§ú‡§®‡§ø‡§ï ‡§∞‡•Ç‡§™ ‡§∏‡•á ‡§â‡§™‡§≤‡§¨‡•ç‡§ß ‡§π‡•à, ‡§∏‡•ç‡§™‡§∑‡•ç‡§ü ‡§®‡§ø‡§∞‡•ç‡§¶‡•á‡§∂‡•ã‡§Ç ‡§ï‡•á ‡§∏‡§æ‡§• ‡§ú‡§ø‡§∏‡§∏‡•á ‡§Ü‡§™ ‡§Ö‡§™‡§®‡•á ‡§°‡•á‡§ü‡§æ ‡§ï‡•á ‡§∏‡§æ‡§• ThinkSound ‡§ï‡•ã ‡§ï‡§∏‡•ç‡§ü‡§Æ‡§æ‡§á‡§ú‡§º ‡§î‡§∞ ‡§è‡§ï‡•ç‡§∏‡§ü‡•á‡§Ç‡§° ‡§ï‡§∞ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç‡•§\n- **2025.07.15** &nbsp; üì¶ ‡§Ü‡§∏‡§æ‡§® ‡§á‡§Ç‡§∏‡•ç‡§ü‡•â‡§≤‡•á‡§∂‡§® ‡§î‡§∞ ‡§â‡§™‡§Ø‡•ã‡§ó‡§ø‡§§‡§æ: PyPI ‡§™‡§∞ ‡§°‡§ø‡§™‡•á‡§Ç‡§°‡•á‡§Ç‡§∏‡•Ä‡•õ ‡§ï‡•ç‡§∞‡•â‡§∏-‡§™‡•ç‡§≤‡•á‡§ü‡§´‡•â‡§∞‡•ç‡§Æ ‡§∏‡•á‡§ü‡§Ö‡§™ ‡§ï‡•á ‡§≤‡§ø‡§è; Windows `.bat` ‡§∏‡•ç‡§ï‡•ç‡§∞‡§ø‡§™‡•ç‡§ü‡•ç‡§∏ ‡§µ‡§æ‡§§‡§æ‡§µ‡§∞‡§£ ‡§®‡§ø‡§∞‡•ç‡§Æ‡§æ‡§£ ‡§î‡§∞ ‡§∏‡•ç‡§ï‡•ç‡§∞‡§ø‡§™‡•ç‡§ü ‡§∞‡§®‡§ø‡§Ç‡§ó ‡§ï‡•ã ‡§ë‡§ü‡•ã‡§Æ‡•á‡§ü ‡§ï‡§∞‡§§‡•Ä ‡§π‡•à‡§Ç‡•§\n- **2025.07.08** &nbsp;¬† üîß ‡§™‡•ç‡§∞‡§Æ‡•Å‡§ñ ‡§Ö‡§™‡§°‡•á‡§ü: ‡§Æ‡•â‡§°‡§≤ ‡§ï‡•ã ‡§π‡§≤‡•ç‡§ï‡§æ ‡§î‡§∞ ‡§Æ‡•á‡§Æ‡•ã‡§∞‡•Ä ‡§µ GPU ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡•ã ‡§ë‡§™‡•ç‡§ü‡§ø‡§Æ‡§æ‡§á‡•õ ‡§ï‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ, ‡§Ö‡§¨ ‡§¨‡§°‡§º‡•á ‡§™‡•à‡§Æ‡§æ‡§®‡•á ‡§™‡§∞ ‡§π‡§æ‡§à-‡§•‡•ç‡§∞‡•Ç‡§™‡•Å‡§ü ‡§ë‡§°‡§ø‡§Ø‡•ã ‡§ú‡•á‡§®‡§∞‡•á‡§∂‡§® ‡§ï‡•ã ‡§∏‡§™‡•ã‡§∞‡•ç‡§ü ‡§ï‡§∞‡§§‡§æ ‡§π‡•à!\n- **2025.07.01** &nbsp; üî•‡§ë‡§®‡§≤‡§æ‡§á‡§® ‡§°‡•á‡§Æ‡•ã [Hugging Face Spaces](https://huggingface.co/spaces/FunAudioLLM/ThinkSound) ‡§î‡§∞ [ModelScope](https://modelscope.cn/studios/iic/ThinkSound) ‡§™‡§∞ ‡§á‡§Ç‡§ü‡§∞‡§è‡§ï‡•ç‡§ü‡§ø‡§µ ‡§Ö‡§®‡•Å‡§≠‡§µ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§â‡§™‡§≤‡§¨‡•ç‡§ß!\n- **2025.07.01** &nbsp; üî•‡§á‡§®‡•ç‡§´‡•á‡§∞‡•á‡§Ç‡§∏ ‡§∏‡•ç‡§ï‡•ç‡§∞‡§ø‡§™‡•ç‡§ü‡•ç‡§∏ ‡§î‡§∞ ‡§µ‡•á‡§¨ ‡§á‡§Ç‡§ü‡§∞‡§´‡•á‡§∏ ‡§ú‡§æ‡§∞‡•Ä ‡§ï‡§ø‡§è ‡§ó‡§è;\n- **2025.06** &nbsp; üî•[ThinkSound ‡§™‡•á‡§™‡§∞](https://arxiv.org/pdf/2506.21448) arXiv ‡§™‡§∞ ‡§ú‡§æ‡§∞‡•Ä!\n- **2025.06** &nbsp; üî•[‡§ë‡§®‡§≤‡§æ‡§á‡§® ‡§°‡•á‡§Æ‡•ã](http://thinksound-project.github.io/) ‡§≤‡§æ‡§á‡§µ ‡§π‡•à - ‡§Ö‡§≠‡•Ä ‡§Ü‡§ú‡§º‡§Æ‡§æ‡§è‡§Å!\n\n---\n\n\n## üöÄ ‡§µ‡§ø‡§∂‡•á‡§∑‡§§‡§æ‡§è‡§Å\n\n- **Any2Audio**: ‡§ï‡§ø‡§∏‡•Ä ‡§≠‡•Ä ‡§Æ‡•ã‡§°‡§æ‡§≤‡§ø‡§ü‡•Ä ‡§∏‡•á ‡§ë‡§°‡§ø‡§Ø‡•ã ‡§ú‡§®‡§∞‡•á‡§ü ‡§ï‡§∞‡•á‡§Ç ‚Äî ‡§µ‡•Ä‡§°‡§ø‡§Ø‡•ã, ‡§ü‡•á‡§ï‡•ç‡§∏‡•ç‡§ü, ‡§ë‡§°‡§ø‡§Ø‡•ã ‡§Ø‡§æ ‡§â‡§®‡§ï‡•á ‡§∏‡§Ç‡§Ø‡•ã‡§ú‡§®‡•§\n- **‡§µ‡•Ä‡§°‡§ø‡§Ø‡•ã-‡§ü‡•Ç-‡§ë‡§°‡§ø‡§Ø‡•ã SOTA**: ‡§ï‡§à V2A ‡§¨‡•á‡§Ç‡§ö‡§Æ‡§æ‡§∞‡•ç‡§ï‡•ç‡§∏ ‡§™‡§∞ ‡§∏‡§∞‡•ç‡§µ‡§∂‡•ç‡§∞‡•á‡§∑‡•ç‡§† ‡§™‡§∞‡§ø‡§£‡§æ‡§Æ ‡§™‡•ç‡§∞‡§æ‡§™‡•ç‡§§ ‡§ï‡§∞‡§§‡§æ ‡§π‡•à‡•§\n- **CoT-‡§ö‡§æ‡§≤‡§ø‡§§ ‡§∞‡•Ä‡§ú‡§®‡§ø‡§Ç‡§ó**: MLLMs ‡§ï‡•á ‡§Æ‡§æ‡§ß‡•ç‡§Ø‡§Æ ‡§∏‡•á ‡§ï‡§Ç‡§™‡•ã‡§ú‡§ø‡§∂‡§®‡§≤ ‡§î‡§∞ ‡§®‡§ø‡§Ø‡§Ç‡§§‡•ç‡§∞‡§ø‡§§ ‡§ë‡§°‡§ø‡§Ø‡•ã ‡§ú‡§®‡§∞‡•á‡§∂‡§® ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ö‡•á‡§®-‡§ë‡§´-‡§•‡•â‡§ü ‡§∞‡•Ä‡§ú‡§®‡§ø‡§Ç‡§ó‡•§\n- **‡§á‡§Ç‡§ü‡§∞‡§è‡§ï‡•ç‡§ü‡§ø‡§µ ‡§ë‡§¨‡•ç‡§ú‡•á‡§ï‡•ç‡§ü-‡§∏‡•á‡§Ç‡§ü‡•ç‡§∞‡§ø‡§ï ‡§è‡§°‡§ø‡§ü‡§ø‡§Ç‡§ó**: ‡§µ‡§ø‡§ú‡•Å‡§Ö‡§≤ ‡§ë‡§¨‡•ç‡§ú‡•á‡§ï‡•ç‡§ü‡•ç‡§∏ ‡§™‡§∞ ‡§ï‡•ç‡§≤‡§ø‡§ï ‡§Ø‡§æ ‡§ü‡•á‡§ï‡•ç‡§∏‡•ç‡§ü ‡§®‡§ø‡§∞‡•ç‡§¶‡•á‡§∂‡•ã‡§Ç ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡§ï‡•á ‡§µ‡§ø‡§∂‡§ø‡§∑‡•ç‡§ü ‡§∏‡§æ‡§â‡§Ç‡§° ‡§á‡§µ‡•á‡§Ç‡§ü‡•ç‡§∏ ‡§ï‡•ã ‡§∏‡•Å‡§ß‡§æ‡§∞‡•á‡§Ç ‡§Ø‡§æ ‡§è‡§°‡§ø‡§ü ‡§ï‡§∞‡•á‡§Ç‡•§\n- **‡§è‡§ï‡•Ä‡§ï‡•É‡§§ ‡§´‡•ç‡§∞‡•á‡§Æ‡§µ‡§∞‡•ç‡§ï**: ‡§è‡§ï ‡§´‡§æ‡§â‡§Ç‡§°‡•á‡§∂‡§® ‡§Æ‡•â‡§°‡§≤ ‡§ú‡•á‡§®‡§∞‡•á‡§∂‡§®, ‡§è‡§°‡§ø‡§ü‡§ø‡§Ç‡§ó ‡§î‡§∞ ‡§á‡§Ç‡§ü‡§∞‡§è‡§ï‡•ç‡§ü‡§ø‡§µ ‡§µ‡§∞‡•ç‡§ï‡§´‡•ç‡§≤‡•ã ‡§ï‡•ã ‡§∏‡§™‡•ã‡§∞‡•ç‡§ü ‡§ï‡§∞‡§§‡§æ ‡§π‡•à‡•§\n\n---\n\n## ‚ú® ‡§µ‡§ø‡§ß‡§ø ‡§Ö‡§µ‡§≤‡•ã‡§ï‡§®\n\nThinkSound ‡§ë‡§°‡§ø‡§Ø‡•ã ‡§ú‡•á‡§®‡§∞‡•á‡§∂‡§® ‡§î‡§∞ ‡§è‡§°‡§ø‡§ü‡§ø‡§Ç‡§ó ‡§ï‡•ã ‡§§‡•Ä‡§® ‡§á‡§Ç‡§ü‡§∞‡§è‡§ï‡•ç‡§ü‡§ø‡§µ ‡§ö‡§∞‡§£‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§µ‡§ø‡§≠‡§æ‡§ú‡§ø‡§§ ‡§ï‡§∞‡§§‡§æ ‡§π‡•à, ‡§ú‡•ã ‡§∏‡§≠‡•Ä MLLM-‡§Ü‡§ß‡§æ‡§∞‡§ø‡§§ ‡§ö‡•á‡§®-‡§ë‡§´-‡§•‡•â‡§ü (CoT) ‡§∞‡•Ä‡§ú‡§®‡§ø‡§Ç‡§ó ‡§¶‡•ç‡§µ‡§æ‡§∞‡§æ ‡§®‡§ø‡§∞‡•ç‡§¶‡•á‡§∂‡§ø‡§§ ‡§π‡•à‡§Ç:\n\n1. **‡§´‡•ã‡§≤‡•Ä ‡§ú‡•á‡§®‡§∞‡•á‡§∂‡§®:** ‡§µ‡•Ä‡§°‡§ø‡§Ø‡•ã ‡§∏‡•á ‡§Æ‡•Ç‡§≤, ‡§∏‡•à‡§Æ‡§æ‡§®‡•ç‡§Ø ‡§î‡§∞ ‡§∏‡§Æ‡§Ø‡§æ‡§®‡•Å‡§ï‡•Ç‡§≤ ‡§∏‡§æ‡§â‡§Ç‡§°‡§∏‡•ç‡§ï‡•á‡§™‡•ç‡§∏ ‡§ú‡§®‡§∞‡•á‡§ü ‡§ï‡§∞‡•á‡§Ç‡•§\n2. **‡§ë‡§¨‡•ç‡§ú‡•á‡§ï‡•ç‡§ü-‡§∏‡•á‡§Ç‡§ü‡•ç‡§∞‡§ø‡§ï ‡§™‡§∞‡§ø‡§∑‡•ç‡§ï‡§∞‡§£:** ‡§µ‡•Ä‡§°‡§ø‡§Ø‡•ã ‡§Æ‡•á‡§Ç ‡§ï‡•ç‡§≤‡§ø‡§ï ‡§Ø‡§æ ‡§ö‡§Ø‡§®‡§ø‡§§ ‡§ï‡•ç‡§∑‡•á‡§§‡•ç‡§∞‡•ã‡§Ç ‡§ï‡•á ‡§Æ‡§æ‡§ß‡•ç‡§Ø‡§Æ ‡§∏‡•á ‡§Ø‡•Ç‡§ú‡§∞ ‡§¶‡•ç‡§µ‡§æ‡§∞‡§æ ‡§®‡§ø‡§∞‡•ç‡§¶‡§ø‡§∑‡•ç‡§ü ‡§ë‡§¨‡•ç‡§ú‡•á‡§ï‡•ç‡§ü‡•ç‡§∏ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§∏‡§æ‡§â‡§Ç‡§°‡•ç‡§∏ ‡§ï‡•ã ‡§∏‡•Å‡§ß‡§æ‡§∞‡•á‡§Ç ‡§Ø‡§æ ‡§ú‡•ã‡§°‡§º‡•á‡§Ç‡•§\n3. **‡§≤‡§ï‡•ç‡§∑‡§ø‡§§ ‡§ë‡§°‡§ø‡§Ø‡•ã ‡§∏‡§Ç‡§™‡§æ‡§¶‡§®:** ‡§â‡§ö‡•ç‡§ö-‡§∏‡•ç‡§§‡§∞‡•Ä‡§Ø ‡§™‡•ç‡§∞‡§æ‡§ï‡•É‡§§‡§ø‡§ï ‡§≠‡§æ‡§∑‡§æ ‡§®‡§ø‡§∞‡•ç‡§¶‡•á‡§∂‡•ã‡§Ç ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡§ï‡•á ‡§ú‡§®‡§∞‡•á‡§ü‡•á‡§° ‡§ë‡§°‡§ø‡§Ø‡•ã ‡§ï‡•ã ‡§∏‡§Ç‡§™‡§æ‡§¶‡§ø‡§§ ‡§ï‡§∞‡•á‡§Ç‡•§\n\n![ThinkSound ‡§Ö‡§µ‡§≤‡•ã‡§ï‡§®](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig3_model.png)\n<!-- ‡§è‡§ï ‡§¨‡§°‡§º‡•á ‡§™‡•à‡§Æ‡§æ‡§®‡•á ‡§ï‡§æ CoT-‡§è‡§®‡•ã‡§ü‡•á‡§ü‡•á‡§° ‡§°‡•á‡§ü‡§æ‡§∏‡•á‡§ü (**AudioCoT**) ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§¶‡•ã‡§®‡•ã‡§Ç ‡§∞‡•Ä‡§ú‡§®‡§ø‡§Ç‡§ó ‡§Æ‡•â‡§°‡•ç‡§Ø‡•Ç‡§≤ ‡§î‡§∞ ‡§è‡§ï‡•Ä‡§ï‡•É‡§§ ‡§ë‡§°‡§ø‡§Ø‡•ã ‡§´‡§æ‡§â‡§Ç‡§°‡•á‡§∂‡§® ‡§Æ‡•â‡§°‡§≤ ‡§ï‡•ã ‡§™‡•ç‡§∞‡§∂‡§ø‡§ï‡•ç‡§∑‡§ø‡§§ ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ï‡§ø‡§Ø‡§æ ‡§ú‡§æ‡§§‡§æ ‡§π‡•à‡•§",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 2,
        "rowsha": "eexREJOMCITdo96Iwg4N4PQqu1ux/UwupfjVRj0l/L8=",
        "originContent": "PyTorch implementation for multimodal audio generation and editing: generate or edit audio from video, text, and audio, powered by step-by-step reasoning from Multimodal Large Language Models (MLLMs).",
        "translatedContent": "‡§Æ‡§≤‡•ç‡§ü‡•Ä‡§Æ‡•â‡§°‡§≤ ‡§ë‡§°‡§ø‡§Ø‡•ã ‡§ú‡•á‡§®‡§∞‡•á‡§∂‡§® ‡§î‡§∞ ‡§è‡§°‡§ø‡§ü‡§ø‡§Ç‡§ó ‡§ï‡•á ‡§≤‡§ø‡§è PyTorch ‡§á‡§Æ‡•ç‡§™‡•ç‡§≤‡•Ä‡§Æ‡•á‡§Ç‡§ü‡•á‡§∂‡§®: ‡§µ‡•Ä‡§°‡§ø‡§Ø‡•ã, ‡§ü‡•á‡§ï‡•ç‡§∏‡•ç‡§ü ‡§î‡§∞ ‡§ë‡§°‡§ø‡§Ø‡•ã ‡§∏‡•á ‡§ë‡§°‡§ø‡§Ø‡•ã ‡§ú‡§®‡§∞‡•á‡§ü ‡§Ø‡§æ ‡§è‡§°‡§ø‡§ü ‡§ï‡§∞‡•á‡§Ç, ‡§Æ‡§≤‡•ç‡§ü‡•Ä‡§Æ‡•â‡§°‡§≤ ‡§≤‡§æ‡§∞‡•ç‡§ú ‡§≤‡•à‡§Ç‡§ó‡•ç‡§µ‡•á‡§ú ‡§Æ‡•â‡§°‡§≤‡•ç‡§∏ (MLLMs) ‡§ï‡•Ä ‡§∏‡•ç‡§ü‡•á‡§™-‡§¨‡§æ‡§Ø-‡§∏‡•ç‡§ü‡•á‡§™ ‡§∞‡•Ä‡§ú‡§®‡§ø‡§Ç‡§ó ‡§¶‡•ç‡§µ‡§æ‡§∞‡§æ ‡§∏‡§Ç‡§ö‡§æ‡§≤‡§ø‡§§‡•§"
      },
      {
        "row": 3,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 4,
        "rowsha": "+7Cx1rdpWiIOeWRA/RM6HsKf7pNA3hHsQk2Bpadt4II=",
        "originContent": "![Teaser](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig1_teaser.png)",
        "translatedContent": "![‡§ü‡•Ä‡§ú‡§º‡§∞](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig1_teaser.png)"
      },
      {
        "row": 5,
        "rowsha": "yz+R1U7uMOU+NbK5mQX3Dxae1Un9eJCdPawt78ntjTs=",
        "originContent": "---",
        "translatedContent": "---"
      },
      {
        "row": 6,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 7,
        "rowsha": "0YeCyxpcm7/4RDbaM+OQoI8YfqEHQzDkpGW15VZdi1U=",
        "originContent": "## üì∞ News",
        "translatedContent": "## üì∞ ‡§∏‡§Æ‡§æ‡§ö‡§æ‡§∞"
      },
      {
        "row": 8,
        "rowsha": "vj2hbV/6MacDcxRmFA0AtTog5xU6CHoqBFO3YMO+yJo=",
        "originContent": "- **2025.09.19** &nbsp; üéâ ThinkSound has been accepted to the **NeurIPS 2025 Main Conference**!",
        "translatedContent": "- **2025.09.19** &nbsp; üéâ ThinkSound ‡§ï‡•ã **NeurIPS 2025 ‡§Æ‡•Å‡§ñ‡•ç‡§Ø ‡§∏‡§Æ‡•ç‡§Æ‡•á‡§≤‡§®** ‡§Æ‡•á‡§Ç ‡§∏‡•ç‡§µ‡•Ä‡§ï‡•É‡§§‡§ø ‡§Æ‡§ø‡§≤‡•Ä ‡§π‡•à!"
      },
      {
        "row": 9,
        "rowsha": "cowWEeVmTC64/Cn+su00RYaecArXegbIhiQxYHzseg4=",
        "originContent": "- **2025.09.01** &nbsp; üî• Our AudioCoT dataset is now open-sourced and available on [Hugging Face](https://huggingface.co/datasets/liuhuadai/AudioCoT)!",
        "translatedContent": "- **2025.09.01** &nbsp; üî• ‡§π‡§Æ‡§æ‡§∞‡§æ AudioCoT ‡§°‡•á‡§ü‡§æ‡§∏‡•á‡§ü ‡§Ö‡§¨ ‡§ì‡§™‡§®-‡§∏‡•ã‡§∞‡•ç‡§∏ ‡§π‡•à ‡§î‡§∞ [Hugging Face](https://huggingface.co/datasets/liuhuadai/AudioCoT) ‡§™‡§∞ ‡§â‡§™‡§≤‡§¨‡•ç‡§ß ‡§π‡•à!"
      },
      {
        "row": 10,
        "rowsha": "4Jq9g83O8cYV4fVKsetfTpI+JrSepLrjK6J7Xg9tSqo=",
        "originContent": "- **2025.07.17** &nbsp; üß† Finetuning enabled: training and finetuning code is now publicly available, along with clear usage instructions to help you customize and extend ThinkSound with your own data.",
        "translatedContent": "- **2025.07.17** &nbsp; üß† ‡§´‡§æ‡§á‡§®‡§ü‡•ç‡§Ø‡•Ç‡§®‡§ø‡§Ç‡§ó ‡§∏‡§ï‡•ç‡§∑‡§Æ: ‡§ü‡•ç‡§∞‡•á‡§®‡§ø‡§Ç‡§ó ‡§î‡§∞ ‡§´‡§æ‡§á‡§®‡§ü‡•ç‡§Ø‡•Ç‡§®‡§ø‡§Ç‡§ó ‡§ï‡•ã‡§° ‡§Ö‡§¨ ‡§∏‡§æ‡§∞‡•ç‡§µ‡§ú‡§®‡§ø‡§ï ‡§∞‡•Ç‡§™ ‡§∏‡•á ‡§â‡§™‡§≤‡§¨‡•ç‡§ß ‡§π‡•à, ‡§∏‡•ç‡§™‡§∑‡•ç‡§ü ‡§®‡§ø‡§∞‡•ç‡§¶‡•á‡§∂‡•ã‡§Ç ‡§ï‡•á ‡§∏‡§æ‡§• ‡§ú‡§ø‡§∏‡§∏‡•á ‡§Ü‡§™ ‡§Ö‡§™‡§®‡•á ‡§°‡•á‡§ü‡§æ ‡§ï‡•á ‡§∏‡§æ‡§• ThinkSound ‡§ï‡•ã ‡§ï‡§∏‡•ç‡§ü‡§Æ‡§æ‡§á‡§ú‡§º ‡§î‡§∞ ‡§è‡§ï‡•ç‡§∏‡§ü‡•á‡§Ç‡§° ‡§ï‡§∞ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç‡•§"
      },
      {
        "row": 11,
        "rowsha": "Ae5w+cTrCd9E8qidC11IWJAgg+LuOgUxA4czDPNG/G0=",
        "originContent": "- **2025.07.15** &nbsp; üì¶ Simplified installation and usability: dependencies on PyPI for easy cross-platform setup; Windows `.bat` scripts automate environment creation and script running.",
        "translatedContent": "- **2025.07.15** &nbsp; üì¶ ‡§Ü‡§∏‡§æ‡§® ‡§á‡§Ç‡§∏‡•ç‡§ü‡•â‡§≤‡•á‡§∂‡§® ‡§î‡§∞ ‡§â‡§™‡§Ø‡•ã‡§ó‡§ø‡§§‡§æ: PyPI ‡§™‡§∞ ‡§°‡§ø‡§™‡•á‡§Ç‡§°‡•á‡§Ç‡§∏‡•Ä‡•õ ‡§ï‡•ç‡§∞‡•â‡§∏-‡§™‡•ç‡§≤‡•á‡§ü‡§´‡•â‡§∞‡•ç‡§Æ ‡§∏‡•á‡§ü‡§Ö‡§™ ‡§ï‡•á ‡§≤‡§ø‡§è; Windows `.bat` ‡§∏‡•ç‡§ï‡•ç‡§∞‡§ø‡§™‡•ç‡§ü‡•ç‡§∏ ‡§µ‡§æ‡§§‡§æ‡§µ‡§∞‡§£ ‡§®‡§ø‡§∞‡•ç‡§Æ‡§æ‡§£ ‡§î‡§∞ ‡§∏‡•ç‡§ï‡•ç‡§∞‡§ø‡§™‡•ç‡§ü ‡§∞‡§®‡§ø‡§Ç‡§ó ‡§ï‡•ã ‡§ë‡§ü‡•ã‡§Æ‡•á‡§ü ‡§ï‡§∞‡§§‡•Ä ‡§π‡•à‡§Ç‡•§"
      },
      {
        "row": 12,
        "rowsha": "nYxNhwgSqjwYLuWsfHAqP5sx2PnzYwoFrwcf9U+Fdss=",
        "originContent": "- **2025.07.08** &nbsp;¬† üîß Major update: model lightweighted and optimized memory and GPU usage, now supports high-throughput audio generation at scale!",
        "translatedContent": "- **2025.07.08** &nbsp;¬† üîß ‡§™‡•ç‡§∞‡§Æ‡•Å‡§ñ ‡§Ö‡§™‡§°‡•á‡§ü: ‡§Æ‡•â‡§°‡§≤ ‡§ï‡•ã ‡§π‡§≤‡•ç‡§ï‡§æ ‡§î‡§∞ ‡§Æ‡•á‡§Æ‡•ã‡§∞‡•Ä ‡§µ GPU ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡•ã ‡§ë‡§™‡•ç‡§ü‡§ø‡§Æ‡§æ‡§á‡•õ ‡§ï‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ, ‡§Ö‡§¨ ‡§¨‡§°‡§º‡•á ‡§™‡•à‡§Æ‡§æ‡§®‡•á ‡§™‡§∞ ‡§π‡§æ‡§à-‡§•‡•ç‡§∞‡•Ç‡§™‡•Å‡§ü ‡§ë‡§°‡§ø‡§Ø‡•ã ‡§ú‡•á‡§®‡§∞‡•á‡§∂‡§® ‡§ï‡•ã ‡§∏‡§™‡•ã‡§∞‡•ç‡§ü ‡§ï‡§∞‡§§‡§æ ‡§π‡•à!"
      },
      {
        "row": 13,
        "rowsha": "xuARkITJMc1ABOl8/xX47dORDInuxwAsk8O1r5dvfpc=",
        "originContent": "- **2025.07.01** &nbsp; üî•Online demo on [Hugging Face Spaces](https://huggingface.co/spaces/FunAudioLLM/ThinkSound) and [ModelScope](https://modelscope.cn/studios/iic/ThinkSound) for interactive experience!",
        "translatedContent": "- **2025.07.01** &nbsp; üî•‡§ë‡§®‡§≤‡§æ‡§á‡§® ‡§°‡•á‡§Æ‡•ã [Hugging Face Spaces](https://huggingface.co/spaces/FunAudioLLM/ThinkSound) ‡§î‡§∞ [ModelScope](https://modelscope.cn/studios/iic/ThinkSound) ‡§™‡§∞ ‡§á‡§Ç‡§ü‡§∞‡§è‡§ï‡•ç‡§ü‡§ø‡§µ ‡§Ö‡§®‡•Å‡§≠‡§µ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§â‡§™‡§≤‡§¨‡•ç‡§ß!"
      },
      {
        "row": 14,
        "rowsha": "aIpa8g7qqXl8Iq8shRpiY5Ha5WD8c9Pd9PWybZ+wr18=",
        "originContent": "- **2025.07.01** &nbsp; üî•Released inference scripts and web interface; ",
        "translatedContent": "- **2025.07.01** &nbsp; üî•‡§á‡§®‡•ç‡§´‡•á‡§∞‡•á‡§Ç‡§∏ ‡§∏‡•ç‡§ï‡•ç‡§∞‡§ø‡§™‡•ç‡§ü‡•ç‡§∏ ‡§î‡§∞ ‡§µ‡•á‡§¨ ‡§á‡§Ç‡§ü‡§∞‡§´‡•á‡§∏ ‡§ú‡§æ‡§∞‡•Ä ‡§ï‡§ø‡§è ‡§ó‡§è;"
      },
      {
        "row": 15,
        "rowsha": "ynCJTuWmfRd3D7hcoW1WvIQ482zzFcdaXc8pgOG02Tw=",
        "originContent": "- **2025.06** &nbsp; üî•[ThinkSound paper](https://arxiv.org/pdf/2506.21448) released on arXiv!",
        "translatedContent": "- **2025.06** &nbsp; üî•[ThinkSound ‡§™‡•á‡§™‡§∞](https://arxiv.org/pdf/2506.21448) arXiv ‡§™‡§∞ ‡§ú‡§æ‡§∞‡•Ä!"
      },
      {
        "row": 16,
        "rowsha": "se+rRi5CpnStAflq7OZvd/2mN+51ezQQaBeYckrGFCk=",
        "originContent": "- **2025.06** &nbsp; üî•[Online Demo](http://thinksound-project.github.io/) is live - try it now!",
        "translatedContent": "- **2025.06** &nbsp; üî•[‡§ë‡§®‡§≤‡§æ‡§á‡§® ‡§°‡•á‡§Æ‡•ã](http://thinksound-project.github.io/) ‡§≤‡§æ‡§á‡§µ ‡§π‡•à - ‡§Ö‡§≠‡•Ä ‡§Ü‡§ú‡§º‡§Æ‡§æ‡§è‡§Å!"
      },
      {
        "row": 17,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 18,
        "rowsha": "yz+R1U7uMOU+NbK5mQX3Dxae1Un9eJCdPawt78ntjTs=",
        "originContent": "---",
        "translatedContent": "---"
      },
      {
        "row": 19,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 20,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 21,
        "rowsha": "f4oQIFLM2EJQxJ65F4oMEA7yWOIqs0eBtiIvGxI+GgI=",
        "originContent": "## üöÄ Features",
        "translatedContent": "## üöÄ ‡§µ‡§ø‡§∂‡•á‡§∑‡§§‡§æ‡§è‡§Å"
      },
      {
        "row": 22,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 23,
        "rowsha": "8TbVluJJPR3C0fX41HklpO/vH9/k/rHC+jlvmHHfzQU=",
        "originContent": "- **Any2Audio**: Generate audio from arbitrary modalities ‚Äî video, text, audio, or their combinations.",
        "translatedContent": "- **Any2Audio**: ‡§ï‡§ø‡§∏‡•Ä ‡§≠‡•Ä ‡§Æ‡•ã‡§°‡§æ‡§≤‡§ø‡§ü‡•Ä ‡§∏‡•á ‡§ë‡§°‡§ø‡§Ø‡•ã ‡§ú‡§®‡§∞‡•á‡§ü ‡§ï‡§∞‡•á‡§Ç ‚Äî ‡§µ‡•Ä‡§°‡§ø‡§Ø‡•ã, ‡§ü‡•á‡§ï‡•ç‡§∏‡•ç‡§ü, ‡§ë‡§°‡§ø‡§Ø‡•ã ‡§Ø‡§æ ‡§â‡§®‡§ï‡•á ‡§∏‡§Ç‡§Ø‡•ã‡§ú‡§®‡•§"
      },
      {
        "row": 24,
        "rowsha": "+Jf5LrYz+d1ShYCuQe8UF9taEJUpuGhDk6fAlYK3Kj4=",
        "originContent": "- **Video-to-Audio SOTA**: Achieves state-of-the-art results on multiple V2A benchmarks.",
        "translatedContent": "- **‡§µ‡•Ä‡§°‡§ø‡§Ø‡•ã-‡§ü‡•Ç-‡§ë‡§°‡§ø‡§Ø‡•ã SOTA**: ‡§ï‡§à V2A ‡§¨‡•á‡§Ç‡§ö‡§Æ‡§æ‡§∞‡•ç‡§ï‡•ç‡§∏ ‡§™‡§∞ ‡§∏‡§∞‡•ç‡§µ‡§∂‡•ç‡§∞‡•á‡§∑‡•ç‡§† ‡§™‡§∞‡§ø‡§£‡§æ‡§Æ ‡§™‡•ç‡§∞‡§æ‡§™‡•ç‡§§ ‡§ï‡§∞‡§§‡§æ ‡§π‡•à‡•§"
      },
      {
        "row": 25,
        "rowsha": "mU7qXkjW1YifKoYXJedYo9l64NsTBaiXsgoGFRF/g+E=",
        "originContent": "- **CoT-Driven Reasoning**: Chain-of-Thought reasoning for compositional and controllable audio generation via MLLMs.",
        "translatedContent": "- **CoT-‡§ö‡§æ‡§≤‡§ø‡§§ ‡§∞‡•Ä‡§ú‡§®‡§ø‡§Ç‡§ó**: MLLMs ‡§ï‡•á ‡§Æ‡§æ‡§ß‡•ç‡§Ø‡§Æ ‡§∏‡•á ‡§ï‡§Ç‡§™‡•ã‡§ú‡§ø‡§∂‡§®‡§≤ ‡§î‡§∞ ‡§®‡§ø‡§Ø‡§Ç‡§§‡•ç‡§∞‡§ø‡§§ ‡§ë‡§°‡§ø‡§Ø‡•ã ‡§ú‡§®‡§∞‡•á‡§∂‡§® ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ö‡•á‡§®-‡§ë‡§´-‡§•‡•â‡§ü ‡§∞‡•Ä‡§ú‡§®‡§ø‡§Ç‡§ó‡•§"
      },
      {
        "row": 26,
        "rowsha": "RComOCBBrXsZf9RHmLginqKTh9eI/bKUZuUunQEmD5M=",
        "originContent": "- **Interactive Object-centric Editing**: Refine or edit specific sound events by clicking on visual objects or using text instructions.",
        "translatedContent": "- **‡§á‡§Ç‡§ü‡§∞‡§è‡§ï‡•ç‡§ü‡§ø‡§µ ‡§ë‡§¨‡•ç‡§ú‡•á‡§ï‡•ç‡§ü-‡§∏‡•á‡§Ç‡§ü‡•ç‡§∞‡§ø‡§ï ‡§è‡§°‡§ø‡§ü‡§ø‡§Ç‡§ó**: ‡§µ‡§ø‡§ú‡•Å‡§Ö‡§≤ ‡§ë‡§¨‡•ç‡§ú‡•á‡§ï‡•ç‡§ü‡•ç‡§∏ ‡§™‡§∞ ‡§ï‡•ç‡§≤‡§ø‡§ï ‡§Ø‡§æ ‡§ü‡•á‡§ï‡•ç‡§∏‡•ç‡§ü ‡§®‡§ø‡§∞‡•ç‡§¶‡•á‡§∂‡•ã‡§Ç ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡§ï‡•á ‡§µ‡§ø‡§∂‡§ø‡§∑‡•ç‡§ü ‡§∏‡§æ‡§â‡§Ç‡§° ‡§á‡§µ‡•á‡§Ç‡§ü‡•ç‡§∏ ‡§ï‡•ã ‡§∏‡•Å‡§ß‡§æ‡§∞‡•á‡§Ç ‡§Ø‡§æ ‡§è‡§°‡§ø‡§ü ‡§ï‡§∞‡•á‡§Ç‡•§"
      },
      {
        "row": 27,
        "rowsha": "C3sf87sy73G/XZft+TDo5NjXo5XcrtJB805ayHRAXoQ=",
        "originContent": "- **Unified Framework**: One foundation model supports generation, editing, and interactive workflow.",
        "translatedContent": "- **‡§è‡§ï‡•Ä‡§ï‡•É‡§§ ‡§´‡•ç‡§∞‡•á‡§Æ‡§µ‡§∞‡•ç‡§ï**: ‡§è‡§ï ‡§´‡§æ‡§â‡§Ç‡§°‡•á‡§∂‡§® ‡§Æ‡•â‡§°‡§≤ ‡§ú‡•á‡§®‡§∞‡•á‡§∂‡§®, ‡§è‡§°‡§ø‡§ü‡§ø‡§Ç‡§ó ‡§î‡§∞ ‡§á‡§Ç‡§ü‡§∞‡§è‡§ï‡•ç‡§ü‡§ø‡§µ ‡§µ‡§∞‡•ç‡§ï‡§´‡•ç‡§≤‡•ã ‡§ï‡•ã ‡§∏‡§™‡•ã‡§∞‡•ç‡§ü ‡§ï‡§∞‡§§‡§æ ‡§π‡•à‡•§"
      },
      {
        "row": 28,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 29,
        "rowsha": "yz+R1U7uMOU+NbK5mQX3Dxae1Un9eJCdPawt78ntjTs=",
        "originContent": "---",
        "translatedContent": "---"
      },
      {
        "row": 30,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 31,
        "rowsha": "gjgLOIAU2x83BBZdLUdgEB+F64ajt/QuLYQXM1hDBLE=",
        "originContent": "## ‚ú® Method Overview",
        "translatedContent": "## ‚ú® ‡§µ‡§ø‡§ß‡§ø ‡§Ö‡§µ‡§≤‡•ã‡§ï‡§®"
      },
      {
        "row": 32,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 33,
        "rowsha": "v5//GqG/smYIGoUpN+12k+9/3GWH3GdYD+jLqScb7AM=",
        "originContent": "ThinkSound decomposes audio generation and editing into three interactive stages, all guided by MLLM-based Chain-of-Thought (CoT) reasoning:",
        "translatedContent": "ThinkSound ‡§ë‡§°‡§ø‡§Ø‡•ã ‡§ú‡•á‡§®‡§∞‡•á‡§∂‡§® ‡§î‡§∞ ‡§è‡§°‡§ø‡§ü‡§ø‡§Ç‡§ó ‡§ï‡•ã ‡§§‡•Ä‡§® ‡§á‡§Ç‡§ü‡§∞‡§è‡§ï‡•ç‡§ü‡§ø‡§µ ‡§ö‡§∞‡§£‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§µ‡§ø‡§≠‡§æ‡§ú‡§ø‡§§ ‡§ï‡§∞‡§§‡§æ ‡§π‡•à, ‡§ú‡•ã ‡§∏‡§≠‡•Ä MLLM-‡§Ü‡§ß‡§æ‡§∞‡§ø‡§§ ‡§ö‡•á‡§®-‡§ë‡§´-‡§•‡•â‡§ü (CoT) ‡§∞‡•Ä‡§ú‡§®‡§ø‡§Ç‡§ó ‡§¶‡•ç‡§µ‡§æ‡§∞‡§æ ‡§®‡§ø‡§∞‡•ç‡§¶‡•á‡§∂‡§ø‡§§ ‡§π‡•à‡§Ç:"
      },
      {
        "row": 34,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 35,
        "rowsha": "vTObEWb7f5gCU681X3dTkwqhsaSW89TLw3GgMJ5I3bo=",
        "originContent": "1. **Foley Generation:** Generate foundational, semantically and temporally aligned soundscapes from video.",
        "translatedContent": "1. **‡§´‡•ã‡§≤‡•Ä ‡§ú‡•á‡§®‡§∞‡•á‡§∂‡§®:** ‡§µ‡•Ä‡§°‡§ø‡§Ø‡•ã ‡§∏‡•á ‡§Æ‡•Ç‡§≤, ‡§∏‡•à‡§Æ‡§æ‡§®‡•ç‡§Ø ‡§î‡§∞ ‡§∏‡§Æ‡§Ø‡§æ‡§®‡•Å‡§ï‡•Ç‡§≤ ‡§∏‡§æ‡§â‡§Ç‡§°‡§∏‡•ç‡§ï‡•á‡§™‡•ç‡§∏ ‡§ú‡§®‡§∞‡•á‡§ü ‡§ï‡§∞‡•á‡§Ç‡•§"
      },
      {
        "row": 36,
        "rowsha": "LTBpIQQHtEkNF8StAa+ZEDASGmRhmHIKDQOdZ4ExJWM=",
        "originContent": "2. **Object-Centric Refinement:** Refine or add sounds for user-specified objects via clicks or regions in the video.",
        "translatedContent": "2. **‡§ë‡§¨‡•ç‡§ú‡•á‡§ï‡•ç‡§ü-‡§∏‡•á‡§Ç‡§ü‡•ç‡§∞‡§ø‡§ï ‡§™‡§∞‡§ø‡§∑‡•ç‡§ï‡§∞‡§£:** ‡§µ‡•Ä‡§°‡§ø‡§Ø‡•ã ‡§Æ‡•á‡§Ç ‡§ï‡•ç‡§≤‡§ø‡§ï ‡§Ø‡§æ ‡§ö‡§Ø‡§®‡§ø‡§§ ‡§ï‡•ç‡§∑‡•á‡§§‡•ç‡§∞‡•ã‡§Ç ‡§ï‡•á ‡§Æ‡§æ‡§ß‡•ç‡§Ø‡§Æ ‡§∏‡•á ‡§Ø‡•Ç‡§ú‡§∞ ‡§¶‡•ç‡§µ‡§æ‡§∞‡§æ ‡§®‡§ø‡§∞‡•ç‡§¶‡§ø‡§∑‡•ç‡§ü ‡§ë‡§¨‡•ç‡§ú‡•á‡§ï‡•ç‡§ü‡•ç‡§∏ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§∏‡§æ‡§â‡§Ç‡§°‡•ç‡§∏ ‡§ï‡•ã ‡§∏‡•Å‡§ß‡§æ‡§∞‡•á‡§Ç ‡§Ø‡§æ ‡§ú‡•ã‡§°‡§º‡•á‡§Ç‡•§"
      },
      {
        "row": 37,
        "rowsha": "8wrAo7X7dPC6Sgpfrlq2ziv/Wg/3+JnlFYvO+RMxADQ=",
        "originContent": "3. **Targeted Audio Editing:** Modify generated audio using high-level natural language instructions.",
        "translatedContent": "3. **‡§≤‡§ï‡•ç‡§∑‡§ø‡§§ ‡§ë‡§°‡§ø‡§Ø‡•ã ‡§∏‡§Ç‡§™‡§æ‡§¶‡§®:** ‡§â‡§ö‡•ç‡§ö-‡§∏‡•ç‡§§‡§∞‡•Ä‡§Ø ‡§™‡•ç‡§∞‡§æ‡§ï‡•É‡§§‡§ø‡§ï ‡§≠‡§æ‡§∑‡§æ ‡§®‡§ø‡§∞‡•ç‡§¶‡•á‡§∂‡•ã‡§Ç ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡§ï‡•á ‡§ú‡§®‡§∞‡•á‡§ü‡•á‡§° ‡§ë‡§°‡§ø‡§Ø‡•ã ‡§ï‡•ã ‡§∏‡§Ç‡§™‡§æ‡§¶‡§ø‡§§ ‡§ï‡§∞‡•á‡§Ç‡•§"
      },
      {
        "row": 38,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 39,
        "rowsha": "4UKlvFW3Xb0bSAVjcBNeekH/MMiYS0XDg9w4mCuPy/Q=",
        "originContent": "![ThinkSound Overview](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig3_model.png)",
        "translatedContent": "![ThinkSound ‡§Ö‡§µ‡§≤‡•ã‡§ï‡§®](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig3_model.png)"
      },
      {
        "row": 40,
        "rowsha": "GaujeIM3x7+YcFy07LNNyITlujhkgpgeIaOiKHJkYnE=",
        "originContent": "<!-- A large-scale CoT-annotated dataset (**AudioCoT**) is used to train both the reasoning module and the unified audio foundation model.",
        "translatedContent": "<!-- ‡§è‡§ï ‡§¨‡§°‡§º‡•á ‡§™‡•à‡§Æ‡§æ‡§®‡•á ‡§ï‡§æ CoT-‡§è‡§®‡•ã‡§ü‡•á‡§ü‡•á‡§° ‡§°‡•á‡§ü‡§æ‡§∏‡•á‡§ü (**AudioCoT**) ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§¶‡•ã‡§®‡•ã‡§Ç ‡§∞‡•Ä‡§ú‡§®‡§ø‡§Ç‡§ó ‡§Æ‡•â‡§°‡•ç‡§Ø‡•Ç‡§≤ ‡§î‡§∞ ‡§è‡§ï‡•Ä‡§ï‡•É‡§§ ‡§ë‡§°‡§ø‡§Ø‡•ã ‡§´‡§æ‡§â‡§Ç‡§°‡•á‡§∂‡§® ‡§Æ‡•â‡§°‡§≤ ‡§ï‡•ã ‡§™‡•ç‡§∞‡§∂‡§ø‡§ï‡•ç‡§∑‡§ø‡§§ ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ï‡§ø‡§Ø‡§æ ‡§ú‡§æ‡§§‡§æ ‡§π‡•à‡•§"
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 3,
    "Content": "![AudioCoT Pipeline](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig2_dataset.png) -->\n\n---\n\n## ‚ö° Quick Start\n\n**Environment Preparation:**",
    "ContentSha": "5Rba8EQ45fpaVHEqHaJGyTRp/2KZkH08iiZZct8rbWI=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "![AudioCoT Pipeline](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig2_dataset.png) -->\n\n---\n\n## ‚ö° ‡§§‡•ç‡§µ‡§∞‡§ø‡§§ ‡§™‡•ç‡§∞‡§æ‡§∞‡§Ç‡§≠\n\n**‡§™‡§∞‡•ç‡§Ø‡§æ‡§µ‡§∞‡§£ ‡§§‡•à‡§Ø‡§æ‡§∞‡•Ä:**",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "qYOXaaTiYkoaPFcpTXE5xdSqqiW3ebi//EW/RfSXd9g=",
        "originContent": "![AudioCoT Pipeline](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig2_dataset.png) -->",
        "translatedContent": "![AudioCoT Pipeline](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig2_dataset.png) -->"
      },
      {
        "row": 2,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 3,
        "rowsha": "yz+R1U7uMOU+NbK5mQX3Dxae1Un9eJCdPawt78ntjTs=",
        "originContent": "---",
        "translatedContent": "---"
      },
      {
        "row": 4,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 5,
        "rowsha": "PrY/jc4yAHdS+Sr+s+Yhab477/BDp3GAzMJ8+WyumyI=",
        "originContent": "## ‚ö° Quick Start",
        "translatedContent": "## ‚ö° ‡§§‡•ç‡§µ‡§∞‡§ø‡§§ ‡§™‡•ç‡§∞‡§æ‡§∞‡§Ç‡§≠"
      },
      {
        "row": 6,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 7,
        "rowsha": "mD63DGEpdc7FlccTEps0KPAiwsJpO/C3yjV+SKIi/vE=",
        "originContent": "**Environment Preparation:**",
        "translatedContent": "**‡§™‡§∞‡•ç‡§Ø‡§æ‡§µ‡§∞‡§£ ‡§§‡•à‡§Ø‡§æ‡§∞‡•Ä:**"
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 4,
    "Content": "```bash\ngit clone https://github.com/liuhuadai/ThinkSound.git\ncd ThinkSound\nconda create -n thinksound python=3.10\nconda activate thinksound\npip install thinksound\nconda install -y -c conda-forge 'ffmpeg<7'\n# Download pretrained weights https://huggingface.co/liuhuadai/ThinkSound to Directory ckpts/\n# model weights can be also downloaded from https://www.modelscope.cn/models/iic/ThinkSound\ngit lfs install\ngit clone https://huggingface.co/liuhuadai/ThinkSound ckpts\n# To improve inference and training speed, you may optionally install a FlashAttention backend compatible with your system and PyTorch version.\n```",
    "ContentSha": "CSBCDvBmuatxDa1cNMeHEBTJJzdLjK6wyO9v0LrETM8=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\ngit clone https://github.com/liuhuadai/ThinkSound.git\ncd ThinkSound\nconda create -n thinksound python=3.10\nconda activate thinksound\npip install thinksound\nconda install -y -c conda-forge 'ffmpeg<7'\n# Download pretrained weights https://huggingface.co/liuhuadai/ThinkSound to Directory ckpts/\n# model weights can be also downloaded from https://www.modelscope.cn/models/iic/ThinkSound\ngit lfs install\ngit clone https://huggingface.co/liuhuadai/ThinkSound ckpts\n# To improve inference and training speed, you may optionally install a FlashAttention backend compatible with your system and PyTorch version.\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 5,
    "Content": "\n> ‚úÖ **Windows Tip:**  \n> Windows users can simply run `setup_windows.bat` (or double-click it) to automatically create the conda environment, install all dependencies (including FFmpeg), and download the pretrained model ‚Äî no manual setup required.  \n> Make sure `conda` and `git` are installed and available in your system PATH before running the script.\n\n\n### ‚ñ∂Ô∏è Run the Demo\n\n#### **Linux/macOS**\n",
    "ContentSha": "YGhm7lbBNPq6xLS6zXlFTPszO8rc4QZCwsScPNskcto=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "> ‚úÖ **Windows ‡§ü‡§ø‡§™:**  \n> Windows ‡§â‡§™‡§Ø‡•ã‡§ó‡§ï‡§∞‡•ç‡§§‡§æ ‡§ï‡•á‡§µ‡§≤ `setup_windows.bat` ‡§ö‡§≤‡§æ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç (‡§Ø‡§æ ‡§â‡§∏ ‡§™‡§∞ ‡§°‡§¨‡§≤-‡§ï‡•ç‡§≤‡§ø‡§ï ‡§ï‡§∞ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç) ‡§ú‡§ø‡§∏‡§∏‡•á ‡§ï‡•ã‡§Ç‡§°‡§æ ‡§µ‡§æ‡§§‡§æ‡§µ‡§∞‡§£ ‡§Ö‡§™‡§®‡•á ‡§Ü‡§™ ‡§¨‡§® ‡§ú‡§æ‡§è‡§ó‡§æ, ‡§∏‡§≠‡•Ä ‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï‡§§‡§æ‡§è‡§Å (FFmpeg ‡§∏‡§π‡§ø‡§§) ‡§∏‡•ç‡§•‡§æ‡§™‡§ø‡§§ ‡§π‡•ã ‡§ú‡§æ‡§è‡§Ç‡§ó‡•Ä, ‡§î‡§∞ ‡§™‡•ç‡§∞‡•Ä‡§ü‡•ç‡§∞‡•á‡§Ç‡§° ‡§Æ‡•â‡§°‡§≤ ‡§°‡§æ‡§â‡§®‡§≤‡•ã‡§° ‡§π‡•ã ‡§ú‡§æ‡§è‡§ó‡§æ ‚Äî ‡§ï‡•ã‡§à ‡§Æ‡•à‡§®‡•ç‡§Ø‡•Å‡§Ö‡§≤ ‡§∏‡•á‡§ü‡§Ö‡§™ ‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï ‡§®‡§π‡•Ä‡§Ç ‡§π‡•à‡•§  \n> ‡§∏‡•ç‡§ï‡•ç‡§∞‡§ø‡§™‡•ç‡§ü ‡§ö‡§≤‡§æ‡§®‡•á ‡§∏‡•á ‡§™‡§π‡§≤‡•á ‡§∏‡•Å‡§®‡§ø‡§∂‡•ç‡§ö‡§ø‡§§ ‡§ï‡§∞‡•á‡§Ç ‡§ï‡§ø ‡§Ü‡§™‡§ï‡•á ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ PATH ‡§Æ‡•á‡§Ç `conda` ‡§î‡§∞ `git` ‡§á‡§Ç‡§∏‡•ç‡§ü‡•â‡§≤ ‡§î‡§∞ ‡§â‡§™‡§≤‡§¨‡•ç‡§ß ‡§π‡•à‡§Ç‡•§\n\n\n### ‚ñ∂Ô∏è ‡§°‡•á‡§Æ‡•ã ‡§ö‡§≤‡§æ‡§è‡§Å\n\n#### **Linux/macOS**\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 6,
    "Content": "```bash\nchmod +x scripts/demo.sh\n./scripts/demo.sh <path-to-your-demo-video> <title> <CoT description> [use-half]\n```",
    "ContentSha": "EW6OKf+6hdOehT5SO7gfI7wR8oAoMckp60MRfIA1jHc=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\nchmod +x scripts/demo.sh\n./scripts/demo.sh <path-to-your-demo-video> <title> <CoT description> [use-half]\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 7,
    "Content": "\n#### **Windows**\n\nYou can use the provided `.bat` script instead:\n",
    "ContentSha": "zXqRZWTEWOuKZG1GOlqqZff+IH24zUwdPtSfwESqS9E=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "#### **Windows**\n\n‡§á‡§∏‡§ï‡•á ‡§¨‡§ú‡§æ‡§Ø ‡§Ü‡§™ ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡•Ä ‡§ó‡§à `.bat` ‡§∏‡•ç‡§ï‡•ç‡§∞‡§ø‡§™‡•ç‡§ü ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç:\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 8,
    "Content": "```bash\n.\\scripts\\demo.bat <path-to-your-demo-video> <title> <CoT description> [use-half]\n```",
    "ContentSha": "A2a1kVuIPNs8ht1a6LBYTEijJjnfjiTN0r+2n7VEJSg=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\n.\\scripts\\demo.bat <path-to-your-demo-video> <title> <CoT description> [use-half]\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 9,
    "Content": "\n**Note:**\n\n* `<path-to-your-demo-video>`: The path to a single video\n* `[use-half]` (optional): Add use-half at the end to enable half precision feature extraction.\n\n---\n\n### üì¶ Batch Inference\n\n#### **Linux/macOS**\n",
    "ContentSha": "T7owm3ZZW7sVjKwFivgiuYX2+RVuNBl0RYTSnIcxxbM=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "**‡§®‡•ã‡§ü:**\n\n* `<path-to-your-demo-video>`: ‡§è‡§ï‡§≤ ‡§µ‡•Ä‡§°‡§ø‡§Ø‡•ã ‡§ï‡§æ ‡§™‡§•\n* `[use-half]` (‡§µ‡•à‡§ï‡§≤‡•ç‡§™‡§ø‡§ï): ‡§Ö‡§Ç‡§§‡§ø‡§Æ ‡§Æ‡•á‡§Ç use-half ‡§ú‡•ã‡§°‡§º‡•á‡§Ç ‡§§‡§æ‡§ï‡§ø ‡§π‡§æ‡§´ ‡§™‡•ç‡§∞‡§ø‡§∏‡•Ä‡§ú‡§® ‡§´‡•Ä‡§ö‡§∞ ‡§è‡§ï‡•ç‡§∏‡§ü‡•ç‡§∞‡•à‡§ï‡•ç‡§∂‡§® ‡§∏‡§ï‡•ç‡§∑‡§Æ ‡§π‡•ã ‡§∏‡§ï‡•á‡•§\n\n---\n\n### üì¶ ‡§¨‡•à‡§ö ‡§á‡§®‡§´‡•á‡§∞‡•á‡§Ç‡§∏\n\n#### **Linux/macOS**\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 10,
    "Content": "```bash\nchmod +x scripts/eval_batch.sh\n./scripts/eval_batch.sh <video_path> <csv_path> <save_path (optional)> [use-half]\n```",
    "ContentSha": "EQ4HuSYii55aHfgphESvOXMz2+Fq39+Xquxg6Z6uzdU=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\nchmod +x scripts/eval_batch.sh\n./scripts/eval_batch.sh <video_path> <csv_path> <save_path (optional)> [use-half]\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 11,
    "Content": "\n#### **Windows**\n\nUse the equivalent `.bat` script:\n",
    "ContentSha": "njm5i6o3MR7AV4Q3WLctbe3LN1njFn89fPfTlo+zSmc=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "#### **‡§µ‡§ø‡§Ç‡§°‡•ã‡§ú‡§º**\n\n‡§∏‡§Æ‡§æ‡§® `.bat` ‡§∏‡•ç‡§ï‡•ç‡§∞‡§ø‡§™‡•ç‡§ü ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡•á‡§Ç:\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 12,
    "Content": "```bash\n.\\scripts\\eval_batch.bat <video_path> <csv_path> <save_path (optional)> [use-half]\n```",
    "ContentSha": "XLkAqxYBZeJiF6XnpshI6naENFsr5yFAH7af132cgb0=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\n.\\scripts\\eval_batch.bat <video_path> <csv_path> <save_path (optional)> [use-half]\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 13,
    "Content": "\n**Note:**\n\n* `<video_path>`: Path to the root directory containing all .mp4 videos to be processed (all videos must be of equal duration).\n* `<csv_path>`: A CSV file with text prompts for each video (see `demo_test.csv` for format).\n* `<save_path>` (optional): Where to save generated audio. Defaults to `results/features`.\n* `[use-half]` (optional): Add use-half at the end to enable half precision feature extraction.\n\n---\n\n\n### Web Interface Usage\n\nFor an interactive experience, launch the Gradio web interface:\n",
    "ContentSha": "yT/y6PXpYV8wS4qmKJfVNVGDLOwreTxCdCDFDv2VbLo=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "**‡§®‡•ã‡§ü:**\n\n* `<video_path>`: ‡§â‡§∏ ‡§Æ‡•Ç‡§≤ ‡§®‡§ø‡§∞‡•ç‡§¶‡•á‡§∂‡§ø‡§ï‡§æ ‡§ï‡§æ ‡§™‡§• ‡§ú‡§ø‡§∏‡§Æ‡•á‡§Ç ‡§∏‡§≠‡•Ä .mp4 ‡§µ‡•Ä‡§°‡§ø‡§Ø‡•ã ‡§™‡•ç‡§∞‡•ã‡§∏‡•á‡§∏‡§ø‡§Ç‡§ó ‡§ï‡•á ‡§≤‡§ø‡§è ‡§∞‡§ñ‡•á ‡§ó‡§è ‡§π‡•à‡§Ç (‡§∏‡§≠‡•Ä ‡§µ‡•Ä‡§°‡§ø‡§Ø‡•ã ‡§ï‡•Ä ‡§Ö‡§µ‡§ß‡§ø ‡§∏‡§Æ‡§æ‡§® ‡§π‡•ã‡§®‡•Ä ‡§ö‡§æ‡§π‡§ø‡§è)‡•§\n* `<csv_path>`: ‡§™‡•ç‡§∞‡§§‡•ç‡§Ø‡•á‡§ï ‡§µ‡•Ä‡§°‡§ø‡§Ø‡•ã ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ü‡•á‡§ï‡•ç‡§∏‡•ç‡§ü ‡§™‡•ç‡§∞‡•â‡§Æ‡•ç‡§™‡•ç‡§ü‡•ç‡§∏ ‡§µ‡§æ‡§≤‡•Ä ‡§è‡§ï CSV ‡§´‡§º‡§æ‡§á‡§≤ (‡§´‡•â‡§∞‡•ç‡§Æ‡•á‡§ü ‡§ï‡•á ‡§≤‡§ø‡§è `demo_test.csv` ‡§¶‡•á‡§ñ‡•á‡§Ç)‡•§\n* `<save_path>` (‡§µ‡•à‡§ï‡§≤‡•ç‡§™‡§ø‡§ï): ‡§ú‡§®‡§∞‡•á‡§ü‡•á‡§° ‡§ë‡§°‡§ø‡§Ø‡•ã ‡§ï‡•ã ‡§ï‡§π‡§æ‡§Å ‡§∏‡•á‡§µ ‡§ï‡§∞‡§®‡§æ ‡§π‡•à‡•§ ‡§°‡§ø‡§´‡§º‡•â‡§≤‡•ç‡§ü ‡§π‡•à `results/features`‡•§\n* `[use-half]` (‡§µ‡•à‡§ï‡§≤‡•ç‡§™‡§ø‡§ï): ‡§π‡§æ‡§´ ‡§™‡•ç‡§∞‡§ø‡§∏‡•Ä‡§ú‡§® ‡§´‡§º‡•Ä‡§ö‡§∞ ‡§è‡§ï‡•ç‡§∏‡§ü‡•ç‡§∞‡•à‡§ï‡•ç‡§∂‡§® ‡§ï‡•ã ‡§∏‡§ï‡•ç‡§∑‡§Æ ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Ö‡§Ç‡§§ ‡§Æ‡•á‡§Ç use-half ‡§ú‡•ã‡§°‡§º‡•á‡§Ç‡•§\n\n---\n\n\n### ‡§µ‡•á‡§¨ ‡§á‡§Ç‡§ü‡§∞‡§´‡•á‡§∏ ‡§â‡§™‡§Ø‡•ã‡§ó\n\n‡§á‡§Ç‡§ü‡§∞‡§è‡§ï‡•ç‡§ü‡§ø‡§µ ‡§Ö‡§®‡•Å‡§≠‡§µ ‡§ï‡•á ‡§≤‡§ø‡§è, Gradio ‡§µ‡•á‡§¨ ‡§á‡§Ç‡§ü‡§∞‡§´‡•á‡§∏ ‡§≤‡•â‡§®‡•ç‡§ö ‡§ï‡§∞‡•á‡§Ç:\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 14,
    "Content": "```bash\npython app.py\n```",
    "ContentSha": "2nQFYMHYtsOO4+egbu20DhxqoaxfzoH8CneeM8qTEb0=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\npython app.py\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 15,
    "Content": "\n\n## üèãÔ∏è Train the Model\n\nSee [`Training.md`](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/docs/Training.md)\n\n\n---\n\n## üìù TODO & Future Plans\n* - [ ] Release a more powerful foundation model covering multiple domains to provide more engaging and immersive foley creation\n* - [ ] Add support for additional modalities and downstream tasks\n* - [ ] Release models at different scales\n* - [x] Open-source AudioCoT dataset and automated pipeline\n* - [x] Release training scripts for ThinkSound models\n* - [x] A beginner-friendly Windows quick-start README\n---\n\n\n## üìÑ License\n\nThis project is released under the Apache 2.0 License.\n\n> **Note:**\n> The code, models, and dataset are **for research and educational purposes only**.\n> **Commercial use is NOT permitted.**\n> For commercial licensing, please contact the authors.\n\n**üì¶ Third-Party Components**\n\n* **Stable Audio Open VAE** (by Stability AI):\n  This repository includes a fine-tuned VAE from [Stable Audio Open](https://huggingface.co/stabilityai/stable-audio-open-1.0/), licensed under the [Stability AI Community License](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/./third_party/LICENSE_StabilityAI.md).\n  **Commercial use and redistribution require prior permission from Stability AI.**\n\n* üìò **All other code and models** are released under the Apache License 2.0.\n\n---\n\n## Acknowledgements\n",
    "ContentSha": "j3jq6Afpr38oSd7nSvDiMiQ889Z6kSywM0DVVT9ieNA=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "\n\n## üèãÔ∏è ‡§Æ‡•â‡§°‡§≤ ‡§ï‡•ã ‡§™‡•ç‡§∞‡§∂‡§ø‡§ï‡•ç‡§∑‡§ø‡§§ ‡§ï‡§∞‡•á‡§Ç\n\n‡§¶‡•á‡§ñ‡•á‡§Ç [`Training.md`](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/docs/Training.md)\n\n\n---\n\n## üìù TODO ‡§î‡§∞ ‡§≠‡§µ‡§ø‡§∑‡•ç‡§Ø ‡§ï‡•Ä ‡§Ø‡•ã‡§ú‡§®‡§æ‡§è‡§Å\n* - [ ] ‡§è‡§ï ‡§Ö‡§ß‡§ø‡§ï ‡§∂‡§ï‡•ç‡§§‡§ø‡§∂‡§æ‡§≤‡•Ä ‡§´‡§æ‡§â‡§Ç‡§°‡•á‡§∂‡§® ‡§Æ‡•â‡§°‡§≤ ‡§ú‡§æ‡§∞‡•Ä ‡§ï‡§∞‡•á‡§Ç ‡§ú‡•ã ‡§ï‡§à ‡§ï‡•ç‡§∑‡•á‡§§‡•ç‡§∞‡•ã‡§Ç ‡§ï‡•ã ‡§ï‡§µ‡§∞ ‡§ï‡§∞‡•á ‡§§‡§æ‡§ï‡§ø ‡§Ö‡§ß‡§ø‡§ï ‡§Ü‡§ï‡§∞‡•ç‡§∑‡§ï ‡§î‡§∞ ‡§á‡§Æ‡§∞‡•ç‡§∏‡§ø‡§µ ‡§´‡•ã‡§≤‡•Ä ‡§®‡§ø‡§∞‡•ç‡§Æ‡§æ‡§£ ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡§ø‡§Ø‡§æ ‡§ú‡§æ ‡§∏‡§ï‡•á\n* - [ ] ‡§Ö‡§§‡§ø‡§∞‡§ø‡§ï‡•ç‡§§ ‡§Æ‡•ã‡§°‡§æ‡§≤‡§ø‡§ü‡•Ä ‡§î‡§∞ ‡§°‡§æ‡§â‡§®‡§∏‡•ç‡§ü‡•ç‡§∞‡•Ä‡§Æ ‡§ï‡§æ‡§∞‡•ç‡§Ø‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§∏‡§Æ‡§∞‡•ç‡§•‡§® ‡§ú‡•ã‡§°‡§º‡•á‡§Ç\n* - [ ] ‡§µ‡§ø‡§≠‡§ø‡§®‡•ç‡§® ‡§∏‡•ç‡§§‡§∞‡•ã‡§Ç ‡§™‡§∞ ‡§Æ‡•â‡§°‡§≤ ‡§ú‡§æ‡§∞‡•Ä ‡§ï‡§∞‡•á‡§Ç\n* - [x] AudioCoT ‡§°‡•á‡§ü‡§æ‡§∏‡•á‡§ü ‡§î‡§∞ ‡§∏‡•ç‡§µ‡§ö‡§æ‡§≤‡§ø‡§§ ‡§™‡§æ‡§á‡§™‡§≤‡§æ‡§á‡§® ‡§ï‡•ã ‡§ì‡§™‡§®-‡§∏‡•ã‡§∞‡•ç‡§∏ ‡§ï‡§∞‡•á‡§Ç\n* - [x] ThinkSound ‡§Æ‡•â‡§°‡§≤ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§™‡•ç‡§∞‡§∂‡§ø‡§ï‡•ç‡§∑‡§£ ‡§∏‡•ç‡§ï‡•ç‡§∞‡§ø‡§™‡•ç‡§ü ‡§ú‡§æ‡§∞‡•Ä ‡§ï‡§∞‡•á‡§Ç\n* - [x] ‡§∂‡•Å‡§∞‡•Å‡§Ü‡§§‡•Ä ‡§ï‡•á ‡§≤‡§ø‡§è Windows ‡§ï‡•ç‡§µ‡§ø‡§ï-‡§∏‡•ç‡§ü‡§æ‡§∞‡•ç‡§ü README ‡§ú‡§æ‡§∞‡•Ä ‡§ï‡§∞‡•á‡§Ç\n---\n\n\n## üìÑ ‡§≤‡§æ‡§á‡§∏‡•á‡§Ç‡§∏\n\n‡§Ø‡§π ‡§™‡§∞‡§ø‡§Ø‡•ã‡§ú‡§®‡§æ Apache 2.0 ‡§≤‡§æ‡§á‡§∏‡•á‡§Ç‡§∏ ‡§ï‡•á ‡§§‡§π‡§§ ‡§ú‡§æ‡§∞‡•Ä ‡§ï‡•Ä ‡§ó‡§à ‡§π‡•à‡•§\n\n> **‡§®‡•ã‡§ü:**\n> ‡§ï‡•ã‡§°, ‡§Æ‡•â‡§°‡§≤, ‡§î‡§∞ ‡§°‡•á‡§ü‡§æ‡§∏‡•á‡§ü **‡§ï‡•á‡§µ‡§≤ ‡§∂‡•ã‡§ß ‡§î‡§∞ ‡§∂‡•à‡§ï‡•ç‡§∑‡§ø‡§ï ‡§â‡§¶‡•ç‡§¶‡•á‡§∂‡•ç‡§Ø‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§π‡•à‡§Ç**‡•§\n> **‡§µ‡•ç‡§Ø‡§æ‡§µ‡§∏‡§æ‡§Ø‡§ø‡§ï ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡•Ä ‡§Ö‡§®‡•Å‡§Æ‡§§‡§ø ‡§®‡§π‡•Ä‡§Ç ‡§π‡•à‡•§**\n> ‡§µ‡•ç‡§Ø‡§æ‡§µ‡§∏‡§æ‡§Ø‡§ø‡§ï ‡§≤‡§æ‡§á‡§∏‡•á‡§Ç‡§∏‡§ø‡§Ç‡§ó ‡§ï‡•á ‡§≤‡§ø‡§è, ‡§ï‡•É‡§™‡§Ø‡§æ ‡§≤‡•á‡§ñ‡§ï‡•ã‡§Ç ‡§∏‡•á ‡§∏‡§Ç‡§™‡§∞‡•ç‡§ï ‡§ï‡§∞‡•á‡§Ç‡•§\n\n**üì¶ ‡§§‡•É‡§§‡•Ä‡§Ø-‡§™‡§ï‡•ç‡§∑ ‡§ò‡§ü‡§ï**\n\n* **Stable Audio Open VAE** (Stability AI ‡§¶‡•ç‡§µ‡§æ‡§∞‡§æ):\n  ‡§Ø‡§π ‡§∞‡§ø‡§™‡•â‡§ú‡§ø‡§ü‡§∞‡•Ä [Stable Audio Open](https://huggingface.co/stabilityai/stable-audio-open-1.0/) ‡§∏‡•á ‡§´‡§æ‡§á‡§®-‡§ü‡•ç‡§Ø‡•Ç‡§® ‡§ï‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ VAE ‡§∂‡§æ‡§Æ‡§ø‡§≤ ‡§ï‡§∞‡§§‡•Ä ‡§π‡•à, ‡§ú‡•ã [Stability AI Community License](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/./third_party/LICENSE_StabilityAI.md) ‡§ï‡•á ‡§Ö‡§Ç‡§§‡§∞‡•ç‡§ó‡§§ ‡§≤‡§æ‡§á‡§∏‡•á‡§Ç‡§∏ ‡§™‡•ç‡§∞‡§æ‡§™‡•ç‡§§ ‡§π‡•à‡•§\n  **‡§µ‡•ç‡§Ø‡§æ‡§µ‡§∏‡§æ‡§Ø‡§ø‡§ï ‡§â‡§™‡§Ø‡•ã‡§ó ‡§î‡§∞ ‡§™‡•Å‡§®‡§∞‡•ç‡§µ‡§ø‡§§‡§∞‡§£ ‡§ï‡•á ‡§≤‡§ø‡§è Stability AI ‡§∏‡•á ‡§™‡•Ç‡§∞‡•ç‡§µ ‡§Ö‡§®‡•Å‡§Æ‡§§‡§ø ‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï ‡§π‡•à‡•§**\n\n* üìò **‡§Ö‡§®‡•ç‡§Ø ‡§∏‡§≠‡•Ä ‡§ï‡•ã‡§° ‡§î‡§∞ ‡§Æ‡•â‡§°‡§≤** Apache License 2.0 ‡§ï‡•á ‡§§‡§π‡§§ ‡§ú‡§æ‡§∞‡•Ä ‡§ï‡§ø‡§è ‡§ó‡§è ‡§π‡•à‡§Ç‡•§\n\n---\n\n## ‡§Ü‡§≠‡§æ‡§∞\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 2,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 3,
        "rowsha": "gqXeKd562+SIhV8X5lKkIq9fmYls0JvenYq/r5leqGU=",
        "originContent": "## üèãÔ∏è Train the Model",
        "translatedContent": "## üèãÔ∏è ‡§Æ‡•â‡§°‡§≤ ‡§ï‡•ã ‡§™‡•ç‡§∞‡§∂‡§ø‡§ï‡•ç‡§∑‡§ø‡§§ ‡§ï‡§∞‡•á‡§Ç"
      },
      {
        "row": 4,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 5,
        "rowsha": "2tP4BwaoybodWdJJ8ZupmDbf3ea5A0f+lD6kd0qGru8=",
        "originContent": "See [`Training.md`](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/docs/Training.md)",
        "translatedContent": "‡§¶‡•á‡§ñ‡•á‡§Ç [`Training.md`](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/docs/Training.md)"
      },
      {
        "row": 6,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 7,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 8,
        "rowsha": "yz+R1U7uMOU+NbK5mQX3Dxae1Un9eJCdPawt78ntjTs=",
        "originContent": "---",
        "translatedContent": "---"
      },
      {
        "row": 9,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 10,
        "rowsha": "21hoBW2Chiv9qZT66tUvbTf1cEdQjWTP1PUgVsUkdFY=",
        "originContent": "## üìù TODO & Future Plans",
        "translatedContent": "## üìù TODO ‡§î‡§∞ ‡§≠‡§µ‡§ø‡§∑‡•ç‡§Ø ‡§ï‡•Ä ‡§Ø‡•ã‡§ú‡§®‡§æ‡§è‡§Å"
      },
      {
        "row": 11,
        "rowsha": "FrwO0jQkAGelT7Z0nxH1R9qrULhNLkTE9mkwOhdMPY8=",
        "originContent": "* - [ ] Release a more powerful foundation model covering multiple domains to provide more engaging and immersive foley creation",
        "translatedContent": "* - [ ] ‡§è‡§ï ‡§Ö‡§ß‡§ø‡§ï ‡§∂‡§ï‡•ç‡§§‡§ø‡§∂‡§æ‡§≤‡•Ä ‡§´‡§æ‡§â‡§Ç‡§°‡•á‡§∂‡§® ‡§Æ‡•â‡§°‡§≤ ‡§ú‡§æ‡§∞‡•Ä ‡§ï‡§∞‡•á‡§Ç ‡§ú‡•ã ‡§ï‡§à ‡§ï‡•ç‡§∑‡•á‡§§‡•ç‡§∞‡•ã‡§Ç ‡§ï‡•ã ‡§ï‡§µ‡§∞ ‡§ï‡§∞‡•á ‡§§‡§æ‡§ï‡§ø ‡§Ö‡§ß‡§ø‡§ï ‡§Ü‡§ï‡§∞‡•ç‡§∑‡§ï ‡§î‡§∞ ‡§á‡§Æ‡§∞‡•ç‡§∏‡§ø‡§µ ‡§´‡•ã‡§≤‡•Ä ‡§®‡§ø‡§∞‡•ç‡§Æ‡§æ‡§£ ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡§ø‡§Ø‡§æ ‡§ú‡§æ ‡§∏‡§ï‡•á"
      },
      {
        "row": 12,
        "rowsha": "UkxbZFENzZPvcMheOeyohEptbnVaOGv9G4R6F65rAUA=",
        "originContent": "* - [ ] Add support for additional modalities and downstream tasks",
        "translatedContent": "* - [ ] ‡§Ö‡§§‡§ø‡§∞‡§ø‡§ï‡•ç‡§§ ‡§Æ‡•ã‡§°‡§æ‡§≤‡§ø‡§ü‡•Ä ‡§î‡§∞ ‡§°‡§æ‡§â‡§®‡§∏‡•ç‡§ü‡•ç‡§∞‡•Ä‡§Æ ‡§ï‡§æ‡§∞‡•ç‡§Ø‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§∏‡§Æ‡§∞‡•ç‡§•‡§® ‡§ú‡•ã‡§°‡§º‡•á‡§Ç"
      },
      {
        "row": 13,
        "rowsha": "E0/ATBXmq5Z+04AptdW37Wxd5y8GSQNsoEWooX9af6s=",
        "originContent": "* - [ ] Release models at different scales",
        "translatedContent": "* - [ ] ‡§µ‡§ø‡§≠‡§ø‡§®‡•ç‡§® ‡§∏‡•ç‡§§‡§∞‡•ã‡§Ç ‡§™‡§∞ ‡§Æ‡•â‡§°‡§≤ ‡§ú‡§æ‡§∞‡•Ä ‡§ï‡§∞‡•á‡§Ç"
      },
      {
        "row": 14,
        "rowsha": "fjIAroioQtu6rLpfZfLu7D1x79s4hnPI+ZQSINXiAVk=",
        "originContent": "* - [x] Open-source AudioCoT dataset and automated pipeline",
        "translatedContent": "* - [x] AudioCoT ‡§°‡•á‡§ü‡§æ‡§∏‡•á‡§ü ‡§î‡§∞ ‡§∏‡•ç‡§µ‡§ö‡§æ‡§≤‡§ø‡§§ ‡§™‡§æ‡§á‡§™‡§≤‡§æ‡§á‡§® ‡§ï‡•ã ‡§ì‡§™‡§®-‡§∏‡•ã‡§∞‡•ç‡§∏ ‡§ï‡§∞‡•á‡§Ç"
      },
      {
        "row": 15,
        "rowsha": "k5iXHel4EfGgiGsMDCE6yv2H9ETcLNi9lRuB8gaPbt4=",
        "originContent": "* - [x] Release training scripts for ThinkSound models",
        "translatedContent": "* - [x] ThinkSound ‡§Æ‡•â‡§°‡§≤ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§™‡•ç‡§∞‡§∂‡§ø‡§ï‡•ç‡§∑‡§£ ‡§∏‡•ç‡§ï‡•ç‡§∞‡§ø‡§™‡•ç‡§ü ‡§ú‡§æ‡§∞‡•Ä ‡§ï‡§∞‡•á‡§Ç"
      },
      {
        "row": 16,
        "rowsha": "AKQD74q/2r77sZrB6i/RNuvdN/QOzatiPxneZX2CGJY=",
        "originContent": "* - [x] A beginner-friendly Windows quick-start README",
        "translatedContent": "* - [x] ‡§∂‡•Å‡§∞‡•Å‡§Ü‡§§‡•Ä ‡§ï‡•á ‡§≤‡§ø‡§è Windows ‡§ï‡•ç‡§µ‡§ø‡§ï-‡§∏‡•ç‡§ü‡§æ‡§∞‡•ç‡§ü README ‡§ú‡§æ‡§∞‡•Ä ‡§ï‡§∞‡•á‡§Ç"
      },
      {
        "row": 17,
        "rowsha": "yz+R1U7uMOU+NbK5mQX3Dxae1Un9eJCdPawt78ntjTs=",
        "originContent": "---",
        "translatedContent": "---"
      },
      {
        "row": 18,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 19,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 20,
        "rowsha": "qdzKI50RqHyAaNHbQuVekCMXyk/TfGfppMlRPvlONC4=",
        "originContent": "## üìÑ License",
        "translatedContent": "## üìÑ ‡§≤‡§æ‡§á‡§∏‡•á‡§Ç‡§∏"
      },
      {
        "row": 21,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 22,
        "rowsha": "aXzA1Vml4g3VpeAQHojytlHw5gMbI/HCXkxCOreR8fk=",
        "originContent": "This project is released under the Apache 2.0 License.",
        "translatedContent": "‡§Ø‡§π ‡§™‡§∞‡§ø‡§Ø‡•ã‡§ú‡§®‡§æ Apache 2.0 ‡§≤‡§æ‡§á‡§∏‡•á‡§Ç‡§∏ ‡§ï‡•á ‡§§‡§π‡§§ ‡§ú‡§æ‡§∞‡•Ä ‡§ï‡•Ä ‡§ó‡§à ‡§π‡•à‡•§"
      },
      {
        "row": 23,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 24,
        "rowsha": "q6szrCjtQrp9SVd3O6pmLDmi4BNjrSJj5JAz5iOimGA=",
        "originContent": "> **Note:**",
        "translatedContent": "> **‡§®‡•ã‡§ü:**"
      },
      {
        "row": 25,
        "rowsha": "rOuOE29N380ZQ7xL0jH7/C5Wx2byuzA8mLZWbrRiPMU=",
        "originContent": "> The code, models, and dataset are **for research and educational purposes only**.",
        "translatedContent": "> ‡§ï‡•ã‡§°, ‡§Æ‡•â‡§°‡§≤, ‡§î‡§∞ ‡§°‡•á‡§ü‡§æ‡§∏‡•á‡§ü **‡§ï‡•á‡§µ‡§≤ ‡§∂‡•ã‡§ß ‡§î‡§∞ ‡§∂‡•à‡§ï‡•ç‡§∑‡§ø‡§ï ‡§â‡§¶‡•ç‡§¶‡•á‡§∂‡•ç‡§Ø‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§π‡•à‡§Ç**‡•§"
      },
      {
        "row": 26,
        "rowsha": "FEb26wdcJZ+QYdFQmEiYYJyI1m7dr8KnrT/jJ+mJJ9E=",
        "originContent": "> **Commercial use is NOT permitted.**",
        "translatedContent": "> **‡§µ‡•ç‡§Ø‡§æ‡§µ‡§∏‡§æ‡§Ø‡§ø‡§ï ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡•Ä ‡§Ö‡§®‡•Å‡§Æ‡§§‡§ø ‡§®‡§π‡•Ä‡§Ç ‡§π‡•à‡•§**"
      },
      {
        "row": 27,
        "rowsha": "YQDz0urnAm3iQlKVm+90x6BIEceDXonnoA+1AGDIxUo=",
        "originContent": "> For commercial licensing, please contact the authors.",
        "translatedContent": "> ‡§µ‡•ç‡§Ø‡§æ‡§µ‡§∏‡§æ‡§Ø‡§ø‡§ï ‡§≤‡§æ‡§á‡§∏‡•á‡§Ç‡§∏‡§ø‡§Ç‡§ó ‡§ï‡•á ‡§≤‡§ø‡§è, ‡§ï‡•É‡§™‡§Ø‡§æ ‡§≤‡•á‡§ñ‡§ï‡•ã‡§Ç ‡§∏‡•á ‡§∏‡§Ç‡§™‡§∞‡•ç‡§ï ‡§ï‡§∞‡•á‡§Ç‡•§"
      },
      {
        "row": 28,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 29,
        "rowsha": "idCvsL23+SgGxeiktrTl5Y+r1XCJFcD6eO3243OaAPY=",
        "originContent": "**üì¶ Third-Party Components**",
        "translatedContent": "**üì¶ ‡§§‡•É‡§§‡•Ä‡§Ø-‡§™‡§ï‡•ç‡§∑ ‡§ò‡§ü‡§ï**"
      },
      {
        "row": 30,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 31,
        "rowsha": "WE7FE/+7lXbNs5ENH4uLy9/fzMNY1H60uSJ7lRbBD0o=",
        "originContent": "* **Stable Audio Open VAE** (by Stability AI):",
        "translatedContent": "* **Stable Audio Open VAE** (Stability AI ‡§¶‡•ç‡§µ‡§æ‡§∞‡§æ):"
      },
      {
        "row": 32,
        "rowsha": "n8R1JiNonohwAL0UGMf3R1xgnYRnz5fdUI6ZtkdzKnU=",
        "originContent": "  This repository includes a fine-tuned VAE from [Stable Audio Open](https://huggingface.co/stabilityai/stable-audio-open-1.0/), licensed under the [Stability AI Community License](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/./third_party/LICENSE_StabilityAI.md).",
        "translatedContent": "  ‡§Ø‡§π ‡§∞‡§ø‡§™‡•â‡§ú‡§ø‡§ü‡§∞‡•Ä [Stable Audio Open](https://huggingface.co/stabilityai/stable-audio-open-1.0/) ‡§∏‡•á ‡§´‡§æ‡§á‡§®-‡§ü‡•ç‡§Ø‡•Ç‡§® ‡§ï‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ VAE ‡§∂‡§æ‡§Æ‡§ø‡§≤ ‡§ï‡§∞‡§§‡•Ä ‡§π‡•à, ‡§ú‡•ã [Stability AI Community License](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/./third_party/LICENSE_StabilityAI.md) ‡§ï‡•á ‡§Ö‡§Ç‡§§‡§∞‡•ç‡§ó‡§§ ‡§≤‡§æ‡§á‡§∏‡•á‡§Ç‡§∏ ‡§™‡•ç‡§∞‡§æ‡§™‡•ç‡§§ ‡§π‡•à‡•§"
      },
      {
        "row": 33,
        "rowsha": "z1nrjZCTFkfKVpjvRtVTCvLJ3eIRc/0lYZ6q1FAyF9Y=",
        "originContent": "  **Commercial use and redistribution require prior permission from Stability AI.**",
        "translatedContent": "  **‡§µ‡•ç‡§Ø‡§æ‡§µ‡§∏‡§æ‡§Ø‡§ø‡§ï ‡§â‡§™‡§Ø‡•ã‡§ó ‡§î‡§∞ ‡§™‡•Å‡§®‡§∞‡•ç‡§µ‡§ø‡§§‡§∞‡§£ ‡§ï‡•á ‡§≤‡§ø‡§è Stability AI ‡§∏‡•á ‡§™‡•Ç‡§∞‡•ç‡§µ ‡§Ö‡§®‡•Å‡§Æ‡§§‡§ø ‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï ‡§π‡•à‡•§**"
      },
      {
        "row": 34,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 35,
        "rowsha": "Rc/58q3GXX1uj9YQLKADnw6rI9fXJsB3qr7SgcFxhJQ=",
        "originContent": "* üìò **All other code and models** are released under the Apache License 2.0.",
        "translatedContent": "* üìò **‡§Ö‡§®‡•ç‡§Ø ‡§∏‡§≠‡•Ä ‡§ï‡•ã‡§° ‡§î‡§∞ ‡§Æ‡•â‡§°‡§≤** Apache License 2.0 ‡§ï‡•á ‡§§‡§π‡§§ ‡§ú‡§æ‡§∞‡•Ä ‡§ï‡§ø‡§è ‡§ó‡§è ‡§π‡•à‡§Ç‡•§"
      },
      {
        "row": 36,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 37,
        "rowsha": "yz+R1U7uMOU+NbK5mQX3Dxae1Un9eJCdPawt78ntjTs=",
        "originContent": "---",
        "translatedContent": "---"
      },
      {
        "row": 38,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 39,
        "rowsha": "HvkwNudYOlwL8j/t4djBVF3hUJwHWa2r5QjmSxgq3AA=",
        "originContent": "## Acknowledgements",
        "translatedContent": "## ‡§Ü‡§≠‡§æ‡§∞"
      },
      {
        "row": 40,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 16,
    "Content": "Many thanks to:\n\n* **stable-audio-tools** (by Stability AI):\nFor providing an easy-to-use framework for audio generation, as well as the VAE module and weights.\n* **MMAudio**:\n  For the implementation of the MM-DiT backbone in the audio domain.\n\n---\n\n## üìñ Citation\n\nIf you find ThinkSound useful in your research or work, please cite our paper:\n",
    "ContentSha": "FsK5U++tkthvkZ/Gd4G7gn74YKpB282Oxnkt96u9C1k=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "‡§¨‡§π‡•Å‡§§ ‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ‡§¶:\n\n* **stable-audio-tools** (Stability AI ‡§¶‡•ç‡§µ‡§æ‡§∞‡§æ):\n‡§ë‡§°‡§ø‡§Ø‡•ã ‡§ú‡§®‡§∞‡•á‡§∂‡§® ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Ü‡§∏‡§æ‡§® ‡§´‡•ç‡§∞‡•á‡§Æ‡§µ‡§∞‡•ç‡§ï ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è, ‡§∏‡§æ‡§• ‡§π‡•Ä VAE ‡§Æ‡•â‡§°‡•ç‡§Ø‡•Ç‡§≤ ‡§î‡§∞ ‡§µ‡§ú‡§º‡§® ‡§ï‡•á ‡§≤‡§ø‡§è‡•§\n* **MMAudio**:\n  ‡§ë‡§°‡§ø‡§Ø‡•ã ‡§°‡•ã‡§Æ‡•á‡§® ‡§Æ‡•á‡§Ç MM-DiT ‡§¨‡•à‡§ï‡§¨‡•ã‡§® ‡§ï‡•á ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§æ‡§®‡•ç‡§µ‡§Ø‡§® ‡§ï‡•á ‡§≤‡§ø‡§è‡•§\n\n---\n\n## üìñ ‡§â‡§¶‡•ç‡§ß‡§∞‡§£\n\n‡§Ø‡§¶‡§ø ‡§Ü‡§™‡§ï‡•ã ThinkSound ‡§Ö‡§™‡§®‡•á ‡§∂‡•ã‡§ß ‡§Ø‡§æ ‡§ï‡§æ‡§∞‡•ç‡§Ø ‡§Æ‡•á‡§Ç ‡§â‡§™‡§Ø‡•ã‡§ó‡•Ä ‡§≤‡§ó‡•á, ‡§§‡•ã ‡§ï‡•É‡§™‡§Ø‡§æ ‡§π‡§Æ‡§æ‡§∞‡•á ‡§™‡•á‡§™‡§∞ ‡§ï‡§æ ‡§â‡§≤‡•ç‡§≤‡•á‡§ñ ‡§ï‡§∞‡•á‡§Ç:\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "nrozD4yXZdvCdVDGRjdO303ENLy2DrpELvY0lV8DjU4=",
        "originContent": "Many thanks to:",
        "translatedContent": "‡§¨‡§π‡•Å‡§§ ‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ‡§¶:"
      },
      {
        "row": 2,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 3,
        "rowsha": "7poAa5FddcjiBYp6TtQpLbB4qN57dBa/V6Oc1d6Ak1c=",
        "originContent": "* **stable-audio-tools** (by Stability AI):",
        "translatedContent": "* **stable-audio-tools** (Stability AI ‡§¶‡•ç‡§µ‡§æ‡§∞‡§æ):"
      },
      {
        "row": 4,
        "rowsha": "ChUiuc0nNLek0lyZz64pXvYp23+nJyAL95/UOo1ez4U=",
        "originContent": "For providing an easy-to-use framework for audio generation, as well as the VAE module and weights.",
        "translatedContent": "‡§ë‡§°‡§ø‡§Ø‡•ã ‡§ú‡§®‡§∞‡•á‡§∂‡§® ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Ü‡§∏‡§æ‡§® ‡§´‡•ç‡§∞‡•á‡§Æ‡§µ‡§∞‡•ç‡§ï ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è, ‡§∏‡§æ‡§• ‡§π‡•Ä VAE ‡§Æ‡•â‡§°‡•ç‡§Ø‡•Ç‡§≤ ‡§î‡§∞ ‡§µ‡§ú‡§º‡§® ‡§ï‡•á ‡§≤‡§ø‡§è‡•§"
      },
      {
        "row": 5,
        "rowsha": "nn9Ut2wJSSgxPicEUDiiTuEnuQK99h2v5Ue5JFAtHN0=",
        "originContent": "* **MMAudio**:",
        "translatedContent": "* **MMAudio**:"
      },
      {
        "row": 6,
        "rowsha": "3yv6rAm2+j4agcTG/gcAtQLX1Kv0n/+YvFmBsObWoYo=",
        "originContent": "  For the implementation of the MM-DiT backbone in the audio domain.",
        "translatedContent": "  ‡§ë‡§°‡§ø‡§Ø‡•ã ‡§°‡•ã‡§Æ‡•á‡§® ‡§Æ‡•á‡§Ç MM-DiT ‡§¨‡•à‡§ï‡§¨‡•ã‡§® ‡§ï‡•á ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§æ‡§®‡•ç‡§µ‡§Ø‡§® ‡§ï‡•á ‡§≤‡§ø‡§è‡•§"
      },
      {
        "row": 7,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 8,
        "rowsha": "yz+R1U7uMOU+NbK5mQX3Dxae1Un9eJCdPawt78ntjTs=",
        "originContent": "---",
        "translatedContent": "---"
      },
      {
        "row": 9,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 10,
        "rowsha": "syomH5Of+YY9KSCalKtADVZFMa9lRWCIOiYIqbfDgKI=",
        "originContent": "## üìñ Citation",
        "translatedContent": "## üìñ ‡§â‡§¶‡•ç‡§ß‡§∞‡§£"
      },
      {
        "row": 11,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 12,
        "rowsha": "o5GEZn4azbbEeVodFzyyGdWtJ79JPcZQcPI33OuhB4o=",
        "originContent": "If you find ThinkSound useful in your research or work, please cite our paper:",
        "translatedContent": "‡§Ø‡§¶‡§ø ‡§Ü‡§™‡§ï‡•ã ThinkSound ‡§Ö‡§™‡§®‡•á ‡§∂‡•ã‡§ß ‡§Ø‡§æ ‡§ï‡§æ‡§∞‡•ç‡§Ø ‡§Æ‡•á‡§Ç ‡§â‡§™‡§Ø‡•ã‡§ó‡•Ä ‡§≤‡§ó‡•á, ‡§§‡•ã ‡§ï‡•É‡§™‡§Ø‡§æ ‡§π‡§Æ‡§æ‡§∞‡•á ‡§™‡•á‡§™‡§∞ ‡§ï‡§æ ‡§â‡§≤‡•ç‡§≤‡•á‡§ñ ‡§ï‡§∞‡•á‡§Ç:"
      },
      {
        "row": 13,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 17,
    "Content": "```bibtex\n@misc{liu2025thinksoundchainofthoughtreasoningmultimodal,\n      title={ThinkSound: Chain-of-Thought Reasoning in Multimodal Large Language Models for Audio Generation and Editing}, \n      author={Huadai Liu and Jialei Wang and Kaicheng Luo and Wen Wang and Qian Chen and Zhou Zhao and Wei Xue},\n      year={2025},\n      eprint={2506.21448},\n      archivePrefix={arXiv},\n      primaryClass={eess.AS},\n      url={https://arxiv.org/abs/2506.21448}, \n}\n```",
    "ContentSha": "KKv35iBt6IDF1ifN04L+6lkh0BHkbObnW/+m50Wufrs=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bibtex\n@misc{liu2025thinksoundchainofthoughtreasoningmultimodal,\n      title={ThinkSound: Chain-of-Thought Reasoning in Multimodal Large Language Models for Audio Generation and Editing}, \n      author={Huadai Liu and Jialei Wang and Kaicheng Luo and Wen Wang and Qian Chen and Zhou Zhao and Wei Xue},\n      year={2025},\n      eprint={2506.21448},\n      archivePrefix={arXiv},\n      primaryClass={eess.AS},\n      url={https://arxiv.org/abs/2506.21448}, \n}\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 18,
    "Content": "\n---\n\n## üì¨ Contact\n\n\n‚ú® Feel free to [open an issue](https://github.com/liuhuadai/ThinkSound/issues) or contact us via email ([liuhuadai@zju.edu.cn](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/mailto:liuhuadai@zju.edu.cn)) if you have any questions or suggestions!\n\n",
    "ContentSha": "bhgThXKCFQGVw+ap6COOeWEROoFc9CTAywSYDLrpw98=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "\n---\n\n## üì¨ Contact\n\n\n‚ú® Feel free to [open an issue](https://github.com/liuhuadai/ThinkSound/issues) or contact us via email ([liuhuadai@zju.edu.cn](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/mailto:liuhuadai@zju.edu.cn)) if you have any questions or suggestions!\n\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 2,
        "rowsha": "yz+R1U7uMOU+NbK5mQX3Dxae1Un9eJCdPawt78ntjTs=",
        "originContent": "---",
        "translatedContent": "---"
      },
      {
        "row": 3,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 4,
        "rowsha": "V0ea1xQLKG+cGj5kHVv5f15HDd+yj0ulkcBQnvErdJc=",
        "originContent": "## üì¨ Contact",
        "translatedContent": "## üì¨ Contact"
      },
      {
        "row": 5,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 6,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 7,
        "rowsha": "QsDuVwX1DXlTNejKuNftx4k1x7yNHjfP9/1HS85hJng=",
        "originContent": "‚ú® Feel free to [open an issue](https://github.com/liuhuadai/ThinkSound/issues) or contact us via email ([liuhuadai@zju.edu.cn](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/mailto:liuhuadai@zju.edu.cn)) if you have any questions or suggestions!",
        "translatedContent": "‚ú® Feel free to [open an issue](https://github.com/liuhuadai/ThinkSound/issues) or contact us via email ([liuhuadai@zju.edu.cn](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/mailto:liuhuadai@zju.edu.cn)) if you have any questions or suggestions!"
      },
      {
        "row": 8,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 9,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  }
]