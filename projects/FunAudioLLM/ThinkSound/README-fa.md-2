{
  "id": 2,
  "origin": "## ğŸ“ TODO\n\n- â˜ Release training scripts for ThinkSound models\n- â˜ Open-source AudioCoT dataset and automated pipeline\n- â˜ Provide detailed documentation and API reference\n- â˜ Add support for additional modalities and downstream tasks\n\n---\n\n## ğŸ“„ License\n\nThis project is released under the [Apache 2.0 License](LICENSE).\n\n> **Note:**  \n> The code, models, and dataset are **for research and educational purposes only**.  \n> **Commercial use is NOT permitted.**\n>\n> For commercial licensing, please contact the authors.\n\n---\n\n## ğŸ“– Citation\n\nIf you find ThinkSound useful in your research or work, please cite our paper:\n\n```bibtex\n@misc{liu2025thinksoundchainofthoughtreasoningmultimodal,\n      title={ThinkSound: Chain-of-Thought Reasoning in Multimodal Large Language Models for Audio Generation and Editing}, \n      author={Huadai Liu and Jialei Wang and Kaicheng Luo and Wen Wang and Qian Chen and Zhou Zhao and Wei Xue},\n      year={2025},\n      eprint={2506.21448},\n      archivePrefix={arXiv},\n      primaryClass={eess.AS},\n      url={https://arxiv.org/abs/2506.21448}, \n}\n```\n\n---\n\n## ğŸ“¬ Contact\n\nâœ¨ Feel free to [open an issue](https://github.com/liuhuadai/ThinkSound/issues) or contact us via email ([liuhuadai@zju.edu.cn](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/mailto:liuhuadai@zju.edu.cn)) if you have any questions or suggestions!\n",
  "origin_sha": "NEFlwyN+fN3dUarHAXDiIoJazYSSuWRByH696fda+qA=",
  "translate": "## ğŸ“ TODO\n\n- â˜ Ø§Ù†ØªØ´Ø§Ø± Ø§Ø³Ú©Ø±ÛŒÙ¾Øªâ€ŒÙ‡Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ ThinkSound\n- â˜ Ù…ØªÙ†â€ŒØ¨Ø§Ø² Ú©Ø±Ø¯Ù† Ø¯ÛŒØªØ§Ø³Øª AudioCoT Ùˆ Ø®Ø· Ù„ÙˆÙ„Ù‡ Ø®ÙˆØ¯Ú©Ø§Ø±\n- â˜ Ø§Ø±Ø§Ø¦Ù‡ Ù…Ø³ØªÙ†Ø¯Ø§Øª Ø¬Ø§Ù…Ø¹ Ùˆ Ù…Ø±Ø¬Ø¹ API\n- â˜ Ø§ÙØ²ÙˆØ¯Ù† Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø§Ø² Ù…ÙˆØ¯Ø§Ù„ÛŒØªÙ€ÛŒâ€ŒÙ‡Ø§ Ùˆ ÙˆØ¸Ø§ÛŒÙ Ù¾Ø§ÛŒÛŒÙ†â€ŒØ¯Ø³ØªÛŒ Ø¨ÛŒØ´ØªØ±\n\n---\n\n## ğŸ“„ Ù…Ø¬ÙˆØ²\n\nØ§ÛŒÙ† Ù¾Ø±ÙˆÚ˜Ù‡ ØªØ­Øª [Ù…Ø¬ÙˆØ² Apache 2.0](LICENSE) Ù…Ù†ØªØ´Ø± Ø´Ø¯Ù‡ Ø§Ø³Øª.\n\n> **ØªÙˆØ¬Ù‡:**  \n> Ú©Ø¯ØŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ùˆ Ø¯ÛŒØªØ§Ø³Øª **ØªÙ†Ù‡Ø§ Ø¨Ø±Ø§ÛŒ Ø§Ù‡Ø¯Ø§Ù Ù¾Ú˜ÙˆÙ‡Ø´ÛŒ Ùˆ Ø¢Ù…ÙˆØ²Ø´ÛŒ** Ù‡Ø³ØªÙ†Ø¯.  \n> **Ø§Ø³ØªÙØ§Ø¯Ù‡ ØªØ¬Ø§Ø±ÛŒ Ù…Ø¬Ø§Ø² Ù†ÛŒØ³Øª.**\n>\n> Ø¨Ø±Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ù…Ø¬ÙˆØ² ØªØ¬Ø§Ø±ÛŒØŒ Ù„Ø·ÙØ§Ù‹ Ø¨Ø§ Ù†ÙˆÛŒØ³Ù†Ø¯Ú¯Ø§Ù† ØªÙ…Ø§Ø³ Ø¨Ú¯ÛŒØ±ÛŒØ¯.\n\n---\n\n## ğŸ“– Ø§Ø³ØªÙ†Ø§Ø¯\n\nØ§Ú¯Ø± ThinkSound Ø¯Ø± Ù¾Ú˜ÙˆÙ‡Ø´ ÛŒØ§ Ú©Ø§Ø± Ø´Ù…Ø§ Ù…ÙÛŒØ¯ Ø¨ÙˆØ¯Ù‡ Ø§Ø³ØªØŒ Ù„Ø·ÙØ§Ù‹ Ø¨Ù‡ Ù…Ù‚Ø§Ù„Ù‡ Ù…Ø§ Ø§Ø±Ø¬Ø§Ø¹ Ø¯Ù‡ÛŒØ¯:\n\n```bibtex\n@misc{liu2025thinksoundchainofthoughtreasoningmultimodal,\n      title={ThinkSound: Chain-of-Thought Reasoning in Multimodal Large Language Models for Audio Generation and Editing}, \n      author={Huadai Liu and Jialei Wang and Kaicheng Luo and Wen Wang and Qian Chen and Zhou Zhao and Wei Xue},\n      year={2025},\n      eprint={2506.21448},\n      archivePrefix={arXiv},\n      primaryClass={eess.AS},\n      url={https://arxiv.org/abs/2506.21448}, \n}\n```\n\n---\n\n## ğŸ“¬ ØªÙ…Ø§Ø³\n\nâœ¨ Ø¯Ø± ØµÙˆØ±Øª Ø¯Ø§Ø´ØªÙ† Ù‡Ø±Ú¯ÙˆÙ†Ù‡ Ø³ÙˆØ§Ù„ ÛŒØ§ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ØŒ [ÛŒÚ© Ø§ÛŒØ´Ùˆ Ø¨Ø§Ø² Ú©Ù†ÛŒØ¯](https://github.com/liuhuadai/ThinkSound/issues) ÛŒØ§ Ø§Ø² Ø·Ø±ÛŒÙ‚ Ø§ÛŒÙ…ÛŒÙ„ ([liuhuadai@zju.edu.cn](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/mailto:liuhuadai@zju.edu.cn)) Ø¨Ø§ Ù…Ø§ Ø¯Ø± Ø§Ø±ØªØ¨Ø§Ø· Ø¨Ø§Ø´ÛŒØ¯!",
  "status": "ok"
}