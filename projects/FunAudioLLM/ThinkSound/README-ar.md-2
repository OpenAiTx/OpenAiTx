{
  "id": 2,
  "origin": "## ğŸ“ TODO\n\n- â˜ Release training scripts for ThinkSound models\n- â˜ Open-source AudioCoT dataset and automated pipeline\n- â˜ Provide detailed documentation and API reference\n- â˜ Add support for additional modalities and downstream tasks\n\n---\n\n## ğŸ“„ License\n\nThis project is released under the [Apache 2.0 License](LICENSE).\n\n> **Note:**  \n> The code, models, and dataset are **for research and educational purposes only**.  \n> **Commercial use is NOT permitted.**\n>\n> For commercial licensing, please contact the authors.\n\n---\n\n## ğŸ“– Citation\n\nIf you find ThinkSound useful in your research or work, please cite our paper:\n\n```bibtex\n@misc{liu2025thinksoundchainofthoughtreasoningmultimodal,\n      title={ThinkSound: Chain-of-Thought Reasoning in Multimodal Large Language Models for Audio Generation and Editing}, \n      author={Huadai Liu and Jialei Wang and Kaicheng Luo and Wen Wang and Qian Chen and Zhou Zhao and Wei Xue},\n      year={2025},\n      eprint={2506.21448},\n      archivePrefix={arXiv},\n      primaryClass={eess.AS},\n      url={https://arxiv.org/abs/2506.21448}, \n}\n```\n\n---\n\n## ğŸ“¬ Contact\n\nâœ¨ Feel free to [open an issue](https://github.com/liuhuadai/ThinkSound/issues) or contact us via email ([liuhuadai@zju.edu.cn](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/mailto:liuhuadai@zju.edu.cn)) if you have any questions or suggestions!\n",
  "origin_sha": "NEFlwyN+fN3dUarHAXDiIoJazYSSuWRByH696fda+qA=",
  "translate": "## ğŸ“ Ø§Ù„Ù…Ù‡Ø§Ù…\n\n- â˜ Ø¥ØµØ¯Ø§Ø± Ù†ØµÙˆØµ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ù„Ù†Ù…Ø§Ø°Ø¬ ThinkSound\n- â˜ Ø¥ØªØ§Ø­Ø© Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª AudioCoT ÙˆØ®Ø· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨ Ø§Ù„Ù…Ø¤ØªÙ…Øª ÙƒÙ…ØµØ¯Ø± Ù…ÙØªÙˆØ­\n- â˜ ØªÙˆÙÙŠØ± ØªÙˆØ«ÙŠÙ‚ Ù…ÙØµÙ„ ÙˆÙ…Ø±Ø¬Ø¹ API\n- â˜ Ø¥Ø¶Ø§ÙØ© Ø¯Ø¹Ù… Ù„Ø£Ù†Ù…Ø§Ø· Ø¨ÙŠØ§Ù†Ø§Øª ÙˆÙ…Ù‡Ø§Ù… Ù†Ù‡Ø§Ø¦ÙŠØ© Ø¥Ø¶Ø§ÙÙŠØ©\n\n---\n\n## ğŸ“„ Ø§Ù„Ø±Ø®ØµØ©\n\nØªÙ… Ø¥ØµØ¯Ø§Ø± Ù‡Ø°Ø§ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ Ø¨Ù…ÙˆØ¬Ø¨ [Ø±Ø®ØµØ© Ø£Ø¨Ø§ØªØ´ÙŠ 2.0](LICENSE).\n\n> **Ù…Ù„Ø§Ø­Ø¸Ø©:**  \n> Ø§Ù„ÙƒÙˆØ¯ ÙˆØ§Ù„Ù†Ù…Ø§Ø°Ø¬ ÙˆÙ…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù‡ÙŠ **Ù„Ø£ØºØ±Ø§Ø¶ Ø§Ù„Ø¨Ø­Ø« ÙˆØ§Ù„ØªØ¹Ù„ÙŠÙ… ÙÙ‚Ø·**.  \n> **Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ØªØ¬Ø§Ø±ÙŠ ØºÙŠØ± Ù…Ø³Ù…ÙˆØ­.**\n>\n> Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØªØ±Ø®ÙŠØµ ØªØ¬Ø§Ø±ÙŠØŒ ÙŠØ±Ø¬Ù‰ Ø§Ù„ØªÙˆØ§ØµÙ„ Ù…Ø¹ Ø§Ù„Ù…Ø¤Ù„ÙÙŠÙ†.\n\n---\n\n## ğŸ“– Ø§Ù„Ø§Ù‚ØªØ¨Ø§Ø³\n\nØ¥Ø°Ø§ ÙˆØ¬Ø¯Øª ThinkSound Ù…ÙÙŠØ¯Ù‹Ø§ ÙÙŠ Ø£Ø¨Ø­Ø§Ø«Ùƒ Ø£Ùˆ Ø¹Ù…Ù„ÙƒØŒ ÙŠØ±Ø¬Ù‰ Ø§Ù„Ø§Ø³ØªØ´Ù‡Ø§Ø¯ Ø¨ÙˆØ±Ù‚ØªÙ†Ø§:\n\n```bibtex\n@misc{liu2025thinksoundchainofthoughtreasoningmultimodal,\n      title={ThinkSound: Chain-of-Thought Reasoning in Multimodal Large Language Models for Audio Generation and Editing}, \n      author={Huadai Liu and Jialei Wang and Kaicheng Luo and Wen Wang and Qian Chen and Zhou Zhao and Wei Xue},\n      year={2025},\n      eprint={2506.21448},\n      archivePrefix={arXiv},\n      primaryClass={eess.AS},\n      url={https://arxiv.org/abs/2506.21448}, \n}\n```\n\n---\n\n## ğŸ“¬ Ø§Ù„ØªÙˆØ§ØµÙ„\n\nâœ¨ Ù„Ø§ ØªØªØ±Ø¯Ø¯ ÙÙŠ [ÙØªØ­ Ù‚Ø¶ÙŠØ©](https://github.com/liuhuadai/ThinkSound/issues) Ø£Ùˆ Ø§Ù„ØªÙˆØ§ØµÙ„ Ù…Ø¹Ù†Ø§ Ø¹Ø¨Ø± Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ ([liuhuadai@zju.edu.cn](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/mailto:liuhuadai@zju.edu.cn)) Ø¥Ø°Ø§ ÙƒØ§Ù† Ù„Ø¯ÙŠÙƒ Ø£ÙŠ Ø£Ø³Ø¦Ù„Ø© Ø£Ùˆ Ø§Ù‚ØªØ±Ø§Ø­Ø§Øª!",
  "status": "ok"
}