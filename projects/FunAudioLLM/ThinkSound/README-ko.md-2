{
  "id": 2,
  "origin": "## ğŸ“ TODO\n\n- â˜ Release training scripts for ThinkSound models\n- â˜ Open-source AudioCoT dataset and automated pipeline\n- â˜ Provide detailed documentation and API reference\n- â˜ Add support for additional modalities and downstream tasks\n\n---\n\n## ğŸ“„ License\n\nThis project is released under the [Apache 2.0 License](LICENSE).\n\n> **Note:**  \n> The code, models, and dataset are **for research and educational purposes only**.  \n> **Commercial use is NOT permitted.**\n>\n> For commercial licensing, please contact the authors.\n\n---\n\n## ğŸ“– Citation\n\nIf you find ThinkSound useful in your research or work, please cite our paper:\n\n```bibtex\n@misc{liu2025thinksoundchainofthoughtreasoningmultimodal,\n      title={ThinkSound: Chain-of-Thought Reasoning in Multimodal Large Language Models for Audio Generation and Editing}, \n      author={Huadai Liu and Jialei Wang and Kaicheng Luo and Wen Wang and Qian Chen and Zhou Zhao and Wei Xue},\n      year={2025},\n      eprint={2506.21448},\n      archivePrefix={arXiv},\n      primaryClass={eess.AS},\n      url={https://arxiv.org/abs/2506.21448}, \n}\n```\n\n---\n\n## ğŸ“¬ Contact\n\nâœ¨ Feel free to [open an issue](https://github.com/liuhuadai/ThinkSound/issues) or contact us via email ([liuhuadai@zju.edu.cn](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/mailto:liuhuadai@zju.edu.cn)) if you have any questions or suggestions!\n",
  "origin_sha": "NEFlwyN+fN3dUarHAXDiIoJazYSSuWRByH696fda+qA=",
  "translate": "## ğŸ“ TODO\n\n- â˜ ThinkSound ëª¨ë¸ìš© í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ ê³µê°œ\n- â˜ AudioCoT ë°ì´í„°ì…‹ ë° ìë™í™” íŒŒì´í”„ë¼ì¸ ì˜¤í”ˆì†ŒìŠ¤í™”\n- â˜ ìƒì„¸í•œ ë¬¸ì„œ ë° API ë ˆí¼ëŸ°ìŠ¤ ì œê³µ\n- â˜ ì¶”ê°€ ëª¨ë‹¬ë¦¬í‹° ë° ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ íƒœìŠ¤í¬ ì§€ì› ì¶”ê°€\n\n---\n\n## ğŸ“„ ë¼ì´ì„ ìŠ¤\n\nì´ í”„ë¡œì íŠ¸ëŠ” [Apache 2.0 ë¼ì´ì„ ìŠ¤](LICENSE) í•˜ì— ê³µê°œë©ë‹ˆë‹¤.\n\n> **ì°¸ê³ :**  \n> ì½”ë“œ, ëª¨ë¸, ë°ì´í„°ì…‹ì€ **ì—°êµ¬ ë° êµìœ¡ ëª©ì ìœ¼ë¡œë§Œ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.**  \n> **ìƒì—…ì  ì‚¬ìš©ì€ í—ˆê°€ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.**\n>\n> ìƒì—…ì  ë¼ì´ì„ ìŠ¤ê°€ í•„ìš”í•˜ì‹  ê²½ìš°, ì €ìì—ê²Œ ë¬¸ì˜í•´ ì£¼ì„¸ìš”.\n\n---\n\n## ğŸ“– ì¸ìš©\n\nThinkSoundê°€ ì—°êµ¬ë‚˜ ì‘ì—…ì— ìœ ìš©í•˜ë‹¤ë©´, ì•„ë˜ì˜ ë…¼ë¬¸ì„ ì¸ìš©í•´ ì£¼ì„¸ìš”:\n\n```bibtex\n@misc{liu2025thinksoundchainofthoughtreasoningmultimodal,\n      title={ThinkSound: Chain-of-Thought Reasoning in Multimodal Large Language Models for Audio Generation and Editing}, \n      author={Huadai Liu and Jialei Wang and Kaicheng Luo and Wen Wang and Qian Chen and Zhou Zhao and Wei Xue},\n      year={2025},\n      eprint={2506.21448},\n      archivePrefix={arXiv},\n      primaryClass={eess.AS},\n      url={https://arxiv.org/abs/2506.21448}, \n}\n```\n\n---\n\n## ğŸ“¬ ì—°ë½ì²˜\n\nâœ¨ ê¶ê¸ˆí•œ ì ì´ë‚˜ ì œì•ˆì‚¬í•­ì´ ìˆìœ¼ì‹œë©´ [ì´ìŠˆë¥¼ ë“±ë¡](https://github.com/liuhuadai/ThinkSound/issues)í•˜ì‹œê±°ë‚˜ ì´ë©”ì¼([liuhuadai@zju.edu.cn](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/mailto:liuhuadai@zju.edu.cn))ë¡œ ì—°ë½í•´ ì£¼ì„¸ìš”!",
  "status": "ok"
}