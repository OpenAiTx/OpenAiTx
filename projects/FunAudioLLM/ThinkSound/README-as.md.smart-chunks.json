[
  {
    "Id": 1,
    "Content": "<h1 align=\"center\">ThinkSound</h1>\n\n<p align=\"center\">\n  üåê\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=en\">English</a> |\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=zh-CN\">ÁÆÄ‰Ωì‰∏≠Êñá</a> |\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=zh-TW\">ÁπÅÈ´î‰∏≠Êñá</a> |\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=es\">Espa√±ol</a> |\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=fr\">Fran√ßais</a> |\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=ja\">Êó•Êú¨Ë™û</a>\n  \n</p>\n<p align=\"center\">\n  <img src=\"https://img.shields.io/badge/NeurIPS 2025-Main Conference-blue.svg\" alt=\"NeurIPS 2025\"/>\n<p align=\"center\">\n  <a href=\"https://arxiv.org/pdf/2506.21448\">\n    <img src=\"https://img.shields.io/badge/arXiv-2506.21448-b31b1b.svg\" alt=\"arXiv\"/>\n  </a>\n  &nbsp;\n  <a href=\"https://thinksound-project.github.io/\">\n    <img src=\"https://img.shields.io/badge/Online%20Demo-üåê-blue\" alt=\"Online Demo\"/>\n  </a>\n  &nbsp;\n  <a href=\"https://huggingface.co/spaces/FunAudioLLM/ThinkSound\">\n    <img src=\"https://img.shields.io/badge/HuggingFace-Spaces-orange?logo=huggingface\" alt=\"Hugging Face\"/>\n  </a>\n  &nbsp;\n  <a href=\"https://modelscope.cn/studios/iic/ThinkSound\">\n    <img src=\"https://img.shields.io/badge/ModelScope-Âú®Á∫ø‰ΩìÈ™å-green\" alt=\"ModelScope\"/>\n  </a>\n</p>\n\n<p align=\"center\">\n  If you find this project useful,<br>\n  a star ‚≠ê on GitHub would be greatly appreciated!\n</p>\n\n---\n\n**ThinkSound** is a unified Any2Audio generation framework with flow matching guided by Chain-of-Thought (CoT) reasoning.",
    "ContentSha": "3764VshEOMedejxsV+uo8k5R5Emk0MLuYfIOX8JadcY=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "<h1 align=\"center\">ThinkSound</h1>\n\n<p align=\"center\">\n  üåê\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=en\">English</a> |\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=zh-CN\">ÁÆÄ‰Ωì‰∏≠Êñá</a> |\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=zh-TW\">ÁπÅÈ´î‰∏≠Êñá</a> |\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=es\">Espa√±ol</a> |\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=fr\">Fran√ßais</a> |\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=ja\">Êó•Êú¨Ë™û</a>\n  \n</p>\n<p align=\"center\">\n  <img src=\"https://img.shields.io/badge/NeurIPS 2025-Main Conference-blue.svg\" alt=\"NeurIPS 2025\"/>\n<p align=\"center\">\n  <a href=\"https://arxiv.org/pdf/2506.21448\">\n    <img src=\"https://img.shields.io/badge/arXiv-2506.21448-b31b1b.svg\" alt=\"arXiv\"/>\n  </a>\n  &nbsp;\n  <a href=\"https://thinksound-project.github.io/\">\n    <img src=\"https://img.shields.io/badge/Online%20Demo-üåê-blue\" alt=\"Online Demo\"/>\n  </a>\n  &nbsp;\n  <a href=\"https://huggingface.co/spaces/FunAudioLLM/ThinkSound\">\n    <img src=\"https://img.shields.io/badge/HuggingFace-Spaces-orange?logo=huggingface\" alt=\"Hugging Face\"/>\n  </a>\n  &nbsp;\n  <a href=\"https://modelscope.cn/studios/iic/ThinkSound\">\n    <img src=\"https://img.shields.io/badge/ModelScope-Âú®Á∫ø‰ΩìÈ™å-green\" alt=\"ModelScope\"/>\n  </a>\n</p>\n\n<p align=\"center\">\n  ‡¶Ø‡¶¶‡¶ø ‡¶Ü‡¶™‡ßÅ‡¶®‡¶ø ‡¶è‡¶á ‡¶™‡ßç‡ß∞‡¶ï‡¶≤‡ßç‡¶™‡¶ü‡ßã ‡¶â‡¶™‡¶ï‡¶æ‡ß∞‡ßÄ ‡¶¨‡ßÅ‡¶≤‡¶ø ‡¶≠‡¶æ‡¶¨‡ßá‡¶®,<br>\n  GitHub-‡¶§ ‡¶è‡¶ü‡¶æ ‡¶∑‡ßç‡¶ü‡¶æ‡ß∞ ‚≠ê ‡¶¶‡¶ø‡¶Ø‡¶º‡¶æ ‡¶Ö‡¶§‡¶ø ‡¶Æ‡ßÇ‡¶≤‡ßç‡¶Ø‡¶¨‡¶æ‡¶® ‡¶π'‡¶¨!\n</p>\n\n---\n\n**ThinkSound** ‡¶π‡ßà‡¶õ‡ßá ‡¶è‡¶ü‡¶æ ‡¶è‡¶ï‡¶§‡ßç‡ß∞ Any2Audio ‡¶â‡ßé‡¶™‡¶æ‡¶¶‡¶® ‡¶´‡ßç‡ß∞‡ßá‡¶Æ‡ß±‡ß∞‡ßç‡¶ï ‡¶Ø‡¶ø Flow Matching-Chain-of-Thought (CoT) reasoning-‡¶è‡ß∞‡ßá ‡¶™‡¶• ‡¶™‡ß∞‡¶ø‡¶ö‡¶æ‡¶≤‡¶®‡¶æ ‡¶ï‡ß∞‡ßá‡•§",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 2,
    "Content": "\nPyTorch implementation for multimodal audio generation and editing: generate or edit audio from video, text, and audio, powered by step-by-step reasoning from Multimodal Large Language Models (MLLMs).\n\n![Teaser](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig1_teaser.png)\n---\n\n## üì∞ News\n- **2025.11.25** &nbsp; üî•[Online PrismAudio Demo](http://prismaudio-project.github.io/) is live - try it now!\n- **2025.11.25** &nbsp; üî•[PrismAudio paper](https://arxiv.org/pdf/2511.18833) released on arXiv, the first multi-dimensional CoT-RL framework for Video-to-Audio Generation!\n- **2025.09.19** &nbsp; üéâ ThinkSound has been accepted to the **NeurIPS 2025 Main Conference**!\n- **2025.09.01** &nbsp; Our AudioCoT dataset is now open-sourced and available on [Hugging Face](https://huggingface.co/datasets/liuhuadai/AudioCoT)!\n- **2025.07.17** &nbsp; üß† Finetuning enabled: training and finetuning code is now publicly available, along with clear usage instructions to help you customize and extend ThinkSound with your own data.\n- **2025.07.15** &nbsp; üì¶ Simplified installation and usability: dependencies on PyPI for easy cross-platform setup; Windows `.bat` scripts automate environment creation and script running.\n- **2025.07.08** &nbsp;¬† üîß Major update: model lightweighted and optimized memory and GPU usage, now supports high-throughput audio generation at scale!\n- **2025.07.01** &nbsp; Online demo on [Hugging Face Spaces](https://huggingface.co/spaces/FunAudioLLM/ThinkSound) and [ModelScope](https://modelscope.cn/studios/iic/ThinkSound) for interactive experience!\n- **2025.07.01** &nbsp; Released inference scripts and web interface; \n- **2025.06** &nbsp; [ThinkSound paper](https://arxiv.org/pdf/2506.21448) released on arXiv!\n- **2025.06** &nbsp; [Online Demo](http://thinksound-project.github.io/) is live - try it now!\n\n---\n\n\n## üöÄ Features\n\n- **Any2Audio**: Generate audio from arbitrary modalities ‚Äî video, text, audio, or their combinations.\n- **Video-to-Audio SOTA**: Achieves state-of-the-art results on multiple V2A benchmarks.\n- **CoT-Driven Reasoning**: Chain-of-Thought reasoning for compositional and controllable audio generation via MLLMs.\n- **Interactive Object-centric Editing**: Refine or edit specific sound events by clicking on visual objects or using text instructions.\n- **Unified Framework**: One foundation model supports generation, editing, and interactive workflow.\n\n---\n\n## ‚ú® Method Overview\n\nThinkSound decomposes audio generation and editing into three interactive stages, all guided by MLLM-based Chain-of-Thought (CoT) reasoning:\n\n1. **Foley Generation:** Generate foundational, semantically and temporally aligned soundscapes from video.\n2. **Object-Centric Refinement:** Refine or add sounds for user-specified objects via clicks or regions in the video.\n3. **Targeted Audio Editing:** Modify generated audio using high-level natural language instructions.\n",
    "ContentSha": "Vp81xeUGr9WCESp62x1lkoIptJHl0dM1R8kleL4V10c=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "\n‡¶Æ‡¶æ‡¶≤‡ßç‡¶ü‡¶ø‡¶Æ'‡¶°‡ßá‡¶≤ ‡¶Ö‡¶°‡¶ø‡¶Ö' ‡¶ú‡ßá‡¶®‡¶æ‡ß∞‡ßá‡¶ö‡¶® ‡¶Ü‡ß∞‡ßÅ ‡¶∏‡¶Æ‡ßç‡¶™‡¶æ‡¶¶‡¶®‡¶æ‡ß∞ ‡¶¨‡¶æ‡¶¨‡ßá PyTorch ‡ß∞‡ßÇ‡¶™‡¶æ‡¶Ø‡¶º‡¶£: ‡¶≠‡¶ø‡¶°‡¶ø‡¶Ö', ‡¶™‡¶æ‡¶†‡ßç‡¶Ø, ‡¶Ü‡ß∞‡ßÅ ‡¶Ö‡¶°‡¶ø‡¶Ö'‡ß∞ ‡¶™‡ß∞‡¶æ ‡¶Ö‡¶°‡¶ø‡¶Ö' ‡¶â‡¶§‡ßç‡¶™‡¶®‡ßç‡¶® ‡¶ï‡ß∞‡¶ï ‡¶¨‡¶æ ‡¶∏‡¶Æ‡ßç‡¶™‡¶æ‡¶¶‡¶®‡¶æ ‡¶ï‡ß∞‡¶ï, Multimodal Large Language Models (MLLMs) ‡ß∞ ‡¶ß‡¶æ‡¶™-‡¶ß‡¶æ‡¶™‡ßá ‡¶Ø‡ßÅ‡¶ï‡ßç‡¶§‡¶ø‡¶¨‡¶æ‡¶¶ ‡¶¶‡ßç‡¶¨‡¶æ‡ß∞‡¶æ ‡¶∂‡¶ï‡ßç‡¶§‡¶ø‡¶∂‡¶æ‡¶≤‡ßÄ‡•§\n\n![Teaser](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig1_teaser.png)\n---\n\n## üì∞ ‡¶¨‡¶æ‡¶§‡ß∞‡¶ø\n- **‡ß®‡ß¶‡ß®‡ß´.‡ßß‡ßß.‡ß®‡ß´** &nbsp; üî•[‡¶Ö‡¶®‡¶≤‡¶æ‡¶á‡¶® PrismAudio ‡¶°‡ßá‡¶Æ‡ßã](http://prismaudio-project.github.io/) ‡¶â‡¶™‡¶≤‡¶¨‡ßç‡¶ß - ‡¶è‡¶§‡¶ø‡¶Ø‡¶º‡¶æ‡¶á ‡¶ö‡ßá‡¶∑‡ßç‡¶ü‡¶æ ‡¶ï‡ß∞‡¶ï!\n- **‡ß®‡ß¶‡ß®‡ß´.‡ßß‡ßß.‡ß®‡ß´** &nbsp; üî•[PrismAudio ‡¶ï‡¶æ‡¶ó‡¶ú](https://arxiv.org/pdf/2511.18833) arXiv-‡¶§ ‡¶Æ‡ßÅ‡¶ï‡ßç‡¶§‡¶ø, Video-to-Audio Generation-‡ß∞ ‡¶¨‡¶æ‡¶¨‡ßá ‡¶™‡ßç‡ß∞‡¶•‡¶Æ ‡¶¨‡¶π‡ßÅ-‡¶Æ‡¶æ‡¶§‡ßç‡ß∞‡¶ø‡¶ï CoT-RL ‡¶´‡ßç‡ß∞‡ßá‡¶Æ‡ß±‡ß∞‡ßç‡¶ï!\n- **‡ß®‡ß¶‡ß®‡ß´.‡ß¶‡ßØ.‡ßß‡ßØ** &nbsp; üéâ ThinkSound **NeurIPS 2025 ‡¶Æ‡ßÅ‡¶ñ‡ßç‡¶Ø ‡¶∏‡¶Æ‡ßç‡¶Æ‡ßá‡¶≤‡¶®**-‡¶§ ‡¶ó‡ßç‡ß∞‡¶π‡¶£ ‡¶ï‡ß∞‡¶æ ‡¶π‡ßà‡¶õ‡ßá!\n- **‡ß®‡ß¶‡ß®‡ß´.‡ß¶‡ßØ.‡ß¶‡ßß** &nbsp; ‡¶Ü‡¶Æ‡¶æ‡ß∞ AudioCoT ‡¶°‡ßá‡¶ü‡¶æ‡¶õ‡ßá‡¶ü ‡¶è‡¶§‡¶ø‡¶Ø‡¶º‡¶æ ‡¶Æ‡ßÅ‡¶ï‡ßç‡¶§-‡¶â‡ßé‡¶∏ ‡¶Ü‡ß∞‡ßÅ [Hugging Face](https://huggingface.co/datasets/liuhuadai/AudioCoT)-‡¶§ ‡¶â‡¶™‡¶≤‡¶¨‡ßç‡¶ß!\n- **‡ß®‡ß¶‡ß®‡ß´.‡ß¶‡ß≠.‡ßß‡ß≠** &nbsp; üß† ‡¶´‡¶æ‡¶á‡¶®‡¶ü‡¶ø‡¶â‡¶®‡¶ø‡¶Ç ‡¶∏‡¶ï‡ßç‡ß∞‡¶ø‡¶Ø‡¶º: ‡¶™‡ßç‡ß∞‡¶∂‡¶ø‡¶ï‡ßç‡¶∑‡¶£ ‡¶Ü‡ß∞‡ßÅ ‡¶´‡¶æ‡¶á‡¶®‡¶ü‡¶ø‡¶â‡¶®‡¶ø‡¶Ç ‡¶ï‡ßã‡¶° ‡¶è‡¶§‡¶ø‡¶Ø‡¶º‡¶æ ‡¶™‡¶æ‡¶¨‡¶≤‡¶ø‡¶ï, ‡¶∏‡ßç‡¶™‡¶∑‡ßç‡¶ü ‡¶¨‡ßç‡¶Ø‡ß±‡¶π‡¶æ‡ß∞ ‡¶®‡¶ø‡ß∞‡ßç‡¶¶‡ßá‡¶∂‡¶®‡¶æ ‡¶∏‡¶π ThinkSound ‡¶Ü‡¶™‡ßã‡¶®‡¶æ‡ß∞ ‡¶®‡¶ø‡¶ú‡ß∞ ‡¶°‡ßá‡¶ü‡¶æ‡ß∞‡ßá ‡¶ï‡¶æ‡¶∑‡ßç‡¶ü‡¶Æ‡¶æ‡¶á‡¶ú ‡¶Ü‡ß∞‡ßÅ ‡¶¨‡¶ø‡¶∏‡ßç‡¶§‡ßÉ‡¶§ ‡¶ï‡ß∞‡¶ø‡¶¨‡¶≤‡ßà‡•§\n- **‡ß®‡ß¶‡ß®‡ß´.‡ß¶‡ß≠.‡ßß‡ß´** &nbsp; üì¶ ‡¶∏‡¶π‡¶ú ‡¶á‡¶®‡¶∏‡ßç‡¶ü‡¶≤‡ßá‡¶∂‡ßç‡¶¨‡¶® ‡¶Ü‡ß∞‡ßÅ ‡¶¨‡ßç‡¶Ø‡ß±‡¶π‡¶æ‡ß∞‡¶Ø‡ßã‡¶ó‡ßç‡¶Ø‡¶§‡¶æ: PyPI-‡ß∞ ‡¶ì‡¶™‡ß∞‡¶§ ‡¶®‡¶ø‡¶∞‡ßç‡¶≠‡¶∞‡¶§‡¶æ‡¶¨‡ßã‡ß∞‡ßá ‡¶∏‡¶π‡¶ú cross-platform ‡¶õ‡ßá‡¶ü‡¶Ü‡¶™; Windows `.bat` ‡¶∏‡ßç‡¶ï‡ßç‡ß∞‡¶ø‡¶™‡ßç‡¶ü‡ßá ‡¶™‡ß∞‡¶ø‡ß±‡ßá‡¶∂ ‡¶∏‡ßÉ‡¶∑‡ßç‡¶ü‡¶ø ‡¶Ü‡ß∞‡ßÅ ‡¶∏‡ßç‡¶ï‡ßç‡ß∞‡¶ø‡¶™‡ßç‡¶ü ‡¶ö‡¶≤‡ßã‡ß±‡¶æ ‡¶∏‡ßç‡¶¨‡¶Ø‡¶º‡¶Ç‡¶ï‡ßç‡ß∞‡¶ø‡¶Ø‡¶º ‡¶ï‡ß∞‡ßá‡•§\n- **‡ß®‡ß¶‡ß®‡ß´.‡ß¶‡ß≠.‡ß¶‡ßÆ** &nbsp;¬† üîß ‡¶°‡¶æ‡¶ô‡ß∞ ‡¶Ü‡¶™‡¶°‡ßá‡¶ü: ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶π‡¶æ‡¶≤‡¶ï‡¶æ ‡¶Ü‡ß∞‡ßÅ ‡¶Æ‡ßá‡¶Æ'‡ß∞‡¶ø ‡¶Ü‡ß∞‡ßÅ GPU ‡¶¨‡ßç‡¶Ø‡ß±‡¶π‡¶æ‡ß∞ ‡¶Ö‡¶®‡ßÅ‡¶ï‡ßÇ‡¶≤‡¶ø‡¶§, ‡¶è‡¶§‡¶ø‡¶Ø‡¶º‡¶æ ‡¶â‡¶ö‡ßç‡¶ö-‡¶•‡ßç‡ß∞‡ßÅ‡¶™‡ßÅ‡¶ü ‡¶Ö‡¶°‡¶ø‡¶Ö' ‡¶ú‡ßá‡¶®‡¶æ‡ß∞‡ßá‡¶ö‡¶® ‡¶∏‡ßç‡¶ï‡ßá‡¶≤‡¶§ ‡¶∏‡¶Æ‡ß∞‡ßç‡¶•‡¶ø‡¶§!\n- **‡ß®‡ß¶‡ß®‡ß´.‡ß¶‡ß≠.‡ß¶‡ßß** &nbsp; ‡¶Ö‡¶®‡¶≤‡¶æ‡¶á‡¶® ‡¶°‡ßá‡¶Æ‡ßã [Hugging Face Spaces](https://huggingface.co/spaces/FunAudioLLM/ThinkSound) ‡¶Ü‡ß∞‡ßÅ [ModelScope](https://modelscope.cn/studios/iic/ThinkSound)-‡¶§ ‡¶á‡¶®‡ßç‡¶ü‡¶æ‡ß∞‡ßá‡¶ï‡ßç‡¶ü‡¶ø‡¶≠ ‡¶Ö‡¶≠‡¶ø‡¶ú‡ßç‡¶û‡¶§‡¶æ‡ß∞ ‡¶¨‡¶æ‡¶¨‡ßá!\n- **‡ß®‡ß¶‡ß®‡ß´.‡ß¶‡ß≠.‡ß¶‡ßß** &nbsp; ‡¶á‡¶®‡¶´‡¶æ‡ß∞‡ßá‡¶®‡ßç‡¶∏ ‡¶∏‡ßç‡¶ï‡ßç‡ß∞‡¶ø‡¶™‡ßç‡¶ü ‡¶Ü‡ß∞‡ßÅ ‡ß±‡ßá‡¶¨ ‡¶á‡¶®‡ßç‡¶ü‡¶æ‡ß∞‡¶´‡ßá‡¶ö ‡¶Æ‡ßÅ‡¶ï‡ßç‡¶§‡¶ø; \n- **‡ß®‡ß¶‡ß®‡ß´.‡ß¶‡ß¨** &nbsp; [ThinkSound ‡¶ï‡¶æ‡¶ó‡¶ú](https://arxiv.org/pdf/2506.21448) arXiv-‡¶§ ‡¶Æ‡ßÅ‡¶ï‡ßç‡¶§‡¶ø!\n- **‡ß®‡ß¶‡ß®‡ß´.‡ß¶‡ß¨** &nbsp; [‡¶Ö‡¶®‡¶≤‡¶æ‡¶á‡¶® ‡¶°‡ßá‡¶Æ‡ßã](http://thinksound-project.github.io/) ‡¶â‡¶™‡¶≤‡¶¨‡ßç‡¶ß - ‡¶è‡¶§‡¶ø‡¶Ø‡¶º‡¶æ‡¶á ‡¶ö‡ßá‡¶∑‡ßç‡¶ü‡¶æ ‡¶ï‡ß∞‡¶ï!\n\n---\n\n\n## üöÄ ‡¶¨‡ßà‡¶∂‡¶ø‡¶∑‡ßç‡¶ü‡ßç‡¶Ø‡¶∏‡¶Æ‡ßÇ‡¶π\n\n- **Any2Audio**: ‡¶Ø‡¶ø‡¶ï‡ßã‡¶®‡ßã ‡¶Æ‡¶°‡¶æ‡¶≤‡¶ø‡¶ü‡¶ø‡ß∞ ‡¶™‡ß∞‡¶æ ‡¶Ö‡¶°‡¶ø‡¶Ö' ‡¶â‡¶§‡ßç‡¶™‡¶®‡ßç‡¶® ‡¶ï‡ß∞‡¶ï ‚Äî ‡¶≠‡¶ø‡¶°‡¶ø‡¶Ö', ‡¶™‡¶æ‡¶†‡ßç‡¶Ø, ‡¶Ö‡¶°‡¶ø‡¶Ö', ‡¶¨‡¶æ ‡¶∏‡¶ø‡¶ô‡ßç‡¶ó‡¶§‡¶ø‡•§\n- **Video-to-Audio SOTA**: ‡¶¨‡¶π‡ßÅ‡¶¨‡¶ø‡¶ß V2A ‡¶¨‡ßá‡¶û‡ßç‡¶ö‡¶Æ‡¶æ‡ß∞‡ßç‡¶ï‡¶§ state-of-the-art ‡¶´‡¶≤‡¶æ‡¶´‡¶≤ ‡¶≤‡¶æ‡¶≠ ‡¶ï‡ß∞‡ßá‡•§\n- **CoT-Driven Reasoning**: MLLMs-‡ß∞ ‡¶Æ‡¶æ‡¶ß‡ßç‡¶Ø‡¶Æ‡ßá ‡¶∏‡¶Ç‡¶Ø‡ßã‡¶ú‡¶ø‡¶§ ‡¶Ü‡ß∞‡ßÅ ‡¶®‡¶ø‡¶Ø‡¶º‡¶®‡ßç‡¶§‡ßç‡ß∞‡¶£‡¶Ø‡ßã‡¶ó‡ßç‡¶Ø ‡¶Ö‡¶°‡¶ø‡¶Ö' ‡¶ú‡ßá‡¶®‡¶æ‡ß∞‡ßá‡¶ö‡¶®‡ß∞ ‡¶¨‡¶æ‡¶¨‡ßá Chain-of-Thought ‡¶Ø‡ßÅ‡¶ï‡ßç‡¶§‡¶ø‡¶¨‡¶æ‡¶¶‡•§\n- **Interactive Object-centric Editing**: ‡¶¶‡ßÉ‡¶∂‡ßç‡¶Ø‡¶Æ‡¶æ‡¶® ‡¶Ö‡¶¨‡¶ú‡ßá‡¶ï‡ßç‡¶ü‡¶§ ‡¶ï‡ßç‡¶≤‡¶ø‡¶ï ‡¶¨‡¶æ ‡¶™‡¶æ‡¶†‡ßç‡¶Ø ‡¶®‡¶ø‡ß∞‡ßç‡¶¶‡ßá‡¶∂‡¶®‡¶æ ‡¶¨‡ßç‡¶Ø‡ß±‡¶π‡¶æ‡ß∞ ‡¶ï‡ß∞‡¶ø ‡¶®‡¶ø‡ß∞‡ßç‡¶¶‡¶ø‡¶∑‡ßç‡¶ü ‡¶∂‡¶¨‡ßç‡¶¶ ‡¶ò‡¶ü‡¶®‡¶æ‡¶∏‡¶Æ‡ßÇ‡¶π ‡¶∏‡¶Ç‡¶∂‡ßã‡¶ß‡¶® ‡¶¨‡¶æ ‡¶∏‡¶Æ‡ßç‡¶™‡¶æ‡¶¶‡¶®‡¶æ ‡¶ï‡ß∞‡¶ï‡•§\n- **Unified Framework**: ‡¶è‡¶ü‡¶æ ‡¶Æ‡ßå‡¶≤‡¶ø‡¶ï ‡¶Æ‡¶°‡ßá‡¶≤‡ßá ‡¶ú‡ßá‡¶®‡¶æ‡ß∞‡ßá‡¶ö‡¶®, ‡¶∏‡¶Æ‡ßç‡¶™‡¶æ‡¶¶‡¶®‡¶æ, ‡¶Ü‡ß∞‡ßÅ ‡¶á‡¶®‡ßç‡¶ü‡¶æ‡ß∞‡ßá‡¶ï‡ßç‡¶ü‡¶ø‡¶≠ ‡ß±‡ß∞‡ßç‡¶ï‡¶´‡ßç‡¶≤‡ßã ‡¶∏‡¶Æ‡ß∞‡ßç‡¶•‡¶® ‡¶ï‡ß∞‡ßá‡•§\n\n---\n\n## ‚ú® ‡¶™‡¶¶‡ßç‡¶ß‡¶§‡¶ø‡ß∞ ‡¶∏‡¶Ç‡¶ï‡ßç‡¶∑‡¶ø‡¶™‡ßç‡¶§‡¶∏‡¶æ‡ß∞\n\nThinkSound-‡¶è ‡¶Ö‡¶°‡¶ø‡¶Ö' ‡¶ú‡ßá‡¶®‡¶æ‡ß∞‡ßá‡¶ö‡¶® ‡¶Ü‡ß∞‡ßÅ ‡¶∏‡¶Æ‡ßç‡¶™‡¶æ‡¶¶‡¶®‡¶æ‡¶ï ‡¶§‡¶ø‡¶®‡¶ø‡¶ü‡¶æ ‡¶á‡¶®‡ßç‡¶ü‡¶æ‡ß∞‡ßá‡¶ï‡ßç‡¶ü‡¶ø‡¶≠ ‡¶™‡ß∞‡ßç‡¶Ø‡¶æ‡¶Ø‡¶º‡¶§ ‡¶¨‡¶ø‡¶≠‡¶ï‡ßç‡¶§ ‡¶ï‡ß∞‡ßá, ‡¶∏‡¶ï‡¶≤‡ßã MLLM-‡¶≠‡¶ø‡¶§‡ßç‡¶§‡¶ø‡¶ï Chain-of-Thought (CoT) ‡¶Ø‡ßÅ‡¶ï‡ßç‡¶§‡¶ø‡¶¨‡¶æ‡¶¶ ‡¶¶‡ßç‡¶¨‡¶æ‡ß∞‡¶æ ‡¶®‡¶ø‡ß∞‡ßç‡¶¶‡ßá‡¶∂‡¶ø‡¶§:\n\n1. **Foley Generation:** ‡¶≠‡¶ø‡¶°‡¶ø‡¶Ö'-‡ß∞ ‡¶™‡ß∞‡¶æ ‡¶Æ‡ßå‡¶≤‡¶ø‡¶ï, ‡¶Ö‡ß∞‡ßç‡¶•‡¶¨‡¶π ‡¶Ü‡ß∞‡ßÅ ‡¶ï‡¶æ‡¶≤‡¶æ‡¶®‡ßÅ‡¶ï‡ßç‡ß∞‡¶Æ‡¶ø‡¶ï‡¶≠‡¶æ‡ß±‡ßá ‡¶Æ‡¶ø‡¶≤‡¶ø‡¶§ ‡¶∂‡¶¨‡ßç‡¶¶ ‡¶∏‡ßÉ‡¶∑‡ßç‡¶ü‡¶ø ‡¶ï‡ß∞‡¶ï‡•§\n2. **Object-Centric Refinement:** ‡¶≠‡¶ø‡¶°‡¶ø‡¶Ö'‡¶§ ‡¶ï‡ßç‡¶≤‡¶ø‡¶ï ‡¶¨‡¶æ ‡¶Ö‡¶û‡ßç‡¶ö‡¶≤‡¶∏‡¶Æ‡ßÇ‡¶π‡ß∞ ‡¶Æ‡¶æ‡¶ß‡ßç‡¶Ø‡¶Æ‡ßá ‡¶¨‡ßç‡¶Ø‡ß±‡¶π‡¶æ‡ß∞‡¶ï‡¶æ‡ß∞‡ßÄ ‡¶®‡¶ø‡ß∞‡ßç‡¶¶‡¶ø‡¶∑‡ßç‡¶ü ‡¶Ö‡¶¨‡¶ú‡ßá‡¶ï‡ßç‡¶ü‡ß∞ ‡¶¨‡¶æ‡¶¨‡ßá ‡¶∂‡¶¨‡ßç‡¶¶ ‡¶∏‡¶Ç‡¶∂‡ßã‡¶ß‡¶® ‡¶¨‡¶æ ‡¶Ø‡ßã‡¶ó ‡¶ï‡ß∞‡¶ï‡•§\n3. **Targeted Audio Editing:** ‡¶â‡¶ö‡ßç‡¶ö-‡¶∏‡ßç‡¶§‡ß∞‡ß∞ ‡¶™‡ßç‡ß∞‡¶æ‡¶ï‡ßÉ‡¶§‡¶ø‡¶ï ‡¶≠‡¶æ‡¶∑‡¶æ ‡¶®‡¶ø‡ß∞‡ßç‡¶¶‡ßá‡¶∂‡¶®‡¶æ ‡¶¨‡ßç‡¶Ø‡ß±‡¶π‡¶æ‡ß∞ ‡¶ï‡ß∞‡¶ø ‡¶â‡¶§‡ßç‡¶™‡¶®‡ßç‡¶® ‡¶Ö‡¶°‡¶ø‡¶Ö' ‡¶∏‡¶Æ‡ßç‡¶™‡¶æ‡¶¶‡¶®‡¶æ ‡¶ï‡ß∞‡¶ï‡•§\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 2,
        "rowsha": "eexREJOMCITdo96Iwg4N4PQqu1ux/UwupfjVRj0l/L8=",
        "originContent": "PyTorch implementation for multimodal audio generation and editing: generate or edit audio from video, text, and audio, powered by step-by-step reasoning from Multimodal Large Language Models (MLLMs).",
        "translatedContent": "‡¶Æ‡¶æ‡¶≤‡ßç‡¶ü‡¶ø‡¶Æ'‡¶°‡ßá‡¶≤ ‡¶Ö‡¶°‡¶ø‡¶Ö' ‡¶ú‡ßá‡¶®‡¶æ‡ß∞‡ßá‡¶ö‡¶® ‡¶Ü‡ß∞‡ßÅ ‡¶∏‡¶Æ‡ßç‡¶™‡¶æ‡¶¶‡¶®‡¶æ‡ß∞ ‡¶¨‡¶æ‡¶¨‡ßá PyTorch ‡ß∞‡ßÇ‡¶™‡¶æ‡¶Ø‡¶º‡¶£: ‡¶≠‡¶ø‡¶°‡¶ø‡¶Ö', ‡¶™‡¶æ‡¶†‡ßç‡¶Ø, ‡¶Ü‡ß∞‡ßÅ ‡¶Ö‡¶°‡¶ø‡¶Ö'‡ß∞ ‡¶™‡ß∞‡¶æ ‡¶Ö‡¶°‡¶ø‡¶Ö' ‡¶â‡¶§‡ßç‡¶™‡¶®‡ßç‡¶® ‡¶ï‡ß∞‡¶ï ‡¶¨‡¶æ ‡¶∏‡¶Æ‡ßç‡¶™‡¶æ‡¶¶‡¶®‡¶æ ‡¶ï‡ß∞‡¶ï, Multimodal Large Language Models (MLLMs) ‡ß∞ ‡¶ß‡¶æ‡¶™-‡¶ß‡¶æ‡¶™‡ßá ‡¶Ø‡ßÅ‡¶ï‡ßç‡¶§‡¶ø‡¶¨‡¶æ‡¶¶ ‡¶¶‡ßç‡¶¨‡¶æ‡ß∞‡¶æ ‡¶∂‡¶ï‡ßç‡¶§‡¶ø‡¶∂‡¶æ‡¶≤‡ßÄ‡•§"
      },
      {
        "row": 3,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 4,
        "rowsha": "+7Cx1rdpWiIOeWRA/RM6HsKf7pNA3hHsQk2Bpadt4II=",
        "originContent": "![Teaser](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig1_teaser.png)",
        "translatedContent": "![Teaser](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig1_teaser.png)"
      },
      {
        "row": 5,
        "rowsha": "yz+R1U7uMOU+NbK5mQX3Dxae1Un9eJCdPawt78ntjTs=",
        "originContent": "---",
        "translatedContent": "---"
      },
      {
        "row": 6,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 7,
        "rowsha": "0YeCyxpcm7/4RDbaM+OQoI8YfqEHQzDkpGW15VZdi1U=",
        "originContent": "## üì∞ News",
        "translatedContent": "## üì∞ ‡¶¨‡¶æ‡¶§‡ß∞‡¶ø"
      },
      {
        "row": 8,
        "rowsha": "EeDKxV0PYB9iw6GxOqwnsP3C385ykbqk8PtEVoVhAcc=",
        "originContent": "- **2025.11.25** &nbsp; üî•[Online PrismAudio Demo](http://prismaudio-project.github.io/) is live - try it now!",
        "translatedContent": "- **‡ß®‡ß¶‡ß®‡ß´.‡ßß‡ßß.‡ß®‡ß´** &nbsp; üî•[‡¶Ö‡¶®‡¶≤‡¶æ‡¶á‡¶® PrismAudio ‡¶°‡ßá‡¶Æ‡ßã](http://prismaudio-project.github.io/) ‡¶â‡¶™‡¶≤‡¶¨‡ßç‡¶ß - ‡¶è‡¶§‡¶ø‡¶Ø‡¶º‡¶æ‡¶á ‡¶ö‡ßá‡¶∑‡ßç‡¶ü‡¶æ ‡¶ï‡ß∞‡¶ï!"
      },
      {
        "row": 9,
        "rowsha": "Q6c68QE34xLPSZ5xAL4zofEn/u8umRYYiH3ddCcy5vk=",
        "originContent": "- **2025.11.25** &nbsp; üî•[PrismAudio paper](https://arxiv.org/pdf/2511.18833) released on arXiv, the first multi-dimensional CoT-RL framework for Video-to-Audio Generation!",
        "translatedContent": "- **‡ß®‡ß¶‡ß®‡ß´.‡ßß‡ßß.‡ß®‡ß´** &nbsp; üî•[PrismAudio ‡¶ï‡¶æ‡¶ó‡¶ú](https://arxiv.org/pdf/2511.18833) arXiv-‡¶§ ‡¶Æ‡ßÅ‡¶ï‡ßç‡¶§‡¶ø, Video-to-Audio Generation-‡ß∞ ‡¶¨‡¶æ‡¶¨‡ßá ‡¶™‡ßç‡ß∞‡¶•‡¶Æ ‡¶¨‡¶π‡ßÅ-‡¶Æ‡¶æ‡¶§‡ßç‡ß∞‡¶ø‡¶ï CoT-RL ‡¶´‡ßç‡ß∞‡ßá‡¶Æ‡ß±‡ß∞‡ßç‡¶ï!"
      },
      {
        "row": 10,
        "rowsha": "vj2hbV/6MacDcxRmFA0AtTog5xU6CHoqBFO3YMO+yJo=",
        "originContent": "- **2025.09.19** &nbsp; üéâ ThinkSound has been accepted to the **NeurIPS 2025 Main Conference**!",
        "translatedContent": "- **‡ß®‡ß¶‡ß®‡ß´.‡ß¶‡ßØ.‡ßß‡ßØ** &nbsp; üéâ ThinkSound **NeurIPS 2025 ‡¶Æ‡ßÅ‡¶ñ‡ßç‡¶Ø ‡¶∏‡¶Æ‡ßç‡¶Æ‡ßá‡¶≤‡¶®**-‡¶§ ‡¶ó‡ßç‡ß∞‡¶π‡¶£ ‡¶ï‡ß∞‡¶æ ‡¶π‡ßà‡¶õ‡ßá!"
      },
      {
        "row": 11,
        "rowsha": "+guVQwDlJDqR1pBGMGc4FQ11nryItaEtKQ3etaCBcn0=",
        "originContent": "- **2025.09.01** &nbsp; Our AudioCoT dataset is now open-sourced and available on [Hugging Face](https://huggingface.co/datasets/liuhuadai/AudioCoT)!",
        "translatedContent": "- **‡ß®‡ß¶‡ß®‡ß´.‡ß¶‡ßØ.‡ß¶‡ßß** &nbsp; ‡¶Ü‡¶Æ‡¶æ‡ß∞ AudioCoT ‡¶°‡ßá‡¶ü‡¶æ‡¶õ‡ßá‡¶ü ‡¶è‡¶§‡¶ø‡¶Ø‡¶º‡¶æ ‡¶Æ‡ßÅ‡¶ï‡ßç‡¶§-‡¶â‡ßé‡¶∏ ‡¶Ü‡ß∞‡ßÅ [Hugging Face](https://huggingface.co/datasets/liuhuadai/AudioCoT)-‡¶§ ‡¶â‡¶™‡¶≤‡¶¨‡ßç‡¶ß!"
      },
      {
        "row": 12,
        "rowsha": "4Jq9g83O8cYV4fVKsetfTpI+JrSepLrjK6J7Xg9tSqo=",
        "originContent": "- **2025.07.17** &nbsp; üß† Finetuning enabled: training and finetuning code is now publicly available, along with clear usage instructions to help you customize and extend ThinkSound with your own data.",
        "translatedContent": "- **‡ß®‡ß¶‡ß®‡ß´.‡ß¶‡ß≠.‡ßß‡ß≠** &nbsp; üß† ‡¶´‡¶æ‡¶á‡¶®‡¶ü‡¶ø‡¶â‡¶®‡¶ø‡¶Ç ‡¶∏‡¶ï‡ßç‡ß∞‡¶ø‡¶Ø‡¶º: ‡¶™‡ßç‡ß∞‡¶∂‡¶ø‡¶ï‡ßç‡¶∑‡¶£ ‡¶Ü‡ß∞‡ßÅ ‡¶´‡¶æ‡¶á‡¶®‡¶ü‡¶ø‡¶â‡¶®‡¶ø‡¶Ç ‡¶ï‡ßã‡¶° ‡¶è‡¶§‡¶ø‡¶Ø‡¶º‡¶æ ‡¶™‡¶æ‡¶¨‡¶≤‡¶ø‡¶ï, ‡¶∏‡ßç‡¶™‡¶∑‡ßç‡¶ü ‡¶¨‡ßç‡¶Ø‡ß±‡¶π‡¶æ‡ß∞ ‡¶®‡¶ø‡ß∞‡ßç‡¶¶‡ßá‡¶∂‡¶®‡¶æ ‡¶∏‡¶π ThinkSound ‡¶Ü‡¶™‡ßã‡¶®‡¶æ‡ß∞ ‡¶®‡¶ø‡¶ú‡ß∞ ‡¶°‡ßá‡¶ü‡¶æ‡ß∞‡ßá ‡¶ï‡¶æ‡¶∑‡ßç‡¶ü‡¶Æ‡¶æ‡¶á‡¶ú ‡¶Ü‡ß∞‡ßÅ ‡¶¨‡¶ø‡¶∏‡ßç‡¶§‡ßÉ‡¶§ ‡¶ï‡ß∞‡¶ø‡¶¨‡¶≤‡ßà‡•§"
      },
      {
        "row": 13,
        "rowsha": "Ae5w+cTrCd9E8qidC11IWJAgg+LuOgUxA4czDPNG/G0=",
        "originContent": "- **2025.07.15** &nbsp; üì¶ Simplified installation and usability: dependencies on PyPI for easy cross-platform setup; Windows `.bat` scripts automate environment creation and script running.",
        "translatedContent": "- **‡ß®‡ß¶‡ß®‡ß´.‡ß¶‡ß≠.‡ßß‡ß´** &nbsp; üì¶ ‡¶∏‡¶π‡¶ú ‡¶á‡¶®‡¶∏‡ßç‡¶ü‡¶≤‡ßá‡¶∂‡ßç‡¶¨‡¶® ‡¶Ü‡ß∞‡ßÅ ‡¶¨‡ßç‡¶Ø‡ß±‡¶π‡¶æ‡ß∞‡¶Ø‡ßã‡¶ó‡ßç‡¶Ø‡¶§‡¶æ: PyPI-‡ß∞ ‡¶ì‡¶™‡ß∞‡¶§ ‡¶®‡¶ø‡¶∞‡ßç‡¶≠‡¶∞‡¶§‡¶æ‡¶¨‡ßã‡ß∞‡ßá ‡¶∏‡¶π‡¶ú cross-platform ‡¶õ‡ßá‡¶ü‡¶Ü‡¶™; Windows `.bat` ‡¶∏‡ßç‡¶ï‡ßç‡ß∞‡¶ø‡¶™‡ßç‡¶ü‡ßá ‡¶™‡ß∞‡¶ø‡ß±‡ßá‡¶∂ ‡¶∏‡ßÉ‡¶∑‡ßç‡¶ü‡¶ø ‡¶Ü‡ß∞‡ßÅ ‡¶∏‡ßç‡¶ï‡ßç‡ß∞‡¶ø‡¶™‡ßç‡¶ü ‡¶ö‡¶≤‡ßã‡ß±‡¶æ ‡¶∏‡ßç‡¶¨‡¶Ø‡¶º‡¶Ç‡¶ï‡ßç‡ß∞‡¶ø‡¶Ø‡¶º ‡¶ï‡ß∞‡ßá‡•§"
      },
      {
        "row": 14,
        "rowsha": "nYxNhwgSqjwYLuWsfHAqP5sx2PnzYwoFrwcf9U+Fdss=",
        "originContent": "- **2025.07.08** &nbsp;¬† üîß Major update: model lightweighted and optimized memory and GPU usage, now supports high-throughput audio generation at scale!",
        "translatedContent": "- **‡ß®‡ß¶‡ß®‡ß´.‡ß¶‡ß≠.‡ß¶‡ßÆ** &nbsp;¬† üîß ‡¶°‡¶æ‡¶ô‡ß∞ ‡¶Ü‡¶™‡¶°‡ßá‡¶ü: ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶π‡¶æ‡¶≤‡¶ï‡¶æ ‡¶Ü‡ß∞‡ßÅ ‡¶Æ‡ßá‡¶Æ'‡ß∞‡¶ø ‡¶Ü‡ß∞‡ßÅ GPU ‡¶¨‡ßç‡¶Ø‡ß±‡¶π‡¶æ‡ß∞ ‡¶Ö‡¶®‡ßÅ‡¶ï‡ßÇ‡¶≤‡¶ø‡¶§, ‡¶è‡¶§‡¶ø‡¶Ø‡¶º‡¶æ ‡¶â‡¶ö‡ßç‡¶ö-‡¶•‡ßç‡ß∞‡ßÅ‡¶™‡ßÅ‡¶ü ‡¶Ö‡¶°‡¶ø‡¶Ö' ‡¶ú‡ßá‡¶®‡¶æ‡ß∞‡ßá‡¶ö‡¶® ‡¶∏‡ßç‡¶ï‡ßá‡¶≤‡¶§ ‡¶∏‡¶Æ‡ß∞‡ßç‡¶•‡¶ø‡¶§!"
      },
      {
        "row": 15,
        "rowsha": "RPL6cU3/Jgu90ib4PkeN5Q/ALrnjq9hK0ZUCranb/PA=",
        "originContent": "- **2025.07.01** &nbsp; Online demo on [Hugging Face Spaces](https://huggingface.co/spaces/FunAudioLLM/ThinkSound) and [ModelScope](https://modelscope.cn/studios/iic/ThinkSound) for interactive experience!",
        "translatedContent": "- **‡ß®‡ß¶‡ß®‡ß´.‡ß¶‡ß≠.‡ß¶‡ßß** &nbsp; ‡¶Ö‡¶®‡¶≤‡¶æ‡¶á‡¶® ‡¶°‡ßá‡¶Æ‡ßã [Hugging Face Spaces](https://huggingface.co/spaces/FunAudioLLM/ThinkSound) ‡¶Ü‡ß∞‡ßÅ [ModelScope](https://modelscope.cn/studios/iic/ThinkSound)-‡¶§ ‡¶á‡¶®‡ßç‡¶ü‡¶æ‡ß∞‡ßá‡¶ï‡ßç‡¶ü‡¶ø‡¶≠ ‡¶Ö‡¶≠‡¶ø‡¶ú‡ßç‡¶û‡¶§‡¶æ‡ß∞ ‡¶¨‡¶æ‡¶¨‡ßá!"
      },
      {
        "row": 16,
        "rowsha": "0PEL3eOyUmX2U56FPEPvYfaltZ/P/wbH0uO6GcLPlUE=",
        "originContent": "- **2025.07.01** &nbsp; Released inference scripts and web interface; ",
        "translatedContent": "- **‡ß®‡ß¶‡ß®‡ß´.‡ß¶‡ß≠.‡ß¶‡ßß** &nbsp; ‡¶á‡¶®‡¶´‡¶æ‡ß∞‡ßá‡¶®‡ßç‡¶∏ ‡¶∏‡ßç‡¶ï‡ßç‡ß∞‡¶ø‡¶™‡ßç‡¶ü ‡¶Ü‡ß∞‡ßÅ ‡ß±‡ßá‡¶¨ ‡¶á‡¶®‡ßç‡¶ü‡¶æ‡ß∞‡¶´‡ßá‡¶ö ‡¶Æ‡ßÅ‡¶ï‡ßç‡¶§‡¶ø; "
      },
      {
        "row": 17,
        "rowsha": "XNdJ/DN741rXoJAruiGiRueQILXIUHRXzBlp+HVWM88=",
        "originContent": "- **2025.06** &nbsp; [ThinkSound paper](https://arxiv.org/pdf/2506.21448) released on arXiv!",
        "translatedContent": "- **‡ß®‡ß¶‡ß®‡ß´.‡ß¶‡ß¨** &nbsp; [ThinkSound ‡¶ï‡¶æ‡¶ó‡¶ú](https://arxiv.org/pdf/2506.21448) arXiv-‡¶§ ‡¶Æ‡ßÅ‡¶ï‡ßç‡¶§‡¶ø!"
      },
      {
        "row": 18,
        "rowsha": "W45oflUmoUAksoDc1WjcR2hErqh9UIi738PFVipiDg0=",
        "originContent": "- **2025.06** &nbsp; [Online Demo](http://thinksound-project.github.io/) is live - try it now!",
        "translatedContent": "- **‡ß®‡ß¶‡ß®‡ß´.‡ß¶‡ß¨** &nbsp; [‡¶Ö‡¶®‡¶≤‡¶æ‡¶á‡¶® ‡¶°‡ßá‡¶Æ‡ßã](http://thinksound-project.github.io/) ‡¶â‡¶™‡¶≤‡¶¨‡ßç‡¶ß - ‡¶è‡¶§‡¶ø‡¶Ø‡¶º‡¶æ‡¶á ‡¶ö‡ßá‡¶∑‡ßç‡¶ü‡¶æ ‡¶ï‡ß∞‡¶ï!"
      },
      {
        "row": 19,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 20,
        "rowsha": "yz+R1U7uMOU+NbK5mQX3Dxae1Un9eJCdPawt78ntjTs=",
        "originContent": "---",
        "translatedContent": "---"
      },
      {
        "row": 21,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 22,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 23,
        "rowsha": "f4oQIFLM2EJQxJ65F4oMEA7yWOIqs0eBtiIvGxI+GgI=",
        "originContent": "## üöÄ Features",
        "translatedContent": "## üöÄ ‡¶¨‡ßà‡¶∂‡¶ø‡¶∑‡ßç‡¶ü‡ßç‡¶Ø‡¶∏‡¶Æ‡ßÇ‡¶π"
      },
      {
        "row": 24,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 25,
        "rowsha": "8TbVluJJPR3C0fX41HklpO/vH9/k/rHC+jlvmHHfzQU=",
        "originContent": "- **Any2Audio**: Generate audio from arbitrary modalities ‚Äî video, text, audio, or their combinations.",
        "translatedContent": "- **Any2Audio**: ‡¶Ø‡¶ø‡¶ï‡ßã‡¶®‡ßã ‡¶Æ‡¶°‡¶æ‡¶≤‡¶ø‡¶ü‡¶ø‡ß∞ ‡¶™‡ß∞‡¶æ ‡¶Ö‡¶°‡¶ø‡¶Ö' ‡¶â‡¶§‡ßç‡¶™‡¶®‡ßç‡¶® ‡¶ï‡ß∞‡¶ï ‚Äî ‡¶≠‡¶ø‡¶°‡¶ø‡¶Ö', ‡¶™‡¶æ‡¶†‡ßç‡¶Ø, ‡¶Ö‡¶°‡¶ø‡¶Ö', ‡¶¨‡¶æ ‡¶∏‡¶ø‡¶ô‡ßç‡¶ó‡¶§‡¶ø‡•§"
      },
      {
        "row": 26,
        "rowsha": "+Jf5LrYz+d1ShYCuQe8UF9taEJUpuGhDk6fAlYK3Kj4=",
        "originContent": "- **Video-to-Audio SOTA**: Achieves state-of-the-art results on multiple V2A benchmarks.",
        "translatedContent": "- **Video-to-Audio SOTA**: ‡¶¨‡¶π‡ßÅ‡¶¨‡¶ø‡¶ß V2A ‡¶¨‡ßá‡¶û‡ßç‡¶ö‡¶Æ‡¶æ‡ß∞‡ßç‡¶ï‡¶§ state-of-the-art ‡¶´‡¶≤‡¶æ‡¶´‡¶≤ ‡¶≤‡¶æ‡¶≠ ‡¶ï‡ß∞‡ßá‡•§"
      },
      {
        "row": 27,
        "rowsha": "mU7qXkjW1YifKoYXJedYo9l64NsTBaiXsgoGFRF/g+E=",
        "originContent": "- **CoT-Driven Reasoning**: Chain-of-Thought reasoning for compositional and controllable audio generation via MLLMs.",
        "translatedContent": "- **CoT-Driven Reasoning**: MLLMs-‡ß∞ ‡¶Æ‡¶æ‡¶ß‡ßç‡¶Ø‡¶Æ‡ßá ‡¶∏‡¶Ç‡¶Ø‡ßã‡¶ú‡¶ø‡¶§ ‡¶Ü‡ß∞‡ßÅ ‡¶®‡¶ø‡¶Ø‡¶º‡¶®‡ßç‡¶§‡ßç‡ß∞‡¶£‡¶Ø‡ßã‡¶ó‡ßç‡¶Ø ‡¶Ö‡¶°‡¶ø‡¶Ö' ‡¶ú‡ßá‡¶®‡¶æ‡ß∞‡ßá‡¶ö‡¶®‡ß∞ ‡¶¨‡¶æ‡¶¨‡ßá Chain-of-Thought ‡¶Ø‡ßÅ‡¶ï‡ßç‡¶§‡¶ø‡¶¨‡¶æ‡¶¶‡•§"
      },
      {
        "row": 28,
        "rowsha": "RComOCBBrXsZf9RHmLginqKTh9eI/bKUZuUunQEmD5M=",
        "originContent": "- **Interactive Object-centric Editing**: Refine or edit specific sound events by clicking on visual objects or using text instructions.",
        "translatedContent": "- **Interactive Object-centric Editing**: ‡¶¶‡ßÉ‡¶∂‡ßç‡¶Ø‡¶Æ‡¶æ‡¶® ‡¶Ö‡¶¨‡¶ú‡ßá‡¶ï‡ßç‡¶ü‡¶§ ‡¶ï‡ßç‡¶≤‡¶ø‡¶ï ‡¶¨‡¶æ ‡¶™‡¶æ‡¶†‡ßç‡¶Ø ‡¶®‡¶ø‡ß∞‡ßç‡¶¶‡ßá‡¶∂‡¶®‡¶æ ‡¶¨‡ßç‡¶Ø‡ß±‡¶π‡¶æ‡ß∞ ‡¶ï‡ß∞‡¶ø ‡¶®‡¶ø‡ß∞‡ßç‡¶¶‡¶ø‡¶∑‡ßç‡¶ü ‡¶∂‡¶¨‡ßç‡¶¶ ‡¶ò‡¶ü‡¶®‡¶æ‡¶∏‡¶Æ‡ßÇ‡¶π ‡¶∏‡¶Ç‡¶∂‡ßã‡¶ß‡¶® ‡¶¨‡¶æ ‡¶∏‡¶Æ‡ßç‡¶™‡¶æ‡¶¶‡¶®‡¶æ ‡¶ï‡ß∞‡¶ï‡•§"
      },
      {
        "row": 29,
        "rowsha": "C3sf87sy73G/XZft+TDo5NjXo5XcrtJB805ayHRAXoQ=",
        "originContent": "- **Unified Framework**: One foundation model supports generation, editing, and interactive workflow.",
        "translatedContent": "- **Unified Framework**: ‡¶è‡¶ü‡¶æ ‡¶Æ‡ßå‡¶≤‡¶ø‡¶ï ‡¶Æ‡¶°‡ßá‡¶≤‡ßá ‡¶ú‡ßá‡¶®‡¶æ‡ß∞‡ßá‡¶ö‡¶®, ‡¶∏‡¶Æ‡ßç‡¶™‡¶æ‡¶¶‡¶®‡¶æ, ‡¶Ü‡ß∞‡ßÅ ‡¶á‡¶®‡ßç‡¶ü‡¶æ‡ß∞‡ßá‡¶ï‡ßç‡¶ü‡¶ø‡¶≠ ‡ß±‡ß∞‡ßç‡¶ï‡¶´‡ßç‡¶≤‡ßã ‡¶∏‡¶Æ‡ß∞‡ßç‡¶•‡¶® ‡¶ï‡ß∞‡ßá‡•§"
      },
      {
        "row": 30,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 31,
        "rowsha": "yz+R1U7uMOU+NbK5mQX3Dxae1Un9eJCdPawt78ntjTs=",
        "originContent": "---",
        "translatedContent": "---"
      },
      {
        "row": 32,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 33,
        "rowsha": "gjgLOIAU2x83BBZdLUdgEB+F64ajt/QuLYQXM1hDBLE=",
        "originContent": "## ‚ú® Method Overview",
        "translatedContent": "## ‚ú® ‡¶™‡¶¶‡ßç‡¶ß‡¶§‡¶ø‡ß∞ ‡¶∏‡¶Ç‡¶ï‡ßç‡¶∑‡¶ø‡¶™‡ßç‡¶§‡¶∏‡¶æ‡ß∞"
      },
      {
        "row": 34,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 35,
        "rowsha": "v5//GqG/smYIGoUpN+12k+9/3GWH3GdYD+jLqScb7AM=",
        "originContent": "ThinkSound decomposes audio generation and editing into three interactive stages, all guided by MLLM-based Chain-of-Thought (CoT) reasoning:",
        "translatedContent": "ThinkSound-‡¶è ‡¶Ö‡¶°‡¶ø‡¶Ö' ‡¶ú‡ßá‡¶®‡¶æ‡ß∞‡ßá‡¶ö‡¶® ‡¶Ü‡ß∞‡ßÅ ‡¶∏‡¶Æ‡ßç‡¶™‡¶æ‡¶¶‡¶®‡¶æ‡¶ï ‡¶§‡¶ø‡¶®‡¶ø‡¶ü‡¶æ ‡¶á‡¶®‡ßç‡¶ü‡¶æ‡ß∞‡ßá‡¶ï‡ßç‡¶ü‡¶ø‡¶≠ ‡¶™‡ß∞‡ßç‡¶Ø‡¶æ‡¶Ø‡¶º‡¶§ ‡¶¨‡¶ø‡¶≠‡¶ï‡ßç‡¶§ ‡¶ï‡ß∞‡ßá, ‡¶∏‡¶ï‡¶≤‡ßã MLLM-‡¶≠‡¶ø‡¶§‡ßç‡¶§‡¶ø‡¶ï Chain-of-Thought (CoT) ‡¶Ø‡ßÅ‡¶ï‡ßç‡¶§‡¶ø‡¶¨‡¶æ‡¶¶ ‡¶¶‡ßç‡¶¨‡¶æ‡ß∞‡¶æ ‡¶®‡¶ø‡ß∞‡ßç‡¶¶‡ßá‡¶∂‡¶ø‡¶§:"
      },
      {
        "row": 36,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 37,
        "rowsha": "vTObEWb7f5gCU681X3dTkwqhsaSW89TLw3GgMJ5I3bo=",
        "originContent": "1. **Foley Generation:** Generate foundational, semantically and temporally aligned soundscapes from video.",
        "translatedContent": "1. **Foley Generation:** ‡¶≠‡¶ø‡¶°‡¶ø‡¶Ö'-‡ß∞ ‡¶™‡ß∞‡¶æ ‡¶Æ‡ßå‡¶≤‡¶ø‡¶ï, ‡¶Ö‡ß∞‡ßç‡¶•‡¶¨‡¶π ‡¶Ü‡ß∞‡ßÅ ‡¶ï‡¶æ‡¶≤‡¶æ‡¶®‡ßÅ‡¶ï‡ßç‡ß∞‡¶Æ‡¶ø‡¶ï‡¶≠‡¶æ‡ß±‡ßá ‡¶Æ‡¶ø‡¶≤‡¶ø‡¶§ ‡¶∂‡¶¨‡ßç‡¶¶ ‡¶∏‡ßÉ‡¶∑‡ßç‡¶ü‡¶ø ‡¶ï‡ß∞‡¶ï‡•§"
      },
      {
        "row": 38,
        "rowsha": "LTBpIQQHtEkNF8StAa+ZEDASGmRhmHIKDQOdZ4ExJWM=",
        "originContent": "2. **Object-Centric Refinement:** Refine or add sounds for user-specified objects via clicks or regions in the video.",
        "translatedContent": "2. **Object-Centric Refinement:** ‡¶≠‡¶ø‡¶°‡¶ø‡¶Ö'‡¶§ ‡¶ï‡ßç‡¶≤‡¶ø‡¶ï ‡¶¨‡¶æ ‡¶Ö‡¶û‡ßç‡¶ö‡¶≤‡¶∏‡¶Æ‡ßÇ‡¶π‡ß∞ ‡¶Æ‡¶æ‡¶ß‡ßç‡¶Ø‡¶Æ‡ßá ‡¶¨‡ßç‡¶Ø‡ß±‡¶π‡¶æ‡ß∞‡¶ï‡¶æ‡ß∞‡ßÄ ‡¶®‡¶ø‡ß∞‡ßç‡¶¶‡¶ø‡¶∑‡ßç‡¶ü ‡¶Ö‡¶¨‡¶ú‡ßá‡¶ï‡ßç‡¶ü‡ß∞ ‡¶¨‡¶æ‡¶¨‡ßá ‡¶∂‡¶¨‡ßç‡¶¶ ‡¶∏‡¶Ç‡¶∂‡ßã‡¶ß‡¶® ‡¶¨‡¶æ ‡¶Ø‡ßã‡¶ó ‡¶ï‡ß∞‡¶ï‡•§"
      },
      {
        "row": 39,
        "rowsha": "8wrAo7X7dPC6Sgpfrlq2ziv/Wg/3+JnlFYvO+RMxADQ=",
        "originContent": "3. **Targeted Audio Editing:** Modify generated audio using high-level natural language instructions.",
        "translatedContent": "3. **Targeted Audio Editing:** ‡¶â‡¶ö‡ßç‡¶ö-‡¶∏‡ßç‡¶§‡ß∞‡ß∞ ‡¶™‡ßç‡ß∞‡¶æ‡¶ï‡ßÉ‡¶§‡¶ø‡¶ï ‡¶≠‡¶æ‡¶∑‡¶æ ‡¶®‡¶ø‡ß∞‡ßç‡¶¶‡ßá‡¶∂‡¶®‡¶æ ‡¶¨‡ßç‡¶Ø‡ß±‡¶π‡¶æ‡ß∞ ‡¶ï‡ß∞‡¶ø ‡¶â‡¶§‡ßç‡¶™‡¶®‡ßç‡¶® ‡¶Ö‡¶°‡¶ø‡¶Ö' ‡¶∏‡¶Æ‡ßç‡¶™‡¶æ‡¶¶‡¶®‡¶æ ‡¶ï‡ß∞‡¶ï‡•§"
      },
      {
        "row": 40,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 3,
    "Content": "![ThinkSound Overview](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig3_model.png)\n<!-- A large-scale CoT-annotated dataset (**AudioCoT**) is used to train both the reasoning module and the unified audio foundation model.\n![AudioCoT Pipeline](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig2_dataset.png) -->\n\n---\n\n## ‚ö° Quick Start\n\n**Environment Preparation:**",
    "ContentSha": "QpULU62syvvJhbUWGR7NuQMiHmHmeeiFfKqP+ZpqFOk=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "![ThinkSound Overview](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig3_model.png)\n<!-- ‡¶è‡¶ï ‡¶¨‡ßÉ‡¶π‡ßé-‡¶™‡ß∞‡¶ø‡¶∏‡ß∞‡ß∞ CoT-‡¶ü‡¶ø‡¶™‡ßç‡¶™‡¶®‡ßÄ‡¶Ø‡ßÅ‡¶ï‡ßç‡¶§ ‡¶°‡ßá‡¶ü‡¶æ‡¶õ‡ßá‡¶ü (**AudioCoT**) ‡¶¨‡ßç‡¶Ø‡ß±‡¶π‡¶æ‡ß∞ ‡¶ï‡ß∞‡¶æ ‡¶π‡ßà‡¶õ‡ßá ‡¶¶‡ßÅ‡¶Ø‡¶º‡ßã‡¶ü‡¶æ reasoning ‡¶Æ‡¶°‡¶ø‡¶â‡¶≤ ‡¶Ü‡ß∞‡ßÅ ‡¶è‡¶ï‡¶§‡ßç‡ß∞‡¶ø‡¶§ ‡¶Ö‡¶°‡¶ø‡¶Ö' ‡¶´‡¶æ‡¶â‡¶®‡ßç‡¶°‡ßá‡¶∂‡ßç‡¶Ø‡¶® ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶™‡ßç‡ß∞‡¶∂‡¶ø‡¶ï‡ßç‡¶∑‡¶£ ‡¶ï‡ß∞‡¶ø‡¶¨‡¶≤‡ßà‡•§\n![AudioCoT Pipeline](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig2_dataset.png) -->\n\n---\n\n## ‚ö° ‡¶§‡ßé‡¶ï‡ßç‡¶∑‡¶£‡¶æ‡¶§ ‡¶Ü‡ß∞‡¶Æ‡ßç‡¶≠ ‡¶ï‡ß∞‡¶ï\n\n**‡¶™‡ß∞‡¶ø‡¶¨‡ßá‡¶∂ ‡¶™‡ßç‡ß∞‡¶∏‡ßç‡¶§‡ßÅ‡¶§‡¶ø:**",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "4UKlvFW3Xb0bSAVjcBNeekH/MMiYS0XDg9w4mCuPy/Q=",
        "originContent": "![ThinkSound Overview](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig3_model.png)",
        "translatedContent": "![ThinkSound Overview](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig3_model.png)"
      },
      {
        "row": 2,
        "rowsha": "GaujeIM3x7+YcFy07LNNyITlujhkgpgeIaOiKHJkYnE=",
        "originContent": "<!-- A large-scale CoT-annotated dataset (**AudioCoT**) is used to train both the reasoning module and the unified audio foundation model.",
        "translatedContent": "<!-- ‡¶è‡¶ï ‡¶¨‡ßÉ‡¶π‡ßé-‡¶™‡ß∞‡¶ø‡¶∏‡ß∞‡ß∞ CoT-‡¶ü‡¶ø‡¶™‡ßç‡¶™‡¶®‡ßÄ‡¶Ø‡ßÅ‡¶ï‡ßç‡¶§ ‡¶°‡ßá‡¶ü‡¶æ‡¶õ‡ßá‡¶ü (**AudioCoT**) ‡¶¨‡ßç‡¶Ø‡ß±‡¶π‡¶æ‡ß∞ ‡¶ï‡ß∞‡¶æ ‡¶π‡ßà‡¶õ‡ßá ‡¶¶‡ßÅ‡¶Ø‡¶º‡ßã‡¶ü‡¶æ reasoning ‡¶Æ‡¶°‡¶ø‡¶â‡¶≤ ‡¶Ü‡ß∞‡ßÅ ‡¶è‡¶ï‡¶§‡ßç‡ß∞‡¶ø‡¶§ ‡¶Ö‡¶°‡¶ø‡¶Ö' ‡¶´‡¶æ‡¶â‡¶®‡ßç‡¶°‡ßá‡¶∂‡ßç‡¶Ø‡¶® ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶™‡ßç‡ß∞‡¶∂‡¶ø‡¶ï‡ßç‡¶∑‡¶£ ‡¶ï‡ß∞‡¶ø‡¶¨‡¶≤‡ßà‡•§"
      },
      {
        "row": 3,
        "rowsha": "qYOXaaTiYkoaPFcpTXE5xdSqqiW3ebi//EW/RfSXd9g=",
        "originContent": "![AudioCoT Pipeline](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig2_dataset.png) -->",
        "translatedContent": "![AudioCoT Pipeline](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig2_dataset.png) -->"
      },
      {
        "row": 4,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 5,
        "rowsha": "yz+R1U7uMOU+NbK5mQX3Dxae1Un9eJCdPawt78ntjTs=",
        "originContent": "---",
        "translatedContent": "---"
      },
      {
        "row": 6,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 7,
        "rowsha": "PrY/jc4yAHdS+Sr+s+Yhab477/BDp3GAzMJ8+WyumyI=",
        "originContent": "## ‚ö° Quick Start",
        "translatedContent": "## ‚ö° ‡¶§‡ßé‡¶ï‡ßç‡¶∑‡¶£‡¶æ‡¶§ ‡¶Ü‡ß∞‡¶Æ‡ßç‡¶≠ ‡¶ï‡ß∞‡¶ï"
      },
      {
        "row": 8,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 9,
        "rowsha": "mD63DGEpdc7FlccTEps0KPAiwsJpO/C3yjV+SKIi/vE=",
        "originContent": "**Environment Preparation:**",
        "translatedContent": "**‡¶™‡ß∞‡¶ø‡¶¨‡ßá‡¶∂ ‡¶™‡ßç‡ß∞‡¶∏‡ßç‡¶§‡ßÅ‡¶§‡¶ø:**"
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 4,
    "Content": "```bash\ngit clone https://github.com/liuhuadai/ThinkSound.git\ncd ThinkSound\nconda create -n thinksound python=3.10\nconda activate thinksound\npip install thinksound\nconda install -y -c conda-forge 'ffmpeg<7'\n# Download pretrained weights https://huggingface.co/liuhuadai/ThinkSound to Directory ckpts/\n# model weights can be also downloaded from https://www.modelscope.cn/models/iic/ThinkSound\ngit lfs install\ngit clone https://huggingface.co/liuhuadai/ThinkSound ckpts\n# To improve inference and training speed, you may optionally install a FlashAttention backend compatible with your system and PyTorch version.\n```",
    "ContentSha": "CSBCDvBmuatxDa1cNMeHEBTJJzdLjK6wyO9v0LrETM8=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\ngit clone https://github.com/liuhuadai/ThinkSound.git\ncd ThinkSound\nconda create -n thinksound python=3.10\nconda activate thinksound\npip install thinksound\nconda install -y -c conda-forge 'ffmpeg<7'\n# Download pretrained weights https://huggingface.co/liuhuadai/ThinkSound to Directory ckpts/\n# model weights can be also downloaded from https://www.modelscope.cn/models/iic/ThinkSound\ngit lfs install\ngit clone https://huggingface.co/liuhuadai/ThinkSound ckpts\n# To improve inference and training speed, you may optionally install a FlashAttention backend compatible with your system and PyTorch version.\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 5,
    "Content": "\n> ‚úÖ **Windows Tip:**  \n> Windows users can simply run `setup_windows.bat` (or double-click it) to automatically create the conda environment, install all dependencies (including FFmpeg), and download the pretrained model ‚Äî no manual setup required.  \n> Make sure `conda` and `git` are installed and available in your system PATH before running the script.\n\n\n### ‚ñ∂Ô∏è Run the Demo\n\n#### **Linux/macOS**\n",
    "ContentSha": "YGhm7lbBNPq6xLS6zXlFTPszO8rc4QZCwsScPNskcto=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "\n> ‚úÖ **‡¶â‡¶á‡¶£‡ßç‡¶°'‡¶ú ‡¶ü‡¶ø‡¶™:**  \n> ‡¶â‡¶á‡¶£‡ßç‡¶°'‡¶ú ‡¶¨‡ßç‡¶Ø‡ß±‡¶π‡¶æ‡ß∞‡¶ï‡¶æ‡ß∞‡ßÄ‡¶∏‡¶ï‡¶≤‡ßá ‡¶∏‡¶π‡¶ú‡ßá `setup_windows.bat` ‡¶ö‡¶≤‡¶æ‡¶¨ ‡¶™‡¶æ‡ß∞‡ßá (‡¶Ö‡¶•‡¶¨‡¶æ ‡¶á‡¶Ø‡¶º‡¶æ‡¶§ ‡¶°‡¶æ‡¶¨‡¶≤-‡¶ï‡ßç‡¶≤‡¶ø‡¶ï ‡¶ï‡ß∞‡¶ø‡¶¨ ‡¶™‡¶æ‡ß∞‡ßá) ‡¶Ø‡¶æ‡¶§‡ßá ‡¶∏‡ßç‡¶¨‡¶Ø‡¶º‡¶Ç‡¶ï‡ßç‡ß∞‡¶ø‡¶Ø‡¶º‡¶≠‡¶æ‡ß±‡ßá ‡¶ï‡¶®‡ßç‡¶°‡¶æ ‡¶™‡ß∞‡¶ø‡ß±‡ßá‡¶∂ ‡¶∏‡ßÉ‡¶∑‡ßç‡¶ü‡¶ø ‡¶π‡¶Ø‡¶º, ‡¶∏‡¶ï‡¶≤‡ßã ‡¶®‡¶ø‡ß∞‡ßç‡¶≠‡ß∞‡¶§‡¶æ (FFmpeg ‡¶∏‡¶π) ‡¶∏‡¶Ç‡¶∏‡ßç‡¶•‡¶æ‡¶™‡¶® ‡¶π‡¶Ø‡¶º, ‡¶Ü‡ß∞‡ßÅ ‡¶™‡ßç‡ß∞‡¶ø-‡¶ü‡ßç‡ß∞‡ßá‡¶á‡¶®‡¶° ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶°‡¶æ‡¶â‡¶®‡¶≤‡ßã‡¶° ‡¶π‡¶Ø‡¶º ‚Äî ‡¶ï‡ßã‡¶®‡ßã ‡¶π‡¶∏‡ßç‡¶§‡¶ö‡¶æ‡¶≤‡¶ø‡¶§ ‡¶∏‡¶Ç‡¶∏‡ßç‡¶•‡¶æ‡¶™‡¶® ‡¶™‡ßç‡ß∞‡¶Ø‡¶º‡ßã‡¶ú‡¶® ‡¶®‡¶π‡¶Ø‡¶º‡•§  \n> ‡¶∏‡ßç‡¶ï‡ßç‡ß∞‡¶ø‡¶™‡ßç‡¶ü ‡¶ö‡¶≤‡ßã‡ß±‡¶æ‡ß∞ ‡¶Ü‡¶ó‡¶§‡ßá ‡¶Ü‡¶™‡ßã‡¶®‡¶æ‡ß∞ ‡¶¨‡ßç‡¶Ø‡ß±‡¶∏‡ßç‡¶•‡¶æ‡¶§ `conda` ‡¶Ü‡ß∞‡ßÅ `git` ‡¶∏‡¶Ç‡¶∏‡ßç‡¶•‡¶æ‡¶™‡¶® ‡¶ï‡ß∞‡¶æ ‡¶Ü‡ß∞‡ßÅ PATH-‡¶§ ‡¶â‡¶™‡¶≤‡¶¨‡ßç‡¶ß ‡¶π‡ßã‡ß±‡¶æ ‡¶®‡¶ø‡¶∂‡ßç‡¶ö‡¶ø‡¶§ ‡¶ï‡ß∞‡¶ï‡•§\n\n\n### ‚ñ∂Ô∏è ‡¶°‡ßá‡¶Æ‚Äô ‡¶ö‡¶≤‡¶æ‡¶ì‡¶ï\n\n#### **‡¶≤‡¶ø‡¶®‡¶æ‡¶ï‡ßç‡¶∏/‡¶Æ‡ßç‡¶Ø‡¶æ‡¶ï‚Äô‡¶è‡¶∏**\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 6,
    "Content": "```bash\nchmod +x scripts/demo.sh\n./scripts/demo.sh <path-to-your-demo-video> <title> <CoT description> [use-half]\n```",
    "ContentSha": "EW6OKf+6hdOehT5SO7gfI7wR8oAoMckp60MRfIA1jHc=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\nchmod +x scripts/demo.sh\n./scripts/demo.sh <path-to-your-demo-video> <title> <CoT description> [use-half]\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 7,
    "Content": "\n#### **Windows**\n\nYou can use the provided `.bat` script instead:\n",
    "ContentSha": "zXqRZWTEWOuKZG1GOlqqZff+IH24zUwdPtSfwESqS9E=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "\n#### **Windows**\n\n‡¶Ü‡¶™‡ßÅ‡¶®‡¶ø ‡¶á‡ßü‡¶æ‡ß∞ ‡¶¨‡¶ø‡¶™‡ß∞‡ßÄ‡¶§‡ßá ‡¶™‡ßç‡ß∞‡¶¶‡¶æ‡¶® ‡¶ï‡ß∞‡¶æ `.bat` ‡¶∏‡ßç‡¶ï‡ßç‡ß∞‡¶ø‡¶™‡ßç‡¶ü ‡¶¨‡ßç‡¶Ø‡ß±‡¶π‡¶æ‡ß∞ ‡¶ï‡ß∞‡¶ø‡¶¨ ‡¶™‡¶æ‡ß∞‡ßá:\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 8,
    "Content": "```bash\n.\\scripts\\demo.bat <path-to-your-demo-video> <title> <CoT description> [use-half]\n```",
    "ContentSha": "A2a1kVuIPNs8ht1a6LBYTEijJjnfjiTN0r+2n7VEJSg=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\n.\\scripts\\demo.bat <path-to-your-demo-video> <title> <CoT description> [use-half]\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 9,
    "Content": "\n**Note:**\n\n* `<path-to-your-demo-video>`: The path to a single video\n* `[use-half]` (optional): Add use-half at the end to enable half precision feature extraction.\n\n---\n\n### üì¶ Batch Inference\n\n#### **Linux/macOS**\n",
    "ContentSha": "T7owm3ZZW7sVjKwFivgiuYX2+RVuNBl0RYTSnIcxxbM=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "\n**‡¶ü‡ßã‡¶ï‡¶æ:**\n\n* `<path-to-your-demo-video>`: ‡¶è‡¶ü‡¶æ ‡¶≠‡¶ø‡¶°‡¶ø‡¶Ö'‡ß∞ ‡¶™‡¶•\n* `[use-half]` (‡¶ê‡¶ö‡ßç‡¶õ‡¶ø‡¶ï): ‡¶Ü‡¶ß‡¶æ ‡¶™‡ßç‡ß∞‡ßá‡¶õ‡¶ø‡¶õ‡¶® ‡¶¨‡ßà‡¶∂‡¶ø‡¶∑‡ßç‡¶ü‡ßç‡¶Ø ‡¶è‡¶ï‡ßç‡¶∏‡¶ü‡ßç‡ß∞‡¶æ‡¶ï‡¶∂‡ßç‡¶Ø‡¶® ‡¶∏‡¶ï‡ßç‡ß∞‡¶ø‡¶Ø‡¶º ‡¶ï‡ß∞‡¶ø‡¶¨‡¶≤‡ßà ‡¶∂‡ßá‡¶∑‡¶§ use-half ‡¶Ø‡ßã‡¶ó ‡¶ï‡ß∞‡¶ï‡•§\n\n---\n\n### üì¶ ‡¶¨‡ßá‡¶ü‡¶ö ‡¶á‡¶®‡¶´‡¶æ‡ß∞‡ßá‡¶®‡ßç‡¶∏\n\n#### **Linux/macOS**\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 10,
    "Content": "```bash\nchmod +x scripts/eval_batch.sh\n./scripts/eval_batch.sh <video_path> <csv_path> <save_path (optional)> [use-half]\n```",
    "ContentSha": "EQ4HuSYii55aHfgphESvOXMz2+Fq39+Xquxg6Z6uzdU=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\nchmod +x scripts/eval_batch.sh\n./scripts/eval_batch.sh <video_path> <csv_path> <save_path (optional)> [use-half]\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 11,
    "Content": "\n#### **Windows**\n\nUse the equivalent `.bat` script:\n",
    "ContentSha": "njm5i6o3MR7AV4Q3WLctbe3LN1njFn89fPfTlo+zSmc=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "\n#### **‡¶â‡¶á‡¶£‡ßç‡¶°‡ßã‡¶ú**\n\n‡¶∏‡¶Æ‡¶æ‡¶® `.bat` ‡¶∏‡ßç‡¶ï‡ßç‡ß∞‡¶ø‡¶™‡ßç‡¶ü ‡¶¨‡ßç‡¶Ø‡ß±‡¶π‡¶æ‡ß∞ ‡¶ï‡ß∞‡¶ï:\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 12,
    "Content": "```bash\n.\\scripts\\eval_batch.bat <video_path> <csv_path> <save_path (optional)> [use-half]\n```",
    "ContentSha": "XLkAqxYBZeJiF6XnpshI6naENFsr5yFAH7af132cgb0=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\n.\\scripts\\eval_batch.bat <video_path> <csv_path> <save_path (optional)> [use-half]\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 13,
    "Content": "\n**Note:**\n\n* `<video_path>`: Path to the root directory containing all .mp4 videos to be processed (all videos must be of equal duration).\n* `<csv_path>`: A CSV file with text prompts for each video (see `demo_test.csv` for format).\n* `<save_path>` (optional): Where to save generated audio. Defaults to `results/features`.\n* `[use-half]` (optional): Add use-half at the end to enable half precision feature extraction.\n\n---\n\n\n### Web Interface Usage\n\nFor an interactive experience, launch the Gradio web interface:\n",
    "ContentSha": "yT/y6PXpYV8wS4qmKJfVNVGDLOwreTxCdCDFDv2VbLo=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "\n**‡¶ü‡ßã‡¶ï‡¶æ:**\n\n* `<video_path>`: ‡¶™‡ßç‡ß∞‡¶ï‡ßç‡ß∞‡¶ø‡¶Ø‡¶º‡¶æ ‡¶ï‡ß∞‡¶ø‡¶¨‡¶≤‡ßà ‡¶∏‡¶ï‡¶≤‡ßã .mp4 ‡¶≠‡¶ø‡¶°‡¶ø‡¶Ö' ‡¶•‡¶ï‡¶æ ‡¶Æ‡ßÇ‡¶≤ ‡¶°‡¶æ‡¶á‡ß∞‡ßá‡¶ï‡ßç‡¶ü‡ß∞‡ßÄ‡ß∞ ‡¶™‡¶• (‡¶∏‡¶ï‡¶≤‡ßã ‡¶≠‡¶ø‡¶°‡¶ø‡¶Ö'‡ß∞ ‡¶∏‡¶Æ‡¶Ø‡¶º‡¶∏‡ßÄ‡¶Æ‡¶æ ‡¶∏‡¶Æ‡¶æ‡¶® ‡¶π'‡¶¨ ‡¶≤‡¶æ‡¶ó‡¶ø‡¶¨).\n* `<csv_path>`: ‡¶™‡ßç‡ß∞‡¶§‡ßç‡¶Ø‡ßá‡¶ï ‡¶≠‡¶ø‡¶°‡¶ø‡¶Ö'‡ß∞ ‡¶¨‡¶æ‡¶¨‡ßá ‡¶ü‡ßá‡¶ï‡ßç‡¶∏‡¶ü ‡¶™‡ßç‡ß∞‡¶Æ‡ßç‡¶™‡¶ü ‡¶•‡¶ï‡¶æ ‡¶è‡¶ü‡¶æ CSV ‡¶´‡¶æ‡¶á‡¶≤ (`demo_test.csv`‡¶§ ‡¶´‡ß∞‡ßç‡¶Æ‡ßá‡¶ü ‡¶ö‡¶æ‡¶ì‡¶ï).\n* `<save_path>` (‡¶ê‡¶ö‡ßç‡¶õ‡¶ø‡¶ï): ‡¶®‡¶ø‡ß∞‡ßç‡¶Æ‡¶ø‡¶§ ‡¶Ö‡¶°‡¶ø‡¶Ö' ‡¶∏‡¶Ç‡ß∞‡¶ï‡ßç‡¶∑‡¶£ ‡¶ï‡ß∞‡¶æ‡ß∞ ‡¶∏‡ßç‡¶•‡¶æ‡¶®. ‡¶°‡¶ø‡¶´‡¶≤‡ßç‡¶ü `results/features`‡•§\n* `[use-half]` (‡¶ê‡¶ö‡ßç‡¶õ‡¶ø‡¶ï): ‡¶Ü‡¶ß‡¶æ ‡¶™‡ßç‡ß∞‡¶ø‡¶∏‡¶ø‡¶∂‡¶® ‡¶´‡¶ø‡¶ö‡¶æ‡ß∞ ‡¶è‡¶ï‡ßç‡¶∏‡¶ü‡ßç‡ß∞‡¶æ‡¶ï‡¶ö‡¶® ‡¶∏‡¶ï‡ßç‡ß∞‡¶ø‡¶Ø‡¶º ‡¶ï‡ß∞‡¶ø‡¶¨‡¶≤‡ßà ‡¶∂‡ßá‡¶∑‡¶§ use-half ‡¶Ø‡ßã‡¶ó ‡¶ï‡ß∞‡¶ï‡•§\n\n---\n\n\n### ‡ß±‡ßá‡¶¨ ‡¶á‡¶£‡ßç‡¶ü‡¶æ‡ß∞‡¶´‡ßá‡¶õ ‡¶¨‡ßç‡¶Ø‡ß±‡¶π‡¶æ‡ß∞\n\n‡¶á‡¶®‡ßç‡¶ü‡¶æ‡ß∞‡ßá‡¶ï‡ßç‡¶ü‡¶ø‡¶≠ ‡¶Ö‡¶≠‡¶ø‡¶ú‡ßç‡¶û‡¶§‡¶æ‡ß∞ ‡¶¨‡¶æ‡¶¨‡ßá, Gradio ‡ß±‡ßá‡¶¨ ‡¶á‡¶£‡ßç‡¶ü‡¶æ‡ß∞‡¶´‡ßá‡¶õ ‡¶Ü‡ß∞‡¶Æ‡ßç‡¶≠ ‡¶ï‡ß∞‡¶ï:\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 14,
    "Content": "```bash\npython app.py\n```",
    "ContentSha": "2nQFYMHYtsOO4+egbu20DhxqoaxfzoH8CneeM8qTEb0=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\npython app.py\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 15,
    "Content": "\n\n## üèãÔ∏è Train the Model\n\nSee [`Training.md`](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/docs/Training.md)\n\n\n---\n\n## üìù TODO & Future Plans\n* - [ ] Release a more powerful foundation model covering multiple domains to provide more engaging and immersive foley creation\n* - [ ] Add support for additional modalities and downstream tasks\n* - [ ] Release models at different scales\n* - [x] Open-source AudioCoT dataset and automated pipeline\n* - [x] Release training scripts for ThinkSound models\n* - [x] A beginner-friendly Windows quick-start README\n---\n\n\n## üìÑ License\n\nThis project is released under the Apache 2.0 License.\n\n> **Note:**\n> The code, models, and dataset are **for research and educational purposes only**.\n> **Commercial use is NOT permitted.**\n> For commercial licensing, please contact the authors.\n\n**üì¶ Third-Party Components**\n\n* **Stable Audio Open VAE** (by Stability AI):\n  This repository includes a fine-tuned VAE from [Stable Audio Open](https://huggingface.co/stabilityai/stable-audio-open-1.0/), licensed under the [Stability AI Community License](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/./third_party/LICENSE_StabilityAI.md).\n  **Commercial use and redistribution require prior permission from Stability AI.**\n\n* üìò **All other code and models** are released under the Apache License 2.0.\n\n---\n\n## Acknowledgements\n",
    "ContentSha": "j3jq6Afpr38oSd7nSvDiMiQ889Z6kSywM0DVVT9ieNA=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "\n\n## üèãÔ∏è ‡¶Æ‡¶°‡ßá‡¶≤‡¶ü‡ßã ‡¶™‡ßç‡ß∞‡¶∂‡¶ø‡¶ï‡ßç‡¶∑‡¶£ ‡¶¶‡¶ø‡¶Ø‡¶º‡¶ï\n\n‡¶ö‡¶æ‡¶ì‡¶ï [`Training.md`](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/docs/Training.md)\n\n\n---\n\n## üìù TODO ‡¶Ü‡ß∞‡ßÅ ‡¶≠‡¶¨‡¶ø‡¶∑‡ßç‡¶Ø‡¶§‡ß∞ ‡¶™‡ß∞‡¶ø‡¶ï‡¶≤‡ßç‡¶™‡¶®‡¶æ\n* - [ ] ‡¶¨‡¶π‡ßÅ‡¶§‡ßã ‡¶ï‡ßç‡¶∑‡ßá‡¶§‡ßç‡ß∞‡¶§ ‡¶Ö‡¶ß‡¶ø‡¶ï ‡¶∂‡¶ï‡ßç‡¶§‡¶ø‡¶∂‡¶æ‡¶≤‡ßÄ ‡¶´‡¶æ‡¶â‡¶£‡ßç‡¶°‡ßá‡¶∂‡ßç‡¶Ø‡¶® ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶Æ‡ßÅ‡¶ï‡ßç‡¶§‡¶ø ‡¶¶‡¶ø‡¶Ø‡¶º‡¶ï, ‡¶Ø‡¶æ‡¶§‡ßá ‡¶Ö‡¶ß‡¶ø‡¶ï ‡¶Ü‡¶ï‡ß∞‡ßç‡¶∑‡¶£‡ßÄ‡¶Ø‡¶º ‡¶Ü‡ß∞‡ßÅ ‡¶°‡ßÅ‡¶¨ ‡¶¶‡¶ø‡¶Ø‡¶º‡¶æ ‡¶´oley ‡¶∏‡ßÉ‡¶∑‡ßç‡¶ü‡¶ø ‡¶ï‡ß∞‡¶ø‡¶¨ ‡¶™‡¶æ‡ß∞‡¶ø\n* - [ ] ‡¶Ö‡¶§‡¶ø‡ß∞‡¶ø‡¶ï‡ßç‡¶§ ‡¶Æ‡ßã‡¶°‡¶æ‡¶≤‡¶ø‡¶ü‡ßÄ ‡¶Ü‡ß∞‡ßÅ ‡¶°‡¶æ‡¶â‡¶®‡¶∏‡ßç‡¶ü‡ßç‡ß∞‡¶ø‡¶Æ ‡¶ü‡¶æ‡¶∏‡ßç‡¶ï ‡¶∏‡¶Æ‡ß∞‡ßç‡¶•‡¶® ‡¶Ø‡ßã‡¶ó ‡¶ï‡ß∞‡¶ï\n* - [ ] ‡¶≠‡¶ø‡¶®‡ßç‡¶® ‡¶∏‡ßç‡¶ï‡ßá‡¶≤‡¶§ ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶Æ‡ßÅ‡¶ï‡ßç‡¶§‡¶ø ‡¶¶‡¶ø‡¶Ø‡¶º‡¶ï\n* - [x] AudioCoT ‡¶°‡ßá‡¶ü‡¶æ‡¶∏‡ßá‡¶ü ‡¶Ü‡ß∞‡ßÅ ‡¶∏‡ßç‡¶¨‡¶ö‡¶æ‡¶≤‡¶ø‡¶§ ‡¶™‡¶æ‡¶á‡¶™‡¶≤‡¶æ‡¶á‡¶® ‡¶ì‡¶™‡ßá‡¶®-‡¶õ‡ß∞‡ßç‡¶ö ‡¶ï‡ß∞‡¶ï\n* - [x] ThinkSound ‡¶Æ‡¶°‡ßá‡¶≤‡ß∞ ‡¶™‡ßç‡ß∞‡¶∂‡¶ø‡¶ï‡ßç‡¶∑‡¶£ ‡¶∏‡ßç‡¶ï‡ßç‡ß∞‡¶ø‡¶™‡ßç‡¶ü ‡¶Æ‡ßÅ‡¶ï‡ßç‡¶§‡¶ø ‡¶¶‡¶ø‡¶Ø‡¶º‡¶ï\n* - [x] ‡¶Ü‡ß∞‡¶Æ‡ßç‡¶≠‡¶®‡¶ø‡¶¨‡¶æ‡¶π‡ßÄ Windows ‡¶ï‡ßÅ‡¶á‡¶ï-‡¶∏‡ßç‡¶ü‡¶æ‡ß∞‡ßç‡¶ü README\n---\n\n\n## üìÑ ‡¶Ö‡¶®‡ßÅ‡¶Æ‡¶§‡¶ø ‡¶™‡¶§‡ßç‡ß∞\n\n‡¶è‡¶á ‡¶™‡ßç‡ß∞‡¶ï‡¶≤‡ßç‡¶™‡¶ü‡ßã Apache 2.0 License ‡¶Ö‡¶ß‡ßÄ‡¶®‡¶§ ‡¶Æ‡ßÅ‡¶ï‡ßç‡¶§‡¶ø ‡¶ï‡ß∞‡¶æ ‡¶π‡ßà‡¶õ‡ßá‡•§\n\n> **‡¶ü‡ßã‡¶ï‡¶æ:**\n> ‡¶ï‡ßã‡¶°, ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶Ü‡ß∞‡ßÅ ‡¶°‡ßá‡¶ü‡¶æ‡¶∏‡ßá‡¶ü **‡¶ó‡ß±‡ßá‡¶∑‡¶£‡¶æ ‡¶Ü‡ß∞‡ßÅ ‡¶∂‡¶ø‡¶ï‡ßç‡¶∑‡¶æ ‡¶â‡¶¶‡ßç‡¶¶‡ßá‡¶∂‡ßç‡¶Ø‡ß∞ ‡¶¨‡¶æ‡¶¨‡ßá**‡•§\n> **‡¶¨‡ßç‡¶Ø‡ß±‡¶∏‡¶æ‡¶Ø‡¶º‡¶ø‡¶ï ‡¶¨‡ßç‡¶Ø‡ß±‡¶π‡¶æ‡ß∞ ‡¶Ö‡¶®‡ßÅ‡¶Æ‡ßã‡¶¶‡¶ø‡¶§ ‡¶®‡¶π‡¶Ø‡¶º‡•§**\n> ‡¶¨‡ßç‡¶Ø‡ß±‡¶∏‡¶æ‡¶Ø‡¶º‡¶ø‡¶ï ‡¶Ö‡¶®‡ßÅ‡¶Æ‡¶§‡¶ø‡ß∞ ‡¶¨‡¶æ‡¶¨‡ßá, ‡¶Ö‡¶®‡ßÅ‡¶ó‡ßç‡ß∞‡¶π ‡¶ï‡ß∞‡¶ø ‡¶≤‡ßá‡¶ñ‡¶ï‡¶∏‡¶ï‡¶≤‡ß∞ ‡¶∏‡ßà‡¶§‡ßá ‡¶Ø‡ßã‡¶ó‡¶æ‡¶Ø‡ßã‡¶ó ‡¶ï‡ß∞‡¶ï‡•§\n\n**üì¶ ‡¶§‡ßÉ‡¶§‡ßÄ‡¶Ø‡¶º ‡¶™‡¶ï‡ßç‡¶∑‡ß∞ ‡¶â‡¶™‡¶æ‡¶¶‡¶æ‡¶®‡¶∏‡¶Æ‡ßÇ‡¶π**\n\n* **Stable Audio Open VAE** (Stability AI ‡¶¶‡ßç‡¶¨‡¶æ‡ß∞‡¶æ):\n  ‡¶è‡¶á ‡ß∞‡¶ø‡¶™'‡¶ú‡¶ø‡¶ü‡ß∞‡¶ø‡¶ü‡ßã‡¶§ [Stable Audio Open](https://huggingface.co/stabilityai/stable-audio-open-1.0/) ‡ß∞ ‡¶™‡ß∞‡¶æ ‡¶´‡¶æ‡¶á‡¶®-‡¶ü‡¶ø‡¶â‡¶® ‡¶ï‡ß∞‡¶æ VAE ‡¶Ö‡¶®‡ßç‡¶§‡¶∞‡ßç‡¶≠‡ßÅ‡¶ï‡ßç‡¶§ ‡¶Ü‡¶õ‡ßá, ‡¶Ø‡¶ø [Stability AI Community License](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/./third_party/LICENSE_StabilityAI.md) ‡¶Ö‡¶ß‡ßÄ‡¶®‡¶§ ‡¶≤‡¶æ‡¶á‡¶∏‡ßá‡¶®‡ßç‡¶∏ ‡¶ï‡ß∞‡¶æ ‡¶π‡ßà‡¶õ‡ßá‡•§\n  **‡¶¨‡ßç‡¶Ø‡ß±‡¶∏‡¶æ‡¶Ø‡¶º‡¶ø‡¶ï ‡¶¨‡ßç‡¶Ø‡ß±‡¶π‡¶æ‡ß∞ ‡¶Ü‡ß∞‡ßÅ ‡¶™‡ßÅ‡¶®‡ß∞‡ßç‡¶¨‡¶ø‡¶§‡ß∞‡¶£‡ß∞ ‡¶¨‡¶æ‡¶¨‡ßá Stability AI ‡ß∞ ‡¶™‡ßÇ‡ß∞‡ßç‡¶¨ ‡¶Ö‡¶®‡ßÅ‡¶Æ‡¶§‡¶ø ‡¶Ü‡ß±‡¶∂‡ßç‡¶Ø‡¶ï‡•§**\n\n* üìò **‡¶¨‡¶æ‡¶ï‡ßÄ ‡¶∏‡¶ï‡¶≤‡ßã ‡¶ï‡ßã‡¶° ‡¶Ü‡ß∞‡ßÅ ‡¶Æ‡¶°‡ßá‡¶≤** Apache License 2.0 ‡¶Ö‡¶ß‡ßÄ‡¶®‡¶§ ‡¶Æ‡ßÅ‡¶ï‡ßç‡¶§‡¶ø ‡¶ï‡ß∞‡¶æ ‡¶π‡ßà‡¶õ‡ßá‡•§\n\n---\n\n## ‡¶ï‡ßÉ‡¶§‡¶ú‡ßç‡¶û‡¶§‡¶æ\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 16,
    "Content": "Many thanks to:\n\n* **stable-audio-tools** (by Stability AI):\nFor providing an easy-to-use framework for audio generation, as well as the VAE module and weights.\n* **MMAudio**:\n  For the implementation of the MM-DiT backbone in the audio domain.\n\n---\n\n## üìñ Citation\n\nIf you find ThinkSound useful in your research or work, please cite our paper:\n",
    "ContentSha": "FsK5U++tkthvkZ/Gd4G7gn74YKpB282Oxnkt96u9C1k=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "‡¶ß‡¶®‡ßç‡¶Ø‡¶¨‡¶æ‡¶¶ ‡¶ú‡ßç‡¶û‡¶æ‡¶™‡¶®:\n\n* **stable-audio-tools** (Stability AI ‡¶¶‡ßç‡¶¨‡¶æ‡ß∞‡¶æ):\n‡¶Ö‡¶°‡¶ø‡¶Ö' ‡¶™‡ßç‡ß∞‡¶ú‡¶®‡ßç‡¶Æ‡ß∞ ‡¶¨‡¶æ‡¶¨‡ßá ‡¶∏‡¶π‡¶ú ‡¶¨‡ßç‡¶Ø‡ß±‡¶π‡¶æ‡ß∞‡¶Ø‡ßã‡¶ó‡ßç‡¶Ø ‡¶´‡ßç‡ß∞‡ßá‡¶Æ‡ß±‡ß∞‡ßç‡¶ï, ‡¶≤‡¶ó‡¶§‡ßá VAE ‡¶Æ‡¶°‡¶ø‡¶â‡¶≤ ‡¶Ü‡ß∞‡ßÅ ‡ß±‡ßá‡¶á‡¶ü ‡¶â‡¶™‡¶≤‡¶¨‡ßç‡¶ß ‡¶ï‡ß∞‡ßã‡ß±‡¶æ‡ß∞ ‡¶¨‡¶æ‡¶¨‡ßá‡•§\n* **MMAudio**:\n  ‡¶Ö‡¶°‡¶ø‡¶Ö' ‡¶ï‡ßç‡¶∑‡ßá‡¶§‡ßç‡ß∞‡¶§ MM-DiT ‡¶¨‡ßá‡¶ï‡¶¨'‡¶®‡ß∞ ‡ß∞‡ßÇ‡¶™‡¶æ‡¶Ø‡¶º‡¶£‡ß∞ ‡¶¨‡¶æ‡¶¨‡ßá‡•§\n\n---\n\n## üìñ ‡¶â‡¶¶‡ßç‡¶ß‡ßÉ‡¶§‡¶ø\n\n‡¶Ø‡¶¶‡¶ø ‡¶Ü‡¶™‡ßÅ‡¶®‡¶ø ThinkSound ‡¶Ü‡¶™‡ßã‡¶®‡¶æ‡ß∞ ‡¶ó‡ß±‡ßá‡¶∑‡¶£‡¶æ ‡¶¨‡¶æ ‡¶ï‡¶æ‡¶Æ‡¶§ ‡¶∏‡¶π‡¶æ‡¶Ø‡¶º‡¶ï ‡¶¨‡ßÅ‡¶≤‡¶ø ‡¶™‡ßã‡ß±‡¶æ ‡¶Ø‡¶æ‡¶Ø‡¶º, ‡¶Ö‡¶®‡ßÅ‡¶ó‡ßç‡ß∞‡¶π ‡¶ï‡ß∞‡¶ø ‡¶Ü‡¶Æ‡¶æ‡ß∞ ‡¶™‡ßç‡ß∞‡¶¨‡¶®‡ßç‡¶ß ‡¶â‡¶¶‡ßç‡¶ß‡ßÉ‡¶§ ‡¶ï‡ß∞‡¶ï:\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 17,
    "Content": "```bibtex\n@misc{liu2025thinksoundchainofthoughtreasoningmultimodal,\n      title={ThinkSound: Chain-of-Thought Reasoning in Multimodal Large Language Models for Audio Generation and Editing}, \n      author={Huadai Liu and Jialei Wang and Kaicheng Luo and Wen Wang and Qian Chen and Zhou Zhao and Wei Xue},\n      year={2025},\n      eprint={2506.21448},\n      archivePrefix={arXiv},\n      primaryClass={eess.AS},\n      url={https://arxiv.org/abs/2506.21448}, \n}\n```",
    "ContentSha": "KKv35iBt6IDF1ifN04L+6lkh0BHkbObnW/+m50Wufrs=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bibtex\n@misc{liu2025thinksoundchainofthoughtreasoningmultimodal,\n      title={ThinkSound: Chain-of-Thought Reasoning in Multimodal Large Language Models for Audio Generation and Editing}, \n      author={Huadai Liu and Jialei Wang and Kaicheng Luo and Wen Wang and Qian Chen and Zhou Zhao and Wei Xue},\n      year={2025},\n      eprint={2506.21448},\n      archivePrefix={arXiv},\n      primaryClass={eess.AS},\n      url={https://arxiv.org/abs/2506.21448}, \n}\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 18,
    "Content": "\n---\n\n## üì¨ Contact\n\n\n‚ú® Feel free to [open an issue](https://github.com/liuhuadai/ThinkSound/issues) or contact us via email ([liuhuadai@zju.edu.cn](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/mailto:liuhuadai@zju.edu.cn)) if you have any questions or suggestions!\n\n\n",
    "ContentSha": "QMNRHPzbmsL2YxrLNEPneJCBrTj4/XiY9XGTX01NZl8=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "\n---\n\n## üì¨ Contact\n\n\n‚ú® Feel free to [open an issue](https://github.com/liuhuadai/ThinkSound/issues) or contact us via email ([liuhuadai@zju.edu.cn](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/mailto:liuhuadai@zju.edu.cn)) if you have any questions or suggestions!\n\n\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 2,
        "rowsha": "yz+R1U7uMOU+NbK5mQX3Dxae1Un9eJCdPawt78ntjTs=",
        "originContent": "---",
        "translatedContent": "---"
      },
      {
        "row": 3,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 4,
        "rowsha": "V0ea1xQLKG+cGj5kHVv5f15HDd+yj0ulkcBQnvErdJc=",
        "originContent": "## üì¨ Contact",
        "translatedContent": "## üì¨ Contact"
      },
      {
        "row": 5,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 6,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 7,
        "rowsha": "QsDuVwX1DXlTNejKuNftx4k1x7yNHjfP9/1HS85hJng=",
        "originContent": "‚ú® Feel free to [open an issue](https://github.com/liuhuadai/ThinkSound/issues) or contact us via email ([liuhuadai@zju.edu.cn](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/mailto:liuhuadai@zju.edu.cn)) if you have any questions or suggestions!",
        "translatedContent": "‚ú® Feel free to [open an issue](https://github.com/liuhuadai/ThinkSound/issues) or contact us via email ([liuhuadai@zju.edu.cn](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/mailto:liuhuadai@zju.edu.cn)) if you have any questions or suggestions!"
      },
      {
        "row": 8,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 9,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 10,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  }
]