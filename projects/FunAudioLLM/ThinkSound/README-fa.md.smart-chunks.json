[
  {
    "Id": 1,
    "Content": "<h1 align=\"center\">ThinkSound</h1>\n\n<p align=\"center\">\n  ğŸŒ\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=en\">English</a> |\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=zh-CN\">ç®€ä½“ä¸­æ–‡</a> |\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=zh-TW\">ç¹é«”ä¸­æ–‡</a> |\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=es\">EspaÃ±ol</a> |\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=fr\">FranÃ§ais</a> |\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=ja\">æ—¥æœ¬èª</a>\n  \n</p>\n<p align=\"center\">\n  <img src=\"https://img.shields.io/badge/NeurIPS 2025-Main Conference-blue.svg\" alt=\"NeurIPS 2025\"/>\n<p align=\"center\">\n  <a href=\"https://arxiv.org/pdf/2506.21448\">\n    <img src=\"https://img.shields.io/badge/arXiv-2506.21448-b31b1b.svg\" alt=\"arXiv\"/>\n  </a>\n  &nbsp;\n  <a href=\"https://thinksound-project.github.io/\">\n    <img src=\"https://img.shields.io/badge/Online%20Demo-ğŸŒ-blue\" alt=\"Online Demo\"/>\n  </a>\n  &nbsp;\n  <a href=\"https://huggingface.co/spaces/FunAudioLLM/ThinkSound\">\n    <img src=\"https://img.shields.io/badge/HuggingFace-Spaces-orange?logo=huggingface\" alt=\"Hugging Face\"/>\n  </a>\n  &nbsp;\n  <a href=\"https://modelscope.cn/studios/iic/ThinkSound\">\n    <img src=\"https://img.shields.io/badge/ModelScope-åœ¨çº¿ä½“éªŒ-green\" alt=\"ModelScope\"/>\n  </a>\n</p>\n\n<p align=\"center\">\n  If you find this project useful,<br>\n  a star â­ on GitHub would be greatly appreciated!\n</p>\n\n---\n\n**ThinkSound** is a unified Any2Audio generation framework with flow matching guided by Chain-of-Thought (CoT) reasoning.",
    "ContentSha": "3764VshEOMedejxsV+uo8k5R5Emk0MLuYfIOX8JadcY=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "<h1 align=\"center\">ØªÛŒÙ†Ú©â€ŒØ³Ø§Ù†Ø¯</h1>\n\n<p align=\"center\">\n  ğŸŒ\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=en\">Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ</a> |\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=zh-CN\">ç®€ä½“ä¸­æ–‡</a> |\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=zh-TW\">ç¹é«”ä¸­æ–‡</a> |\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=es\">Ø§Ø³Ù¾Ø§Ù†ÛŒØ§ÛŒÛŒ</a> |\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=fr\">ÙØ±Ø§Ù†Ø³ÙˆÛŒ</a> |\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=ja\">Ú˜Ø§Ù¾Ù†ÛŒ</a>\n  \n</p>\n<p align=\"center\">\n  <img src=\"https://img.shields.io/badge/NeurIPS 2025-Main Conference-blue.svg\" alt=\"NeurIPS 2025\"/>\n<p align=\"center\">\n  <a href=\"https://arxiv.org/pdf/2506.21448\">\n    <img src=\"https://img.shields.io/badge/arXiv-2506.21448-b31b1b.svg\" alt=\"arXiv\"/>\n  </a>\n  &nbsp;\n  <a href=\"https://thinksound-project.github.io/\">\n    <img src=\"https://img.shields.io/badge/Online%20Demo-ğŸŒ-blue\" alt=\"Ø¯Ù…ÙˆÛŒ Ø¢Ù†Ù„Ø§ÛŒÙ†\"/>\n  </a>\n  &nbsp;\n  <a href=\"https://huggingface.co/spaces/FunAudioLLM/ThinkSound\">\n    <img src=\"https://img.shields.io/badge/HuggingFace-Spaces-orange?logo=huggingface\" alt=\"Hugging Face\"/>\n  </a>\n  &nbsp;\n  <a href=\"https://modelscope.cn/studios/iic/ThinkSound\">\n    <img src=\"https://img.shields.io/badge/ModelScope-ØªØ¬Ø±Ø¨Ù‡ Ø¢Ù†Ù„Ø§ÛŒÙ†-green\" alt=\"ModelScope\"/>\n  </a>\n</p>\n\n<p align=\"center\">\n  Ø§Ú¯Ø± Ø§ÛŒÙ† Ù¾Ø±ÙˆÚ˜Ù‡ Ø¨Ø±Ø§ÛŒ Ø´Ù…Ø§ Ù…ÙÛŒØ¯ Ø¨ÙˆØ¯ØŒ<br>\n  ÛŒÚ© Ø³ØªØ§Ø±Ù‡ â­ Ø¯Ø± Ú¯ÛŒØªâ€ŒÙ‡Ø§Ø¨ Ø¨Ø³ÛŒØ§Ø± Ø§Ø±Ø²Ø´Ù…Ù†Ø¯ Ø®ÙˆØ§Ù‡Ø¯ Ø¨ÙˆØ¯!\n</p>\n\n---\n\n**ØªÛŒÙ†Ú©â€ŒØ³Ø§Ù†Ø¯** ÛŒÚ© Ú†Ø§Ø±Ú†ÙˆØ¨ ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡ Ø¨Ø±Ø§ÛŒ ØªÙˆÙ„ÛŒØ¯ Any2Audio Ø§Ø³Øª Ú©Ù‡ Ø¨Ø§ ØªØ·Ø¨ÛŒÙ‚ Ø¬Ø±ÛŒØ§Ù† Ùˆ Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒÛŒ Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ø²Ù†Ø¬ÛŒØ±Ù‡â€ŒØ§ÛŒ (CoT) Ù‡Ø¯Ø§ÛŒØª Ù…ÛŒâ€ŒØ´ÙˆØ¯.",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 2,
    "Content": "\nPyTorch implementation for multimodal audio generation and editing: generate or edit audio from video, text, and audio, powered by step-by-step reasoning from Multimodal Large Language Models (MLLMs).\n\n![Teaser](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig1_teaser.png)\n---\n\n## ğŸ“° News\n- **2025.11.25** &nbsp; ğŸ”¥[Online PrismAudio Demo](http://prismaudio-project.github.io/) is live - try it now!\n- **2025.11.25** &nbsp; ğŸ”¥[PrismAudio paper](https://arxiv.org/pdf/2511.18833) released on arXiv, the first multi-dimensional CoT-RL framework for Video-to-Audio Generation!\n- **2025.09.19** &nbsp; ğŸ‰ ThinkSound has been accepted to the **NeurIPS 2025 Main Conference**!\n- **2025.09.01** &nbsp; Our AudioCoT dataset is now open-sourced and available on [Hugging Face](https://huggingface.co/datasets/liuhuadai/AudioCoT)!\n- **2025.07.17** &nbsp; ğŸ§  Finetuning enabled: training and finetuning code is now publicly available, along with clear usage instructions to help you customize and extend ThinkSound with your own data.\n- **2025.07.15** &nbsp; ğŸ“¦ Simplified installation and usability: dependencies on PyPI for easy cross-platform setup; Windows `.bat` scripts automate environment creation and script running.\n- **2025.07.08** &nbsp;Â  ğŸ”§ Major update: model lightweighted and optimized memory and GPU usage, now supports high-throughput audio generation at scale!\n- **2025.07.01** &nbsp; Online demo on [Hugging Face Spaces](https://huggingface.co/spaces/FunAudioLLM/ThinkSound) and [ModelScope](https://modelscope.cn/studios/iic/ThinkSound) for interactive experience!\n- **2025.07.01** &nbsp; Released inference scripts and web interface; \n- **2025.06** &nbsp; [ThinkSound paper](https://arxiv.org/pdf/2506.21448) released on arXiv!\n- **2025.06** &nbsp; [Online Demo](http://thinksound-project.github.io/) is live - try it now!\n\n---\n\n\n## ğŸš€ Features\n\n- **Any2Audio**: Generate audio from arbitrary modalities â€” video, text, audio, or their combinations.\n- **Video-to-Audio SOTA**: Achieves state-of-the-art results on multiple V2A benchmarks.\n- **CoT-Driven Reasoning**: Chain-of-Thought reasoning for compositional and controllable audio generation via MLLMs.\n- **Interactive Object-centric Editing**: Refine or edit specific sound events by clicking on visual objects or using text instructions.\n- **Unified Framework**: One foundation model supports generation, editing, and interactive workflow.\n\n---\n\n## âœ¨ Method Overview\n\nThinkSound decomposes audio generation and editing into three interactive stages, all guided by MLLM-based Chain-of-Thought (CoT) reasoning:\n\n1. **Foley Generation:** Generate foundational, semantically and temporally aligned soundscapes from video.\n2. **Object-Centric Refinement:** Refine or add sounds for user-specified objects via clicks or regions in the video.\n3. **Targeted Audio Editing:** Modify generated audio using high-level natural language instructions.\n",
    "ContentSha": "Vp81xeUGr9WCESp62x1lkoIptJHl0dM1R8kleL4V10c=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "\nÙ¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ PyTorch Ø¨Ø±Ø§ÛŒ ØªÙˆÙ„ÛŒØ¯ Ùˆ ÙˆÛŒØ±Ø§ÛŒØ´ Ú†Ù†Ø¯Ø­Ø§Ù„ØªÙ‡ ØµÙˆØªÛŒ: ØªÙˆÙ„ÛŒØ¯ ÛŒØ§ ÙˆÛŒØ±Ø§ÛŒØ´ ØµÙˆØª Ø§Ø² ÙˆÛŒØ¯ÛŒÙˆØŒ Ù…ØªÙ† Ùˆ ØµÙˆØªØŒ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ú¯Ø§Ù…â€ŒØ¨Ù‡â€ŒÚ¯Ø§Ù… ØªÙˆØ³Ø· Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¨Ø²Ø±Ú¯ Ø²Ø¨Ø§Ù†ÛŒ Ú†Ù†Ø¯Ø­Ø§Ù„ØªÙ‡ (MLLM).\n\n![Ù¾ÛŒØ´â€ŒÙ†Ù…Ø§ÛŒØ´](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig1_teaser.png)\n---\n\n## ğŸ“° Ø§Ø®Ø¨Ø§Ø±\n- **2025.11.25** &nbsp; ğŸ”¥[Ø¯Ù…ÙˆÛŒ Ø¢Ù†Ù„Ø§ÛŒÙ† PrismAudio](http://prismaudio-project.github.io/) ÙØ¹Ø§Ù„ Ø´Ø¯ - Ù‡Ù…ÛŒÙ† Ø­Ø§Ù„Ø§ Ø§Ù…ØªØ­Ø§Ù† Ú©Ù†ÛŒØ¯!\n- **2025.11.25** &nbsp; ğŸ”¥[Ù…Ù‚Ø§Ù„Ù‡ PrismAudio](https://arxiv.org/pdf/2511.18833) Ø¯Ø± arXiv Ù…Ù†ØªØ´Ø± Ø´Ø¯ØŒ Ø§ÙˆÙ„ÛŒÙ† Ú†Ø§Ø±Ú†ÙˆØ¨ Ú†Ù†Ø¯Ø¨Ø¹Ø¯ÛŒ CoT-RL Ø¨Ø±Ø§ÛŒ ØªÙˆÙ„ÛŒØ¯ ØµÙˆØª Ø§Ø² ÙˆÛŒØ¯ÛŒÙˆ!\n- **2025.09.19** &nbsp; ğŸ‰ ThinkSound Ø¯Ø± Ú©Ù†ÙØ±Ø§Ù†Ø³ Ø§ØµÙ„ÛŒ **NeurIPS 2025** Ù¾Ø°ÛŒØ±ÙØªÙ‡ Ø´Ø¯!\n- **2025.09.01** &nbsp; Ø¯ÛŒØªØ§Ø³Øª AudioCoT Ø§Ú©Ù†ÙˆÙ† Ù…ØªÙ†â€ŒØ¨Ø§Ø² Ø¨ÙˆØ¯Ù‡ Ùˆ Ø¯Ø± [Hugging Face](https://huggingface.co/datasets/liuhuadai/AudioCoT) Ù‚Ø§Ø¨Ù„ Ø¯Ø³ØªØ±Ø³ÛŒ Ø§Ø³Øª!\n- **2025.07.17** &nbsp; ğŸ§  Ø¢Ù…ÙˆØ²Ø´ Ùˆ Ø±ÛŒØ²ØªÙ†Ø¸ÛŒÙ… ÙØ¹Ø§Ù„ Ø´Ø¯: Ú©Ø¯ Ø¢Ù…ÙˆØ²Ø´ Ùˆ Ø±ÛŒØ²ØªÙ†Ø¸ÛŒÙ… Ø§Ú©Ù†ÙˆÙ† Ø¨Ù‡ ØµÙˆØ±Øª Ø¹Ù…ÙˆÙ…ÛŒ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ø§Ø³ØªØŒ Ù‡Ù…Ø±Ø§Ù‡ Ø¨Ø§ Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø´ÙØ§Ù Ø¨Ø±Ø§ÛŒ Ø´Ø®ØµÛŒâ€ŒØ³Ø§Ø²ÛŒ Ùˆ ØªÙˆØ³Ø¹Ù‡ ThinkSound Ø¨Ø§ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø®ÙˆØ¯ØªØ§Ù†.\n- **2025.07.15** &nbsp; ğŸ“¦ Ù†ØµØ¨ Ùˆ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø³Ø§Ø¯Ù‡â€ŒØ´Ø¯Ù‡: ÙˆØ§Ø¨Ø³ØªÚ¯ÛŒâ€ŒÙ‡Ø§ Ø¯Ø± PyPI Ø¨Ø±Ø§ÛŒ Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø¢Ø³Ø§Ù† Ø¨Ø± Ø±ÙˆÛŒ Ù‡Ù…Ù‡ Ù¾Ù„ØªÙØ±Ù…â€ŒÙ‡Ø§Ø› Ø§Ø³Ú©Ø±ÛŒÙ¾Øªâ€ŒÙ‡Ø§ÛŒ ÙˆÛŒÙ†Ø¯ÙˆØ² `.bat` Ø¨Ø±Ø§ÛŒ Ø®ÙˆØ¯Ú©Ø§Ø±Ø³Ø§Ø²ÛŒ Ø³Ø§Ø®Øª Ù…Ø­ÛŒØ· Ùˆ Ø§Ø¬Ø±Ø§ÛŒ Ø§Ø³Ú©Ø±ÛŒÙ¾Øªâ€ŒÙ‡Ø§.\n- **2025.07.08** &nbsp;Â  ğŸ”§ Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø¹Ù…Ø¯Ù‡: Ù…Ø¯Ù„ Ø³Ø¨Ú©â€ŒØªØ± Ø´Ø¯Ù‡ Ùˆ Ù…ØµØ±Ù Ø­Ø§ÙØ¸Ù‡ Ùˆ GPU Ø¨Ù‡ÛŒÙ†Ù‡ Ø´Ø¯Ù‡ØŒ Ø§Ú©Ù†ÙˆÙ† Ø§Ø² ØªÙˆÙ„ÛŒØ¯ ØµÙˆØª Ø¨Ø§ ØªÙˆØ§Ù† Ø¨Ø§Ù„Ø§ Ø¯Ø± Ù…Ù‚ÛŒØ§Ø³ ÙˆØ³ÛŒØ¹ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯!\n- **2025.07.01** &nbsp; Ø¯Ù…ÙˆÛŒ Ø¢Ù†Ù„Ø§ÛŒÙ† Ø¯Ø± [Hugging Face Spaces](https://huggingface.co/spaces/FunAudioLLM/ThinkSound) Ùˆ [ModelScope](https://modelscope.cn/studios/iic/ThinkSound) Ø¨Ø±Ø§ÛŒ ØªØ¬Ø±Ø¨Ù‡ ØªØ¹Ø§Ù…Ù„ÛŒ!\n- **2025.07.01** &nbsp; Ø§Ø³Ú©Ø±ÛŒÙ¾Øªâ€ŒÙ‡Ø§ÛŒ Ø§Ø³ØªÙ†ØªØ§Ø¬ Ùˆ Ø±Ø§Ø¨Ø· ÙˆØ¨ Ù…Ù†ØªØ´Ø± Ø´Ø¯Ø› \n- **2025.06** &nbsp; [Ù…Ù‚Ø§Ù„Ù‡ ThinkSound](https://arxiv.org/pdf/2506.21448) Ø¯Ø± arXiv Ù…Ù†ØªØ´Ø± Ø´Ø¯!\n- **2025.06** &nbsp; [Ø¯Ù…ÙˆÛŒ Ø¢Ù†Ù„Ø§ÛŒÙ†](http://thinksound-project.github.io/) ÙØ¹Ø§Ù„ Ø´Ø¯ - Ù‡Ù…ÛŒÙ† Ø­Ø§Ù„Ø§ Ø§Ù…ØªØ­Ø§Ù† Ú©Ù†ÛŒØ¯!\n\n---\n\n\n## ğŸš€ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§\n\n- **Any2Audio**: ØªÙˆÙ„ÛŒØ¯ ØµÙˆØª Ø§Ø² Ù‡Ø± Ø­Ø§Ù„Øª Ø¯Ù„Ø®ÙˆØ§Ù‡ â€” ÙˆÛŒØ¯ÛŒÙˆØŒ Ù…ØªÙ†ØŒ ØµÙˆØª ÛŒØ§ ØªØ±Ú©ÛŒØ¨ Ø¢Ù†â€ŒÙ‡Ø§.\n- **Video-to-Audio SOTA**: Ø¯Ø³ØªÛŒØ§Ø¨ÛŒ Ø¨Ù‡ Ù†ØªØ§ÛŒØ¬ Ù¾ÛŒØ´Ø±Ùˆ Ø¯Ø± Ú†Ù†Ø¯ÛŒÙ† Ù…Ø¹ÛŒØ§Ø± V2A.\n- **Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ù…Ø¨ØªÙ†ÛŒ Ø¨Ø± CoT**: Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ø²Ù†Ø¬ÛŒØ±Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ ØªÙˆÙ„ÛŒØ¯ ØµÙˆØª ØªØ±Ú©ÛŒØ¨ÛŒ Ùˆ Ù‚Ø§Ø¨Ù„ Ú©Ù†ØªØ±Ù„ Ø§Ø² Ø·Ø±ÛŒÙ‚ MLLMÙ‡Ø§.\n- **ÙˆÛŒØ±Ø§ÛŒØ´ ØªØ¹Ø§Ù…Ù„ÛŒ Ù…Ø¨ØªÙ†ÛŒ Ø¨Ø± Ø´ÛŒØ¡**: Ø§ØµÙ„Ø§Ø­ ÛŒØ§ ÙˆÛŒØ±Ø§ÛŒØ´ Ø±ÙˆÛŒØ¯Ø§Ø¯Ù‡Ø§ÛŒ ØµÙˆØªÛŒ Ø®Ø§Øµ Ø¨Ø§ Ú©Ù„ÛŒÚ© Ø±ÙˆÛŒ Ø§Ø´ÛŒØ§Ø¡ Ø¨ØµØ±ÛŒ ÛŒØ§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø¯Ø³ØªÙˆØ±Ø§Ù„Ø¹Ù…Ù„ Ù…ØªÙ†ÛŒ.\n- **Ú†Ø§Ø±Ú†ÙˆØ¨ ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡**: ÛŒÚ© Ù…Ø¯Ù„ Ù¾Ø§ÛŒÙ‡ Ú©Ù‡ Ø§Ø² ØªÙˆÙ„ÛŒØ¯ØŒ ÙˆÛŒØ±Ø§ÛŒØ´ Ùˆ Ú¯Ø±Ø¯Ø´â€ŒÚ©Ø§Ø± ØªØ¹Ø§Ù…Ù„ÛŒ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.\n\n---\n\n## âœ¨ Ù…Ø±ÙˆØ± Ø±ÙˆØ´\n\nThinkSound ØªÙˆÙ„ÛŒØ¯ Ùˆ ÙˆÛŒØ±Ø§ÛŒØ´ ØµÙˆØª Ø±Ø§ Ø¨Ù‡ Ø³Ù‡ Ù…Ø±Ø­Ù„Ù‡ ØªØ¹Ø§Ù…Ù„ÛŒ ØªÙ‚Ø³ÛŒÙ… Ù…ÛŒâ€ŒÚ©Ù†Ø¯ Ú©Ù‡ Ù‡Ù…Ú¯ÛŒ Ø¨Ø§ Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ø²Ù†Ø¬ÛŒØ±Ù‡â€ŒØ§ÛŒ Ù…Ø¨ØªÙ†ÛŒ Ø¨Ø± MLLM Ù‡Ø¯Ø§ÛŒØª Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯:\n\n1. **ØªÙˆÙ„ÛŒØ¯ Foley:** ØªÙˆÙ„ÛŒØ¯ ØµØ­Ù†Ù‡â€ŒÙ‡Ø§ÛŒ ØµÙˆØªÛŒ Ù¾Ø§ÛŒÙ‡ Ø¨Ø§ Ù‡Ù…â€ŒØªØ±Ø§Ø²ÛŒ Ù…Ø¹Ù†Ø§ÛŒÛŒ Ùˆ Ø²Ù…Ø§Ù†ÛŒ Ø§Ø² ÙˆÛŒØ¯ÛŒÙˆ.\n2. **Ø§ØµÙ„Ø§Ø­ Ù…Ø¨ØªÙ†ÛŒ Ø¨Ø± Ø´ÛŒØ¡:** Ø§ØµÙ„Ø§Ø­ ÛŒØ§ Ø§ÙØ²ÙˆØ¯Ù† ØµÙˆØª Ø¨Ø±Ø§ÛŒ Ø§Ø´ÛŒØ§Ø¡ Ù…Ø´Ø®Øµâ€ŒØ´Ø¯Ù‡ ØªÙˆØ³Ø· Ú©Ø§Ø±Ø¨Ø± Ø§Ø² Ø·Ø±ÛŒÙ‚ Ú©Ù„ÛŒÚ© ÛŒØ§ Ù†Ø§Ø­ÛŒÙ‡ Ø¯Ø± ÙˆÛŒØ¯ÛŒÙˆ.\n3. **ÙˆÛŒØ±Ø§ÛŒØ´ Ù‡Ø¯ÙÙ…Ù†Ø¯ ØµÙˆØª:** ØªØºÛŒÛŒØ± ØµÙˆØª ØªÙˆÙ„ÛŒØ¯Ø´Ø¯Ù‡ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø¯Ø³ØªÙˆØ±Ø§Ù„Ø¹Ù…Ù„â€ŒÙ‡Ø§ÛŒ Ø²Ø¨Ø§Ù† Ø·Ø¨ÛŒØ¹ÛŒ Ø³Ø·Ø­ Ø¨Ø§Ù„Ø§.\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 2,
        "rowsha": "eexREJOMCITdo96Iwg4N4PQqu1ux/UwupfjVRj0l/L8=",
        "originContent": "PyTorch implementation for multimodal audio generation and editing: generate or edit audio from video, text, and audio, powered by step-by-step reasoning from Multimodal Large Language Models (MLLMs).",
        "translatedContent": "Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ PyTorch Ø¨Ø±Ø§ÛŒ ØªÙˆÙ„ÛŒØ¯ Ùˆ ÙˆÛŒØ±Ø§ÛŒØ´ Ú†Ù†Ø¯Ø­Ø§Ù„ØªÙ‡ ØµÙˆØªÛŒ: ØªÙˆÙ„ÛŒØ¯ ÛŒØ§ ÙˆÛŒØ±Ø§ÛŒØ´ ØµÙˆØª Ø§Ø² ÙˆÛŒØ¯ÛŒÙˆØŒ Ù…ØªÙ† Ùˆ ØµÙˆØªØŒ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ú¯Ø§Ù…â€ŒØ¨Ù‡â€ŒÚ¯Ø§Ù… ØªÙˆØ³Ø· Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¨Ø²Ø±Ú¯ Ø²Ø¨Ø§Ù†ÛŒ Ú†Ù†Ø¯Ø­Ø§Ù„ØªÙ‡ (MLLM)."
      },
      {
        "row": 3,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 4,
        "rowsha": "+7Cx1rdpWiIOeWRA/RM6HsKf7pNA3hHsQk2Bpadt4II=",
        "originContent": "![Teaser](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig1_teaser.png)",
        "translatedContent": "![Ù¾ÛŒØ´â€ŒÙ†Ù…Ø§ÛŒØ´](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig1_teaser.png)"
      },
      {
        "row": 5,
        "rowsha": "yz+R1U7uMOU+NbK5mQX3Dxae1Un9eJCdPawt78ntjTs=",
        "originContent": "---",
        "translatedContent": "---"
      },
      {
        "row": 6,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 7,
        "rowsha": "0YeCyxpcm7/4RDbaM+OQoI8YfqEHQzDkpGW15VZdi1U=",
        "originContent": "## ğŸ“° News",
        "translatedContent": "## ğŸ“° Ø§Ø®Ø¨Ø§Ø±"
      },
      {
        "row": 8,
        "rowsha": "EeDKxV0PYB9iw6GxOqwnsP3C385ykbqk8PtEVoVhAcc=",
        "originContent": "- **2025.11.25** &nbsp; ğŸ”¥[Online PrismAudio Demo](http://prismaudio-project.github.io/) is live - try it now!",
        "translatedContent": "- **2025.11.25** &nbsp; ğŸ”¥[Ø¯Ù…ÙˆÛŒ Ø¢Ù†Ù„Ø§ÛŒÙ† PrismAudio](http://prismaudio-project.github.io/) ÙØ¹Ø§Ù„ Ø´Ø¯ - Ù‡Ù…ÛŒÙ† Ø­Ø§Ù„Ø§ Ø§Ù…ØªØ­Ø§Ù† Ú©Ù†ÛŒØ¯!"
      },
      {
        "row": 9,
        "rowsha": "Q6c68QE34xLPSZ5xAL4zofEn/u8umRYYiH3ddCcy5vk=",
        "originContent": "- **2025.11.25** &nbsp; ğŸ”¥[PrismAudio paper](https://arxiv.org/pdf/2511.18833) released on arXiv, the first multi-dimensional CoT-RL framework for Video-to-Audio Generation!",
        "translatedContent": "- **2025.11.25** &nbsp; ğŸ”¥[Ù…Ù‚Ø§Ù„Ù‡ PrismAudio](https://arxiv.org/pdf/2511.18833) Ø¯Ø± arXiv Ù…Ù†ØªØ´Ø± Ø´Ø¯ØŒ Ø§ÙˆÙ„ÛŒÙ† Ú†Ø§Ø±Ú†ÙˆØ¨ Ú†Ù†Ø¯Ø¨Ø¹Ø¯ÛŒ CoT-RL Ø¨Ø±Ø§ÛŒ ØªÙˆÙ„ÛŒØ¯ ØµÙˆØª Ø§Ø² ÙˆÛŒØ¯ÛŒÙˆ!"
      },
      {
        "row": 10,
        "rowsha": "vj2hbV/6MacDcxRmFA0AtTog5xU6CHoqBFO3YMO+yJo=",
        "originContent": "- **2025.09.19** &nbsp; ğŸ‰ ThinkSound has been accepted to the **NeurIPS 2025 Main Conference**!",
        "translatedContent": "- **2025.09.19** &nbsp; ğŸ‰ ThinkSound Ø¯Ø± Ú©Ù†ÙØ±Ø§Ù†Ø³ Ø§ØµÙ„ÛŒ **NeurIPS 2025** Ù¾Ø°ÛŒØ±ÙØªÙ‡ Ø´Ø¯!"
      },
      {
        "row": 11,
        "rowsha": "+guVQwDlJDqR1pBGMGc4FQ11nryItaEtKQ3etaCBcn0=",
        "originContent": "- **2025.09.01** &nbsp; Our AudioCoT dataset is now open-sourced and available on [Hugging Face](https://huggingface.co/datasets/liuhuadai/AudioCoT)!",
        "translatedContent": "- **2025.09.01** &nbsp; Ø¯ÛŒØªØ§Ø³Øª AudioCoT Ø§Ú©Ù†ÙˆÙ† Ù…ØªÙ†â€ŒØ¨Ø§Ø² Ø¨ÙˆØ¯Ù‡ Ùˆ Ø¯Ø± [Hugging Face](https://huggingface.co/datasets/liuhuadai/AudioCoT) Ù‚Ø§Ø¨Ù„ Ø¯Ø³ØªØ±Ø³ÛŒ Ø§Ø³Øª!"
      },
      {
        "row": 12,
        "rowsha": "4Jq9g83O8cYV4fVKsetfTpI+JrSepLrjK6J7Xg9tSqo=",
        "originContent": "- **2025.07.17** &nbsp; ğŸ§  Finetuning enabled: training and finetuning code is now publicly available, along with clear usage instructions to help you customize and extend ThinkSound with your own data.",
        "translatedContent": "- **2025.07.17** &nbsp; ğŸ§  Ø¢Ù…ÙˆØ²Ø´ Ùˆ Ø±ÛŒØ²ØªÙ†Ø¸ÛŒÙ… ÙØ¹Ø§Ù„ Ø´Ø¯: Ú©Ø¯ Ø¢Ù…ÙˆØ²Ø´ Ùˆ Ø±ÛŒØ²ØªÙ†Ø¸ÛŒÙ… Ø§Ú©Ù†ÙˆÙ† Ø¨Ù‡ ØµÙˆØ±Øª Ø¹Ù…ÙˆÙ…ÛŒ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ø§Ø³ØªØŒ Ù‡Ù…Ø±Ø§Ù‡ Ø¨Ø§ Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø´ÙØ§Ù Ø¨Ø±Ø§ÛŒ Ø´Ø®ØµÛŒâ€ŒØ³Ø§Ø²ÛŒ Ùˆ ØªÙˆØ³Ø¹Ù‡ ThinkSound Ø¨Ø§ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø®ÙˆØ¯ØªØ§Ù†."
      },
      {
        "row": 13,
        "rowsha": "Ae5w+cTrCd9E8qidC11IWJAgg+LuOgUxA4czDPNG/G0=",
        "originContent": "- **2025.07.15** &nbsp; ğŸ“¦ Simplified installation and usability: dependencies on PyPI for easy cross-platform setup; Windows `.bat` scripts automate environment creation and script running.",
        "translatedContent": "- **2025.07.15** &nbsp; ğŸ“¦ Ù†ØµØ¨ Ùˆ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø³Ø§Ø¯Ù‡â€ŒØ´Ø¯Ù‡: ÙˆØ§Ø¨Ø³ØªÚ¯ÛŒâ€ŒÙ‡Ø§ Ø¯Ø± PyPI Ø¨Ø±Ø§ÛŒ Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø¢Ø³Ø§Ù† Ø¨Ø± Ø±ÙˆÛŒ Ù‡Ù…Ù‡ Ù¾Ù„ØªÙØ±Ù…â€ŒÙ‡Ø§Ø› Ø§Ø³Ú©Ø±ÛŒÙ¾Øªâ€ŒÙ‡Ø§ÛŒ ÙˆÛŒÙ†Ø¯ÙˆØ² `.bat` Ø¨Ø±Ø§ÛŒ Ø®ÙˆØ¯Ú©Ø§Ø±Ø³Ø§Ø²ÛŒ Ø³Ø§Ø®Øª Ù…Ø­ÛŒØ· Ùˆ Ø§Ø¬Ø±Ø§ÛŒ Ø§Ø³Ú©Ø±ÛŒÙ¾Øªâ€ŒÙ‡Ø§."
      },
      {
        "row": 14,
        "rowsha": "nYxNhwgSqjwYLuWsfHAqP5sx2PnzYwoFrwcf9U+Fdss=",
        "originContent": "- **2025.07.08** &nbsp;Â  ğŸ”§ Major update: model lightweighted and optimized memory and GPU usage, now supports high-throughput audio generation at scale!",
        "translatedContent": "- **2025.07.08** &nbsp;Â  ğŸ”§ Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø¹Ù…Ø¯Ù‡: Ù…Ø¯Ù„ Ø³Ø¨Ú©â€ŒØªØ± Ø´Ø¯Ù‡ Ùˆ Ù…ØµØ±Ù Ø­Ø§ÙØ¸Ù‡ Ùˆ GPU Ø¨Ù‡ÛŒÙ†Ù‡ Ø´Ø¯Ù‡ØŒ Ø§Ú©Ù†ÙˆÙ† Ø§Ø² ØªÙˆÙ„ÛŒØ¯ ØµÙˆØª Ø¨Ø§ ØªÙˆØ§Ù† Ø¨Ø§Ù„Ø§ Ø¯Ø± Ù…Ù‚ÛŒØ§Ø³ ÙˆØ³ÛŒØ¹ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯!"
      },
      {
        "row": 15,
        "rowsha": "RPL6cU3/Jgu90ib4PkeN5Q/ALrnjq9hK0ZUCranb/PA=",
        "originContent": "- **2025.07.01** &nbsp; Online demo on [Hugging Face Spaces](https://huggingface.co/spaces/FunAudioLLM/ThinkSound) and [ModelScope](https://modelscope.cn/studios/iic/ThinkSound) for interactive experience!",
        "translatedContent": "- **2025.07.01** &nbsp; Ø¯Ù…ÙˆÛŒ Ø¢Ù†Ù„Ø§ÛŒÙ† Ø¯Ø± [Hugging Face Spaces](https://huggingface.co/spaces/FunAudioLLM/ThinkSound) Ùˆ [ModelScope](https://modelscope.cn/studios/iic/ThinkSound) Ø¨Ø±Ø§ÛŒ ØªØ¬Ø±Ø¨Ù‡ ØªØ¹Ø§Ù…Ù„ÛŒ!"
      },
      {
        "row": 16,
        "rowsha": "0PEL3eOyUmX2U56FPEPvYfaltZ/P/wbH0uO6GcLPlUE=",
        "originContent": "- **2025.07.01** &nbsp; Released inference scripts and web interface; ",
        "translatedContent": "- **2025.07.01** &nbsp; Ø§Ø³Ú©Ø±ÛŒÙ¾Øªâ€ŒÙ‡Ø§ÛŒ Ø§Ø³ØªÙ†ØªØ§Ø¬ Ùˆ Ø±Ø§Ø¨Ø· ÙˆØ¨ Ù…Ù†ØªØ´Ø± Ø´Ø¯Ø› "
      },
      {
        "row": 17,
        "rowsha": "XNdJ/DN741rXoJAruiGiRueQILXIUHRXzBlp+HVWM88=",
        "originContent": "- **2025.06** &nbsp; [ThinkSound paper](https://arxiv.org/pdf/2506.21448) released on arXiv!",
        "translatedContent": "- **2025.06** &nbsp; [Ù…Ù‚Ø§Ù„Ù‡ ThinkSound](https://arxiv.org/pdf/2506.21448) Ø¯Ø± arXiv Ù…Ù†ØªØ´Ø± Ø´Ø¯!"
      },
      {
        "row": 18,
        "rowsha": "W45oflUmoUAksoDc1WjcR2hErqh9UIi738PFVipiDg0=",
        "originContent": "- **2025.06** &nbsp; [Online Demo](http://thinksound-project.github.io/) is live - try it now!",
        "translatedContent": "- **2025.06** &nbsp; [Ø¯Ù…ÙˆÛŒ Ø¢Ù†Ù„Ø§ÛŒÙ†](http://thinksound-project.github.io/) ÙØ¹Ø§Ù„ Ø´Ø¯ - Ù‡Ù…ÛŒÙ† Ø­Ø§Ù„Ø§ Ø§Ù…ØªØ­Ø§Ù† Ú©Ù†ÛŒØ¯!"
      },
      {
        "row": 19,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 20,
        "rowsha": "yz+R1U7uMOU+NbK5mQX3Dxae1Un9eJCdPawt78ntjTs=",
        "originContent": "---",
        "translatedContent": "---"
      },
      {
        "row": 21,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 22,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 23,
        "rowsha": "f4oQIFLM2EJQxJ65F4oMEA7yWOIqs0eBtiIvGxI+GgI=",
        "originContent": "## ğŸš€ Features",
        "translatedContent": "## ğŸš€ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§"
      },
      {
        "row": 24,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 25,
        "rowsha": "8TbVluJJPR3C0fX41HklpO/vH9/k/rHC+jlvmHHfzQU=",
        "originContent": "- **Any2Audio**: Generate audio from arbitrary modalities â€” video, text, audio, or their combinations.",
        "translatedContent": "- **Any2Audio**: ØªÙˆÙ„ÛŒØ¯ ØµÙˆØª Ø§Ø² Ù‡Ø± Ø­Ø§Ù„Øª Ø¯Ù„Ø®ÙˆØ§Ù‡ â€” ÙˆÛŒØ¯ÛŒÙˆØŒ Ù…ØªÙ†ØŒ ØµÙˆØª ÛŒØ§ ØªØ±Ú©ÛŒØ¨ Ø¢Ù†â€ŒÙ‡Ø§."
      },
      {
        "row": 26,
        "rowsha": "+Jf5LrYz+d1ShYCuQe8UF9taEJUpuGhDk6fAlYK3Kj4=",
        "originContent": "- **Video-to-Audio SOTA**: Achieves state-of-the-art results on multiple V2A benchmarks.",
        "translatedContent": "- **Video-to-Audio SOTA**: Ø¯Ø³ØªÛŒØ§Ø¨ÛŒ Ø¨Ù‡ Ù†ØªØ§ÛŒØ¬ Ù¾ÛŒØ´Ø±Ùˆ Ø¯Ø± Ú†Ù†Ø¯ÛŒÙ† Ù…Ø¹ÛŒØ§Ø± V2A."
      },
      {
        "row": 27,
        "rowsha": "mU7qXkjW1YifKoYXJedYo9l64NsTBaiXsgoGFRF/g+E=",
        "originContent": "- **CoT-Driven Reasoning**: Chain-of-Thought reasoning for compositional and controllable audio generation via MLLMs.",
        "translatedContent": "- **Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ù…Ø¨ØªÙ†ÛŒ Ø¨Ø± CoT**: Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ø²Ù†Ø¬ÛŒØ±Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ ØªÙˆÙ„ÛŒØ¯ ØµÙˆØª ØªØ±Ú©ÛŒØ¨ÛŒ Ùˆ Ù‚Ø§Ø¨Ù„ Ú©Ù†ØªØ±Ù„ Ø§Ø² Ø·Ø±ÛŒÙ‚ MLLMÙ‡Ø§."
      },
      {
        "row": 28,
        "rowsha": "RComOCBBrXsZf9RHmLginqKTh9eI/bKUZuUunQEmD5M=",
        "originContent": "- **Interactive Object-centric Editing**: Refine or edit specific sound events by clicking on visual objects or using text instructions.",
        "translatedContent": "- **ÙˆÛŒØ±Ø§ÛŒØ´ ØªØ¹Ø§Ù…Ù„ÛŒ Ù…Ø¨ØªÙ†ÛŒ Ø¨Ø± Ø´ÛŒØ¡**: Ø§ØµÙ„Ø§Ø­ ÛŒØ§ ÙˆÛŒØ±Ø§ÛŒØ´ Ø±ÙˆÛŒØ¯Ø§Ø¯Ù‡Ø§ÛŒ ØµÙˆØªÛŒ Ø®Ø§Øµ Ø¨Ø§ Ú©Ù„ÛŒÚ© Ø±ÙˆÛŒ Ø§Ø´ÛŒØ§Ø¡ Ø¨ØµØ±ÛŒ ÛŒØ§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø¯Ø³ØªÙˆØ±Ø§Ù„Ø¹Ù…Ù„ Ù…ØªÙ†ÛŒ."
      },
      {
        "row": 29,
        "rowsha": "C3sf87sy73G/XZft+TDo5NjXo5XcrtJB805ayHRAXoQ=",
        "originContent": "- **Unified Framework**: One foundation model supports generation, editing, and interactive workflow.",
        "translatedContent": "- **Ú†Ø§Ø±Ú†ÙˆØ¨ ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡**: ÛŒÚ© Ù…Ø¯Ù„ Ù¾Ø§ÛŒÙ‡ Ú©Ù‡ Ø§Ø² ØªÙˆÙ„ÛŒØ¯ØŒ ÙˆÛŒØ±Ø§ÛŒØ´ Ùˆ Ú¯Ø±Ø¯Ø´â€ŒÚ©Ø§Ø± ØªØ¹Ø§Ù…Ù„ÛŒ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."
      },
      {
        "row": 30,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 31,
        "rowsha": "yz+R1U7uMOU+NbK5mQX3Dxae1Un9eJCdPawt78ntjTs=",
        "originContent": "---",
        "translatedContent": "---"
      },
      {
        "row": 32,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 33,
        "rowsha": "gjgLOIAU2x83BBZdLUdgEB+F64ajt/QuLYQXM1hDBLE=",
        "originContent": "## âœ¨ Method Overview",
        "translatedContent": "## âœ¨ Ù…Ø±ÙˆØ± Ø±ÙˆØ´"
      },
      {
        "row": 34,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 35,
        "rowsha": "v5//GqG/smYIGoUpN+12k+9/3GWH3GdYD+jLqScb7AM=",
        "originContent": "ThinkSound decomposes audio generation and editing into three interactive stages, all guided by MLLM-based Chain-of-Thought (CoT) reasoning:",
        "translatedContent": "ThinkSound ØªÙˆÙ„ÛŒØ¯ Ùˆ ÙˆÛŒØ±Ø§ÛŒØ´ ØµÙˆØª Ø±Ø§ Ø¨Ù‡ Ø³Ù‡ Ù…Ø±Ø­Ù„Ù‡ ØªØ¹Ø§Ù…Ù„ÛŒ ØªÙ‚Ø³ÛŒÙ… Ù…ÛŒâ€ŒÚ©Ù†Ø¯ Ú©Ù‡ Ù‡Ù…Ú¯ÛŒ Ø¨Ø§ Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ø²Ù†Ø¬ÛŒØ±Ù‡â€ŒØ§ÛŒ Ù…Ø¨ØªÙ†ÛŒ Ø¨Ø± MLLM Ù‡Ø¯Ø§ÛŒØª Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯:"
      },
      {
        "row": 36,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 37,
        "rowsha": "vTObEWb7f5gCU681X3dTkwqhsaSW89TLw3GgMJ5I3bo=",
        "originContent": "1. **Foley Generation:** Generate foundational, semantically and temporally aligned soundscapes from video.",
        "translatedContent": "1. **ØªÙˆÙ„ÛŒØ¯ Foley:** ØªÙˆÙ„ÛŒØ¯ ØµØ­Ù†Ù‡â€ŒÙ‡Ø§ÛŒ ØµÙˆØªÛŒ Ù¾Ø§ÛŒÙ‡ Ø¨Ø§ Ù‡Ù…â€ŒØªØ±Ø§Ø²ÛŒ Ù…Ø¹Ù†Ø§ÛŒÛŒ Ùˆ Ø²Ù…Ø§Ù†ÛŒ Ø§Ø² ÙˆÛŒØ¯ÛŒÙˆ."
      },
      {
        "row": 38,
        "rowsha": "LTBpIQQHtEkNF8StAa+ZEDASGmRhmHIKDQOdZ4ExJWM=",
        "originContent": "2. **Object-Centric Refinement:** Refine or add sounds for user-specified objects via clicks or regions in the video.",
        "translatedContent": "2. **Ø§ØµÙ„Ø§Ø­ Ù…Ø¨ØªÙ†ÛŒ Ø¨Ø± Ø´ÛŒØ¡:** Ø§ØµÙ„Ø§Ø­ ÛŒØ§ Ø§ÙØ²ÙˆØ¯Ù† ØµÙˆØª Ø¨Ø±Ø§ÛŒ Ø§Ø´ÛŒØ§Ø¡ Ù…Ø´Ø®Øµâ€ŒØ´Ø¯Ù‡ ØªÙˆØ³Ø· Ú©Ø§Ø±Ø¨Ø± Ø§Ø² Ø·Ø±ÛŒÙ‚ Ú©Ù„ÛŒÚ© ÛŒØ§ Ù†Ø§Ø­ÛŒÙ‡ Ø¯Ø± ÙˆÛŒØ¯ÛŒÙˆ."
      },
      {
        "row": 39,
        "rowsha": "8wrAo7X7dPC6Sgpfrlq2ziv/Wg/3+JnlFYvO+RMxADQ=",
        "originContent": "3. **Targeted Audio Editing:** Modify generated audio using high-level natural language instructions.",
        "translatedContent": "3. **ÙˆÛŒØ±Ø§ÛŒØ´ Ù‡Ø¯ÙÙ…Ù†Ø¯ ØµÙˆØª:** ØªØºÛŒÛŒØ± ØµÙˆØª ØªÙˆÙ„ÛŒØ¯Ø´Ø¯Ù‡ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø¯Ø³ØªÙˆØ±Ø§Ù„Ø¹Ù…Ù„â€ŒÙ‡Ø§ÛŒ Ø²Ø¨Ø§Ù† Ø·Ø¨ÛŒØ¹ÛŒ Ø³Ø·Ø­ Ø¨Ø§Ù„Ø§."
      },
      {
        "row": 40,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 3,
    "Content": "![ThinkSound Overview](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig3_model.png)\n<!-- A large-scale CoT-annotated dataset (**AudioCoT**) is used to train both the reasoning module and the unified audio foundation model.\n![AudioCoT Pipeline](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig2_dataset.png) -->\n\n---\n\n## âš¡ Quick Start\n\n**Environment Preparation:**",
    "ContentSha": "QpULU62syvvJhbUWGR7NuQMiHmHmeeiFfKqP+ZpqFOk=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "![Ù†Ù…Ø§ÛŒ Ú©Ù„ÛŒ ThinkSound](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig3_model.png)\n<!-- ÛŒÚ© Ù…Ø¬Ù…ÙˆØ¹Ù‡ Ø¯Ø§Ø¯Ù‡ Ø­Ø§Ø´ÛŒÙ‡â€ŒÙ†ÙˆÛŒØ³ÛŒâ€ŒØ´Ø¯Ù‡ Ø¨Ø§ Ø²Ù†Ø¬ÛŒØ±Ù‡ ÙÚ©Ø± Ø¯Ø± Ù…Ù‚ÛŒØ§Ø³ Ø¨Ø²Ø±Ú¯ (**AudioCoT**) Ø¨Ø±Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ Ù‡Ø± Ø¯Ùˆ Ù…Ø§Ú˜ÙˆÙ„ Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ùˆ Ù…Ø¯Ù„ Ø¨Ù†ÛŒØ§Ø¯ÛŒÙ† ØµÙˆØªÛŒ ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.\n![Ø®Ø· Ù„ÙˆÙ„Ù‡ AudioCoT](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig2_dataset.png) -->\n\n---\n\n## âš¡ Ø´Ø±ÙˆØ¹ Ø³Ø±ÛŒØ¹\n\n**Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…Ø­ÛŒØ·:**",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "4UKlvFW3Xb0bSAVjcBNeekH/MMiYS0XDg9w4mCuPy/Q=",
        "originContent": "![ThinkSound Overview](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig3_model.png)",
        "translatedContent": "![Ù†Ù…Ø§ÛŒ Ú©Ù„ÛŒ ThinkSound](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig3_model.png)"
      },
      {
        "row": 2,
        "rowsha": "GaujeIM3x7+YcFy07LNNyITlujhkgpgeIaOiKHJkYnE=",
        "originContent": "<!-- A large-scale CoT-annotated dataset (**AudioCoT**) is used to train both the reasoning module and the unified audio foundation model.",
        "translatedContent": "<!-- ÛŒÚ© Ù…Ø¬Ù…ÙˆØ¹Ù‡ Ø¯Ø§Ø¯Ù‡ Ø­Ø§Ø´ÛŒÙ‡â€ŒÙ†ÙˆÛŒØ³ÛŒâ€ŒØ´Ø¯Ù‡ Ø¨Ø§ Ø²Ù†Ø¬ÛŒØ±Ù‡ ÙÚ©Ø± Ø¯Ø± Ù…Ù‚ÛŒØ§Ø³ Ø¨Ø²Ø±Ú¯ (**AudioCoT**) Ø¨Ø±Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ Ù‡Ø± Ø¯Ùˆ Ù…Ø§Ú˜ÙˆÙ„ Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ùˆ Ù…Ø¯Ù„ Ø¨Ù†ÛŒØ§Ø¯ÛŒÙ† ØµÙˆØªÛŒ ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯."
      },
      {
        "row": 3,
        "rowsha": "qYOXaaTiYkoaPFcpTXE5xdSqqiW3ebi//EW/RfSXd9g=",
        "originContent": "![AudioCoT Pipeline](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig2_dataset.png) -->",
        "translatedContent": "![Ø®Ø· Ù„ÙˆÙ„Ù‡ AudioCoT](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig2_dataset.png) -->"
      },
      {
        "row": 4,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 5,
        "rowsha": "yz+R1U7uMOU+NbK5mQX3Dxae1Un9eJCdPawt78ntjTs=",
        "originContent": "---",
        "translatedContent": "---"
      },
      {
        "row": 6,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 7,
        "rowsha": "PrY/jc4yAHdS+Sr+s+Yhab477/BDp3GAzMJ8+WyumyI=",
        "originContent": "## âš¡ Quick Start",
        "translatedContent": "## âš¡ Ø´Ø±ÙˆØ¹ Ø³Ø±ÛŒØ¹"
      },
      {
        "row": 8,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 9,
        "rowsha": "mD63DGEpdc7FlccTEps0KPAiwsJpO/C3yjV+SKIi/vE=",
        "originContent": "**Environment Preparation:**",
        "translatedContent": "**Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…Ø­ÛŒØ·:**"
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 4,
    "Content": "```bash\ngit clone https://github.com/liuhuadai/ThinkSound.git\ncd ThinkSound\nconda create -n thinksound python=3.10\nconda activate thinksound\npip install thinksound\nconda install -y -c conda-forge 'ffmpeg<7'\n# Download pretrained weights https://huggingface.co/liuhuadai/ThinkSound to Directory ckpts/\n# model weights can be also downloaded from https://www.modelscope.cn/models/iic/ThinkSound\ngit lfs install\ngit clone https://huggingface.co/liuhuadai/ThinkSound ckpts\n# To improve inference and training speed, you may optionally install a FlashAttention backend compatible with your system and PyTorch version.\n```",
    "ContentSha": "CSBCDvBmuatxDa1cNMeHEBTJJzdLjK6wyO9v0LrETM8=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\ngit clone https://github.com/liuhuadai/ThinkSound.git\ncd ThinkSound\nconda create -n thinksound python=3.10\nconda activate thinksound\npip install thinksound\nconda install -y -c conda-forge 'ffmpeg<7'\n# Download pretrained weights https://huggingface.co/liuhuadai/ThinkSound to Directory ckpts/\n# model weights can be also downloaded from https://www.modelscope.cn/models/iic/ThinkSound\ngit lfs install\ngit clone https://huggingface.co/liuhuadai/ThinkSound ckpts\n# To improve inference and training speed, you may optionally install a FlashAttention backend compatible with your system and PyTorch version.\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 5,
    "Content": "\n> âœ… **Windows Tip:**  \n> Windows users can simply run `setup_windows.bat` (or double-click it) to automatically create the conda environment, install all dependencies (including FFmpeg), and download the pretrained model â€” no manual setup required.  \n> Make sure `conda` and `git` are installed and available in your system PATH before running the script.\n\n\n### â–¶ï¸ Run the Demo\n\n#### **Linux/macOS**\n",
    "ContentSha": "YGhm7lbBNPq6xLS6zXlFTPszO8rc4QZCwsScPNskcto=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "> âœ… **Ù†Ú©ØªÙ‡ ÙˆÛŒÙ†Ø¯ÙˆØ²:**  \n> Ú©Ø§Ø±Ø¨Ø±Ø§Ù† ÙˆÛŒÙ†Ø¯ÙˆØ² Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ù†Ø¯ Ø¨Ù‡ Ø³Ø§Ø¯Ú¯ÛŒ ÙØ§ÛŒÙ„ `setup_windows.bat` Ø±Ø§ Ø§Ø¬Ø±Ø§ Ú©Ù†Ù†Ø¯ (ÛŒØ§ Ø±ÙˆÛŒ Ø¢Ù† Ø¯ÙˆØ¨Ø§Ø± Ú©Ù„ÛŒÚ© Ú©Ù†Ù†Ø¯) ØªØ§ Ù…Ø­ÛŒØ· Ú©Ø§Ù†Ø¯Ø§ Ø¨Ù‡â€ŒØ·ÙˆØ± Ø®ÙˆØ¯Ú©Ø§Ø± Ø³Ø§Ø®ØªÙ‡ Ø´ÙˆØ¯ØŒ ØªÙ…Ø§Ù…ÛŒ ÙˆØ§Ø¨Ø³ØªÚ¯ÛŒâ€ŒÙ‡Ø§ (Ø§Ø² Ø¬Ù…Ù„Ù‡ FFmpeg) Ù†ØµØ¨ Ø´ÙˆÙ†Ø¯ Ùˆ Ù…Ø¯Ù„ Ø§Ø² Ù¾ÛŒØ´ Ø¢Ù…ÙˆØ²Ø´â€ŒØ¯ÛŒØ¯Ù‡ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ú¯Ø±Ø¯Ø¯ â€” Ù‡ÛŒÚ† ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¯Ø³ØªÛŒ Ù„Ø§Ø²Ù… Ù†ÛŒØ³Øª.  \n> Ù‚Ø¨Ù„ Ø§Ø² Ø§Ø¬Ø±Ø§ÛŒ Ø§Ø³Ú©Ø±ÛŒÙ¾ØªØŒ Ù…Ø·Ù…Ø¦Ù† Ø´ÙˆÛŒØ¯ Ú©Ù‡ `conda` Ùˆ `git` Ù†ØµØ¨ Ø´Ø¯Ù‡ Ùˆ Ø¯Ø± PATH Ø³ÛŒØ³ØªÙ… Ø´Ù…Ø§ Ù‚Ø±Ø§Ø± Ø¯Ø§Ø±Ù†Ø¯.\n\n\n### â–¶ï¸ Ø§Ø¬Ø±Ø§ÛŒ Ø¯Ù…Ùˆ\n\n#### **Ù„ÛŒÙ†ÙˆÚ©Ø³/macOS**\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 6,
    "Content": "```bash\nchmod +x scripts/demo.sh\n./scripts/demo.sh <path-to-your-demo-video> <title> <CoT description> [use-half]\n```",
    "ContentSha": "EW6OKf+6hdOehT5SO7gfI7wR8oAoMckp60MRfIA1jHc=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\nchmod +x scripts/demo.sh\n./scripts/demo.sh <path-to-your-demo-video> <title> <CoT description> [use-half]\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 7,
    "Content": "\n#### **Windows**\n\nYou can use the provided `.bat` script instead:\n",
    "ContentSha": "zXqRZWTEWOuKZG1GOlqqZff+IH24zUwdPtSfwESqS9E=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "#### **ÙˆÛŒÙ†Ø¯ÙˆØ²**\n\nØ¯Ø± Ø¹ÙˆØ¶ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø§Ø² Ø§Ø³Ú©Ø±ÛŒÙ¾Øª `.bat` Ø§Ø±Ø§Ø¦Ù‡â€ŒØ´Ø¯Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯:\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 8,
    "Content": "```bash\n.\\scripts\\demo.bat <path-to-your-demo-video> <title> <CoT description> [use-half]\n```",
    "ContentSha": "A2a1kVuIPNs8ht1a6LBYTEijJjnfjiTN0r+2n7VEJSg=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\n.\\scripts\\demo.bat <path-to-your-demo-video> <title> <CoT description> [use-half]\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 9,
    "Content": "\n**Note:**\n\n* `<path-to-your-demo-video>`: The path to a single video\n* `[use-half]` (optional): Add use-half at the end to enable half precision feature extraction.\n\n---\n\n### ğŸ“¦ Batch Inference\n\n#### **Linux/macOS**\n",
    "ContentSha": "T7owm3ZZW7sVjKwFivgiuYX2+RVuNBl0RYTSnIcxxbM=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "**ØªÙˆØ¬Ù‡:**\n\n* `<path-to-your-demo-video>`: Ù…Ø³ÛŒØ± ÛŒÚ© ÙˆÛŒØ¯Ø¦ÙˆÛŒ ØªÚ©ÛŒ\n* `[use-half]` (Ø§Ø®ØªÛŒØ§Ø±ÛŒ): Ø§ÙØ²ÙˆØ¯Ù† use-half Ø¯Ø± Ø§Ù†ØªÙ‡Ø§ Ø¨Ø±Ø§ÛŒ ÙØ¹Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆÛŒÚ˜Ú¯ÛŒ Ø¨Ø§ Ø¯Ù‚Øª Ù†ÛŒÙ…Ù‡.\n\n---\n\n### ğŸ“¦ Ø§Ø³ØªÙ†ØªØ§Ø¬ Ø¯Ø³ØªÙ‡â€ŒØ§ÛŒ\n\n#### **Ù„ÛŒÙ†ÙˆÚ©Ø³/macOS**\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 10,
    "Content": "```bash\nchmod +x scripts/eval_batch.sh\n./scripts/eval_batch.sh <video_path> <csv_path> <save_path (optional)> [use-half]\n```",
    "ContentSha": "EQ4HuSYii55aHfgphESvOXMz2+Fq39+Xquxg6Z6uzdU=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\nchmod +x scripts/eval_batch.sh\n./scripts/eval_batch.sh <video_path> <csv_path> <save_path (optional)> [use-half]\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 11,
    "Content": "\n#### **Windows**\n\nUse the equivalent `.bat` script:\n",
    "ContentSha": "njm5i6o3MR7AV4Q3WLctbe3LN1njFn89fPfTlo+zSmc=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "#### **ÙˆÛŒÙ†Ø¯ÙˆØ²**\n\nØ§Ø² Ø§Ø³Ú©Ø±ÛŒÙ¾Øª Ù…Ø¹Ø§Ø¯Ù„ `.bat` Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯:\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 12,
    "Content": "```bash\n.\\scripts\\eval_batch.bat <video_path> <csv_path> <save_path (optional)> [use-half]\n```",
    "ContentSha": "XLkAqxYBZeJiF6XnpshI6naENFsr5yFAH7af132cgb0=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\n.\\scripts\\eval_batch.bat <video_path> <csv_path> <save_path (optional)> [use-half]\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 13,
    "Content": "\n**Note:**\n\n* `<video_path>`: Path to the root directory containing all .mp4 videos to be processed (all videos must be of equal duration).\n* `<csv_path>`: A CSV file with text prompts for each video (see `demo_test.csv` for format).\n* `<save_path>` (optional): Where to save generated audio. Defaults to `results/features`.\n* `[use-half]` (optional): Add use-half at the end to enable half precision feature extraction.\n\n---\n\n\n### Web Interface Usage\n\nFor an interactive experience, launch the Gradio web interface:\n",
    "ContentSha": "yT/y6PXpYV8wS4qmKJfVNVGDLOwreTxCdCDFDv2VbLo=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "**ØªÙˆØ¬Ù‡:**\n\n* `<video_path>`: Ù…Ø³ÛŒØ± Ø¯Ø§ÛŒØ±Ú©ØªÙˆØ±ÛŒ Ø§ØµÙ„ÛŒ Ú©Ù‡ Ø­Ø§ÙˆÛŒ ØªÙ…Ø§Ù… ÙˆÛŒØ¯ÛŒÙˆÙ‡Ø§ÛŒ .mp4 Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø§Ø³Øª (Ù‡Ù…Ù‡ ÙˆÛŒØ¯ÛŒÙˆÙ‡Ø§ Ø¨Ø§ÛŒØ¯ Ù…Ø¯Øª Ø²Ù…Ø§Ù† ÛŒÚ©Ø³Ø§Ù† Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ù†Ø¯).\n* `<csv_path>`: ÛŒÚ© ÙØ§ÛŒÙ„ CSV Ø¨Ø§ Ù…ØªÙˆÙ† Ø±Ø§Ù‡Ù†Ù…Ø§ Ø¨Ø±Ø§ÛŒ Ù‡Ø± ÙˆÛŒØ¯ÛŒÙˆ (ÙØ±Ù…Øª Ø±Ø§ Ø¯Ø± `demo_test.csv` Ø¨Ø¨ÛŒÙ†ÛŒØ¯).\n* `<save_path>` (Ø§Ø®ØªÛŒØ§Ø±ÛŒ): Ù…Ø³ÛŒØ± Ø°Ø®ÛŒØ±Ù‡â€ŒØ³Ø§Ø²ÛŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ ØµÙˆØªÛŒ ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯Ù‡. Ø¨Ù‡ Ø·ÙˆØ± Ù¾ÛŒØ´â€ŒÙØ±Ø¶ `results/features` Ø§Ø³Øª.\n* `[use-half]` (Ø§Ø®ØªÛŒØ§Ø±ÛŒ): Ø§ÙØ²ÙˆØ¯Ù† use-half Ø¯Ø± Ø§Ù†ØªÙ‡Ø§ Ø¨Ø±Ø§ÛŒ ÙØ¹Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆÛŒÚ˜Ú¯ÛŒ Ø¨Ø§ Ø¯Ù‚Øª Ù†ÛŒÙ…Ù‡.\n\n---\n\n\n### Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø±Ø§Ø¨Ø· ÙˆØ¨\n\nØ¨Ø±Ø§ÛŒ ØªØ¬Ø±Ø¨Ù‡ ØªØ¹Ø§Ù…Ù„ÛŒØŒ Ø±Ø§Ø¨Ø· ÙˆØ¨ Gradio Ø±Ø§ Ø§Ø¬Ø±Ø§ Ú©Ù†ÛŒØ¯:\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 14,
    "Content": "```bash\npython app.py\n```",
    "ContentSha": "2nQFYMHYtsOO4+egbu20DhxqoaxfzoH8CneeM8qTEb0=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\npython app.py\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 15,
    "Content": "\n\n## ğŸ‹ï¸ Train the Model\n\nSee [`Training.md`](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/docs/Training.md)\n\n\n---\n\n## ğŸ“ TODO & Future Plans\n* - [ ] Release a more powerful foundation model covering multiple domains to provide more engaging and immersive foley creation\n* - [ ] Add support for additional modalities and downstream tasks\n* - [ ] Release models at different scales\n* - [x] Open-source AudioCoT dataset and automated pipeline\n* - [x] Release training scripts for ThinkSound models\n* - [x] A beginner-friendly Windows quick-start README\n---\n\n\n## ğŸ“„ License\n\nThis project is released under the Apache 2.0 License.\n\n> **Note:**\n> The code, models, and dataset are **for research and educational purposes only**.\n> **Commercial use is NOT permitted.**\n> For commercial licensing, please contact the authors.\n\n**ğŸ“¦ Third-Party Components**\n\n* **Stable Audio Open VAE** (by Stability AI):\n  This repository includes a fine-tuned VAE from [Stable Audio Open](https://huggingface.co/stabilityai/stable-audio-open-1.0/), licensed under the [Stability AI Community License](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/./third_party/LICENSE_StabilityAI.md).\n  **Commercial use and redistribution require prior permission from Stability AI.**\n\n* ğŸ“˜ **All other code and models** are released under the Apache License 2.0.\n\n---\n\n## Acknowledgements\n",
    "ContentSha": "j3jq6Afpr38oSd7nSvDiMiQ889Z6kSywM0DVVT9ieNA=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "\n\n## ğŸ‹ï¸ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„\n\nØ¨Ù‡ [`Training.md`](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/docs/Training.md) Ù…Ø±Ø§Ø¬Ø¹Ù‡ Ú©Ù†ÛŒØ¯.\n\n\n---\n\n## ğŸ“ Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒÙ‡Ø§ÛŒ Ø¢ÛŒÙ†Ø¯Ù‡ Ùˆ Ú©Ø§Ø±Ù‡Ø§ÛŒ Ø¨Ø§Ù‚ÛŒâ€ŒÙ…Ø§Ù†Ø¯Ù‡\n* - [ ] Ø§Ù†ØªØ´Ø§Ø± ÛŒÚ© Ù…Ø¯Ù„ Ù¾Ø§ÛŒÙ‡ Ù‚Ø¯Ø±ØªÙ…Ù†Ø¯ØªØ± Ú©Ù‡ Ú†Ù†Ø¯ÛŒÙ† Ø­ÙˆØ²Ù‡ Ø±Ø§ Ù¾ÙˆØ´Ø´ Ø¯Ù‡Ø¯ Ùˆ Ø®Ù„Ù‚ ÙÙˆÙ„ÛŒ Ø¬Ø°Ø§Ø¨â€ŒØªØ± Ùˆ ÙØ±Ø§Ú¯ÛŒØ±ØªØ±ÛŒ Ø§Ø±Ø§Ø¦Ù‡ Ú©Ù†Ø¯\n* - [ ] Ø§ÙØ²ÙˆØ¯Ù† Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø§Ø² Ø­Ø§Ù„Øªâ€ŒÙ‡Ø§ÛŒ Ø¨ÛŒØ´ØªØ± Ùˆ ÙˆØ¸Ø§ÛŒÙ Ù¾Ø§ÛŒÛŒÙ†â€ŒØ¯Ø³ØªÛŒ\n* - [ ] Ø§Ù†ØªØ´Ø§Ø± Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ø¯Ø± Ù…Ù‚ÛŒØ§Ø³â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù\n* - [x] Ù…ØªÙ†â€ŒØ¨Ø§Ø² Ú©Ø±Ø¯Ù† Ù…Ø¬Ù…ÙˆØ¹Ù‡ Ø¯Ø§Ø¯Ù‡ AudioCoT Ùˆ Ø®Ø· Ù„ÙˆÙ„Ù‡ Ø®ÙˆØ¯Ú©Ø§Ø±\n* - [x] Ø§Ù†ØªØ´Ø§Ø± Ø§Ø³Ú©Ø±ÛŒÙ¾Øªâ€ŒÙ‡Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ ThinkSound\n* - [x] README Ø´Ø±ÙˆØ¹ Ø³Ø±ÛŒØ¹ Ø¨Ø±Ø§ÛŒ ÙˆÛŒÙ†Ø¯ÙˆØ² Ù…Ù†Ø§Ø³Ø¨ Ù…Ø¨ØªØ¯ÛŒØ§Ù†\n---\n\n\n## ğŸ“„ Ù…Ø¬ÙˆØ²\n\nØ§ÛŒÙ† Ù¾Ø±ÙˆÚ˜Ù‡ ØªØ­Øª Ù…Ø¬ÙˆØ² Apache 2.0 Ù…Ù†ØªØ´Ø± Ø´Ø¯Ù‡ Ø§Ø³Øª.\n\n> **ØªÙˆØ¬Ù‡:**\n> Ú©Ø¯ØŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ùˆ Ù…Ø¬Ù…ÙˆØ¹Ù‡ Ø¯Ø§Ø¯Ù‡ **ÙÙ‚Ø· Ø¨Ø±Ø§ÛŒ Ø§Ù‡Ø¯Ø§Ù Ù¾Ú˜ÙˆÙ‡Ø´ÛŒ Ùˆ Ø¢Ù…ÙˆØ²Ø´ÛŒ** Ù‡Ø³ØªÙ†Ø¯.\n> **Ø§Ø³ØªÙØ§Ø¯Ù‡ ØªØ¬Ø§Ø±ÛŒ Ù…Ø¬Ø§Ø² Ù†ÛŒØ³Øª.**\n> Ø¨Ø±Ø§ÛŒ Ø§Ø®Ø° Ù…Ø¬ÙˆØ² ØªØ¬Ø§Ø±ÛŒØŒ Ù„Ø·ÙØ§Ù‹ Ø¨Ø§ Ù†ÙˆÛŒØ³Ù†Ø¯Ú¯Ø§Ù† ØªÙ…Ø§Ø³ Ø¨Ú¯ÛŒØ±ÛŒØ¯.\n\n**ğŸ“¦ Ø§Ø¬Ø²Ø§ÛŒ Ø´Ø®Øµ Ø«Ø§Ù„Ø«**\n\n* **Stable Audio Open VAE** (ØªÙˆØ³Ø· Stability AI):\n  Ø§ÛŒÙ† Ù…Ø®Ø²Ù† Ø´Ø§Ù…Ù„ ÛŒÚ© VAE ØªÙ†Ø¸ÛŒÙ…â€ŒØ´Ø¯Ù‡ Ø§Ø² [Stable Audio Open](https://huggingface.co/stabilityai/stable-audio-open-1.0/) Ø§Ø³Øª Ú©Ù‡ ØªØ­Øª [Ù…Ø¬ÙˆØ² Stability AI Community License](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/./third_party/LICENSE_StabilityAI.md) Ø§Ø±Ø§Ø¦Ù‡ Ø´Ø¯Ù‡ Ø§Ø³Øª.\n  **Ø§Ø³ØªÙØ§Ø¯Ù‡ Ùˆ ØªÙˆØ²ÛŒØ¹ ØªØ¬Ø§Ø±ÛŒ Ù†ÛŒØ§Ø²Ù…Ù†Ø¯ Ø§Ø®Ø° Ù…Ø¬ÙˆØ² Ù‚Ø¨Ù„ÛŒ Ø§Ø² Stability AI Ø§Ø³Øª.**\n\n* ğŸ“˜ **Ø³Ø§ÛŒØ± Ú©Ø¯Ù‡Ø§ Ùˆ Ù…Ø¯Ù„â€ŒÙ‡Ø§** ØªØ­Øª Ù…Ø¬ÙˆØ² Apache License 2.0 Ù…Ù†ØªØ´Ø± Ø´Ø¯Ù‡â€ŒØ§Ù†Ø¯.\n\n---\n\n## ØªÙ‚Ø¯ÛŒØ± Ùˆ ØªØ´Ú©Ø±\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 16,
    "Content": "Many thanks to:\n\n* **stable-audio-tools** (by Stability AI):\nFor providing an easy-to-use framework for audio generation, as well as the VAE module and weights.\n* **MMAudio**:\n  For the implementation of the MM-DiT backbone in the audio domain.\n\n---\n\n## ğŸ“– Citation\n\nIf you find ThinkSound useful in your research or work, please cite our paper:\n",
    "ContentSha": "FsK5U++tkthvkZ/Gd4G7gn74YKpB282Oxnkt96u9C1k=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "Ø¨Ø§ ØªØ´Ú©Ø± ÙØ±Ø§ÙˆØ§Ù† Ø§Ø²:\n\n* **stable-audio-tools** (ØªÙˆØ³Ø· Stability AI):\nØ¨Ø±Ø§ÛŒ Ø§Ø±Ø§Ø¦Ù‡ ÛŒÚ© Ú†Ø§Ø±Ú†ÙˆØ¨ Ø¢Ø³Ø§Ù† Ø¨Ø±Ø§ÛŒ ØªÙˆÙ„ÛŒØ¯ ØµÙˆØªØŒ Ù‡Ù…Ú†Ù†ÛŒÙ† Ù…Ø§Ú˜ÙˆÙ„ VAE Ùˆ ÙˆØ²Ù†â€ŒÙ‡Ø§.\n* **MMAudio**:\n  Ø¨Ø±Ø§ÛŒ Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø³ØªÙˆÙ† ÙÙ‚Ø±Ø§Øª MM-DiT Ø¯Ø± Ø­ÙˆØ²Ù‡ ØµÙˆØª.\n\n---\n\n## ğŸ“– Ø§Ø±Ø¬Ø§Ø¹\n\nØ§Ú¯Ø± ThinkSound Ø¯Ø± ØªØ­Ù‚ÛŒÙ‚Ø§Øª ÛŒØ§ Ú©Ø§Ø± Ø´Ù…Ø§ Ù…ÙÛŒØ¯ Ø¨ÙˆØ¯ØŒ Ù„Ø·ÙØ§Ù‹ Ù…Ù‚Ø§Ù„Ù‡ Ù…Ø§ Ø±Ø§ Ø§Ø±Ø¬Ø§Ø¹ Ø¯Ù‡ÛŒØ¯:\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 17,
    "Content": "```bibtex\n@misc{liu2025thinksoundchainofthoughtreasoningmultimodal,\n      title={ThinkSound: Chain-of-Thought Reasoning in Multimodal Large Language Models for Audio Generation and Editing}, \n      author={Huadai Liu and Jialei Wang and Kaicheng Luo and Wen Wang and Qian Chen and Zhou Zhao and Wei Xue},\n      year={2025},\n      eprint={2506.21448},\n      archivePrefix={arXiv},\n      primaryClass={eess.AS},\n      url={https://arxiv.org/abs/2506.21448}, \n}\n```",
    "ContentSha": "KKv35iBt6IDF1ifN04L+6lkh0BHkbObnW/+m50Wufrs=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bibtex\n@misc{liu2025thinksoundchainofthoughtreasoningmultimodal,\n      title={ThinkSound: Chain-of-Thought Reasoning in Multimodal Large Language Models for Audio Generation and Editing}, \n      author={Huadai Liu and Jialei Wang and Kaicheng Luo and Wen Wang and Qian Chen and Zhou Zhao and Wei Xue},\n      year={2025},\n      eprint={2506.21448},\n      archivePrefix={arXiv},\n      primaryClass={eess.AS},\n      url={https://arxiv.org/abs/2506.21448}, \n}\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 18,
    "Content": "\n---\n\n## ğŸ“¬ Contact\n\n\nâœ¨ Feel free to [open an issue](https://github.com/liuhuadai/ThinkSound/issues) or contact us via email ([liuhuadai@zju.edu.cn](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/mailto:liuhuadai@zju.edu.cn)) if you have any questions or suggestions!\n\n\n",
    "ContentSha": "QMNRHPzbmsL2YxrLNEPneJCBrTj4/XiY9XGTX01NZl8=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "\n---\n\n## ğŸ“¬ Contact\n\n\nâœ¨ Feel free to [open an issue](https://github.com/liuhuadai/ThinkSound/issues) or contact us via email ([liuhuadai@zju.edu.cn](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/mailto:liuhuadai@zju.edu.cn)) if you have any questions or suggestions!\n\n\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 2,
        "rowsha": "yz+R1U7uMOU+NbK5mQX3Dxae1Un9eJCdPawt78ntjTs=",
        "originContent": "---",
        "translatedContent": "---"
      },
      {
        "row": 3,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 4,
        "rowsha": "V0ea1xQLKG+cGj5kHVv5f15HDd+yj0ulkcBQnvErdJc=",
        "originContent": "## ğŸ“¬ Contact",
        "translatedContent": "## ğŸ“¬ Contact"
      },
      {
        "row": 5,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 6,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 7,
        "rowsha": "QsDuVwX1DXlTNejKuNftx4k1x7yNHjfP9/1HS85hJng=",
        "originContent": "âœ¨ Feel free to [open an issue](https://github.com/liuhuadai/ThinkSound/issues) or contact us via email ([liuhuadai@zju.edu.cn](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/mailto:liuhuadai@zju.edu.cn)) if you have any questions or suggestions!",
        "translatedContent": "âœ¨ Feel free to [open an issue](https://github.com/liuhuadai/ThinkSound/issues) or contact us via email ([liuhuadai@zju.edu.cn](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/mailto:liuhuadai@zju.edu.cn)) if you have any questions or suggestions!"
      },
      {
        "row": 8,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 9,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 10,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  }
]