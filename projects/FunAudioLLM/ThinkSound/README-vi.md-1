{
  "id": 1,
  "origin": "# ğŸ¶ ThinkSound\n\n<p align=\"center\">\n  If you find this project useful, a star â­ on GitHub would be greatly appreciated!\n</p>\n\n<p align=\"center\">\n  <a href=\"https://arxiv.org/pdf/2506.21448\">\n    <img src=\"https://img.shields.io/badge/arXiv-2506.21448-b31b1b.svg\" alt=\"arXiv\"/>\n  </a>\n  &nbsp;\n  <a href=\"https://thinksound-project.github.io/\">\n    <img src=\"https://img.shields.io/badge/Online%20Demo-ğŸŒ-blue\" alt=\"Online Demo\"/>\n  </a>\n  &nbsp;\n  <a href=\"https://huggingface.co/spaces/FunAudioLLM/ThinkSound\">\n    <img src=\"https://img.shields.io/badge/HuggingFace-Spaces-orange?logo=huggingface\" alt=\"Hugging Face\"/>\n  </a>\n  &nbsp;\n  <a href=\"https://modelscope.cn/studios/iic/ThinkSound\">\n    <img src=\"https://img.shields.io/badge/ModelScope-åœ¨çº¿ä½“éªŒ-green\" alt=\"ModelScope\"/>\n  </a>\n</p>\n\n---\n\n**ThinkSound** is a unified Any2Audio generation framework with flow matching guided by Chain-of-Thought (CoT) reasoning.\n\nPyTorch implementation for multimodal audio generation and editing: generate or edit audio from video, text, and audio, powered by step-by-step reasoning from Multimodal Large Language Models (MLLMs).\n\n![Teaser](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig1_teaser.png)\n---\n\n## ğŸ“° News\n- **2025.07** &nbsp; ğŸ”¥Online demo on [Hugging Face Spaces](https://huggingface.co/spaces/FunAudioLLM/ThinkSound) and [ModelScope](https://modelscope.cn/studios/iic/ThinkSound) for interactive experience!\n- **2025.07** &nbsp; ğŸ”¥Released inference scripts and web interface; \n- **2025.06** &nbsp; ğŸ”¥[ThinkSound paper](https://arxiv.org/pdf/2506.21448) released on arXiv!\n- **2025.06** &nbsp; ğŸ”¥[Online Demo](http://thinksound-project.github.io/) is live - try it now!\n\n---\n\n## ğŸš€ Features\n\n- **Any2Audio**: Generate audio from arbitrary modalities â€” video, text, audio, or their combinations.\n- **Video-to-Audio SOTA**: Achieves state-of-the-art results on multiple V2A benchmarks.\n- **CoT-Driven Reasoning**: Chain-of-Thought reasoning for compositional and controllable audio generation via MLLMs.\n- **Interactive Object-centric Editing**: Refine or edit specific sound events by clicking on visual objects or using text instructions.\n- **Unified Framework**: One foundation model supports generation, editing, and interactive workflow.\n\n---\n\n## âœ¨ Method Overview\n\nThinkSound decomposes audio generation and editing into three interactive stages, all guided by MLLM-based Chain-of-Thought (CoT) reasoning:\n\n1. **Foley Generation:** Generate foundational, semantically and temporally aligned soundscapes from video.\n2. **Object-Centric Refinement:** Refine or add sounds for user-specified objects via clicks or regions in the video.\n3. **Targeted Audio Editing:** Modify generated audio using high-level natural language instructions.\n\n![ThinkSound Overview](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig3_model.png)\n<!-- A large-scale CoT-annotated dataset (**AudioCoT**) is used to train both the reasoning module and the unified audio foundation model.\n![AudioCoT Pipeline](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig2_dataset.png) -->\n\n---\n\n## âš¡ Quick Start\n\n**Environment Preparation:**\n```bash\ngit clone https://github.com/liuhuadai/ThinkSound.git\ncd ThinkSound\npip install -r requirements.txt\nconda install -y -c conda-forge 'ffmpeg<7'\n# Download pretrained weights https://huggingface.co/liuhuadai/ThinkSound to Directory ckpts/\n# model weights can be also downloaded from https://www.modelscope.cn/models/iic/ThinkSound\ngit lfs install\ngit clone https://huggingface.co/liuhuadai/ThinkSound ckpts\n```\n\n**Make it executable**\n```bash\nchmod +x scripts/demo.sh\n```\n\n**Run the script**\n```bash\n./scripts/demo.sh <video_path> <caption> <CoT description>\n```\n\n\n### Web Interface Usage\n\nFor an interactive experience, launch the Gradio web interface:\n\n```bash\npython app.py\n```\n\n---\n",
  "origin_sha": "vYi4X/38TyDFihDOfSBGZIgKnu2bd0a73Iz5+m+7pd0=",
  "translate": "# ğŸ¶ ThinkSound\n\n<p align=\"center\">\n  Náº¿u báº¡n tháº¥y dá»± Ã¡n nÃ y há»¯u Ã­ch, má»™t ngÃ´i sao â­ trÃªn GitHub sáº½ Ä‘Æ°á»£c Ä‘Ã¡nh giÃ¡ ráº¥t cao!\n</p>\n\n<p align=\"center\">\n  <a href=\"https://arxiv.org/pdf/2506.21448\">\n    <img src=\"https://img.shields.io/badge/arXiv-2506.21448-b31b1b.svg\" alt=\"arXiv\"/>\n  </a>\n  &nbsp;\n  <a href=\"https://thinksound-project.github.io/\">\n    <img src=\"https://img.shields.io/badge/Online%20Demo-ğŸŒ-blue\" alt=\"Online Demo\"/>\n  </a>\n  &nbsp;\n  <a href=\"https://huggingface.co/spaces/FunAudioLLM/ThinkSound\">\n    <img src=\"https://img.shields.io/badge/HuggingFace-Spaces-orange?logo=huggingface\" alt=\"Hugging Face\"/>\n  </a>\n  &nbsp;\n  <a href=\"https://modelscope.cn/studios/iic/ThinkSound\">\n    <img src=\"https://img.shields.io/badge/ModelScope-åœ¨çº¿ä½“éªŒ-green\" alt=\"ModelScope\"/>\n  </a>\n</p>\n\n---\n\n**ThinkSound** lÃ  má»™t framework há»£p nháº¥t cho Any2Audio vá»›i phÆ°Æ¡ng phÃ¡p flow matching Ä‘Æ°á»£c dáº«n dáº¯t bá»Ÿi lÃ½ luáº­n Chuá»—i Suy NghÄ© (Chain-of-Thought - CoT).\n\nHiá»‡n thá»±c PyTorch cho viá»‡c táº¡o vÃ  chá»‰nh sá»­a Ã¢m thanh Ä‘a phÆ°Æ¡ng tiá»‡n: táº¡o hoáº·c chá»‰nh sá»­a Ã¢m thanh tá»« video, vÄƒn báº£n, vÃ  Ã¢m thanh, Ä‘Æ°á»£c há»— trá»£ bá»Ÿi quÃ¡ trÃ¬nh suy luáº­n tá»«ng bÆ°á»›c tá»« MÃ´ hÃ¬nh NgÃ´n ngá»¯ Lá»›n Äa phÆ°Æ¡ng tiá»‡n (MLLMs).\n\n![Teaser](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig1_teaser.png)\n---\n\n## ğŸ“° Tin tá»©c\n- **2025.07** &nbsp; ğŸ”¥Demo trá»±c tuyáº¿n trÃªn [Hugging Face Spaces](https://huggingface.co/spaces/FunAudioLLM/ThinkSound) vÃ  [ModelScope](https://modelscope.cn/studios/iic/ThinkSound) cho tráº£i nghiá»‡m tÆ°Æ¡ng tÃ¡c!\n- **2025.07** &nbsp; ğŸ”¥PhÃ¡t hÃ nh mÃ£ suy luáº­n vÃ  giao diá»‡n web;\n- **2025.06** &nbsp; ğŸ”¥[BÃ i bÃ¡o ThinkSound](https://arxiv.org/pdf/2506.21448) Ä‘Æ°á»£c phÃ¡t hÃ nh trÃªn arXiv!\n- **2025.06** &nbsp; ğŸ”¥[Demo trá»±c tuyáº¿n](http://thinksound-project.github.io/) Ä‘Ã£ hoáº¡t Ä‘á»™ng - hÃ£y thá»­ ngay!\n\n---\n\n## ğŸš€ TÃ­nh nÄƒng\n\n- **Any2Audio**: Táº¡o Ã¢m thanh tá»« báº¥t ká»³ loáº¡i dá»¯ liá»‡u nÃ o â€” video, vÄƒn báº£n, Ã¢m thanh, hoáº·c káº¿t há»£p cá»§a chÃºng.\n- **Video-to-Audio SOTA**: Äáº¡t káº¿t quáº£ tá»‘t nháº¥t trÃªn nhiá»u bá»™ chuáº©n V2A.\n- **LÃ½ luáº­n dá»±a trÃªn CoT**: LÃ½ luáº­n Chuá»—i Suy NghÄ© cho viá»‡c táº¡o Ã¢m thanh cÃ³ tÃ­nh thÃ nh pháº§n vÃ  kiá»ƒm soÃ¡t Ä‘Æ°á»£c thÃ´ng qua MLLMs.\n- **Chá»‰nh sá»­a táº­p trung vÃ o Ä‘á»‘i tÆ°á»£ng tÆ°Æ¡ng tÃ¡c**: Tinh chá»‰nh hoáº·c chá»‰nh sá»­a sá»± kiá»‡n Ã¢m thanh cá»¥ thá»ƒ báº±ng cÃ¡ch nháº¥p vÃ o Ä‘á»‘i tÆ°á»£ng hÃ¬nh áº£nh hoáº·c sá»­ dá»¥ng hÆ°á»›ng dáº«n vÄƒn báº£n.\n- **Khung há»£p nháº¥t**: Má»™t mÃ´ hÃ¬nh ná»n táº£ng há»— trá»£ táº¡o, chá»‰nh sá»­a vÃ  quy trÃ¬nh lÃ m viá»‡c tÆ°Æ¡ng tÃ¡c.\n\n---\n\n## âœ¨ Tá»•ng quan phÆ°Æ¡ng phÃ¡p\n\nThinkSound phÃ¢n tÃ¡ch quÃ¡ trÃ¬nh táº¡o vÃ  chá»‰nh sá»­a Ã¢m thanh thÃ nh ba giai Ä‘oáº¡n tÆ°Æ¡ng tÃ¡c, táº¥t cáº£ Ä‘á»u Ä‘Æ°á»£c dáº«n dáº¯t bá»Ÿi lÃ½ luáº­n Chuá»—i Suy NghÄ© (CoT) dá»±a trÃªn MLLM:\n\n1. **Táº¡o Foley:** Táº¡o ná»n Ã¢m thanh cÆ¡ báº£n, phÃ¹ há»£p vá» ngá»¯ nghÄ©a vÃ  thá»i gian tá»« video.\n2. **Tinh chá»‰nh táº­p trung vÃ o Ä‘á»‘i tÆ°á»£ng:** Tinh chá»‰nh hoáº·c thÃªm Ã¢m thanh cho cÃ¡c Ä‘á»‘i tÆ°á»£ng do ngÆ°á»i dÃ¹ng chá»‰ Ä‘á»‹nh thÃ´ng qua click hoáº·c vÃ¹ng chá»n trong video.\n3. **Chá»‰nh sá»­a Ã¢m thanh má»¥c tiÃªu:** Chá»‰nh sá»­a Ã¢m thanh Ä‘Ã£ táº¡o báº±ng hÆ°á»›ng dáº«n ngÃ´n ngá»¯ tá»± nhiÃªn á»Ÿ cáº¥p Ä‘á»™ cao.\n\n![Tá»•ng quan ThinkSound](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig3_model.png)\n<!-- Má»™t bá»™ dá»¯ liá»‡u quy mÃ´ lá»›n Ä‘Æ°á»£c chÃº thÃ­ch theo CoT (**AudioCoT**) Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ huáº¥n luyá»‡n cáº£ module lÃ½ luáº­n vÃ  mÃ´ hÃ¬nh ná»n táº£ng Ã¢m thanh há»£p nháº¥t.\n![AudioCoT Pipeline](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig2_dataset.png) -->\n\n---\n\n## âš¡ Báº¯t Ä‘áº§u nhanh\n\n**Chuáº©n bá»‹ mÃ´i trÆ°á»ng:**\n```bash\ngit clone https://github.com/liuhuadai/ThinkSound.git\ncd ThinkSound\npip install -r requirements.txt\nconda install -y -c conda-forge 'ffmpeg<7'\n# Táº£i trá»ng sá»‘ Ä‘Ã£ huáº¥n luyá»‡n sáºµn https://huggingface.co/liuhuadai/ThinkSound vá» thÆ° má»¥c ckpts/\n# Trá»ng sá»‘ mÃ´ hÃ¬nh cÅ©ng cÃ³ thá»ƒ táº£i tá»« https://www.modelscope.cn/models/iic/ThinkSound\ngit lfs install\ngit clone https://huggingface.co/liuhuadai/ThinkSound ckpts\n```\n\n**Cáº¥p quyá»n thá»±c thi**\n```bash\nchmod +x scripts/demo.sh\n```\n\n**Cháº¡y script**\n```bash\n./scripts/demo.sh <video_path> <caption> <CoT description>\n```\n\n\n### Sá»­ dá»¥ng giao diá»‡n web\n\nÄá»ƒ cÃ³ tráº£i nghiá»‡m tÆ°Æ¡ng tÃ¡c, hÃ£y khá»Ÿi Ä‘á»™ng giao diá»‡n web Gradio:\n\n```bash\npython app.py\n```\n\n---",
  "status": "ok"
}