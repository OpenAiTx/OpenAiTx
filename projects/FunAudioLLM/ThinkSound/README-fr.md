# üé∂ ThinkSound

<p align="center">
  Si vous trouvez ce projet utile, une √©toile ‚≠ê sur GitHub serait grandement appr√©ci√©e !
</p>

<p align="center">
  <a href="https://arxiv.org/pdf/2506.21448">
    <img src="https://img.shields.io/badge/arXiv-2506.21448-b31b1b.svg" alt="arXiv"/>
  </a>
  &nbsp;
  <a href="https://thinksound-project.github.io/">
    <img src="https://img.shields.io/badge/Online%20Demo-üåê-blue" alt="Online Demo"/>
  </a>
  &nbsp;
  <a href="https://huggingface.co/spaces/FunAudioLLM/ThinkSound">
    <img src="https://img.shields.io/badge/HuggingFace-Spaces-orange?logo=huggingface" alt="Hugging Face"/>
  </a>
  &nbsp;
  <a href="https://modelscope.cn/studios/iic/ThinkSound">
    <img src="https://img.shields.io/badge/ModelScope-Âú®Á∫ø‰ΩìÈ™å-green" alt="ModelScope"/>
  </a>
</p>

---

**ThinkSound** est un cadre unifi√© de g√©n√©ration Any2Audio avec un guidage par appariement de flux bas√© sur le raisonnement Chain-of-Thought (CoT).

Impl√©mentation PyTorch pour la g√©n√©ration et l'√©dition audio multimodales : g√©n√©rez ou √©ditez de l‚Äôaudio √† partir de vid√©o, de texte et d‚Äôaudio, aliment√© par un raisonnement √©tape par √©tape provenant de Mod√®les de Langage Multimodaux de Grande Taille (MLLMs).

![Teaser](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig1_teaser.png)
---

## üì∞ Actualit√©s
- **2025.07** &nbsp; üî•D√©mo en ligne sur [Hugging Face Spaces](https://huggingface.co/spaces/FunAudioLLM/ThinkSound) et [ModelScope](https://modelscope.cn/studios/iic/ThinkSound) pour une exp√©rience interactive !
- **2025.07** &nbsp; üî•Scripts d‚Äôinf√©rence et interface web publi√©s ; 
- **2025.06** &nbsp; üî•[Article ThinkSound](https://arxiv.org/pdf/2506.21448) publi√© sur arXiv !
- **2025.06** &nbsp; üî•[D√©mo en ligne](http://thinksound-project.github.io/) disponible - essayez-la d√®s maintenant !

---

## üöÄ Fonctionnalit√©s

- **Any2Audio** : G√©n√©ration audio √† partir de modalit√©s arbitraires ‚Äî vid√©o, texte, audio, ou leurs combinaisons.
- **Vid√©o-vers-Audio SOTA** : R√©sultats √† la pointe de la technologie sur plusieurs benchmarks V2A.
- **Raisonnement guid√© par CoT** : Raisonnement Chain-of-Thought pour une g√©n√©ration audio compositionnelle et contr√¥lable via les MLLMs.
- **√âdition interactive centr√©e objet** : Affinez ou √©ditez des √©v√©nements sonores sp√©cifiques en cliquant sur des objets visuels ou via des instructions textuelles.
- **Cadre unifi√©** : Un mod√®le fondamental unique prend en charge la g√©n√©ration, l‚Äô√©dition et le flux de travail interactif.

---

## ‚ú® Aper√ßu de la m√©thode

ThinkSound d√©compose la g√©n√©ration et l‚Äô√©dition audio en trois √©tapes interactives, toutes guid√©es par le raisonnement Chain-of-Thought (CoT) bas√© sur les MLLMs :

1. **G√©n√©ration Foley :** G√©n√©rer des paysages sonores fondamentaux, s√©mantiquement et temporellement align√©s √† partir de la vid√©o.
2. **Affinement centr√© objet :** Affiner ou ajouter des sons pour des objets sp√©cifi√©s par l‚Äôutilisateur via des clics ou des r√©gions dans la vid√©o.
3. **√âdition audio cibl√©e :** Modifier l‚Äôaudio g√©n√©r√© √† l‚Äôaide d‚Äôinstructions en langage naturel de haut niveau.

![ThinkSound Overview](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig3_model.png)
<!-- Un jeu de donn√©es annot√© CoT √† grande √©chelle (**AudioCoT**) est utilis√© pour entra√Æner √† la fois le module de raisonnement et le mod√®le audio fondamental unifi√©.
![AudioCoT Pipeline](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig2_dataset.png) -->

---

## ‚ö° D√©marrage rapide

**Pr√©paration de l‚Äôenvironnement :**
```bash
git clone https://github.com/liuhuadai/ThinkSound.git
cd ThinkSound
pip install -r requirements.txt
conda install -y -c conda-forge 'ffmpeg<7'
# T√©l√©charger les poids pr√©-entra√Æn√©s https://huggingface.co/liuhuadai/ThinkSound dans le dossier ckpts/
# Les poids du mod√®le peuvent √©galement √™tre t√©l√©charg√©s depuis https://www.modelscope.cn/models/iic/ThinkSound
git lfs install
git clone https://huggingface.co/liuhuadai/ThinkSound ckpts
```

**Rendez-le ex√©cutable**
```bash
chmod +x scripts/demo.sh
```

**Lancer le script**
```bash
./scripts/demo.sh <chemin_vers_video> <l√©gende> <description_CoT>
```


### Utilisation de l‚Äôinterface web

Pour une exp√©rience interactive, lancez l‚Äôinterface web Gradio :

```bash
python app.py
```

---
## üìù √Ä FAIRE

- ‚òê Publier les scripts d'entra√Ænement pour les mod√®les ThinkSound
- ‚òê Ouvrir le code source du jeu de donn√©es AudioCoT et du pipeline automatis√©
- ‚òê Fournir une documentation d√©taill√©e et une r√©f√©rence API
- ‚òê Ajouter la prise en charge de modalit√©s suppl√©mentaires et de t√¢ches en aval

---

## üìÑ Licence

Ce projet est publi√© sous la [Licence Apache 2.0](LICENSE).

> **Remarque :**  
> Le code, les mod√®les et le jeu de donn√©es sont **uniquement destin√©s √† la recherche et √† l'√©ducation**.  
> **L'utilisation commerciale N'EST PAS autoris√©e.**
>
> Pour une licence commerciale, veuillez contacter les auteurs.

---

## üìñ Citation

Si ThinkSound vous est utile dans vos travaux ou recherches, veuillez citer notre article :

```bibtex
@misc{liu2025thinksoundchainofthoughtreasoningmultimodal,
      title={ThinkSound: Chain-of-Thought Reasoning in Multimodal Large Language Models for Audio Generation and Editing}, 
      author={Huadai Liu and Jialei Wang and Kaicheng Luo and Wen Wang and Qian Chen and Zhou Zhao and Wei Xue},
      year={2025},
      eprint={2506.21448},
      archivePrefix={arXiv},
      primaryClass={eess.AS},
      url={https://arxiv.org/abs/2506.21448}, 
}
```

---

## üì¨ Contact

‚ú® N'h√©sitez pas √† [ouvrir une issue](https://github.com/liuhuadai/ThinkSound/issues) ou √† nous contacter par e-mail ([liuhuadai@zju.edu.cn](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/mailto:liuhuadai@zju.edu.cn)) si vous avez des questions ou des suggestions !

---

Tranlated By [Open Ai Tx](https://github.com/OpenAiTx/OpenAiTx) | Last indexed: 2025-07-03

---