<h1 align="center">ThinkSound</h1>

<p align="center">
  üåê
  <a href="https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=en">English</a> |
  <a href="https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=zh-CN">ÁÆÄ‰Ωì‰∏≠Êñá</a> |
  <a href="https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=zh-TW">ÁπÅÈ´î‰∏≠Êñá</a> |
  <a href="https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=es">Espa√±ol</a> |
  <a href="https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=fr">Fran√ßais</a> |
  <a href="https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=ja">Êó•Êú¨Ë™û</a>
  
</p>

<p align="center">
  <a href="https://arxiv.org/pdf/2506.21448">
    <img src="https://img.shields.io/badge/arXiv-2506.21448-b31b1b.svg" alt="arXiv"/>
  </a>
  &nbsp;
  <a href="https://thinksound-project.github.io/">
    <img src="https://img.shields.io/badge/Online%20Demo-üåê-blue" alt="Online Demo"/>
  </a>
  &nbsp;
  <a href="https://huggingface.co/spaces/FunAudioLLM/ThinkSound">
    <img src="https://img.shields.io/badge/HuggingFace-Spaces-orange?logo=huggingface" alt="Hugging Face"/>
  </a>
  &nbsp;
  <a href="https://modelscope.cn/studios/iic/ThinkSound">
    <img src="https://img.shields.io/badge/ModelScope-Âú®Á∫ø‰ΩìÈ™å-green" alt="ModelScope"/>
  </a>
</p>

<p align="center">
  Si vous trouvez ce projet utile,<br>
  une √©toile ‚≠ê sur GitHub serait tr√®s appr√©ci√©e !
</p>

---

**ThinkSound** est un cadre unifi√© de g√©n√©ration Any2Audio avec correspondance de flux guid√©e par le raisonnement Chain-of-Thought (CoT).

Impl√©mentation PyTorch pour la g√©n√©ration et l'√©dition audio multimodales : g√©n√©rez ou √©ditez de l'audio √† partir de vid√©os, de texte et d'audio, propuls√© par un raisonnement √©tape par √©tape gr√¢ce aux grands mod√®les de langage multimodaux (MLLMs).

![Teaser](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig1_teaser.png)
---

## üì∞ Actualit√©s
- **2025.07.17** &nbsp; üß† Affinage activ√© : le code d'entra√Ænement et d'affinage est maintenant disponible publiquement, accompagn√© d'instructions claires pour vous aider √† personnaliser et √©tendre ThinkSound avec vos propres donn√©es.
- **2025.07.15** &nbsp; üì¶ Installation et utilisation simplifi√©es : d√©pendances sur PyPI pour une installation multiplateforme facile ; les scripts Windows `.bat` automatisent la cr√©ation d'environnement et l'ex√©cution des scripts.
- **2025.07.08** &nbsp;¬† üîß Mise √† jour majeure : mod√®le all√©g√© et optimisation de la m√©moire et de l'utilisation du GPU, supporte d√©sormais la g√©n√©ration audio √† haut d√©bit √† grande √©chelle !
- **2025.07.01** &nbsp; üî•D√©mo en ligne sur [Hugging Face Spaces](https://huggingface.co/spaces/FunAudioLLM/ThinkSound) et [ModelScope](https://modelscope.cn/studios/iic/ThinkSound) pour une exp√©rience interactive !
- **2025.07.01** &nbsp; üî•Scripts d'inf√©rence et interface web publi√©s ;
- **2025.06** &nbsp; üî•[Article ThinkSound](https://arxiv.org/pdf/2506.21448) publi√© sur arXiv !
- **2025.06** &nbsp; üî•[D√©mo en ligne](http://thinksound-project.github.io/) disponible - essayez-la d√®s maintenant !

---

## üöÄ Fonctionnalit√©s

- **Any2Audio** : G√©n√©rez de l'audio √† partir de n'importe quelle modalit√© ‚Äî vid√©o, texte, audio, ou leurs combinaisons.
- **Vid√©o-vers-Audio SOTA** : Obtient des r√©sultats √† la pointe de la technologie sur plusieurs benchmarks V2A.
- **Raisonnement pilot√© par CoT** : Raisonnement Chain-of-Thought pour une g√©n√©ration audio compositionnelle et contr√¥lable via les MLLMs.
- **√âdition interactive centr√©e sur les objets** : Affinez ou √©ditez des √©v√©nements sonores sp√©cifiques en cliquant sur des objets visuels ou en utilisant des instructions textuelles.
- **Cadre unifi√©** : Un mod√®le de base unique supporte la g√©n√©ration, l'√©dition et le flux de travail interactif.

---

## ‚ú® Vue d'ensemble de la m√©thode

ThinkSound d√©compose la g√©n√©ration et l'√©dition audio en trois √©tapes interactives, toutes guid√©es par le raisonnement Chain-of-Thought (CoT) bas√© sur les MLLMs :

1. **G√©n√©ration Foley :** G√©n√©rer des paysages sonores de base, s√©mantiquement et temporellement align√©s √† partir de la vid√©o.
2. **Affinage centr√© sur l'objet :** Affiner ou ajouter des sons pour des objets sp√©cifi√©s par l'utilisateur via des clics ou des r√©gions dans la vid√©o.
3. **√âdition audio cibl√©e :** Modifier l'audio g√©n√©r√© √† l'aide d'instructions en langage naturel de haut niveau.

![ThinkSound Overview](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig3_model.png)
<!-- Un jeu de donn√©es √† grande √©chelle annot√© CoT (**AudioCoT**) est utilis√© pour entra√Æner √† la fois le module de raisonnement et le mod√®le audio de base unifi√©.
![AudioCoT Pipeline](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig2_dataset.png) -->

---

## ‚ö° D√©marrage rapide

**Pr√©paration de l'environnement :**

```bash
git clone https://github.com/liuhuadai/ThinkSound.git
cd ThinkSound
conda create -n thinksound python=3.10
conda activate thinksound
pip install thinksound
conda install -y -c conda-forge 'ffmpeg<7'
# Download pretrained weights https://huggingface.co/liuhuadai/ThinkSound to Directory ckpts/
# model weights can be also downloaded from https://www.modelscope.cn/models/iic/ThinkSound
git lfs install
git clone https://huggingface.co/liuhuadai/ThinkSound ckpts
# To improve inference and training speed, you may optionally install a FlashAttention backend compatible with your system and PyTorch version.
```
> ‚úÖ **Astuce Windows :**  
> Les utilisateurs de Windows peuvent simplement ex√©cuter `setup_windows.bat` (ou double-cliquer dessus) pour cr√©er automatiquement l'environnement conda, installer toutes les d√©pendances (y compris FFmpeg) et t√©l√©charger le mod√®le pr√©-entra√Æn√© ‚Äî aucune configuration manuelle n'est requise.  
> Assurez-vous que `conda` et `git` sont install√©s et disponibles dans le PATH de votre syst√®me avant d'ex√©cuter le script.


### ‚ñ∂Ô∏è Ex√©cuter la d√©mo

#### **Linux/macOS**


```bash
chmod +x scripts/demo.sh
./scripts/demo.sh <path-to-your-demo-video> <title> <CoT description> [use-half]
```
#### **Windows**

Vous pouvez utiliser le script `.bat` fourni √† la place¬†:


```bash
.\scripts\demo.bat <path-to-your-demo-video> <title> <CoT description> [use-half]
```
**Remarque :**

* `<chemin-vers-votre-vid√©o-d√©mo>` : Le chemin vers une seule vid√©o
* `[utiliser-half]` (optionnel) : Ajoutez utiliser-half √† la fin pour activer l‚Äôextraction de caract√©ristiques en demi-pr√©cision.

---

### üì¶ Inf√©rence par lot

#### **Linux/macOS**


```bash
chmod +x scripts/eval_batch.sh
./scripts/eval_batch.sh <video_path> <csv_path> <save_path (optional)> [use-half]
```
#### **Windows**

Utilisez le script `.bat` √©quivalent¬†:


```bash
.\scripts\eval_batch.bat <video_path> <csv_path> <save_path (optional)> [use-half]
```
**Remarque :**

* `<video_path>` : Chemin vers le r√©pertoire racine contenant toutes les vid√©os .mp4 √† traiter (toutes les vid√©os doivent avoir la m√™me dur√©e).
* `<csv_path>` : Un fichier CSV avec les invites textuelles pour chaque vid√©o (voir `demo_test.csv` pour le format).
* `<save_path>` (optionnel) : Emplacement o√π enregistrer l'audio g√©n√©r√©. Par d√©faut `results/features`.
* `[use-half]` (optionnel) : Ajoutez use-half √† la fin pour activer l'extraction de caract√©ristiques en demi-pr√©cision.

---


### Utilisation de l‚Äôinterface Web

Pour une exp√©rience interactive, lancez l‚Äôinterface web Gradio :


```bash
python app.py
```
## üèãÔ∏è Entra√Æner le mod√®le

Voir [`Training.md`](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/docs/Training.md)


---

## üìù √Ä faire & Plans futurs
* - [ ] Open-source du jeu de donn√©es AudioCoT et pipeline automatis√© (Attendu avant le 23/07/2025)
* - [ ] Publication d‚Äôun mod√®le de base plus puissant couvrant plusieurs domaines pour offrir une cr√©ation foley plus engageante et immersive (Attendu pour fin ao√ªt 2025)
* - [ ] Ajouter la prise en charge de modalit√©s suppl√©mentaires et de t√¢ches aval (Attendu avant fin juillet 2025)
* - [ ] Publication de mod√®les √† diff√©rentes √©chelles (Attendu avant fin juillet 2025)
* - [x] Publication des scripts d'entra√Ænement pour les mod√®les ThinkSound
* - [x] Un guide de d√©marrage rapide convivial sous Windows
---


## üìÑ Licence

Ce projet est publi√© sous licence Apache 2.0.

> **Remarque :**
> Le code, les mod√®les et le jeu de donn√©es sont **uniquement destin√©s √† la recherche et √† l'√©ducation**.
> **L'utilisation commerciale n'est PAS autoris√©e.**
> Pour une licence commerciale, veuillez contacter les auteurs.

**üì¶ Composants tiers**

* **Stable Audio Open VAE** (par Stability AI) :
  Ce d√©p√¥t inclut un VAE affin√© √† partir de [Stable Audio Open](https://huggingface.co/stabilityai/stable-audio-open-1.0/), sous licence [Stability AI Community License](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/./third_party/LICENSE_StabilityAI.md).
  **L'utilisation commerciale et la redistribution n√©cessitent l'autorisation pr√©alable de Stability AI.**

* üìò **Tout le reste du code et des mod√®les** sont publi√©s sous licence Apache 2.0.

---

## Remerciements

Un grand merci √† :

* **stable-audio-tools** (par Stability AI) :
Pour avoir fourni un cadre facile √† utiliser pour la g√©n√©ration audio, ainsi que le module VAE et ses poids.
* **MMAudio** :
  Pour l‚Äôimpl√©mentation du backbone MM-DiT dans le domaine audio.

---

## üìñ Citation

Si ThinkSound vous a √©t√© utile dans vos recherches ou votre travail, veuillez citer notre article :



```bibtex
@misc{liu2025thinksoundchainofthoughtreasoningmultimodal,
      title={ThinkSound: Chain-of-Thought Reasoning in Multimodal Large Language Models for Audio Generation and Editing}, 
      author={Huadai Liu and Jialei Wang and Kaicheng Luo and Wen Wang and Qian Chen and Zhou Zhao and Wei Xue},
      year={2025},
      eprint={2506.21448},
      archivePrefix={arXiv},
      primaryClass={eess.AS},
      url={https://arxiv.org/abs/2506.21448}, 
}
```
---

## üì¨ Contact

‚ú® N'h√©sitez pas √† [ouvrir une issue](https://github.com/liuhuadai/ThinkSound/issues) ou √† nous contacter par email ([liuhuadai@zju.edu.cn](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/mailto:liuhuadai@zju.edu.cn)) si vous avez des questions ou des suggestions !


---

Tranlated By [Open Ai Tx](https://github.com/OpenAiTx/OpenAiTx) | Last indexed: 2025-07-17

---