[
  {
    "Id": 1,
    "Content": "<h1 align=\"center\">ThinkSound</h1>\n\n<p align=\"center\">\n  üåê\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=en\">English</a> |\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=zh-CN\">ÁÆÄ‰Ωì‰∏≠Êñá</a> |\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=zh-TW\">ÁπÅÈ´î‰∏≠Êñá</a> |\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=es\">Espa√±ol</a> |\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=fr\">Fran√ßais</a> |\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=ja\">Êó•Êú¨Ë™û</a>\n  \n</p>\n<p align=\"center\">\n  <img src=\"https://img.shields.io/badge/NeurIPS 2025-Main Conference-blue.svg\" alt=\"NeurIPS 2025\"/>\n<p align=\"center\">\n  <a href=\"https://arxiv.org/pdf/2506.21448\">\n    <img src=\"https://img.shields.io/badge/arXiv-2506.21448-b31b1b.svg\" alt=\"arXiv\"/>\n  </a>\n  &nbsp;\n  <a href=\"https://thinksound-project.github.io/\">\n    <img src=\"https://img.shields.io/badge/Online%20Demo-üåê-blue\" alt=\"Online Demo\"/>\n  </a>\n  &nbsp;\n  <a href=\"https://huggingface.co/spaces/FunAudioLLM/ThinkSound\">\n    <img src=\"https://img.shields.io/badge/HuggingFace-Spaces-orange?logo=huggingface\" alt=\"Hugging Face\"/>\n  </a>\n  &nbsp;\n  <a href=\"https://modelscope.cn/studios/iic/ThinkSound\">\n    <img src=\"https://img.shields.io/badge/ModelScope-Âú®Á∫ø‰ΩìÈ™å-green\" alt=\"ModelScope\"/>\n  </a>\n</p>\n\n<p align=\"center\">\n  If you find this project useful,<br>\n  a star ‚≠ê on GitHub would be greatly appreciated!\n</p>\n\n---\n\n**ThinkSound** is a unified Any2Audio generation framework with flow matching guided by Chain-of-Thought (CoT) reasoning.",
    "ContentSha": "3764VshEOMedejxsV+uo8k5R5Emk0MLuYfIOX8JadcY=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "<h1 align=\"center\">ThinkSound</h1>\n\n<p align=\"center\">\n  üåê\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=en\">English</a> |\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=zh-CN\">ÁÆÄ‰Ωì‰∏≠Êñá</a> |\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=zh-TW\">ÁπÅÈ´î‰∏≠Êñá</a> |\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=es\">Espa√±ol</a> |\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=fr\">Fran√ßais</a> |\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=ja\">Êó•Êú¨Ë™û</a>\n  \n</p>\n<p align=\"center\">\n  <img src=\"https://img.shields.io/badge/NeurIPS 2025-Main Conference-blue.svg\" alt=\"NeurIPS 2025\"/>\n<p align=\"center\">\n  <a href=\"https://arxiv.org/pdf/2506.21448\">\n    <img src=\"https://img.shields.io/badge/arXiv-2506.21448-b31b1b.svg\" alt=\"arXiv\"/>\n  </a>\n  &nbsp;\n  <a href=\"https://thinksound-project.github.io/\">\n    <img src=\"https://img.shields.io/badge/Online%20Demo-üåê-blue\" alt=\"Online Demo\"/>\n  </a>\n  &nbsp;\n  <a href=\"https://huggingface.co/spaces/FunAudioLLM/ThinkSound\">\n    <img src=\"https://img.shields.io/badge/HuggingFace-Spaces-orange?logo=huggingface\" alt=\"Hugging Face\"/>\n  </a>\n  &nbsp;\n  <a href=\"https://modelscope.cn/studios/iic/ThinkSound\">\n    <img src=\"https://img.shields.io/badge/ModelScope-Âú®Á∫ø‰ΩìÈ™å-green\" alt=\"ModelScope\"/>\n  </a>\n</p>\n\n<p align=\"center\">\n  –ï—Å–ª–∏ –≤—ã —Å—á–∏—Ç–∞–µ—Ç–µ —ç—Ç–æ—Ç –ø—Ä–æ–µ–∫—Ç –ø–æ–ª–µ–∑–Ω—ã–º,<br>\n  –∑–≤–µ–∑–¥–∞ ‚≠ê –Ω–∞ GitHub –±—É–¥–µ—Ç –æ—á–µ–Ω—å –ø—Ä–∏–∑–Ω–∞—Ç–µ–ª—å–Ω–∞!\n</p>\n\n---\n\n**ThinkSound** ‚Äî —ç—Ç–æ —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ Any2Audio —Å —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ–º –ø–æ—Ç–æ–∫–æ–≤, —É–ø—Ä–∞–≤–ª—è–µ–º–∞—è —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è–º–∏ –≤ —Å—Ç–∏–ª–µ Chain-of-Thought (CoT).",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 2,
    "Content": "\nPyTorch implementation for multimodal audio generation and editing: generate or edit audio from video, text, and audio, powered by step-by-step reasoning from Multimodal Large Language Models (MLLMs).\n\n![Teaser](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig1_teaser.png)\n---\n\n## üì∞ News\n- **2025.11.25** &nbsp; üî•[Online PrismAudio Demo](http://prismaudio-project.github.io/) is live - try it now!\n- **2025.11.25** &nbsp; üî•[PrismAudio paper](https://arxiv.org/pdf/2511.18833) released on arXiv, the first multi-dimensional CoT-RL framework for Video-to-Audio Generation!\n- **2025.09.19** &nbsp; üéâ ThinkSound has been accepted to the **NeurIPS 2025 Main Conference**!\n- **2025.09.01** &nbsp; Our AudioCoT dataset is now open-sourced and available on [Hugging Face](https://huggingface.co/datasets/liuhuadai/AudioCoT)!\n- **2025.07.17** &nbsp; üß† Finetuning enabled: training and finetuning code is now publicly available, along with clear usage instructions to help you customize and extend ThinkSound with your own data.\n- **2025.07.15** &nbsp; üì¶ Simplified installation and usability: dependencies on PyPI for easy cross-platform setup; Windows `.bat` scripts automate environment creation and script running.\n- **2025.07.08** &nbsp;¬† üîß Major update: model lightweighted and optimized memory and GPU usage, now supports high-throughput audio generation at scale!\n- **2025.07.01** &nbsp; Online demo on [Hugging Face Spaces](https://huggingface.co/spaces/FunAudioLLM/ThinkSound) and [ModelScope](https://modelscope.cn/studios/iic/ThinkSound) for interactive experience!\n- **2025.07.01** &nbsp; Released inference scripts and web interface; \n- **2025.06** &nbsp; [ThinkSound paper](https://arxiv.org/pdf/2506.21448) released on arXiv!\n- **2025.06** &nbsp; [Online Demo](http://thinksound-project.github.io/) is live - try it now!\n\n---\n\n\n## üöÄ Features\n\n- **Any2Audio**: Generate audio from arbitrary modalities ‚Äî video, text, audio, or their combinations.\n- **Video-to-Audio SOTA**: Achieves state-of-the-art results on multiple V2A benchmarks.\n- **CoT-Driven Reasoning**: Chain-of-Thought reasoning for compositional and controllable audio generation via MLLMs.\n- **Interactive Object-centric Editing**: Refine or edit specific sound events by clicking on visual objects or using text instructions.\n- **Unified Framework**: One foundation model supports generation, editing, and interactive workflow.\n\n---\n\n## ‚ú® Method Overview\n\nThinkSound decomposes audio generation and editing into three interactive stages, all guided by MLLM-based Chain-of-Thought (CoT) reasoning:\n\n1. **Foley Generation:** Generate foundational, semantically and temporally aligned soundscapes from video.\n2. **Object-Centric Refinement:** Refine or add sounds for user-specified objects via clicks or regions in the video.\n3. **Targeted Audio Editing:** Modify generated audio using high-level natural language instructions.\n",
    "ContentSha": "Vp81xeUGr9WCESp62x1lkoIptJHl0dM1R8kleL4V10c=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "\n–†–µ–∞–ª–∏–∑–∞—Ü–∏—è –Ω–∞ PyTorch –¥–ª—è –º–Ω–æ–≥–æ–º–æ–¥–∞–ª—å–Ω–æ–≥–æ –∞—É–¥–∏–æ–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–∏—è –∏ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: —Å–æ–∑–¥–∞–≤–∞–π—Ç–µ –∏–ª–∏ —Ä–µ–¥–∞–∫—Ç–∏—Ä—É–π—Ç–µ –∞—É–¥–∏–æ –ø–æ –≤–∏–¥–µ–æ, —Ç–µ–∫—Å—Ç—É –∏ –∞—É–¥–∏–æ, —Å –ø–æ—à–∞–≥–æ–≤—ã–º —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ–º –Ω–∞ –æ—Å–Ω–æ–≤–µ –ú—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –ë–æ–ª—å—à–∏—Ö –Ø–∑—ã–∫–æ–≤—ã—Ö –ú–æ–¥–µ–ª–µ–π (MLLM).\n\n![Teaser](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig1_teaser.png)\n---\n\n## üì∞ –ù–æ–≤–æ—Å—Ç–∏\n- **2025.11.25** &nbsp; üî•[–û–Ω–ª–∞–π–Ω –¥–µ–º–æ PrismAudio](http://prismaudio-project.github.io/) –¥–æ—Å—Ç—É–ø–Ω–æ ‚Äî –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–µ–π—á–∞—Å!\n- **2025.11.25** &nbsp; üî•[–°—Ç–∞—Ç—å—è –æ PrismAudio](https://arxiv.org/pdf/2511.18833) –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–∞ –Ω–∞ arXiv, –ø–µ—Ä–≤–∞—è –º–Ω–æ–≥–æ–º–µ—Ä–Ω–∞—è CoT-RL-–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∞—É–¥–∏–æ –∏–∑ –≤–∏–¥–µ–æ!\n- **2025.09.19** &nbsp; üéâ ThinkSound –ø—Ä–∏–Ω—è—Ç –Ω–∞ **NeurIPS 2025 Main Conference**!\n- **2025.09.01** &nbsp; –ù–∞—à –¥–∞—Ç–∞—Å–µ—Ç AudioCoT —Ç–µ–ø–µ—Ä—å –≤ –æ—Ç–∫—Ä—ã—Ç–æ–º –¥–æ—Å—Ç—É–ø–µ –Ω–∞ [Hugging Face](https://huggingface.co/datasets/liuhuadai/AudioCoT)!\n- **2025.07.17** &nbsp; üß† –î–æ—Å—Ç—É–ø–Ω–∞ –¥–æ–æ–±—É—á–∞–µ–º–æ—Å—Ç—å: –∫–æ–¥ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∏ –¥–æ–æ–±—É—á–µ–Ω–∏—è –æ—Ç–∫—Ä—ã—Ç, —Å –ø–æ–¥—Ä–æ–±–Ω–æ–π –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–µ–π –ø–æ –∫–∞—Å—Ç–æ–º–∏–∑–∞—Ü–∏–∏ –∏ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—é ThinkSound –Ω–∞ –≤–∞—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö.\n- **2025.07.15** &nbsp; üì¶ –£–ø—Ä–æ—â–µ–Ω–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∞ –∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ —á–µ—Ä–µ–∑ PyPI –¥–ª—è –ª–µ–≥–∫–æ–π –∫—Ä–æ—Å—Å–ø–ª–∞—Ç—Ñ–æ—Ä–º–µ–Ω–Ω–æ–π —É—Å—Ç–∞–Ω–æ–≤–∫–∏; Windows `.bat`-—Å–∫—Ä–∏–ø—Ç—ã –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä—É—é—Ç —Å–æ–∑–¥–∞–Ω–∏–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏ –∑–∞–ø—É—Å–∫.\n- **2025.07.08** &nbsp;¬† üîß –ö—Ä—É–ø–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ: –º–æ–¥–µ–ª—å –æ–±–ª–µ–≥—á–µ–Ω–∞, –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏ –∏ GPU, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –º–∞—Å—à—Ç–∞–±–Ω–æ–µ –≤—ã—Å–æ–∫–æ–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ–µ –∞—É–¥–∏–æ–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ!\n- **2025.07.01** &nbsp; –û–Ω–ª–∞–π–Ω-–¥–µ–º–æ –Ω–∞ [Hugging Face Spaces](https://huggingface.co/spaces/FunAudioLLM/ThinkSound) –∏ [ModelScope](https://modelscope.cn/studios/iic/ThinkSound) –¥–ª—è –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–π —Ä–∞–±–æ—Ç—ã!\n- **2025.07.01** &nbsp; –í—ã–ø—É—â–µ–Ω—ã —Å–∫—Ä–∏–ø—Ç—ã –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ –∏ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å; \n- **2025.06** &nbsp; [–°—Ç–∞—Ç—å—è –æ ThinkSound](https://arxiv.org/pdf/2506.21448) –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–∞ –Ω–∞ arXiv!\n- **2025.06** &nbsp; [–û–Ω–ª–∞–π–Ω-–¥–µ–º–æ](http://thinksound-project.github.io/) –¥–æ—Å—Ç—É–ø–Ω–æ ‚Äî –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–µ–π—á–∞—Å!\n\n---\n\n\n## üöÄ –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏\n\n- **Any2Audio**: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∞—É–¥–∏–æ –∏–∑ –ª—é–±—ã—Ö –º–æ–¥–∞–ª—å–Ω–æ—Å—Ç–µ–π ‚Äî –≤–∏–¥–µ–æ, —Ç–µ–∫—Å—Ç–∞, –∞—É–¥–∏–æ –∏–ª–∏ –∏—Ö –∫–æ–º–±–∏–Ω–∞—Ü–∏–π.\n- **Video-to-Audio SOTA**: –î–æ—Å—Ç–∏–∂–µ–Ω–∏–µ –ª—É—á—à–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –Ω–∞ —Ä—è–¥–µ V2A-–±–µ–Ω—á–º–∞—Ä–∫–æ–≤.\n- **CoT-—É–ø—Ä–∞–≤–ª—è–µ–º–æ–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ**: –ü–æ—à–∞–≥–æ–≤–æ–µ Chain-of-Thought —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ –¥–ª—è –∫–æ–º–ø–æ–∑–∏—Ü–∏–æ–Ω–Ω–æ–≥–æ –∏ —É–ø—Ä–∞–≤–ª—è–µ–º–æ–≥–æ –∞—É–¥–∏–æ–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–∏—è —á–µ—Ä–µ–∑ MLLM.\n- **–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–µ –æ–±—ä–µ–∫—Ç–Ω–æ-—Ü–µ–Ω—Ç—Ä–∏—á–Ω–æ–µ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ**: –î–µ—Ç–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ –∏–ª–∏ —Ä–µ–¥–∞–∫—Ç–∏—Ä—É–π—Ç–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –∑–≤—É–∫–æ–≤—ã–µ —Å–æ–±—ã—Ç–∏—è –ø–æ –∫–ª–∏–∫—É –Ω–∞ –≤–∏–∑—É–∞–ª—å–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–∞—Ö –∏–ª–∏ —Ç–µ–∫—Å—Ç–æ–≤—ã–º –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è–º.\n- **–ï–¥–∏–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞**: –û–¥–Ω–∞ –±–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏—é, —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—É—é —Ä–∞–±–æ—Ç—É.\n\n---\n\n## ‚ú® –û–±–∑–æ—Ä –º–µ—Ç–æ–¥–∞\n\nThinkSound —Ä–∞–∑–¥–µ–ª—è–µ—Ç –∑–∞–¥–∞—á–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∞—É–¥–∏–æ –Ω–∞ —Ç—Ä–∏ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã—Ö —ç—Ç–∞–ø–∞, –≤—Å–µ —É–ø—Ä–∞–≤–ª—è—é—Ç—Å—è Chain-of-Thought —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ–º –Ω–∞ –æ—Å–Ω–æ–≤–µ MLLM:\n\n1. **Foley-–≥–µ–Ω–µ—Ä–∞—Ü–∏—è:** –°–æ–∑–¥–∞–Ω–∏–µ –±–∞–∑–æ–≤—ã—Ö, —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏ –∏ –≤—Ä–µ–º–µ–Ω–Ω–æ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω—ã—Ö –∑–≤—É–∫–æ–≤—ã—Ö –ª–∞–Ω–¥—à–∞—Ñ—Ç–æ–≤ –ø–æ –≤–∏–¥–µ–æ.\n2. **–û–±—ä–µ–∫—Ç–Ω–æ-—Ü–µ–Ω—Ç—Ä–∏—á–Ω–∞—è –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è:** –î–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è –∏–ª–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –∑–≤—É–∫–æ–≤ –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º –æ–±—ä–µ–∫—Ç–æ–≤ —á–µ—Ä–µ–∑ –∫–ª–∏–∫–∏ –∏–ª–∏ –æ–±–ª–∞—Å—Ç–∏ –Ω–∞ –≤–∏–¥–µ–æ.\n3. **–¶–µ–ª–µ–≤–æ–µ –∞—É–¥–∏–æ—Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ:** –ú–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏—è —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∞—É–¥–∏–æ —Å –ø–æ–º–æ—â—å—é –≤—ã—Å–æ–∫–æ—É—Ä–æ–≤–Ω–µ–≤—ã—Ö –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π –Ω–∞ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–º —è–∑—ã–∫–µ.\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 2,
        "rowsha": "eexREJOMCITdo96Iwg4N4PQqu1ux/UwupfjVRj0l/L8=",
        "originContent": "PyTorch implementation for multimodal audio generation and editing: generate or edit audio from video, text, and audio, powered by step-by-step reasoning from Multimodal Large Language Models (MLLMs).",
        "translatedContent": "–†–µ–∞–ª–∏–∑–∞—Ü–∏—è –Ω–∞ PyTorch –¥–ª—è –º–Ω–æ–≥–æ–º–æ–¥–∞–ª—å–Ω–æ–≥–æ –∞—É–¥–∏–æ–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–∏—è –∏ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: —Å–æ–∑–¥–∞–≤–∞–π—Ç–µ –∏–ª–∏ —Ä–µ–¥–∞–∫—Ç–∏—Ä—É–π—Ç–µ –∞—É–¥–∏–æ –ø–æ –≤–∏–¥–µ–æ, —Ç–µ–∫—Å—Ç—É –∏ –∞—É–¥–∏–æ, —Å –ø–æ—à–∞–≥–æ–≤—ã–º —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ–º –Ω–∞ –æ—Å–Ω–æ–≤–µ –ú—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –ë–æ–ª—å—à–∏—Ö –Ø–∑—ã–∫–æ–≤—ã—Ö –ú–æ–¥–µ–ª–µ–π (MLLM)."
      },
      {
        "row": 3,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 4,
        "rowsha": "+7Cx1rdpWiIOeWRA/RM6HsKf7pNA3hHsQk2Bpadt4II=",
        "originContent": "![Teaser](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig1_teaser.png)",
        "translatedContent": "![Teaser](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig1_teaser.png)"
      },
      {
        "row": 5,
        "rowsha": "yz+R1U7uMOU+NbK5mQX3Dxae1Un9eJCdPawt78ntjTs=",
        "originContent": "---",
        "translatedContent": "---"
      },
      {
        "row": 6,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 7,
        "rowsha": "0YeCyxpcm7/4RDbaM+OQoI8YfqEHQzDkpGW15VZdi1U=",
        "originContent": "## üì∞ News",
        "translatedContent": "## üì∞ –ù–æ–≤–æ—Å—Ç–∏"
      },
      {
        "row": 8,
        "rowsha": "EeDKxV0PYB9iw6GxOqwnsP3C385ykbqk8PtEVoVhAcc=",
        "originContent": "- **2025.11.25** &nbsp; üî•[Online PrismAudio Demo](http://prismaudio-project.github.io/) is live - try it now!",
        "translatedContent": "- **2025.11.25** &nbsp; üî•[–û–Ω–ª–∞–π–Ω –¥–µ–º–æ PrismAudio](http://prismaudio-project.github.io/) –¥–æ—Å—Ç—É–ø–Ω–æ ‚Äî –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–µ–π—á–∞—Å!"
      },
      {
        "row": 9,
        "rowsha": "Q6c68QE34xLPSZ5xAL4zofEn/u8umRYYiH3ddCcy5vk=",
        "originContent": "- **2025.11.25** &nbsp; üî•[PrismAudio paper](https://arxiv.org/pdf/2511.18833) released on arXiv, the first multi-dimensional CoT-RL framework for Video-to-Audio Generation!",
        "translatedContent": "- **2025.11.25** &nbsp; üî•[–°—Ç–∞—Ç—å—è –æ PrismAudio](https://arxiv.org/pdf/2511.18833) –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–∞ –Ω–∞ arXiv, –ø–µ—Ä–≤–∞—è –º–Ω–æ–≥–æ–º–µ—Ä–Ω–∞—è CoT-RL-–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∞—É–¥–∏–æ –∏–∑ –≤–∏–¥–µ–æ!"
      },
      {
        "row": 10,
        "rowsha": "vj2hbV/6MacDcxRmFA0AtTog5xU6CHoqBFO3YMO+yJo=",
        "originContent": "- **2025.09.19** &nbsp; üéâ ThinkSound has been accepted to the **NeurIPS 2025 Main Conference**!",
        "translatedContent": "- **2025.09.19** &nbsp; üéâ ThinkSound –ø—Ä–∏–Ω—è—Ç –Ω–∞ **NeurIPS 2025 Main Conference**!"
      },
      {
        "row": 11,
        "rowsha": "+guVQwDlJDqR1pBGMGc4FQ11nryItaEtKQ3etaCBcn0=",
        "originContent": "- **2025.09.01** &nbsp; Our AudioCoT dataset is now open-sourced and available on [Hugging Face](https://huggingface.co/datasets/liuhuadai/AudioCoT)!",
        "translatedContent": "- **2025.09.01** &nbsp; –ù–∞—à –¥–∞—Ç–∞—Å–µ—Ç AudioCoT —Ç–µ–ø–µ—Ä—å –≤ –æ—Ç–∫—Ä—ã—Ç–æ–º –¥–æ—Å—Ç—É–ø–µ –Ω–∞ [Hugging Face](https://huggingface.co/datasets/liuhuadai/AudioCoT)!"
      },
      {
        "row": 12,
        "rowsha": "4Jq9g83O8cYV4fVKsetfTpI+JrSepLrjK6J7Xg9tSqo=",
        "originContent": "- **2025.07.17** &nbsp; üß† Finetuning enabled: training and finetuning code is now publicly available, along with clear usage instructions to help you customize and extend ThinkSound with your own data.",
        "translatedContent": "- **2025.07.17** &nbsp; üß† –î–æ—Å—Ç—É–ø–Ω–∞ –¥–æ–æ–±—É—á–∞–µ–º–æ—Å—Ç—å: –∫–æ–¥ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∏ –¥–æ–æ–±—É—á–µ–Ω–∏—è –æ—Ç–∫—Ä—ã—Ç, —Å –ø–æ–¥—Ä–æ–±–Ω–æ–π –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–µ–π –ø–æ –∫–∞—Å—Ç–æ–º–∏–∑–∞—Ü–∏–∏ –∏ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—é ThinkSound –Ω–∞ –≤–∞—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö."
      },
      {
        "row": 13,
        "rowsha": "Ae5w+cTrCd9E8qidC11IWJAgg+LuOgUxA4czDPNG/G0=",
        "originContent": "- **2025.07.15** &nbsp; üì¶ Simplified installation and usability: dependencies on PyPI for easy cross-platform setup; Windows `.bat` scripts automate environment creation and script running.",
        "translatedContent": "- **2025.07.15** &nbsp; üì¶ –£–ø—Ä–æ—â–µ–Ω–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∞ –∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ —á–µ—Ä–µ–∑ PyPI –¥–ª—è –ª–µ–≥–∫–æ–π –∫—Ä–æ—Å—Å–ø–ª–∞—Ç—Ñ–æ—Ä–º–µ–Ω–Ω–æ–π —É—Å—Ç–∞–Ω–æ–≤–∫–∏; Windows `.bat`-—Å–∫—Ä–∏–ø—Ç—ã –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä—É—é—Ç —Å–æ–∑–¥–∞–Ω–∏–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏ –∑–∞–ø—É—Å–∫."
      },
      {
        "row": 14,
        "rowsha": "nYxNhwgSqjwYLuWsfHAqP5sx2PnzYwoFrwcf9U+Fdss=",
        "originContent": "- **2025.07.08** &nbsp;¬† üîß Major update: model lightweighted and optimized memory and GPU usage, now supports high-throughput audio generation at scale!",
        "translatedContent": "- **2025.07.08** &nbsp;¬† üîß –ö—Ä—É–ø–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ: –º–æ–¥–µ–ª—å –æ–±–ª–µ–≥—á–µ–Ω–∞, –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏ –∏ GPU, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –º–∞—Å—à—Ç–∞–±–Ω–æ–µ –≤—ã—Å–æ–∫–æ–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ–µ –∞—É–¥–∏–æ–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ!"
      },
      {
        "row": 15,
        "rowsha": "RPL6cU3/Jgu90ib4PkeN5Q/ALrnjq9hK0ZUCranb/PA=",
        "originContent": "- **2025.07.01** &nbsp; Online demo on [Hugging Face Spaces](https://huggingface.co/spaces/FunAudioLLM/ThinkSound) and [ModelScope](https://modelscope.cn/studios/iic/ThinkSound) for interactive experience!",
        "translatedContent": "- **2025.07.01** &nbsp; –û–Ω–ª–∞–π–Ω-–¥–µ–º–æ –Ω–∞ [Hugging Face Spaces](https://huggingface.co/spaces/FunAudioLLM/ThinkSound) –∏ [ModelScope](https://modelscope.cn/studios/iic/ThinkSound) –¥–ª—è –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–π —Ä–∞–±–æ—Ç—ã!"
      },
      {
        "row": 16,
        "rowsha": "0PEL3eOyUmX2U56FPEPvYfaltZ/P/wbH0uO6GcLPlUE=",
        "originContent": "- **2025.07.01** &nbsp; Released inference scripts and web interface; ",
        "translatedContent": "- **2025.07.01** &nbsp; –í—ã–ø—É—â–µ–Ω—ã —Å–∫—Ä–∏–ø—Ç—ã –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ –∏ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å; "
      },
      {
        "row": 17,
        "rowsha": "XNdJ/DN741rXoJAruiGiRueQILXIUHRXzBlp+HVWM88=",
        "originContent": "- **2025.06** &nbsp; [ThinkSound paper](https://arxiv.org/pdf/2506.21448) released on arXiv!",
        "translatedContent": "- **2025.06** &nbsp; [–°—Ç–∞—Ç—å—è –æ ThinkSound](https://arxiv.org/pdf/2506.21448) –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–∞ –Ω–∞ arXiv!"
      },
      {
        "row": 18,
        "rowsha": "W45oflUmoUAksoDc1WjcR2hErqh9UIi738PFVipiDg0=",
        "originContent": "- **2025.06** &nbsp; [Online Demo](http://thinksound-project.github.io/) is live - try it now!",
        "translatedContent": "- **2025.06** &nbsp; [–û–Ω–ª–∞–π–Ω-–¥–µ–º–æ](http://thinksound-project.github.io/) –¥–æ—Å—Ç—É–ø–Ω–æ ‚Äî –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–µ–π—á–∞—Å!"
      },
      {
        "row": 19,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 20,
        "rowsha": "yz+R1U7uMOU+NbK5mQX3Dxae1Un9eJCdPawt78ntjTs=",
        "originContent": "---",
        "translatedContent": "---"
      },
      {
        "row": 21,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 22,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 23,
        "rowsha": "f4oQIFLM2EJQxJ65F4oMEA7yWOIqs0eBtiIvGxI+GgI=",
        "originContent": "## üöÄ Features",
        "translatedContent": "## üöÄ –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏"
      },
      {
        "row": 24,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 25,
        "rowsha": "8TbVluJJPR3C0fX41HklpO/vH9/k/rHC+jlvmHHfzQU=",
        "originContent": "- **Any2Audio**: Generate audio from arbitrary modalities ‚Äî video, text, audio, or their combinations.",
        "translatedContent": "- **Any2Audio**: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∞—É–¥–∏–æ –∏–∑ –ª—é–±—ã—Ö –º–æ–¥–∞–ª—å–Ω–æ—Å—Ç–µ–π ‚Äî –≤–∏–¥–µ–æ, —Ç–µ–∫—Å—Ç–∞, –∞—É–¥–∏–æ –∏–ª–∏ –∏—Ö –∫–æ–º–±–∏–Ω–∞—Ü–∏–π."
      },
      {
        "row": 26,
        "rowsha": "+Jf5LrYz+d1ShYCuQe8UF9taEJUpuGhDk6fAlYK3Kj4=",
        "originContent": "- **Video-to-Audio SOTA**: Achieves state-of-the-art results on multiple V2A benchmarks.",
        "translatedContent": "- **Video-to-Audio SOTA**: –î–æ—Å—Ç–∏–∂–µ–Ω–∏–µ –ª—É—á—à–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –Ω–∞ —Ä—è–¥–µ V2A-–±–µ–Ω—á–º–∞—Ä–∫–æ–≤."
      },
      {
        "row": 27,
        "rowsha": "mU7qXkjW1YifKoYXJedYo9l64NsTBaiXsgoGFRF/g+E=",
        "originContent": "- **CoT-Driven Reasoning**: Chain-of-Thought reasoning for compositional and controllable audio generation via MLLMs.",
        "translatedContent": "- **CoT-—É–ø—Ä–∞–≤–ª—è–µ–º–æ–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ**: –ü–æ—à–∞–≥–æ–≤–æ–µ Chain-of-Thought —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ –¥–ª—è –∫–æ–º–ø–æ–∑–∏—Ü–∏–æ–Ω–Ω–æ–≥–æ –∏ —É–ø—Ä–∞–≤–ª—è–µ–º–æ–≥–æ –∞—É–¥–∏–æ–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–∏—è —á–µ—Ä–µ–∑ MLLM."
      },
      {
        "row": 28,
        "rowsha": "RComOCBBrXsZf9RHmLginqKTh9eI/bKUZuUunQEmD5M=",
        "originContent": "- **Interactive Object-centric Editing**: Refine or edit specific sound events by clicking on visual objects or using text instructions.",
        "translatedContent": "- **–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–µ –æ–±—ä–µ–∫—Ç–Ω–æ-—Ü–µ–Ω—Ç—Ä–∏—á–Ω–æ–µ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ**: –î–µ—Ç–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ –∏–ª–∏ —Ä–µ–¥–∞–∫—Ç–∏—Ä—É–π—Ç–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –∑–≤—É–∫–æ–≤—ã–µ —Å–æ–±—ã—Ç–∏—è –ø–æ –∫–ª–∏–∫—É –Ω–∞ –≤–∏–∑—É–∞–ª—å–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–∞—Ö –∏–ª–∏ —Ç–µ–∫—Å—Ç–æ–≤—ã–º –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è–º."
      },
      {
        "row": 29,
        "rowsha": "C3sf87sy73G/XZft+TDo5NjXo5XcrtJB805ayHRAXoQ=",
        "originContent": "- **Unified Framework**: One foundation model supports generation, editing, and interactive workflow.",
        "translatedContent": "- **–ï–¥–∏–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞**: –û–¥–Ω–∞ –±–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏—é, —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—É—é —Ä–∞–±–æ—Ç—É."
      },
      {
        "row": 30,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 31,
        "rowsha": "yz+R1U7uMOU+NbK5mQX3Dxae1Un9eJCdPawt78ntjTs=",
        "originContent": "---",
        "translatedContent": "---"
      },
      {
        "row": 32,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 33,
        "rowsha": "gjgLOIAU2x83BBZdLUdgEB+F64ajt/QuLYQXM1hDBLE=",
        "originContent": "## ‚ú® Method Overview",
        "translatedContent": "## ‚ú® –û–±–∑–æ—Ä –º–µ—Ç–æ–¥–∞"
      },
      {
        "row": 34,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 35,
        "rowsha": "v5//GqG/smYIGoUpN+12k+9/3GWH3GdYD+jLqScb7AM=",
        "originContent": "ThinkSound decomposes audio generation and editing into three interactive stages, all guided by MLLM-based Chain-of-Thought (CoT) reasoning:",
        "translatedContent": "ThinkSound —Ä–∞–∑–¥–µ–ª—è–µ—Ç –∑–∞–¥–∞—á–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∞—É–¥–∏–æ –Ω–∞ —Ç—Ä–∏ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã—Ö —ç—Ç–∞–ø–∞, –≤—Å–µ —É–ø—Ä–∞–≤–ª—è—é—Ç—Å—è Chain-of-Thought —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ–º –Ω–∞ –æ—Å–Ω–æ–≤–µ MLLM:"
      },
      {
        "row": 36,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 37,
        "rowsha": "vTObEWb7f5gCU681X3dTkwqhsaSW89TLw3GgMJ5I3bo=",
        "originContent": "1. **Foley Generation:** Generate foundational, semantically and temporally aligned soundscapes from video.",
        "translatedContent": "1. **Foley-–≥–µ–Ω–µ—Ä–∞—Ü–∏—è:** –°–æ–∑–¥–∞–Ω–∏–µ –±–∞–∑–æ–≤—ã—Ö, —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏ –∏ –≤—Ä–µ–º–µ–Ω–Ω–æ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω—ã—Ö –∑–≤—É–∫–æ–≤—ã—Ö –ª–∞–Ω–¥—à–∞—Ñ—Ç–æ–≤ –ø–æ –≤–∏–¥–µ–æ."
      },
      {
        "row": 38,
        "rowsha": "LTBpIQQHtEkNF8StAa+ZEDASGmRhmHIKDQOdZ4ExJWM=",
        "originContent": "2. **Object-Centric Refinement:** Refine or add sounds for user-specified objects via clicks or regions in the video.",
        "translatedContent": "2. **–û–±—ä–µ–∫—Ç–Ω–æ-—Ü–µ–Ω—Ç—Ä–∏—á–Ω–∞—è –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è:** –î–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è –∏–ª–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –∑–≤—É–∫–æ–≤ –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º –æ–±—ä–µ–∫—Ç–æ–≤ —á–µ—Ä–µ–∑ –∫–ª–∏–∫–∏ –∏–ª–∏ –æ–±–ª–∞—Å—Ç–∏ –Ω–∞ –≤–∏–¥–µ–æ."
      },
      {
        "row": 39,
        "rowsha": "8wrAo7X7dPC6Sgpfrlq2ziv/Wg/3+JnlFYvO+RMxADQ=",
        "originContent": "3. **Targeted Audio Editing:** Modify generated audio using high-level natural language instructions.",
        "translatedContent": "3. **–¶–µ–ª–µ–≤–æ–µ –∞—É–¥–∏–æ—Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ:** –ú–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏—è —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∞—É–¥–∏–æ —Å –ø–æ–º–æ—â—å—é –≤—ã—Å–æ–∫–æ—É—Ä–æ–≤–Ω–µ–≤—ã—Ö –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π –Ω–∞ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–º —è–∑—ã–∫–µ."
      },
      {
        "row": 40,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 3,
    "Content": "![ThinkSound Overview](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig3_model.png)\n<!-- A large-scale CoT-annotated dataset (**AudioCoT**) is used to train both the reasoning module and the unified audio foundation model.\n![AudioCoT Pipeline](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig2_dataset.png) -->\n\n---\n\n## ‚ö° Quick Start\n\n**Environment Preparation:**",
    "ContentSha": "QpULU62syvvJhbUWGR7NuQMiHmHmeeiFfKqP+ZpqFOk=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "![–û–±–∑–æ—Ä ThinkSound](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig3_model.png)\n<!-- –ö—Ä—É–ø–Ω–æ–º–∞—Å—à—Ç–∞–±–Ω—ã–π –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö —Å –∞–Ω–Ω–æ—Ç–∞—Ü–∏—è–º–∏ CoT (**AudioCoT**) –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∫–∞–∫ –º–æ–¥—É–ª—è —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π, —Ç–∞–∫ –∏ –µ–¥–∏–Ω–æ–π –∞—É–¥–∏–æ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏.\n![–ö–æ–Ω–≤–µ–π–µ—Ä AudioCoT](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig2_dataset.png) -->\n\n---\n\n## ‚ö° –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç\n\n**–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Å—Ä–µ–¥—ã:**",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "4UKlvFW3Xb0bSAVjcBNeekH/MMiYS0XDg9w4mCuPy/Q=",
        "originContent": "![ThinkSound Overview](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig3_model.png)",
        "translatedContent": "![–û–±–∑–æ—Ä ThinkSound](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig3_model.png)"
      },
      {
        "row": 2,
        "rowsha": "GaujeIM3x7+YcFy07LNNyITlujhkgpgeIaOiKHJkYnE=",
        "originContent": "<!-- A large-scale CoT-annotated dataset (**AudioCoT**) is used to train both the reasoning module and the unified audio foundation model.",
        "translatedContent": "<!-- –ö—Ä—É–ø–Ω–æ–º–∞—Å—à—Ç–∞–±–Ω—ã–π –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö —Å –∞–Ω–Ω–æ—Ç–∞—Ü–∏—è–º–∏ CoT (**AudioCoT**) –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∫–∞–∫ –º–æ–¥—É–ª—è —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π, —Ç–∞–∫ –∏ –µ–¥–∏–Ω–æ–π –∞—É–¥–∏–æ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏."
      },
      {
        "row": 3,
        "rowsha": "qYOXaaTiYkoaPFcpTXE5xdSqqiW3ebi//EW/RfSXd9g=",
        "originContent": "![AudioCoT Pipeline](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig2_dataset.png) -->",
        "translatedContent": "![–ö–æ–Ω–≤–µ–π–µ—Ä AudioCoT](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig2_dataset.png) -->"
      },
      {
        "row": 4,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 5,
        "rowsha": "yz+R1U7uMOU+NbK5mQX3Dxae1Un9eJCdPawt78ntjTs=",
        "originContent": "---",
        "translatedContent": "---"
      },
      {
        "row": 6,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 7,
        "rowsha": "PrY/jc4yAHdS+Sr+s+Yhab477/BDp3GAzMJ8+WyumyI=",
        "originContent": "## ‚ö° Quick Start",
        "translatedContent": "## ‚ö° –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç"
      },
      {
        "row": 8,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 9,
        "rowsha": "mD63DGEpdc7FlccTEps0KPAiwsJpO/C3yjV+SKIi/vE=",
        "originContent": "**Environment Preparation:**",
        "translatedContent": "**–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Å—Ä–µ–¥—ã:**"
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 4,
    "Content": "```bash\ngit clone https://github.com/liuhuadai/ThinkSound.git\ncd ThinkSound\nconda create -n thinksound python=3.10\nconda activate thinksound\npip install thinksound\nconda install -y -c conda-forge 'ffmpeg<7'\n# Download pretrained weights https://huggingface.co/liuhuadai/ThinkSound to Directory ckpts/\n# model weights can be also downloaded from https://www.modelscope.cn/models/iic/ThinkSound\ngit lfs install\ngit clone https://huggingface.co/liuhuadai/ThinkSound ckpts\n# To improve inference and training speed, you may optionally install a FlashAttention backend compatible with your system and PyTorch version.\n```",
    "ContentSha": "CSBCDvBmuatxDa1cNMeHEBTJJzdLjK6wyO9v0LrETM8=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\ngit clone https://github.com/liuhuadai/ThinkSound.git\ncd ThinkSound\nconda create -n thinksound python=3.10\nconda activate thinksound\npip install thinksound\nconda install -y -c conda-forge 'ffmpeg<7'\n# Download pretrained weights https://huggingface.co/liuhuadai/ThinkSound to Directory ckpts/\n# model weights can be also downloaded from https://www.modelscope.cn/models/iic/ThinkSound\ngit lfs install\ngit clone https://huggingface.co/liuhuadai/ThinkSound ckpts\n# To improve inference and training speed, you may optionally install a FlashAttention backend compatible with your system and PyTorch version.\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 5,
    "Content": "\n> ‚úÖ **Windows Tip:**  \n> Windows users can simply run `setup_windows.bat` (or double-click it) to automatically create the conda environment, install all dependencies (including FFmpeg), and download the pretrained model ‚Äî no manual setup required.  \n> Make sure `conda` and `git` are installed and available in your system PATH before running the script.\n\n\n### ‚ñ∂Ô∏è Run the Demo\n\n#### **Linux/macOS**\n",
    "ContentSha": "YGhm7lbBNPq6xLS6zXlFTPszO8rc4QZCwsScPNskcto=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "> ‚úÖ **–°–æ–≤–µ—Ç –¥–ª—è Windows:**  \n> –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ Windows –º–æ–≥—É—Ç –ø—Ä–æ—Å—Ç–æ –∑–∞–ø—É—Å—Ç–∏—Ç—å `setup_windows.bat` (–∏–ª–∏ –¥–≤–∞–∂–¥—ã —â–µ–ª–∫–Ω—É—Ç—å –ø–æ –Ω–µ–º—É), —á—Ç–æ–±—ã –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–æ–∑–¥–∞—Ç—å —Å—Ä–µ–¥—É conda, —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –≤—Å–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ (–≤–∫–ª—é—á–∞—è FFmpeg) –∏ –∑–∞–≥—Ä—É–∑–∏—Ç—å –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å ‚Äî –Ω–∏–∫–∞–∫–æ–π —Ä—É—á–Ω–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è.  \n> –ü–µ—Ä–µ–¥ –∑–∞–ø—É—Å–∫–æ–º —Å–∫—Ä–∏–ø—Ç–∞ —É–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ `conda` –∏ `git` —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã –∏ –¥–æ—Å—Ç—É–ø–Ω—ã –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π PATH –≤–∞—à–µ–π —Å–∏—Å—Ç–µ–º—ã.\n\n\n### ‚ñ∂Ô∏è –ó–∞–ø—É—Å–∫ –¥–µ–º–æ\n\n#### **Linux/macOS**\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 6,
    "Content": "```bash\nchmod +x scripts/demo.sh\n./scripts/demo.sh <path-to-your-demo-video> <title> <CoT description> [use-half]\n```",
    "ContentSha": "EW6OKf+6hdOehT5SO7gfI7wR8oAoMckp60MRfIA1jHc=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\nchmod +x scripts/demo.sh\n./scripts/demo.sh <path-to-your-demo-video> <title> <CoT description> [use-half]\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 7,
    "Content": "\n#### **Windows**\n\nYou can use the provided `.bat` script instead:\n",
    "ContentSha": "zXqRZWTEWOuKZG1GOlqqZff+IH24zUwdPtSfwESqS9E=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "#### **Windows**\n\n–í–º–µ—Å—Ç–æ —ç—Ç–æ–≥–æ –≤—ã –º–æ–∂–µ—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π —Å–∫—Ä–∏–ø—Ç `.bat`:\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 8,
    "Content": "```bash\n.\\scripts\\demo.bat <path-to-your-demo-video> <title> <CoT description> [use-half]\n```",
    "ContentSha": "A2a1kVuIPNs8ht1a6LBYTEijJjnfjiTN0r+2n7VEJSg=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\n.\\scripts\\demo.bat <path-to-your-demo-video> <title> <CoT description> [use-half]\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 9,
    "Content": "\n**Note:**\n\n* `<path-to-your-demo-video>`: The path to a single video\n* `[use-half]` (optional): Add use-half at the end to enable half precision feature extraction.\n\n---\n\n### üì¶ Batch Inference\n\n#### **Linux/macOS**\n",
    "ContentSha": "T7owm3ZZW7sVjKwFivgiuYX2+RVuNBl0RYTSnIcxxbM=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "**–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ:**\n\n* `<path-to-your-demo-video>`: –ü—É—Ç—å –∫ –æ–¥–Ω–æ–º—É –≤–∏–¥–µ–æ\n* `[use-half]` (–Ω–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ): –î–æ–±–∞–≤—å—Ç–µ use-half –≤ –∫–æ–Ω—Ü–µ –¥–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –≤ –ø–æ–ª–æ–≤–∏–Ω–Ω–æ–π —Ç–æ—á–Ω–æ—Å—Ç–∏.\n\n---\n\n### üì¶ –ü–∞–∫–µ—Ç–Ω—ã–π –≤—ã–≤–æ–¥\n\n#### **Linux/macOS**\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 10,
    "Content": "```bash\nchmod +x scripts/eval_batch.sh\n./scripts/eval_batch.sh <video_path> <csv_path> <save_path (optional)> [use-half]\n```",
    "ContentSha": "EQ4HuSYii55aHfgphESvOXMz2+Fq39+Xquxg6Z6uzdU=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\nchmod +x scripts/eval_batch.sh\n./scripts/eval_batch.sh <video_path> <csv_path> <save_path (optional)> [use-half]\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 11,
    "Content": "\n#### **Windows**\n\nUse the equivalent `.bat` script:\n",
    "ContentSha": "njm5i6o3MR7AV4Q3WLctbe3LN1njFn89fPfTlo+zSmc=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "#### **Windows**\n\n–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —ç–∫–≤–∏–≤–∞–ª–µ–Ω—Ç–Ω—ã–π —Å–∫—Ä–∏–ø—Ç `.bat`:\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 12,
    "Content": "```bash\n.\\scripts\\eval_batch.bat <video_path> <csv_path> <save_path (optional)> [use-half]\n```",
    "ContentSha": "XLkAqxYBZeJiF6XnpshI6naENFsr5yFAH7af132cgb0=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\n.\\scripts\\eval_batch.bat <video_path> <csv_path> <save_path (optional)> [use-half]\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 13,
    "Content": "\n**Note:**\n\n* `<video_path>`: Path to the root directory containing all .mp4 videos to be processed (all videos must be of equal duration).\n* `<csv_path>`: A CSV file with text prompts for each video (see `demo_test.csv` for format).\n* `<save_path>` (optional): Where to save generated audio. Defaults to `results/features`.\n* `[use-half]` (optional): Add use-half at the end to enable half precision feature extraction.\n\n---\n\n\n### Web Interface Usage\n\nFor an interactive experience, launch the Gradio web interface:\n",
    "ContentSha": "yT/y6PXpYV8wS4qmKJfVNVGDLOwreTxCdCDFDv2VbLo=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "**–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ:**\n\n* `<video_path>`: –ü—É—Ç—å –∫ –∫–æ—Ä–Ω–µ–≤–æ–º—É –∫–∞—Ç–∞–ª–æ–≥—É, —Å–æ–¥–µ—Ä–∂–∞—â–µ–º—É –≤—Å–µ .mp4 –≤–∏–¥–µ–æ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ (–≤—Å–µ –≤–∏–¥–µ–æ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –æ–¥–∏–Ω–∞–∫–æ–≤–æ–π –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏).\n* `<csv_path>`: CSV-—Ñ–∞–π–ª —Å —Ç–µ–∫—Å—Ç–æ–≤—ã–º–∏ –ø–æ–¥—Å–∫–∞–∑–∫–∞–º–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –≤–∏–¥–µ–æ (—Å–º. —Ñ–æ—Ä–º–∞—Ç –≤ `demo_test.csv`).\n* `<save_path>` (–Ω–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ): –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∞—É–¥–∏–æ. –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é `results/features`.\n* `[use-half]` (–Ω–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ): –î–æ–±–∞–≤—å—Ç–µ use-half –≤ –∫–æ–Ω—Ü–µ –¥–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –≤ –ø–æ–ª–æ–≤–∏–Ω–Ω–æ–π —Ç–æ—á–Ω–æ—Å—Ç–∏.\n\n---\n\n### –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞\n\n–î–ª—è –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–π —Ä–∞–±–æ—Ç—ã –∑–∞–ø—É—Å—Ç–∏—Ç–µ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å Gradio:\n\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 14,
    "Content": "```bash\npython app.py\n```",
    "ContentSha": "2nQFYMHYtsOO4+egbu20DhxqoaxfzoH8CneeM8qTEb0=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\npython app.py\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 15,
    "Content": "\n\n## üèãÔ∏è Train the Model\n\nSee [`Training.md`](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/docs/Training.md)\n\n\n---\n\n## üìù TODO & Future Plans\n* - [ ] Release a more powerful foundation model covering multiple domains to provide more engaging and immersive foley creation\n* - [ ] Add support for additional modalities and downstream tasks\n* - [ ] Release models at different scales\n* - [x] Open-source AudioCoT dataset and automated pipeline\n* - [x] Release training scripts for ThinkSound models\n* - [x] A beginner-friendly Windows quick-start README\n---\n\n\n## üìÑ License\n\nThis project is released under the Apache 2.0 License.\n\n> **Note:**\n> The code, models, and dataset are **for research and educational purposes only**.\n> **Commercial use is NOT permitted.**\n> For commercial licensing, please contact the authors.\n\n**üì¶ Third-Party Components**\n\n* **Stable Audio Open VAE** (by Stability AI):\n  This repository includes a fine-tuned VAE from [Stable Audio Open](https://huggingface.co/stabilityai/stable-audio-open-1.0/), licensed under the [Stability AI Community License](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/./third_party/LICENSE_StabilityAI.md).\n  **Commercial use and redistribution require prior permission from Stability AI.**\n\n* üìò **All other code and models** are released under the Apache License 2.0.\n\n---\n\n## Acknowledgements\n",
    "ContentSha": "j3jq6Afpr38oSd7nSvDiMiQ889Z6kSywM0DVVT9ieNA=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "\n\n## üèãÔ∏è –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏\n\n–°–º. [`Training.md`](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/docs/Training.md)\n\n\n---\n\n## üìù –ü–ª–∞–Ω—ã TODO –∏ –Ω–∞ –±—É–¥—É—â–µ–µ\n* - [ ] –í—ã–ø—É—Å—Ç–∏—Ç—å –±–æ–ª–µ–µ –º–æ—â–Ω—É—é –±–∞–∑–æ–≤—É—é –º–æ–¥–µ–ª—å, –æ—Ö–≤–∞—Ç—ã–≤–∞—é—â—É—é –Ω–µ—Å–∫–æ–ª—å–∫–æ –¥–æ–º–µ–Ω–æ–≤, –¥–ª—è –±–æ–ª–µ–µ —É–≤–ª–µ–∫–∞—Ç–µ–ª—å–Ω–æ–≥–æ –∏ –∏–º–º–µ—Ä—Å–∏–≤–Ω–æ–≥–æ —Å–æ–∑–¥–∞–Ω–∏—è —Ñ–æ–ª–∏\n* - [ ] –î–æ–±–∞–≤–∏—Ç—å –ø–æ–¥–¥–µ—Ä–∂–∫—É –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –º–æ–¥–∞–ª—å–Ω–æ—Å—Ç–µ–π –∏ –ø–æ—Å–ª–µ–¥—É—é—â–∏—Ö –∑–∞–¥–∞—á\n* - [ ] –í—ã–ø—É—Å—Ç–∏—Ç—å –º–æ–¥–µ–ª–∏ —Ä–∞–∑–Ω—ã—Ö –º–∞—Å—à—Ç–∞–±–æ–≤\n* - [x] –û—Ç–∫—Ä—ã—Ç—å –∏—Å—Ö–æ–¥–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç AudioCoT –∏ –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–Ω–≤–µ–π–µ—Ä\n* - [x] –í—ã–ø—É—Å—Ç–∏—Ç—å –æ–±—É—á–∞—é—â–∏–µ —Å–∫—Ä–∏–ø—Ç—ã –¥–ª—è –º–æ–¥–µ–ª–µ–π ThinkSound\n* - [x] README –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Å—Ç–∞—Ä—Ç–∞ –Ω–∞ Windows –¥–ª—è –Ω–æ–≤–∏—á–∫–æ–≤\n---\n\n\n## üìÑ –õ–∏—Ü–µ–Ω–∑–∏—è\n\n–≠—Ç–æ—Ç –ø—Ä–æ–µ–∫—Ç —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω—è–µ—Ç—Å—è –ø–æ –ª–∏—Ü–µ–Ω–∑–∏–∏ Apache 2.0.\n\n> **–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ:**\n> –ö–æ–¥, –º–æ–¥–µ–ª–∏ –∏ –¥–∞—Ç–∞—Å–µ—Ç –ø—Ä–µ–¥–Ω–∞–∑–Ω–∞—á–µ–Ω—ã **—Ç–æ–ª—å–∫–æ –¥–ª—è –Ω–∞—É—á–Ω—ã—Ö –∏ –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—ã—Ö —Ü–µ–ª–µ–π**.\n> **–ö–æ–º–º–µ—Ä—á–µ—Å–∫–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ù–ï —Ä–∞–∑—Ä–µ—à–µ–Ω–æ.**\n> –î–ª—è –∫–æ–º–º–µ—Ä—á–µ—Å–∫–æ–≥–æ –ª–∏—Ü–µ–Ω–∑–∏—Ä–æ–≤–∞–Ω–∏—è, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, —Å–≤—è–∂–∏—Ç–µ—Å—å —Å –∞–≤—Ç–æ—Ä–∞–º–∏.\n\n**üì¶ –°—Ç–æ—Ä–æ–Ω–Ω–∏–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã**\n\n* **Stable Audio Open VAE** (–æ—Ç Stability AI):\n  –≠—Ç–æ—Ç —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π –≤–∫–ª—é—á–∞–µ—Ç –¥–æ—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π VAE –∏–∑ [Stable Audio Open](https://huggingface.co/stabilityai/stable-audio-open-1.0/), –ª–∏—Ü–µ–Ω–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ [–ª–∏—Ü–µ–Ω–∑–∏–∏ Stability AI Community License](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/./third_party/LICENSE_StabilityAI.md).\n  **–ö–æ–º–º–µ—Ä—á–µ—Å–∫–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –∏ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ —Ç—Ä–µ–±—É—é—Ç –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è Stability AI.**\n\n* üìò **–í–µ—Å—å –æ—Å—Ç–∞–ª—å–Ω–æ–π –∫–æ–¥ –∏ –º–æ–¥–µ–ª–∏** —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω—è—é—Ç—Å—è –ø–æ –ª–∏—Ü–µ–Ω–∑–∏–∏ Apache 2.0.\n\n---\n\n## –ë–ª–∞–≥–æ–¥–∞—Ä–Ω–æ—Å—Ç–∏\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 16,
    "Content": "Many thanks to:\n\n* **stable-audio-tools** (by Stability AI):\nFor providing an easy-to-use framework for audio generation, as well as the VAE module and weights.\n* **MMAudio**:\n  For the implementation of the MM-DiT backbone in the audio domain.\n\n---\n\n## üìñ Citation\n\nIf you find ThinkSound useful in your research or work, please cite our paper:\n",
    "ContentSha": "FsK5U++tkthvkZ/Gd4G7gn74YKpB282Oxnkt96u9C1k=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "–ë–ª–∞–≥–æ–¥–∞—Ä–Ω–æ—Å—Ç–∏:\n\n* **stable-audio-tools** (–æ—Ç Stability AI):\n–ó–∞ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —É–¥–æ–±–Ω–æ–π –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∞—É–¥–∏–æ, –∞ —Ç–∞–∫–∂–µ –º–æ–¥—É–ª—è VAE –∏ –≤–µ—Å–æ–≤.\n* **MMAudio**:\n  –ó–∞ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã MM-DiT –≤ –∞—É–¥–∏–æ-–¥–æ–º–µ–Ω–µ.\n\n---\n\n## üìñ –¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ\n\n–ï—Å–ª–∏ ThinkSound –æ–∫–∞–∑–∞–ª—Å—è –ø–æ–ª–µ–∑–Ω—ã–º –¥–ª—è –≤–∞—à–∏—Ö –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π –∏–ª–∏ —Ä–∞–±–æ—Ç—ã, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø—Ä–æ—Ü–∏—Ç–∏—Ä—É–π—Ç–µ –Ω–∞—à—É —Å—Ç–∞—Ç—å—é:\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 17,
    "Content": "```bibtex\n@misc{liu2025thinksoundchainofthoughtreasoningmultimodal,\n      title={ThinkSound: Chain-of-Thought Reasoning in Multimodal Large Language Models for Audio Generation and Editing}, \n      author={Huadai Liu and Jialei Wang and Kaicheng Luo and Wen Wang and Qian Chen and Zhou Zhao and Wei Xue},\n      year={2025},\n      eprint={2506.21448},\n      archivePrefix={arXiv},\n      primaryClass={eess.AS},\n      url={https://arxiv.org/abs/2506.21448}, \n}\n```",
    "ContentSha": "KKv35iBt6IDF1ifN04L+6lkh0BHkbObnW/+m50Wufrs=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bibtex\n@misc{liu2025thinksoundchainofthoughtreasoningmultimodal,\n      title={ThinkSound: Chain-of-Thought Reasoning in Multimodal Large Language Models for Audio Generation and Editing}, \n      author={Huadai Liu and Jialei Wang and Kaicheng Luo and Wen Wang and Qian Chen and Zhou Zhao and Wei Xue},\n      year={2025},\n      eprint={2506.21448},\n      archivePrefix={arXiv},\n      primaryClass={eess.AS},\n      url={https://arxiv.org/abs/2506.21448}, \n}\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 18,
    "Content": "\n---\n\n## üì¨ Contact\n\n\n‚ú® Feel free to [open an issue](https://github.com/liuhuadai/ThinkSound/issues) or contact us via email ([liuhuadai@zju.edu.cn](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/mailto:liuhuadai@zju.edu.cn)) if you have any questions or suggestions!\n\n\n",
    "ContentSha": "QMNRHPzbmsL2YxrLNEPneJCBrTj4/XiY9XGTX01NZl8=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "\n---\n\n## üì¨ Contact\n\n\n‚ú® Feel free to [open an issue](https://github.com/liuhuadai/ThinkSound/issues) or contact us via email ([liuhuadai@zju.edu.cn](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/mailto:liuhuadai@zju.edu.cn)) if you have any questions or suggestions!\n\n\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 2,
        "rowsha": "yz+R1U7uMOU+NbK5mQX3Dxae1Un9eJCdPawt78ntjTs=",
        "originContent": "---",
        "translatedContent": "---"
      },
      {
        "row": 3,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 4,
        "rowsha": "V0ea1xQLKG+cGj5kHVv5f15HDd+yj0ulkcBQnvErdJc=",
        "originContent": "## üì¨ Contact",
        "translatedContent": "## üì¨ Contact"
      },
      {
        "row": 5,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 6,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 7,
        "rowsha": "QsDuVwX1DXlTNejKuNftx4k1x7yNHjfP9/1HS85hJng=",
        "originContent": "‚ú® Feel free to [open an issue](https://github.com/liuhuadai/ThinkSound/issues) or contact us via email ([liuhuadai@zju.edu.cn](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/mailto:liuhuadai@zju.edu.cn)) if you have any questions or suggestions!",
        "translatedContent": "‚ú® Feel free to [open an issue](https://github.com/liuhuadai/ThinkSound/issues) or contact us via email ([liuhuadai@zju.edu.cn](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/mailto:liuhuadai@zju.edu.cn)) if you have any questions or suggestions!"
      },
      {
        "row": 8,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 9,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 10,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  }
]