{
  "id": 2,
  "origin": "## ğŸ“ TODO\n\n- â˜ Release training scripts for ThinkSound models\n- â˜ Open-source AudioCoT dataset and automated pipeline\n- â˜ Provide detailed documentation and API reference\n- â˜ Add support for additional modalities and downstream tasks\n\n---\n\n## ğŸ“„ License\n\nThis project is released under the [Apache 2.0 License](LICENSE).\n\n> **Note:**  \n> The code, models, and dataset are **for research and educational purposes only**.  \n> **Commercial use is NOT permitted.**\n>\n> For commercial licensing, please contact the authors.\n\n---\n\n## ğŸ“– Citation\n\nIf you find ThinkSound useful in your research or work, please cite our paper:\n\n```bibtex\n@misc{liu2025thinksoundchainofthoughtreasoningmultimodal,\n      title={ThinkSound: Chain-of-Thought Reasoning in Multimodal Large Language Models for Audio Generation and Editing}, \n      author={Huadai Liu and Jialei Wang and Kaicheng Luo and Wen Wang and Qian Chen and Zhou Zhao and Wei Xue},\n      year={2025},\n      eprint={2506.21448},\n      archivePrefix={arXiv},\n      primaryClass={eess.AS},\n      url={https://arxiv.org/abs/2506.21448}, \n}\n```\n\n---\n\n## ğŸ“¬ Contact\n\nâœ¨ Feel free to [open an issue](https://github.com/liuhuadai/ThinkSound/issues) or contact us via email ([liuhuadai@zju.edu.cn](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/mailto:liuhuadai@zju.edu.cn)) if you have any questions or suggestions!\n",
  "origin_sha": "NEFlwyN+fN3dUarHAXDiIoJazYSSuWRByH696fda+qA=",
  "translate": "## ğŸ“ TODO\n\n- â˜ ç™¼ä½ˆ ThinkSound æ¨¡å‹çš„è¨“ç·´è…³æœ¬\n- â˜ é–‹æº AudioCoT æ•¸æ“šé›†åŠè‡ªå‹•åŒ–æµç¨‹\n- â˜ æä¾›è©³ç´°çš„æ–‡ä»¶èˆ‡ API åƒè€ƒ\n- â˜ å¢åŠ å°æ›´å¤šæ¨¡æ…‹åŠä¸‹æ¸¸ä»»å‹™çš„æ”¯æ´\n\n---\n\n## ğŸ“„ æˆæ¬Šæ¢æ¬¾\n\næœ¬å°ˆæ¡ˆä¾æ“š [Apache 2.0 æˆæ¬Šæ¢æ¬¾](LICENSE) ç™¼ä½ˆã€‚\n\n> **æ³¨æ„ï¼š**  \n> æ­¤ç¨‹å¼ç¢¼ã€æ¨¡å‹åŠæ•¸æ“šé›†**åƒ…ä¾›å­¸è¡“ç ”ç©¶èˆ‡æ•™è‚²ç”¨é€”**ã€‚  \n> **ç¦æ­¢å•†æ¥­ç”¨é€”ã€‚**\n>\n> è‹¥éœ€å•†æ¥­æˆæ¬Šï¼Œè«‹è¯çµ¡ä½œè€…ã€‚\n\n---\n\n## ğŸ“– å¼•ç”¨\n\nå¦‚æœæ‚¨åœ¨ç ”ç©¶æˆ–å·¥ä½œä¸­è¦ºå¾— ThinkSound æœ‰å¹«åŠ©ï¼Œè«‹å¼•ç”¨æˆ‘å€‘çš„è«–æ–‡ï¼š\n\n```bibtex\n@misc{liu2025thinksoundchainofthoughtreasoningmultimodal,\n      title={ThinkSound: Chain-of-Thought Reasoning in Multimodal Large Language Models for Audio Generation and Editing}, \n      author={Huadai Liu and Jialei Wang and Kaicheng Luo and Wen Wang and Qian Chen and Zhou Zhao and Wei Xue},\n      year={2025},\n      eprint={2506.21448},\n      archivePrefix={arXiv},\n      primaryClass={eess.AS},\n      url={https://arxiv.org/abs/2506.21448}, \n}\n```\n\n---\n\n## ğŸ“¬ è¯çµ¡æ–¹å¼\n\nâœ¨ å¦‚æœæ‚¨æœ‰ä»»ä½•å•é¡Œæˆ–å»ºè­°ï¼Œæ­¡è¿[æäº¤ issue](https://github.com/liuhuadai/ThinkSound/issues)æˆ–é€éé›»å­éƒµä»¶ ([liuhuadai@zju.edu.cn](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/mailto:liuhuadai@zju.edu.cn)) è¯çµ¡æˆ‘å€‘ï¼",
  "status": "ok"
}