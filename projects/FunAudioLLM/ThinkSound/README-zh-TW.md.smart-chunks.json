[
  {
    "Id": 1,
    "Content": "<h1 align=\"center\">ThinkSound</h1>\n\n<p align=\"center\">\n  ğŸŒ\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=en\">English</a> |\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=zh-CN\">ç®€ä½“ä¸­æ–‡</a> |\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=zh-TW\">ç¹é«”ä¸­æ–‡</a> |\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=es\">EspaÃ±ol</a> |\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=fr\">FranÃ§ais</a> |\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=ja\">æ—¥æœ¬èª</a>\n  \n</p>\n\n<p align=\"center\">\n  <a href=\"https://arxiv.org/pdf/2506.21448\">\n    <img src=\"https://img.shields.io/badge/arXiv-2506.21448-b31b1b.svg\" alt=\"arXiv\"/>\n  </a>\n  &nbsp;\n  <a href=\"https://thinksound-project.github.io/\">\n    <img src=\"https://img.shields.io/badge/Online%20Demo-ğŸŒ-blue\" alt=\"Online Demo\"/>\n  </a>\n  &nbsp;\n  <a href=\"https://huggingface.co/spaces/FunAudioLLM/ThinkSound\">\n    <img src=\"https://img.shields.io/badge/HuggingFace-Spaces-orange?logo=huggingface\" alt=\"Hugging Face\"/>\n  </a>\n  &nbsp;\n  <a href=\"https://modelscope.cn/studios/iic/ThinkSound\">\n    <img src=\"https://img.shields.io/badge/ModelScope-åœ¨çº¿ä½“éªŒ-green\" alt=\"ModelScope\"/>\n  </a>\n</p>\n\n<p align=\"center\">\n  If you find this project useful,<br>\n  a star â­ on GitHub would be greatly appreciated!\n</p>\n\n---\n\n**ThinkSound** is a unified Any2Audio generation framework with flow matching guided by Chain-of-Thought (CoT) reasoning.\n\nPyTorch implementation for multimodal audio generation and editing: generate or edit audio from video, text, and audio, powered by step-by-step reasoning from Multimodal Large Language Models (MLLMs).\n\n![Teaser](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig1_teaser.png)\n---\n\n## ğŸ“° News\n- **2025.07.17** &nbsp; ğŸ§  Finetuning enabled: training and finetuning code is now publicly available, along with clear usage instructions to help you customize and extend ThinkSound with your own data.\n- **2025.07.15** &nbsp; ğŸ“¦ Simplified installation and usability: dependencies on PyPI for easy cross-platform setup; Windows `.bat` scripts automate environment creation and script running.\n- **2025.07.08** &nbsp;Â  ğŸ”§ Major update: model lightweighted and optimized memory and GPU usage, now supports high-throughput audio generation at scale!\n- **2025.07.01** &nbsp; ğŸ”¥Online demo on [Hugging Face Spaces](https://huggingface.co/spaces/FunAudioLLM/ThinkSound) and [ModelScope](https://modelscope.cn/studios/iic/ThinkSound) for interactive experience!\n- **2025.07.01** &nbsp; ğŸ”¥Released inference scripts and web interface; \n- **2025.06** &nbsp; ğŸ”¥[ThinkSound paper](https://arxiv.org/pdf/2506.21448) released on arXiv!\n- **2025.06** &nbsp; ğŸ”¥[Online Demo](http://thinksound-project.github.io/) is live - try it now!\n\n---\n\n\n## ğŸš€ Features\n\n- **Any2Audio**: Generate audio from arbitrary modalities â€” video, text, audio, or their combinations.\n- **Video-to-Audio SOTA**: Achieves state-of-the-art results on multiple V2A benchmarks.\n- **CoT-Driven Reasoning**: Chain-of-Thought reasoning for compositional and controllable audio generation via MLLMs.\n- **Interactive Object-centric Editing**: Refine or edit specific sound events by clicking on visual objects or using text instructions.\n- **Unified Framework**: One foundation model supports generation, editing, and interactive workflow.\n\n---\n\n## âœ¨ Method Overview\n\nThinkSound decomposes audio generation and editing into three interactive stages, all guided by MLLM-based Chain-of-Thought (CoT) reasoning:\n\n1. **Foley Generation:** Generate foundational, semantically and temporally aligned soundscapes from video.\n2. **Object-Centric Refinement:** Refine or add sounds for user-specified objects via clicks or regions in the video.\n3. **Targeted Audio Editing:** Modify generated audio using high-level natural language instructions.\n\n![ThinkSound Overview](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig3_model.png)\n<!-- A large-scale CoT-annotated dataset (**AudioCoT**) is used to train both the reasoning module and the unified audio foundation model.\n![AudioCoT Pipeline](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig2_dataset.png) -->\n\n---\n\n## âš¡ Quick Start\n\n**Environment Preparation:**",
    "ContentSha": "4/bI+NRdw8asyoBT7fbmw53SyxDNRbIwFef01YDcY9Q=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "<h1 align=\"center\">ThinkSound</h1>\n\n<p align=\"center\">\n  ğŸŒ\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=en\">English</a> |\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=zh-CN\">ç®€ä½“ä¸­æ–‡</a> |\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=zh-TW\">ç¹é«”ä¸­æ–‡</a> |\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=es\">EspaÃ±ol</a> |\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=fr\">FranÃ§ais</a> |\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=ja\">æ—¥æœ¬èª</a>\n  \n</p>\n\n<p align=\"center\">\n  <a href=\"https://arxiv.org/pdf/2506.21448\">\n    <img src=\"https://img.shields.io/badge/arXiv-2506.21448-b31b1b.svg\" alt=\"arXiv\"/>\n  </a>\n  &nbsp;\n  <a href=\"https://thinksound-project.github.io/\">\n    <img src=\"https://img.shields.io/badge/Online%20Demo-ğŸŒ-blue\" alt=\"Online Demo\"/>\n  </a>\n  &nbsp;\n  <a href=\"https://huggingface.co/spaces/FunAudioLLM/ThinkSound\">\n    <img src=\"https://img.shields.io/badge/HuggingFace-Spaces-orange?logo=huggingface\" alt=\"Hugging Face\"/>\n  </a>\n  &nbsp;\n  <a href=\"https://modelscope.cn/studios/iic/ThinkSound\">\n    <img src=\"https://img.shields.io/badge/ModelScope-åœ¨çº¿ä½“éªŒ-green\" alt=\"ModelScope\"/>\n  </a>\n</p>\n\n<p align=\"center\">\n  å¦‚æœæ‚¨è¦ºå¾—é€™å€‹å°ˆæ¡ˆæœ‰å¹«åŠ©ï¼Œ<br>\n  æ­¡è¿åœ¨ GitHub ä¸Šé»å€‹æ˜Ÿæ˜Ÿ â­ æ”¯æŒæˆ‘å€‘ï¼\n</p>\n\n---\n\n**ThinkSound** æ˜¯ä¸€å€‹çµ±ä¸€çš„ Any2Audio ç”Ÿæˆæ¡†æ¶ï¼Œçµåˆäº† Chain-of-Thoughtï¼ˆCoTï¼‰æ¨ç†å¼•å°çš„æµåŒ¹é…æŠ€è¡“ã€‚\n\nåŸºæ–¼ PyTorch çš„å¤šæ¨¡æ…‹éŸ³é »ç”Ÿæˆèˆ‡ç·¨è¼¯å·¥å…·ï¼šå¯å¾å½±åƒã€æ–‡å­—èˆ‡éŸ³é »ç”¢ç”Ÿæˆ–ç·¨è¼¯è²éŸ³ï¼Œä¸¦ç”±å¤šæ¨¡æ…‹å¤§å‹èªè¨€æ¨¡å‹ï¼ˆMLLMsï¼‰æä¾›é€æ­¥æ¨ç†æ”¯æŒã€‚\n\n![Teaser](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig1_teaser.png)\n---\n\n## ğŸ“° æœ€æ–°æ¶ˆæ¯\n- **2025.07.17** &nbsp; ğŸ§  é–‹æ”¾å¾®èª¿åŠŸèƒ½ï¼šç¾å·²å…¬é–‹è¨“ç·´èˆ‡å¾®èª¿ç¨‹å¼ç¢¼ï¼Œä¸¦é™„æœ‰è©³ç´°æ“ä½œèªªæ˜ï¼Œå¹«åŠ©æ‚¨ä»¥è‡ªå·±çš„è³‡æ–™è‡ªè¨‚èˆ‡æ“´å…… ThinkSoundã€‚\n- **2025.07.15** &nbsp; ğŸ“¦ å®‰è£èˆ‡ä½¿ç”¨æ›´åŠ ç°¡æ˜“ï¼šPyPI ä¾è³´è¼•é¬†è·¨å¹³å°å®‰è£ï¼›Windows `.bat` è…³æœ¬è‡ªå‹•å»ºç«‹ç’°å¢ƒèˆ‡é‹è¡Œè…³æœ¬ã€‚\n- **2025.07.08** &nbsp;Â  ğŸ”§ é‡å¤§æ›´æ–°ï¼šæ¨¡å‹æ›´è¼•é‡ã€è¨˜æ†¶é«”èˆ‡ GPU ä½¿ç”¨å„ªåŒ–ï¼Œç¾æ”¯æ´å¤§è¦æ¨¡é«˜ååéŸ³é »ç”Ÿæˆï¼\n- **2025.07.01** &nbsp; ğŸ”¥[Hugging Face Spaces](https://huggingface.co/spaces/FunAudioLLM/ThinkSound) èˆ‡ [ModelScope](https://modelscope.cn/studios/iic/ThinkSound) ä¸Šç·šäº’å‹•å¼ç·šä¸Šæ¼”ç¤ºï¼\n- **2025.07.01** &nbsp; ğŸ”¥é‡‹å‡ºæ¨ç†è…³æœ¬èˆ‡ç¶²é ä»‹é¢ï¼›\n- **2025.06** &nbsp; ğŸ”¥[ThinkSound è«–æ–‡](https://arxiv.org/pdf/2506.21448) å·²ç™¼ä½ˆæ–¼ arXivï¼\n- **2025.06** &nbsp; ğŸ”¥[ç·šä¸Šæ¼”ç¤º](http://thinksound-project.github.io/) å·²ä¸Šç·š - æ­¡è¿é«”é©—ï¼\n\n---\n\n\n## ğŸš€ ç‰¹è‰²\n\n- **Any2Audio**ï¼šæ”¯æ´å¾ä»»æ„æ¨¡æ…‹ï¼ˆå½±åƒã€æ–‡å­—ã€éŸ³é »æˆ–å…¶çµ„åˆï¼‰ç”ŸæˆéŸ³é »ã€‚\n- **Video-to-Audio SOTA**ï¼šæ–¼å¤šé … V2A åŸºæº–æ•¸æ“šé›†é”åˆ°æœ€æ–°æŠ€è¡“æ°´æº–ã€‚\n- **CoT æ¨ç†é©…å‹•**ï¼šåŸºæ–¼ MLLM çš„ Chain-of-Thought æ¨ç†å¯¦ç¾å¯çµ„åˆã€å¯æ§çš„éŸ³é »ç”Ÿæˆã€‚\n- **äº’å‹•å¼ç‰©ä»¶å°å‘ç·¨è¼¯**ï¼šå¯é»æ“Šå½±åƒç‰©ä»¶æˆ–ä½¿ç”¨æ–‡å­—æŒ‡ä»¤ä¾†ç´°ç·»ç·¨è¼¯ç‰¹å®šè²éŸ³äº‹ä»¶ã€‚\n- **çµ±ä¸€æ¡†æ¶**ï¼šä¸€å€‹åŸºç¤æ¨¡å‹åŒæ™‚æ”¯æ´ç”Ÿæˆã€ç·¨è¼¯èˆ‡äº’å‹•å¼å·¥ä½œæµã€‚\n\n---\n\n## âœ¨ æ–¹æ³•æ¦‚è¿°\n\nThinkSound å°‡éŸ³é »ç”Ÿæˆèˆ‡ç·¨è¼¯åˆ†ç‚ºä¸‰å€‹äº’å‹•éšæ®µï¼Œå…¨éƒ¨ç”± MLLM é©…å‹•çš„ Chain-of-Thoughtï¼ˆCoTï¼‰æ¨ç†å¼•å°ï¼š\n\n1. **Foley ç”Ÿæˆï¼š** å¾å½±ç‰‡ä¸­ç”Ÿæˆèªæ„èˆ‡æ™‚é–“å°é½Šçš„åŸºç¤è²æ™¯ã€‚\n2. **ç‰©ä»¶å°å‘ç´°åŒ–ï¼š** é€éåœ¨å½±ç‰‡ä¸­é»æ“Šç‰©ä»¶æˆ–å€åŸŸï¼Œç´°åŒ–æˆ–æ–°å¢ä½¿ç”¨è€…æŒ‡å®šç‰©ä»¶çš„è²éŸ³ã€‚\n3. **ç›®æ¨™éŸ³é »ç·¨è¼¯ï¼š** åˆ©ç”¨é«˜éšè‡ªç„¶èªè¨€æŒ‡ä»¤ä¿®æ”¹å·²ç”Ÿæˆçš„éŸ³é »ã€‚\n\n![ThinkSound Overview](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig3_model.png)\n<!-- å¤§è¦æ¨¡ CoT æ¨™è¨»è³‡æ–™é›†ï¼ˆ**AudioCoT**ï¼‰åŒæ™‚ç”¨æ–¼è¨“ç·´æ¨ç†æ¨¡çµ„èˆ‡çµ±ä¸€éŸ³é »åŸºç¤æ¨¡å‹ã€‚\n![AudioCoT Pipeline](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig2_dataset.png) -->\n\n---\n\n## âš¡ å¿«é€Ÿé–‹å§‹\n\n**ç’°å¢ƒæº–å‚™ï¼š**",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "JxESpSOemcOHL7YK3E5sXNUt0UcsbKqLYX+tuvsu7P4=",
        "originContent": "<h1 align=\"center\">ThinkSound</h1>",
        "translatedContent": "<h1 align=\"center\">ThinkSound</h1>"
      },
      {
        "row": 2,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 3,
        "rowsha": "+/a9XmPwQixGFroME/GMEOLpReZZV4ARosR9orAplJY=",
        "originContent": "<p align=\"center\">",
        "translatedContent": "<p align=\"center\">"
      },
      {
        "row": 4,
        "rowsha": "CSeo6S41hUQEjrndf6ijg79FX29RUxiFJUVIA3cYsNQ=",
        "originContent": "  ğŸŒ",
        "translatedContent": "  ğŸŒ"
      },
      {
        "row": 5,
        "rowsha": "IJLGqpRt+7ez3r1WoZz6fvh/rC+8KZ5K3FP2xs/0LNM=",
        "originContent": "  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=en\">English</a> |",
        "translatedContent": "  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=en\">English</a> |"
      },
      {
        "row": 6,
        "rowsha": "hhbPoa8bqBB7SPpAAUVT30o77g3w0Ky5ywfQeyLf1j4=",
        "originContent": "  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=zh-CN\">ç®€ä½“ä¸­æ–‡</a> |",
        "translatedContent": "  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=zh-CN\">ç®€ä½“ä¸­æ–‡</a> |"
      },
      {
        "row": 7,
        "rowsha": "tRfgQgD9d867JyLy4SUrBX76D1lWSxv43P6AXFC6S+E=",
        "originContent": "  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=zh-TW\">ç¹é«”ä¸­æ–‡</a> |",
        "translatedContent": "  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=zh-TW\">ç¹é«”ä¸­æ–‡</a> |"
      },
      {
        "row": 8,
        "rowsha": "6wLn1diFukrW2YDUESRE3YVcqNY3dxojo6fHTtwy5Pw=",
        "originContent": "  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=es\">EspaÃ±ol</a> |",
        "translatedContent": "  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=es\">EspaÃ±ol</a> |"
      },
      {
        "row": 9,
        "rowsha": "evSE8XG0v3qXaLIwGU0C7m+8gbYGsKYAemuq5Tn6Xog=",
        "originContent": "  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=fr\">FranÃ§ais</a> |",
        "translatedContent": "  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=fr\">FranÃ§ais</a> |"
      },
      {
        "row": 10,
        "rowsha": "9f+fFClA7BNYID46cHbx1rrKXWcVW5LDZW5Zy7DVZ+w=",
        "originContent": "  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=ja\">æ—¥æœ¬èª</a>",
        "translatedContent": "  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=ja\">æ—¥æœ¬èª</a>"
      },
      {
        "row": 11,
        "rowsha": "bBefIeb2K2KQVdirQPRU7QLki2hWORNHO4V9NjjiOyg=",
        "originContent": "  ",
        "translatedContent": "  "
      },
      {
        "row": 12,
        "rowsha": "dSdvPNAZSmR86FDDSF6tkQUCVfI9qmACHOR5tThOetY=",
        "originContent": "</p>",
        "translatedContent": "</p>"
      },
      {
        "row": 13,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 14,
        "rowsha": "+/a9XmPwQixGFroME/GMEOLpReZZV4ARosR9orAplJY=",
        "originContent": "<p align=\"center\">",
        "translatedContent": "<p align=\"center\">"
      },
      {
        "row": 15,
        "rowsha": "U41oE9v936BfSGDgJuMB1g3jQTqsJtmJPQUhVonUNHI=",
        "originContent": "  <a href=\"https://arxiv.org/pdf/2506.21448\">",
        "translatedContent": "  <a href=\"https://arxiv.org/pdf/2506.21448\">"
      },
      {
        "row": 16,
        "rowsha": "ynIImIY0Z2jVqizQykbwGTP/PcL0XGIQs5BslFVtz58=",
        "originContent": "    <img src=\"https://img.shields.io/badge/arXiv-2506.21448-b31b1b.svg\" alt=\"arXiv\"/>",
        "translatedContent": "    <img src=\"https://img.shields.io/badge/arXiv-2506.21448-b31b1b.svg\" alt=\"arXiv\"/>"
      },
      {
        "row": 17,
        "rowsha": "7Sl5c7caJ7+Yt222Hl2I2PLtk1UIeh8Qfn02MNONw0Y=",
        "originContent": "  </a>",
        "translatedContent": "  </a>"
      },
      {
        "row": 18,
        "rowsha": "robEj93GNR0ga47/E63BGVUMman0bHA00TiujTzIdqs=",
        "originContent": "  &nbsp;",
        "translatedContent": "  &nbsp;"
      },
      {
        "row": 19,
        "rowsha": "Yff0X0Mje5Jr8Vv7MEJie2CoYJL+UpE7RrCgKgVeN0c=",
        "originContent": "  <a href=\"https://thinksound-project.github.io/\">",
        "translatedContent": "  <a href=\"https://thinksound-project.github.io/\">"
      },
      {
        "row": 20,
        "rowsha": "H+PqZbUh0elg8uffxX9z5kKKpS5/odGusuxfm7oCW7w=",
        "originContent": "    <img src=\"https://img.shields.io/badge/Online%20Demo-ğŸŒ-blue\" alt=\"Online Demo\"/>",
        "translatedContent": "    <img src=\"https://img.shields.io/badge/Online%20Demo-ğŸŒ-blue\" alt=\"Online Demo\"/>"
      },
      {
        "row": 21,
        "rowsha": "7Sl5c7caJ7+Yt222Hl2I2PLtk1UIeh8Qfn02MNONw0Y=",
        "originContent": "  </a>",
        "translatedContent": "  </a>"
      },
      {
        "row": 22,
        "rowsha": "robEj93GNR0ga47/E63BGVUMman0bHA00TiujTzIdqs=",
        "originContent": "  &nbsp;",
        "translatedContent": "  &nbsp;"
      },
      {
        "row": 23,
        "rowsha": "8w8i7BBaV0MFFj9oV8SQ9+mUcgmT0lDsYIGPYBRMK4k=",
        "originContent": "  <a href=\"https://huggingface.co/spaces/FunAudioLLM/ThinkSound\">",
        "translatedContent": "  <a href=\"https://huggingface.co/spaces/FunAudioLLM/ThinkSound\">"
      },
      {
        "row": 24,
        "rowsha": "MShdQrgDW0rCwuvHGbK9UiqT/w2XoWfU6MCC4EQ8Oo0=",
        "originContent": "    <img src=\"https://img.shields.io/badge/HuggingFace-Spaces-orange?logo=huggingface\" alt=\"Hugging Face\"/>",
        "translatedContent": "    <img src=\"https://img.shields.io/badge/HuggingFace-Spaces-orange?logo=huggingface\" alt=\"Hugging Face\"/>"
      },
      {
        "row": 25,
        "rowsha": "7Sl5c7caJ7+Yt222Hl2I2PLtk1UIeh8Qfn02MNONw0Y=",
        "originContent": "  </a>",
        "translatedContent": "  </a>"
      },
      {
        "row": 26,
        "rowsha": "robEj93GNR0ga47/E63BGVUMman0bHA00TiujTzIdqs=",
        "originContent": "  &nbsp;",
        "translatedContent": "  &nbsp;"
      },
      {
        "row": 27,
        "rowsha": "ycu3inIAlcQNI/CFyarNMwyiRfw4GtBsvcc/0LcD3c0=",
        "originContent": "  <a href=\"https://modelscope.cn/studios/iic/ThinkSound\">",
        "translatedContent": "  <a href=\"https://modelscope.cn/studios/iic/ThinkSound\">"
      },
      {
        "row": 28,
        "rowsha": "4Z9FQa2ROL8/O+DmziXnhj/aKyTxS9GGOmocWYnVJ6g=",
        "originContent": "    <img src=\"https://img.shields.io/badge/ModelScope-åœ¨çº¿ä½“éªŒ-green\" alt=\"ModelScope\"/>",
        "translatedContent": "    <img src=\"https://img.shields.io/badge/ModelScope-åœ¨çº¿ä½“éªŒ-green\" alt=\"ModelScope\"/>"
      },
      {
        "row": 29,
        "rowsha": "7Sl5c7caJ7+Yt222Hl2I2PLtk1UIeh8Qfn02MNONw0Y=",
        "originContent": "  </a>",
        "translatedContent": "  </a>"
      },
      {
        "row": 30,
        "rowsha": "dSdvPNAZSmR86FDDSF6tkQUCVfI9qmACHOR5tThOetY=",
        "originContent": "</p>",
        "translatedContent": "</p>"
      },
      {
        "row": 31,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 32,
        "rowsha": "+/a9XmPwQixGFroME/GMEOLpReZZV4ARosR9orAplJY=",
        "originContent": "<p align=\"center\">",
        "translatedContent": "<p align=\"center\">"
      },
      {
        "row": 33,
        "rowsha": "fxEtxfqHrh5PDQ2L/Ev2ea69zRukpezpCLPOHXsEpDw=",
        "originContent": "  If you find this project useful,<br>",
        "translatedContent": "  å¦‚æœæ‚¨è¦ºå¾—é€™å€‹å°ˆæ¡ˆæœ‰å¹«åŠ©ï¼Œ<br>"
      },
      {
        "row": 34,
        "rowsha": "oOAWVtx09WaVCvchPgX0GhZlzuPjXH1p6nhjfyZ2aS8=",
        "originContent": "  a star â­ on GitHub would be greatly appreciated!",
        "translatedContent": "  æ­¡è¿åœ¨ GitHub ä¸Šé»å€‹æ˜Ÿæ˜Ÿ â­ æ”¯æŒæˆ‘å€‘ï¼"
      },
      {
        "row": 35,
        "rowsha": "dSdvPNAZSmR86FDDSF6tkQUCVfI9qmACHOR5tThOetY=",
        "originContent": "</p>",
        "translatedContent": "</p>"
      },
      {
        "row": 36,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 37,
        "rowsha": "yz+R1U7uMOU+NbK5mQX3Dxae1Un9eJCdPawt78ntjTs=",
        "originContent": "---",
        "translatedContent": "---"
      },
      {
        "row": 38,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 39,
        "rowsha": "FQA4zA43MxvNXTogMO1WpS71bCSxerCOM1e/tmSmotg=",
        "originContent": "**ThinkSound** is a unified Any2Audio generation framework with flow matching guided by Chain-of-Thought (CoT) reasoning.",
        "translatedContent": "**ThinkSound** æ˜¯ä¸€å€‹çµ±ä¸€çš„ Any2Audio ç”Ÿæˆæ¡†æ¶ï¼Œçµåˆäº† Chain-of-Thoughtï¼ˆCoTï¼‰æ¨ç†å¼•å°çš„æµåŒ¹é…æŠ€è¡“ã€‚"
      },
      {
        "row": 40,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 41,
        "rowsha": "eexREJOMCITdo96Iwg4N4PQqu1ux/UwupfjVRj0l/L8=",
        "originContent": "PyTorch implementation for multimodal audio generation and editing: generate or edit audio from video, text, and audio, powered by step-by-step reasoning from Multimodal Large Language Models (MLLMs).",
        "translatedContent": "åŸºæ–¼ PyTorch çš„å¤šæ¨¡æ…‹éŸ³é »ç”Ÿæˆèˆ‡ç·¨è¼¯å·¥å…·ï¼šå¯å¾å½±åƒã€æ–‡å­—èˆ‡éŸ³é »ç”¢ç”Ÿæˆ–ç·¨è¼¯è²éŸ³ï¼Œä¸¦ç”±å¤šæ¨¡æ…‹å¤§å‹èªè¨€æ¨¡å‹ï¼ˆMLLMsï¼‰æä¾›é€æ­¥æ¨ç†æ”¯æŒã€‚"
      },
      {
        "row": 42,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 43,
        "rowsha": "+7Cx1rdpWiIOeWRA/RM6HsKf7pNA3hHsQk2Bpadt4II=",
        "originContent": "![Teaser](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig1_teaser.png)",
        "translatedContent": "![Teaser](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig1_teaser.png)"
      },
      {
        "row": 44,
        "rowsha": "yz+R1U7uMOU+NbK5mQX3Dxae1Un9eJCdPawt78ntjTs=",
        "originContent": "---",
        "translatedContent": "---"
      },
      {
        "row": 45,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 46,
        "rowsha": "0YeCyxpcm7/4RDbaM+OQoI8YfqEHQzDkpGW15VZdi1U=",
        "originContent": "## ğŸ“° News",
        "translatedContent": "## ğŸ“° æœ€æ–°æ¶ˆæ¯"
      },
      {
        "row": 47,
        "rowsha": "4Jq9g83O8cYV4fVKsetfTpI+JrSepLrjK6J7Xg9tSqo=",
        "originContent": "- **2025.07.17** &nbsp; ğŸ§  Finetuning enabled: training and finetuning code is now publicly available, along with clear usage instructions to help you customize and extend ThinkSound with your own data.",
        "translatedContent": "- **2025.07.17** &nbsp; ğŸ§  é–‹æ”¾å¾®èª¿åŠŸèƒ½ï¼šç¾å·²å…¬é–‹è¨“ç·´èˆ‡å¾®èª¿ç¨‹å¼ç¢¼ï¼Œä¸¦é™„æœ‰è©³ç´°æ“ä½œèªªæ˜ï¼Œå¹«åŠ©æ‚¨ä»¥è‡ªå·±çš„è³‡æ–™è‡ªè¨‚èˆ‡æ“´å…… ThinkSoundã€‚"
      },
      {
        "row": 48,
        "rowsha": "Ae5w+cTrCd9E8qidC11IWJAgg+LuOgUxA4czDPNG/G0=",
        "originContent": "- **2025.07.15** &nbsp; ğŸ“¦ Simplified installation and usability: dependencies on PyPI for easy cross-platform setup; Windows `.bat` scripts automate environment creation and script running.",
        "translatedContent": "- **2025.07.15** &nbsp; ğŸ“¦ å®‰è£èˆ‡ä½¿ç”¨æ›´åŠ ç°¡æ˜“ï¼šPyPI ä¾è³´è¼•é¬†è·¨å¹³å°å®‰è£ï¼›Windows `.bat` è…³æœ¬è‡ªå‹•å»ºç«‹ç’°å¢ƒèˆ‡é‹è¡Œè…³æœ¬ã€‚"
      },
      {
        "row": 49,
        "rowsha": "nYxNhwgSqjwYLuWsfHAqP5sx2PnzYwoFrwcf9U+Fdss=",
        "originContent": "- **2025.07.08** &nbsp;Â  ğŸ”§ Major update: model lightweighted and optimized memory and GPU usage, now supports high-throughput audio generation at scale!",
        "translatedContent": "- **2025.07.08** &nbsp;Â  ğŸ”§ é‡å¤§æ›´æ–°ï¼šæ¨¡å‹æ›´è¼•é‡ã€è¨˜æ†¶é«”èˆ‡ GPU ä½¿ç”¨å„ªåŒ–ï¼Œç¾æ”¯æ´å¤§è¦æ¨¡é«˜ååéŸ³é »ç”Ÿæˆï¼"
      },
      {
        "row": 50,
        "rowsha": "xuARkITJMc1ABOl8/xX47dORDInuxwAsk8O1r5dvfpc=",
        "originContent": "- **2025.07.01** &nbsp; ğŸ”¥Online demo on [Hugging Face Spaces](https://huggingface.co/spaces/FunAudioLLM/ThinkSound) and [ModelScope](https://modelscope.cn/studios/iic/ThinkSound) for interactive experience!",
        "translatedContent": "- **2025.07.01** &nbsp; ğŸ”¥[Hugging Face Spaces](https://huggingface.co/spaces/FunAudioLLM/ThinkSound) èˆ‡ [ModelScope](https://modelscope.cn/studios/iic/ThinkSound) ä¸Šç·šäº’å‹•å¼ç·šä¸Šæ¼”ç¤ºï¼"
      },
      {
        "row": 51,
        "rowsha": "aIpa8g7qqXl8Iq8shRpiY5Ha5WD8c9Pd9PWybZ+wr18=",
        "originContent": "- **2025.07.01** &nbsp; ğŸ”¥Released inference scripts and web interface; ",
        "translatedContent": "- **2025.07.01** &nbsp; ğŸ”¥é‡‹å‡ºæ¨ç†è…³æœ¬èˆ‡ç¶²é ä»‹é¢ï¼›"
      },
      {
        "row": 52,
        "rowsha": "ynCJTuWmfRd3D7hcoW1WvIQ482zzFcdaXc8pgOG02Tw=",
        "originContent": "- **2025.06** &nbsp; ğŸ”¥[ThinkSound paper](https://arxiv.org/pdf/2506.21448) released on arXiv!",
        "translatedContent": "- **2025.06** &nbsp; ğŸ”¥[ThinkSound è«–æ–‡](https://arxiv.org/pdf/2506.21448) å·²ç™¼ä½ˆæ–¼ arXivï¼"
      },
      {
        "row": 53,
        "rowsha": "se+rRi5CpnStAflq7OZvd/2mN+51ezQQaBeYckrGFCk=",
        "originContent": "- **2025.06** &nbsp; ğŸ”¥[Online Demo](http://thinksound-project.github.io/) is live - try it now!",
        "translatedContent": "- **2025.06** &nbsp; ğŸ”¥[ç·šä¸Šæ¼”ç¤º](http://thinksound-project.github.io/) å·²ä¸Šç·š - æ­¡è¿é«”é©—ï¼"
      },
      {
        "row": 54,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 55,
        "rowsha": "yz+R1U7uMOU+NbK5mQX3Dxae1Un9eJCdPawt78ntjTs=",
        "originContent": "---",
        "translatedContent": "---"
      },
      {
        "row": 56,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 57,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 58,
        "rowsha": "f4oQIFLM2EJQxJ65F4oMEA7yWOIqs0eBtiIvGxI+GgI=",
        "originContent": "## ğŸš€ Features",
        "translatedContent": "## ğŸš€ ç‰¹è‰²"
      },
      {
        "row": 59,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 60,
        "rowsha": "8TbVluJJPR3C0fX41HklpO/vH9/k/rHC+jlvmHHfzQU=",
        "originContent": "- **Any2Audio**: Generate audio from arbitrary modalities â€” video, text, audio, or their combinations.",
        "translatedContent": "- **Any2Audio**ï¼šæ”¯æ´å¾ä»»æ„æ¨¡æ…‹ï¼ˆå½±åƒã€æ–‡å­—ã€éŸ³é »æˆ–å…¶çµ„åˆï¼‰ç”ŸæˆéŸ³é »ã€‚"
      },
      {
        "row": 61,
        "rowsha": "+Jf5LrYz+d1ShYCuQe8UF9taEJUpuGhDk6fAlYK3Kj4=",
        "originContent": "- **Video-to-Audio SOTA**: Achieves state-of-the-art results on multiple V2A benchmarks.",
        "translatedContent": "- **Video-to-Audio SOTA**ï¼šæ–¼å¤šé … V2A åŸºæº–æ•¸æ“šé›†é”åˆ°æœ€æ–°æŠ€è¡“æ°´æº–ã€‚"
      },
      {
        "row": 62,
        "rowsha": "mU7qXkjW1YifKoYXJedYo9l64NsTBaiXsgoGFRF/g+E=",
        "originContent": "- **CoT-Driven Reasoning**: Chain-of-Thought reasoning for compositional and controllable audio generation via MLLMs.",
        "translatedContent": "- **CoT æ¨ç†é©…å‹•**ï¼šåŸºæ–¼ MLLM çš„ Chain-of-Thought æ¨ç†å¯¦ç¾å¯çµ„åˆã€å¯æ§çš„éŸ³é »ç”Ÿæˆã€‚"
      },
      {
        "row": 63,
        "rowsha": "RComOCBBrXsZf9RHmLginqKTh9eI/bKUZuUunQEmD5M=",
        "originContent": "- **Interactive Object-centric Editing**: Refine or edit specific sound events by clicking on visual objects or using text instructions.",
        "translatedContent": "- **äº’å‹•å¼ç‰©ä»¶å°å‘ç·¨è¼¯**ï¼šå¯é»æ“Šå½±åƒç‰©ä»¶æˆ–ä½¿ç”¨æ–‡å­—æŒ‡ä»¤ä¾†ç´°ç·»ç·¨è¼¯ç‰¹å®šè²éŸ³äº‹ä»¶ã€‚"
      },
      {
        "row": 64,
        "rowsha": "C3sf87sy73G/XZft+TDo5NjXo5XcrtJB805ayHRAXoQ=",
        "originContent": "- **Unified Framework**: One foundation model supports generation, editing, and interactive workflow.",
        "translatedContent": "- **çµ±ä¸€æ¡†æ¶**ï¼šä¸€å€‹åŸºç¤æ¨¡å‹åŒæ™‚æ”¯æ´ç”Ÿæˆã€ç·¨è¼¯èˆ‡äº’å‹•å¼å·¥ä½œæµã€‚"
      },
      {
        "row": 65,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 66,
        "rowsha": "yz+R1U7uMOU+NbK5mQX3Dxae1Un9eJCdPawt78ntjTs=",
        "originContent": "---",
        "translatedContent": "---"
      },
      {
        "row": 67,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 68,
        "rowsha": "gjgLOIAU2x83BBZdLUdgEB+F64ajt/QuLYQXM1hDBLE=",
        "originContent": "## âœ¨ Method Overview",
        "translatedContent": "## âœ¨ æ–¹æ³•æ¦‚è¿°"
      },
      {
        "row": 69,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 70,
        "rowsha": "v5//GqG/smYIGoUpN+12k+9/3GWH3GdYD+jLqScb7AM=",
        "originContent": "ThinkSound decomposes audio generation and editing into three interactive stages, all guided by MLLM-based Chain-of-Thought (CoT) reasoning:",
        "translatedContent": "ThinkSound å°‡éŸ³é »ç”Ÿæˆèˆ‡ç·¨è¼¯åˆ†ç‚ºä¸‰å€‹äº’å‹•éšæ®µï¼Œå…¨éƒ¨ç”± MLLM é©…å‹•çš„ Chain-of-Thoughtï¼ˆCoTï¼‰æ¨ç†å¼•å°ï¼š"
      },
      {
        "row": 71,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 72,
        "rowsha": "vTObEWb7f5gCU681X3dTkwqhsaSW89TLw3GgMJ5I3bo=",
        "originContent": "1. **Foley Generation:** Generate foundational, semantically and temporally aligned soundscapes from video.",
        "translatedContent": "1. **Foley ç”Ÿæˆï¼š** å¾å½±ç‰‡ä¸­ç”Ÿæˆèªæ„èˆ‡æ™‚é–“å°é½Šçš„åŸºç¤è²æ™¯ã€‚"
      },
      {
        "row": 73,
        "rowsha": "LTBpIQQHtEkNF8StAa+ZEDASGmRhmHIKDQOdZ4ExJWM=",
        "originContent": "2. **Object-Centric Refinement:** Refine or add sounds for user-specified objects via clicks or regions in the video.",
        "translatedContent": "2. **ç‰©ä»¶å°å‘ç´°åŒ–ï¼š** é€éåœ¨å½±ç‰‡ä¸­é»æ“Šç‰©ä»¶æˆ–å€åŸŸï¼Œç´°åŒ–æˆ–æ–°å¢ä½¿ç”¨è€…æŒ‡å®šç‰©ä»¶çš„è²éŸ³ã€‚"
      },
      {
        "row": 74,
        "rowsha": "8wrAo7X7dPC6Sgpfrlq2ziv/Wg/3+JnlFYvO+RMxADQ=",
        "originContent": "3. **Targeted Audio Editing:** Modify generated audio using high-level natural language instructions.",
        "translatedContent": "3. **ç›®æ¨™éŸ³é »ç·¨è¼¯ï¼š** åˆ©ç”¨é«˜éšè‡ªç„¶èªè¨€æŒ‡ä»¤ä¿®æ”¹å·²ç”Ÿæˆçš„éŸ³é »ã€‚"
      },
      {
        "row": 75,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 76,
        "rowsha": "4UKlvFW3Xb0bSAVjcBNeekH/MMiYS0XDg9w4mCuPy/Q=",
        "originContent": "![ThinkSound Overview](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig3_model.png)",
        "translatedContent": "![ThinkSound Overview](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig3_model.png)"
      },
      {
        "row": 77,
        "rowsha": "GaujeIM3x7+YcFy07LNNyITlujhkgpgeIaOiKHJkYnE=",
        "originContent": "<!-- A large-scale CoT-annotated dataset (**AudioCoT**) is used to train both the reasoning module and the unified audio foundation model.",
        "translatedContent": "<!-- å¤§è¦æ¨¡ CoT æ¨™è¨»è³‡æ–™é›†ï¼ˆ**AudioCoT**ï¼‰åŒæ™‚ç”¨æ–¼è¨“ç·´æ¨ç†æ¨¡çµ„èˆ‡çµ±ä¸€éŸ³é »åŸºç¤æ¨¡å‹ã€‚"
      },
      {
        "row": 78,
        "rowsha": "qYOXaaTiYkoaPFcpTXE5xdSqqiW3ebi//EW/RfSXd9g=",
        "originContent": "![AudioCoT Pipeline](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig2_dataset.png) -->",
        "translatedContent": "![AudioCoT Pipeline](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig2_dataset.png) -->"
      },
      {
        "row": 79,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 80,
        "rowsha": "yz+R1U7uMOU+NbK5mQX3Dxae1Un9eJCdPawt78ntjTs=",
        "originContent": "---",
        "translatedContent": "---"
      },
      {
        "row": 81,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 82,
        "rowsha": "PrY/jc4yAHdS+Sr+s+Yhab477/BDp3GAzMJ8+WyumyI=",
        "originContent": "## âš¡ Quick Start",
        "translatedContent": "## âš¡ å¿«é€Ÿé–‹å§‹"
      },
      {
        "row": 83,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 84,
        "rowsha": "mD63DGEpdc7FlccTEps0KPAiwsJpO/C3yjV+SKIi/vE=",
        "originContent": "**Environment Preparation:**",
        "translatedContent": "**ç’°å¢ƒæº–å‚™ï¼š**"
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 2,
    "Content": "```bash\ngit clone https://github.com/liuhuadai/ThinkSound.git\ncd ThinkSound\nconda create -n thinksound python=3.10\nconda activate thinksound\npip install thinksound\nconda install -y -c conda-forge 'ffmpeg<7'\n# Download pretrained weights https://huggingface.co/liuhuadai/ThinkSound to Directory ckpts/\n# model weights can be also downloaded from https://www.modelscope.cn/models/iic/ThinkSound\ngit lfs install\ngit clone https://huggingface.co/liuhuadai/ThinkSound ckpts\n# To improve inference and training speed, you may optionally install a FlashAttention backend compatible with your system and PyTorch version.\n```",
    "ContentSha": "CSBCDvBmuatxDa1cNMeHEBTJJzdLjK6wyO9v0LrETM8=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\ngit clone https://github.com/liuhuadai/ThinkSound.git\ncd ThinkSound\nconda create -n thinksound python=3.10\nconda activate thinksound\npip install thinksound\nconda install -y -c conda-forge 'ffmpeg<7'\n# Download pretrained weights https://huggingface.co/liuhuadai/ThinkSound to Directory ckpts/\n# model weights can be also downloaded from https://www.modelscope.cn/models/iic/ThinkSound\ngit lfs install\ngit clone https://huggingface.co/liuhuadai/ThinkSound ckpts\n# To improve inference and training speed, you may optionally install a FlashAttention backend compatible with your system and PyTorch version.\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 3,
    "Content": "\n> âœ… **Windows Tip:**  \n> Windows users can simply run `setup_windows.bat` (or double-click it) to automatically create the conda environment, install all dependencies (including FFmpeg), and download the pretrained model â€” no manual setup required.  \n> Make sure `conda` and `git` are installed and available in your system PATH before running the script.\n\n\n### â–¶ï¸ Run the Demo\n\n#### **Linux/macOS**\n",
    "ContentSha": "YGhm7lbBNPq6xLS6zXlFTPszO8rc4QZCwsScPNskcto=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "> âœ… **Windows æç¤ºï¼š**  \n> Windows ä½¿ç”¨è€…åªéœ€åŸ·è¡Œ `setup_windows.bat`ï¼ˆæˆ–é›™æ“Šå®ƒï¼‰å³å¯è‡ªå‹•å»ºç«‹ conda ç’°å¢ƒã€å®‰è£æ‰€æœ‰ä¾è³´ï¼ˆåŒ…æ‹¬ FFmpegï¼‰ï¼Œä¸¦ä¸‹è¼‰é è¨“ç·´æ¨¡å‹â€”â€”ç„¡éœ€æ‰‹å‹•è¨­ç½®ã€‚  \n> åœ¨åŸ·è¡Œè…³æœ¬å‰ï¼Œè«‹ç¢ºä¿ `conda` å’Œ `git` å·²ç¶“å®‰è£ä¸¦ä¸”å¯åœ¨ç³»çµ± PATH ä¸­ä½¿ç”¨ã€‚\n\n\n### â–¶ï¸ åŸ·è¡Œç¤ºç¯„\n\n#### **Linux/macOS**\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 4,
    "Content": "```bash\nchmod +x scripts/demo.sh\n./scripts/demo.sh <path-to-your-demo-video> <title> <CoT description> [use-half]\n```",
    "ContentSha": "EW6OKf+6hdOehT5SO7gfI7wR8oAoMckp60MRfIA1jHc=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\nchmod +x scripts/demo.sh\n./scripts/demo.sh <path-to-your-demo-video> <title> <CoT description> [use-half]\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 5,
    "Content": "\n#### **Windows**\n\nYou can use the provided `.bat` script instead:\n",
    "ContentSha": "zXqRZWTEWOuKZG1GOlqqZff+IH24zUwdPtSfwESqS9E=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "#### **Windows**\n\næ‚¨ä¹Ÿå¯ä»¥æ”¹ç”¨æä¾›çš„ `.bat` è…³æœ¬ï¼š\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 6,
    "Content": "```bash\n.\\scripts\\demo.bat <path-to-your-demo-video> <title> <CoT description> [use-half]\n```",
    "ContentSha": "A2a1kVuIPNs8ht1a6LBYTEijJjnfjiTN0r+2n7VEJSg=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\n.\\scripts\\demo.bat <path-to-your-demo-video> <title> <CoT description> [use-half]\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 7,
    "Content": "\n**Note:**\n\n* `<path-to-your-demo-video>`: The path to a single video\n* `[use-half]` (optional): Add use-half at the end to enable half precision feature extraction.\n\n---\n\n### ğŸ“¦ Batch Inference\n\n#### **Linux/macOS**\n",
    "ContentSha": "T7owm3ZZW7sVjKwFivgiuYX2+RVuNBl0RYTSnIcxxbM=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "**æ³¨æ„ï¼š**\n\n* `<path-to-your-demo-video>`ï¼šå–®ä¸€å½±ç‰‡çš„è·¯å¾‘\n* `[use-half]`ï¼ˆå¯é¸ï¼‰ï¼šåœ¨çµå°¾åŠ ä¸Š use-half ä»¥å•Ÿç”¨åŠç²¾åº¦ç‰¹å¾µæå–ã€‚\n\n---\n\n### ğŸ“¦ æ‰¹æ¬¡æ¨è«–\n\n#### **Linux/macOS**\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 8,
    "Content": "```bash\nchmod +x scripts/eval_batch.sh\n./scripts/eval_batch.sh <video_path> <csv_path> <save_path (optional)> [use-half]\n```",
    "ContentSha": "EQ4HuSYii55aHfgphESvOXMz2+Fq39+Xquxg6Z6uzdU=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\nchmod +x scripts/eval_batch.sh\n./scripts/eval_batch.sh <video_path> <csv_path> <save_path (optional)> [use-half]\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 9,
    "Content": "\n#### **Windows**\n\nUse the equivalent `.bat` script:\n",
    "ContentSha": "njm5i6o3MR7AV4Q3WLctbe3LN1njFn89fPfTlo+zSmc=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "#### **Windows**\n\nè«‹ä½¿ç”¨ç­‰æ•ˆçš„ `.bat` è…³æœ¬ï¼š\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 10,
    "Content": "```bash\n.\\scripts\\eval_batch.bat <video_path> <csv_path> <save_path (optional)> [use-half]\n```",
    "ContentSha": "XLkAqxYBZeJiF6XnpshI6naENFsr5yFAH7af132cgb0=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\n.\\scripts\\eval_batch.bat <video_path> <csv_path> <save_path (optional)> [use-half]\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 11,
    "Content": "\n**Note:**\n\n* `<video_path>`: Path to the root directory containing all .mp4 videos to be processed (all videos must be of equal duration).\n* `<csv_path>`: A CSV file with text prompts for each video (see `demo_test.csv` for format).\n* `<save_path>` (optional): Where to save generated audio. Defaults to `results/features`.\n* `[use-half]` (optional): Add use-half at the end to enable half precision feature extraction.\n\n---\n\n\n### Web Interface Usage\n\nFor an interactive experience, launch the Gradio web interface:\n",
    "ContentSha": "yT/y6PXpYV8wS4qmKJfVNVGDLOwreTxCdCDFDv2VbLo=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "**æ³¨æ„ï¼š**\n\n* `<video_path>`ï¼šåŒ…å«æ‰€æœ‰å¾…è™•ç† .mp4 å½±ç‰‡çš„æ ¹ç›®éŒ„è·¯å¾‘ï¼ˆæ‰€æœ‰å½±ç‰‡å¿…é ˆé•·åº¦ç›¸åŒï¼‰ã€‚\n* `<csv_path>`ï¼šæ¯å€‹å½±ç‰‡çš„æ–‡å­—æç¤º CSV æª”æ¡ˆï¼ˆæ ¼å¼è«‹åƒè€ƒ `demo_test.csv`ï¼‰ã€‚\n* `<save_path>`ï¼ˆå¯é¸ï¼‰ï¼šç”¢ç”Ÿçš„éŸ³è¨Šå„²å­˜ä½ç½®ã€‚é è¨­ç‚º `results/features`ã€‚\n* `[use-half]`ï¼ˆå¯é¸ï¼‰ï¼šæœ€å¾ŒåŠ ä¸Š use-halfï¼Œå¯å•Ÿç”¨åŠç²¾åº¦ç‰¹å¾µæ“·å–ã€‚\n\n---\n\n### ç¶²é ä»‹é¢ä½¿ç”¨æ–¹å¼\n\nè‹¥éœ€äº’å‹•å¼æ“ä½œï¼Œå¯å•Ÿå‹• Gradio ç¶²é ä»‹é¢ï¼š\n\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 12,
    "Content": "```bash\npython app.py\n```",
    "ContentSha": "2nQFYMHYtsOO4+egbu20DhxqoaxfzoH8CneeM8qTEb0=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\npython app.py\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 13,
    "Content": "\n\n## ğŸ‹ï¸ Train the Model\n\nSee [`Training.md`](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/docs/Training.md)\n\n\n---\n\n## ğŸ“ TODO & Future Plans\n* - [ ] Open-source AudioCoT dataset and automated pipeline (Expected before 07/23/2025)\n* - [ ] Release a more powerful foundation model covering multiple domains to provide more engaging and immersive foley creation (Expected by end of August 2025)\n* - [ ] Add support for additional modalities and downstream tasks (Expected before end of July 2025)\n* - [ ] Release models at different scales (Expected before end of July 2025)\n* - [x] Release training scripts for ThinkSound models\n* - [x] A beginner-friendly Windows quick-start README\n---\n\n\n## ğŸ“„ License\n\nThis project is released under the Apache 2.0 License.\n\n> **Note:**\n> The code, models, and dataset are **for research and educational purposes only**.\n> **Commercial use is NOT permitted.**\n> For commercial licensing, please contact the authors.\n\n**ğŸ“¦ Third-Party Components**\n\n* **Stable Audio Open VAE** (by Stability AI):\n  This repository includes a fine-tuned VAE from [Stable Audio Open](https://huggingface.co/stabilityai/stable-audio-open-1.0/), licensed under the [Stability AI Community License](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/./third_party/LICENSE_StabilityAI.md).\n  **Commercial use and redistribution require prior permission from Stability AI.**\n\n* ğŸ“˜ **All other code and models** are released under the Apache License 2.0.\n\n---\n\n## Acknowledgements\n\nMany thanks to:\n\n* **stable-audio-tools** (by Stability AI):\nFor providing an easy-to-use framework for audio generation, as well as the VAE module and weights.\n* **MMAudio**:\n  For the implementation of the MM-DiT backbone in the audio domain.\n\n---\n\n## ğŸ“– Citation\n\nIf you find ThinkSound useful in your research or work, please cite our paper:\n",
    "ContentSha": "LyXdmPt/Z/rTkWmKzdZmSxPrCBT+5I5ZovzaMY/JLRQ=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "## ğŸ‹ï¸ è¨“ç·´æ¨¡å‹\n\nè«‹åƒé–± [`Training.md`](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/docs/Training.md)\n\n\n---\n\n## ğŸ“ TODO èˆ‡æœªä¾†è¨ˆç•«\n* - [ ] é–‹æº AudioCoT æ•¸æ“šé›†èˆ‡è‡ªå‹•åŒ–æµç¨‹ï¼ˆé è¨ˆæ–¼ 2025 å¹´ 7 æœˆ 23 æ—¥å‰ï¼‰\n* - [ ] ç™¼å¸ƒæ¶µè“‹å¤šé ˜åŸŸã€æ›´å¼·å¤§çš„åŸºç¤æ¨¡å‹ï¼Œä»¥å¸¶ä¾†æ›´å…·å¸å¼•åŠ›èˆ‡æ²‰æµ¸æ„Ÿçš„æ“¬éŸ³å‰µä½œï¼ˆé è¨ˆæ–¼ 2025 å¹´ 8 æœˆåº•å‰ï¼‰\n* - [ ] å¢åŠ å°æ›´å¤šæ¨¡æ…‹èˆ‡ä¸‹æ¸¸ä»»å‹™çš„æ”¯æ´ï¼ˆé è¨ˆæ–¼ 2025 å¹´ 7 æœˆåº•å‰ï¼‰\n* - [ ] ç™¼å¸ƒä¸åŒè¦æ¨¡çš„æ¨¡å‹ï¼ˆé è¨ˆæ–¼ 2025 å¹´ 7 æœˆåº•å‰ï¼‰\n* - [x] é‡‹å‡º ThinkSound æ¨¡å‹è¨“ç·´è…³æœ¬\n* - [x] æ–°æ‰‹å‹å¥½çš„ Windows å¿«é€Ÿå…¥é–€ README\n---\n\n## ğŸ“„ æˆæ¬Šæ¢æ¬¾\n\næœ¬å°ˆæ¡ˆä»¥ Apache 2.0 æˆæ¬Šæ¢æ¬¾é‡‹å‡ºã€‚\n\n> **æ³¨æ„ï¼š**\n> ç¨‹å¼ç¢¼ã€æ¨¡å‹åŠæ•¸æ“šé›†**åƒ…ä¾›ç ”ç©¶èˆ‡æ•™è‚²ç”¨é€”**ã€‚\n> **ç¦æ­¢å•†æ¥­ç”¨é€”ã€‚**\n> å¦‚éœ€å•†æ¥­æˆæ¬Šï¼Œè«‹è¯ç¹«ä½œè€…ã€‚\n\n**ğŸ“¦ ç¬¬ä¸‰æ–¹çµ„ä»¶**\n\n* **Stable Audio Open VAE**ï¼ˆç”± Stability AI æä¾›ï¼‰ï¼š\n  æœ¬å„²å­˜åº«åŒ…å«è‡ª [Stable Audio Open](https://huggingface.co/stabilityai/stable-audio-open-1.0/) å¾®èª¿ä¹‹ VAEï¼Œæˆæ¬Šä¾æ“š [Stability AI Community License](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/./third_party/LICENSE_StabilityAI.md)ã€‚\n  **å•†æ¥­ç”¨é€”èˆ‡å†ç™¼ä½ˆéœ€äº‹å…ˆå–å¾— Stability AI è¨±å¯ã€‚**\n\n* ğŸ“˜ **æ‰€æœ‰å…¶ä»–ç¨‹å¼ç¢¼èˆ‡æ¨¡å‹**çš†ä»¥ Apache License 2.0 é‡‹å‡ºã€‚\n\n---\n\n## è‡´è¬\n\nç‰¹åˆ¥æ„Ÿè¬ï¼š\n\n* **stable-audio-tools**ï¼ˆç”± Stability AI æä¾›ï¼‰ï¼š\næä¾›æ˜“æ–¼ä½¿ç”¨çš„éŸ³è¨Šç”Ÿæˆæ¡†æ¶ï¼Œä»¥åŠ VAE æ¨¡çµ„èˆ‡æ¬Šé‡ã€‚\n* **MMAudio**ï¼š\n  åœ¨éŸ³è¨Šé ˜åŸŸå¯¦ç¾ MM-DiT ä¸»å¹¹æ¶æ§‹ã€‚\n\n---\n\n## ğŸ“– å¼•ç”¨\n\nè‹¥æ‚¨åœ¨ç ”ç©¶æˆ–å·¥ä½œä¸­è¦ºå¾— ThinkSound æœ‰å¹«åŠ©ï¼Œè«‹å¼•ç”¨æœ¬è«–æ–‡ï¼š\n\n\n\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "## ğŸ‹ï¸ è¨“ç·´æ¨¡å‹"
      },
      {
        "row": 2,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 3,
        "rowsha": "gqXeKd562+SIhV8X5lKkIq9fmYls0JvenYq/r5leqGU=",
        "originContent": "## ğŸ‹ï¸ Train the Model",
        "translatedContent": "è«‹åƒé–± [`Training.md`](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/docs/Training.md)"
      },
      {
        "row": 4,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 5,
        "rowsha": "2tP4BwaoybodWdJJ8ZupmDbf3ea5A0f+lD6kd0qGru8=",
        "originContent": "See [`Training.md`](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/docs/Training.md)",
        "translatedContent": ""
      },
      {
        "row": 6,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "---"
      },
      {
        "row": 7,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 8,
        "rowsha": "yz+R1U7uMOU+NbK5mQX3Dxae1Un9eJCdPawt78ntjTs=",
        "originContent": "---",
        "translatedContent": "## ğŸ“ TODO èˆ‡æœªä¾†è¨ˆç•«"
      },
      {
        "row": 9,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "* - [ ] é–‹æº AudioCoT æ•¸æ“šé›†èˆ‡è‡ªå‹•åŒ–æµç¨‹ï¼ˆé è¨ˆæ–¼ 2025 å¹´ 7 æœˆ 23 æ—¥å‰ï¼‰"
      },
      {
        "row": 10,
        "rowsha": "21hoBW2Chiv9qZT66tUvbTf1cEdQjWTP1PUgVsUkdFY=",
        "originContent": "## ğŸ“ TODO & Future Plans",
        "translatedContent": "* - [ ] ç™¼å¸ƒæ¶µè“‹å¤šé ˜åŸŸã€æ›´å¼·å¤§çš„åŸºç¤æ¨¡å‹ï¼Œä»¥å¸¶ä¾†æ›´å…·å¸å¼•åŠ›èˆ‡æ²‰æµ¸æ„Ÿçš„æ“¬éŸ³å‰µä½œï¼ˆé è¨ˆæ–¼ 2025 å¹´ 8 æœˆåº•å‰ï¼‰"
      },
      {
        "row": 11,
        "rowsha": "BSIZGpY/yZMNK7fOauneKYGRm+1hDzo+Mu2V6he08qo=",
        "originContent": "* - [ ] Open-source AudioCoT dataset and automated pipeline (Expected before 07/23/2025)",
        "translatedContent": "* - [ ] å¢åŠ å°æ›´å¤šæ¨¡æ…‹èˆ‡ä¸‹æ¸¸ä»»å‹™çš„æ”¯æ´ï¼ˆé è¨ˆæ–¼ 2025 å¹´ 7 æœˆåº•å‰ï¼‰"
      },
      {
        "row": 12,
        "rowsha": "pngFpkGabb/lYcBffIdKTsEfy6A7rvQW7SveWlfjlxY=",
        "originContent": "* - [ ] Release a more powerful foundation model covering multiple domains to provide more engaging and immersive foley creation (Expected by end of August 2025)",
        "translatedContent": "* - [ ] ç™¼å¸ƒä¸åŒè¦æ¨¡çš„æ¨¡å‹ï¼ˆé è¨ˆæ–¼ 2025 å¹´ 7 æœˆåº•å‰ï¼‰"
      },
      {
        "row": 13,
        "rowsha": "LJxZcHWhItXExDnxDCValvP3y+54yrzAsyS4lmv/+rU=",
        "originContent": "* - [ ] Add support for additional modalities and downstream tasks (Expected before end of July 2025)",
        "translatedContent": "* - [x] é‡‹å‡º ThinkSound æ¨¡å‹è¨“ç·´è…³æœ¬"
      },
      {
        "row": 14,
        "rowsha": "XaQkB1iwFKeYv1+P1NqxrD8hUhTDw0pWVPBUxnOUA58=",
        "originContent": "* - [ ] Release models at different scales (Expected before end of July 2025)",
        "translatedContent": "* - [x] æ–°æ‰‹å‹å¥½çš„ Windows å¿«é€Ÿå…¥é–€ README"
      },
      {
        "row": 15,
        "rowsha": "k5iXHel4EfGgiGsMDCE6yv2H9ETcLNi9lRuB8gaPbt4=",
        "originContent": "* - [x] Release training scripts for ThinkSound models",
        "translatedContent": "---"
      },
      {
        "row": 16,
        "rowsha": "AKQD74q/2r77sZrB6i/RNuvdN/QOzatiPxneZX2CGJY=",
        "originContent": "* - [x] A beginner-friendly Windows quick-start README",
        "translatedContent": ""
      },
      {
        "row": 17,
        "rowsha": "yz+R1U7uMOU+NbK5mQX3Dxae1Un9eJCdPawt78ntjTs=",
        "originContent": "---",
        "translatedContent": "## ğŸ“„ æˆæ¬Šæ¢æ¬¾"
      },
      {
        "row": 18,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 19,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "æœ¬å°ˆæ¡ˆä»¥ Apache 2.0 æˆæ¬Šæ¢æ¬¾é‡‹å‡ºã€‚"
      },
      {
        "row": 20,
        "rowsha": "qdzKI50RqHyAaNHbQuVekCMXyk/TfGfppMlRPvlONC4=",
        "originContent": "## ğŸ“„ License",
        "translatedContent": ""
      },
      {
        "row": 21,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "> **æ³¨æ„ï¼š**"
      },
      {
        "row": 22,
        "rowsha": "aXzA1Vml4g3VpeAQHojytlHw5gMbI/HCXkxCOreR8fk=",
        "originContent": "This project is released under the Apache 2.0 License.",
        "translatedContent": "> ç¨‹å¼ç¢¼ã€æ¨¡å‹åŠæ•¸æ“šé›†**åƒ…ä¾›ç ”ç©¶èˆ‡æ•™è‚²ç”¨é€”**ã€‚"
      },
      {
        "row": 23,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "> **ç¦æ­¢å•†æ¥­ç”¨é€”ã€‚**"
      },
      {
        "row": 24,
        "rowsha": "q6szrCjtQrp9SVd3O6pmLDmi4BNjrSJj5JAz5iOimGA=",
        "originContent": "> **Note:**",
        "translatedContent": "> å¦‚éœ€å•†æ¥­æˆæ¬Šï¼Œè«‹è¯ç¹«ä½œè€…ã€‚"
      },
      {
        "row": 25,
        "rowsha": "rOuOE29N380ZQ7xL0jH7/C5Wx2byuzA8mLZWbrRiPMU=",
        "originContent": "> The code, models, and dataset are **for research and educational purposes only**.",
        "translatedContent": ""
      },
      {
        "row": 26,
        "rowsha": "FEb26wdcJZ+QYdFQmEiYYJyI1m7dr8KnrT/jJ+mJJ9E=",
        "originContent": "> **Commercial use is NOT permitted.**",
        "translatedContent": "**ğŸ“¦ ç¬¬ä¸‰æ–¹çµ„ä»¶**"
      },
      {
        "row": 27,
        "rowsha": "YQDz0urnAm3iQlKVm+90x6BIEceDXonnoA+1AGDIxUo=",
        "originContent": "> For commercial licensing, please contact the authors.",
        "translatedContent": ""
      },
      {
        "row": 28,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "* **Stable Audio Open VAE**ï¼ˆç”± Stability AI æä¾›ï¼‰ï¼š"
      },
      {
        "row": 29,
        "rowsha": "idCvsL23+SgGxeiktrTl5Y+r1XCJFcD6eO3243OaAPY=",
        "originContent": "**ğŸ“¦ Third-Party Components**",
        "translatedContent": "  æœ¬å„²å­˜åº«åŒ…å«è‡ª [Stable Audio Open](https://huggingface.co/stabilityai/stable-audio-open-1.0/) å¾®èª¿ä¹‹ VAEï¼Œæˆæ¬Šä¾æ“š [Stability AI Community License](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/./third_party/LICENSE_StabilityAI.md)ã€‚"
      },
      {
        "row": 30,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "  **å•†æ¥­ç”¨é€”èˆ‡å†ç™¼ä½ˆéœ€äº‹å…ˆå–å¾— Stability AI è¨±å¯ã€‚**"
      },
      {
        "row": 31,
        "rowsha": "WE7FE/+7lXbNs5ENH4uLy9/fzMNY1H60uSJ7lRbBD0o=",
        "originContent": "* **Stable Audio Open VAE** (by Stability AI):",
        "translatedContent": ""
      },
      {
        "row": 32,
        "rowsha": "n8R1JiNonohwAL0UGMf3R1xgnYRnz5fdUI6ZtkdzKnU=",
        "originContent": "  This repository includes a fine-tuned VAE from [Stable Audio Open](https://huggingface.co/stabilityai/stable-audio-open-1.0/), licensed under the [Stability AI Community License](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/./third_party/LICENSE_StabilityAI.md).",
        "translatedContent": "* ğŸ“˜ **æ‰€æœ‰å…¶ä»–ç¨‹å¼ç¢¼èˆ‡æ¨¡å‹**çš†ä»¥ Apache License 2.0 é‡‹å‡ºã€‚"
      },
      {
        "row": 33,
        "rowsha": "z1nrjZCTFkfKVpjvRtVTCvLJ3eIRc/0lYZ6q1FAyF9Y=",
        "originContent": "  **Commercial use and redistribution require prior permission from Stability AI.**",
        "translatedContent": ""
      },
      {
        "row": 34,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "---"
      },
      {
        "row": 35,
        "rowsha": "Rc/58q3GXX1uj9YQLKADnw6rI9fXJsB3qr7SgcFxhJQ=",
        "originContent": "* ğŸ“˜ **All other code and models** are released under the Apache License 2.0.",
        "translatedContent": ""
      },
      {
        "row": 36,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "## è‡´è¬"
      },
      {
        "row": 37,
        "rowsha": "yz+R1U7uMOU+NbK5mQX3Dxae1Un9eJCdPawt78ntjTs=",
        "originContent": "---",
        "translatedContent": ""
      },
      {
        "row": 38,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "ç‰¹åˆ¥æ„Ÿè¬ï¼š"
      },
      {
        "row": 39,
        "rowsha": "HvkwNudYOlwL8j/t4djBVF3hUJwHWa2r5QjmSxgq3AA=",
        "originContent": "## Acknowledgements",
        "translatedContent": ""
      },
      {
        "row": 40,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "* **stable-audio-tools**ï¼ˆç”± Stability AI æä¾›ï¼‰ï¼š"
      },
      {
        "row": 41,
        "rowsha": "nrozD4yXZdvCdVDGRjdO303ENLy2DrpELvY0lV8DjU4=",
        "originContent": "Many thanks to:",
        "translatedContent": "æä¾›æ˜“æ–¼ä½¿ç”¨çš„éŸ³è¨Šç”Ÿæˆæ¡†æ¶ï¼Œä»¥åŠ VAE æ¨¡çµ„èˆ‡æ¬Šé‡ã€‚"
      },
      {
        "row": 42,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "* **MMAudio**ï¼š"
      },
      {
        "row": 43,
        "rowsha": "7poAa5FddcjiBYp6TtQpLbB4qN57dBa/V6Oc1d6Ak1c=",
        "originContent": "* **stable-audio-tools** (by Stability AI):",
        "translatedContent": "  åœ¨éŸ³è¨Šé ˜åŸŸå¯¦ç¾ MM-DiT ä¸»å¹¹æ¶æ§‹ã€‚"
      },
      {
        "row": 44,
        "rowsha": "ChUiuc0nNLek0lyZz64pXvYp23+nJyAL95/UOo1ez4U=",
        "originContent": "For providing an easy-to-use framework for audio generation, as well as the VAE module and weights.",
        "translatedContent": ""
      },
      {
        "row": 45,
        "rowsha": "nn9Ut2wJSSgxPicEUDiiTuEnuQK99h2v5Ue5JFAtHN0=",
        "originContent": "* **MMAudio**:",
        "translatedContent": "---"
      },
      {
        "row": 46,
        "rowsha": "3yv6rAm2+j4agcTG/gcAtQLX1Kv0n/+YvFmBsObWoYo=",
        "originContent": "  For the implementation of the MM-DiT backbone in the audio domain.",
        "translatedContent": ""
      },
      {
        "row": 47,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "## ğŸ“– å¼•ç”¨"
      },
      {
        "row": 48,
        "rowsha": "yz+R1U7uMOU+NbK5mQX3Dxae1Un9eJCdPawt78ntjTs=",
        "originContent": "---",
        "translatedContent": ""
      },
      {
        "row": 49,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "è‹¥æ‚¨åœ¨ç ”ç©¶æˆ–å·¥ä½œä¸­è¦ºå¾— ThinkSound æœ‰å¹«åŠ©ï¼Œè«‹å¼•ç”¨æœ¬è«–æ–‡ï¼š"
      },
      {
        "row": 50,
        "rowsha": "syomH5Of+YY9KSCalKtADVZFMa9lRWCIOiYIqbfDgKI=",
        "originContent": "## ğŸ“– Citation",
        "translatedContent": ""
      },
      {
        "row": 51,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 52,
        "rowsha": "o5GEZn4azbbEeVodFzyyGdWtJ79JPcZQcPI33OuhB4o=",
        "originContent": "If you find ThinkSound useful in your research or work, please cite our paper:",
        "translatedContent": ""
      },
      {
        "row": 53,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 14,
    "Content": "```bibtex\n@misc{liu2025thinksoundchainofthoughtreasoningmultimodal,\n      title={ThinkSound: Chain-of-Thought Reasoning in Multimodal Large Language Models for Audio Generation and Editing}, \n      author={Huadai Liu and Jialei Wang and Kaicheng Luo and Wen Wang and Qian Chen and Zhou Zhao and Wei Xue},\n      year={2025},\n      eprint={2506.21448},\n      archivePrefix={arXiv},\n      primaryClass={eess.AS},\n      url={https://arxiv.org/abs/2506.21448}, \n}\n```",
    "ContentSha": "KKv35iBt6IDF1ifN04L+6lkh0BHkbObnW/+m50Wufrs=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bibtex\n@misc{liu2025thinksoundchainofthoughtreasoningmultimodal,\n      title={ThinkSound: Chain-of-Thought Reasoning in Multimodal Large Language Models for Audio Generation and Editing}, \n      author={Huadai Liu and Jialei Wang and Kaicheng Luo and Wen Wang and Qian Chen and Zhou Zhao and Wei Xue},\n      year={2025},\n      eprint={2506.21448},\n      archivePrefix={arXiv},\n      primaryClass={eess.AS},\n      url={https://arxiv.org/abs/2506.21448}, \n}\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 15,
    "Content": "\n---\n\n## ğŸ“¬ Contact\n\nâœ¨ Feel free to [open an issue](https://github.com/liuhuadai/ThinkSound/issues) or contact us via email ([liuhuadai@zju.edu.cn](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/mailto:liuhuadai@zju.edu.cn)) if you have any questions or suggestions!",
    "ContentSha": "Snq8+wbgyNtcTxjUtmf/hccl2QsJwcGSU5a2QF0XFhE=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "---\n\n## ğŸ“¬ è¯çµ¡æˆ‘å€‘\n\nâœ¨ å¦‚æœæ‚¨æœ‰ä»»ä½•å•é¡Œæˆ–å»ºè­°ï¼Œæ­¡è¿[æäº¤è­°é¡Œ](https://github.com/liuhuadai/ThinkSound/issues)æˆ–é€šéé›»å­éƒµä»¶è¯ç¹«æˆ‘å€‘ï¼ˆ[liuhuadai@zju.edu.cn](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/mailto:liuhuadai@zju.edu.cn)ï¼‰ï¼\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "---"
      },
      {
        "row": 2,
        "rowsha": "yz+R1U7uMOU+NbK5mQX3Dxae1Un9eJCdPawt78ntjTs=",
        "originContent": "---",
        "translatedContent": ""
      },
      {
        "row": 3,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "## ğŸ“¬ è¯çµ¡æˆ‘å€‘"
      },
      {
        "row": 4,
        "rowsha": "V0ea1xQLKG+cGj5kHVv5f15HDd+yj0ulkcBQnvErdJc=",
        "originContent": "## ğŸ“¬ Contact",
        "translatedContent": ""
      },
      {
        "row": 5,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "âœ¨ å¦‚æœæ‚¨æœ‰ä»»ä½•å•é¡Œæˆ–å»ºè­°ï¼Œæ­¡è¿[æäº¤è­°é¡Œ](https://github.com/liuhuadai/ThinkSound/issues)æˆ–é€šéé›»å­éƒµä»¶è¯ç¹«æˆ‘å€‘ï¼ˆ[liuhuadai@zju.edu.cn](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/mailto:liuhuadai@zju.edu.cn)ï¼‰ï¼"
      },
      {
        "row": 6,
        "rowsha": "QsDuVwX1DXlTNejKuNftx4k1x7yNHjfP9/1HS85hJng=",
        "originContent": "âœ¨ Feel free to [open an issue](https://github.com/liuhuadai/ThinkSound/issues) or contact us via email ([liuhuadai@zju.edu.cn](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/mailto:liuhuadai@zju.edu.cn)) if you have any questions or suggestions!",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  }
]