{
  "id": 2,
  "origin": "## üìù TODO\n\n- ‚òê Release training scripts for ThinkSound models\n- ‚òê Open-source AudioCoT dataset and automated pipeline\n- ‚òê Provide detailed documentation and API reference\n- ‚òê Add support for additional modalities and downstream tasks\n\n---\n\n## üìÑ License\n\nThis project is released under the [Apache 2.0 License](LICENSE).\n\n> **Note:**  \n> The code, models, and dataset are **for research and educational purposes only**.  \n> **Commercial use is NOT permitted.**\n>\n> For commercial licensing, please contact the authors.\n\n---\n\n## üìñ Citation\n\nIf you find ThinkSound useful in your research or work, please cite our paper:\n\n```bibtex\n@misc{liu2025thinksoundchainofthoughtreasoningmultimodal,\n      title={ThinkSound: Chain-of-Thought Reasoning in Multimodal Large Language Models for Audio Generation and Editing}, \n      author={Huadai Liu and Jialei Wang and Kaicheng Luo and Wen Wang and Qian Chen and Zhou Zhao and Wei Xue},\n      year={2025},\n      eprint={2506.21448},\n      archivePrefix={arXiv},\n      primaryClass={eess.AS},\n      url={https://arxiv.org/abs/2506.21448}, \n}\n```\n\n---\n\n## üì¨ Contact\n\n‚ú® Feel free to [open an issue](https://github.com/liuhuadai/ThinkSound/issues) or contact us via email ([liuhuadai@zju.edu.cn](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/mailto:liuhuadai@zju.edu.cn)) if you have any questions or suggestions!\n",
  "origin_sha": "NEFlwyN+fN3dUarHAXDiIoJazYSSuWRByH696fda+qA=",
  "translate": "## üìù TODO\n\n- ‚òê ‡πÄ‡∏ú‡∏¢‡πÅ‡∏û‡∏£‡πà‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏• ThinkSound\n- ‚òê ‡πÇ‡∏≠‡πÄ‡∏û‡∏ô‡∏ã‡∏≠‡∏£‡πå‡∏™‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• AudioCoT ‡πÅ‡∏•‡∏∞‡∏£‡∏∞‡∏ö‡∏ö‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥\n- ‚òê ‡∏à‡∏±‡∏î‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á API\n- ‚òê ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡πÇ‡∏°‡∏î‡∏≤‡∏•‡∏¥‡∏ï‡∏µ‡πÅ‡∏•‡∏∞‡∏á‡∏≤‡∏ô‡∏î‡∏≤‡∏ß‡∏ô‡πå‡∏™‡∏ï‡∏£‡∏µ‡∏°‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°\n\n---\n\n## üìÑ ‡∏•‡∏¥‡∏Ç‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå\n\n‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå‡∏ô‡∏µ‡πâ‡∏ñ‡∏π‡∏Å‡πÄ‡∏ú‡∏¢‡πÅ‡∏û‡∏£‡πà‡∏†‡∏≤‡∏¢‡πÉ‡∏ï‡πâ [‡∏™‡∏±‡∏ç‡∏ç‡∏≤‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï Apache 2.0](LICENSE)\n\n> **‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏:**  \n> ‡πÇ‡∏Ñ‡πâ‡∏î, ‡πÇ‡∏°‡πÄ‡∏î‡∏• ‡πÅ‡∏•‡∏∞‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡∏µ‡πâ **‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå‡∏î‡πâ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô**  \n> **‡πÑ‡∏°‡πà‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡πÄ‡∏ä‡∏¥‡∏á‡∏û‡∏≤‡∏ì‡∏¥‡∏ä‡∏¢‡πå**\n>\n> ‡∏´‡∏≤‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ç‡∏≠‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÄ‡∏ä‡∏¥‡∏á‡∏û‡∏≤‡∏ì‡∏¥‡∏ä‡∏¢‡πå ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠‡∏ú‡∏π‡πâ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô\n\n---\n\n## üìñ ‡∏Å‡∏≤‡∏£‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á\n\n‡∏´‡∏≤‡∏Å‡∏Ñ‡∏∏‡∏ì‡∏û‡∏ö‡∏ß‡πà‡∏≤ ThinkSound ‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå‡πÉ‡∏ô‡∏á‡∏≤‡∏ô‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡∏´‡∏£‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏ö‡∏ó‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤:\n\n```bibtex\n@misc{liu2025thinksoundchainofthoughtreasoningmultimodal,\n      title={ThinkSound: Chain-of-Thought Reasoning in Multimodal Large Language Models for Audio Generation and Editing}, \n      author={Huadai Liu and Jialei Wang and Kaicheng Luo and Wen Wang and Qian Chen and Zhou Zhao and Wei Xue},\n      year={2025},\n      eprint={2506.21448},\n      archivePrefix={arXiv},\n      primaryClass={eess.AS},\n      url={https://arxiv.org/abs/2506.21448}, \n}\n```\n\n---\n\n## üì¨ ‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠\n\n‚ú® ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ [‡πÄ‡∏õ‡∏¥‡∏î issue](https://github.com/liuhuadai/ThinkSound/issues) ‡∏´‡∏£‡∏∑‡∏≠ ‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠‡πÄ‡∏£‡∏≤‡∏ó‡∏≤‡∏á‡∏≠‡∏µ‡πÄ‡∏°‡∏• ([liuhuadai@zju.edu.cn](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/mailto:liuhuadai@zju.edu.cn)) ‡∏´‡∏≤‡∏Å‡∏Ñ‡∏∏‡∏ì‡∏°‡∏µ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏´‡∏£‡∏∑‡∏≠‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏ô‡∏≠‡πÅ‡∏ô‡∏∞!",
  "status": "ok"
}