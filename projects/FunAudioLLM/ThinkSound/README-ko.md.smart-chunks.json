[
  {
    "Id": 1,
    "Content": "<h1 align=\"center\">ThinkSound</h1>\n\n<p align=\"center\">\n  🌐\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=en\">English</a> |\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=zh-CN\">简体中文</a> |\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=zh-TW\">繁體中文</a> |\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=es\">Español</a> |\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=fr\">Français</a> |\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=ja\">日本語</a>\n  \n</p>\n\n<p align=\"center\">\n  <a href=\"https://arxiv.org/pdf/2506.21448\">\n    <img src=\"https://img.shields.io/badge/arXiv-2506.21448-b31b1b.svg\" alt=\"arXiv\"/>\n  </a>\n  &nbsp;\n  <a href=\"https://thinksound-project.github.io/\">\n    <img src=\"https://img.shields.io/badge/Online%20Demo-🌐-blue\" alt=\"Online Demo\"/>\n  </a>\n  &nbsp;\n  <a href=\"https://huggingface.co/spaces/FunAudioLLM/ThinkSound\">\n    <img src=\"https://img.shields.io/badge/HuggingFace-Spaces-orange?logo=huggingface\" alt=\"Hugging Face\"/>\n  </a>\n  &nbsp;\n  <a href=\"https://modelscope.cn/studios/iic/ThinkSound\">\n    <img src=\"https://img.shields.io/badge/ModelScope-在线体验-green\" alt=\"ModelScope\"/>\n  </a>\n</p>\n\n<p align=\"center\">\n  If you find this project useful,<br>\n  a star ⭐ on GitHub would be greatly appreciated!\n</p>\n\n---\n\n**ThinkSound** is a unified Any2Audio generation framework with flow matching guided by Chain-of-Thought (CoT) reasoning.\n\nPyTorch implementation for multimodal audio generation and editing: generate or edit audio from video, text, and audio, powered by step-by-step reasoning from Multimodal Large Language Models (MLLMs).\n\n![Teaser](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig1_teaser.png)\n---\n\n## 📰 News\n- **2025.07.15** &nbsp; 📦 Simplified installation and usability: dependencies on PyPI for easy cross-platform setup; Windows `.bat` scripts automate environment creation and script running.\n- **2025.07.08** &nbsp;  🔧 Major update: model lightweighted and optimized memory and GPU usage, now supports high-throughput audio generation at scale!\n- **2025.07.01** &nbsp; 🔥Online demo on [Hugging Face Spaces](https://huggingface.co/spaces/FunAudioLLM/ThinkSound) and [ModelScope](https://modelscope.cn/studios/iic/ThinkSound) for interactive experience!\n- **2025.07.01** &nbsp; 🔥Released inference scripts and web interface; \n- **2025.06** &nbsp; 🔥[ThinkSound paper](https://arxiv.org/pdf/2506.21448) released on arXiv!\n- **2025.06** &nbsp; 🔥[Online Demo](http://thinksound-project.github.io/) is live - try it now!\n\n---\n\n\n## 🚀 Features\n\n- **Any2Audio**: Generate audio from arbitrary modalities — video, text, audio, or their combinations.\n- **Video-to-Audio SOTA**: Achieves state-of-the-art results on multiple V2A benchmarks.\n- **CoT-Driven Reasoning**: Chain-of-Thought reasoning for compositional and controllable audio generation via MLLMs.\n- **Interactive Object-centric Editing**: Refine or edit specific sound events by clicking on visual objects or using text instructions.\n- **Unified Framework**: One foundation model supports generation, editing, and interactive workflow.\n\n---\n\n## ✨ Method Overview\n\nThinkSound decomposes audio generation and editing into three interactive stages, all guided by MLLM-based Chain-of-Thought (CoT) reasoning:\n\n1. **Foley Generation:** Generate foundational, semantically and temporally aligned soundscapes from video.\n2. **Object-Centric Refinement:** Refine or add sounds for user-specified objects via clicks or regions in the video.\n3. **Targeted Audio Editing:** Modify generated audio using high-level natural language instructions.\n\n![ThinkSound Overview](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig3_model.png)\n<!-- A large-scale CoT-annotated dataset (**AudioCoT**) is used to train both the reasoning module and the unified audio foundation model.\n![AudioCoT Pipeline](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig2_dataset.png) -->\n\n---\n\n## ⚡ Quick Start\n\n**Environment Preparation:**",
    "ContentSha": "QY5UNM6ZnpyovE0W5mCEPRYXtTRlbVfpAQUA8nFKaGw=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "<h1 align=\"center\">ThinkSound</h1>\n\n<p align=\"center\">\n  🌐\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=en\">English</a> |\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=zh-CN\">简体中文</a> |\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=zh-TW\">繁體中文</a> |\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=es\">Español</a> |\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=fr\">Français</a> |\n  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=ja\">日本語</a>\n  \n</p>\n\n<p align=\"center\">\n  <a href=\"https://arxiv.org/pdf/2506.21448\">\n    <img src=\"https://img.shields.io/badge/arXiv-2506.21448-b31b1b.svg\" alt=\"arXiv\"/>\n  </a>\n  &nbsp;\n  <a href=\"https://thinksound-project.github.io/\">\n    <img src=\"https://img.shields.io/badge/Online%20Demo-🌐-blue\" alt=\"Online Demo\"/>\n  </a>\n  &nbsp;\n  <a href=\"https://huggingface.co/spaces/FunAudioLLM/ThinkSound\">\n    <img src=\"https://img.shields.io/badge/HuggingFace-Spaces-orange?logo=huggingface\" alt=\"Hugging Face\"/>\n  </a>\n  &nbsp;\n  <a href=\"https://modelscope.cn/studios/iic/ThinkSound\">\n    <img src=\"https://img.shields.io/badge/ModelScope-在线体验-green\" alt=\"ModelScope\"/>\n  </a>\n</p>\n\n<p align=\"center\">\n  이 프로젝트가 유용하다면,<br>\n  GitHub에 별표 ⭐를 남겨주시면 큰 힘이 됩니다!\n</p>\n\n---\n\n**ThinkSound**는 Chain-of-Thought (CoT) 추론으로 유도되는 플로우 매칭 기반의 통합 Any2Audio 생성 프레임워크입니다.\n\nPyTorch 기반 멀티모달 오디오 생성 및 편집 구현: 비디오, 텍스트, 오디오로부터 오디오를 생성하거나 편집하며, 멀티모달 대형 언어 모델(MLLM)의 단계별 추론을 활용합니다.\n\n![Teaser](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig1_teaser.png)\n---\n\n## 📰 새 소식\n- **2025.07.15** &nbsp; 📦 설치 및 사용성 간소화: PyPI 기반 의존성으로 간편한 크로스 플랫폼 셋업; Windows `.bat` 스크립트로 환경 생성 및 스크립트 실행 자동화.\n- **2025.07.08** &nbsp;  🔧 주요 업데이트: 모델 경량화 및 메모리·GPU 사용 최적화, 대규모 고속 오디오 생성 지원!\n- **2025.07.01** &nbsp; 🔥[Hugging Face Spaces](https://huggingface.co/spaces/FunAudioLLM/ThinkSound) 및 [ModelScope](https://modelscope.cn/studios/iic/ThinkSound)에서 온라인 데모 제공!\n- **2025.07.01** &nbsp; 🔥추론 스크립트 및 웹 인터페이스 릴리즈; \n- **2025.06** &nbsp; 🔥[ThinkSound 논문](https://arxiv.org/pdf/2506.21448)이 arXiv에 공개되었습니다!\n- **2025.06** &nbsp; 🔥[온라인 데모](http://thinksound-project.github.io/) 오픈 - 지금 체험해보세요!\n\n---\n\n\n## 🚀 주요 특징\n\n- **Any2Audio**: 비디오, 텍스트, 오디오 또는 이들의 조합 등 임의의 모달리티로부터 오디오 생성.\n- **Video-to-Audio SOTA**: 다수의 V2A 벤치마크에서 최신 성능 달성.\n- **CoT 기반 추론**: MLLM을 통한 Chain-of-Thought 추론으로 조합적·제어 가능한 오디오 생성.\n- **인터랙티브 객체 중심 편집**: 시각적 객체 클릭 또는 텍스트 지시로 특정 사운드 이벤트 세밀 편집.\n- **통합 프레임워크**: 하나의 기반 모델로 생성, 편집, 인터랙티브 워크플로우 지원.\n\n---\n\n## ✨ 방법 개요\n\nThinkSound는 오디오 생성 및 편집을 MLLM 기반 Chain-of-Thought(COT) 추론으로 유도되는 세 가지 상호작용 단계로 분해합니다:\n\n1. **폴리 생성:** 비디오로부터 의미적·시간적으로 정렬된 기초 사운드스케이프 생성.\n2. **객체 중심 정제:** 비디오 내 클릭 또는 영역 지정으로 사용자가 선택한 객체의 사운드를 정제 또는 추가.\n3. **목표 지향 오디오 편집:** 자연어 지시문으로 생성된 오디오를 고수준에서 수정.\n\n![ThinkSound Overview](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig3_model.png)\n<!-- 대규모 CoT 주석 데이터셋(**AudioCoT**)으로 추론 모듈 및 통합 오디오 기반 모델을 모두 학습합니다.\n![AudioCoT Pipeline](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig2_dataset.png) -->\n\n---\n\n## ⚡ 빠른 시작\n\n**환경 준비:**",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "JxESpSOemcOHL7YK3E5sXNUt0UcsbKqLYX+tuvsu7P4=",
        "originContent": "<h1 align=\"center\">ThinkSound</h1>",
        "translatedContent": "<h1 align=\"center\">ThinkSound</h1>"
      },
      {
        "row": 2,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 3,
        "rowsha": "+/a9XmPwQixGFroME/GMEOLpReZZV4ARosR9orAplJY=",
        "originContent": "<p align=\"center\">",
        "translatedContent": "<p align=\"center\">"
      },
      {
        "row": 4,
        "rowsha": "CSeo6S41hUQEjrndf6ijg79FX29RUxiFJUVIA3cYsNQ=",
        "originContent": "  🌐",
        "translatedContent": "  🌐"
      },
      {
        "row": 5,
        "rowsha": "IJLGqpRt+7ez3r1WoZz6fvh/rC+8KZ5K3FP2xs/0LNM=",
        "originContent": "  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=en\">English</a> |",
        "translatedContent": "  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=en\">English</a> |"
      },
      {
        "row": 6,
        "rowsha": "hhbPoa8bqBB7SPpAAUVT30o77g3w0Ky5ywfQeyLf1j4=",
        "originContent": "  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=zh-CN\">简体中文</a> |",
        "translatedContent": "  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=zh-CN\">简体中文</a> |"
      },
      {
        "row": 7,
        "rowsha": "tRfgQgD9d867JyLy4SUrBX76D1lWSxv43P6AXFC6S+E=",
        "originContent": "  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=zh-TW\">繁體中文</a> |",
        "translatedContent": "  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=zh-TW\">繁體中文</a> |"
      },
      {
        "row": 8,
        "rowsha": "6wLn1diFukrW2YDUESRE3YVcqNY3dxojo6fHTtwy5Pw=",
        "originContent": "  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=es\">Español</a> |",
        "translatedContent": "  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=es\">Español</a> |"
      },
      {
        "row": 9,
        "rowsha": "evSE8XG0v3qXaLIwGU0C7m+8gbYGsKYAemuq5Tn6Xog=",
        "originContent": "  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=fr\">Français</a> |",
        "translatedContent": "  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=fr\">Français</a> |"
      },
      {
        "row": 10,
        "rowsha": "9f+fFClA7BNYID46cHbx1rrKXWcVW5LDZW5Zy7DVZ+w=",
        "originContent": "  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=ja\">日本語</a>",
        "translatedContent": "  <a href=\"https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=ja\">日本語</a>"
      },
      {
        "row": 11,
        "rowsha": "bBefIeb2K2KQVdirQPRU7QLki2hWORNHO4V9NjjiOyg=",
        "originContent": "  ",
        "translatedContent": "  "
      },
      {
        "row": 12,
        "rowsha": "dSdvPNAZSmR86FDDSF6tkQUCVfI9qmACHOR5tThOetY=",
        "originContent": "</p>",
        "translatedContent": "</p>"
      },
      {
        "row": 13,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 14,
        "rowsha": "+/a9XmPwQixGFroME/GMEOLpReZZV4ARosR9orAplJY=",
        "originContent": "<p align=\"center\">",
        "translatedContent": "<p align=\"center\">"
      },
      {
        "row": 15,
        "rowsha": "U41oE9v936BfSGDgJuMB1g3jQTqsJtmJPQUhVonUNHI=",
        "originContent": "  <a href=\"https://arxiv.org/pdf/2506.21448\">",
        "translatedContent": "  <a href=\"https://arxiv.org/pdf/2506.21448\">"
      },
      {
        "row": 16,
        "rowsha": "ynIImIY0Z2jVqizQykbwGTP/PcL0XGIQs5BslFVtz58=",
        "originContent": "    <img src=\"https://img.shields.io/badge/arXiv-2506.21448-b31b1b.svg\" alt=\"arXiv\"/>",
        "translatedContent": "    <img src=\"https://img.shields.io/badge/arXiv-2506.21448-b31b1b.svg\" alt=\"arXiv\"/>"
      },
      {
        "row": 17,
        "rowsha": "7Sl5c7caJ7+Yt222Hl2I2PLtk1UIeh8Qfn02MNONw0Y=",
        "originContent": "  </a>",
        "translatedContent": "  </a>"
      },
      {
        "row": 18,
        "rowsha": "robEj93GNR0ga47/E63BGVUMman0bHA00TiujTzIdqs=",
        "originContent": "  &nbsp;",
        "translatedContent": "  &nbsp;"
      },
      {
        "row": 19,
        "rowsha": "Yff0X0Mje5Jr8Vv7MEJie2CoYJL+UpE7RrCgKgVeN0c=",
        "originContent": "  <a href=\"https://thinksound-project.github.io/\">",
        "translatedContent": "  <a href=\"https://thinksound-project.github.io/\">"
      },
      {
        "row": 20,
        "rowsha": "H+PqZbUh0elg8uffxX9z5kKKpS5/odGusuxfm7oCW7w=",
        "originContent": "    <img src=\"https://img.shields.io/badge/Online%20Demo-🌐-blue\" alt=\"Online Demo\"/>",
        "translatedContent": "    <img src=\"https://img.shields.io/badge/Online%20Demo-🌐-blue\" alt=\"Online Demo\"/>"
      },
      {
        "row": 21,
        "rowsha": "7Sl5c7caJ7+Yt222Hl2I2PLtk1UIeh8Qfn02MNONw0Y=",
        "originContent": "  </a>",
        "translatedContent": "  </a>"
      },
      {
        "row": 22,
        "rowsha": "robEj93GNR0ga47/E63BGVUMman0bHA00TiujTzIdqs=",
        "originContent": "  &nbsp;",
        "translatedContent": "  &nbsp;"
      },
      {
        "row": 23,
        "rowsha": "8w8i7BBaV0MFFj9oV8SQ9+mUcgmT0lDsYIGPYBRMK4k=",
        "originContent": "  <a href=\"https://huggingface.co/spaces/FunAudioLLM/ThinkSound\">",
        "translatedContent": "  <a href=\"https://huggingface.co/spaces/FunAudioLLM/ThinkSound\">"
      },
      {
        "row": 24,
        "rowsha": "MShdQrgDW0rCwuvHGbK9UiqT/w2XoWfU6MCC4EQ8Oo0=",
        "originContent": "    <img src=\"https://img.shields.io/badge/HuggingFace-Spaces-orange?logo=huggingface\" alt=\"Hugging Face\"/>",
        "translatedContent": "    <img src=\"https://img.shields.io/badge/HuggingFace-Spaces-orange?logo=huggingface\" alt=\"Hugging Face\"/>"
      },
      {
        "row": 25,
        "rowsha": "7Sl5c7caJ7+Yt222Hl2I2PLtk1UIeh8Qfn02MNONw0Y=",
        "originContent": "  </a>",
        "translatedContent": "  </a>"
      },
      {
        "row": 26,
        "rowsha": "robEj93GNR0ga47/E63BGVUMman0bHA00TiujTzIdqs=",
        "originContent": "  &nbsp;",
        "translatedContent": "  &nbsp;"
      },
      {
        "row": 27,
        "rowsha": "ycu3inIAlcQNI/CFyarNMwyiRfw4GtBsvcc/0LcD3c0=",
        "originContent": "  <a href=\"https://modelscope.cn/studios/iic/ThinkSound\">",
        "translatedContent": "  <a href=\"https://modelscope.cn/studios/iic/ThinkSound\">"
      },
      {
        "row": 28,
        "rowsha": "4Z9FQa2ROL8/O+DmziXnhj/aKyTxS9GGOmocWYnVJ6g=",
        "originContent": "    <img src=\"https://img.shields.io/badge/ModelScope-在线体验-green\" alt=\"ModelScope\"/>",
        "translatedContent": "    <img src=\"https://img.shields.io/badge/ModelScope-在线体验-green\" alt=\"ModelScope\"/>"
      },
      {
        "row": 29,
        "rowsha": "7Sl5c7caJ7+Yt222Hl2I2PLtk1UIeh8Qfn02MNONw0Y=",
        "originContent": "  </a>",
        "translatedContent": "  </a>"
      },
      {
        "row": 30,
        "rowsha": "dSdvPNAZSmR86FDDSF6tkQUCVfI9qmACHOR5tThOetY=",
        "originContent": "</p>",
        "translatedContent": "</p>"
      },
      {
        "row": 31,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 32,
        "rowsha": "+/a9XmPwQixGFroME/GMEOLpReZZV4ARosR9orAplJY=",
        "originContent": "<p align=\"center\">",
        "translatedContent": "<p align=\"center\">"
      },
      {
        "row": 33,
        "rowsha": "fxEtxfqHrh5PDQ2L/Ev2ea69zRukpezpCLPOHXsEpDw=",
        "originContent": "  If you find this project useful,<br>",
        "translatedContent": "  이 프로젝트가 유용하다면,<br>"
      },
      {
        "row": 34,
        "rowsha": "oOAWVtx09WaVCvchPgX0GhZlzuPjXH1p6nhjfyZ2aS8=",
        "originContent": "  a star ⭐ on GitHub would be greatly appreciated!",
        "translatedContent": "  GitHub에 별표 ⭐를 남겨주시면 큰 힘이 됩니다!"
      },
      {
        "row": 35,
        "rowsha": "dSdvPNAZSmR86FDDSF6tkQUCVfI9qmACHOR5tThOetY=",
        "originContent": "</p>",
        "translatedContent": "</p>"
      },
      {
        "row": 36,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 37,
        "rowsha": "yz+R1U7uMOU+NbK5mQX3Dxae1Un9eJCdPawt78ntjTs=",
        "originContent": "---",
        "translatedContent": "---"
      },
      {
        "row": 38,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 39,
        "rowsha": "FQA4zA43MxvNXTogMO1WpS71bCSxerCOM1e/tmSmotg=",
        "originContent": "**ThinkSound** is a unified Any2Audio generation framework with flow matching guided by Chain-of-Thought (CoT) reasoning.",
        "translatedContent": "**ThinkSound**는 Chain-of-Thought (CoT) 추론으로 유도되는 플로우 매칭 기반의 통합 Any2Audio 생성 프레임워크입니다."
      },
      {
        "row": 40,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 41,
        "rowsha": "eexREJOMCITdo96Iwg4N4PQqu1ux/UwupfjVRj0l/L8=",
        "originContent": "PyTorch implementation for multimodal audio generation and editing: generate or edit audio from video, text, and audio, powered by step-by-step reasoning from Multimodal Large Language Models (MLLMs).",
        "translatedContent": "PyTorch 기반 멀티모달 오디오 생성 및 편집 구현: 비디오, 텍스트, 오디오로부터 오디오를 생성하거나 편집하며, 멀티모달 대형 언어 모델(MLLM)의 단계별 추론을 활용합니다."
      },
      {
        "row": 42,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 43,
        "rowsha": "+7Cx1rdpWiIOeWRA/RM6HsKf7pNA3hHsQk2Bpadt4II=",
        "originContent": "![Teaser](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig1_teaser.png)",
        "translatedContent": "![Teaser](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig1_teaser.png)"
      },
      {
        "row": 44,
        "rowsha": "yz+R1U7uMOU+NbK5mQX3Dxae1Un9eJCdPawt78ntjTs=",
        "originContent": "---",
        "translatedContent": "---"
      },
      {
        "row": 45,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 46,
        "rowsha": "0YeCyxpcm7/4RDbaM+OQoI8YfqEHQzDkpGW15VZdi1U=",
        "originContent": "## 📰 News",
        "translatedContent": "## 📰 새 소식"
      },
      {
        "row": 47,
        "rowsha": "Ae5w+cTrCd9E8qidC11IWJAgg+LuOgUxA4czDPNG/G0=",
        "originContent": "- **2025.07.15** &nbsp; 📦 Simplified installation and usability: dependencies on PyPI for easy cross-platform setup; Windows `.bat` scripts automate environment creation and script running.",
        "translatedContent": "- **2025.07.15** &nbsp; 📦 설치 및 사용성 간소화: PyPI 기반 의존성으로 간편한 크로스 플랫폼 셋업; Windows `.bat` 스크립트로 환경 생성 및 스크립트 실행 자동화."
      },
      {
        "row": 48,
        "rowsha": "nYxNhwgSqjwYLuWsfHAqP5sx2PnzYwoFrwcf9U+Fdss=",
        "originContent": "- **2025.07.08** &nbsp;  🔧 Major update: model lightweighted and optimized memory and GPU usage, now supports high-throughput audio generation at scale!",
        "translatedContent": "- **2025.07.08** &nbsp;  🔧 주요 업데이트: 모델 경량화 및 메모리·GPU 사용 최적화, 대규모 고속 오디오 생성 지원!"
      },
      {
        "row": 49,
        "rowsha": "xuARkITJMc1ABOl8/xX47dORDInuxwAsk8O1r5dvfpc=",
        "originContent": "- **2025.07.01** &nbsp; 🔥Online demo on [Hugging Face Spaces](https://huggingface.co/spaces/FunAudioLLM/ThinkSound) and [ModelScope](https://modelscope.cn/studios/iic/ThinkSound) for interactive experience!",
        "translatedContent": "- **2025.07.01** &nbsp; 🔥[Hugging Face Spaces](https://huggingface.co/spaces/FunAudioLLM/ThinkSound) 및 [ModelScope](https://modelscope.cn/studios/iic/ThinkSound)에서 온라인 데모 제공!"
      },
      {
        "row": 50,
        "rowsha": "aIpa8g7qqXl8Iq8shRpiY5Ha5WD8c9Pd9PWybZ+wr18=",
        "originContent": "- **2025.07.01** &nbsp; 🔥Released inference scripts and web interface; ",
        "translatedContent": "- **2025.07.01** &nbsp; 🔥추론 스크립트 및 웹 인터페이스 릴리즈; "
      },
      {
        "row": 51,
        "rowsha": "ynCJTuWmfRd3D7hcoW1WvIQ482zzFcdaXc8pgOG02Tw=",
        "originContent": "- **2025.06** &nbsp; 🔥[ThinkSound paper](https://arxiv.org/pdf/2506.21448) released on arXiv!",
        "translatedContent": "- **2025.06** &nbsp; 🔥[ThinkSound 논문](https://arxiv.org/pdf/2506.21448)이 arXiv에 공개되었습니다!"
      },
      {
        "row": 52,
        "rowsha": "se+rRi5CpnStAflq7OZvd/2mN+51ezQQaBeYckrGFCk=",
        "originContent": "- **2025.06** &nbsp; 🔥[Online Demo](http://thinksound-project.github.io/) is live - try it now!",
        "translatedContent": "- **2025.06** &nbsp; 🔥[온라인 데모](http://thinksound-project.github.io/) 오픈 - 지금 체험해보세요!"
      },
      {
        "row": 53,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 54,
        "rowsha": "yz+R1U7uMOU+NbK5mQX3Dxae1Un9eJCdPawt78ntjTs=",
        "originContent": "---",
        "translatedContent": "---"
      },
      {
        "row": 55,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 56,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 57,
        "rowsha": "f4oQIFLM2EJQxJ65F4oMEA7yWOIqs0eBtiIvGxI+GgI=",
        "originContent": "## 🚀 Features",
        "translatedContent": "## 🚀 주요 특징"
      },
      {
        "row": 58,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 59,
        "rowsha": "8TbVluJJPR3C0fX41HklpO/vH9/k/rHC+jlvmHHfzQU=",
        "originContent": "- **Any2Audio**: Generate audio from arbitrary modalities — video, text, audio, or their combinations.",
        "translatedContent": "- **Any2Audio**: 비디오, 텍스트, 오디오 또는 이들의 조합 등 임의의 모달리티로부터 오디오 생성."
      },
      {
        "row": 60,
        "rowsha": "+Jf5LrYz+d1ShYCuQe8UF9taEJUpuGhDk6fAlYK3Kj4=",
        "originContent": "- **Video-to-Audio SOTA**: Achieves state-of-the-art results on multiple V2A benchmarks.",
        "translatedContent": "- **Video-to-Audio SOTA**: 다수의 V2A 벤치마크에서 최신 성능 달성."
      },
      {
        "row": 61,
        "rowsha": "mU7qXkjW1YifKoYXJedYo9l64NsTBaiXsgoGFRF/g+E=",
        "originContent": "- **CoT-Driven Reasoning**: Chain-of-Thought reasoning for compositional and controllable audio generation via MLLMs.",
        "translatedContent": "- **CoT 기반 추론**: MLLM을 통한 Chain-of-Thought 추론으로 조합적·제어 가능한 오디오 생성."
      },
      {
        "row": 62,
        "rowsha": "RComOCBBrXsZf9RHmLginqKTh9eI/bKUZuUunQEmD5M=",
        "originContent": "- **Interactive Object-centric Editing**: Refine or edit specific sound events by clicking on visual objects or using text instructions.",
        "translatedContent": "- **인터랙티브 객체 중심 편집**: 시각적 객체 클릭 또는 텍스트 지시로 특정 사운드 이벤트 세밀 편집."
      },
      {
        "row": 63,
        "rowsha": "C3sf87sy73G/XZft+TDo5NjXo5XcrtJB805ayHRAXoQ=",
        "originContent": "- **Unified Framework**: One foundation model supports generation, editing, and interactive workflow.",
        "translatedContent": "- **통합 프레임워크**: 하나의 기반 모델로 생성, 편집, 인터랙티브 워크플로우 지원."
      },
      {
        "row": 64,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 65,
        "rowsha": "yz+R1U7uMOU+NbK5mQX3Dxae1Un9eJCdPawt78ntjTs=",
        "originContent": "---",
        "translatedContent": "---"
      },
      {
        "row": 66,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 67,
        "rowsha": "gjgLOIAU2x83BBZdLUdgEB+F64ajt/QuLYQXM1hDBLE=",
        "originContent": "## ✨ Method Overview",
        "translatedContent": "## ✨ 방법 개요"
      },
      {
        "row": 68,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 69,
        "rowsha": "v5//GqG/smYIGoUpN+12k+9/3GWH3GdYD+jLqScb7AM=",
        "originContent": "ThinkSound decomposes audio generation and editing into three interactive stages, all guided by MLLM-based Chain-of-Thought (CoT) reasoning:",
        "translatedContent": "ThinkSound는 오디오 생성 및 편집을 MLLM 기반 Chain-of-Thought(COT) 추론으로 유도되는 세 가지 상호작용 단계로 분해합니다:"
      },
      {
        "row": 70,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 71,
        "rowsha": "vTObEWb7f5gCU681X3dTkwqhsaSW89TLw3GgMJ5I3bo=",
        "originContent": "1. **Foley Generation:** Generate foundational, semantically and temporally aligned soundscapes from video.",
        "translatedContent": "1. **폴리 생성:** 비디오로부터 의미적·시간적으로 정렬된 기초 사운드스케이프 생성."
      },
      {
        "row": 72,
        "rowsha": "LTBpIQQHtEkNF8StAa+ZEDASGmRhmHIKDQOdZ4ExJWM=",
        "originContent": "2. **Object-Centric Refinement:** Refine or add sounds for user-specified objects via clicks or regions in the video.",
        "translatedContent": "2. **객체 중심 정제:** 비디오 내 클릭 또는 영역 지정으로 사용자가 선택한 객체의 사운드를 정제 또는 추가."
      },
      {
        "row": 73,
        "rowsha": "8wrAo7X7dPC6Sgpfrlq2ziv/Wg/3+JnlFYvO+RMxADQ=",
        "originContent": "3. **Targeted Audio Editing:** Modify generated audio using high-level natural language instructions.",
        "translatedContent": "3. **목표 지향 오디오 편집:** 자연어 지시문으로 생성된 오디오를 고수준에서 수정."
      },
      {
        "row": 74,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 75,
        "rowsha": "4UKlvFW3Xb0bSAVjcBNeekH/MMiYS0XDg9w4mCuPy/Q=",
        "originContent": "![ThinkSound Overview](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig3_model.png)",
        "translatedContent": "![ThinkSound Overview](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig3_model.png)"
      },
      {
        "row": 76,
        "rowsha": "GaujeIM3x7+YcFy07LNNyITlujhkgpgeIaOiKHJkYnE=",
        "originContent": "<!-- A large-scale CoT-annotated dataset (**AudioCoT**) is used to train both the reasoning module and the unified audio foundation model.",
        "translatedContent": "<!-- 대규모 CoT 주석 데이터셋(**AudioCoT**)으로 추론 모듈 및 통합 오디오 기반 모델을 모두 학습합니다."
      },
      {
        "row": 77,
        "rowsha": "qYOXaaTiYkoaPFcpTXE5xdSqqiW3ebi//EW/RfSXd9g=",
        "originContent": "![AudioCoT Pipeline](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig2_dataset.png) -->",
        "translatedContent": "![AudioCoT Pipeline](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig2_dataset.png) -->"
      },
      {
        "row": 78,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 79,
        "rowsha": "yz+R1U7uMOU+NbK5mQX3Dxae1Un9eJCdPawt78ntjTs=",
        "originContent": "---",
        "translatedContent": "---"
      },
      {
        "row": 80,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 81,
        "rowsha": "PrY/jc4yAHdS+Sr+s+Yhab477/BDp3GAzMJ8+WyumyI=",
        "originContent": "## ⚡ Quick Start",
        "translatedContent": "## ⚡ 빠른 시작"
      },
      {
        "row": 82,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 83,
        "rowsha": "mD63DGEpdc7FlccTEps0KPAiwsJpO/C3yjV+SKIi/vE=",
        "originContent": "**Environment Preparation:**",
        "translatedContent": "**환경 준비:**"
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 2,
    "Content": "```bash\ngit clone https://github.com/liuhuadai/ThinkSound.git\ncd ThinkSound\nconda create -n thinksound python=3.10\nconda activate thinksound\npip install thinksound\nconda install -y -c conda-forge 'ffmpeg<7'\n# Download pretrained weights https://huggingface.co/liuhuadai/ThinkSound to Directory ckpts/\n# model weights can be also downloaded from https://www.modelscope.cn/models/iic/ThinkSound\ngit lfs install\ngit clone https://huggingface.co/liuhuadai/ThinkSound ckpts\n# To improve inference and training speed, you may optionally install a FlashAttention backend compatible with your system and PyTorch version.\n```",
    "ContentSha": "CSBCDvBmuatxDa1cNMeHEBTJJzdLjK6wyO9v0LrETM8=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\ngit clone https://github.com/liuhuadai/ThinkSound.git\ncd ThinkSound\nconda create -n thinksound python=3.10\nconda activate thinksound\npip install thinksound\nconda install -y -c conda-forge 'ffmpeg<7'\n# Download pretrained weights https://huggingface.co/liuhuadai/ThinkSound to Directory ckpts/\n# model weights can be also downloaded from https://www.modelscope.cn/models/iic/ThinkSound\ngit lfs install\ngit clone https://huggingface.co/liuhuadai/ThinkSound ckpts\n# To improve inference and training speed, you may optionally install a FlashAttention backend compatible with your system and PyTorch version.\n```",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "rTMjNc+qNIxb1xXDR5hEYiJw1fc4muBwuBsTXVIaIho=",
        "originContent": "```bash",
        "translatedContent": "```bash"
      },
      {
        "row": 2,
        "rowsha": "R1Xupm2YCvNGSo0R1oDPlU263xV1q6Ii/X+znHRwSMg=",
        "originContent": "git clone https://github.com/liuhuadai/ThinkSound.git",
        "translatedContent": "git clone https://github.com/liuhuadai/ThinkSound.git"
      },
      {
        "row": 3,
        "rowsha": "kaCr2IlZUf/0jRFIQfiDYnz4RTyjJCNI5jaOHqxFlNw=",
        "originContent": "cd ThinkSound",
        "translatedContent": "cd ThinkSound"
      },
      {
        "row": 4,
        "rowsha": "/0rX4Xxr5vTCC+9HWeSyszEUsr6/+Pfrzto+nNr4Wmw=",
        "originContent": "conda create -n thinksound python=3.10",
        "translatedContent": "conda create -n thinksound python=3.10"
      },
      {
        "row": 5,
        "rowsha": "e+x6/3nrdpbjhP4v5SmNZTbngOcQNqH1RlPmaU6qhkI=",
        "originContent": "conda activate thinksound",
        "translatedContent": "conda activate thinksound"
      },
      {
        "row": 6,
        "rowsha": "qtiW4fMgC/G6jnEBSujA9CP2cNXkDmuMimjSQaMU1mg=",
        "originContent": "pip install thinksound",
        "translatedContent": "pip install thinksound"
      },
      {
        "row": 7,
        "rowsha": "Tr65QKkCGsD1ghGftcHZ4NKrw+EeOw00sJzBR5rByM8=",
        "originContent": "conda install -y -c conda-forge 'ffmpeg<7'",
        "translatedContent": "conda install -y -c conda-forge 'ffmpeg<7'"
      },
      {
        "row": 8,
        "rowsha": "9Y6oss9SmtPWB47e6QFt4+7jrC852JhZYlhLnrMDgow=",
        "originContent": "# Download pretrained weights https://huggingface.co/liuhuadai/ThinkSound to Directory ckpts/",
        "translatedContent": "# Download pretrained weights https://huggingface.co/liuhuadai/ThinkSound to Directory ckpts/"
      },
      {
        "row": 9,
        "rowsha": "2UtZgbdRiaSp+oSUVf+OwL1KFIBfKe3EnlO7Kzi7MFQ=",
        "originContent": "# model weights can be also downloaded from https://www.modelscope.cn/models/iic/ThinkSound",
        "translatedContent": "# model weights can be also downloaded from https://www.modelscope.cn/models/iic/ThinkSound"
      },
      {
        "row": 10,
        "rowsha": "clodLDXAiqjPHky4IWGjF9+WRBhuO6qdi8htIa3E0U0=",
        "originContent": "git lfs install",
        "translatedContent": "git lfs install"
      },
      {
        "row": 11,
        "rowsha": "RAcPf8pJvR/7lmRPTlJG292n3vBaGFJnaqsTZ5inaAQ=",
        "originContent": "git clone https://huggingface.co/liuhuadai/ThinkSound ckpts",
        "translatedContent": "git clone https://huggingface.co/liuhuadai/ThinkSound ckpts"
      },
      {
        "row": 12,
        "rowsha": "J03WWwyzoiBkYXOBeL6xJZAlyh2BidovVP8Ow7O1Rcs=",
        "originContent": "# To improve inference and training speed, you may optionally install a FlashAttention backend compatible with your system and PyTorch version.",
        "translatedContent": "# To improve inference and training speed, you may optionally install a FlashAttention backend compatible with your system and PyTorch version."
      },
      {
        "row": 13,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      }
    ],
    "IsCodeBlock": true
  },
  {
    "Id": 3,
    "Content": "\n> ✅ **Windows Tip:**  \n> Windows users can simply run `setup_windows.bat` (or double-click it) to automatically create the conda environment, install all dependencies (including FFmpeg), and download the pretrained model — no manual setup required.  \n> Make sure `conda` and `git` are installed and available in your system PATH before running the script.\n\n\n### ▶️ Run the Demo\n\n#### **Linux/macOS**\n",
    "ContentSha": "YGhm7lbBNPq6xLS6zXlFTPszO8rc4QZCwsScPNskcto=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "> ✅ **Windows 팁:**  \n> Windows 사용자는 `setup_windows.bat` 파일을 실행(또는 더블 클릭)하면 콘다 환경이 자동으로 생성되고, 모든 종속성(FFmpeg 포함)과 사전 학습된 모델이 다운로드됩니다 — 별도의 수동 설정이 필요하지 않습니다.  \n> 스크립트를 실행하기 전에 `conda`와 `git`이 시스템 PATH에 설치되어 있고 사용 가능한지 확인하세요.\n\n\n### ▶️ 데모 실행\n\n#### **Linux/macOS**\n\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "> ✅ **Windows 팁:**  "
      },
      {
        "row": 2,
        "rowsha": "bfNRy7WhSPxbnnj0dKFTvZnAmBtBoukQ35LKX67/lN4=",
        "originContent": "> ✅ **Windows Tip:**  ",
        "translatedContent": "> Windows 사용자는 `setup_windows.bat` 파일을 실행(또는 더블 클릭)하면 콘다 환경이 자동으로 생성되고, 모든 종속성(FFmpeg 포함)과 사전 학습된 모델이 다운로드됩니다 — 별도의 수동 설정이 필요하지 않습니다.  "
      },
      {
        "row": 3,
        "rowsha": "DcKqnY5qiULt6PXuE1M+fa8rAuf/wepUs9BzO8FTLA4=",
        "originContent": "> Windows users can simply run `setup_windows.bat` (or double-click it) to automatically create the conda environment, install all dependencies (including FFmpeg), and download the pretrained model — no manual setup required.  ",
        "translatedContent": "> 스크립트를 실행하기 전에 `conda`와 `git`이 시스템 PATH에 설치되어 있고 사용 가능한지 확인하세요."
      },
      {
        "row": 4,
        "rowsha": "EmRBUhYh8oZgb9XMXCGIMX3ww1RuNXBbm8vE1Oo0MEw=",
        "originContent": "> Make sure `conda` and `git` are installed and available in your system PATH before running the script.",
        "translatedContent": ""
      },
      {
        "row": 5,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 6,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "### ▶️ 데모 실행"
      },
      {
        "row": 7,
        "rowsha": "N0N1r9IBZHGSkTsDU5FudgjmYqCDI6+8RUYx2H+2iPs=",
        "originContent": "### ▶️ Run the Demo",
        "translatedContent": ""
      },
      {
        "row": 8,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "#### **Linux/macOS**"
      },
      {
        "row": 9,
        "rowsha": "5FGzHp/7uc5YpNXQZ01Xu4aUJuGQDQYamvIbkAWckfs=",
        "originContent": "#### **Linux/macOS**",
        "translatedContent": ""
      },
      {
        "row": 10,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 4,
    "Content": "```bash\nchmod +x scripts/demo.sh\n./scripts/demo.sh <path-to-your-demo-video> <title> <CoT description> [use-half]\n```",
    "ContentSha": "EW6OKf+6hdOehT5SO7gfI7wR8oAoMckp60MRfIA1jHc=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\nchmod +x scripts/demo.sh\n./scripts/demo.sh <path-to-your-demo-video> <title> <CoT description> [use-half]\n```",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "rTMjNc+qNIxb1xXDR5hEYiJw1fc4muBwuBsTXVIaIho=",
        "originContent": "```bash",
        "translatedContent": "```bash"
      },
      {
        "row": 2,
        "rowsha": "J5c1TjTdF0jSgopcRMpN5gJsxqFqqzDqSPsaXqi242w=",
        "originContent": "chmod +x scripts/demo.sh",
        "translatedContent": "chmod +x scripts/demo.sh"
      },
      {
        "row": 3,
        "rowsha": "oIgr2zQTH0d9MuO2YGFTPkw3iLl9YQPgcIhtav0rU6U=",
        "originContent": "./scripts/demo.sh <path-to-your-demo-video> <title> <CoT description> [use-half]",
        "translatedContent": "./scripts/demo.sh <path-to-your-demo-video> <title> <CoT description> [use-half]"
      },
      {
        "row": 4,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      }
    ],
    "IsCodeBlock": true
  },
  {
    "Id": 5,
    "Content": "\n#### **Windows**\n\nYou can use the provided `.bat` script instead:\n",
    "ContentSha": "zXqRZWTEWOuKZG1GOlqqZff+IH24zUwdPtSfwESqS9E=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "#### **Windows**\n\n대신 제공된 `.bat` 스크립트를 사용할 수 있습니다:\n\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "#### **Windows**"
      },
      {
        "row": 2,
        "rowsha": "IvNhdwV6MEZQPmXWBSKSY2UIwWunxNQWrk2BlOKlkQI=",
        "originContent": "#### **Windows**",
        "translatedContent": ""
      },
      {
        "row": 3,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "대신 제공된 `.bat` 스크립트를 사용할 수 있습니다:"
      },
      {
        "row": 4,
        "rowsha": "+Q8WG+ahtdog4pE0KhD58+hIi5d8cK/eqCv9QbNeAhU=",
        "originContent": "You can use the provided `.bat` script instead:",
        "translatedContent": ""
      },
      {
        "row": 5,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 6,
    "Content": "```bash\n.\\scripts\\demo.bat <path-to-your-demo-video> <title> <CoT description> [use-half]\n```",
    "ContentSha": "A2a1kVuIPNs8ht1a6LBYTEijJjnfjiTN0r+2n7VEJSg=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\n.\\scripts\\demo.bat <path-to-your-demo-video> <title> <CoT description> [use-half]\n```",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "rTMjNc+qNIxb1xXDR5hEYiJw1fc4muBwuBsTXVIaIho=",
        "originContent": "```bash",
        "translatedContent": "```bash"
      },
      {
        "row": 2,
        "rowsha": "SpoDkLiwYSUnjgeTzAh4JZqMd0lK1584yy5b7qucoiE=",
        "originContent": ".\\scripts\\demo.bat <path-to-your-demo-video> <title> <CoT description> [use-half]",
        "translatedContent": ".\\scripts\\demo.bat <path-to-your-demo-video> <title> <CoT description> [use-half]"
      },
      {
        "row": 3,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      }
    ],
    "IsCodeBlock": true
  },
  {
    "Id": 7,
    "Content": "\n**Note:**\n\n* `<path-to-your-demo-video>`: The path to a single video\n* `[use-half]` (optional): Add use-half at the end to enable half precision feature extraction.\n\n---\n\n### 📦 Batch Inference\n\n#### **Linux/macOS**\n",
    "ContentSha": "T7owm3ZZW7sVjKwFivgiuYX2+RVuNBl0RYTSnIcxxbM=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "**참고:**\n\n* `<path-to-your-demo-video>`: 단일 비디오의 경로\n* `[use-half]` (선택사항): 마지막에 use-half를 추가하여 하프 프리시전 특징 추출을 활성화합니다.\n\n---\n\n### 📦 배치 추론\n\n#### **Linux/macOS**\n\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "**참고:**"
      },
      {
        "row": 2,
        "rowsha": "LDViEFNefAj3r6IbuZpUsbi3yHQYqXlV59h97yxu73w=",
        "originContent": "**Note:**",
        "translatedContent": ""
      },
      {
        "row": 3,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "* `<path-to-your-demo-video>`: 단일 비디오의 경로"
      },
      {
        "row": 4,
        "rowsha": "48I09q6DeuVUkp3Ui7OEyWf9Ily3Ud2OBdiKDArldLo=",
        "originContent": "* `<path-to-your-demo-video>`: The path to a single video",
        "translatedContent": "* `[use-half]` (선택사항): 마지막에 use-half를 추가하여 하프 프리시전 특징 추출을 활성화합니다."
      },
      {
        "row": 5,
        "rowsha": "ens4JMYkg0aQjpfFvBkqVm1PgwR5rJkL+HSw4NGEVyQ=",
        "originContent": "* `[use-half]` (optional): Add use-half at the end to enable half precision feature extraction.",
        "translatedContent": ""
      },
      {
        "row": 6,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "---"
      },
      {
        "row": 7,
        "rowsha": "yz+R1U7uMOU+NbK5mQX3Dxae1Un9eJCdPawt78ntjTs=",
        "originContent": "---",
        "translatedContent": ""
      },
      {
        "row": 8,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "### 📦 배치 추론"
      },
      {
        "row": 9,
        "rowsha": "Q+f5RMbEuYfOdt2FDFHyk0Hr7grVpxDmGdtI8bdN4NE=",
        "originContent": "### 📦 Batch Inference",
        "translatedContent": ""
      },
      {
        "row": 10,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "#### **Linux/macOS**"
      },
      {
        "row": 11,
        "rowsha": "5FGzHp/7uc5YpNXQZ01Xu4aUJuGQDQYamvIbkAWckfs=",
        "originContent": "#### **Linux/macOS**",
        "translatedContent": ""
      },
      {
        "row": 12,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 8,
    "Content": "```bash\nchmod +x scripts/eval_batch.sh\n./scripts/eval_batch.sh <video_path> <csv_path> <save_path (optional)> [use-half]\n```",
    "ContentSha": "EQ4HuSYii55aHfgphESvOXMz2+Fq39+Xquxg6Z6uzdU=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\nchmod +x scripts/eval_batch.sh\n./scripts/eval_batch.sh <video_path> <csv_path> <save_path (optional)> [use-half]\n```",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "rTMjNc+qNIxb1xXDR5hEYiJw1fc4muBwuBsTXVIaIho=",
        "originContent": "```bash",
        "translatedContent": "```bash"
      },
      {
        "row": 2,
        "rowsha": "8NiNkrtlu77jFPD7Lh82B8MvHKOUyCV0TWiZgnwaGC8=",
        "originContent": "chmod +x scripts/eval_batch.sh",
        "translatedContent": "chmod +x scripts/eval_batch.sh"
      },
      {
        "row": 3,
        "rowsha": "wMz9evcS6E8WTRsrITU4FOHSqOUeY2aG0VdEZ4eG+j0=",
        "originContent": "./scripts/eval_batch.sh <video_path> <csv_path> <save_path (optional)> [use-half]",
        "translatedContent": "./scripts/eval_batch.sh <video_path> <csv_path> <save_path (optional)> [use-half]"
      },
      {
        "row": 4,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      }
    ],
    "IsCodeBlock": true
  },
  {
    "Id": 9,
    "Content": "\n#### **Windows**\n\nUse the equivalent `.bat` script:\n",
    "ContentSha": "njm5i6o3MR7AV4Q3WLctbe3LN1njFn89fPfTlo+zSmc=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "#### **Windows**\n\n동등한 `.bat` 스크립트를 사용하세요:\n\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "#### **Windows**"
      },
      {
        "row": 2,
        "rowsha": "IvNhdwV6MEZQPmXWBSKSY2UIwWunxNQWrk2BlOKlkQI=",
        "originContent": "#### **Windows**",
        "translatedContent": ""
      },
      {
        "row": 3,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "동등한 `.bat` 스크립트를 사용하세요:"
      },
      {
        "row": 4,
        "rowsha": "QDPJnlFM4AUl9Mmm6KtpF9+2vF665h/CroAPE3mSV0g=",
        "originContent": "Use the equivalent `.bat` script:",
        "translatedContent": ""
      },
      {
        "row": 5,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 10,
    "Content": "```bash\n.\\scripts\\eval_batch.bat <video_path> <csv_path> <save_path (optional)> [use-half]\n```",
    "ContentSha": "XLkAqxYBZeJiF6XnpshI6naENFsr5yFAH7af132cgb0=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\n.\\scripts\\eval_batch.bat <video_path> <csv_path> <save_path (optional)> [use-half]\n```",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "rTMjNc+qNIxb1xXDR5hEYiJw1fc4muBwuBsTXVIaIho=",
        "originContent": "```bash",
        "translatedContent": "```bash"
      },
      {
        "row": 2,
        "rowsha": "BTePyxyc6Ro/TLDXFnmnWeFuZDuWeC8a6weyCdB8RjE=",
        "originContent": ".\\scripts\\eval_batch.bat <video_path> <csv_path> <save_path (optional)> [use-half]",
        "translatedContent": ".\\scripts\\eval_batch.bat <video_path> <csv_path> <save_path (optional)> [use-half]"
      },
      {
        "row": 3,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      }
    ],
    "IsCodeBlock": true
  },
  {
    "Id": 11,
    "Content": "\n**Note:**\n\n* `<video_path>`: Path to the root directory containing all .mp4 videos to be processed (all videos must be of equal duration).\n* `<csv_path>`: A CSV file with text prompts for each video (see `demo_test.csv` for format).\n* `<save_path>` (optional): Where to save generated audio. Defaults to `results/features`.\n* `[use-half]` (optional): Add use-half at the end to enable half precision feature extraction.\n\n---\n\n\n### Web Interface Usage\n\nFor an interactive experience, launch the Gradio web interface:\n",
    "ContentSha": "yT/y6PXpYV8wS4qmKJfVNVGDLOwreTxCdCDFDv2VbLo=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "**참고:**\n\n* `<video_path>`: 처리할 모든 .mp4 비디오가 포함된 루트 디렉터리의 경로 (모든 비디오는 동일한 길이여야 합니다).\n* `<csv_path>`: 각 비디오에 대한 텍스트 프롬프트가 포함된 CSV 파일 (`demo_test.csv`에서 형식 참고).\n* `<save_path>` (선택사항): 생성된 오디오를 저장할 위치. 기본값은 `results/features`입니다.\n* `[use-half]` (선택사항): 마지막에 use-half를 추가하면 하프 프리시전 특징 추출이 활성화됩니다.\n\n---\n\n\n### 웹 인터페이스 사용법\n\n인터랙티브한 경험을 위해 Gradio 웹 인터페이스를 실행하세요:\n\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "**참고:**"
      },
      {
        "row": 2,
        "rowsha": "LDViEFNefAj3r6IbuZpUsbi3yHQYqXlV59h97yxu73w=",
        "originContent": "**Note:**",
        "translatedContent": ""
      },
      {
        "row": 3,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "* `<video_path>`: 처리할 모든 .mp4 비디오가 포함된 루트 디렉터리의 경로 (모든 비디오는 동일한 길이여야 합니다)."
      },
      {
        "row": 4,
        "rowsha": "2W5eTtvuUPrcK2v+A/18e/BX3qtS32uN+zKEaaLCVkw=",
        "originContent": "* `<video_path>`: Path to the root directory containing all .mp4 videos to be processed (all videos must be of equal duration).",
        "translatedContent": "* `<csv_path>`: 각 비디오에 대한 텍스트 프롬프트가 포함된 CSV 파일 (`demo_test.csv`에서 형식 참고)."
      },
      {
        "row": 5,
        "rowsha": "nJFYlnml6Fy8cRJyaFwusjEaRLjVQuwt0F5Ee+YBPbM=",
        "originContent": "* `<csv_path>`: A CSV file with text prompts for each video (see `demo_test.csv` for format).",
        "translatedContent": "* `<save_path>` (선택사항): 생성된 오디오를 저장할 위치. 기본값은 `results/features`입니다."
      },
      {
        "row": 6,
        "rowsha": "1SDMpljrrNqKgzgybFzlcPJPLABZwboG0dgHXDQ2IhI=",
        "originContent": "* `<save_path>` (optional): Where to save generated audio. Defaults to `results/features`.",
        "translatedContent": "* `[use-half]` (선택사항): 마지막에 use-half를 추가하면 하프 프리시전 특징 추출이 활성화됩니다."
      },
      {
        "row": 7,
        "rowsha": "ens4JMYkg0aQjpfFvBkqVm1PgwR5rJkL+HSw4NGEVyQ=",
        "originContent": "* `[use-half]` (optional): Add use-half at the end to enable half precision feature extraction.",
        "translatedContent": ""
      },
      {
        "row": 8,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "---"
      },
      {
        "row": 9,
        "rowsha": "yz+R1U7uMOU+NbK5mQX3Dxae1Un9eJCdPawt78ntjTs=",
        "originContent": "---",
        "translatedContent": ""
      },
      {
        "row": 10,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 11,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "### 웹 인터페이스 사용법"
      },
      {
        "row": 12,
        "rowsha": "XQzsbi1g1hG+TGIiO5bH2+mpTMKKH80wOyWRbBu1GzU=",
        "originContent": "### Web Interface Usage",
        "translatedContent": ""
      },
      {
        "row": 13,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "인터랙티브한 경험을 위해 Gradio 웹 인터페이스를 실행하세요:"
      },
      {
        "row": 14,
        "rowsha": "CxOaKBfiLYRZdWNX8eXrQXAWQT3TbLii7HHo/HqNdKg=",
        "originContent": "For an interactive experience, launch the Gradio web interface:",
        "translatedContent": ""
      },
      {
        "row": 15,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 12,
    "Content": "```bash\npython app.py\n```",
    "ContentSha": "2nQFYMHYtsOO4+egbu20DhxqoaxfzoH8CneeM8qTEb0=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\npython app.py\n```",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "rTMjNc+qNIxb1xXDR5hEYiJw1fc4muBwuBsTXVIaIho=",
        "originContent": "```bash",
        "translatedContent": "```bash"
      },
      {
        "row": 2,
        "rowsha": "yTP73cr3O39gKLRUBLHoG37pGRVYjUGUDuod1taGRp8=",
        "originContent": "python app.py",
        "translatedContent": "python app.py"
      },
      {
        "row": 3,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      }
    ],
    "IsCodeBlock": true
  },
  {
    "Id": 13,
    "Content": "\n---\n\n## 📝 TODO & Future Plans\n* - [ ] Release training scripts for ThinkSound models (Expected before 07/20/2025)\n* - [ ] Open-source AudioCoT dataset and automated pipeline (Expected before 07/23/2025)\n* - [ ] Provide a ready-to-use environment image (Expected before 07/23/2025)\n* - [ ] Release a more powerful foundation model covering multiple domains to provide more engaging and immersive foley creation (Expected by end of August 2025)\n* - [ ] Add support for additional modalities and downstream tasks (Expected before end of July 2025)\n* - [ ] Release models at different scales (Expected before end of July 2025)\n* - [x] A beginner-friendly Windows quick-start README\n---\n\n\n## 📄 License\n\nThis project is released under the Apache 2.0 License.\n\n> **Note:**\n> The code, models, and dataset are **for research and educational purposes only**.\n> **Commercial use is NOT permitted.**\n> For commercial licensing, please contact the authors.\n\n**📦 Third-Party Components**\n\n* **Stable Audio Open VAE** (by Stability AI):\n  This repository includes a fine-tuned VAE from [Stable Audio Open](https://huggingface.co/stabilityai/stable-audio-open-1.0/), licensed under the [Stability AI Community License](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/./third_party/LICENSE_StabilityAI.md).\n  **Commercial use and redistribution require prior permission from Stability AI.**\n\n* 📘 **All other code and models** are released under the Apache License 2.0.\n\n---\n\n## Acknowledgements\n\nMany thanks to:\n\n* **stable-audio-tools** (by Stability AI):\nFor providing an easy-to-use framework for audio generation, as well as the VAE module and weights.\n* **MMAudio**:\n  For the implementation of the MM-DiT backbone in the audio domain.\n\n---\n\n## 📖 Citation\n\nIf you find ThinkSound useful in your research or work, please cite our paper:\n",
    "ContentSha": "bpi7ofrOVbSl3RIIUdQ8jzda3WXJ5zBMknikMuXn1t8=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "---\n\n## 📝 TODO & 향후 계획\n* - [ ] ThinkSound 모델용 학습 스크립트 공개 (2025년 7월 20일 이전 예정)\n* - [ ] AudioCoT 데이터셋 및 자동화 파이프라인 오픈소스화 (2025년 7월 23일 이전 예정)\n* - [ ] 바로 사용할 수 있는 환경 이미지 제공 (2025년 7월 23일 이전 예정)\n* - [ ] 다양한 도메인을 아우르는 더욱 강력한 파운데이션 모델 공개로 더욱 몰입감 있는 폴리 제작 지원 (2025년 8월 말까지 예정)\n* - [ ] 추가적인 모달리티 및 다운스트림 작업 지원 추가 (2025년 7월 말 이전 예정)\n* - [ ] 다양한 스케일의 모델 공개 (2025년 7월 말 이전 예정)\n* - [x] 초보자를 위한 Windows 퀵스타트 README\n---\n\n\n## 📄 라이선스\n\n이 프로젝트는 Apache 2.0 라이선스로 공개됩니다.\n\n> **참고:**\n> 코드, 모델 및 데이터셋은 **연구 및 교육 목적에 한정**됩니다.\n> **상업적 사용은 허용되지 않습니다.**\n> 상업적 라이선스가 필요하신 경우, 저자에게 문의해 주세요.\n\n**📦 서드파티 컴포넌트**\n\n* **Stable Audio Open VAE** (Stability AI 제공):\n  본 저장소에는 [Stable Audio Open](https://huggingface.co/stabilityai/stable-audio-open-1.0/)에서 파인튜닝된 VAE가 포함되어 있으며, [Stability AI Community License](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/./third_party/LICENSE_StabilityAI.md) 하에 라이선스됩니다.\n  **상업적 사용 및 재배포는 Stability AI의 사전 허가가 필요합니다.**\n\n* 📘 **기타 모든 코드 및 모델**은 Apache License 2.0으로 공개됩니다.\n\n---\n\n## 감사의 말\n\n다음 분들께 깊이 감사드립니다:\n\n* **stable-audio-tools** (Stability AI 제공):\n오디오 생성 프레임워크와 VAE 모듈 및 가중치를 편리하게 제공해 주셨습니다.\n* **MMAudio**:\n  오디오 도메인에서 MM-DiT 백본 구현을 제공해 주셨습니다.\n\n---\n\n## 📖 인용 안내\n\nThinkSound가 연구나 작업에 도움이 되었다면, 논문을 인용해 주세요:\n\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "---"
      },
      {
        "row": 2,
        "rowsha": "yz+R1U7uMOU+NbK5mQX3Dxae1Un9eJCdPawt78ntjTs=",
        "originContent": "---",
        "translatedContent": ""
      },
      {
        "row": 3,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "## 📝 TODO & 향후 계획"
      },
      {
        "row": 4,
        "rowsha": "21hoBW2Chiv9qZT66tUvbTf1cEdQjWTP1PUgVsUkdFY=",
        "originContent": "## 📝 TODO & Future Plans",
        "translatedContent": "* - [ ] ThinkSound 모델용 학습 스크립트 공개 (2025년 7월 20일 이전 예정)"
      },
      {
        "row": 5,
        "rowsha": "dUdHxX/FiX1nPQsBsFot6omx0/kkHcHYBQSMvG8M5Uo=",
        "originContent": "* - [ ] Release training scripts for ThinkSound models (Expected before 07/20/2025)",
        "translatedContent": "* - [ ] AudioCoT 데이터셋 및 자동화 파이프라인 오픈소스화 (2025년 7월 23일 이전 예정)"
      },
      {
        "row": 6,
        "rowsha": "BSIZGpY/yZMNK7fOauneKYGRm+1hDzo+Mu2V6he08qo=",
        "originContent": "* - [ ] Open-source AudioCoT dataset and automated pipeline (Expected before 07/23/2025)",
        "translatedContent": "* - [ ] 바로 사용할 수 있는 환경 이미지 제공 (2025년 7월 23일 이전 예정)"
      },
      {
        "row": 7,
        "rowsha": "ht/OgxNCEhsdKfz7ShNd16AtjWVUYr1y1cO80pZPvJk=",
        "originContent": "* - [ ] Provide a ready-to-use environment image (Expected before 07/23/2025)",
        "translatedContent": "* - [ ] 다양한 도메인을 아우르는 더욱 강력한 파운데이션 모델 공개로 더욱 몰입감 있는 폴리 제작 지원 (2025년 8월 말까지 예정)"
      },
      {
        "row": 8,
        "rowsha": "pngFpkGabb/lYcBffIdKTsEfy6A7rvQW7SveWlfjlxY=",
        "originContent": "* - [ ] Release a more powerful foundation model covering multiple domains to provide more engaging and immersive foley creation (Expected by end of August 2025)",
        "translatedContent": "* - [ ] 추가적인 모달리티 및 다운스트림 작업 지원 추가 (2025년 7월 말 이전 예정)"
      },
      {
        "row": 9,
        "rowsha": "LJxZcHWhItXExDnxDCValvP3y+54yrzAsyS4lmv/+rU=",
        "originContent": "* - [ ] Add support for additional modalities and downstream tasks (Expected before end of July 2025)",
        "translatedContent": "* - [ ] 다양한 스케일의 모델 공개 (2025년 7월 말 이전 예정)"
      },
      {
        "row": 10,
        "rowsha": "XaQkB1iwFKeYv1+P1NqxrD8hUhTDw0pWVPBUxnOUA58=",
        "originContent": "* - [ ] Release models at different scales (Expected before end of July 2025)",
        "translatedContent": "* - [x] 초보자를 위한 Windows 퀵스타트 README"
      },
      {
        "row": 11,
        "rowsha": "AKQD74q/2r77sZrB6i/RNuvdN/QOzatiPxneZX2CGJY=",
        "originContent": "* - [x] A beginner-friendly Windows quick-start README",
        "translatedContent": "---"
      },
      {
        "row": 12,
        "rowsha": "yz+R1U7uMOU+NbK5mQX3Dxae1Un9eJCdPawt78ntjTs=",
        "originContent": "---",
        "translatedContent": ""
      },
      {
        "row": 13,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 14,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "## 📄 라이선스"
      },
      {
        "row": 15,
        "rowsha": "qdzKI50RqHyAaNHbQuVekCMXyk/TfGfppMlRPvlONC4=",
        "originContent": "## 📄 License",
        "translatedContent": ""
      },
      {
        "row": 16,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "이 프로젝트는 Apache 2.0 라이선스로 공개됩니다."
      },
      {
        "row": 17,
        "rowsha": "aXzA1Vml4g3VpeAQHojytlHw5gMbI/HCXkxCOreR8fk=",
        "originContent": "This project is released under the Apache 2.0 License.",
        "translatedContent": ""
      },
      {
        "row": 18,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "> **참고:**"
      },
      {
        "row": 19,
        "rowsha": "q6szrCjtQrp9SVd3O6pmLDmi4BNjrSJj5JAz5iOimGA=",
        "originContent": "> **Note:**",
        "translatedContent": "> 코드, 모델 및 데이터셋은 **연구 및 교육 목적에 한정**됩니다."
      },
      {
        "row": 20,
        "rowsha": "rOuOE29N380ZQ7xL0jH7/C5Wx2byuzA8mLZWbrRiPMU=",
        "originContent": "> The code, models, and dataset are **for research and educational purposes only**.",
        "translatedContent": "> **상업적 사용은 허용되지 않습니다.**"
      },
      {
        "row": 21,
        "rowsha": "FEb26wdcJZ+QYdFQmEiYYJyI1m7dr8KnrT/jJ+mJJ9E=",
        "originContent": "> **Commercial use is NOT permitted.**",
        "translatedContent": "> 상업적 라이선스가 필요하신 경우, 저자에게 문의해 주세요."
      },
      {
        "row": 22,
        "rowsha": "YQDz0urnAm3iQlKVm+90x6BIEceDXonnoA+1AGDIxUo=",
        "originContent": "> For commercial licensing, please contact the authors.",
        "translatedContent": ""
      },
      {
        "row": 23,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "**📦 서드파티 컴포넌트**"
      },
      {
        "row": 24,
        "rowsha": "idCvsL23+SgGxeiktrTl5Y+r1XCJFcD6eO3243OaAPY=",
        "originContent": "**📦 Third-Party Components**",
        "translatedContent": ""
      },
      {
        "row": 25,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "* **Stable Audio Open VAE** (Stability AI 제공):"
      },
      {
        "row": 26,
        "rowsha": "WE7FE/+7lXbNs5ENH4uLy9/fzMNY1H60uSJ7lRbBD0o=",
        "originContent": "* **Stable Audio Open VAE** (by Stability AI):",
        "translatedContent": "  본 저장소에는 [Stable Audio Open](https://huggingface.co/stabilityai/stable-audio-open-1.0/)에서 파인튜닝된 VAE가 포함되어 있으며, [Stability AI Community License](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/./third_party/LICENSE_StabilityAI.md) 하에 라이선스됩니다."
      },
      {
        "row": 27,
        "rowsha": "n8R1JiNonohwAL0UGMf3R1xgnYRnz5fdUI6ZtkdzKnU=",
        "originContent": "  This repository includes a fine-tuned VAE from [Stable Audio Open](https://huggingface.co/stabilityai/stable-audio-open-1.0/), licensed under the [Stability AI Community License](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/./third_party/LICENSE_StabilityAI.md).",
        "translatedContent": "  **상업적 사용 및 재배포는 Stability AI의 사전 허가가 필요합니다.**"
      },
      {
        "row": 28,
        "rowsha": "z1nrjZCTFkfKVpjvRtVTCvLJ3eIRc/0lYZ6q1FAyF9Y=",
        "originContent": "  **Commercial use and redistribution require prior permission from Stability AI.**",
        "translatedContent": ""
      },
      {
        "row": 29,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "* 📘 **기타 모든 코드 및 모델**은 Apache License 2.0으로 공개됩니다."
      },
      {
        "row": 30,
        "rowsha": "Rc/58q3GXX1uj9YQLKADnw6rI9fXJsB3qr7SgcFxhJQ=",
        "originContent": "* 📘 **All other code and models** are released under the Apache License 2.0.",
        "translatedContent": ""
      },
      {
        "row": 31,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "---"
      },
      {
        "row": 32,
        "rowsha": "yz+R1U7uMOU+NbK5mQX3Dxae1Un9eJCdPawt78ntjTs=",
        "originContent": "---",
        "translatedContent": ""
      },
      {
        "row": 33,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "## 감사의 말"
      },
      {
        "row": 34,
        "rowsha": "HvkwNudYOlwL8j/t4djBVF3hUJwHWa2r5QjmSxgq3AA=",
        "originContent": "## Acknowledgements",
        "translatedContent": ""
      },
      {
        "row": 35,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "다음 분들께 깊이 감사드립니다:"
      },
      {
        "row": 36,
        "rowsha": "nrozD4yXZdvCdVDGRjdO303ENLy2DrpELvY0lV8DjU4=",
        "originContent": "Many thanks to:",
        "translatedContent": ""
      },
      {
        "row": 37,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "* **stable-audio-tools** (Stability AI 제공):"
      },
      {
        "row": 38,
        "rowsha": "7poAa5FddcjiBYp6TtQpLbB4qN57dBa/V6Oc1d6Ak1c=",
        "originContent": "* **stable-audio-tools** (by Stability AI):",
        "translatedContent": "오디오 생성 프레임워크와 VAE 모듈 및 가중치를 편리하게 제공해 주셨습니다."
      },
      {
        "row": 39,
        "rowsha": "ChUiuc0nNLek0lyZz64pXvYp23+nJyAL95/UOo1ez4U=",
        "originContent": "For providing an easy-to-use framework for audio generation, as well as the VAE module and weights.",
        "translatedContent": "* **MMAudio**:"
      },
      {
        "row": 40,
        "rowsha": "nn9Ut2wJSSgxPicEUDiiTuEnuQK99h2v5Ue5JFAtHN0=",
        "originContent": "* **MMAudio**:",
        "translatedContent": "  오디오 도메인에서 MM-DiT 백본 구현을 제공해 주셨습니다."
      },
      {
        "row": 41,
        "rowsha": "3yv6rAm2+j4agcTG/gcAtQLX1Kv0n/+YvFmBsObWoYo=",
        "originContent": "  For the implementation of the MM-DiT backbone in the audio domain.",
        "translatedContent": ""
      },
      {
        "row": 42,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "---"
      },
      {
        "row": 43,
        "rowsha": "yz+R1U7uMOU+NbK5mQX3Dxae1Un9eJCdPawt78ntjTs=",
        "originContent": "---",
        "translatedContent": ""
      },
      {
        "row": 44,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "## 📖 인용 안내"
      },
      {
        "row": 45,
        "rowsha": "syomH5Of+YY9KSCalKtADVZFMa9lRWCIOiYIqbfDgKI=",
        "originContent": "## 📖 Citation",
        "translatedContent": ""
      },
      {
        "row": 46,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "ThinkSound가 연구나 작업에 도움이 되었다면, 논문을 인용해 주세요:"
      },
      {
        "row": 47,
        "rowsha": "o5GEZn4azbbEeVodFzyyGdWtJ79JPcZQcPI33OuhB4o=",
        "originContent": "If you find ThinkSound useful in your research or work, please cite our paper:",
        "translatedContent": ""
      },
      {
        "row": 48,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 14,
    "Content": "```bibtex\n@misc{liu2025thinksoundchainofthoughtreasoningmultimodal,\n      title={ThinkSound: Chain-of-Thought Reasoning in Multimodal Large Language Models for Audio Generation and Editing}, \n      author={Huadai Liu and Jialei Wang and Kaicheng Luo and Wen Wang and Qian Chen and Zhou Zhao and Wei Xue},\n      year={2025},\n      eprint={2506.21448},\n      archivePrefix={arXiv},\n      primaryClass={eess.AS},\n      url={https://arxiv.org/abs/2506.21448}, \n}\n```",
    "ContentSha": "KKv35iBt6IDF1ifN04L+6lkh0BHkbObnW/+m50Wufrs=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bibtex\n@misc{liu2025thinksoundchainofthoughtreasoningmultimodal,\n      title={ThinkSound: Chain-of-Thought Reasoning in Multimodal Large Language Models for Audio Generation and Editing}, \n      author={Huadai Liu and Jialei Wang and Kaicheng Luo and Wen Wang and Qian Chen and Zhou Zhao and Wei Xue},\n      year={2025},\n      eprint={2506.21448},\n      archivePrefix={arXiv},\n      primaryClass={eess.AS},\n      url={https://arxiv.org/abs/2506.21448}, \n}\n```",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "o+TmyQ6wneV6/FQB6aUlRSjIGr2/YLJtnz5uxBgsScQ=",
        "originContent": "```bibtex",
        "translatedContent": "```bibtex"
      },
      {
        "row": 2,
        "rowsha": "4+ZA4tDbpNTtaFwUjD825qSrgvPm1lp4oPjwYI9PYJo=",
        "originContent": "@misc{liu2025thinksoundchainofthoughtreasoningmultimodal,",
        "translatedContent": "@misc{liu2025thinksoundchainofthoughtreasoningmultimodal,"
      },
      {
        "row": 3,
        "rowsha": "bYh8o3dt2vfMgKFnVm8ZrZdgceMMCRKaqpOiLvQ2cTc=",
        "originContent": "      title={ThinkSound: Chain-of-Thought Reasoning in Multimodal Large Language Models for Audio Generation and Editing}, ",
        "translatedContent": "      title={ThinkSound: Chain-of-Thought Reasoning in Multimodal Large Language Models for Audio Generation and Editing}, "
      },
      {
        "row": 4,
        "rowsha": "Aj8WiSEmuROrmL/ndXB8bPn/Uo0Z2U2uoYhPC1sNqF8=",
        "originContent": "      author={Huadai Liu and Jialei Wang and Kaicheng Luo and Wen Wang and Qian Chen and Zhou Zhao and Wei Xue},",
        "translatedContent": "      author={Huadai Liu and Jialei Wang and Kaicheng Luo and Wen Wang and Qian Chen and Zhou Zhao and Wei Xue},"
      },
      {
        "row": 5,
        "rowsha": "1cuvfM9h03loQfZOlvsx9juVCvU41kevaYb2CnD9Gak=",
        "originContent": "      year={2025},",
        "translatedContent": "      year={2025},"
      },
      {
        "row": 6,
        "rowsha": "UdxL2SSDgD327+3Es1j0NqBL+O+TaOvODsNj3wAZ8qY=",
        "originContent": "      eprint={2506.21448},",
        "translatedContent": "      eprint={2506.21448},"
      },
      {
        "row": 7,
        "rowsha": "Fr73/KLqU4TaDaJVUDLO211nM029JE4YRpN5hXSZZqk=",
        "originContent": "      archivePrefix={arXiv},",
        "translatedContent": "      archivePrefix={arXiv},"
      },
      {
        "row": 8,
        "rowsha": "gDNCoWWvTWSOHtZ3IRlTQfSjVStr3eLRGZexyR0Z2z8=",
        "originContent": "      primaryClass={eess.AS},",
        "translatedContent": "      primaryClass={eess.AS},"
      },
      {
        "row": 9,
        "rowsha": "LS6ZYOTaY4CR1YwmP5AXaSGjJlV6P4f339/zMjq1NS8=",
        "originContent": "      url={https://arxiv.org/abs/2506.21448}, ",
        "translatedContent": "      url={https://arxiv.org/abs/2506.21448}, "
      },
      {
        "row": 10,
        "rowsha": "0Qs2qnSlm89KiBhYN/ZYr682Ru/yuxbDko0OkzXpRdI=",
        "originContent": "}",
        "translatedContent": "}"
      },
      {
        "row": 11,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      }
    ],
    "IsCodeBlock": true
  },
  {
    "Id": 15,
    "Content": "\n---\n\n## 📬 Contact\n\n✨ Feel free to [open an issue](https://github.com/liuhuadai/ThinkSound/issues) or contact us via email ([liuhuadai@zju.edu.cn](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/mailto:liuhuadai@zju.edu.cn)) if you have any questions or suggestions!\n",
    "ContentSha": "hTqr3DWxxu87ECLkZznrWo2x8aKpgYaJQhF8+85MzFc=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "---\n\n## 📬 연락처\n\n✨ 궁금한 점이나 제안사항이 있으시면 [이슈를 등록](https://github.com/liuhuadai/ThinkSound/issues)하시거나 이메일([liuhuadai@zju.edu.cn](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/mailto:liuhuadai@zju.edu.cn))로 연락해 주세요!\n\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "---"
      },
      {
        "row": 2,
        "rowsha": "yz+R1U7uMOU+NbK5mQX3Dxae1Un9eJCdPawt78ntjTs=",
        "originContent": "---",
        "translatedContent": ""
      },
      {
        "row": 3,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "## 📬 연락처"
      },
      {
        "row": 4,
        "rowsha": "V0ea1xQLKG+cGj5kHVv5f15HDd+yj0ulkcBQnvErdJc=",
        "originContent": "## 📬 Contact",
        "translatedContent": ""
      },
      {
        "row": 5,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "✨ 궁금한 점이나 제안사항이 있으시면 [이슈를 등록](https://github.com/liuhuadai/ThinkSound/issues)하시거나 이메일([liuhuadai@zju.edu.cn](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/mailto:liuhuadai@zju.edu.cn))로 연락해 주세요!"
      },
      {
        "row": 6,
        "rowsha": "QsDuVwX1DXlTNejKuNftx4k1x7yNHjfP9/1HS85hJng=",
        "originContent": "✨ Feel free to [open an issue](https://github.com/liuhuadai/ThinkSound/issues) or contact us via email ([liuhuadai@zju.edu.cn](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/mailto:liuhuadai@zju.edu.cn)) if you have any questions or suggestions!",
        "translatedContent": ""
      },
      {
        "row": 7,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  }
]