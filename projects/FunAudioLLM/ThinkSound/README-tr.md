<h1 align="center">ThinkSound</h1>

<p align="center">
  ğŸŒ
  <a href="https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=en">English</a> |
  <a href="https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=zh-CN">ç®€ä½“ä¸­æ–‡</a> |
  <a href="https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=zh-TW">ç¹é«”ä¸­æ–‡</a> |
  <a href="https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=es">EspaÃ±ol</a> |
  <a href="https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=fr">FranÃ§ais</a> |
  <a href="https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=ja">æ—¥æœ¬èª</a>
  
</p>

<p align="center">
  <a href="https://arxiv.org/pdf/2506.21448">
    <img src="https://img.shields.io/badge/arXiv-2506.21448-b31b1b.svg" alt="arXiv"/>
  </a>
  &nbsp;
  <a href="https://thinksound-project.github.io/">
    <img src="https://img.shields.io/badge/Online%20Demo-ğŸŒ-blue" alt="Online Demo"/>
  </a>
  &nbsp;
  <a href="https://huggingface.co/spaces/FunAudioLLM/ThinkSound">
    <img src="https://img.shields.io/badge/HuggingFace-Spaces-orange?logo=huggingface" alt="Hugging Face"/>
  </a>
  &nbsp;
  <a href="https://modelscope.cn/studios/iic/ThinkSound">
    <img src="https://img.shields.io/badge/ModelScope-åœ¨çº¿ä½“éªŒ-green" alt="ModelScope"/>
  </a>
</p>

<p align="center">
  EÄŸer bu projeyi faydalÄ± bulduysanÄ±z,<br>
  GitHub'da bir yÄ±ldÄ±z â­ bÄ±rakmanÄ±z Ã§ok memnun edici olur!
</p>

---

**ThinkSound** Zincirleme DÃ¼ÅŸÃ¼nme (Chain-of-Thought, CoT) Ã§Ä±karÄ±mÄ±yla yÃ¶nlendirilen akÄ±ÅŸ eÅŸleme (flow matching) ile birleÅŸik bir Any2Audio Ã¼retim Ã§erÃ§evesidir.

Multimodal ses Ã¼retimi ve dÃ¼zenlemesi iÃ§in PyTorch uygulamasÄ±: Multimodal BÃ¼yÃ¼k Dil Modelleri'nden (MLLMs) adÄ±m adÄ±m Ã§Ä±karÄ±m gÃ¼cÃ¼yle video, metin ve sesten ses oluÅŸturun veya dÃ¼zenleyin.

![Teaser](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig1_teaser.png)
---

## ğŸ“° Haberler
- **2025.07.17** &nbsp; ğŸ§  Ä°nce ayar etkin: EÄŸitim ve ince ayar kodu artÄ±k herkese aÃ§Ä±k; ThinkSound'u kendi verilerinizle Ã¶zelleÅŸtirmenize ve geniÅŸletmenize yardÄ±mcÄ± olacak net kullanÄ±m talimatlarÄ±yla birlikte.
- **2025.07.15** &nbsp; ğŸ“¦ BasitleÅŸtirilmiÅŸ kurulum ve kullanÄ±labilirlik: Kolay Ã§apraz platform kurulum iÃ§in PyPI'da baÄŸÄ±mlÄ±lÄ±klar; Windows `.bat` betikleri ortam oluÅŸturmayÄ± ve betik Ã§alÄ±ÅŸtÄ±rmayÄ± otomatikleÅŸtirir.
- **2025.07.08** &nbsp;Â  ğŸ”§ BÃ¼yÃ¼k gÃ¼ncelleme: Model hafifletildi ve bellek/GPU kullanÄ±mÄ± optimize edildi, artÄ±k Ã¶lÃ§ekli yÃ¼ksek verimli ses Ã¼retimi destekleniyor!
- **2025.07.01** &nbsp; ğŸ”¥[Hugging Face Spaces](https://huggingface.co/spaces/FunAudioLLM/ThinkSound) ve [ModelScope](https://modelscope.cn/studios/iic/ThinkSound) Ã¼zerinde Ã§evrimiÃ§i demo ile interaktif deneyim!
- **2025.07.01** &nbsp; ğŸ”¥Ã‡Ä±karÄ±m betikleri ve web arayÃ¼zÃ¼ yayÄ±nlandÄ±;
- **2025.06** &nbsp; ğŸ”¥[ThinkSound makalesi](https://arxiv.org/pdf/2506.21448) arXiv'de yayÄ±mlandÄ±!
- **2025.06** &nbsp; ğŸ”¥[Ã‡evrimiÃ§i Demo](http://thinksound-project.github.io/) aktif - hemen deneyin!

---


## ğŸš€ Ã–zellikler

- **Any2Audio**: Rastgele modlardan â€” video, metin, ses veya bunlarÄ±n birleÅŸimlerinden ses Ã¼retin.
- **Video'dan Sese SOTA**: BirÃ§ok V2A Ã¶lÃ§Ã¼tÃ¼nde gÃ¼ncel en iyi (state-of-the-art) sonuÃ§lar elde eder.
- **CoT TabanlÄ± Ã‡Ä±karÄ±m**: MLLM'ler aracÄ±lÄ±ÄŸÄ±yla bileÅŸen tabanlÄ± ve kontrol edilebilir ses Ã¼retimi iÃ§in Zincirleme DÃ¼ÅŸÃ¼nme Ã§Ä±karÄ±mÄ±.
- **EtkileÅŸimli Nesne Merkezli DÃ¼zenleme**: GÃ¶rsel nesnelere tÄ±klayarak veya metin talimatlarÄ±yla belirli ses olaylarÄ±nÄ± iyileÅŸtirin veya dÃ¼zenleyin.
- **BirleÅŸik Ã‡erÃ§eve**: Tek temel model ile Ã¼retim, dÃ¼zenleme ve etkileÅŸimli iÅŸ akÄ±ÅŸÄ± desteÄŸi.

---

## âœ¨ YÃ¶ntem Genel BakÄ±ÅŸ

ThinkSound, ses Ã¼retimi ve dÃ¼zenlemesini, tamamÄ± MLLM tabanlÄ± Zincirleme DÃ¼ÅŸÃ¼nme (CoT) ile yÃ¶nlendirilen Ã¼Ã§ etkileÅŸimli aÅŸamaya ayÄ±rÄ±r:

1. **Foley Ãœretimi:** Videodan anlamlÄ± ve zamansal olarak hizalÄ± temel ses ortamlarÄ± oluÅŸturun.
2. **Nesne Merkezli Ä°yileÅŸtirme:** Videodaki nesnelere tÄ±klayarak veya bÃ¶lgeleri seÃ§erek kullanÄ±cÄ± tarafÄ±ndan belirlenen nesneler iÃ§in sesleri iyileÅŸtirin veya ekleyin.
3. **Hedefe YÃ¶nelik Ses DÃ¼zenleme:** OluÅŸturulan sesi, Ã¼st dÃ¼zey doÄŸal dil talimatlarÄ±yla deÄŸiÅŸtirin.

![ThinkSound Genel BakÄ±ÅŸ](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig3_model.png)
<!-- BÃ¼yÃ¼k Ã¶lÃ§ekli CoT etiketli veri seti (**AudioCoT**), hem Ã§Ä±karÄ±m modÃ¼lÃ¼nÃ¼ hem de birleÅŸik ses temel modelini eÄŸitmek iÃ§in kullanÄ±lÄ±r.
![AudioCoT Pipeline](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig2_dataset.png) -->

---

## âš¡ HÄ±zlÄ± BaÅŸlangÄ±Ã§

**Ortam HazÄ±rlÄ±ÄŸÄ±:**
```bash
git clone https://github.com/liuhuadai/ThinkSound.git
cd ThinkSound
conda create -n thinksound python=3.10
conda activate thinksound
pip install thinksound
conda install -y -c conda-forge 'ffmpeg<7'
# Download pretrained weights https://huggingface.co/liuhuadai/ThinkSound to Directory ckpts/
# model weights can be also downloaded from https://www.modelscope.cn/models/iic/ThinkSound
git lfs install
git clone https://huggingface.co/liuhuadai/ThinkSound ckpts
# To improve inference and training speed, you may optionally install a FlashAttention backend compatible with your system and PyTorch version.
```
> âœ… **Windows Ä°pucu:**  
> Windows kullanÄ±cÄ±larÄ±, `setup_windows.bat` dosyasÄ±nÄ± Ã§alÄ±ÅŸtÄ±rarak (veya Ã§ift tÄ±klayarak) conda ortamÄ±nÄ± otomatik olarak oluÅŸturabilir, tÃ¼m baÄŸÄ±mlÄ±lÄ±klarÄ± (FFmpeg dahil) yÃ¼kleyebilir ve Ã¶nceden eÄŸitilmiÅŸ modeli indirebilir â€” elle kurulum gerekmez.  
> Scripti Ã§alÄ±ÅŸtÄ±rmadan Ã¶nce, `conda` ve `git`'in sistem PATH'inizde kurulu ve eriÅŸilebilir olduÄŸundan emin olun.


### â–¶ï¸ Demoyu Ã‡alÄ±ÅŸtÄ±rÄ±n

#### **Linux/macOS**


```bash
chmod +x scripts/demo.sh
./scripts/demo.sh <path-to-your-demo-video> <title> <CoT description> [use-half]
```
#### **Windows**

Bunun yerine saÄŸlanan `.bat` betiÄŸini kullanabilirsiniz:


```bash
.\scripts\demo.bat <path-to-your-demo-video> <title> <CoT description> [use-half]
```
**Not:**

* `<path-to-your-demo-video>`: Tek bir videonun yolu
* `[use-half]` (isteÄŸe baÄŸlÄ±): YarÄ± hassasiyetli Ã¶zellik Ã§Ä±karÄ±mÄ±nÄ± etkinleÅŸtirmek iÃ§in sona use-half ekleyin.

---

### ğŸ“¦ Toplu Ã‡Ä±karÄ±m

#### **Linux/macOS**


```bash
chmod +x scripts/eval_batch.sh
./scripts/eval_batch.sh <video_path> <csv_path> <save_path (optional)> [use-half]
```
#### **Windows**

EÅŸdeÄŸer `.bat` betiÄŸini kullanÄ±n:


```bash
.\scripts\eval_batch.bat <video_path> <csv_path> <save_path (optional)> [use-half]
```
**Not:**

* `<video_path>`: Ä°ÅŸlenecek tÃ¼m .mp4 videolarÄ±n bulunduÄŸu kÃ¶k dizinin yolu (tÃ¼m videolar aynÄ± sÃ¼rede olmalÄ±dÄ±r).
* `<csv_path>`: Her video iÃ§in metin istemleri iÃ§eren bir CSV dosyasÄ± (`demo_test.csv` formatÄ±na bakÄ±nÄ±z).
* `<save_path>` (isteÄŸe baÄŸlÄ±): OluÅŸturulan sesin kaydedileceÄŸi yer. VarsayÄ±lan olarak `results/features`.
* `[use-half]` (isteÄŸe baÄŸlÄ±): YarÄ± hassasiyetli Ã¶zellik Ã§Ä±karÄ±mÄ±nÄ± etkinleÅŸtirmek iÃ§in en sona use-half ekleyin.

---


### Web ArayÃ¼zÃ¼ KullanÄ±mÄ±

EtkileÅŸimli bir deneyim iÃ§in Gradio web arayÃ¼zÃ¼nÃ¼ baÅŸlatÄ±n:


```bash
python app.py
```
## ğŸ‹ï¸ Modeli EÄŸitin

[`Training.md`](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/docs/Training.md) dosyasÄ±na bakÄ±n.


---

## ğŸ“ YAPILACAKLAR & Gelecek Planlar
* - [ ] AudioCoT veri seti ve otomatik hattÄ±nÄ± aÃ§Ä±k kaynak yapmak (07/23/2025 Ã¶ncesi bekleniyor)
* - [ ] Ã‡oklu alanlarÄ± kapsayan, daha gÃ¼Ã§lÃ¼ bir temel model yayÄ±mlayarak daha ilgi Ã§ekici ve etkileyici foley oluÅŸturma saÄŸlamak (AÄŸustos 2025 sonuna kadar bekleniyor)
* - [ ] Ek modalliklere ve alt gÃ¶rev desteklerine ekleme yapmak (Temmuz 2025 Ã¶ncesi bekleniyor)
* - [ ] FarklÄ± Ã¶lÃ§eklerde modeller yayÄ±mlamak (Temmuz 2025 Ã¶ncesi bekleniyor)
* - [x] ThinkSound modelleri iÃ§in eÄŸitim betiklerini yayÄ±mlama
* - [x] Yeni baÅŸlayanlar iÃ§in Windows hÄ±zlÄ± baÅŸlangÄ±Ã§ README'si
---


## ğŸ“„ Lisans

Bu proje Apache 2.0 LisansÄ± altÄ±nda yayÄ±mlanmÄ±ÅŸtÄ±r.

> **Not:**
> Kod, modeller ve veri seti **sadece araÅŸtÄ±rma ve eÄŸitim amaÃ§lÄ±dÄ±r**.
> **Ticari kullanÄ±m Ä°ZÄ°N VERÄ°LMEZ.**
> Ticari lisanslama iÃ§in lÃ¼tfen yazarlarla iletiÅŸime geÃ§in.

**ğŸ“¦ ÃœÃ§Ã¼ncÃ¼ Taraf BileÅŸenler**

* **Stable Audio Open VAE** (Stability AI tarafÄ±ndan):
  Bu depo, [Stable Audio Open](https://huggingface.co/stabilityai/stable-audio-open-1.0/) Ã¼zerinden ince ayar yapÄ±lmÄ±ÅŸ bir VAE iÃ§erir ve [Stability AI Community License](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/./third_party/LICENSE_StabilityAI.md) kapsamÄ±nda lisanslanmÄ±ÅŸtÄ±r.
  **Ticari kullanÄ±m ve yeniden daÄŸÄ±tÄ±m iÃ§in Stability AI'dan Ã¶nceden izin alÄ±nmasÄ± gerekir.**

* ğŸ“˜ **DiÄŸer tÃ¼m kod ve modeller** Apache License 2.0 kapsamÄ±nda yayÄ±mlanmÄ±ÅŸtÄ±r.

---

## TeÅŸekkÃ¼rler

TeÅŸekkÃ¼rler:

* **stable-audio-tools** (Stability AI tarafÄ±ndan):
Ses Ã¼retimi iÃ§in kullanÄ±mÄ± kolay bir Ã§erÃ§eve, ayrÄ±ca VAE modÃ¼lÃ¼ ve aÄŸÄ±rlÄ±klarÄ± saÄŸladÄ±ÄŸÄ±nÄ±z iÃ§in.
* **MMAudio**:
  Ses alanÄ±nda MM-DiT omurgasÄ±nÄ±n uygulanmasÄ± iÃ§in.

---

## ğŸ“– AtÄ±f

ThinkSound'un araÅŸtÄ±rmanÄ±zda veya Ã§alÄ±ÅŸmalarÄ±nÄ±zda faydalÄ± olduÄŸunu dÃ¼ÅŸÃ¼nÃ¼yorsanÄ±z, lÃ¼tfen makalemizi kaynak gÃ¶sterin:



```bibtex
@misc{liu2025thinksoundchainofthoughtreasoningmultimodal,
      title={ThinkSound: Chain-of-Thought Reasoning in Multimodal Large Language Models for Audio Generation and Editing}, 
      author={Huadai Liu and Jialei Wang and Kaicheng Luo and Wen Wang and Qian Chen and Zhou Zhao and Wei Xue},
      year={2025},
      eprint={2506.21448},
      archivePrefix={arXiv},
      primaryClass={eess.AS},
      url={https://arxiv.org/abs/2506.21448}, 
}
```
---

## ğŸ“¬ Ä°letiÅŸim

âœ¨ Herhangi bir sorunuz veya Ã¶neriniz varsa, [bir issue aÃ§maktan](https://github.com/liuhuadai/ThinkSound/issues) veya bize e-posta ile ulaÅŸmaktan ([liuhuadai@zju.edu.cn](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/mailto:liuhuadai@zju.edu.cn)) Ã§ekinmeyin!


---

Tranlated By [Open Ai Tx](https://github.com/OpenAiTx/OpenAiTx) | Last indexed: 2025-07-17

---