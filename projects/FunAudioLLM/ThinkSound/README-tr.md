# ğŸ¶ ThinkSound

<p align="center">
  EÄŸer bu projeyi faydalÄ± bulduysanÄ±z, GitHub'da bir yÄ±ldÄ±z â­ bÄ±rakmanÄ±z Ã§ok memnun edici olurdu!
</p>

<p align="center">
  <a href="https://arxiv.org/pdf/2506.21448">
    <img src="https://img.shields.io/badge/arXiv-2506.21448-b31b1b.svg" alt="arXiv"/>
  </a>
  &nbsp;
  <a href="https://thinksound-project.github.io/">
    <img src="https://img.shields.io/badge/Online%20Demo-ğŸŒ-blue" alt="Online Demo"/>
  </a>
  &nbsp;
  <a href="https://huggingface.co/spaces/FunAudioLLM/ThinkSound">
    <img src="https://img.shields.io/badge/HuggingFace-Spaces-orange?logo=huggingface" alt="Hugging Face"/>
  </a>
  &nbsp;
  <a href="https://modelscope.cn/studios/iic/ThinkSound">
    <img src="https://img.shields.io/badge/ModelScope-åœ¨çº¿ä½“éªŒ-green" alt="ModelScope"/>
  </a>
</p>

---

**ThinkSound**, Zincirleme DÃ¼ÅŸÃ¼nce (CoT) akÄ±l yÃ¼rÃ¼tme ile yÃ¶nlendirilen flow-matching tabanlÄ± birleÅŸik bir Any2Audio Ã¼retim Ã§erÃ§evesidir.

GÃ¶rÃ¼ntÃ¼, metin ve ses girdilerinden ses Ã¼retimi veya dÃ¼zenlemesi iÃ§in PyTorch implementasyonu: Multimodal BÃ¼yÃ¼k Dil Modelleri (MLLM) Ã¼zerinden adÄ±m adÄ±m akÄ±l yÃ¼rÃ¼tme ile gÃ¼Ã§lendirilmiÅŸtir.

![Teaser](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig1_teaser.png)
---

## ğŸ“° Haberler
- **2025.07** &nbsp; ğŸ”¥[Hugging Face Spaces](https://huggingface.co/spaces/FunAudioLLM/ThinkSound) ve [ModelScope](https://modelscope.cn/studios/iic/ThinkSound) Ã¼zerinde etkileÅŸimli deneyim iÃ§in Ã§evrim iÃ§i demo yayÄ±nda!
- **2025.07** &nbsp; ğŸ”¥Ã‡Ä±karÄ±m (inference) betikleri ve web arayÃ¼zÃ¼ yayÄ±nlandÄ±;
- **2025.06** &nbsp; ğŸ”¥[ThinkSound makalesi](https://arxiv.org/pdf/2506.21448) arXiv'de yayÄ±nlandÄ±!
- **2025.06** &nbsp; ğŸ”¥[Ã‡evrim Ä°Ã§i Demo](http://thinksound-project.github.io/) yayÄ±nda - hemen deneyin!

---

## ğŸš€ Ã–zellikler

- **Any2Audio**: Rastgele modlardan â€” video, metin, ses veya bunlarÄ±n kombinasyonlarÄ±ndan â€” ses Ã¼retimi.
- **Video'dan Sese SOTA**: BirÃ§ok V2A (Video to Audio) benchmark'Ä±nda en son teknoloji (state-of-the-art) sonuÃ§lar.
- **CoT TabanlÄ± AkÄ±l YÃ¼rÃ¼tme**: MLLM'ler ile adÄ±m adÄ±m zincirleme dÃ¼ÅŸÃ¼nce akÄ±l yÃ¼rÃ¼tmesiyle bileÅŸen tabanlÄ± ve kontrol edilebilir ses Ã¼retimi.
- **EtkileÅŸimli Nesne Merkezli DÃ¼zenleme**: GÃ¶rsel nesnelere tÄ±klayarak veya metin talimatlarÄ±yla belirli ses olaylarÄ±nÄ± dÃ¼zenleyin veya iyileÅŸtirin.
- **BirleÅŸik Ã‡erÃ§eve**: Tek bir temel model ile Ã¼retim, dÃ¼zenleme ve etkileÅŸimli iÅŸ akÄ±ÅŸÄ± desteÄŸi.

---

## âœ¨ YÃ¶ntem Genel BakÄ±ÅŸÄ±

ThinkSound, ses Ã¼retimi ve dÃ¼zenleme iÅŸlemini, tamamÄ± MLLM tabanlÄ± Zincirleme DÃ¼ÅŸÃ¼nce (CoT) akÄ±l yÃ¼rÃ¼tme ile yÃ¶nlendirilen Ã¼Ã§ etkileÅŸimli aÅŸamaya ayÄ±rÄ±r:

1. **Foley Ãœretimi:** Videodan anlamca ve zamansal olarak hizalÄ± temel ses manzaralarÄ± Ã¼retir.
2. **Nesne Merkezli Ä°yileÅŸtirme:** KullanÄ±cÄ± tarafÄ±ndan belirtilen nesneler iÃ§in video Ã¼zerinde tÄ±klama veya bÃ¶lge seÃ§imi ile sesleri iyileÅŸtirin veya ekleyin.
3. **Hedefli Ses DÃ¼zenleme:** Ãœretilen sesi yÃ¼ksek seviyeli doÄŸal dil talimatlarÄ±yla dÃ¼zenleyin.

![ThinkSound Overview](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig3_model.png)
<!-- GeniÅŸ Ã§aplÄ± CoT ile aÃ§Ä±klamalÄ± bir veri kÃ¼mesi (**AudioCoT**), hem akÄ±l yÃ¼rÃ¼tme modÃ¼lÃ¼nÃ¼ hem de birleÅŸik ses temel modelini eÄŸitmek iÃ§in kullanÄ±lÄ±r.
![AudioCoT Pipeline](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig2_dataset.png) -->

---

## âš¡ HÄ±zlÄ± BaÅŸlangÄ±Ã§

**Ortam HazÄ±rlÄ±ÄŸÄ±:**
```bash
git clone https://github.com/liuhuadai/ThinkSound.git
cd ThinkSound
pip install -r requirements.txt
conda install -y -c conda-forge 'ffmpeg<7'
# Ã–nceden eÄŸitilmiÅŸ aÄŸÄ±rlÄ±klarÄ± https://huggingface.co/liuhuadai/ThinkSound adresinden ckpts/ dizinine indirin
# Model aÄŸÄ±rlÄ±klarÄ± ayrÄ±ca https://www.modelscope.cn/models/iic/ThinkSound adresinden indirilebilir
git lfs install
git clone https://huggingface.co/liuhuadai/ThinkSound ckpts
```

**Ã‡alÄ±ÅŸtÄ±rÄ±labilir yapÄ±n**
```bash
chmod +x scripts/demo.sh
```

**Betik Ã§alÄ±ÅŸtÄ±rma**
```bash
./scripts/demo.sh <video_yolu> <altyazÄ±> <CoT aÃ§Ä±klamasÄ±>
```


### Web ArayÃ¼zÃ¼ KullanÄ±mÄ±

EtkileÅŸimli bir deneyim iÃ§in Gradio web arayÃ¼zÃ¼nÃ¼ baÅŸlatÄ±n:

```bash
python app.py
```

---
## ğŸ“ YAPILACAKLAR

- â˜ ThinkSound modelleri iÃ§in eÄŸitim betiklerini yayÄ±mla
- â˜ AudioCoT veri setini ve otomatikleÅŸtirilmiÅŸ hattÄ± aÃ§Ä±k kaynak yap
- â˜ AyrÄ±ntÄ±lÄ± dokÃ¼mantasyon ve API referansÄ± saÄŸla
- â˜ Ek modallikler ve ardÄ±l gÃ¶revler iÃ§in destek ekle

---

## ğŸ“„ Lisans

Bu proje [Apache 2.0 LisansÄ±](LICENSE) altÄ±nda yayÄ±mlanmÄ±ÅŸtÄ±r.

> **Not:**  
> Kod, modeller ve veri seti **yalnÄ±zca araÅŸtÄ±rma ve eÄŸitim amaÃ§lÄ±dÄ±r**.  
> **Ticari kullanÄ±m Ä°ZÄ°N VERÄ°LMEMEKTEDÄ°R.**
>
> Ticari lisanslama iÃ§in lÃ¼tfen yazarlarla iletiÅŸime geÃ§in.

---

## ğŸ“– AtÄ±f

ThinkSound'u araÅŸtÄ±rmanÄ±zda veya Ã§alÄ±ÅŸmalarÄ±nÄ±zda faydalÄ± bulursanÄ±z, lÃ¼tfen makalemizi kaynak gÃ¶sterin:

```bibtex
@misc{liu2025thinksoundchainofthoughtreasoningmultimodal,
      title={ThinkSound: Chain-of-Thought Reasoning in Multimodal Large Language Models for Audio Generation and Editing}, 
      author={Huadai Liu and Jialei Wang and Kaicheng Luo and Wen Wang and Qian Chen and Zhou Zhao and Wei Xue},
      year={2025},
      eprint={2506.21448},
      archivePrefix={arXiv},
      primaryClass={eess.AS},
      url={https://arxiv.org/abs/2506.21448}, 
}
```

---

## ğŸ“¬ Ä°letiÅŸim

âœ¨ Herhangi bir sorunuz veya Ã¶neriniz varsa [bir issue aÃ§maktan](https://github.com/liuhuadai/ThinkSound/issues) veya e-posta yoluyla bizimle iletiÅŸime geÃ§mekten ([liuhuadai@zju.edu.cn](https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/mailto:liuhuadai@zju.edu.cn)) Ã§ekinmeyin!

---

Tranlated By [Open Ai Tx](https://github.com/OpenAiTx/OpenAiTx) | Last indexed: 2025-07-03

---