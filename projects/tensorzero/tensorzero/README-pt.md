<img src="https://github.com/user-attachments/assets/47d67430-386d-4675-82ad-d4734d3262d9" width=128 height=128>

# TensorZero

**O TensorZero cria um ciclo de feedback para otimizar aplica√ß√µes LLM ‚Äî transformando dados de produ√ß√£o em modelos mais inteligentes, r√°pidos e econ√¥micos.**

1. Integre nosso gateway de modelos
2. Envie m√©tricas ou feedbacks
3. Otimize prompts, modelos e estrat√©gias de infer√™ncia
4. Observe seus LLMs melhorando ao longo do tempo

Ele fornece um **flywheel de dados e aprendizado para LLMs** ao unificar:

- [x] **Infer√™ncia:** uma API para todos os LLMs, com overhead P99 <1ms
- [x] **Observabilidade:** infer√™ncia & feedback ‚Üí seu banco de dados
- [x] **Otimiza√ß√£o:** de prompts ao fine-tuning e RL
- [x] **Avalia√ß√µes:** compare prompts, modelos, estrat√©gias de infer√™ncia
- [x] **Experimenta√ß√£o:** teste A/B integrado, roteamento, fallbacks

---

<p align="center">
  <b><a href="https://www.tensorzero.com/" target="_blank">Website</a></b>
  ¬∑
  <b><a href="https://www.tensorzero.com/docs" target="_blank">Docs</a></b>
  ¬∑
  <b><a href="https://www.x.com/tensorzero" target="_blank">Twitter</a></b>
  ¬∑
  <b><a href="https://www.tensorzero.com/slack" target="_blank">Slack</a></b>
  ¬∑
  <b><a href="https://www.tensorzero.com/discord" target="_blank">Discord</a></b>
  <br>
  <br>
  <b><a href="https://www.tensorzero.com/docs/quickstart" target="_blank">Comece R√°pido (5min)</a></b>
  ¬∑
  <b><a href="https://www.tensorzero.com/docs/gateway/tutorial" target="_blank">Tutorial Completo</a></b>
  ¬∑
  <b><a href="https://www.tensorzero.com/docs/gateway/deployment" target="_blank">Guia de Deploy</a></b>
  ¬∑
  <b><a href="https://www.tensorzero.com/docs/gateway/api-reference" target="_blank">Refer√™ncia da API</a></b>
  ¬∑
  <b><a href="https://www.tensorzero.com/docs/gateway/deployment" target="_blank">Refer√™ncia de Configura√ß√£o</a></b>
</p>

---

<table>
  <tr>
    <td width="30%" valign="top"><b>O que √© o TensorZero?</b></td>
    <td width="70%" valign="top">TensorZero √© um framework open-source para construir aplica√ß√µes LLM de n√≠vel de produ√ß√£o. Ele unifica um gateway LLM, observabilidade, otimiza√ß√£o, avalia√ß√µes e experimenta√ß√£o.</td>
  </tr>
  <tr>
    <td width="30%" valign="top"><b>Como o TensorZero se diferencia de outros frameworks de LLM?</b></td>
    <td width="70%" valign="top">
      1. O TensorZero permite que voc√™ otimize aplica√ß√µes LLM complexas com base em m√©tricas de produ√ß√£o e feedback humano.<br>
      2. O TensorZero atende √†s necessidades de aplica√ß√µes LLM em escala industrial: baixa lat√™ncia, alta vaz√£o, tipagem segura, auto-hospedado, GitOps, customiz√°vel, etc.<br>
      3. O TensorZero unifica toda a stack LLMOps, criando benef√≠cios compostos. Por exemplo, avalia√ß√µes de LLM podem ser usadas para fine-tuning de modelos junto com ju√≠zes IA.
    </td>
  </tr>
  <tr>
    <td width="30%" valign="top"><b>Posso usar o TensorZero com ___?</b></td>
    <td width="70%" valign="top">Sim. Todo grande idioma de programa√ß√£o √© suportado. Voc√™ pode usar o TensorZero com nosso cliente Python, qualquer SDK OpenAI, ou nossa API HTTP.</td>
  </tr>
  <tr>
    <td width="30%" valign="top"><b>O TensorZero est√° pronto para produ√ß√£o?</b></td>
    <td width="70%" valign="top">Sim. Aqui est√° um estudo de caso: <b><a href="https://www.tensorzero.com/blog/case-study-automating-code-changelogs-at-a-large-bank-with-llms">Automatizando Changelogs de C√≥digo em um Grande Banco com LLMs</a></b></td>
  </tr>
  <tr>
    <td width="30%" valign="top"><b>Quanto custa o TensorZero?</b></td>
    <td width="70%" valign="top">Nada. O TensorZero √© 100% auto-hospedado e open-source. N√£o existem recursos pagos.</td>
  </tr>
  <tr>
    <td width="30%" valign="top"><b>Quem est√° construindo o TensorZero?</b></td>
    <td width="70%" valign="top">Nossa equipe t√©cnica inclui um ex-mantenedor do compilador Rust, pesquisadores de machine learning (Stanford, CMU, Oxford, Columbia) com milhares de cita√ß√µes, e o chief product officer de uma startup decacorn. Somos apoiados pelos mesmos investidores de projetos open-source l√≠deres (ex: ClickHouse, CockroachDB) e laborat√≥rios de IA (ex: OpenAI, Anthropic).</td>
  </tr>
  <tr>
    <td width="30%" valign="top"><b>Como come√ßo?</b></td>
    <td width="70%" valign="top">Voc√™ pode adotar o TensorZero incrementalmente. Nosso <b><a href="https://www.tensorzero.com/docs/quickstart">Comece R√°pido</a></b> vai de um wrapper OpenAI puro para uma aplica√ß√£o LLM pronta para produ√ß√£o com observabilidade e fine-tuning em apenas 5 minutos.</td>
  </tr>
</table>

---

## Funcionalidades

### üåê Gateway LLM

> **Integre-se ao TensorZero uma vez e acesse todos os principais provedores de LLM.**

<table>
  <tr></tr> <!-- flip highlight order -->
  <tr>
    <td width="50%" align="center" valign="middle"><b>Provedores de Modelos</b></td>
    <td width="50%" align="center" valign="middle"><b>Funcionalidades</b></td>
  </tr>
  <tr>
    <td width="50%" align="left" valign="top">
      <p>
        O Gateway TensorZero suporta nativamente:
      </p>
      <ul>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/anthropic">Anthropic</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/aws-bedrock">AWS Bedrock</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/aws-sagemaker">AWS SageMaker</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/azure">Azure OpenAI Service</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/deepseek">DeepSeek</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/fireworks">Fireworks</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/gcp-vertex-ai-anthropic">GCP Vertex AI Anthropic</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/gcp-vertex-ai-gemini">GCP Vertex AI Gemini</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/google-ai-studio-gemini">Google AI Studio (Gemini API)</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/hyperbolic">Hyperbolic</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/mistral">Mistral</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/openai">OpenAI</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/together">Together</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/vllm">vLLM</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/xai">xAI</a></b></li>
      </ul>
      <p>
        <em>
          Precisa de outro provedor?
          Seu provedor provavelmente √© suportado, pois o TensorZero integra-se a <b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/openai-compatible">qualquer API compat√≠vel com OpenAI (ex: Ollama)</a></b>.
        </em>
      </p>
    </td>
    <td width="50%" align="left" valign="top">
      <p>
        O Gateway TensorZero suporta funcionalidades avan√ßadas como:
      </p>
      <ul>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/retries-fallbacks">Retentativas & Fallbacks</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations">Otimiza√ß√µes em Tempo de Infer√™ncia</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/prompt-templates-schemas">Templates e Schemas de Prompt</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/tutorial#experimentation">Experimenta√ß√£o (Teste A/B)</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/configuration-reference">Configuration-as-Code (GitOps)</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/batch-inference">Infer√™ncia em Lote</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/multimodal-inference">Infer√™ncia Multimodal (VLMs)</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/inference-caching">Cache de Infer√™ncia</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/metrics-feedback">M√©tricas & Feedback</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/episodes">Workflows LLM Multi-Etapas (Epis√≥dios)</a></b></li>
        <li><em>& muito mais...</em></li>
      </ul>
      <p>
        O Gateway TensorZero √© escrito em Rust ü¶Ä com foco em <b>performance</b> (&lt;1ms de overhead de lat√™ncia p99 @ 10k QPS).
        Veja <b><a href="https://www.tensorzero.com/docs/gateway/benchmarks">Benchmarks</a></b>.<br>
      </p>
      <p>
        Voc√™ pode rodar infer√™ncias usando o <b>cliente TensorZero</b> (recomendado), o <b>cliente OpenAI</b> ou a <b>API HTTP</b>.
      </p>
    </td>
  </tr>
</table>

<br>

<details open>
<summary><b>Uso: Python &mdash; Cliente TensorZero (Recomendado)</b></summary>

Voc√™ pode acessar qualquer provedor usando o cliente Python do TensorZero.

1. `pip install tensorzero`
2. Opcional: Configure o TensorZero.
3. Execute a infer√™ncia:

```python
from tensorzero import TensorZeroGateway  # ou AsyncTensorZeroGateway


with TensorZeroGateway.build_embedded(clickhouse_url="...", config_file="...") as client:
    response = client.inference(
        model_name="openai::gpt-4o-mini",
        # Experimente outros provedores facilmente: "anthropic::claude-3-7-sonnet-20250219"
        input={
            "messages": [
                {
                    "role": "user",
                    "content": "Escreva um haicai sobre intelig√™ncia artificial.",
                }
            ]
        },
    )
```

Veja **[Comece R√°pido](https://www.tensorzero.com/docs/quickstart)** para mais informa√ß√µes.

</details>

<details>
<summary><b>Uso: Python &mdash; Cliente OpenAI</b></summary>

Voc√™ pode acessar qualquer provedor usando o cliente Python da OpenAI com o TensorZero.

1. `pip install tensorzero`
2. Opcional: Configure o TensorZero.
3. Execute a infer√™ncia:

```python
from openai import OpenAI  # ou AsyncOpenAI
from tensorzero import patch_openai_client

client = OpenAI()
patch_openai_client(
    client,
    clickhouse_url="http://chuser:chpassword@localhost:8123/tensorzero",
    config_file="config/tensorzero.toml",
    async_setup=False,
)

response = client.chat.completions.create(
    model="tensorzero::model_name::openai::gpt-4o-mini",
    # Experimente outros provedores facilmente: "tensorzero::model_name::anthropic::claude-3-7-sonnet-20250219"
    messages=[
        {
            "role": "user",
            "content": "Escreva um haicai sobre intelig√™ncia artificial.",
        }
    ],
)
```

Veja **[In√≠cio R√°pido](https://www.tensorzero.com/docs/quickstart)** para mais informa√ß√µes.

</details>

<details>
<summary><b>Uso: JavaScript / TypeScript (Node) &mdash; Cliente OpenAI</b></summary>

Voc√™ pode acessar qualquer provedor usando o cliente OpenAI Node com o TensorZero.

1. Fa√ßa o deploy do `tensorzero/gateway` usando Docker.
   **[Instru√ß√µes detalhadas ‚Üí](https://www.tensorzero.com/docs/gateway/deployment)**
2. Configure o TensorZero.
3. Execute a infer√™ncia:

```ts
import OpenAI from "openai";

const client = new OpenAI({
  baseURL: "http://localhost:3000/openai/v1",
});

const response = await client.chat.completions.create({
  model: "tensorzero::model_name::openai::gpt-4o-mini",
  // Experimente outros provedores facilmente: "tensorzero::model_name::anthropic::claude-3-7-sonnet-20250219"
  messages: [
    {
      role: "user",
      content: "Escreva um haicai sobre intelig√™ncia artificial.",
    },
  ],
});
```

Veja **[In√≠cio R√°pido](https://www.tensorzero.com/docs/quickstart)** para mais informa√ß√µes.

</details>

<details>
<summary><b>Uso: Outras Linguagens & Plataformas &mdash; API HTTP</b></summary>

O TensorZero suporta praticamente qualquer linguagem de programa√ß√£o ou plataforma via sua API HTTP.

1. Fa√ßa o deploy do `tensorzero/gateway` usando Docker.
   **[Instru√ß√µes detalhadas ‚Üí](https://www.tensorzero.com/docs/gateway/deployment)**
2. Opcional: configure o TensorZero.
3. Execute a infer√™ncia:

```bash
curl -X POST "http://localhost:3000/inference" \
  -H "Content-Type: application/json" \
  -d '{
    "model_name": "openai::gpt-4o-mini",
    "input": {
      "messages": [
        {
          "role": "user",
          "content": "Escreva um haicai sobre intelig√™ncia artificial."
        }
      ]
    }
  }'
```

Veja **[In√≠cio R√°pido](https://www.tensorzero.com/docs/quickstart)** para mais informa√ß√µes.

</details>

<br>

### üìà Otimiza√ß√£o de LLM

> **Envie m√©tricas de produ√ß√£o e feedback humano para otimizar facilmente seus prompts, modelos e estrat√©gias de infer√™ncia &mdash; usando a interface ou programaticamente.**

#### Otimiza√ß√£o de Modelo

Otimize modelos de c√≥digo fechado e aberto usando fine-tuning supervisionado (SFT) e fine-tuning por prefer√™ncia (DPO).

<table>
  <tr></tr> <!-- inverter ordem do destaque -->
  <tr>
    <td width="50%" align="center" valign="middle"><b>Fine-tuning Supervisionado &mdash; Interface</b></td>
    <td width="50%" align="center" valign="middle"><b>Fine-tuning por Prefer√™ncia (DPO) &mdash; Jupyter Notebook</b></td>
  </tr>
  <tr>
    <td width="50%" align="center" valign="middle"><img src="https://github.com/user-attachments/assets/cf7acf66-732b-43b3-af2a-5eba1ce40f6f"></td>
    <td width="50%" align="center" valign="middle"><img src="https://github.com/user-attachments/assets/a67a0634-04a7-42b0-b934-9130cb7cdf51"></td>
  </tr>
</table>

#### Otimiza√ß√£o em Tempo de Infer√™ncia

Aumente o desempenho atualizando dinamicamente seus prompts com exemplos relevantes, combinando respostas de m√∫ltiplas infer√™ncias, e mais.

<table>
  <tr></tr> <!-- inverter ordem do destaque -->
  <tr>
    <td width="50%" align="center" valign="middle"><b><a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#best-of-n-sampling">Best-of-N Sampling</a></b></td>
    <td width="50%" align="center" valign="middle"><b><a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#mixture-of-n-sampling">Mixture-of-N Sampling</a></b></td>
  </tr>
  <tr>
    <td width="50%" align="center" valign="middle"><img src="https://github.com/user-attachments/assets/c0edfa4c-713c-4996-9964-50c0d26e6970"></td>
    <td width="50%" align="center" valign="middle"><img src="https://github.com/user-attachments/assets/75b5bf05-4c1f-43c4-b158-d69d1b8d05be"></td>
  </tr>
  <tr>
    <td width="50%" align="center" valign="middle"><b><a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#dynamic-in-context-learning-dicl">Aprendizagem Din√¢mica de Contexto (DICL)</a></b></td>
    <td width="50%" align="center" valign="middle"><b><a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#chain-of-thought-cot">Cadeia de Pensamento (CoT)</a></b></td>
  </tr>
  <tr>
    <td width="50%" align="center" valign="middle"><img src="https://github.com/user-attachments/assets/d8489e92-ce93-46ac-9aab-289ce19bb67d"></td>
    <td width="50%" align="center" valign="middle"><img src="https://github.com/user-attachments/assets/ea13d73c-76a4-4e0c-a35b-0c648f898311" height="320"></td>
  </tr>
</table>

_Mais em breve..._

<br>

#### Otimiza√ß√£o de Prompt

Otimize seus prompts programaticamente utilizando t√©cnicas de otimiza√ß√£o baseadas em pesquisas.

<table>
  <tr></tr> <!-- inverter ordem do destaque -->
  <tr>
    <td width="50%" align="center" valign="middle"><b><a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#best-of-n-sampling">MIPROv2</a></b></td>
    <td width="50%" align="center" valign="middle"><b><a href="https://github.com/tensorzero/tensorzero/tree/main/examples/gsm8k-custom-recipe-dspy">Integra√ß√£o DSPy</a></b></td>
  </tr>
  <tr>
    <td width="50%" align="center" valign="middle"><img src="https://github.com/user-attachments/assets/d81a7c37-382f-4c46-840f-e6c2593301db" alt="Diagrama MIPROv2"></td>
    <td width="50%" align="center" valign="middle">
      O TensorZero vem com v√°rias receitas de otimiza√ß√£o, mas voc√™ tamb√©m pode criar facilmente as suas pr√≥prias.
      Este exemplo mostra como otimizar uma fun√ß√£o do TensorZero usando uma ferramenta arbitr√°ria ‚Äî aqui, o DSPy, uma biblioteca popular para engenharia de prompts automatizada.
    </td>
  </tr>
</table>

_Mais em breve..._

<br>

### üîç Observabilidade de LLM

> **Aproxime para depurar chamadas individuais de API, ou afaste para monitorar m√©tricas entre modelos e prompts ao longo do tempo &mdash; tudo usando a interface open-source do TensorZero.**

<table>
  <tr></tr> <!-- inverter ordem do destaque -->
  <tr>
    <td width="50%" align="center" valign="middle"><b>Observabilidade ¬ª Infer√™ncia</b></td>
    <td width="50%" align="center" valign="middle"><b>Observabilidade ¬ª Fun√ß√£o</b></td>
  </tr>
  <tr>
    <td width="50%" align="center" valign="middle"><img src="https://github.com/user-attachments/assets/2cc3cc9a-f33f-4e94-b8de-07522326f80a"></td>
    <td width="50%" align="center" valign="middle"><img src="https://github.com/user-attachments/assets/00ae6605-8fa0-4efd-8238-ae8ea589860f"></td>
  </tr>
</table>

<br>

### üìä Avalia√ß√µes de LLM

> **Compare prompts, modelos e estrat√©gias de infer√™ncia usando as Avalia√ß√µes do TensorZero &mdash; com suporte para heur√≠sticas e ju√≠zes LLM.**

<table>
  <tr></tr> <!-- inverter ordem do destaque -->
  <tr>
    <td width="50%" align="center" valign="middle"><b>Avalia√ß√£o ¬ª Interface</b></td>
    <td width="50%" align="center" valign="middle"><b>Avalia√ß√£o ¬ª CLI</b></td>
  </tr>
  <tr>
    <td width="50%" align="center" valign="middle"><img src="https://github.com/user-attachments/assets/f4bf54e3-1b63-46c8-be12-2eaabf615699"></td>
    <td width="50%" align="left" valign="middle">
<pre><code class="language-bash">docker compose run --rm evaluations \
  --evaluation-name extract_data \
  --dataset-name hard_test_cases \
  --variant-name gpt_4o \
  --concurrency 5</code></pre>
<pre><code class="language-bash">Run ID: 01961de9-c8a4-7c60-ab8d-15491a9708e4
Number of datapoints: 100
‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 100/100
exact_match: 0.83 ¬± 0.03
semantic_match: 0,98 ¬± 0,01
item_count: 7,15 ¬± 0,39</code></pre>
    </td>
  </tr>
</table>

## Demonstra√ß√£o

> **Veja LLMs melhorando na extra√ß√£o de dados em tempo real com TensorZero!**
>
> **[Aprendizado din√¢mico em contexto (DICL)](https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#dynamic-in-context-learning-dicl)** √© uma poderosa otimiza√ß√£o em tempo de infer√™ncia dispon√≠vel nativamente com o TensorZero.
> Ele aprimora o desempenho de LLMs incorporando automaticamente exemplos hist√≥ricos relevantes no prompt, sem necessidade de ajuste fino do modelo.

https://github.com/user-attachments/assets/4df1022e-886e-48c2-8f79-6af3cdad79cb

## Engenharia de LLM com TensorZero

<br>
<p align="center" >
  <a href="https://www.tensorzero.com/docs">
    <picture>
      <source media="(prefers-color-scheme: light)" srcset="https://github.com/user-attachments/assets/34a92c18-242e-4d76-a99c-861283de68a6">
      <source media="(prefers-color-scheme: dark)" srcset="https://github.com/user-attachments/assets/e8bc699b-6378-4c2a-9cc1-6d189025e270">
      <img alt="TensorZero Flywheel" src="https://github.com/user-attachments/assets/34a92c18-242e-4d76-a99c-861283de68a6" width=720>
    </picture>
  </a>
</p>
<br>

1. O **[TensorZero Gateway](https://www.tensorzero.com/docs/gateway/)** √© um gateway de modelos de alto desempenho escrito em Rust ü¶Ä que fornece uma interface de API unificada para todos os principais provedores de LLM, permitindo integra√ß√£o e fallback entre plataformas de forma transparente.
2. Ele realiza infer√™ncia estruturada baseada em esquemas com overhead de lat√™ncia P99 &lt;1ms (veja os **[Benchmarks](https://www.tensorzero.com/docs/gateway/benchmarks)**) e possui observabilidade, experimenta√ß√£o e **[otimiza√ß√µes em tempo de infer√™ncia](https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations)** integradas.
3. Tamb√©m coleta m√©tricas downstream e feedbacks associados a essas infer√™ncias, com suporte de primeira classe para sistemas LLM multi-etapas.
4. Tudo √© armazenado em um data warehouse ClickHouse que voc√™ controla, para an√°lises em tempo real, escal√°veis e amig√°veis ao desenvolvedor.
5. Com o tempo, as **[Receitas TensorZero](https://www.tensorzero.com/docs/recipes)** aproveitam esse conjunto de dados estruturados para otimizar seus prompts e modelos: execute receitas prontas para fluxos de trabalho comuns como fine-tuning ou crie as suas pr√≥prias com total flexibilidade usando qualquer linguagem e plataforma.
6. Finalmente, os recursos de experimenta√ß√£o do gateway e a orquestra√ß√£o GitOps permitem que voc√™ itere e fa√ßa deploy com confian√ßa, seja de um √∫nico LLM ou de milhares deles.

Nosso objetivo √© ajudar engenheiros a construir, gerenciar e otimizar a pr√≥xima gera√ß√£o de aplica√ß√µes LLM: sistemas que aprendem com experi√™ncias do mundo real.
Leia mais sobre nossa **[Vis√£o & Roadmap](https://www.tensorzero.com/docs/vision-roadmap/)**.

## Primeiros Passos

**Comece a construir hoje.**
O **[Guia R√°pido](https://www.tensorzero.com/docs/quickstart)** mostra como √© f√°cil configurar uma aplica√ß√£o LLM com o TensorZero.
Se quiser se aprofundar, o **[Tutorial](https://www.tensorzero.com/docs/gateway/tutorial)** ensina como construir um chatbot simples, um copiloto de email, um sistema RAG de clima e um pipeline de extra√ß√£o de dados estruturados.

**D√∫vidas?**
Pergunte para n√≥s no **[Slack](https://www.tensorzero.com/slack)** ou **[Discord](https://www.tensorzero.com/discord)**.

**Usando TensorZero no trabalho?**
Envie um e-mail para **[hello@tensorzero.com](mailto:hello@tensorzero.com)** para criar um canal Slack ou Teams com sua equipe (gratuito).

**Trabalhe conosco.**
Estamos **[contratando em Nova York](https://www.tensorzero.com/jobs)**.
Tamb√©m aceitamos **[contribui√ß√µes open-source](https://github.com/tensorzero/tensorzero/blob/main/CONTRIBUTING.md)**!

## Exemplos

Estamos trabalhando em uma s√©rie de **exemplos completos e execut√°veis** ilustrando o ciclo de dados & aprendizado do TensorZero.

> **[Otimiza√ß√£o de Extra√ß√£o de Dados (NER) com TensorZero](https://github.com/tensorzero/tensorzero/tree/main/examples/data-extraction-ner)**
>
> Este exemplo mostra como usar o TensorZero para otimizar um pipeline de extra√ß√£o de dados.
> Demonstramos t√©cnicas como fine-tuning e aprendizado din√¢mico em contexto (DICL).
> No final, um modelo GPT-4o Mini otimizado supera o GPT-4o nesta tarefa &mdash; a uma fra√ß√£o do custo e da lat√™ncia &mdash; usando uma pequena quantidade de dados de treinamento.

> **[Agentic RAG ‚Äî Resposta a Perguntas Multi-Hop com LLMs](https://github.com/tensorzero/tensorzero/tree/main/examples/rag-retrieval-augmented-generation/simple-agentic-rag/)**
>
> Este exemplo mostra como construir um agente de recupera√ß√£o multi-hop usando o TensorZero.
> O agente pesquisa iterativamente a Wikip√©dia para reunir informa√ß√µes e decide quando tem contexto suficiente para responder uma pergunta complexa.

> **[Escrevendo Haikais para Satisfazer um Juiz com Prefer√™ncias Ocultas](https://github.com/tensorzero/tensorzero/tree/main/examples/haiku-hidden-preferences)**
>
> Este exemplo faz fine-tuning no GPT-4o Mini para gerar haikais personalizados para um gosto espec√≠fico.
> Voc√™ ver√° o "ciclo de dados em uma caixa" do TensorZero em a√ß√£o: melhores variantes levam a melhores dados, e melhores dados levam a melhores variantes.
> Voc√™ ver√° progresso refinando o LLM m√∫ltiplas vezes.

> **[Melhorando a Habilidade de Xadrez do LLM com Best-of-N Sampling](https://github.com/tensorzero/tensorzero/tree/main/examples/chess-puzzles/)**
>
> Este exemplo mostra como o best-of-N sampling pode melhorar significativamente a habilidade de jogo de xadrez de um LLM, selecionando os movimentos mais promissores entre v√°rias op√ß√µes geradas.

> **[Aprimorando o Racioc√≠nio Matem√°tico com Receita Customizada de Engenharia Automatizada de Prompts (DSPy)](https://github.com/tensorzero/tensorzero/tree/main/examples/gsm8k-custom-recipe-dspy)**
>
> O TensorZero oferece v√°rias receitas de otimiza√ß√£o prontas que cobrem fluxos de trabalho comuns de engenharia de LLMs.
> Mas voc√™ tamb√©m pode criar facilmente suas pr√≥prias receitas e fluxos de trabalho!
> Este exemplo mostra como otimizar uma fun√ß√£o TensorZero usando qualquer ferramenta ‚Äî neste caso, DSPy.

_& muitos outros a caminho!_

---

Tranlated By [Open Ai Tx](https://github.com/OpenAiTx/OpenAiTx) | Last indexed: 2025-06-09

---