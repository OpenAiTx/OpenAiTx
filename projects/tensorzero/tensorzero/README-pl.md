<img src="https://github.com/user-attachments/assets/47d67430-386d-4675-82ad-d4734d3262d9" width=128 height=128>

# TensorZero

**TensorZero tworzy pÄ™tlÄ™ sprzÄ™Å¼enia zwrotnego dla optymalizacji aplikacji LLM â€” zamieniajÄ…c dane produkcyjne w inteligentniejsze, szybsze i taÅ„sze modele.**

1. Zintegruj naszÄ… bramkÄ™ modelowÄ…
2. WysyÅ‚aj metryki lub feedback
3. Optymalizuj prompt'y, modele i strategie inferencji
4. Obserwuj, jak Twoje LLM-y poprawiajÄ… siÄ™ z czasem

Zapewnia **koÅ‚o zamachowe danych i uczenia dla LLM-Ã³w** poprzez ujednolicenie:

- [x] **Inferencja:** jedno API dla wszystkich LLM-Ã³w, z narzutem <1 ms P99
- [x] **ObserwowalnoÅ›Ä‡:** inferencja i feedback â†’ Twoja baza danych
- [x] **Optymalizacja:** od promptÃ³w po fine-tuning i RL
- [x] **Ewaluacje:** porÃ³wnuj prompt'y, modele, strategie inferencji
- [x] **Eksperymentowanie:** wbudowane testy A/B, routing, fallbacki

---

<p align="center">
  <b><a href="https://www.tensorzero.com/" target="_blank">Strona WWW</a></b>
  Â·
  <b><a href="https://www.tensorzero.com/docs" target="_blank">Dokumentacja</a></b>
  Â·
  <b><a href="https://www.x.com/tensorzero" target="_blank">Twitter</a></b>
  Â·
  <b><a href="https://www.tensorzero.com/slack" target="_blank">Slack</a></b>
  Â·
  <b><a href="https://www.tensorzero.com/discord" target="_blank">Discord</a></b>
  <br>
  <br>
  <b><a href="https://www.tensorzero.com/docs/quickstart" target="_blank">Szybki start (5 min)</a></b>
  Â·
  <b><a href="https://www.tensorzero.com/docs/gateway/tutorial" target="_blank">Kompletny tutorial</a></b>
  Â·
  <b><a href="https://www.tensorzero.com/docs/gateway/deployment" target="_blank">Przewodnik wdroÅ¼eniowy</a></b>
  Â·
  <b><a href="https://www.tensorzero.com/docs/gateway/api-reference" target="_blank">Referencja API</a></b>
  Â·
  <b><a href="https://www.tensorzero.com/docs/gateway/deployment" target="_blank">Referencja konfiguracji</a></b>
</p>

---

<table>
  <tr>
    <td width="30%" valign="top"><b>Czym jest TensorZero?</b></td>
    <td width="70%" valign="top">TensorZero to open-source'owy framework do budowy aplikacji LLM klasy produkcyjnej. Ujednolica bramkÄ™ LLM, obserwowalnoÅ›Ä‡, optymalizacjÄ™, ewaluacje i eksperymentowanie.</td>
  </tr>
  <tr>
    <td width="30%" valign="top"><b>Czym TensorZero rÃ³Å¼ni siÄ™ od innych frameworkÃ³w LLM?</b></td>
    <td width="70%" valign="top">
      1. TensorZero umoÅ¼liwia optymalizacjÄ™ zÅ‚oÅ¼onych aplikacji LLM na podstawie metryk produkcyjnych i feedbacku od ludzi.<br>
      2. TensorZero wspiera potrzeby aplikacji LLM na skalÄ™ przemysÅ‚owÄ…: niskie opÃ³Åºnienia, wysokÄ… przepustowoÅ›Ä‡, bezpieczeÅ„stwo typÃ³w, self-hosting, GitOps, moÅ¼liwoÅ›Ä‡ dostosowania, itd.<br>
      3. TensorZero jednoczy caÅ‚y stack LLMOps, tworzÄ…c efekt kuli Å›nieÅ¼nej. Na przykÅ‚ad ewaluacje LLM mogÄ… byÄ‡ wykorzystywane do fine-tuningu modeli razem z AI judge'ami.
    </td>
  </tr>
  <tr>
    <td width="30%" valign="top"><b>Czy mogÄ™ uÅ¼ywaÄ‡ TensorZero z ___?</b></td>
    <td width="70%" valign="top">Tak. Wspierane sÄ… wszystkie gÅ‚Ã³wne jÄ™zyki programowania. MoÅ¼esz uÅ¼ywaÄ‡ TensorZero z naszym klientem Pythona, dowolnym SDK OpenAI lub przez nasze HTTP API.</td>
  </tr>
  <tr>
    <td width="30%" valign="top"><b>Czy TensorZero jest gotowy na produkcjÄ™?</b></td>
    <td width="70%" valign="top">Tak. PrzykÅ‚ad wdroÅ¼enia: <b><a href="https://www.tensorzero.com/blog/case-study-automating-code-changelogs-at-a-large-bank-with-llms">Automatyzacja changelogÃ³w w duÅ¼ym banku za pomocÄ… LLM-Ã³w</a></b></td>
  </tr>
  <tr>
    <td width="30%" valign="top"><b>Ile kosztuje TensorZero?</b></td>
    <td width="70%" valign="top">Nic. TensorZero jest w 100% self-hosted i open-source. Nie ma pÅ‚atnych funkcji.</td>
  </tr>
  <tr>
    <td width="30%" valign="top"><b>Kto rozwija TensorZero?</b></td>
    <td width="70%" valign="top">Nasz zespÃ³Å‚ techniczny to m.in. byÅ‚y maintainer kompilatora Rust, badacze machine learning (Stanford, CMU, Oxford, Columbia) z tysiÄ…cami cytowaÅ„ i CPO startupu typu decacorn. WspierajÄ… nas ci sami inwestorzy co wiodÄ…ce projekty open-source (np. ClickHouse, CockroachDB) i laboratoria AI (np. OpenAI, Anthropic).</td>
  </tr>
  <tr>
    <td width="30%" valign="top"><b>Jak zaczÄ…Ä‡?</b></td>
    <td width="70%" valign="top">MoÅ¼esz wdraÅ¼aÄ‡ TensorZero stopniowo. Nasz <b><a href="https://www.tensorzero.com/docs/quickstart">Szybki start</a></b> prowadzi od zwykÅ‚ego wrappera OpenAI do aplikacji LLM gotowej na produkcjÄ™ z obserwowalnoÅ›ciÄ… i fine-tuningiem w 5 minut.</td>
  </tr>
</table>

---

## Funkcje

### ğŸŒ Bramka LLM

> **Zintegruj siÄ™ z TensorZero raz i uzyskaj dostÄ™p do wszystkich gÅ‚Ã³wnych dostawcÃ³w LLM.**

<table>
  <tr></tr> <!-- flip highlight order -->
  <tr>
    <td width="50%" align="center" valign="middle"><b>Dostawcy modeli</b></td>
    <td width="50%" align="center" valign="middle"><b>Funkcje</b></td>
  </tr>
  <tr>
    <td width="50%" align="left" valign="top">
      <p>
        Bramka TensorZero natywnie obsÅ‚uguje:
      </p>
      <ul>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/anthropic">Anthropic</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/aws-bedrock">AWS Bedrock</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/aws-sagemaker">AWS SageMaker</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/azure">Azure OpenAI Service</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/deepseek">DeepSeek</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/fireworks">Fireworks</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/gcp-vertex-ai-anthropic">GCP Vertex AI Anthropic</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/gcp-vertex-ai-gemini">GCP Vertex AI Gemini</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/google-ai-studio-gemini">Google AI Studio (Gemini API)</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/hyperbolic">Hyperbolic</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/mistral">Mistral</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/openai">OpenAI</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/together">Together</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/vllm">vLLM</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/xai">xAI</a></b></li>
      </ul>
      <p>
        <em>
          Potrzebujesz czegoÅ› innego?
          TwÃ³j dostawca jest najpewniej wspierany, poniewaÅ¼ TensorZero integruje siÄ™ z <b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/openai-compatible">kaÅ¼dym API kompatybilnym z OpenAI (np. Ollama)</a></b>.
          </em>
      </p>
    </td>
    <td width="50%" align="left" valign="top">
      <p>
        Bramka TensorZero obsÅ‚uguje zaawansowane funkcje, takie jak:
      </p>
      <ul>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/retries-fallbacks">Retry & Fallbacki</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations">Optymalizacje czasu inferencji</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/prompt-templates-schemas">Szablony promptÃ³w & Schematy</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/tutorial#experimentation">Eksperymentowanie (A/B Testing)</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/configuration-reference">Konfiguracja jako kod (GitOps)</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/batch-inference">Inferencja wsadowa</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/multimodal-inference">Inferencja multimodalna (VLM)</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/inference-caching">Cache'owanie inferencji</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/metrics-feedback">Metryki & Feedback</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/episodes">Wielokrokowe workflow LLM (Episodes)</a></b></li>
        <li><em>& wiele wiÄ™cej...</em></li>
      </ul>
      <p>
        Bramka TensorZero napisana jest w Rust ğŸ¦€ z myÅ›lÄ… o <b>wydajnoÅ›ci</b> (&lt;1ms p99 latency overhead przy 10k QPS).
        Zobacz <b><a href="https://www.tensorzero.com/docs/gateway/benchmarks">Benchmarki</a></b>.<br>
      </p>
      <p>
        MoÅ¼esz uruchamiaÄ‡ inferencjÄ™ uÅ¼ywajÄ…c <b>klienta TensorZero</b> (zalecane), <b>klienta OpenAI</b> lub <b>HTTP API</b>.
      </p>
    </td>
  </tr>
</table>

<br>

<details open>
<summary><b>UÅ¼ycie: Python &mdash; Klient TensorZero (zalecane)</b></summary>

MoÅ¼esz uzyskaÄ‡ dostÄ™p do dowolnego dostawcy za pomocÄ… klienta TensorZero dla Pythona.

1. `pip install tensorzero`
2. Opcjonalnie: Skonfiguruj TensorZero.
3. Uruchom inferencjÄ™:

```python
from tensorzero import TensorZeroGateway  # lub AsyncTensorZeroGateway


with TensorZeroGateway.build_embedded(clickhouse_url="...", config_file="...") as client:
    response = client.inference(
        model_name="openai::gpt-4o-mini",
        # Åatwo przetestuj innych dostawcÃ³w: "anthropic::claude-3-7-sonnet-20250219"
        input={
            "messages": [
                {
                    "role": "user",
                    "content": "Napisz haiku o sztucznej inteligencji.",
                }
            ]
        },
    )
```

Zobacz **[Szybki Start](https://www.tensorzero.com/docs/quickstart)** po wiÄ™cej informacji.

</details>

<details>
<summary><b>UÅ¼ycie: Python &mdash; Klient OpenAI</b></summary>

MoÅ¼esz uzyskaÄ‡ dostÄ™p do dowolnego dostawcy przez klienta OpenAI dla Pythona z TensorZero.

1. `pip install tensorzero`
2. Opcjonalnie: Skonfiguruj TensorZero.
3. Uruchom inferencjÄ™:

```python
from openai import OpenAI  # lub AsyncOpenAI
from tensorzero import patch_openai_client

client = OpenAI()
```
patch_openai_client(
    client,
    clickhouse_url="http://chuser:chpassword@localhost:8123/tensorzero",
    config_file="config/tensorzero.toml",
    async_setup=False,
)

response = client.chat.completions.create(
    model="tensorzero::model_name::openai::gpt-4o-mini",
    # WyprÃ³buj innych dostawcÃ³w Å‚atwo: "tensorzero::model_name::anthropic::claude-3-7-sonnet-20250219"
    messages=[
        {
            "role": "user",
            "content": "Napisz haiku o sztucznej inteligencji.",
        }
    ],
)
```

Zobacz **[Szybki Start](https://www.tensorzero.com/docs/quickstart)** po wiÄ™cej informacji.

</details>

<details>
<summary><b>UÅ¼ycie: JavaScript / TypeScript (Node) &mdash; Klient OpenAI</b></summary>

MoÅ¼esz uzyskaÄ‡ dostÄ™p do dowolnego dostawcy za pomocÄ… klienta OpenAI Node z TensorZero.

1. WdrÃ³Å¼ `tensorzero/gateway` uÅ¼ywajÄ…c Dockera.
   **[SzczegÃ³Å‚owa instrukcja â†’](https://www.tensorzero.com/docs/gateway/deployment)**
2. Skonfiguruj TensorZero.
3. Uruchom inferencjÄ™:

```ts
import OpenAI from "openai";

const client = new OpenAI({
  baseURL: "http://localhost:3000/openai/v1",
});

const response = await client.chat.completions.create({
  model: "tensorzero::model_name::openai::gpt-4o-mini",
  // WyprÃ³buj innych dostawcÃ³w Å‚atwo: "tensorzero::model_name::anthropic::claude-3-7-sonnet-20250219"
  messages: [
    {
      role: "user",
      content: "Napisz haiku o sztucznej inteligencji.",
    },
  ],
});
```

Zobacz **[Szybki Start](https://www.tensorzero.com/docs/quickstart)** po wiÄ™cej informacji.

</details>

<details>
<summary><b>UÅ¼ycie: Inne jÄ™zyki i platformy &mdash; HTTP API</b></summary>

TensorZero obsÅ‚uguje praktycznie kaÅ¼dy jÄ™zyk programowania lub platformÄ™ przez API HTTP.

1. WdrÃ³Å¼ `tensorzero/gateway` uÅ¼ywajÄ…c Dockera.
   **[SzczegÃ³Å‚owa instrukcja â†’](https://www.tensorzero.com/docs/gateway/deployment)**
2. Opcjonalnie: Skonfiguruj TensorZero.
3. Uruchom inferencjÄ™:

```bash
curl -X POST "http://localhost:3000/inference" \
  -H "Content-Type: application/json" \
  -d '{
    "model_name": "openai::gpt-4o-mini",
    "input": {
      "messages": [
        {
          "role": "user",
          "content": "Napisz haiku o sztucznej inteligencji."
        }
      ]
    }
  }'
```

Zobacz **[Szybki Start](https://www.tensorzero.com/docs/quickstart)** po wiÄ™cej informacji.

</details>

<br>

### ğŸ“ˆ Optymalizacja LLM

> **PrzesyÅ‚aj metryki produkcyjne oraz feedback uÅ¼ytkownikÃ³w, aby z Å‚atwoÅ›ciÄ… optymalizowaÄ‡ prompty, modele i strategie inferencji â€” przez UI lub programistycznie.**

#### Optymalizacja modelu

Optymalizuj modele zamkniÄ™to- i otwartoÅºrÃ³dÅ‚owe poprzez nadzorowane dostrajanie (SFT) i dostrajanie preferencji (DPO).

<table>
  <tr></tr> <!-- flip highlight order -->
  <tr>
    <td width="50%" align="center" valign="middle"><b>Dostrajanie nadzorowane &mdash; UI</b></td>
    <td width="50%" align="center" valign="middle"><b>Dostrajanie preferencji (DPO) &mdash; Jupyter Notebook</b></td>
  </tr>
  <tr>
    <td width="50%" align="center" valign="middle"><img src="https://github.com/user-attachments/assets/cf7acf66-732b-43b3-af2a-5eba1ce40f6f"></td>
    <td width="50%" align="center" valign="middle"><img src="https://github.com/user-attachments/assets/a67a0634-04a7-42b0-b934-9130cb7cdf51"></td>
  </tr>
</table>

#### Optymalizacja w czasie inferencji

ZwiÄ™ksz wydajnoÅ›Ä‡, dynamicznie aktualizujÄ…c prompt z odpowiednimi przykÅ‚adami, Å‚Ä…czÄ…c odpowiedzi z wielu inferencji i wiÄ™cej.

<table>
  <tr></tr> <!-- flip highlight order -->
  <tr>
    <td width="50%" align="center" valign="middle"><b><a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#best-of-n-sampling">Best-of-N Sampling</a></b></td>
    <td width="50%" align="center" valign="middle"><b><a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#mixture-of-n-sampling">Mixture-of-N Sampling</a></b></td>
  </tr>
  <tr>
    <td width="50%" align="center" valign="middle"><img src="https://github.com/user-attachments/assets/c0edfa4c-713c-4996-9964-50c0d26e6970"></td>
    <td width="50%" align="center" valign="middle"><img src="https://github.com/user-attachments/assets/75b5bf05-4c1f-43c4-b158-d69d1b8d05be"></td>
  </tr>
  <tr>
    <td width="50%" align="center" valign="middle"><b><a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#dynamic-in-context-learning-dicl">Dynamic In-Context Learning (DICL)</a></b></td>
    <td width="50%" align="center" valign="middle"><b><a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#chain-of-thought-cot">Chain-of-Thought (CoT)</a></b></td>
  </tr>
  <tr>
    <td width="50%" align="center" valign="middle"><img src="https://github.com/user-attachments/assets/d8489e92-ce93-46ac-9aab-289ce19bb67d"></td>
    <td width="50%" align="center" valign="middle"><img src="https://github.com/user-attachments/assets/ea13d73c-76a4-4e0c-a35b-0c648f898311" height="320"></td>
  </tr>
</table>

_WiÄ™cej wkrÃ³tce..._

<br>

#### Optymalizacja promptÃ³w

Optymalizuj swoje prompty programistycznie, korzystajÄ…c z technik opartych na badaniach naukowych.

<table>
  <tr></tr> <!-- flip highlight order -->
  <tr>
    <td width="50%" align="center" valign="middle"><b><a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#best-of-n-sampling">MIPROv2</a></b></td>
    <td width="50%" align="center" valign="middle"><b><a href="https://github.com/tensorzero/tensorzero/tree/main/examples/gsm8k-custom-recipe-dspy">Integracja DSPy</a></b></td>
  </tr>
  <tr>
    <td width="50%" align="center" valign="middle"><img src="https://github.com/user-attachments/assets/d81a7c37-382f-4c46-840f-e6c2593301db" alt="MIPROv2 diagram"></td>
    <td width="50%" align="center" valign="middle">
      TensorZero posiada kilka gotowych przepisÃ³w optymalizacyjnych, ale moÅ¼esz rÃ³wnieÅ¼ Å‚atwo tworzyÄ‡ wÅ‚asne.
      Ten przykÅ‚ad pokazuje jak zoptymalizowaÄ‡ funkcjÄ™ TensorZero przy uÅ¼yciu dowolnego narzÄ™dzia â€” tutaj DSPy, popularnej biblioteki do automatycznego inÅ¼ynierii promptÃ³w.
    </td>
  </tr>
</table>

_WiÄ™cej wkrÃ³tce..._

<br>

### ğŸ” ObserwowalnoÅ›Ä‡ LLM

> **PrzybliÅ¼aj, aby debugowaÄ‡ pojedyncze wywoÅ‚ania API lub oddalaj, aby monitorowaÄ‡ metryki modeli i promptÃ³w w czasie â€” wszystko z wykorzystaniem otwartoÅºrÃ³dÅ‚owego UI TensorZero.**

<table>
  <tr></tr> <!-- flip highlight order -->
  <tr>
    <td width="50%" align="center" valign="middle"><b>ObserwowalnoÅ›Ä‡ Â» Inferencja</b></td>
    <td width="50%" align="center" valign="middle"><b>ObserwowalnoÅ›Ä‡ Â» Funkcja</b></td>
  </tr>
  <tr>
    <td width="50%" align="center" valign="middle"><img src="https://github.com/user-attachments/assets/2cc3cc9a-f33f-4e94-b8de-07522326f80a"></td>
    <td width="50%" align="center" valign="middle"><img src="https://github.com/user-attachments/assets/00ae6605-8fa0-4efd-8238-ae8ea589860f"></td>
  </tr>
</table>

<br>

### ğŸ“Š Ewaluacje LLM

> **PorÃ³wnuj prompty, modele i strategie inferencji przy uÅ¼yciu TensorZero Evaluations â€” z obsÅ‚ugÄ… heurystyk i sÄ™dziÃ³w LLM.**

<table>
  <tr></tr> <!-- flip highlight order -->
  <tr>
    <td width="50%" align="center" valign="middle"><b>Ewaluacja Â» UI</b></td>
    <td width="50%" align="center" valign="middle"><b>Ewaluacja Â» CLI</b></td>
  </tr>
  <tr>
    <td width="50%" align="center" valign="middle"><img src="https://github.com/user-attachments/assets/f4bf54e3-1b63-46c8-be12-2eaabf615699"></td>
    <td width="50%" align="left" valign="middle">
<pre><code class="language-bash">docker compose run --rm evaluations \
  --evaluation-name extract_data \
  --dataset-name hard_test_cases \
  --variant-name gpt_4o \
  --concurrency 5</code></pre>
<pre><code class="language-bash">Run ID: 01961de9-c8a4-7c60-ab8d-15491a9708e4
Number of datapoints: 100
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 100/100
exact_match: 0.83 Â± 0.03
semantic_match: 0,98 Â± 0,01  
item_count: 7,15 Â± 0,39</code></pre>
    </td>
  </tr>
</table>

## Demo

> **Obserwuj, jak LLM-y stajÄ… siÄ™ coraz lepsze w ekstrakcji danych w czasie rzeczywistym z TensorZero!**
>
> **[Dynamiczne uczenie w kontekÅ›cie (DICL)](https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#dynamic-in-context-learning-dicl)** to potÄ™Å¼na optymalizacja w czasie inferencji dostÄ™pna od razu z TensorZero.
> ZwiÄ™ksza wydajnoÅ›Ä‡ LLM-Ã³w poprzez automatyczne wÅ‚Ä…czanie odpowiednich historycznych przykÅ‚adÃ³w do promptu, bez koniecznoÅ›ci dostrajania modelu.

https://github.com/user-attachments/assets/4df1022e-886e-48c2-8f79-6af3cdad79cb

## InÅ¼ynieria LLM z TensorZero

<br>
<p align="center" >
  <a href="https://www.tensorzero.com/docs">
    <picture>
      <source media="(prefers-color-scheme: light)" srcset="https://github.com/user-attachments/assets/34a92c18-242e-4d76-a99c-861283de68a6">
      <source media="(prefers-color-scheme: dark)" srcset="https://github.com/user-attachments/assets/e8bc699b-6378-4c2a-9cc1-6d189025e270">
      <img alt="TensorZero Flywheel" src="https://github.com/user-attachments/assets/34a92c18-242e-4d76-a99c-861283de68a6" width=720>
    </picture>
  </a>
</p>
<br>

1. **[TensorZero Gateway](https://www.tensorzero.com/docs/gateway/)** to wysokowydajna bramka modelowa napisana w Rust ğŸ¦€, ktÃ³ra zapewnia zunifikowany interfejs API dla wszystkich gÅ‚Ã³wnych dostawcÃ³w LLM, umoÅ¼liwiajÄ…c bezproblemowÄ… integracjÄ™ miÄ™dzyplatformowÄ… i mechanizmy awaryjne.
2. ObsÅ‚uguje inferencjÄ™ opartÄ… na strukturalnych schematach z opÃ³Åºnieniem P99 poniÅ¼ej 1 ms (zobacz **[Benchmarki](https://www.tensorzero.com/docs/gateway/benchmarks)**) oraz wbudowanÄ… obserwowalnoÅ›Ä‡, eksperymentowanie i **[optymalizacje w czasie inferencji](https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations)**.
3. Zbiera takÅ¼e metryki i informacje zwrotne zwiÄ…zane z tymi inferencjami, z natywnym wsparciem dla wieloetapowych systemÃ³w LLM.
4. Wszystko jest przechowywane w hurtowni danych ClickHouse, ktÃ³rÄ… kontrolujesz â€” dla analityki w czasie rzeczywistym, skalowalnej i przyjaznej deweloperom.
5. Z czasem **[Receptury TensorZero](https://www.tensorzero.com/docs/recipes)** wykorzystujÄ… ten uporzÄ…dkowany zbiÃ³r danych do optymalizacji promptÃ³w i modeli: uruchamiaj gotowe receptury dla typowych zadaÅ„ takich jak fine-tuning lub twÃ³rz wÅ‚asne z peÅ‚nÄ… elastycznoÅ›ciÄ…, uÅ¼ywajÄ…c dowolnego jÄ™zyka i platformy.
6. Na koniec funkcje eksperymentowania bramki i orkiestracja GitOps pozwalajÄ… Ci iterowaÄ‡ i wdraÅ¼aÄ‡ z pewnoÅ›ciÄ… â€” niezaleÅ¼nie czy to pojedynczy LLM, czy tysiÄ…ce modeli.

Naszym celem jest pomoc inÅ¼ynierom w budowaniu, zarzÄ…dzaniu i optymalizacji nowej generacji aplikacji LLM: systemÃ³w uczÄ…cych siÄ™ na podstawie rzeczywistych doÅ›wiadczeÅ„.  
Przeczytaj wiÄ™cej o naszej **[Wizji i Planie Rozwoju](https://www.tensorzero.com/docs/vision-roadmap/)**.

## Pierwsze kroki

**Zacznij budowaÄ‡ juÅ¼ dziÅ›.**  
**[Szybki Start](https://www.tensorzero.com/docs/quickstart)** pokazuje, jak Å‚atwo skonfigurowaÄ‡ aplikacjÄ™ LLM z TensorZero.  
JeÅ›li chcesz zagÅ‚Ä™biÄ‡ siÄ™ bardziej, **[Samouczek](https://www.tensorzero.com/docs/gateway/tutorial)** nauczy CiÄ™, jak zbudowaÄ‡ prostego chatbota, asystenta e-mail, system pogodowy RAG oraz pipeline do ekstrakcji danych strukturalnych.

**Masz pytania?**  
Pytaj nas na **[Slacku](https://www.tensorzero.com/slack)** lub **[Discordzie](https://www.tensorzero.com/discord)**.

**UÅ¼ywasz TensorZero w pracy?**  
Napisz do nas na **[hello@tensorzero.com](mailto:hello@tensorzero.com)**, aby zaÅ‚oÅ¼yÄ‡ kanaÅ‚ Slack lub Teams dla Twojego zespoÅ‚u (za darmo).

**Pracuj z nami.**  
**[Rekrutujemy w NYC](https://www.tensorzero.com/jobs)**.  
ChÄ™tnie przyjmiemy takÅ¼e **[wkÅ‚ady open-source](https://github.com/tensorzero/tensorzero/blob/main/CONTRIBUTING.md)**!

## PrzykÅ‚ady

Pracujemy nad seriÄ… **kompletnych, uruchamialnych przykÅ‚adÃ³w** ilustrujÄ…cych cykl danych i uczenia TensorZero.

> **[Optymalizacja ekstrakcji danych (NER) z TensorZero](https://github.com/tensorzero/tensorzero/tree/main/examples/data-extraction-ner)**
>
> Ten przykÅ‚ad pokazuje, jak uÅ¼yÄ‡ TensorZero do optymalizacji pipeline'u ekstrakcji danych.
> Pokazujemy techniki takie jak fine-tuning i dynamiczne uczenie w kontekÅ›cie (DICL).
> Ostatecznie zoptymalizowany model GPT-4o Mini przewyÅ¼sza GPT-4o w tym zadaniu â€” przy uÅ‚amku kosztu i opÃ³Åºnienia â€” wykorzystujÄ…c niewielkÄ… iloÅ›Ä‡ danych treningowych.

> **[Agentowy RAG â€” Odpowiadanie na pytania wieloetapowe z LLM](https://github.com/tensorzero/tensorzero/tree/main/examples/rag-retrieval-augmented-generation/simple-agentic-rag/)**
>
> Ten przykÅ‚ad pokazuje, jak zbudowaÄ‡ agenta wieloetapowego wyszukiwania za pomocÄ… TensorZero.
> Agent iteracyjnie przeszukuje WikipediÄ™ w celu zebrania informacji i decyduje, kiedy posiada wystarczajÄ…cy kontekst, aby odpowiedzieÄ‡ na zÅ‚oÅ¼one pytanie.

> **[Pisanie haiku, by zadowoliÄ‡ sÄ™dziego o ukrytych preferencjach](https://github.com/tensorzero/tensorzero/tree/main/examples/haiku-hidden-preferences)**
>
> Ten przykÅ‚ad dostraja GPT-4o Mini do generowania haiku dopasowanych do konkretnego gustu.
> Zobaczysz â€cykl danych w pudeÅ‚kuâ€ TensorZero w akcji: lepsze warianty prowadzÄ… do lepszych danych, a lepsze dane do lepszych wariantÃ³w.
> Zobaczysz postÄ™py dziÄ™ki wielokrotnemu fine-tuningowi LLM.

> **[Ulepszanie umiejÄ™tnoÅ›ci szachowych LLM dziÄ™ki Best-of-N Sampling](https://github.com/tensorzero/tensorzero/tree/main/examples/chess-puzzles/)**
>
> Ten przykÅ‚ad pokazuje, jak Best-of-N sampling moÅ¼e znaczÄ…co zwiÄ™kszyÄ‡ umiejÄ™tnoÅ›ci gry w szachy przez LLM, wybierajÄ…c najbardziej obiecujÄ…ce posuniÄ™cia z wielu wygenerowanych opcji.

> **[Poprawa rozumowania matematycznego z wÅ‚asnÄ… recepturÄ… do automatycznej inÅ¼ynierii promptÃ³w (DSPy)](https://github.com/tensorzero/tensorzero/tree/main/examples/gsm8k-custom-recipe-dspy)**
>
> TensorZero oferuje szereg gotowych receptur optymalizacyjnych obejmujÄ…cych typowe procesy inÅ¼ynierii LLM.
> MoÅ¼esz teÅ¼ Å‚atwo tworzyÄ‡ wÅ‚asne receptury i workflow!
> Ten przykÅ‚ad pokazuje, jak zoptymalizowaÄ‡ funkcjÄ™ TensorZero za pomocÄ… dowolnego narzÄ™dzia â€” tutaj DSPy.

_& wiele kolejnych juÅ¼ w drodze!_

---

Tranlated By [Open Ai Tx](https://github.com/OpenAiTx/OpenAiTx) | Last indexed: 2025-06-09

---