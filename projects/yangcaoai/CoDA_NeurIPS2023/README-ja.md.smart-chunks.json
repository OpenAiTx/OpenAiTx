[
  {
    "Id": 1,
    "Content": "\n## :book: CoDA: Collaborative Novel Box Discovery and Cross-modal Alignment for Open-vocabulary 3D Object Detection (NeurIPS2023)\n<p align=\"center\">\n  <small> ğŸ”¥Please star CoDA â­ and share it. ThanksğŸ”¥ </small>\n</p>\n\n> [[Paper](https://arxiv.org/abs/2310.02960)] &emsp; [[Project Page](https://yangcaoai.github.io/publications/CoDA.html)] <br>\n<!-- > [Yang Cao](https://yangcaoai.github.io/), Yihan Zeng, [Hang Xu](https://xuhangcn.github.io/), [Dan Xu](https://www.danxurgb.net) <br> -->\n<!-- > The Hong Kong University of Science and Technology, Huawei Noah's Ark Lab -->\n> [Yang Cao](https://yangcaoai.github.io/), Yihan Zeng, [Hang Xu](https://xuhangcn.github.io/), [Dan Xu](https://www.danxurgb.net) <br>\n> The Hong Kong University of Science and Technology<br>\n> Huawei Noah's Ark Lab\n\n:triangular_flag_on_post: **Updates**  \n\n&#9745; Our new work **CoDAv2** is accepted by TPAMI, check out it [here](https://arxiv.org/pdf/2406.00830v2) !\n\n&#9745; As the first work to introduce 3D Gaussian Splatting into 3D Object Detection, 3DGS-DET is released [here](https://arxiv.org/pdf/2410.01647) !\n\n&#9745; Latest papers&codes about open-vocabulary perception are collected [here](https://github.com/yangcaoai/Awesome-Open-Vocabulary-Perception).\n\n&#9745; All the codes, data and pretrained models have been released!\n\n&#9745; The training and testing codes have been released.\n\n&#9745; The pretrained models have been released.\n\n&#9745; The OV-setting SUN-RGBD datasets have been released.  \n\n&#9745; The OV-setting ScanNet datasets have been released.\n\n&#9745; Paper LaTeX codes are available at https://scienhub.com/Yang/CoDA.\n\n## Framework  \n<img src=\"https://raw.githubusercontent.com/yangcaoai/CoDA_NeurIPS2023/main/assets/ov3d_det.png\">\n\n## Samples  \n<img src=\"https://raw.githubusercontent.com/yangcaoai/CoDA_NeurIPS2023/main/assets/CoDA_sup_fig0_v3_cropped_compressed_v2.jpg\">\n\n## Installation",
    "ContentSha": "nkAq3RrzlfBTtYOQL/kwxpSqws1us5p/H942TZndaW4=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "\n## :book: CoDA: å”èª¿å‹æ–°è¦ãƒœãƒƒã‚¯ã‚¹ç™ºè¦‹ã¨ã‚¯ãƒ­ã‚¹ãƒ¢ãƒ¼ãƒ€ãƒ«æ•´åˆã«ã‚ˆã‚‹ã‚ªãƒ¼ãƒ—ãƒ³ãƒœã‚­ãƒ£ãƒ–ãƒ©ãƒªãƒ¼3Dç‰©ä½“æ¤œå‡º (NeurIPS2023)\n<p align=\"center\">\n  <small> ğŸ”¥CoDAã«ã‚¹ã‚¿ãƒ¼â­ã‚’ä»˜ã‘ã¦ã‚·ã‚§ã‚¢ã—ã¦ãã ã•ã„ã€‚ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ğŸ”¥ </small>\n</p>\n\n> [[è«–æ–‡](https://arxiv.org/abs/2310.02960)] &emsp; [[ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒšãƒ¼ã‚¸](https://yangcaoai.github.io/publications/CoDA.html)] <br>\n<!-- > [Yang Cao](https://yangcaoai.github.io/), Yihan Zeng, [Hang Xu](https://xuhangcn.github.io/), [Dan Xu](https://www.danxurgb.net) <br> -->\n<!-- > é¦™æ¸¯ç§‘æŠ€å¤§å­¦ã€Huawei Noah's Ark Lab -->\n> [Yang Cao](https://yangcaoai.github.io/), Yihan Zeng, [Hang Xu](https://xuhangcn.github.io/), [Dan Xu](https://www.danxurgb.net) <br>\n> é¦™æ¸¯ç§‘æŠ€å¤§å­¦<br>\n> Huawei Noah's Ark Lab\n\n:triangular_flag_on_post: **ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆ**  \n\n&#9745; æ–°ä½œ **CoDAv2** ãŒTPAMIã«æ¡æŠã•ã‚Œã¾ã—ãŸã€‚ã“ã¡ã‚‰ã‹ã‚‰ã”è¦§ãã ã•ã„ [here](https://arxiv.org/pdf/2406.00830v2)ï¼\n\n&#9745; 3Dã‚¬ã‚¦ã‚·ã‚¢ãƒ³ãƒ»ã‚¹ãƒ—ãƒ©ãƒƒãƒ†ã‚£ãƒ³ã‚°ã‚’3Dç‰©ä½“æ¤œå‡ºã«åˆå°å…¥ã—ãŸç ”ç©¶ã€3DGS-DETã‚’å…¬é–‹ã—ã¾ã—ãŸ [here](https://arxiv.org/pdf/2410.01647)ï¼\n\n&#9745; ã‚ªãƒ¼ãƒ—ãƒ³ãƒœã‚­ãƒ£ãƒ–ãƒ©ãƒªãƒ¼èªè­˜ã«é–¢ã™ã‚‹æœ€æ–°è«–æ–‡ï¼†ã‚³ãƒ¼ãƒ‰ã‚’ã“ã¡ã‚‰ã«ã¾ã¨ã‚ã¦ã„ã¾ã™ [here](https://github.com/yangcaoai/Awesome-Open-Vocabulary-Perception)ã€‚\n\n&#9745; ã™ã¹ã¦ã®ã‚³ãƒ¼ãƒ‰ã€ãƒ‡ãƒ¼ã‚¿ã€äº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’å…¬é–‹ã—ã¾ã—ãŸï¼\n\n&#9745; å­¦ç¿’ã¨ãƒ†ã‚¹ãƒˆç”¨ã‚³ãƒ¼ãƒ‰ã‚’å…¬é–‹ã—ã¾ã—ãŸã€‚\n\n&#9745; äº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’å…¬é–‹ã—ã¾ã—ãŸã€‚\n\n&#9745; OVè¨­å®šã®SUN-RGBDãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’å…¬é–‹ã—ã¾ã—ãŸã€‚  \n\n&#9745; OVè¨­å®šã®ScanNetãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’å…¬é–‹ã—ã¾ã—ãŸã€‚\n\n&#9745; è«–æ–‡ã®LaTeXã‚³ãƒ¼ãƒ‰ã¯ https://scienhub.com/Yang/CoDA ã§å…¥æ‰‹å¯èƒ½ã§ã™ã€‚\n\n## ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯  \n<img src=\"https://raw.githubusercontent.com/yangcaoai/CoDA_NeurIPS2023/main/assets/ov3d_det.png\">\n\n## ã‚µãƒ³ãƒ—ãƒ«  \n<img src=\"https://raw.githubusercontent.com/yangcaoai/CoDA_NeurIPS2023/main/assets/CoDA_sup_fig0_v3_cropped_compressed_v2.jpg\">\n\n## ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 2,
    "Content": "Our code is based on PyTorch 1.8.1, torchvision==0.9.1, CUDA 10.1 and Python 3.7. It may work with other versions.\n\nPlease also install the following Python dependencies:\n",
    "ContentSha": "MkBuOS89IVkA73ZwntH2MTDqRNgiIyGJ/ye9um6/L+Q=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "ç§ãŸã¡ã®ã‚³ãƒ¼ãƒ‰ã¯PyTorch 1.8.1ã€torchvision==0.9.1ã€CUDA 10.1ã€ãŠã‚ˆã³Python 3.7ã‚’ãƒ™ãƒ¼ã‚¹ã«ã—ã¦ã„ã¾ã™ã€‚ãã®ä»–ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã§ã‚‚å‹•ä½œã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚\n\nä»¥ä¸‹ã®Pythonä¾å­˜é–¢ä¿‚ã‚‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„ï¼š\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 3,
    "Content": "```\nmatplotlib\nopencv-python\nplyfile\n'trimesh>=2.35.39,<2.35.40'\n'networkx>=2.2,<2.3'\nscipy\n```",
    "ContentSha": "+LL/lZykxdgYQh3eFJPC5i/WWxbqqgyl5dOmoZvIp+c=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```\nmatplotlib\nopencv-python\nplyfile\n'trimesh>=2.35.39,<2.35.40'\n'networkx>=2.2,<2.3'\nscipy\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 4,
    "Content": "\nPlease install `pointnet2` layers by running\n",
    "ContentSha": "o/Dwk1bF0N+Q+KB48cg8SNumjBJR2Ns+wGX4V0EJRCU=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "\n`pointnet2` ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹ã«ã¯ã€ä»¥ä¸‹ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 5,
    "Content": "```\ncd third_party/pointnet2 && python setup.py install\n```",
    "ContentSha": "Jqc6ia7RvrqyRxo2z+DHC7N1OhQN60zNzVebQwQIfbc=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```\ncd third_party/pointnet2 && python setup.py install\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 6,
    "Content": "\nPlease install a Cythonized implementation of gIOU for faster training.",
    "ContentSha": "SCoQ6KlRLPUr36zhojF3NowGH6RqXkqBLDi9gVnwqM4=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "\né«˜é€Ÿãªãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®ãŸã‚ã«ã€gIOUã®CythonåŒ–ã•ã‚ŒãŸå®Ÿè£…ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„ã€‚",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 7,
    "Content": "```\nconda install cython\ncd utils && python cython_compile.py build_ext --inplace\n```",
    "ContentSha": "cA/nqGjuSCNtjc+UjmoLFda1xX+qloFt65jgxMSaEVA=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```\nconda install cython\ncd utils && python cython_compile.py build_ext --inplace\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 8,
    "Content": "\n## Dataset preparation\n\nTo achieve the OV setting, we re-organize the original [ScanNet](https://github.com/facebookresearch/votenet/tree/main/scannet) and [SUN RGB-D](https://github.com/facebookresearch/votenet/tree/main/sunrgbd) and adopt annotations of more categories. Please directly download the ov-setting datasets we provide here: [OV SUN RGB-D](https://huggingface.co/datasets/YangCaoCS/Open-Vocabulary-SUN-RGBD) and [OV ScanNet](https://hkustconnect-my.sharepoint.com/:f:/g/personal/ycaobd_connect_ust_hk/EsqoPe7-VFxOlY0a-v1-vPwBSiEHoGRTgK5cLIhnjyXiEQ?e=jY7nKT). \n\nThen run for the downloaded *.tar file:",
    "ContentSha": "c7izo1HCN/Sa+cMb4Jh9i4TGMiIfVkTvyP/Z0L8/wBo=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "\n## ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæº–å‚™\n\nOVè¨­å®šã‚’å®Ÿç¾ã™ã‚‹ãŸã‚ã«ã€å…ƒã®[ScanNet](https://github.com/facebookresearch/votenet/tree/main/scannet)ãŠã‚ˆã³[SUN RGB-D](https://github.com/facebookresearch/votenet/tree/main/sunrgbd)ã‚’å†ç·¨æˆã—ã€ã‚ˆã‚Šå¤šãã®ã‚«ãƒ†ã‚´ãƒªã®ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æ¡ç”¨ã—ã¾ã—ãŸã€‚ã“ã“ã‹ã‚‰ç›´æ¥ã€æä¾›ã™ã‚‹OVè¨­å®šãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ï¼š[OV SUN RGB-D](https://huggingface.co/datasets/YangCaoCS/Open-Vocabulary-SUN-RGBD)ãŠã‚ˆã³[OV ScanNet](https://hkustconnect-my.sharepoint.com/:f:/g/personal/ycaobd_connect_ust_hk/EsqoPe7-VFxOlY0a-v1-vPwBSiEHoGRTgK5cLIhnjyXiEQ?e=jY7nKT)ã€‚\n\næ¬¡ã«ã€ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ãŸ*.tarãƒ•ã‚¡ã‚¤ãƒ«ã«å¯¾ã—ã¦ä»¥ä¸‹ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ï¼š",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 9,
    "Content": "```\nbash data_preparation.sh\n```",
    "ContentSha": "uURFuiZSdVuJeb80CtZ1OM72fmj9Dk8jeJHj+HcUl+4=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```\nbash data_preparation.sh\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 10,
    "Content": "\n## Evaluation\nDownload the pretrained models [here](https://drive.google.com/file/d/1fTKX1ML5u8jJ249GwAYqdCZGs941907H/view?usp=drive_link).\nThen run:",
    "ContentSha": "ZFrOwpzhrIGgo5/uho2s56cf/VggoxcmksLPPTOzG5Y=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "\n## è©•ä¾¡\näº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã¯[ã“ã¡ã‚‰](https://drive.google.com/file/d/1fTKX1ML5u8jJ249GwAYqdCZGs941907H/view?usp=drive_link)ã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚\næ¬¡ã«ä»¥ä¸‹ã‚’å®Ÿè¡Œã—ã¾ã™:",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 11,
    "Content": "```\nbash test_release_models.sh\n```",
    "ContentSha": "js4nBMboFZkWviwkVXNHpDKlPTNI16/67s1uXJJT3nU=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```\nbash test_release_models.sh\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 12,
    "Content": "\n## Training",
    "ContentSha": "pka6N4zXtqLf0MpQPdxYRJbosGA4+nbrWiDBT56U1/U=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "\n## ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 13,
    "Content": "```\nbash scripts/coda_sunrgbd_stage1.sh\nbash scripts/coda_sunrgbd_stage2.sh\n```",
    "ContentSha": "ZllTPt8b7bzZ1+Di1+u4XAZAuPyc/M8U3Zdi2XFmwXk=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```\nbash scripts/coda_sunrgbd_stage1.sh\nbash scripts/coda_sunrgbd_stage2.sh\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 14,
    "Content": "## Running Samples",
    "ContentSha": "UPp/p/sr/BtI28Zw5AnlTdI1DtBJwEv1BcF5WBIsVvw=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "## ã‚µãƒ³ãƒ—ãƒ«ã®å®Ÿè¡Œ",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 15,
    "Content": "```\nbash run_samples.sh\n```",
    "ContentSha": "iVS72e4zU+Lzzc8XJsuHXPCrJQroDc5eOskNQ1vXPz4=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```\nbash run_samples.sh\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 16,
    "Content": "\n## :scroll: BibTeX\nIf CoDA is helpful, please cite:",
    "ContentSha": "tYKeCqadQOsA4i21BPfvRvVNkoYzbXJ5TDl8YEnilx0=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "\n## :scroll: BibTeX\nCoDAãŒå½¹ç«‹ã£ãŸå ´åˆã¯ã€ä»¥ä¸‹ã‚’å¼•ç”¨ã—ã¦ãã ã•ã„ï¼š",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 17,
    "Content": "```\n@inproceedings{cao2023coda,\n  title={CoDA: Collaborative Novel Box Discovery and Cross-modal Alignment for Open-vocabulary 3D Object Detection},\n  author={Cao, Yang and Zeng, Yihan and Xu, Hang and Xu, Dan},\n  booktitle={NeurIPS},\n  year={2023}\n}\n\n@article{cao2024collaborative,\n  title={Collaborative Novel Object Discovery and Box-Guided Cross-Modal Alignment for Open-Vocabulary 3D Object Detection},\n  author={Cao, Yang and Zeng, Yihan and Xu, Hang and Xu, Dan},\n  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)},\n  year={2025}\n}\n```",
    "ContentSha": "KF8qHIzy18tzrrmzfVnZ44q+WrJbWEfCRokEk6L996Y=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```\n@inproceedings{cao2023coda,\n  title={CoDA: Collaborative Novel Box Discovery and Cross-modal Alignment for Open-vocabulary 3D Object Detection},\n  author={Cao, Yang and Zeng, Yihan and Xu, Hang and Xu, Dan},\n  booktitle={NeurIPS},\n  year={2023}\n}\n\n@article{cao2024collaborative,\n  title={Collaborative Novel Object Discovery and Box-Guided Cross-Modal Alignment for Open-Vocabulary 3D Object Detection},\n  author={Cao, Yang and Zeng, Yihan and Xu, Hang and Xu, Dan},\n  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)},\n  year={2025}\n}\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 18,
    "Content": "\n## :e-mail: Contact\n\nIf you have any question or collaboration need (research purpose or commercial purpose), please email `yangcao.cs@gmail.com`.\n\n## :scroll: Acknowledgement\nCoDA is inspired by [CLIP](https://github.com/openai/CLIP) and [3DETR](https://github.com/facebookresearch/3detr). We appreciate their great codes.\n",
    "ContentSha": "BjI8Gecj3tcJFy6UOxg6DICOwdKomzKeiMi33ODdQyk=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "\n## :e-mail: ãŠå•ã„åˆã‚ã›\n\nã”è³ªå•ã‚„ã‚³ãƒ©ãƒœãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®ã”ä¾é ¼ï¼ˆç ”ç©¶ç›®çš„ã¾ãŸã¯å•†ç”¨ç›®çš„ï¼‰ãŒã‚ã‚‹å ´åˆã¯ã€`yangcao.cs@gmail.com` ã¾ã§ãƒ¡ãƒ¼ãƒ«ã‚’ãŠé€ã‚Šãã ã•ã„ã€‚\n\n## :scroll: è¬è¾\nCoDAã¯[CLIP](https://github.com/openai/CLIP)ãŠã‚ˆã³[3DETR](https://github.com/facebookresearch/3detr)ã«è§¦ç™ºã•ã‚Œã¦ã„ã¾ã™ã€‚ã“ã‚Œã‚‰ã®ç´ æ™´ã‚‰ã—ã„ã‚³ãƒ¼ãƒ‰ã«æ„Ÿè¬ã—ã¾ã™ã€‚\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  }
]