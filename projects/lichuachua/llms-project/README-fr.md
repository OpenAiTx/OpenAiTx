# Feuille de route d'apprentissage pour le développement d'applications de grands modèles (version express)

Ce dépôt contient des matériaux que j'ai organisés et étudiés lors de mon apprentissage du 🔥 développement d'applications de grands modèles 🔥, tous sont du contenu essentiel, sans extensions supplémentaires, 💰 gagner de l'argent est la priorité absolue 💰. Bienvenue à la lecture, si cela vous est utile, merci de cliquer sur 🌟 star !

# ✅ Guide de lecture

Ce projet présente une démonstration simple de RAG et Agent pour le développement d'applications de grands modèles, utilisant tous le cadre LangChain, incluant un cours d'initiation de base, principalement pour aider tout le monde à 🧐 démarrer rapidement 🧐.  
La structure du répertoire est divisée en trois parties :  
- **Dossier LangChain_RAG** : projets Demo et matériaux d'apprentissage liés à RAG ;  
- **Dossier LangChain_Agent** : Demo et matériaux d'apprentissage liés à Agent ;  
- **Interview** : questions types d'entretien pour RAG et Agent de grands modèles.

# ✅ LangChain_RAG

Cette partie comprend **quatre sections** :  
- llms-1 et llms-2 sont des 🕶️ **cours d'initiation** 🕶️ sur Bilibili, présentés clairement et simplement par deux créateurs, principalement pour une compréhension de base, à parcourir rapidement ;  
- llms-3 est un tutoriel RAG officiel de Langchain, avec la vidéo originale et une version traduite nationale présentées ici, expliquant les principaux processus du RAG et ses points d’optimisation, **🔥 il est fortement conseillé de se concentrer sur celui-ci, car beaucoup de questions d’entretien portent sur les optimisations 🔥** ;  
- llms-4 est un **💡 projet RAG 💡** officiel de Langchain, incluant le flux de base du projet RAG, garantissant que vous puissiez le faire tourner immédiatement, avec une structure de code très simple.

## llms-1
### Adresse vidéo (regarder toute la série) :  
- https://www.bilibili.com/video/BV1qC4y1F7Dy  
### Code :  
- 🌹Adresse du code (version exécutable) : https://github.com/lichuachua/llms-project/tree/main/LangChain_RAG/llms-1/  
  - note (✅ conseillé de télécharger et d’exécuter celui-ci ✅) : code testé par moi, mise à jour de certains paquets (certains paquets du code original sont périmés)  
  - original : code original de l’auteur (même emplacement, non conseillé, peut nécessiter mise à jour des paquets)  
- Emplacement original du code : https://github.com/blackinkkkxi/RAG_langchain/tree/main  
- Plateforme d’exécution : sauf langchain_hf, tous peuvent tourner sur Colab ; fonctionnent aussi sur Kaggle, introduction à Kaggle ici : [Calcul gratuit, petite quantité mais suffisante — Kaggle](https://mp.weixin.qq.com/s/SK5VXzx2zijzjc8OYJICKA) ;  
## llms-2
### Adresse vidéo (regarder un seul épisode suffit) :  
- https://www.bilibili.com/video/BV1Cp421R7Y7  
### Code :  
- 🌹Adresse du code (version exécutable) : https://github.com/lichuachua/llms-project/tree/main/LangChain_RAG/llms-2/  
  - note (✅ conseillé de télécharger et d’exécuter celui-ci ✅) : code testé par moi, mise à jour de certains paquets (certains paquets du code original sont périmés)  
  - original : code original de l’auteur (même emplacement, non conseillé, peut nécessiter mise à jour des paquets)  
- Emplacement original du code : https://github.com/owenliang/rag-retrieval/tree/main  
- Plateforme d’exécution : fonctionne sur Kaggle, introduction à Kaggle ici : [Calcul gratuit, petite quantité mais suffisante — Kaggle](https://mp.weixin.qq.com/s/SK5VXzx2zijzjc8OYJICKA) ;  
## llms-3
### Adresse vidéo (regarder toute la série) :  
- Vidéo originale à l’étranger (en anglais) : https://www.youtube.com/playlist?list=PLfaIDFEXuae2LXbO1_PKyVJiQ23ZztA0x
- Version chinoise nationale : https://www.bilibili.com/video/BV1dm41127jc/
### Code :
- 🌹Adresse du code (version exécutable) : https://github.com/lichuachua/llms-project/tree/main/LangChain_RAG/llms-3/
  - note (✅ recommandé de télécharger et d’exécuter celui-ci ✅) : J’ai exécuté le code, certaines mises à jour des packages (le code original utilise des packages périmés)
  - original : code de l’auteur original (même source, non recommandé, pourrait nécessiter une mise à jour des packages)
  - PPT : PPT correspondant à la vidéo officielle
- Source du code : https://github.com/langchain-ai/rag-from-scratch/tree/main  
- Plateforme d’exécution : Exécution sur Kaggle, pour débuter sur Kaggle voir : [Utiliser la puissance de calcul gratuite, petite quantité mais suffisante — Kaggle](https://mp.weixin.qq.com/s/SK5VXzx2zijzjc8OYJICKA) ;
## llms-4
### Code :
- 🌹Adresse du code (✅ code modifié par moi, directement exécutable ✅) : https://github.com/lichuachua/chat-langchain-study/
- Source du code (problèmes d’exécution, nécessite modifications) : https://github.com/langchain-ai/chat-langchain
### Explications :
- langchain-chat est un exemple officiel de projet RAG, que je recommande comme projet d’introduction ; à la demande des internautes, j’ai enregistré une vidéo tutorielle pour garantir que vous puissiez l’exécuter.
### Ressources de référence :
- https://www.bilibili.com/video/BV1eB4y1Z752/
- https://github.com/webup/agi-talks/blob/master/301-langchain-chatdoc/src/slides.md
- https://blog.langchain.dev/building-chat-langchain-2/
            

# ✅ LangChain_Agent

Cette section comporte **deux parties**, ce sont deux démonstrations simples d’Agent sur Bilibili, faciles à comprendre.
- AI_Agent basé sur OPENAI_API
- QW_Agent basé sur QWen_API


## AI_Agent
### Adresse vidéo :
- https://www.bilibili.com/video/BV1JV411F7Yj/
### Code :
- 🌹Adresse du code (✅ code modifié par moi, directement exécutable ✅) : https://github.com/lichuachua/llms-project/tree/main/LangChain_Agents/AI_Agent/
- Source du code : https://github.com/parallel75/AI_Agent  
- Plateforme d’exécution : locale

## QW_Agent
### Adresse vidéo :
- https://www.bilibili.com/video/BV1QF4m177Rx/
### Explications :
- Ce projet nécessite une demande de clé et API liées à Qianwen, il y a des difficultés ; je recommande de télécharger le code modifié par moi, directement exécutable, la nouvelle version de Qianwen nécessite une mise à jour du code que j’ai effectuée.
### Code :  
- 🌹Adresse du code (✅code modifié par moi-même, peut être exécuté directement✅) : https://github.com/lichuachua/llms-project/blob/main/LangChain_Agents/QW_Agent/  
- Adresse originale du code (problèmes d’exécution, nécessite des modifications personnelles) : https://github.com/owenliang/agent  
- Plateforme d’exécution : locale  

# ✅ Entretien  
Cette partie contient deux sections d’entretiens classiques, il s’agit de documents d’application pour grands modèles collectés et organisés par moi-même durant ma recherche d’emploi, testés par moi-même, grâce auxquels j’ai pu trouver plusieurs postes de **ingénieur senior en IA** dans de grandes entreprises.  
- [Document classique sur le développement d’applications grands modèles](https://mp.weixin.qq.com/mp/appmsgalbum?__biz=Mzk1NzgzMjY3OQ==&action=getalbum&album_id=3987723560113356813&scene=126&uin=&key=&devicetype=iMac+MacBookPro18%2C3+OSX+OSX+15.4.1+build(24E263)&version=13080a10&lang=zh_CN&nettype=WIFI&ascene=78&fontScale=100)  
## RAG  
- Présentation détaillée du RAG (Retrieval-Augmented Generation) avec grands modèles (LLMs) / points de connaissance possibles en entretien, texte complet de plus de 40 000 mots, organisé selon le processus : [Notes de connaissances RAG grands modèles](https://mp.weixin.qq.com/s/zmUTGAMoljXSmnoo_cBQig)  
## Agent  
- Présentation détaillée des Agents intelligents avec grands modèles (LLMs) / points de connaissance possibles en entretien, texte complet de plus de 10 000 mots, organisé par modules : [Notes de connaissances Agent grands modèles](https://mp.weixin.qq.com/s/TSioLS_RhrX57YEnY3mkag)


---

Tranlated By [Open Ai Tx](https://github.com/OpenAiTx/OpenAiTx) | Last indexed: 2025-09-03

---