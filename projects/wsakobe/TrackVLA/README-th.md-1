{
  "id": 1,
  "origin": "<p align=\"center\">\n<h1 align=\"center\"><strong>TrackVLA: Embodied Visual Tracking in the Wild</strong></h1>\n  <p align=\"center\">\n    <!--   \t<strong>CoRL 2025</strong><br> -->\n    <a href='https://wsakobe.github.io/' target='_blank'>Shaoan Wang</a>&emsp;\n\t<a href='https://jzhzhang.github.io/' target='_blank'>Jiazhao Zhang</a>&emsp;\n    Minghan Li&emsp;\n    Jiahang Liu&emsp;\n    Anqi Li&emsp; <br>\n    Kui Wu&emsp;\n    <a href='https://fangweizhong.xyz/' target='_blank'>Fangwei Zhong</a>&emsp;\n    <a href='https://www.coe.pku.edu.cn/teaching/manufacturing/9993.html' target='_blank'>Junzhi Yu</a>&emsp;\n\t<a href='https://scholar.google.com/citations?user=X7M0I8kAAAAJ&hl=zh-CN' target='_blank'>Zhizheng Zhang</a>&emsp;\n  <a href='https://hughw19.github.io/' target='_blank'>He Wang</a>&emsp;\n    <br>\n    Peking University&emsp; \n    Galbot&emsp; <br>\n    Beihang University&emsp;\n    Beijing Normal University&emsp;\n    Beijing Academy of Artificial Intelligence&emsp;\n    <br>\n  </p>\n</p>\n\n<div id=\"top\" align=\"center\">\n\n[![Project](https://img.shields.io/badge/Project-%239c403d?style=flat&logoColor=%23FA7F6F\n)](https://pku-epic.github.io/TrackVLA-web/)\n[![arXiv](https://img.shields.io/badge/Arxiv-%233b6291?style=flat&logoColor=%23FA7F6F\n)](http://arxiv.org/abs/2505.23189)\n[![Video](https://img.shields.io/badge/Video-%23c97937?style=flat&logoColor=%23FA7F6F\n)](https://youtu.be/v51U3Nk-SK4?si=foz3zbYD8hLHSybC)\n\n</div>\n\n## üè° About\n<strong><em>TrackVLA</em></strong> is a vision-language-action model capable of simultaneous object recognition and visual tracking, trained on a dataset of 1.7 million samples. It demonstrates robust tracking, long-horizon tracking, and cross-domain generalization across diverse challenging environments.\n<div style=\"text-align: center;\">\n    <img src=\"https://raw.githubusercontent.com/wsakobe/TrackVLA/main/assets/teaser.png\" alt=\"Dialogue_Teaser\" width=100% >\n</div>\n\n## üì¢ News\n\n* [25/07/02]: The EVT-Bench is now available.\n\n## üí° Installation\n1. **Preparing conda env**\n\n   First, you need to install [conda](https://docs.conda.io/projects/conda/en/latest/user-guide/install/). Once conda installed, create a new env:\n   ```bash\n   conda create -n evt_bench python=3.9 cmake=3.14.0\n   conda activate evt_bench\n   ```\n\n2. **Conda install habitat-sim**\n   \n   You need to install habitat-sim v0.3.1\n      ```\n      conda install habitat-sim==0.3.1 withbullet -c conda-forge -c aihabitat\n      ```\n\n3. **Install habitat-lab from source**\n      ```\n      cd habitat-lab\n      pip install -e habitat-lab\n      ```\n\n4. **Prepare datasets**\n\n    Download Habitat Matterport 3D (HM3D) dataset from [here](https://github.com/facebookresearch/habitat-sim/blob/main/DATASETS.md#habitat-matterport-3d-research-dataset-hm3d) and Matterport3D (MP3D) from [here](https://github.com/facebookresearch/habitat-sim/blob/main/DATASETS.md#matterport3d-mp3d-dataset).\n\n    Then move the dataset to `data/scene_datasets`. The structure of the dataset is outlined as follows:\n    ```\n    data/\n     ‚îî‚îÄ‚îÄ scene_datasets/\n        ‚îú‚îÄ‚îÄ hm3d/\n        ‚îÇ ‚îú‚îÄ‚îÄ train/\n        ‚îÇ ‚îÇ   ‚îî‚îÄ‚îÄ ...\n        ‚îÇ ‚îú‚îÄ‚îÄ val/\n        ‚îÇ ‚îÇ   ‚îî‚îÄ‚îÄ ...\n        ‚îÇ ‚îî‚îÄ‚îÄ minival\n        ‚îÇ     ‚îî‚îÄ‚îÄ ...\n        ‚îî‚îÄ‚îÄ mp3d/\n          ‚îú‚îÄ‚îÄ 1LXtFkjw3qL\n          ‚îÇ   ‚îî‚îÄ‚îÄ ...\n          ‚îî‚îÄ‚îÄ ...\n    ```\n\n    Next, run the following code to obtain data for the humanoid avatars:\n      ```\n      python download_humanoid_data.py\n      ```\n\n\n## üß™ Evaluation\n  Run the script with:\n\n    bash eval.sh\n\n  Results will be saved in the specified SAVE_PATH, which will include a log directory and a video directory. To monitor the results during the evaluation process, run:",
  "origin_sha": "chO/Ywe8xISNVTZxxh2xcDW/cZFvAWrpfNAJZKmMzTw=",
  "translate": "<p align=\"center\">\n<h1 align=\"center\"><strong>TrackVLA: ‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡∏†‡∏≤‡∏û‡πÄ‡∏ä‡∏¥‡∏á‡∏£‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏¢‡πÅ‡∏ö‡∏ö‡∏≠‡∏¥‡∏á‡∏™‡∏¥‡πà‡∏á‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏°‡πÉ‡∏ô‡∏™‡∏†‡∏≤‡∏û‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏°‡∏à‡∏£‡∏¥‡∏á</strong></h1>\n  <p align=\"center\">\n    <!--   \t<strong>CoRL 2025</strong><br> -->\n    <a href='https://wsakobe.github.io/' target='_blank'>Shaoan Wang</a>&emsp;\n\t<a href='https://jzhzhang.github.io/' target='_blank'>Jiazhao Zhang</a>&emsp;\n    Minghan Li&emsp;\n    Jiahang Liu&emsp;\n    Anqi Li&emsp; <br>\n    Kui Wu&emsp;\n    <a href='https://fangweizhong.xyz/' target='_blank'>Fangwei Zhong</a>&emsp;\n    <a href='https://www.coe.pku.edu.cn/teaching/manufacturing/9993.html' target='_blank'>Junzhi Yu</a>&emsp;\n\t<a href='https://scholar.google.com/citations?user=X7M0I8kAAAAJ&hl=zh-CN' target='_blank'>Zhizheng Zhang</a>&emsp;\n  <a href='https://hughw19.github.io/' target='_blank'>He Wang</a>&emsp;\n    <br>\n    ‡∏°‡∏´‡∏≤‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏•‡∏±‡∏¢‡∏õ‡∏±‡∏Å‡∏Å‡∏¥‡πà‡∏á&emsp; \n    Galbot&emsp; <br>\n    ‡∏°‡∏´‡∏≤‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏•‡∏±‡∏¢ Beihang&emsp;\n    ‡∏°‡∏´‡∏≤‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏•‡∏±‡∏¢‡∏Ñ‡∏£‡∏π‡∏õ‡∏±‡∏Å‡∏Å‡∏¥‡πà‡∏á&emsp;\n    ‡∏™‡∏ñ‡∏≤‡∏ö‡∏±‡∏ô‡∏õ‡∏±‡∏ç‡∏ç‡∏≤‡∏õ‡∏£‡∏∞‡∏î‡∏¥‡∏©‡∏ê‡πå‡∏õ‡∏±‡∏Å‡∏Å‡∏¥‡πà‡∏á&emsp;\n    <br>\n  </p>\n</p>\n\n<div id=\"top\" align=\"center\">\n\n[![Project](https://img.shields.io/badge/Project-%239c403d?style=flat&logoColor=%23FA7F6F\n)](https://pku-epic.github.io/TrackVLA-web/)\n[![arXiv](https://img.shields.io/badge/Arxiv-%233b6291?style=flat&logoColor=%23FA7F6F\n)](http://arxiv.org/abs/2505.23189)\n[![Video](https://img.shields.io/badge/Video-%23c97937?style=flat&logoColor=%23FA7F6F\n)](https://youtu.be/v51U3Nk-SK4?si=foz3zbYD8hLHSybC)\n\n</div>\n\n## üè° ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö\n<strong><em>TrackVLA</em></strong> ‡∏Ñ‡∏∑‡∏≠‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ß‡∏¥‡∏™‡∏±‡∏¢‡∏ó‡∏±‡∏®‡∏ô‡πå-‡∏†‡∏≤‡∏©‡∏≤-‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏ó‡∏≥‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏à‡∏î‡∏à‡∏≥‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡πÅ‡∏•‡∏∞‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡∏†‡∏≤‡∏û‡πÑ‡∏î‡πâ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô ‡πÇ‡∏î‡∏¢‡∏ú‡πà‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡∏ö‡∏ô‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≥‡∏ô‡∏ß‡∏ô 1.7 ‡∏•‡πâ‡∏≤‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ô‡∏µ‡πâ‡πÅ‡∏™‡∏î‡∏á‡∏®‡∏±‡∏Å‡∏¢‡∏†‡∏≤‡∏û‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡πÅ‡∏Ç‡πá‡∏á‡πÅ‡∏Å‡∏£‡πà‡∏á ‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡∏£‡∏∞‡∏¢‡∏∞‡∏¢‡∏≤‡∏ß ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ‡∏Ç‡πâ‡∏≤‡∏°‡πÇ‡∏î‡πÄ‡∏°‡∏ô‡πÉ‡∏ô‡∏™‡∏†‡∏≤‡∏û‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏°‡∏ó‡∏µ‡πà‡∏ó‡πâ‡∏≤‡∏ó‡∏≤‡∏¢‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö\n<div style=\"text-align: center;\">\n    <img src=\"https://raw.githubusercontent.com/wsakobe/TrackVLA/main/assets/teaser.png\" alt=\"Dialogue_Teaser\" width=100% >\n</div>\n\n## üì¢ ‡∏Ç‡πà‡∏≤‡∏ß‡∏™‡∏≤‡∏£\n\n* [25/07/02]: ‡∏Ç‡∏ì‡∏∞‡∏ô‡∏µ‡πâ EVT-Bench ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÅ‡∏•‡πâ‡∏ß\n\n## üí° ‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á\n1. **‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏™‡∏†‡∏≤‡∏û‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏° conda**\n\n   ‡∏Å‡πà‡∏≠‡∏ô‡∏≠‡∏∑‡πà‡∏ô ‡∏Ñ‡∏∏‡∏ì‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á [conda](https://docs.conda.io/projects/conda/en/latest/user-guide/install/) ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á conda ‡πÅ‡∏•‡πâ‡∏ß ‡πÉ‡∏´‡πâ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏†‡∏≤‡∏û‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏°‡πÉ‡∏´‡∏°‡πà:\n   ```bash\n   conda create -n evt_bench python=3.9 cmake=3.14.0\n   conda activate evt_bench\n   ```\n\n2. **‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á habitat-sim ‡∏î‡πâ‡∏ß‡∏¢ conda**\n   \n   ‡∏Ñ‡∏∏‡∏ì‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á habitat-sim ‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô 0.3.1\n      ```\n      conda install habitat-sim==0.3.1 withbullet -c conda-forge -c aihabitat\n      ```\n\n3. **‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á habitat-lab ‡∏à‡∏≤‡∏Å‡∏ã‡∏≠‡∏£‡πå‡∏™**\n      ```\n      cd habitat-lab\n      pip install -e habitat-lab\n      ```\n\n4. **‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•**\n\n    ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Habitat Matterport 3D (HM3D) ‡∏à‡∏≤‡∏Å [‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà](https://github.com/facebookresearch/habitat-sim/blob/main/DATASETS.md#habitat-matterport-3d-research-dataset-hm3d) ‡πÅ‡∏•‡∏∞ Matterport3D (MP3D) ‡∏à‡∏≤‡∏Å [‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà](https://github.com/facebookresearch/habitat-sim/blob/main/DATASETS.md#matterport3d-mp3d-dataset)\n\n    ‡∏à‡∏≤‡∏Å‡∏ô‡∏±‡πâ‡∏ô‡πÉ‡∏´‡πâ‡∏¢‡πâ‡∏≤‡∏¢‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏õ‡πÑ‡∏ß‡πâ‡∏ó‡∏µ‡πà `data/scene_datasets` ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡∏≠‡∏á‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏°‡∏µ‡∏î‡∏±‡∏á‡∏ô‡∏µ‡πâ:\n    ```\n    data/\n     ‚îî‚îÄ‚îÄ scene_datasets/\n        ‚îú‚îÄ‚îÄ hm3d/\n        ‚îÇ ‚îú‚îÄ‚îÄ train/\n        ‚îÇ ‚îÇ   ‚îî‚îÄ‚îÄ ...\n        ‚îÇ ‚îú‚îÄ‚îÄ val/\n        ‚îÇ ‚îÇ   ‚îî‚îÄ‚îÄ ...\n        ‚îÇ ‚îî‚îÄ‚îÄ minival\n        ‚îÇ     ‚îî‚îÄ‚îÄ ...\n        ‚îî‚îÄ‚îÄ mp3d/\n          ‚îú‚îÄ‚îÄ 1LXtFkjw3qL\n          ‚îÇ   ‚îî‚îÄ‚îÄ ...\n          ‚îî‚îÄ‚îÄ ...\n    ```\n\n    ‡∏ï‡πà‡∏≠‡πÑ‡∏õ ‡πÉ‡∏´‡πâ‡∏£‡∏±‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î‡∏î‡∏±‡∏á‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏≠‡∏ß‡∏≤‡∏ï‡∏≤‡∏£‡πå‡∏°‡∏ô‡∏∏‡∏©‡∏¢‡πå:\n      ```\n      python download_humanoid_data.py\n      ```\n\n\n## üß™ ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•\n  ‡∏£‡∏±‡∏ô‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á:\n\n    bash eval.sh\n\n  ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ß‡πâ‡πÉ‡∏ô SAVE_PATH ‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î ‡∏ã‡∏∂‡πà‡∏á‡∏à‡∏∞‡∏°‡∏µ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå log ‡πÅ‡∏•‡∏∞‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠ ‡∏´‡∏≤‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏Å‡∏£‡∏∞‡∏ö‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏• ‡πÉ‡∏´‡πâ‡∏£‡∏±‡∏ô:",
  "status": "ok"
}