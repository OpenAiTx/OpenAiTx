[
  {
    "Id": 1,
    "Content": "<!-- markdownlint-disable MD041 MD033 -->\n<div align=\"center\">\n    <picture>\n        <source media=\"(prefers-color-scheme: dark)\" srcset=\"docs/images/typedef-fenic-logo-dark.png\">\n        <img src=\"https://raw.githubusercontent.com/typedef-ai/fenic/main/docs/images/typedef-fenic-logo.png\" alt=\"fenic, by typedef\" width=\"90%\">\n    </picture>\n</div>\n\n# fenic: the dataframe (re)built for LLM inference\n\n[![PyPI version](https://img.shields.io/pypi/v/fenic.svg)](https://pypi.org/project/fenic/)\n[![Python versions](https://img.shields.io/pypi/pyversions/fenic.svg)](https://pypi.org/project/fenic/)\n[![License](https://img.shields.io/github/license/typedef-ai/fenic.svg)](https://github.com/typedef-ai/fenic/blob/main/LICENSE)\n[![Discord](https://img.shields.io/discord/1381706122322513952?label=Discord&logo=discord)](https://discord.gg/GdqF3J7huR)\n\n---\n\n## **Documentation**: [docs.fenic.ai](https://docs.fenic.ai/)\n\nfenic is an opinionated, PySpark-inspired DataFrame framework from typedef.ai for building AI and agentic applications. Transform unstructured and structured data into insights using familiar DataFrame operations enhanced with semantic intelligence. With first-class support for markdown, transcripts, and semantic operators, plus efficient batch inference across any model provider.\n",
    "ContentSha": "tmub1AxUb0Y4Al5Ltz67crbP453GMVUntyWUISmU7NQ=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "<!-- markdownlint-disable MD041 MD033 -->\n<div align=\"center\">\n    <picture>\n        <source media=\"(prefers-color-scheme: dark)\" srcset=\"docs/images/typedef-fenic-logo-dark.png\">\n        <img src=\"https://raw.githubusercontent.com/typedef-ai/fenic/main/docs/images/typedef-fenic-logo.png\" alt=\"fenic, by typedef\" width=\"90%\">\n    </picture>\n</div>\n\n# fenic : la dataframe (re)construite pour l'inférence LLM\n\n[![Version PyPI](https://img.shields.io/pypi/v/fenic.svg)](https://pypi.org/project/fenic/)\n[![Versions Python](https://img.shields.io/pypi/pyversions/fenic.svg)](https://pypi.org/project/fenic/)\n[![Licence](https://img.shields.io/github/license/typedef-ai/fenic.svg)](https://github.com/typedef-ai/fenic/blob/main/LICENSE)\n[![Discord](https://img.shields.io/discord/1381706122322513952?label=Discord&logo=discord)](https://discord.gg/GdqF3J7huR)\n\n---\n\n## **Documentation** : [docs.fenic.ai](https://docs.fenic.ai/)\n\nfenic est un framework DataFrame inspiré de PySpark, développé par typedef.ai, pour la construction d'applications d'IA et d'agents. Transformez des données non structurées et structurées en insights grâce à des opérations DataFrame familières, enrichies par l'intelligence sémantique. Profitez d'une prise en charge native du markdown, des transcriptions et des opérateurs sémantiques, ainsi que d'une inférence par lots efficace auprès de tout fournisseur de modèles.",
    "Status": "ok"
  },
  {
    "Id": 2,
    "Content": "## Install\n\nfenic supports Python `[3.10, 3.11, 3.12]`\n\n```bash\npip install fenic\n```\n\n### LLM Provider Setup\n\nfenic requires an API key from at least one LLM provider. Set the appropriate environment variable for your chosen provider:\n\n```bash\n# For OpenAI\nexport OPENAI_API_KEY=\"your-openai-api-key\"\n\n# For Anthropic\nexport ANTHROPIC_API_KEY=\"your-anthropic-api-key\"\n\n# For Google",
    "ContentSha": "QT2GWoHGnyfwnJxlfZAk0I5rpIsEfvGEhJD38oz6lCY=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "## Installation\n\nfenic prend en charge Python `[3.10, 3.11, 3.12]`\n\n```bash\npip install fenic\n```\n\n### Configuration du fournisseur LLM\n\nfenic nécessite une clé API d’au moins un fournisseur LLM. Définissez la variable d’environnement appropriée pour le fournisseur choisi :\n\n```bash\n# Pour OpenAI\nexport OPENAI_API_KEY=\"votre-clé-api-openai\"\n\n# Pour Anthropic\nexport ANTHROPIC_API_KEY=\"votre-clé-api-anthropic\"\n\n# Pour Google",
    "Status": "ok"
  },
  {
    "Id": 3,
    "Content": "export GEMINI_API_KEY=\"your-google-api-key\"\n```\n\n## Quickstart\n\nThe fastest way to learn about fenic is by checking the examples.\n\nBelow is a quick list of the examples in this repo:\n\n| Example                                                                 | Description                                                                                                                         |\n| ----------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------- |\n| [Hello World!](examples/hello_world)                                    | Introduction to semantic extraction and classification using fenic's core operators through error log analysis.                     |\n| [Enrichment](examples/enrichment)                                       | Multi-stage DataFrames with template-based text extraction, joins, and LLM-powered transformations demonstrated via log enrichment. |\n| [Meeting Transcript Processing](examples/meeting_transcript_processing) | Native transcript parsing, Pydantic schema integration, and complex aggregations shown through meeting analysis.                    |\n| [News Analysis](examples/news_analysis)                                 | Analyze and extract insights from news articles using semantic operators and structured data processing.                            |\n| [Podcast Summarization](examples/podcast_summarization)                 | Process and summarize podcast transcripts with speaker-aware analysis and key point extraction.                                     |\n| [Semantic Join](examples/semantic_joins)                                | Instead of simple fuzzy matching, use fenic's powerful semantic join functionality to match data across tables.                     |\n| [Named Entity Recognition](examples/named_entity_recognition)           | Extract and classify named entities from text using semantic extraction and classification.                                         |\n| [Markdown Processing](examples/markdown_processing)                     | Process and transform markdown documents with structured data extraction and formatting.                                            |\n| [JSON Processing](examples/json_processing)                             | Handle complex JSON data structures with semantic operations and schema validation.                                                 |\n| [Feedback Clustering](examples/feedback_clustering)                     | Group and analyze feedback using semantic similarity and clustering operations.                                                     |\n| [Document Extraction](examples/document_extraction)                     | Extract structured information from various document formats using semantic operators.                                              |\n\n(Feel free to click any example above to jump right to its folder.)\n",
    "ContentSha": "RBvJ+qAaDZODC8rvu1sFp9QTE4SUhSKTTu/91HAxBRc=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "export GEMINI_API_KEY=\"votre-clé-api-google\"\n```\n\n## Démarrage rapide\n\nLe moyen le plus rapide de découvrir fenic est de consulter les exemples.\n\nVoici une liste rapide des exemples présents dans ce dépôt :\n\n| Exemple                                                                 | Description                                                                                                                                    |\n| ----------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------- |\n| [Hello World!](examples/hello_world)                                    | Introduction à l’extraction et à la classification sémantiques à l’aide des opérateurs principaux de fenic via l’analyse de journaux d’erreurs. |\n| [Enrichment](examples/enrichment)                                       | DataFrames multi-étapes avec extraction de texte basée sur des modèles, jointures et transformations propulsées par LLM, illustrés via l’enrichissement de journaux. |\n| [Meeting Transcript Processing](examples/meeting_transcript_processing) | Analyse native de transcriptions, intégration de schémas Pydantic et agrégations complexes illustrées par l’analyse de réunions.               |\n| [News Analysis](examples/news_analysis)                                 | Analyse et extraction d’informations à partir d’articles de presse à l’aide d’opérateurs sémantiques et de traitement de données structurées.   |\n| [Podcast Summarization](examples/podcast_summarization)                 | Traitement et synthèse de transcriptions de podcasts avec analyse par intervenant et extraction des points clés.                                |\n| [Semantic Join](examples/semantic_joins)                                | Plutôt que de simples appariements approximatifs, utilisez la puissante fonctionnalité de jointure sémantique de fenic pour relier des données entre tables. |\n| [Named Entity Recognition](examples/named_entity_recognition)           | Extraction et classification d’entités nommées à partir de textes grâce à l’extraction et à la classification sémantiques.                     |\n| [Markdown Processing](examples/markdown_processing)                     | Traitement et transformation de documents markdown avec extraction structurée de données et mise en forme.                                      |\n| [JSON Processing](examples/json_processing)                             | Gestion de structures de données JSON complexes avec opérations sémantiques et validation de schéma.                                           |\n| [Feedback Clustering](examples/feedback_clustering)                     | Regroupement et analyse de retours grâce à la similarité sémantique et aux opérations de clustering.                                           |\n| [Document Extraction](examples/document_extraction)                     | Extraction d’informations structurées à partir de divers formats de documents à l’aide d’opérateurs sémantiques.                                |\n\n(N’hésitez pas à cliquer sur n’importe quel exemple ci-dessus pour accéder directement à son dossier.)",
    "Status": "ok"
  },
  {
    "Id": 4,
    "Content": "## Why use fenic?\n\nfenic is an opinionated, PySpark-inspired DataFrame framework for building production AI and agentic applications.\n\nUnlike traditional data tools retrofitted for LLMs, fenic's query engine is built from the ground up with inference in mind.\n\nTransform structured and unstructured data into insights using familiar DataFrame operations enhanced with semantic intelligence. With first-class support for markdown, transcripts, and semantic operators, plus efficient batch inference across any model provider.\n\nfenic brings the reliability of traditional data pipelines to AI workloads.\n\n### Key Features\n\n#### Purpose-Built for LLM Inference\n\n- Query engine designed from scratch for AI workloads, not retrofitted\n- Automatic batch optimization for API calls\n- Built-in retry logic and rate limiting\n- Token counting and cost tracking\n\n#### Semantic Operators as First-Class Citizens",
    "ContentSha": "POPTpr2d3zFT3V0X0/NRjmMCUTjlIPBHtMTVHIRsyfM=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "## Pourquoi utiliser fenic ?\n\nfenic est un framework DataFrame inspiré de PySpark, orienté et structuré, pour la création d'applications d'IA et agentiques en production.\n\nContrairement aux outils de données traditionnels adaptés a posteriori pour les LLM, le moteur de requête de fenic est conçu dès le départ pour l'inférence.\n\nTransformez des données structurées et non structurées en insights grâce à des opérations DataFrame familières, enrichies par l’intelligence sémantique. Profitez d'une prise en charge native du markdown, des transcriptions et des opérateurs sémantiques, ainsi que d'une inférence batch efficace auprès de tout fournisseur de modèle.\n\nfenic apporte la fiabilité des pipelines de données traditionnels aux charges de travail IA.\n\n### Fonctionnalités clés\n\n#### Conçu spécifiquement pour l'inférence LLM\n\n- Moteur de requête conçu de zéro pour les charges de travail IA, non adapté a posteriori\n- Optimisation automatique du batch pour les appels API\n- Logique de réessai intégrée et limitation du débit\n- Comptage des tokens et suivi des coûts\n\n#### Opérateurs sémantiques comme citoyens de première classe",
    "Status": "ok"
  },
  {
    "Id": 5,
    "Content": "\n- `semantic.analyze_sentiment` - Built-in sentiment analysis\n- `semantic.classify` - Categorize text with few-shot examples\n- `semantic.extract` - Transform unstructured text into structured data with schemas\n- `semantic.group_by` - Group data by semantic similarity\n- `semantic.join` - Join DataFrames on meaning, not just values\n- `semantic.map` - Apply natural language transformations\n- `semantic.predicate` - Create predicates using natural language to filter rows\n- `semantic.reduce` - Aggregate grouped data with LLM operations\n\n#### Native Unstructured Data Support\n\nGoes beyond typical multimodal data types (audio, images) by creating specialized types for text-heavy workloads:\n\n- Markdown parsing and extraction as a first-class data type\n- Transcript processing (SRT, generic formats) with speaker and timestamp awareness\n- JSON manipulation with JQ expressions for nested data\n- Automatic text chunking with configurable overlap for long documents\n\n#### Production-Ready Infrastructure",
    "ContentSha": "NE5dPjdhTPxhAD1E+gcEg2tw/wEtQVkEuw1AGA1YwCQ=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "- `semantic.analyze_sentiment` - Analyse de sentiment intégrée\n- `semantic.classify` - Catégoriser le texte avec des exemples few-shot\n- `semantic.extract` - Transformer du texte non structuré en données structurées avec des schémas\n- `semantic.group_by` - Regrouper les données par similarité sémantique\n- `semantic.join` - Joindre des DataFrames sur la signification, pas seulement sur les valeurs\n- `semantic.map` - Appliquer des transformations en langage naturel\n- `semantic.predicate` - Créer des prédicats en utilisant le langage naturel pour filtrer les lignes\n- `semantic.reduce` - Agréger les données groupées avec des opérations LLM\n\n#### Prise en Charge Native des Données Non Structurées\n\nVa au-delà des types de données multimodales classiques (audio, images) en créant des types spécialisés pour des charges de travail principalement textuelles :\n\n- Analyse et extraction du Markdown en tant que type de données de premier ordre\n- Traitement de transcriptions (SRT, formats génériques) avec prise en compte des intervenants et des horodatages\n- Manipulation de JSON avec des expressions JQ pour les données imbriquées\n- Découpage automatique du texte avec recouvrement configurable pour les longs documents\n\n#### Infrastructure Prête pour la Production",
    "Status": "ok"
  },
  {
    "Id": 6,
    "Content": "\n- Multi-provider support (OpenAI, Anthropic, Gemini)\n- Local and cloud execution backends\n- Comprehensive error handling and logging\n- Pydantic integration for type safety\n\n#### Familiar DataFrame API\n\n- PySpark-compatible operations\n- Lazy evaluation and query optimization\n- SQL support for complex queries\n- Seamless integration with existing data pipelines\n\n### Why DataFrames for LLM and Agentic Applications?\n\nAI and agentic applications are fundamentally pipelines and workflows - exactly what DataFrame APIs were designed to handle. Rather than reinventing patterns for data transformation, filtering, and aggregation, fenic leverages decades of proven engineering practices.\n\n#### Decoupled Architecture for Better Agents\n\nfenic creates a clear separation between heavy inference tasks and real-time agent interactions. By moving batch processing out of the agent runtime, you get:\n\n- More predictable and responsive agents\n- Better resource utilization with batched LLM calls\n- Cleaner separation between planning/orchestration and execution\n",
    "ContentSha": "mT0TcKmDXUG4vMCvQ5Zt2Hov+kI1MOWz6tDxxgD3BGY=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "- Prise en charge de plusieurs fournisseurs (OpenAI, Anthropic, Gemini)\n- Backends d'exécution locaux et cloud\n- Gestion complète des erreurs et journalisation\n- Intégration Pydantic pour la sécurité des types\n\n#### API DataFrame familière\n\n- Opérations compatibles PySpark\n- Évaluation paresseuse et optimisation des requêtes\n- Prise en charge SQL pour des requêtes complexes\n- Intégration transparente avec les pipelines de données existants\n\n### Pourquoi utiliser les DataFrames pour les applications LLM et agentiques ?\n\nLes applications d’IA et agentiques sont fondamentalement des pipelines et des flux de travail – exactement ce pour quoi les API DataFrame ont été conçues. Plutôt que de réinventer des modèles pour la transformation, le filtrage et l’agrégation des données, fenic s’appuie sur des décennies de pratiques d’ingénierie éprouvées.\n\n#### Architecture découplée pour de meilleurs agents\n\nfenic crée une séparation claire entre les tâches d’inférence lourdes et les interactions en temps réel des agents. En déplaçant le traitement par lots hors de l’exécution de l’agent, vous obtenez :\n\n- Des agents plus prévisibles et réactifs\n- Une meilleure utilisation des ressources grâce aux appels LLM groupés\n- Une séparation plus nette entre la planification/l’orchestration et l’exécution",
    "Status": "ok"
  },
  {
    "Id": 7,
    "Content": "#### Built for All Engineers\n\nDataFrames aren't just for data practitioners. The fluent, composable API design makes it accessible to any engineer:\n\n- Chain operations naturally: `df.filter(...).semantic.group_by(...)`\n- Mix imperative and declarative styles seamlessly\n- Get started quickly with familiar patterns from pandas/PySpark or SQL\n\n## Support\n\nJoin our community on [Discord](https://discord.gg/GdqF3J7huR) where you can connect with other users, ask questions, and get help with your fenic projects. Our community is always happy to welcome newcomers!\n\nIf you find fenic useful, consider giving us a ⭐ at the top of this repository. Your support helps us grow and improve the framework for everyone!\n\n## Contributing\n\nWe welcome contributions of all kinds! Whether you're interested in writing code, improving documentation, testing features, or proposing new ideas, your help is valuable to us.\n\nFor developers planning to submit code changes, we encourage you to first open an issue to discuss your ideas before creating a Pull Request. This helps ensure alignment with the project's direction and prevents duplicate efforts.\n\nPlease refer to our [contribution guidelines](https://raw.githubusercontent.com/typedef-ai/fenic/main/CONTRIBUTING.md) for detailed information about the development process and project setup.\n",
    "ContentSha": "uskg5roWGwsGUjyK072Ea16WzdZZykGudJVeAy5e46I=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "#### Conçu pour tous les ingénieurs\n\nLes DataFrames ne sont pas réservés qu’aux spécialistes des données. La conception de l’API, fluide et composable, la rend accessible à tout ingénieur :\n\n- Enchaînez les opérations naturellement : `df.filter(...).semantic.group_by(...)`\n- Mélangez styles impératif et déclaratif sans effort\n- Démarrez rapidement grâce à des schémas familiers de pandas/PySpark ou SQL\n\n## Support\n\nRejoignez notre communauté sur [Discord](https://discord.gg/GdqF3J7huR) où vous pouvez échanger avec d'autres utilisateurs, poser des questions et obtenir de l'aide pour vos projets fenic. Notre communauté est toujours ravie d’accueillir de nouveaux membres !\n\nSi vous trouvez fenic utile, pensez à nous laisser une ⭐ en haut de ce dépôt. Votre soutien nous aide à faire grandir et améliorer le framework pour tous !\n\n## Contribution\n\nNous accueillons toutes sortes de contributions ! Que vous souhaitiez écrire du code, améliorer la documentation, tester des fonctionnalités ou proposer de nouvelles idées, votre aide nous est précieuse.\n\nPour les développeurs envisageant de soumettre des modifications de code, nous vous encourageons à ouvrir d’abord une issue pour discuter de vos idées avant de créer une Pull Request. Cela permet de garantir l’alignement avec l’orientation du projet et d’éviter les efforts en double.\n\nVeuillez consulter notre [guide de contribution](https://raw.githubusercontent.com/typedef-ai/fenic/main/CONTRIBUTING.md) pour des informations détaillées sur le processus de développement et la mise en place du projet.",
    "Status": "ok"
  }
]