[
  {
    "Id": 1,
    "Content": "<!-- markdownlint-disable MD041 MD033 -->\n<div align=\"center\">\n    <picture>\n        <source media=\"(prefers-color-scheme: dark)\" srcset=\"docs/images/typedef-fenic-logo-dark.png\">\n        <img src=\"https://raw.githubusercontent.com/typedef-ai/fenic/main/docs/images/typedef-fenic-logo.png\" alt=\"fenic, by typedef\" width=\"90%\">\n    </picture>\n</div>\n\n# fenic: the dataframe (re)built for LLM inference\n\n[![PyPI version](https://img.shields.io/pypi/v/fenic.svg)](https://pypi.org/project/fenic/)\n[![Python versions](https://img.shields.io/pypi/pyversions/fenic.svg)](https://pypi.org/project/fenic/)\n[![License](https://img.shields.io/github/license/typedef-ai/fenic.svg)](https://github.com/typedef-ai/fenic/blob/main/LICENSE)\n[![Discord](https://img.shields.io/discord/1381706122322513952?label=Discord&logo=discord)](https://discord.gg/GdqF3J7huR)\n\n---\n\n## **Documentation**: [docs.fenic.ai](https://docs.fenic.ai/)\n\nfenic is an opinionated, PySpark-inspired DataFrame framework from typedef.ai for building AI and agentic applications. Transform unstructured and structured data into insights using familiar DataFrame operations enhanced with semantic intelligence. With first-class support for markdown, transcripts, and semantic operators, plus efficient batch inference across any model provider.\n",
    "ContentSha": "tmub1AxUb0Y4Al5Ltz67crbP453GMVUntyWUISmU7NQ=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "<!-- markdownlint-disable MD041 MD033 -->\n<div align=\"center\">\n    <picture>\n        <source media=\"(prefers-color-scheme: dark)\" srcset=\"docs/images/typedef-fenic-logo-dark.png\">\n        <img src=\"https://raw.githubusercontent.com/typedef-ai/fenic/main/docs/images/typedef-fenic-logo.png\" alt=\"fenic, by typedef\" width=\"90%\">\n    </picture>\n</div>\n\n# fenic: DataFrame, (пере)созданный для вывода LLM\n\n[![PyPI version](https://img.shields.io/pypi/v/fenic.svg)](https://pypi.org/project/fenic/)\n[![Python versions](https://img.shields.io/pypi/pyversions/fenic.svg)](https://pypi.org/project/fenic/)\n[![License](https://img.shields.io/github/license/typedef-ai/fenic.svg)](https://github.com/typedef-ai/fenic/blob/main/LICENSE)\n[![Discord](https://img.shields.io/discord/1381706122322513952?label=Discord&logo=discord)](https://discord.gg/GdqF3J7huR)\n\n---\n\n## **Документация**: [docs.fenic.ai](https://docs.fenic.ai/)\n\nfenic — это структурированный, вдохновленный PySpark фреймворк DataFrame от typedef.ai для создания AI и агентных приложений. Преобразуйте неструктурированные и структурированные данные в инсайты с помощью знакомых операций DataFrame, расширенных семантическим интеллектом. С поддержкой markdown, транскриптов и семантических операторов на высоком уровне, а также с эффективным пакетным выводом на любых провайдерах моделей.",
    "Status": "ok"
  },
  {
    "Id": 2,
    "Content": "## Install\n\nfenic supports Python `[3.10, 3.11, 3.12]`\n\n```bash\npip install fenic\n```\n\n### LLM Provider Setup\n\nfenic requires an API key from at least one LLM provider. Set the appropriate environment variable for your chosen provider:\n\n```bash\n# For OpenAI\nexport OPENAI_API_KEY=\"your-openai-api-key\"\n\n# For Anthropic\nexport ANTHROPIC_API_KEY=\"your-anthropic-api-key\"\n\n# For Google",
    "ContentSha": "QT2GWoHGnyfwnJxlfZAk0I5rpIsEfvGEhJD38oz6lCY=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "## Установка\n\nfenic поддерживает Python `[3.10, 3.11, 3.12]`\n\n```bash\npip install fenic\n```\n\n### Настройка провайдера LLM\n\nfenic требует API-ключ хотя бы от одного провайдера LLM. Установите соответствующую переменную окружения для выбранного вами провайдера:\n\n```bash\n# Для OpenAI\nexport OPENAI_API_KEY=\"your-openai-api-key\"\n\n# Для Anthropic\nexport ANTHROPIC_API_KEY=\"your-anthropic-api-key\"\n\n# Для Google",
    "Status": "ok"
  },
  {
    "Id": 3,
    "Content": "export GEMINI_API_KEY=\"your-google-api-key\"\n```\n\n## Quickstart\n\nThe fastest way to learn about fenic is by checking the examples.\n\nBelow is a quick list of the examples in this repo:\n\n| Example                                                                 | Description                                                                                                                         |\n| ----------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------- |\n| [Hello World!](examples/hello_world)                                    | Introduction to semantic extraction and classification using fenic's core operators through error log analysis.                     |\n| [Enrichment](examples/enrichment)                                       | Multi-stage DataFrames with template-based text extraction, joins, and LLM-powered transformations demonstrated via log enrichment. |\n| [Meeting Transcript Processing](examples/meeting_transcript_processing) | Native transcript parsing, Pydantic schema integration, and complex aggregations shown through meeting analysis.                    |\n| [News Analysis](examples/news_analysis)                                 | Analyze and extract insights from news articles using semantic operators and structured data processing.                            |\n| [Podcast Summarization](examples/podcast_summarization)                 | Process and summarize podcast transcripts with speaker-aware analysis and key point extraction.                                     |\n| [Semantic Join](examples/semantic_joins)                                | Instead of simple fuzzy matching, use fenic's powerful semantic join functionality to match data across tables.                     |\n| [Named Entity Recognition](examples/named_entity_recognition)           | Extract and classify named entities from text using semantic extraction and classification.                                         |\n| [Markdown Processing](examples/markdown_processing)                     | Process and transform markdown documents with structured data extraction and formatting.                                            |\n| [JSON Processing](examples/json_processing)                             | Handle complex JSON data structures with semantic operations and schema validation.                                                 |\n| [Feedback Clustering](examples/feedback_clustering)                     | Group and analyze feedback using semantic similarity and clustering operations.                                                     |\n| [Document Extraction](examples/document_extraction)                     | Extract structured information from various document formats using semantic operators.                                              |\n\n(Feel free to click any example above to jump right to its folder.)\n",
    "ContentSha": "RBvJ+qAaDZODC8rvu1sFp9QTE4SUhSKTTu/91HAxBRc=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\nexport GEMINI_API_KEY=\"your-google-api-key\"\n```\n\n## Быстрый старт\n\nСамый быстрый способ узнать о fenic — изучить примеры.\n\nНиже приведён краткий список примеров из этого репозитория:\n\n| Пример                                                                  | Описание                                                                                                                           |\n| ----------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------- |\n| [Hello World!](examples/hello_world)                                    | Введение в семантическое извлечение и классификацию с использованием основных операторов fenic на примере анализа журналов ошибок. |\n| [Enrichment](examples/enrichment)                                       | Многоступенчатые DataFrame с извлечением текста по шаблону, объединениями и преобразованиями на базе LLM, показанными на обогащении логов. |\n| [Обработка транскриптов встреч](examples/meeting_transcript_processing) | Парсинг транскриптов, интеграция схем Pydantic и сложная агрегация на примере анализа совещаний.                                   |\n| [Анализ новостей](examples/news_analysis)                               | Анализ и извлечение инсайтов из новостных статей с помощью семантических операторов и структурированной обработки данных.         |\n| [Суммаризация подкастов](examples/podcast_summarization)                | Обработка и суммаризация транскриптов подкастов с учётом спикеров и выделением ключевых моментов.                                 |\n| [Семантическое объединение](examples/semantic_joins)                    | Вместо простого нечеткого сопоставления используйте мощную функцию семантического объединения fenic для сопоставления данных между таблицами. |\n| [Распознавание именованных сущностей](examples/named_entity_recognition) | Извлечение и классификация именованных сущностей из текста с помощью семантического извлечения и классификации.                   |\n| [Обработка Markdown](examples/markdown_processing)                      | Обработка и преобразование markdown-документов с помощью структурированного извлечения данных и форматирования.                   |\n| [Обработка JSON](examples/json_processing)                              | Работа со сложными структурами данных JSON с помощью семантических операций и валидации схем.                                     |\n| [Кластеризация обратной связи](examples/feedback_clustering)            | Группировка и анализ отзывов с помощью семантического сходства и операций кластеризации.                                          |\n| [Извлечение из документов](examples/document_extraction)                | Извлечение структурированной информации из различных форматов документов с помощью семантических операторов.                      |\n\n(Вы можете кликнуть на любой пример выше, чтобы перейти прямо в соответствующую папку.)\n",
    "Status": "ok"
  },
  {
    "Id": 4,
    "Content": "## Why use fenic?\n\nfenic is an opinionated, PySpark-inspired DataFrame framework for building production AI and agentic applications.\n\nUnlike traditional data tools retrofitted for LLMs, fenic's query engine is built from the ground up with inference in mind.\n\nTransform structured and unstructured data into insights using familiar DataFrame operations enhanced with semantic intelligence. With first-class support for markdown, transcripts, and semantic operators, plus efficient batch inference across any model provider.\n\nfenic brings the reliability of traditional data pipelines to AI workloads.\n\n### Key Features\n\n#### Purpose-Built for LLM Inference\n\n- Query engine designed from scratch for AI workloads, not retrofitted\n- Automatic batch optimization for API calls\n- Built-in retry logic and rate limiting\n- Token counting and cost tracking\n\n#### Semantic Operators as First-Class Citizens",
    "ContentSha": "POPTpr2d3zFT3V0X0/NRjmMCUTjlIPBHtMTVHIRsyfM=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "## Почему стоит использовать fenic?\n\nfenic — это продвинутая фреймворк DataFrame, вдохновлённая PySpark, для построения производственных AI и агентных приложений.\n\nВ отличие от традиционных инструментов работы с данными, доработанных для LLM, движок запросов fenic создан с нуля с учётом инференса.\n\nПреобразуйте структурированные и неструктурированные данные в инсайты, используя привычные DataFrame-операции, усиленные семантическим интеллектом. Поддержка markdown, транскриптов и семантических операторов на уровне ядра, а также эффективный пакетный инференс для любого провайдера моделей.\n\nfenic приносит надёжность традиционных дата-пайплайнов в AI-нагрузки.\n\n### Ключевые особенности\n\n#### Специально создан для инференса LLM\n\n- Движок запросов спроектирован с нуля для AI-нагрузок, а не доработан\n- Автоматическая пакетная оптимизация для API-вызовов\n- Встроенная логика повторных попыток и ограничения скорости\n- Подсчёт токенов и отслеживание стоимости\n\n#### Семантические операторы как объекты первого класса",
    "Status": "ok"
  },
  {
    "Id": 5,
    "Content": "\n- `semantic.analyze_sentiment` - Built-in sentiment analysis\n- `semantic.classify` - Categorize text with few-shot examples\n- `semantic.extract` - Transform unstructured text into structured data with schemas\n- `semantic.group_by` - Group data by semantic similarity\n- `semantic.join` - Join DataFrames on meaning, not just values\n- `semantic.map` - Apply natural language transformations\n- `semantic.predicate` - Create predicates using natural language to filter rows\n- `semantic.reduce` - Aggregate grouped data with LLM operations\n\n#### Native Unstructured Data Support\n\nGoes beyond typical multimodal data types (audio, images) by creating specialized types for text-heavy workloads:\n\n- Markdown parsing and extraction as a first-class data type\n- Transcript processing (SRT, generic formats) with speaker and timestamp awareness\n- JSON manipulation with JQ expressions for nested data\n- Automatic text chunking with configurable overlap for long documents\n\n#### Production-Ready Infrastructure",
    "ContentSha": "NE5dPjdhTPxhAD1E+gcEg2tw/wEtQVkEuw1AGA1YwCQ=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "- `semantic.analyze_sentiment` — Встроенный анализ настроений\n- `semantic.classify` — Категоризация текста с помощью few-shot примеров\n- `semantic.extract` — Преобразование неструктурированного текста в структурированные данные с помощью схем\n- `semantic.group_by` — Группировка данных по семантическому сходству\n- `semantic.join` — Объединение DataFrame по смыслу, а не только по значениям\n- `semantic.map` — Применение преобразований на естественном языке\n- `semantic.predicate` — Создание предикатов на естественном языке для фильтрации строк\n- `semantic.reduce` — Агрегация сгруппированных данных с помощью LLM-операций\n\n#### Родная поддержка неструктурированных данных\n\nВыходит за рамки типичных мультимодальных типов данных (аудио, изображения), создавая специализированные типы для задач с большим объемом текста:\n\n- Парсинг и извлечение Markdown как полноценного типа данных\n- Обработка транскриптов (SRT, общие форматы) с учетом спикеров и временных меток\n- Манипулирование JSON с помощью выражений JQ для вложенных данных\n- Автоматическая нарезка текста на фрагменты с настраиваемым перекрытием для длинных документов\n\n#### Готовая к промышленной эксплуатации инфраструктура",
    "Status": "ok"
  },
  {
    "Id": 6,
    "Content": "\n- Multi-provider support (OpenAI, Anthropic, Gemini)\n- Local and cloud execution backends\n- Comprehensive error handling and logging\n- Pydantic integration for type safety\n\n#### Familiar DataFrame API\n\n- PySpark-compatible operations\n- Lazy evaluation and query optimization\n- SQL support for complex queries\n- Seamless integration with existing data pipelines\n\n### Why DataFrames for LLM and Agentic Applications?\n\nAI and agentic applications are fundamentally pipelines and workflows - exactly what DataFrame APIs were designed to handle. Rather than reinventing patterns for data transformation, filtering, and aggregation, fenic leverages decades of proven engineering practices.\n\n#### Decoupled Architecture for Better Agents\n\nfenic creates a clear separation between heavy inference tasks and real-time agent interactions. By moving batch processing out of the agent runtime, you get:\n\n- More predictable and responsive agents\n- Better resource utilization with batched LLM calls\n- Cleaner separation between planning/orchestration and execution\n",
    "ContentSha": "mT0TcKmDXUG4vMCvQ5Zt2Hov+kI1MOWz6tDxxgD3BGY=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "- Поддержка нескольких провайдеров (OpenAI, Anthropic, Gemini)\n- Локальные и облачные бэкенды выполнения\n- Всесторонняя обработка ошибок и ведение логов\n- Интеграция с Pydantic для типобезопасности\n\n#### Привычный API DataFrame\n\n- Операции, совместимые с PySpark\n- Ленивые вычисления и оптимизация запросов\n- Поддержка SQL для сложных запросов\n- Бесшовная интеграция с существующими пайплайнами данных\n\n### Почему DataFrame для LLM и агентных приложений?\n\nИИ и агентные приложения по своей сути являются пайплайнами и рабочими процессами — именно для этого и были созданы API DataFrame. Вместо изобретения новых паттернов для трансформации данных, фильтрации и агрегации, fenic использует десятилетия проверенных инженерных практик.\n\n#### Разделённая архитектура для лучших агентов\n\nfenic создаёт чёткое разделение между ресурсоёмкими задачами инференса и интерактивными действиями агентов в реальном времени. Перемещая пакетную обработку за пределы времени выполнения агента, вы получаете:\n\n- Более предсказуемых и отзывчивых агентов\n- Лучшее использование ресурсов при пакетных вызовах LLM\n- Более чёткое разделение между планированием/оркестрацией и выполнением",
    "Status": "ok"
  },
  {
    "Id": 7,
    "Content": "#### Built for All Engineers\n\nDataFrames aren't just for data practitioners. The fluent, composable API design makes it accessible to any engineer:\n\n- Chain operations naturally: `df.filter(...).semantic.group_by(...)`\n- Mix imperative and declarative styles seamlessly\n- Get started quickly with familiar patterns from pandas/PySpark or SQL\n\n## Support\n\nJoin our community on [Discord](https://discord.gg/GdqF3J7huR) where you can connect with other users, ask questions, and get help with your fenic projects. Our community is always happy to welcome newcomers!\n\nIf you find fenic useful, consider giving us a ⭐ at the top of this repository. Your support helps us grow and improve the framework for everyone!\n\n## Contributing\n\nWe welcome contributions of all kinds! Whether you're interested in writing code, improving documentation, testing features, or proposing new ideas, your help is valuable to us.\n\nFor developers planning to submit code changes, we encourage you to first open an issue to discuss your ideas before creating a Pull Request. This helps ensure alignment with the project's direction and prevents duplicate efforts.\n\nPlease refer to our [contribution guidelines](https://raw.githubusercontent.com/typedef-ai/fenic/main/CONTRIBUTING.md) for detailed information about the development process and project setup.\n",
    "ContentSha": "uskg5roWGwsGUjyK072Ea16WzdZZykGudJVeAy5e46I=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "#### Создан для всех инженеров\n\nDataFrames предназначены не только для специалистов по данным. Гибкий и составной дизайн API делает его доступным для любого инженера:\n\n- Естественное связывание операций: `df.filter(...).semantic.group_by(...)`\n- Легкое сочетание императивного и декларативного стилей\n- Быстрый старт с использованием знакомых паттернов из pandas/PySpark или SQL\n\n## Поддержка\n\nПрисоединяйтесь к нашему сообществу на [Discord](https://discord.gg/GdqF3J7huR), где вы можете пообщаться с другими пользователями, задать вопросы и получить помощь по вашим проектам на fenic. Наше сообщество всегда с радостью принимает новых участников!\n\nЕсли вы находите fenic полезным, пожалуйста, поставьте нам ⭐ в верхней части этого репозитория. Ваша поддержка помогает нам развивать и совершенствовать фреймворк для всех!\n\n## Вклад\n\nМы приветствуем любые виды вкладов! Будь то написание кода, улучшение документации, тестирование функций или предложение новых идей — ваша помощь для нас очень ценна.\n\nРазработчикам, планирующим отправлять изменения в коде, мы рекомендуем сначала открыть issue для обсуждения своих идей перед созданием Pull Request. Это помогает обеспечить согласованность с направлением проекта и избежать дублирования усилий.\n\nПожалуйста, ознакомьтесь с нашими [руководством по вкладу](https://raw.githubusercontent.com/typedef-ai/fenic/main/CONTRIBUTING.md) для подробной информации о процессе разработки и настройке проекта.",
    "Status": "ok"
  }
]