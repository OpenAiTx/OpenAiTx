[
  {
    "Id": 1,
    "Content": "<!-- markdownlint-disable MD041 MD033 -->\n<div align=\"center\">\n    <picture>\n        <source media=\"(prefers-color-scheme: dark)\" srcset=\"docs/images/typedef-fenic-logo-dark.png\">\n        <img src=\"https://raw.githubusercontent.com/typedef-ai/fenic/main/docs/images/typedef-fenic-logo.png\" alt=\"fenic, by typedef\" width=\"90%\">\n    </picture>\n</div>\n\n# fenic: the dataframe (re)built for LLM inference\n\n[![PyPI version](https://img.shields.io/pypi/v/fenic.svg)](https://pypi.org/project/fenic/)\n[![Python versions](https://img.shields.io/pypi/pyversions/fenic.svg)](https://pypi.org/project/fenic/)\n[![License](https://img.shields.io/github/license/typedef-ai/fenic.svg)](https://github.com/typedef-ai/fenic/blob/main/LICENSE)\n[![Discord](https://img.shields.io/discord/1381706122322513952?label=Discord&logo=discord)](https://discord.gg/GdqF3J7huR)\n\n---\n\n## **Documentation**: [docs.fenic.ai](https://docs.fenic.ai/)\n\nfenic is an opinionated, PySpark-inspired DataFrame framework from typedef.ai for building AI and agentic applications. Transform unstructured and structured data into insights using familiar DataFrame operations enhanced with semantic intelligence. With first-class support for markdown, transcripts, and semantic operators, plus efficient batch inference across any model provider.\n",
    "ContentSha": "tmub1AxUb0Y4Al5Ltz67crbP453GMVUntyWUISmU7NQ=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "<!-- markdownlint-disable MD041 MD033 -->\n<div align=\"center\">\n    <picture>\n        <source media=\"(prefers-color-scheme: dark)\" srcset=\"docs/images/typedef-fenic-logo-dark.png\">\n        <img src=\"https://raw.githubusercontent.com/typedef-ai/fenic/main/docs/images/typedef-fenic-logo.png\" alt=\"fenic, door typedef\" width=\"90%\">\n    </picture>\n</div>\n\n# fenic: de dataframe (opnieuw) gebouwd voor LLM-inferentie\n\n[![PyPI versie](https://img.shields.io/pypi/v/fenic.svg)](https://pypi.org/project/fenic/)\n[![Python versies](https://img.shields.io/pypi/pyversions/fenic.svg)](https://pypi.org/project/fenic/)\n[![Licentie](https://img.shields.io/github/license/typedef-ai/fenic.svg)](https://github.com/typedef-ai/fenic/blob/main/LICENSE)\n[![Discord](https://img.shields.io/discord/1381706122322513952?label=Discord&logo=discord)](https://discord.gg/GdqF3J7huR)\n\n---\n\n## **Documentatie**: [docs.fenic.ai](https://docs.fenic.ai/)\n\nfenic is een eigenzinnig, door PySpark geïnspireerd DataFrame-framework van typedef.ai voor het bouwen van AI- en agent-applicaties. Transformeer ongestructureerde en gestructureerde data naar inzichten met behulp van vertrouwde DataFrame-bewerkingen, verrijkt met semantische intelligentie. Met eersteklas ondersteuning voor markdown, transcripties en semantische operatoren, plus efficiënte batch-inferentie over elke modelprovider.",
    "Status": "ok"
  },
  {
    "Id": 2,
    "Content": "## Install\n\nfenic supports Python `[3.10, 3.11, 3.12]`\n\n```bash\npip install fenic\n```\n\n### LLM Provider Setup\n\nfenic requires an API key from at least one LLM provider. Set the appropriate environment variable for your chosen provider:\n\n```bash\n# For OpenAI\nexport OPENAI_API_KEY=\"your-openai-api-key\"\n\n# For Anthropic\nexport ANTHROPIC_API_KEY=\"your-anthropic-api-key\"\n\n# For Google",
    "ContentSha": "QT2GWoHGnyfwnJxlfZAk0I5rpIsEfvGEhJD38oz6lCY=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "## Installeren\n\nfenic ondersteunt Python `[3.10, 3.11, 3.12]`\n\n```bash\npip install fenic\n```\n\n### LLM Provider Setup\n\nfenic vereist een API-sleutel van ten minste één LLM-provider. Stel de juiste omgevingsvariabele in voor de door jou gekozen provider:\n\n```bash\n# Voor OpenAI\nexport OPENAI_API_KEY=\"jouw-openai-api-sleutel\"\n\n# Voor Anthropic\nexport ANTHROPIC_API_KEY=\"jouw-anthropic-api-sleutel\"\n\n# Voor Google",
    "Status": "ok"
  },
  {
    "Id": 3,
    "Content": "export GEMINI_API_KEY=\"your-google-api-key\"\n```\n\n## Quickstart\n\nThe fastest way to learn about fenic is by checking the examples.\n\nBelow is a quick list of the examples in this repo:\n\n| Example                                                                 | Description                                                                                                                         |\n| ----------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------- |\n| [Hello World!](examples/hello_world)                                    | Introduction to semantic extraction and classification using fenic's core operators through error log analysis.                     |\n| [Enrichment](examples/enrichment)                                       | Multi-stage DataFrames with template-based text extraction, joins, and LLM-powered transformations demonstrated via log enrichment. |\n| [Meeting Transcript Processing](examples/meeting_transcript_processing) | Native transcript parsing, Pydantic schema integration, and complex aggregations shown through meeting analysis.                    |\n| [News Analysis](examples/news_analysis)                                 | Analyze and extract insights from news articles using semantic operators and structured data processing.                            |\n| [Podcast Summarization](examples/podcast_summarization)                 | Process and summarize podcast transcripts with speaker-aware analysis and key point extraction.                                     |\n| [Semantic Join](examples/semantic_joins)                                | Instead of simple fuzzy matching, use fenic's powerful semantic join functionality to match data across tables.                     |\n| [Named Entity Recognition](examples/named_entity_recognition)           | Extract and classify named entities from text using semantic extraction and classification.                                         |\n| [Markdown Processing](examples/markdown_processing)                     | Process and transform markdown documents with structured data extraction and formatting.                                            |\n| [JSON Processing](examples/json_processing)                             | Handle complex JSON data structures with semantic operations and schema validation.                                                 |\n| [Feedback Clustering](examples/feedback_clustering)                     | Group and analyze feedback using semantic similarity and clustering operations.                                                     |\n| [Document Extraction](examples/document_extraction)                     | Extract structured information from various document formats using semantic operators.                                              |\n\n(Feel free to click any example above to jump right to its folder.)\n",
    "ContentSha": "RBvJ+qAaDZODC8rvu1sFp9QTE4SUhSKTTu/91HAxBRc=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "export GEMINI_API_KEY=\"your-google-api-key\"\n```\n\n## Snelstart\n\nDe snelste manier om kennis te maken met fenic is door de voorbeelden te bekijken.\n\nHieronder staat een korte lijst van de voorbeelden in deze repo:\n\n| Voorbeeld                                                                | Beschrijving                                                                                                                        |\n| ------------------------------------------------------------------------ | ----------------------------------------------------------------------------------------------------------------------------------- |\n| [Hello World!](examples/hello_world)                                     | Introductie tot semantische extractie en classificatie met behulp van fenic's kernoperatoren via analyse van foutlogboeken.         |\n| [Verrijking](examples/enrichment)                                        | Meerstaps-DataFrames met template-gebaseerde tekstanalyse, joins en LLM-aangedreven transformaties gedemonstreerd via logverrijking.|\n| [Vergadertranscript Verwerking](examples/meeting_transcript_processing)  | Native transcript parsing, Pydantic schema-integratie en complexe aggregaties getoond via vergaderanalyse.                         |\n| [Nieuws Analyse](examples/news_analysis)                                 | Analyseer en extraheer inzichten uit nieuwsartikelen met behulp van semantische operatoren en gestructureerde dataverwerking.       |\n| [Podcast Samenvatting](examples/podcast_summarization)                   | Verwerk en vat podcasttranscripten samen met spreker-bewuste analyse en extractie van kernpunten.                                  |\n| [Semantische Join](examples/semantic_joins)                              | Gebruik in plaats van eenvoudige fuzzy matching de krachtige semantische join-functionaliteit van fenic om data tussen tabellen te koppelen. |\n| [Naam Entiteit Herkenning](examples/named_entity_recognition)            | Extraheer en classificeer naam-entiteiten uit tekst met behulp van semantische extractie en classificatie.                         |\n| [Markdown Verwerking](examples/markdown_processing)                      | Verwerk en transformeer markdown-documenten met gestructureerde data-extractie en opmaak.                                          |\n| [JSON Verwerking](examples/json_processing)                              | Behandel complexe JSON-datastructuren met semantische operaties en schema-validatie.                                               |\n| [Feedback Clustering](examples/feedback_clustering)                      | Groepeer en analyseer feedback met behulp van semantische gelijkenis en clustering-operaties.                                      |\n| [Document Extractie](examples/document_extraction)                       | Extraheer gestructureerde informatie uit verschillende documentformaten met behulp van semantische operatoren.                     |\n\n(Voel je vrij om op een van de bovenstaande voorbeelden te klikken om direct naar de bijbehorende map te gaan.)\n",
    "Status": "ok"
  },
  {
    "Id": 4,
    "Content": "## Why use fenic?\n\nfenic is an opinionated, PySpark-inspired DataFrame framework for building production AI and agentic applications.\n\nUnlike traditional data tools retrofitted for LLMs, fenic's query engine is built from the ground up with inference in mind.\n\nTransform structured and unstructured data into insights using familiar DataFrame operations enhanced with semantic intelligence. With first-class support for markdown, transcripts, and semantic operators, plus efficient batch inference across any model provider.\n\nfenic brings the reliability of traditional data pipelines to AI workloads.\n\n### Key Features\n\n#### Purpose-Built for LLM Inference\n\n- Query engine designed from scratch for AI workloads, not retrofitted\n- Automatic batch optimization for API calls\n- Built-in retry logic and rate limiting\n- Token counting and cost tracking\n\n#### Semantic Operators as First-Class Citizens",
    "ContentSha": "POPTpr2d3zFT3V0X0/NRjmMCUTjlIPBHtMTVHIRsyfM=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "## Waarom fenic gebruiken?\n\nfenic is een eigenzinnig, door PySpark geïnspireerd DataFrame-framework voor het bouwen van productieklare AI- en agenttoepassingen.\n\nIn tegenstelling tot traditionele datatools die zijn aangepast voor LLM's, is de query-engine van fenic vanaf de basis ontworpen met inferentie in gedachten.\n\nTransformeer gestructureerde en ongestructureerde data naar inzichten met behulp van vertrouwde DataFrame-operaties, uitgebreid met semantische intelligentie. Met eersteklas ondersteuning voor markdown, transcripties en semantische operatoren, plus efficiënte batch-inferentie via elke modelprovider.\n\nfenic brengt de betrouwbaarheid van traditionele datapijplijnen naar AI-workloads.\n\n### Belangrijkste kenmerken\n\n#### Speciaal ontwikkeld voor LLM-inferentie\n\n- Query-engine vanaf nul ontworpen voor AI-workloads, niet aangepast\n- Automatische batchoptimalisatie voor API-calls\n- Ingebouwde retry-logica en snelheidsbeperking\n- Token-telling en kostenregistratie\n\n#### Semantische operatoren als volwaardige elementen",
    "Status": "ok"
  },
  {
    "Id": 5,
    "Content": "\n- `semantic.analyze_sentiment` - Built-in sentiment analysis\n- `semantic.classify` - Categorize text with few-shot examples\n- `semantic.extract` - Transform unstructured text into structured data with schemas\n- `semantic.group_by` - Group data by semantic similarity\n- `semantic.join` - Join DataFrames on meaning, not just values\n- `semantic.map` - Apply natural language transformations\n- `semantic.predicate` - Create predicates using natural language to filter rows\n- `semantic.reduce` - Aggregate grouped data with LLM operations\n\n#### Native Unstructured Data Support\n\nGoes beyond typical multimodal data types (audio, images) by creating specialized types for text-heavy workloads:\n\n- Markdown parsing and extraction as a first-class data type\n- Transcript processing (SRT, generic formats) with speaker and timestamp awareness\n- JSON manipulation with JQ expressions for nested data\n- Automatic text chunking with configurable overlap for long documents\n\n#### Production-Ready Infrastructure",
    "ContentSha": "NE5dPjdhTPxhAD1E+gcEg2tw/wEtQVkEuw1AGA1YwCQ=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "- `semantic.analyze_sentiment` - Ingebouwde sentimentanalyse\n- `semantic.classify` - Categoriseer tekst met few-shot voorbeelden\n- `semantic.extract` - Zet ongestructureerde tekst om in gestructureerde data met schema's\n- `semantic.group_by` - Groepeer data op semantische gelijkenis\n- `semantic.join` - Voeg DataFrames samen op basis van betekenis, niet alleen waarden\n- `semantic.map` - Pas natuurlijke taaltransformaties toe\n- `semantic.predicate` - Maak predicaten met natuurlijke taal om rijen te filteren\n- `semantic.reduce` - Aggregeer gegroepeerde data met LLM-operaties\n\n#### Native Ondersteuning voor Ongestructureerde Data\n\nGaat verder dan typische multimodale datatypes (audio, afbeeldingen) door gespecialiseerde types te creëren voor tekstintensieve workloads:\n\n- Markdown-parsing en extractie als een eersteklas datatype\n- Transcriptverwerking (SRT, generieke formaten) met bewustzijn van spreker en tijdstempel\n- JSON-manipulatie met JQ-expressies voor geneste data\n- Automatische tekstchunking met configureerbare overlap voor lange documenten\n\n#### Productierijpe Infrastructuur",
    "Status": "ok"
  },
  {
    "Id": 6,
    "Content": "\n- Multi-provider support (OpenAI, Anthropic, Gemini)\n- Local and cloud execution backends\n- Comprehensive error handling and logging\n- Pydantic integration for type safety\n\n#### Familiar DataFrame API\n\n- PySpark-compatible operations\n- Lazy evaluation and query optimization\n- SQL support for complex queries\n- Seamless integration with existing data pipelines\n\n### Why DataFrames for LLM and Agentic Applications?\n\nAI and agentic applications are fundamentally pipelines and workflows - exactly what DataFrame APIs were designed to handle. Rather than reinventing patterns for data transformation, filtering, and aggregation, fenic leverages decades of proven engineering practices.\n\n#### Decoupled Architecture for Better Agents\n\nfenic creates a clear separation between heavy inference tasks and real-time agent interactions. By moving batch processing out of the agent runtime, you get:\n\n- More predictable and responsive agents\n- Better resource utilization with batched LLM calls\n- Cleaner separation between planning/orchestration and execution\n",
    "ContentSha": "mT0TcKmDXUG4vMCvQ5Zt2Hov+kI1MOWz6tDxxgD3BGY=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "- Ondersteuning voor meerdere providers (OpenAI, Anthropic, Gemini)\n- Lokale en cloud uitvoeringsbackends\n- Uitgebreide foutafhandeling en logging\n- Pydantic-integratie voor typeveiligheid\n\n#### Vertrouwde DataFrame API\n\n- PySpark-compatibele bewerkingen\n- Lui evalueren en query-optimalisatie\n- SQL-ondersteuning voor complexe queries\n- Naadloze integratie met bestaande datastromen\n\n### Waarom DataFrames voor LLM- en Agent-toepassingen?\n\nAI- en agent-toepassingen zijn in wezen pipelines en workflows – precies waarvoor DataFrame-API’s zijn ontworpen. In plaats van patronen voor datatransformatie, filtering en aggregatie opnieuw uit te vinden, maakt fenic gebruik van decennia aan bewezen technische praktijken.\n\n#### Losgekoppelde Architectuur voor Betere Agents\n\nfenic creëert een duidelijke scheiding tussen zware inferentietaken en realtime agentinteracties. Door batchverwerking uit de agent-runtime te halen, krijg je:\n\n- Meer voorspelbare en responsieve agents\n- Betere resourcebenutting met gebatchte LLM-calls\n- Duidelijkere scheiding tussen planning/orchestratie en uitvoering",
    "Status": "ok"
  },
  {
    "Id": 7,
    "Content": "#### Built for All Engineers\n\nDataFrames aren't just for data practitioners. The fluent, composable API design makes it accessible to any engineer:\n\n- Chain operations naturally: `df.filter(...).semantic.group_by(...)`\n- Mix imperative and declarative styles seamlessly\n- Get started quickly with familiar patterns from pandas/PySpark or SQL\n\n## Support\n\nJoin our community on [Discord](https://discord.gg/GdqF3J7huR) where you can connect with other users, ask questions, and get help with your fenic projects. Our community is always happy to welcome newcomers!\n\nIf you find fenic useful, consider giving us a ⭐ at the top of this repository. Your support helps us grow and improve the framework for everyone!\n\n## Contributing\n\nWe welcome contributions of all kinds! Whether you're interested in writing code, improving documentation, testing features, or proposing new ideas, your help is valuable to us.\n\nFor developers planning to submit code changes, we encourage you to first open an issue to discuss your ideas before creating a Pull Request. This helps ensure alignment with the project's direction and prevents duplicate efforts.\n\nPlease refer to our [contribution guidelines](https://raw.githubusercontent.com/typedef-ai/fenic/main/CONTRIBUTING.md) for detailed information about the development process and project setup.\n",
    "ContentSha": "uskg5roWGwsGUjyK072Ea16WzdZZykGudJVeAy5e46I=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "#### Gemaakt voor Alle Ingenieurs\n\nDataFrames zijn niet alleen voor dataprofessionals. Het vloeiende, samenstelbare API-ontwerp maakt het toegankelijk voor elke ingenieur:\n\n- Koppel bewerkingen op een natuurlijke manier: `df.filter(...).semantic.group_by(...)`\n- Combineer imperatieve en declaratieve stijlen naadloos\n- Begin snel met bekende patronen uit pandas/PySpark of SQL\n\n## Support\n\nWord lid van onze community op [Discord](https://discord.gg/GdqF3J7huR) waar je in contact kunt komen met andere gebruikers, vragen kunt stellen en hulp kunt krijgen bij je fenic-projecten. Onze community verwelkomt altijd graag nieuwkomers!\n\nAls je fenic nuttig vindt, overweeg dan om ons een ⭐ te geven bovenaan deze repository. Jouw steun helpt ons het framework voor iedereen te laten groeien en verbeteren!\n\n## Bijdragen\n\nWe verwelkomen bijdragen van allerlei aard! Of je nu geïnteresseerd bent in het schrijven van code, het verbeteren van documentatie, het testen van functies of het voorstellen van nieuwe ideeën, jouw hulp is waardevol voor ons.\n\nVoor ontwikkelaars die van plan zijn om codewijzigingen in te dienen, raden we aan om eerst een issue te openen om je ideeën te bespreken voordat je een Pull Request aanmaakt. Dit helpt om afstemming met de richting van het project te garanderen en dubbele inspanningen te voorkomen.\n\nRaadpleeg onze [bijdrageregels](https://raw.githubusercontent.com/typedef-ai/fenic/main/CONTRIBUTING.md) voor gedetailleerde informatie over het ontwikkelingsproces en het opzetten van het project.",
    "Status": "ok"
  }
]