[
  {
    "Id": 1,
    "Content": "<!-- markdownlint-disable MD041 MD033 -->\n<div align=\"center\">\n    <picture>\n        <source media=\"(prefers-color-scheme: dark)\" srcset=\"docs/images/typedef-fenic-logo-dark.png\">\n        <img src=\"https://raw.githubusercontent.com/typedef-ai/fenic/main/docs/images/typedef-fenic-logo.png\" alt=\"fenic, by typedef\" width=\"90%\">\n    </picture>\n</div>\n\n# fenic: the dataframe (re)built for LLM inference\n\n[![PyPI version](https://img.shields.io/pypi/v/fenic.svg)](https://pypi.org/project/fenic/)\n[![Python versions](https://img.shields.io/pypi/pyversions/fenic.svg)](https://pypi.org/project/fenic/)\n[![License](https://img.shields.io/github/license/typedef-ai/fenic.svg)](https://github.com/typedef-ai/fenic/blob/main/LICENSE)\n[![Discord](https://img.shields.io/discord/1381706122322513952?label=Discord&logo=discord)](https://discord.gg/GdqF3J7huR)\n\n---\n\n## **Documentation**: [docs.fenic.ai](https://docs.fenic.ai/)\n\nfenic is an opinionated, PySpark-inspired DataFrame framework from typedef.ai for building AI and agentic applications. Transform unstructured and structured data into insights using familiar DataFrame operations enhanced with semantic intelligence. With first-class support for markdown, transcripts, and semantic operators, plus efficient batch inference across any model provider.\n",
    "ContentSha": "tmub1AxUb0Y4Al5Ltz67crbP453GMVUntyWUISmU7NQ=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "<!-- markdownlint-disable MD041 MD033 -->\n<div align=\"center\">\n    <picture>\n        <source media=\"(prefers-color-scheme: dark)\" srcset=\"docs/images/typedef-fenic-logo-dark.png\">\n        <img src=\"https://raw.githubusercontent.com/typedef-ai/fenic/main/docs/images/typedef-fenic-logo.png\" alt=\"fenic, by typedef\" width=\"90%\">\n    </picture>\n</div>\n\n# fenic：為 LLM 推理 (重新)打造的 dataframe\n\n[![PyPI version](https://img.shields.io/pypi/v/fenic.svg)](https://pypi.org/project/fenic/)\n[![Python versions](https://img.shields.io/pypi/pyversions/fenic.svg)](https://pypi.org/project/fenic/)\n[![License](https://img.shields.io/github/license/typedef-ai/fenic.svg)](https://github.com/typedef-ai/fenic/blob/main/LICENSE)\n[![Discord](https://img.shields.io/discord/1381706122322513952?label=Discord&logo=discord)](https://discord.gg/GdqF3J7huR)\n\n---\n\n## **文件**: [docs.fenic.ai](https://docs.fenic.ai/)\n\nfenic 是來自 typedef.ai 的一款具有主見、受 PySpark 啟發的 DataFrame 框架，用於構建 AI 及代理型應用。利用增強語意智能的熟悉 DataFrame 操作，將非結構化與結構化資料轉化為洞見。對 markdown、逐字稿與語意運算子提供一流支援，並可高效進行跨任意模型供應商的批次推理。",
    "Status": "ok"
  },
  {
    "Id": 2,
    "Content": "## Install\n\nfenic supports Python `[3.10, 3.11, 3.12]`\n\n```bash\npip install fenic\n```\n\n### LLM Provider Setup\n\nfenic requires an API key from at least one LLM provider. Set the appropriate environment variable for your chosen provider:\n\n```bash\n# For OpenAI\nexport OPENAI_API_KEY=\"your-openai-api-key\"\n\n# For Anthropic\nexport ANTHROPIC_API_KEY=\"your-anthropic-api-key\"\n\n# For Google",
    "ContentSha": "QT2GWoHGnyfwnJxlfZAk0I5rpIsEfvGEhJD38oz6lCY=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "## 安裝\n\nfenic 支援 Python `[3.10, 3.11, 3.12]`\n\n```bash\npip install fenic\n```\n\n### LLM 供應商設置\n\nfenic 需要至少一個 LLM 供應商的 API 金鑰。請為您選擇的供應商設置相應的環境變數：\n\n```bash\n# 對於 OpenAI\nexport OPENAI_API_KEY=\"your-openai-api-key\"\n\n# 對於 Anthropic\nexport ANTHROPIC_API_KEY=\"your-anthropic-api-key\"\n\n# 對於 Google",
    "Status": "ok"
  },
  {
    "Id": 3,
    "Content": "export GEMINI_API_KEY=\"your-google-api-key\"\n```\n\n## Quickstart\n\nThe fastest way to learn about fenic is by checking the examples.\n\nBelow is a quick list of the examples in this repo:\n\n| Example                                                                 | Description                                                                                                                         |\n| ----------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------- |\n| [Hello World!](examples/hello_world)                                    | Introduction to semantic extraction and classification using fenic's core operators through error log analysis.                     |\n| [Enrichment](examples/enrichment)                                       | Multi-stage DataFrames with template-based text extraction, joins, and LLM-powered transformations demonstrated via log enrichment. |\n| [Meeting Transcript Processing](examples/meeting_transcript_processing) | Native transcript parsing, Pydantic schema integration, and complex aggregations shown through meeting analysis.                    |\n| [News Analysis](examples/news_analysis)                                 | Analyze and extract insights from news articles using semantic operators and structured data processing.                            |\n| [Podcast Summarization](examples/podcast_summarization)                 | Process and summarize podcast transcripts with speaker-aware analysis and key point extraction.                                     |\n| [Semantic Join](examples/semantic_joins)                                | Instead of simple fuzzy matching, use fenic's powerful semantic join functionality to match data across tables.                     |\n| [Named Entity Recognition](examples/named_entity_recognition)           | Extract and classify named entities from text using semantic extraction and classification.                                         |\n| [Markdown Processing](examples/markdown_processing)                     | Process and transform markdown documents with structured data extraction and formatting.                                            |\n| [JSON Processing](examples/json_processing)                             | Handle complex JSON data structures with semantic operations and schema validation.                                                 |\n| [Feedback Clustering](examples/feedback_clustering)                     | Group and analyze feedback using semantic similarity and clustering operations.                                                     |\n| [Document Extraction](examples/document_extraction)                     | Extract structured information from various document formats using semantic operators.                                              |\n\n(Feel free to click any example above to jump right to its folder.)\n",
    "ContentSha": "RBvJ+qAaDZODC8rvu1sFp9QTE4SUhSKTTu/91HAxBRc=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "export GEMINI_API_KEY=\"your-google-api-key\"\n```\n\n## 快速入門\n\n學習 fenic 最快的方法是查看範例。\n\n以下是此資料庫中的範例快速清單：\n\n| 範例                                                                       | 說明                                                                                                                                |\n| -------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------- |\n| [Hello World!](examples/hello_world)                                       | 透過錯誤日誌分析，介紹如何使用 fenic 的核心運算子進行語意萃取與分類。                                                              |\n| [Enrichment](examples/enrichment)                                          | 以日誌增強為例，展示多階段 DataFrame、基於模板的文字萃取、表格聯結與 LLM 驅動的轉換。                                              |\n| [Meeting Transcript Processing](examples/meeting_transcript_processing)    | 透過會議分析，展示原生逐字稿解析、Pydantic 結構整合與複雜彙總運算。                                                               |\n| [News Analysis](examples/news_analysis)                                    | 使用語意運算子與結構化資料處理，分析並萃取新聞文章的見解。                                                                          |\n| [Podcast Summarization](examples/podcast_summarization)                    | 以說話者為單位分析並萃取重點，處理與摘要 Podcast 逐字稿。                                                                           |\n| [Semantic Join](examples/semantic_joins)                                   | 不只是模糊比對，使用 fenic 強大的語意聯結功能跨表比對資料。                                                                         |\n| [Named Entity Recognition](examples/named_entity_recognition)              | 利用語意萃取與分類，從文本中擷取並分類命名實體。                                                                                    |\n| [Markdown Processing](examples/markdown_processing)                        | 以結構化資料萃取與格式轉換來處理與轉換 Markdown 文件。                                                                              |\n| [JSON Processing](examples/json_processing)                                | 透過語意操作與結構驗證處理複雜的 JSON 資料結構。                                                                                    |\n| [Feedback Clustering](examples/feedback_clustering)                        | 透過語意相似性與分群操作，分組並分析回饋意見。                                                                                      |\n| [Document Extraction](examples/document_extraction)                        | 使用語意運算子，從各種文件格式中萃取結構化資訊。                                                                                    |\n\n（歡迎點擊上方任一範例，直接跳轉到其資料夾。）",
    "Status": "ok"
  },
  {
    "Id": 4,
    "Content": "## Why use fenic?\n\nfenic is an opinionated, PySpark-inspired DataFrame framework for building production AI and agentic applications.\n\nUnlike traditional data tools retrofitted for LLMs, fenic's query engine is built from the ground up with inference in mind.\n\nTransform structured and unstructured data into insights using familiar DataFrame operations enhanced with semantic intelligence. With first-class support for markdown, transcripts, and semantic operators, plus efficient batch inference across any model provider.\n\nfenic brings the reliability of traditional data pipelines to AI workloads.\n\n### Key Features\n\n#### Purpose-Built for LLM Inference\n\n- Query engine designed from scratch for AI workloads, not retrofitted\n- Automatic batch optimization for API calls\n- Built-in retry logic and rate limiting\n- Token counting and cost tracking\n\n#### Semantic Operators as First-Class Citizens",
    "ContentSha": "POPTpr2d3zFT3V0X0/NRjmMCUTjlIPBHtMTVHIRsyfM=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "## 為什麼使用 fenic？\n\nfenic 是一個具有明確主張、受 PySpark 啟發的 DataFrame 框架，用於構建生產級 AI 與智能代理應用。\n\n與為 LLMs 臨時修改的傳統數據工具不同，fenic 的查詢引擎從零開始設計，專為推理任務打造。\n\n使用增強語意智能的熟悉 DataFrame 操作，將結構化與非結構化數據轉化為洞見。fenic 原生支援 markdown、逐字稿與語意運算子，並可在任意模型供應商之間高效批量推理。\n\nfenic 將傳統數據管道的可靠性帶入 AI 工作負載。\n\n### 主要特點\n\n#### 專為 LLM 推理打造\n\n- 查詢引擎從零設計，專為 AI 工作負載，非臨時拼湊\n- API 調用自動批次優化\n- 內建重試邏輯與速率限制\n- 支援 token 計數與成本追蹤\n\n#### 語意運算子為一等公民",
    "Status": "ok"
  },
  {
    "Id": 5,
    "Content": "\n- `semantic.analyze_sentiment` - Built-in sentiment analysis\n- `semantic.classify` - Categorize text with few-shot examples\n- `semantic.extract` - Transform unstructured text into structured data with schemas\n- `semantic.group_by` - Group data by semantic similarity\n- `semantic.join` - Join DataFrames on meaning, not just values\n- `semantic.map` - Apply natural language transformations\n- `semantic.predicate` - Create predicates using natural language to filter rows\n- `semantic.reduce` - Aggregate grouped data with LLM operations\n\n#### Native Unstructured Data Support\n\nGoes beyond typical multimodal data types (audio, images) by creating specialized types for text-heavy workloads:\n\n- Markdown parsing and extraction as a first-class data type\n- Transcript processing (SRT, generic formats) with speaker and timestamp awareness\n- JSON manipulation with JQ expressions for nested data\n- Automatic text chunking with configurable overlap for long documents\n\n#### Production-Ready Infrastructure",
    "ContentSha": "NE5dPjdhTPxhAD1E+gcEg2tw/wEtQVkEuw1AGA1YwCQ=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "- `semantic.analyze_sentiment` - 內建情感分析\n- `semantic.classify` - 使用少量範例對文本進行分類\n- `semantic.extract` - 以結構化資料模式轉換非結構化文本\n- `semantic.group_by` - 依語意相似性分組資料\n- `semantic.join` - 依語意合併資料框，而不僅僅是值\n- `semantic.map` - 應用自然語言轉換\n- `semantic.predicate` - 使用自然語言建立謂詞以篩選資料列\n- `semantic.reduce` - 以LLM操作彙總分組資料\n\n#### 原生非結構化資料支援\n\n超越一般多模態資料類型（音訊、影像），針對以文本為主的工作負載創建專門類型：\n\n- Markdown剖析與擷取作為一級資料類型\n- 具備說話者與時間戳辨識的逐字稿處理（SRT、通用格式）\n- 使用JQ表示式處理巢狀資料的JSON操作\n- 可配置重疊的自動文本分段，適用於長文件\n\n#### 生產等級基礎設施",
    "Status": "ok"
  },
  {
    "Id": 6,
    "Content": "\n- Multi-provider support (OpenAI, Anthropic, Gemini)\n- Local and cloud execution backends\n- Comprehensive error handling and logging\n- Pydantic integration for type safety\n\n#### Familiar DataFrame API\n\n- PySpark-compatible operations\n- Lazy evaluation and query optimization\n- SQL support for complex queries\n- Seamless integration with existing data pipelines\n\n### Why DataFrames for LLM and Agentic Applications?\n\nAI and agentic applications are fundamentally pipelines and workflows - exactly what DataFrame APIs were designed to handle. Rather than reinventing patterns for data transformation, filtering, and aggregation, fenic leverages decades of proven engineering practices.\n\n#### Decoupled Architecture for Better Agents\n\nfenic creates a clear separation between heavy inference tasks and real-time agent interactions. By moving batch processing out of the agent runtime, you get:\n\n- More predictable and responsive agents\n- Better resource utilization with batched LLM calls\n- Cleaner separation between planning/orchestration and execution\n",
    "ContentSha": "mT0TcKmDXUG4vMCvQ5Zt2Hov+kI1MOWz6tDxxgD3BGY=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "- 多供應商支援（OpenAI、Anthropic、Gemini）\n- 本地與雲端執行後端\n- 全面性的錯誤處理與日誌記錄\n- Pydantic 型別安全整合\n\n#### 熟悉的 DataFrame API\n\n- 相容於 PySpark 的操作\n- 延遲評估與查詢最佳化\n- 支援複雜查詢的 SQL\n- 可無縫整合現有資料管道\n\n### 為什麼在 LLM 與智能代理應用中使用 DataFrame？\n\nAI 與智能代理應用本質上是管道與工作流程——這正是 DataFrame API 設計來處理的場景。fenic 不必重新發明資料轉換、過濾與聚合的模式，而是善用數十年來經過驗證的工程實踐。\n\n#### 解耦式架構以實現更佳代理\n\nfenic 在繁重的推論任務與即時代理互動之間建立明確分隔。將批次處理移出代理執行時環境後，您將獲得：\n\n- 更可預期且具回應性的代理\n- 透過批次 LLM 呼叫達到更佳資源利用率\n- 將規劃／協調與執行做出更清楚的分離",
    "Status": "ok"
  },
  {
    "Id": 7,
    "Content": "#### Built for All Engineers\n\nDataFrames aren't just for data practitioners. The fluent, composable API design makes it accessible to any engineer:\n\n- Chain operations naturally: `df.filter(...).semantic.group_by(...)`\n- Mix imperative and declarative styles seamlessly\n- Get started quickly with familiar patterns from pandas/PySpark or SQL\n\n## Support\n\nJoin our community on [Discord](https://discord.gg/GdqF3J7huR) where you can connect with other users, ask questions, and get help with your fenic projects. Our community is always happy to welcome newcomers!\n\nIf you find fenic useful, consider giving us a ⭐ at the top of this repository. Your support helps us grow and improve the framework for everyone!\n\n## Contributing\n\nWe welcome contributions of all kinds! Whether you're interested in writing code, improving documentation, testing features, or proposing new ideas, your help is valuable to us.\n\nFor developers planning to submit code changes, we encourage you to first open an issue to discuss your ideas before creating a Pull Request. This helps ensure alignment with the project's direction and prevents duplicate efforts.\n\nPlease refer to our [contribution guidelines](https://raw.githubusercontent.com/typedef-ai/fenic/main/CONTRIBUTING.md) for detailed information about the development process and project setup.\n",
    "ContentSha": "uskg5roWGwsGUjyK072Ea16WzdZZykGudJVeAy5e46I=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "#### 為所有工程師打造\n\nDataFrame 不僅僅是為資料工作者設計的。其流暢且可組合的 API 設計讓任何工程師都能輕鬆上手：\n\n- 自然串接操作：`df.filter(...).semantic.group_by(...)`\n- 無縫混用命令式與宣告式風格\n- 透過來自 pandas/PySpark 或 SQL 的熟悉模式快速上手\n\n## 支援\n\n歡迎加入我們的 [Discord 社群](https://discord.gg/GdqF3J7huR)，在那裡你可以與其他用戶交流、提問，並獲得有關 fenic 專案的協助。我們的社群非常歡迎新朋友加入！\n\n如果你覺得 fenic 有幫助，請考慮在本倉庫頂部給我們一個 ⭐。你的支持有助於我們成長並為大家改進這個框架！\n\n## 貢獻\n\n我們歡迎各種形式的貢獻！無論你有興趣撰寫程式碼、改善文件、測試功能，或是提出新想法，你的幫助對我們都非常寶貴。\n\n對於計劃提交程式碼更動的開發者，我們建議你先開一個 Issue 與我們討論你的想法，再建立 Pull Request。這有助於確保專案方向的一致性，並避免重複工作。\n\n請參閱我們的[貢獻指南](https://raw.githubusercontent.com/typedef-ai/fenic/main/CONTRIBUTING.md)，以獲得有關開發流程和專案設置的詳細資訊。",
    "Status": "ok"
  }
]