[
  {
    "Id": 1,
    "Content": "<!-- markdownlint-disable MD041 MD033 -->\n<div align=\"center\">\n    <picture>\n        <source media=\"(prefers-color-scheme: dark)\" srcset=\"docs/images/typedef-fenic-logo-dark.png\">\n        <img src=\"https://raw.githubusercontent.com/typedef-ai/fenic/main/docs/images/typedef-fenic-logo.png\" alt=\"fenic, by typedef\" width=\"90%\">\n    </picture>\n</div>\n\n# fenic: the dataframe (re)built for LLM inference\n\n[![PyPI version](https://img.shields.io/pypi/v/fenic.svg)](https://pypi.org/project/fenic/)\n[![Python versions](https://img.shields.io/pypi/pyversions/fenic.svg)](https://pypi.org/project/fenic/)\n[![License](https://img.shields.io/github/license/typedef-ai/fenic.svg)](https://github.com/typedef-ai/fenic/blob/main/LICENSE)\n[![Discord](https://img.shields.io/discord/1381706122322513952?label=Discord&logo=discord)](https://discord.gg/GdqF3J7huR)\n\n---\n\n## **Documentation**: [docs.fenic.ai](https://docs.fenic.ai/)\n\nfenic is an opinionated, PySpark-inspired DataFrame framework from typedef.ai for building AI and agentic applications. Transform unstructured and structured data into insights using familiar DataFrame operations enhanced with semantic intelligence. With first-class support for markdown, transcripts, and semantic operators, plus efficient batch inference across any model provider.\n",
    "ContentSha": "tmub1AxUb0Y4Al5Ltz67crbP453GMVUntyWUISmU7NQ=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "<!-- markdownlint-disable MD041 MD033 -->\n<div align=\"center\">\n    <picture>\n        <source media=\"(prefers-color-scheme: dark)\" srcset=\"docs/images/typedef-fenic-logo-dark.png\">\n        <img src=\"https://raw.githubusercontent.com/typedef-ai/fenic/main/docs/images/typedef-fenic-logo.png\" alt=\"fenic, by typedef\" width=\"90%\">\n    </picture>\n</div>\n\n# fenic: دیتافریم (دوباره) ساخته‌شده برای استنتاج LLM\n\n[![نسخه PyPI](https://img.shields.io/pypi/v/fenic.svg)](https://pypi.org/project/fenic/)\n[![نسخه‌های پایتون](https://img.shields.io/pypi/pyversions/fenic.svg)](https://pypi.org/project/fenic/)\n[![لایسنس](https://img.shields.io/github/license/typedef-ai/fenic.svg)](https://github.com/typedef-ai/fenic/blob/main/LICENSE)\n[![دیسکورد](https://img.shields.io/discord/1381706122322513952?label=Discord&logo=discord)](https://discord.gg/GdqF3J7huR)\n\n---\n\n## **مستندات**: [docs.fenic.ai](https://docs.fenic.ai/)\n\nfenic یک چارچوب دیتافریم الهام‌گرفته از PySpark و با دیدگاه خاص از typedef.ai است که برای ساخت برنامه‌های هوش مصنوعی و عامل‌محور طراحی شده است. داده‌های ساخت‌یافته و غیرساخت‌یافته را با استفاده از عملیات دیتافریم آشنا که با هوش معنایی تقویت شده‌اند، به بینش تبدیل کنید. دارای پشتیبانی سطح بالا از مارک‌داون، رونوشت‌ها و عملگرهای معنایی، به‌علاوه استنتاج دسته‌ای کارآمد با هر ارائه‌دهنده مدل.",
    "Status": "ok"
  },
  {
    "Id": 2,
    "Content": "## Install\n\nfenic supports Python `[3.10, 3.11, 3.12]`\n\n```bash\npip install fenic\n```\n\n### LLM Provider Setup\n\nfenic requires an API key from at least one LLM provider. Set the appropriate environment variable for your chosen provider:\n\n```bash\n# For OpenAI\nexport OPENAI_API_KEY=\"your-openai-api-key\"\n\n# For Anthropic\nexport ANTHROPIC_API_KEY=\"your-anthropic-api-key\"\n\n# For Google",
    "ContentSha": "QT2GWoHGnyfwnJxlfZAk0I5rpIsEfvGEhJD38oz6lCY=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "## نصب\n\nfenic از نسخه‌های پایتون `[3.10, 3.11, 3.12]` پشتیبانی می‌کند\n\n```bash\npip install fenic\n```\n\n### راه‌اندازی ارائه‌دهنده LLM\n\nfenic به یک کلید API از حداقل یکی از ارائه‌دهندگان LLM نیاز دارد. متغیر محیطی مناسب را برای ارائه‌دهنده انتخابی خود تنظیم کنید:\n\n```bash\n# برای OpenAI\nexport OPENAI_API_KEY=\"your-openai-api-key\"\n\n# برای Anthropic\nexport ANTHROPIC_API_KEY=\"your-anthropic-api-key\"\n\n# برای Google",
    "Status": "ok"
  },
  {
    "Id": 3,
    "Content": "export GEMINI_API_KEY=\"your-google-api-key\"\n```\n\n## Quickstart\n\nThe fastest way to learn about fenic is by checking the examples.\n\nBelow is a quick list of the examples in this repo:\n\n| Example                                                                 | Description                                                                                                                         |\n| ----------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------- |\n| [Hello World!](examples/hello_world)                                    | Introduction to semantic extraction and classification using fenic's core operators through error log analysis.                     |\n| [Enrichment](examples/enrichment)                                       | Multi-stage DataFrames with template-based text extraction, joins, and LLM-powered transformations demonstrated via log enrichment. |\n| [Meeting Transcript Processing](examples/meeting_transcript_processing) | Native transcript parsing, Pydantic schema integration, and complex aggregations shown through meeting analysis.                    |\n| [News Analysis](examples/news_analysis)                                 | Analyze and extract insights from news articles using semantic operators and structured data processing.                            |\n| [Podcast Summarization](examples/podcast_summarization)                 | Process and summarize podcast transcripts with speaker-aware analysis and key point extraction.                                     |\n| [Semantic Join](examples/semantic_joins)                                | Instead of simple fuzzy matching, use fenic's powerful semantic join functionality to match data across tables.                     |\n| [Named Entity Recognition](examples/named_entity_recognition)           | Extract and classify named entities from text using semantic extraction and classification.                                         |\n| [Markdown Processing](examples/markdown_processing)                     | Process and transform markdown documents with structured data extraction and formatting.                                            |\n| [JSON Processing](examples/json_processing)                             | Handle complex JSON data structures with semantic operations and schema validation.                                                 |\n| [Feedback Clustering](examples/feedback_clustering)                     | Group and analyze feedback using semantic similarity and clustering operations.                                                     |\n| [Document Extraction](examples/document_extraction)                     | Extract structured information from various document formats using semantic operators.                                              |\n\n(Feel free to click any example above to jump right to its folder.)\n",
    "ContentSha": "RBvJ+qAaDZODC8rvu1sFp9QTE4SUhSKTTu/91HAxBRc=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\nexport GEMINI_API_KEY=\"your-google-api-key\"\n```\n\n## شروع سریع\n\nسریع‌ترین راه برای یادگیری fenic بررسی مثال‌ها است.\n\nدر زیر یک فهرست سریع از مثال‌های موجود در این مخزن آورده شده است:\n\n| مثال                                                                      | توضیحات                                                                                                                          |\n| ------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------- |\n| [Hello World!](examples/hello_world)                                      | معرفی استخراج معنایی و طبقه‌بندی با استفاده از عملگرهای اصلی fenic از طریق تحلیل لاگ خطا.                                        |\n| [Enrichment](examples/enrichment)                                         | دیتافریم‌های چند مرحله‌ای با استخراج متن مبتنی بر الگو، جوین‌ها و تبدیل‌های مبتنی بر LLM که از طریق غنی‌سازی لاگ نمایش داده شده‌اند. |\n| [پردازش متن جلسه](examples/meeting_transcript_processing)                | تجزیه بومی متن جلسه، یکپارچه‌سازی اسکیمای Pydantic و تجمیع‌های پیچیده از طریق تحلیل جلسه نشان داده شده است.                       |\n| [تحلیل اخبار](examples/news_analysis)                                     | تجزیه و استخراج بینش از مقالات خبری با استفاده از عملگرهای معنایی و پردازش داده ساختاریافته.                                     |\n| [خلاصه‌سازی پادکست](examples/podcast_summarization)                       | پردازش و خلاصه‌سازی متن پادکست‌ها با تحلیل مبتنی بر گوینده و استخراج نکات کلیدی.                                                |\n| [اتصال معنایی](examples/semantic_joins)                                   | به جای تطابق فازی ساده، از قابلیت اتصال معنایی قدرتمند fenic برای تطابق داده بین جداول استفاده کنید.                             |\n| [شناسایی موجودیت نامدار](examples/named_entity_recognition)              | استخراج و طبقه‌بندی موجودیت‌های نامدار از متن با استفاده از استخراج و طبقه‌بندی معنایی.                                          |\n| [پردازش مارک‌داون](examples/markdown_processing)                          | پردازش و تبدیل اسناد مارک‌داون با استخراج داده ساختار یافته و قالب‌بندی.                                                          |\n| [پردازش JSON](examples/json_processing)                                   | مدیریت ساختارهای پیچیده داده JSON با عملیات معنایی و اعتبارسنجی اسکیمای داده.                                                     |\n| [خوشه‌بندی بازخورد](examples/feedback_clustering)                         | گروه‌بندی و تحلیل بازخوردها با استفاده از شباهت معنایی و عملیات خوشه‌بندی.                                                       |\n| [استخراج اسناد](examples/document_extraction)                             | استخراج اطلاعات ساختاریافته از فرمت‌های مختلف اسناد با استفاده از عملگرهای معنایی.                                                |\n\n(برای رفتن مستقیم به پوشه هر مثال، می‌توانید روی هر مورد بالا کلیک کنید.)\n",
    "Status": "ok"
  },
  {
    "Id": 4,
    "Content": "## Why use fenic?\n\nfenic is an opinionated, PySpark-inspired DataFrame framework for building production AI and agentic applications.\n\nUnlike traditional data tools retrofitted for LLMs, fenic's query engine is built from the ground up with inference in mind.\n\nTransform structured and unstructured data into insights using familiar DataFrame operations enhanced with semantic intelligence. With first-class support for markdown, transcripts, and semantic operators, plus efficient batch inference across any model provider.\n\nfenic brings the reliability of traditional data pipelines to AI workloads.\n\n### Key Features\n\n#### Purpose-Built for LLM Inference\n\n- Query engine designed from scratch for AI workloads, not retrofitted\n- Automatic batch optimization for API calls\n- Built-in retry logic and rate limiting\n- Token counting and cost tracking\n\n#### Semantic Operators as First-Class Citizens",
    "ContentSha": "POPTpr2d3zFT3V0X0/NRjmMCUTjlIPBHtMTVHIRsyfM=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "## چرا از fenic استفاده کنیم؟\n\nfenic یک چارچوب DataFrame با الهام از PySpark و مبتنی بر نظر تخصصی است که برای ساخت برنامه‌های تولیدی هوش مصنوعی و عامل‌محور طراحی شده است.\n\nبر خلاف ابزارهای داده‌ای سنتی که برای LLMها تغییر کاربری داده شده‌اند، موتور جستجوی fenic از ابتدا با در نظر گرفتن استنتاج طراحی شده است.\n\nداده‌های ساختاریافته و غیرساختاریافته را با استفاده از عملیات آشنای DataFrame که با هوش معنایی تقویت شده‌اند، به بینش تبدیل کنید. با پشتیبانی سطح بالا از markdown، رونوشت‌ها و عملگرهای معنایی، به‌علاوه استنتاج دسته‌ای کارآمد برای هر ارائه‌دهنده مدل.\n\nfenic قابلیت اطمینان خطوط پردازش داده سنتی را به حجم کارهای هوش مصنوعی می‌آورد.\n\n### ویژگی‌های کلیدی\n\n#### طراحی شده مخصوص استنتاج LLM\n\n- موتور جستجویی که از پایه برای حجم کارهای هوش مصنوعی طراحی شده، نه تغییر کاربری داده شده\n- بهینه‌سازی خودکار دسته‌ای برای فراخوانی‌های API\n- منطق بازآزمایی داخلی و محدودیت نرخ\n- شمارش توکن و ردیابی هزینه\n\n#### عملگرهای معنایی به عنوان عناصر درجه یک",
    "Status": "ok"
  },
  {
    "Id": 5,
    "Content": "\n- `semantic.analyze_sentiment` - Built-in sentiment analysis\n- `semantic.classify` - Categorize text with few-shot examples\n- `semantic.extract` - Transform unstructured text into structured data with schemas\n- `semantic.group_by` - Group data by semantic similarity\n- `semantic.join` - Join DataFrames on meaning, not just values\n- `semantic.map` - Apply natural language transformations\n- `semantic.predicate` - Create predicates using natural language to filter rows\n- `semantic.reduce` - Aggregate grouped data with LLM operations\n\n#### Native Unstructured Data Support\n\nGoes beyond typical multimodal data types (audio, images) by creating specialized types for text-heavy workloads:\n\n- Markdown parsing and extraction as a first-class data type\n- Transcript processing (SRT, generic formats) with speaker and timestamp awareness\n- JSON manipulation with JQ expressions for nested data\n- Automatic text chunking with configurable overlap for long documents\n\n#### Production-Ready Infrastructure",
    "ContentSha": "NE5dPjdhTPxhAD1E+gcEg2tw/wEtQVkEuw1AGA1YwCQ=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "- `semantic.analyze_sentiment` - تحلیل احساسات داخلی\n- `semantic.classify` - دسته‌بندی متن با نمونه‌های کم (few-shot)\n- `semantic.extract` - تبدیل متن بدون ساختار به داده ساخت‌یافته با استفاده از طرح‌واره‌ها\n- `semantic.group_by` - گروه‌بندی داده‌ها بر اساس شباهت معنایی\n- `semantic.join` - اتصال DataFrameها بر اساس معنا، نه فقط مقادیر\n- `semantic.map` - اعمال تبدیلات زبان طبیعی\n- `semantic.predicate` - ایجاد گزاره‌ها با استفاده از زبان طبیعی برای فیلتر کردن ردیف‌ها\n- `semantic.reduce` - تجمیع داده‌های گروه‌بندی‌شده با عملیات LLM\n\n#### پشتیبانی بومی از داده‌های بدون ساختار\n\nفراتر از انواع داده‌های چندرسانه‌ای معمول (صوت، تصویر) با ایجاد انواع تخصصی برای بارهای کاری متنی:\n\n- تجزیه و استخراج Markdown به عنوان یک نوع داده سطح بالا\n- پردازش رونوشت (SRT، فرمت‌های عمومی) با آگاهی از گوینده و زمان‌بندی\n- دستکاری JSON با عبارات JQ برای داده‌های تو در تو\n- تقسیم خودکار متن با همپوشانی قابل تنظیم برای اسناد طولانی\n\n#### زیرساخت آماده تولید",
    "Status": "ok"
  },
  {
    "Id": 6,
    "Content": "\n- Multi-provider support (OpenAI, Anthropic, Gemini)\n- Local and cloud execution backends\n- Comprehensive error handling and logging\n- Pydantic integration for type safety\n\n#### Familiar DataFrame API\n\n- PySpark-compatible operations\n- Lazy evaluation and query optimization\n- SQL support for complex queries\n- Seamless integration with existing data pipelines\n\n### Why DataFrames for LLM and Agentic Applications?\n\nAI and agentic applications are fundamentally pipelines and workflows - exactly what DataFrame APIs were designed to handle. Rather than reinventing patterns for data transformation, filtering, and aggregation, fenic leverages decades of proven engineering practices.\n\n#### Decoupled Architecture for Better Agents\n\nfenic creates a clear separation between heavy inference tasks and real-time agent interactions. By moving batch processing out of the agent runtime, you get:\n\n- More predictable and responsive agents\n- Better resource utilization with batched LLM calls\n- Cleaner separation between planning/orchestration and execution\n",
    "ContentSha": "mT0TcKmDXUG4vMCvQ5Zt2Hov+kI1MOWz6tDxxgD3BGY=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "- پشتیبانی از چند ارائه‌دهنده (OpenAI، Anthropic، Gemini)\n- پشتیبانی از اجرا به صورت محلی و ابری\n- مدیریت خطا و ثبت گزارش جامع\n- یکپارچگی با Pydantic برای اطمینان از نوع‌دهی ایمن\n\n#### API آشنای DataFrame\n\n- عملیات سازگار با PySpark\n- ارزیابی تنبل و بهینه‌سازی کوئری\n- پشتیبانی از SQL برای کوئری‌های پیچیده\n- یکپارچگی بدون مشکل با خطوط داده موجود\n\n### چرا DataFrameها برای برنامه‌های LLM و عامل‌محور؟\n\nبرنامه‌های هوش مصنوعی و عامل‌محور، اساساً خطوط پردازش و جریان‌های کاری هستند؛ دقیقاً همان چیزی که APIهای DataFrame برای آن طراحی شده‌اند. به جای اختراع دوباره الگوهای تبدیل، فیلتر و تجمیع داده، fenic از دهه‌ها تجربه مهندسی اثبات‌شده بهره می‌برد.\n\n#### معماری جداشده برای عامل‌های بهتر\n\nfenic جداسازی روشنی بین کارهای سنگین استنتاج و تعاملات بلادرنگ عامل ایجاد می‌کند. با انتقال پردازش دسته‌ای به خارج از زمان اجرای عامل، شما موارد زیر را به دست می‌آورید:\n\n- عامل‌هایی با پاسخ‌گویی و پیش‌بینی‌پذیری بیشتر\n- بهره‌وری بهتر منابع با فراخوانی‌های دسته‌ای به LLM\n- جداسازی تمیزتر بین برنامه‌ریزی/هماهنگی و اجرا",
    "Status": "ok"
  },
  {
    "Id": 7,
    "Content": "#### Built for All Engineers\n\nDataFrames aren't just for data practitioners. The fluent, composable API design makes it accessible to any engineer:\n\n- Chain operations naturally: `df.filter(...).semantic.group_by(...)`\n- Mix imperative and declarative styles seamlessly\n- Get started quickly with familiar patterns from pandas/PySpark or SQL\n\n## Support\n\nJoin our community on [Discord](https://discord.gg/GdqF3J7huR) where you can connect with other users, ask questions, and get help with your fenic projects. Our community is always happy to welcome newcomers!\n\nIf you find fenic useful, consider giving us a ⭐ at the top of this repository. Your support helps us grow and improve the framework for everyone!\n\n## Contributing\n\nWe welcome contributions of all kinds! Whether you're interested in writing code, improving documentation, testing features, or proposing new ideas, your help is valuable to us.\n\nFor developers planning to submit code changes, we encourage you to first open an issue to discuss your ideas before creating a Pull Request. This helps ensure alignment with the project's direction and prevents duplicate efforts.\n\nPlease refer to our [contribution guidelines](https://raw.githubusercontent.com/typedef-ai/fenic/main/CONTRIBUTING.md) for detailed information about the development process and project setup.\n",
    "ContentSha": "uskg5roWGwsGUjyK072Ea16WzdZZykGudJVeAy5e46I=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "#### ساخته شده برای همه مهندسان\n\nDataFrameها فقط برای متخصصان داده نیستند. طراحی API روان و ترکیبی، آن را برای هر مهندسی قابل دسترس می‌کند:\n\n- عملیات را به‌صورت طبیعی زنجیره کنید: `df.filter(...).semantic.group_by(...)`\n- سبک‌های دستوری و اعلامی را به‌صورت یکپارچه ترکیب کنید\n- با الگوهای آشنا از pandas/PySpark یا SQL به سرعت شروع کنید\n\n## پشتیبانی\n\nبه جامعه ما در [Discord](https://discord.gg/GdqF3J7huR) بپیوندید، جایی که می‌توانید با سایر کاربران ارتباط برقرار کنید، سوال بپرسید و برای پروژه‌های fenic خود کمک بگیرید. جامعه ما همیشه خوشحال است که از تازه‌واردان استقبال کند!\n\nاگر fenic برای شما مفید است، لطفاً به ما یک ⭐ در بالای این مخزن بدهید. حمایت شما به ما کمک می‌کند تا چارچوب را برای همه توسعه و بهبود دهیم!\n\n## مشارکت\n\nما از هر نوع مشارکتی استقبال می‌کنیم! چه علاقه‌مند به نوشتن کد، بهبود مستندات، تست ویژگی‌ها یا پیشنهاد ایده‌های جدید باشید، کمک شما برای ما ارزشمند است.\n\nبرای توسعه‌دهندگانی که قصد ارسال تغییرات کد را دارند، توصیه می‌کنیم ابتدا یک issue باز کنید تا ایده‌های خود را قبل از ایجاد Pull Request مطرح کنید. این کار باعث هماهنگی با جهت‌گیری پروژه و جلوگیری از تلاش‌های تکراری می‌شود.\n\nلطفاً برای اطلاعات دقیق درباره فرآیند توسعه و راه‌اندازی پروژه به [راهنمای مشارکت](https://raw.githubusercontent.com/typedef-ai/fenic/main/CONTRIBUTING.md) ما مراجعه کنید.",
    "Status": "ok"
  }
]