[
  {
    "Id": 1,
    "Content": "<!-- markdownlint-disable MD041 MD033 -->\n<div align=\"center\">\n    <picture>\n        <source media=\"(prefers-color-scheme: dark)\" srcset=\"docs/images/typedef-fenic-logo-dark.png\">\n        <img src=\"https://raw.githubusercontent.com/typedef-ai/fenic/main/docs/images/typedef-fenic-logo.png\" alt=\"fenic, by typedef\" width=\"90%\">\n    </picture>\n</div>\n\n# fenic: the dataframe (re)built for LLM inference\n\n[![PyPI version](https://img.shields.io/pypi/v/fenic.svg)](https://pypi.org/project/fenic/)\n[![Python versions](https://img.shields.io/pypi/pyversions/fenic.svg)](https://pypi.org/project/fenic/)\n[![License](https://img.shields.io/github/license/typedef-ai/fenic.svg)](https://github.com/typedef-ai/fenic/blob/main/LICENSE)\n[![Discord](https://img.shields.io/discord/1381706122322513952?label=Discord&logo=discord)](https://discord.gg/GdqF3J7huR)\n\n---\n\n## **Documentation**: [docs.fenic.ai](https://docs.fenic.ai/)\n\nfenic is an opinionated, PySpark-inspired DataFrame framework from typedef.ai for building AI and agentic applications. Transform unstructured and structured data into insights using familiar DataFrame operations enhanced with semantic intelligence. With first-class support for markdown, transcripts, and semantic operators, plus efficient batch inference across any model provider.\n",
    "ContentSha": "tmub1AxUb0Y4Al5Ltz67crbP453GMVUntyWUISmU7NQ=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "<!-- markdownlint-disable MD041 MD033 -->\n<div align=\"center\">\n    <picture>\n        <source media=\"(prefers-color-scheme: dark)\" srcset=\"docs/images/typedef-fenic-logo-dark.png\">\n        <img src=\"https://raw.githubusercontent.com/typedef-ai/fenic/main/docs/images/typedef-fenic-logo.png\" alt=\"fenic, by typedef\" width=\"90%\">\n    </picture>\n</div>\n\n# fenic: dataframe (na nowo) stworzony do wnioskowania LLM\n\n[![Wersja PyPI](https://img.shields.io/pypi/v/fenic.svg)](https://pypi.org/project/fenic/)\n[![Wersje Pythona](https://img.shields.io/pypi/pyversions/fenic.svg)](https://pypi.org/project/fenic/)\n[![Licencja](https://img.shields.io/github/license/typedef-ai/fenic.svg)](https://github.com/typedef-ai/fenic/blob/main/LICENSE)\n[![Discord](https://img.shields.io/discord/1381706122322513952?label=Discord&logo=discord)](https://discord.gg/GdqF3J7huR)\n\n---\n\n## **Dokumentacja**: [docs.fenic.ai](https://docs.fenic.ai/)\n\nfenic to opiniotwórczy, inspirowany PySpark DataFrame framework od typedef.ai do budowy aplikacji AI oraz agentowych. Przekształcaj dane nieustrukturyzowane i strukturyzowane w informacje dzięki znanym operacjom DataFrame, wzbogaconym o inteligencję semantyczną. Oferuje natywne wsparcie dla markdown, transkryptów i operatorów semantycznych oraz wydajne wnioskowanie wsadowe dla dowolnego dostawcy modeli.",
    "Status": "ok"
  },
  {
    "Id": 2,
    "Content": "## Install\n\nfenic supports Python `[3.10, 3.11, 3.12]`\n\n```bash\npip install fenic\n```\n\n### LLM Provider Setup\n\nfenic requires an API key from at least one LLM provider. Set the appropriate environment variable for your chosen provider:\n\n```bash\n# For OpenAI\nexport OPENAI_API_KEY=\"your-openai-api-key\"\n\n# For Anthropic\nexport ANTHROPIC_API_KEY=\"your-anthropic-api-key\"\n\n# For Google",
    "ContentSha": "QT2GWoHGnyfwnJxlfZAk0I5rpIsEfvGEhJD38oz6lCY=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "## Instalacja\n\nfenic obsługuje Pythona `[3.10, 3.11, 3.12]`\n\n```bash\npip install fenic\n```\n\n### Konfiguracja dostawcy LLM\n\nfenic wymaga klucza API od co najmniej jednego dostawcy LLM. Ustaw odpowiednią zmienną środowiskową dla wybranego dostawcy:\n\n```bash\n# Dla OpenAI\nexport OPENAI_API_KEY=\"twój-openai-api-key\"\n\n# Dla Anthropic\nexport ANTHROPIC_API_KEY=\"twój-anthropic-api-key\"\n\n# Dla Google",
    "Status": "ok"
  },
  {
    "Id": 3,
    "Content": "export GEMINI_API_KEY=\"your-google-api-key\"\n```\n\n## Quickstart\n\nThe fastest way to learn about fenic is by checking the examples.\n\nBelow is a quick list of the examples in this repo:\n\n| Example                                                                 | Description                                                                                                                         |\n| ----------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------- |\n| [Hello World!](examples/hello_world)                                    | Introduction to semantic extraction and classification using fenic's core operators through error log analysis.                     |\n| [Enrichment](examples/enrichment)                                       | Multi-stage DataFrames with template-based text extraction, joins, and LLM-powered transformations demonstrated via log enrichment. |\n| [Meeting Transcript Processing](examples/meeting_transcript_processing) | Native transcript parsing, Pydantic schema integration, and complex aggregations shown through meeting analysis.                    |\n| [News Analysis](examples/news_analysis)                                 | Analyze and extract insights from news articles using semantic operators and structured data processing.                            |\n| [Podcast Summarization](examples/podcast_summarization)                 | Process and summarize podcast transcripts with speaker-aware analysis and key point extraction.                                     |\n| [Semantic Join](examples/semantic_joins)                                | Instead of simple fuzzy matching, use fenic's powerful semantic join functionality to match data across tables.                     |\n| [Named Entity Recognition](examples/named_entity_recognition)           | Extract and classify named entities from text using semantic extraction and classification.                                         |\n| [Markdown Processing](examples/markdown_processing)                     | Process and transform markdown documents with structured data extraction and formatting.                                            |\n| [JSON Processing](examples/json_processing)                             | Handle complex JSON data structures with semantic operations and schema validation.                                                 |\n| [Feedback Clustering](examples/feedback_clustering)                     | Group and analyze feedback using semantic similarity and clustering operations.                                                     |\n| [Document Extraction](examples/document_extraction)                     | Extract structured information from various document formats using semantic operators.                                              |\n\n(Feel free to click any example above to jump right to its folder.)\n",
    "ContentSha": "RBvJ+qAaDZODC8rvu1sFp9QTE4SUhSKTTu/91HAxBRc=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "export GEMINI_API_KEY=\"your-google-api-key\"\n```\n\n## Szybki start\n\nNajszybszym sposobem na poznanie fenic jest przejrzenie przykładów.\n\nPoniżej znajduje się szybka lista przykładów dostępnych w tym repozytorium:\n\n| Przykład                                                                | Opis                                                                                                                                |\n| ----------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------- |\n| [Hello World!](examples/hello_world)                                    | Wprowadzenie do ekstrakcji semantycznej i klasyfikacji przy użyciu podstawowych operatorów fenic na przykładzie analizy logów błędów. |\n| [Enrichment](examples/enrichment)                                       | Wieloetapowe DataFrame’y z ekstrakcją tekstu na podstawie szablonów, łączeniem i transformacjami wspieranymi przez LLM, pokazane na przykładzie wzbogacania logów. |\n| [Przetwarzanie transkryptu spotkania](examples/meeting_transcript_processing) | Natywne parsowanie transkryptów, integracja schematów Pydantic oraz złożone agregacje przedstawione na przykładzie analizy spotkania. |\n| [Analiza wiadomości](examples/news_analysis)                            | Analizuj i wydobywaj wnioski z artykułów prasowych przy użyciu operatorów semantycznych i przetwarzania danych strukturalnych.      |\n| [Podsumowanie podcastu](examples/podcast_summarization)                 | Przetwarzaj i podsumowuj transkrypty podcastów z analizą z uwzględnieniem mówców oraz ekstrakcją kluczowych punktów.                |\n| [Łączenie semantyczne](examples/semantic_joins)                         | Zamiast prostego dopasowania rozmytego, użyj zaawansowanej funkcji łączenia semantycznego fenic do dopasowywania danych między tabelami. |\n| [Rozpoznawanie nazwanych jednostek](examples/named_entity_recognition)  | Wydobywaj i klasyfikuj nazwane jednostki z tekstu przy użyciu ekstrakcji semantycznej i klasyfikacji.                               |\n| [Przetwarzanie Markdown](examples/markdown_processing)                  | Przetwarzaj i transformuj dokumenty markdown poprzez strukturalną ekstrakcję danych i formatowanie.                                 |\n| [Przetwarzanie JSON](examples/json_processing)                          | Obsługuj złożone struktury danych JSON z operacjami semantycznymi i walidacją schematów.                                            |\n| [Grupowanie opinii](examples/feedback_clustering)                       | Grupuj i analizuj opinie przy użyciu semantycznego podobieństwa i operacji klastrowania.                                            |\n| [Ekstrakcja dokumentów](examples/document_extraction)                   | Wydobywaj strukturalne informacje z różnych formatów dokumentów przy użyciu operatorów semantycznych.                               |\n\n(Możesz kliknąć dowolny przykład powyżej, aby przejść bezpośrednio do odpowiedniego folderu.)\n",
    "Status": "ok"
  },
  {
    "Id": 4,
    "Content": "## Why use fenic?\n\nfenic is an opinionated, PySpark-inspired DataFrame framework for building production AI and agentic applications.\n\nUnlike traditional data tools retrofitted for LLMs, fenic's query engine is built from the ground up with inference in mind.\n\nTransform structured and unstructured data into insights using familiar DataFrame operations enhanced with semantic intelligence. With first-class support for markdown, transcripts, and semantic operators, plus efficient batch inference across any model provider.\n\nfenic brings the reliability of traditional data pipelines to AI workloads.\n\n### Key Features\n\n#### Purpose-Built for LLM Inference\n\n- Query engine designed from scratch for AI workloads, not retrofitted\n- Automatic batch optimization for API calls\n- Built-in retry logic and rate limiting\n- Token counting and cost tracking\n\n#### Semantic Operators as First-Class Citizens",
    "ContentSha": "POPTpr2d3zFT3V0X0/NRjmMCUTjlIPBHtMTVHIRsyfM=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "## Dlaczego używać fenic?\n\nfenic to opiniotwórczy, inspirowany PySpark framework DataFrame do budowania produkcyjnych aplikacji AI i agentowych.\n\nW przeciwieństwie do tradycyjnych narzędzi danych dostosowanych do LLM, silnik zapytań fenic został zbudowany od podstaw z myślą o wnioskowaniu.\n\nPrzekształcaj dane strukturalne i niestrukturalne w informacje za pomocą znanych operacji DataFrame, wzbogaconych o inteligencję semantyczną. Z natywną obsługą markdown, transkryptów i operatorów semantycznych oraz wydajnym wnioskowaniem wsadowym dla dowolnego dostawcy modeli.\n\nfenic wnosi niezawodność tradycyjnych potoków danych do obciążeń AI.\n\n### Kluczowe cechy\n\n#### Stworzony specjalnie do wnioskowania LLM\n\n- Silnik zapytań zaprojektowany od zera dla obciążeń AI, a nie dostosowywany\n- Automatyczna optymalizacja wsadowa dla wywołań API\n- Wbudowana logika ponawiania i ograniczania liczby żądań\n- Zliczanie tokenów i śledzenie kosztów\n\n#### Operatory semantyczne jako pełnoprawni uczestnicy",
    "Status": "ok"
  },
  {
    "Id": 5,
    "Content": "\n- `semantic.analyze_sentiment` - Built-in sentiment analysis\n- `semantic.classify` - Categorize text with few-shot examples\n- `semantic.extract` - Transform unstructured text into structured data with schemas\n- `semantic.group_by` - Group data by semantic similarity\n- `semantic.join` - Join DataFrames on meaning, not just values\n- `semantic.map` - Apply natural language transformations\n- `semantic.predicate` - Create predicates using natural language to filter rows\n- `semantic.reduce` - Aggregate grouped data with LLM operations\n\n#### Native Unstructured Data Support\n\nGoes beyond typical multimodal data types (audio, images) by creating specialized types for text-heavy workloads:\n\n- Markdown parsing and extraction as a first-class data type\n- Transcript processing (SRT, generic formats) with speaker and timestamp awareness\n- JSON manipulation with JQ expressions for nested data\n- Automatic text chunking with configurable overlap for long documents\n\n#### Production-Ready Infrastructure",
    "ContentSha": "NE5dPjdhTPxhAD1E+gcEg2tw/wEtQVkEuw1AGA1YwCQ=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "- `semantic.analyze_sentiment` - Wbudowana analiza sentymentu\n- `semantic.classify` - Kategoryzacja tekstu z użyciem kilku przykładów (few-shot)\n- `semantic.extract` - Przekształcanie nieustrukturyzowanego tekstu w dane strukturalne z użyciem schematów\n- `semantic.group_by` - Grupowanie danych według podobieństwa semantycznego\n- `semantic.join` - Łączenie DataFrame'ów na podstawie znaczenia, nie tylko wartości\n- `semantic.map` - Stosowanie transformacji języka naturalnego\n- `semantic.predicate` - Tworzenie predykatów za pomocą języka naturalnego do filtrowania wierszy\n- `semantic.reduce` - Agregowanie pogrupowanych danych za pomocą operacji LLM\n\n#### Nattywne wsparcie dla nieustrukturyzowanych danych\n\nWykracza poza typowe multimodalne typy danych (audio, obrazy), tworząc wyspecjalizowane typy dla obciążeń opartych głównie na tekście:\n\n- Parsowanie i ekstrakcja Markdown jako natywny typ danych\n- Przetwarzanie transkrypcji (SRT, formaty ogólne) z rozpoznawaniem mówcy i znaczników czasu\n- Manipulacja JSON z użyciem wyrażeń JQ dla danych zagnieżdżonych\n- Automatyczne dzielenie tekstu na fragmenty z konfigurowalną nakładką dla długich dokumentów\n\n#### Infrastruktura gotowa do produkcji",
    "Status": "ok"
  },
  {
    "Id": 6,
    "Content": "\n- Multi-provider support (OpenAI, Anthropic, Gemini)\n- Local and cloud execution backends\n- Comprehensive error handling and logging\n- Pydantic integration for type safety\n\n#### Familiar DataFrame API\n\n- PySpark-compatible operations\n- Lazy evaluation and query optimization\n- SQL support for complex queries\n- Seamless integration with existing data pipelines\n\n### Why DataFrames for LLM and Agentic Applications?\n\nAI and agentic applications are fundamentally pipelines and workflows - exactly what DataFrame APIs were designed to handle. Rather than reinventing patterns for data transformation, filtering, and aggregation, fenic leverages decades of proven engineering practices.\n\n#### Decoupled Architecture for Better Agents\n\nfenic creates a clear separation between heavy inference tasks and real-time agent interactions. By moving batch processing out of the agent runtime, you get:\n\n- More predictable and responsive agents\n- Better resource utilization with batched LLM calls\n- Cleaner separation between planning/orchestration and execution\n",
    "ContentSha": "mT0TcKmDXUG4vMCvQ5Zt2Hov+kI1MOWz6tDxxgD3BGY=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "- Wsparcie dla wielu dostawców (OpenAI, Anthropic, Gemini)\n- Lokalne i chmurowe backendy wykonawcze\n- Kompleksowa obsługa błędów i logowanie\n- Integracja z Pydantic dla bezpieczeństwa typów\n\n#### Znany interfejs API DataFrame\n\n- Operacje kompatybilne z PySpark\n- Leniva ewaluacja i optymalizacja zapytań\n- Obsługa SQL dla złożonych zapytań\n- Bezproblemowa integracja z istniejącymi potokami danych\n\n### Dlaczego DataFrames dla aplikacji LLM i agentowych?\n\nAplikacje AI i agentowe to fundamentalnie potoki i przepływy pracy – dokładnie to, do czego zaprojektowano API DataFrame. Zamiast wymyślać na nowo wzorce przekształcania, filtrowania i agregacji danych, fenic wykorzystuje dekady sprawdzonych praktyk inżynieryjnych.\n\n#### Rozdzielona architektura dla lepszych agentów\n\nfenic tworzy wyraźny podział między wymagającymi dużych zasobów zadaniami inferencyjnymi a interakcjami agentów w czasie rzeczywistym. Przenosząc przetwarzanie wsadowe poza środowisko agenta, zyskujesz:\n\n- Bardziej przewidywalnych i responsywnych agentów\n- Lepsze wykorzystanie zasobów dzięki wsadowym wywołaniom LLM\n- Czystszy podział pomiędzy planowaniem/orchestracją a wykonaniem",
    "Status": "ok"
  },
  {
    "Id": 7,
    "Content": "#### Built for All Engineers\n\nDataFrames aren't just for data practitioners. The fluent, composable API design makes it accessible to any engineer:\n\n- Chain operations naturally: `df.filter(...).semantic.group_by(...)`\n- Mix imperative and declarative styles seamlessly\n- Get started quickly with familiar patterns from pandas/PySpark or SQL\n\n## Support\n\nJoin our community on [Discord](https://discord.gg/GdqF3J7huR) where you can connect with other users, ask questions, and get help with your fenic projects. Our community is always happy to welcome newcomers!\n\nIf you find fenic useful, consider giving us a ⭐ at the top of this repository. Your support helps us grow and improve the framework for everyone!\n\n## Contributing\n\nWe welcome contributions of all kinds! Whether you're interested in writing code, improving documentation, testing features, or proposing new ideas, your help is valuable to us.\n\nFor developers planning to submit code changes, we encourage you to first open an issue to discuss your ideas before creating a Pull Request. This helps ensure alignment with the project's direction and prevents duplicate efforts.\n\nPlease refer to our [contribution guidelines](https://raw.githubusercontent.com/typedef-ai/fenic/main/CONTRIBUTING.md) for detailed information about the development process and project setup.\n",
    "ContentSha": "uskg5roWGwsGUjyK072Ea16WzdZZykGudJVeAy5e46I=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "#### Stworzone dla wszystkich inżynierów\n\nDataFrames nie są przeznaczone tylko dla specjalistów od danych. Przemyślany, składany interfejs API sprawia, że są dostępne dla każdego inżyniera:\n\n- Łańcuchowe operacje w naturalny sposób: `df.filter(...).semantic.group_by(...)`\n- Płynne łączenie stylów imperatywnego i deklaratywnego\n- Szybki start dzięki znanym wzorcom z pandas/PySpark lub SQL\n\n## Wsparcie\n\nDołącz do naszej społeczności na [Discordzie](https://discord.gg/GdqF3J7huR), gdzie możesz połączyć się z innymi użytkownikami, zadawać pytania i uzyskać pomoc przy swoich projektach fenic. Nasza społeczność zawsze chętnie wita nowych członków!\n\nJeśli uważasz, że fenic jest przydatny, rozważ zostawienie nam ⭐ na górze tego repozytorium. Twoje wsparcie pomaga nam rozwijać i ulepszać framework dla wszystkich!\n\n## Współtworzenie\n\nSerdecznie witamy wszelkie formy współpracy! Niezależnie od tego, czy chcesz pisać kod, ulepszać dokumentację, testować funkcje, czy proponować nowe pomysły — Twoja pomoc jest dla nas cenna.\n\nDla programistów planujących zgłaszać zmiany w kodzie zalecamy najpierw otworzyć zgłoszenie (issue), aby omówić swoje pomysły przed utworzeniem Pull Requesta. Pomaga to zapewnić zgodność z kierunkiem projektu i zapobiega dublowaniu wysiłków.\n\nProsimy zapoznać się z naszymi [wytycznymi dotyczącymi współtworzenia](https://raw.githubusercontent.com/typedef-ai/fenic/main/CONTRIBUTING.md), aby uzyskać szczegółowe informacje o procesie rozwoju i konfiguracji projektu.",
    "Status": "ok"
  }
]