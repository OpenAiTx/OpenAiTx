[
  {
    "Id": 1,
    "Content": "<!-- markdownlint-disable MD041 MD033 -->\n<div align=\"center\">\n    <picture>\n        <source media=\"(prefers-color-scheme: dark)\" srcset=\"docs/images/typedef-fenic-logo-dark.png\">\n        <img src=\"https://raw.githubusercontent.com/typedef-ai/fenic/main/docs/images/typedef-fenic-logo.png\" alt=\"fenic, by typedef\" width=\"90%\">\n    </picture>\n</div>\n\n# fenic: the dataframe (re)built for LLM inference\n\n[![PyPI version](https://img.shields.io/pypi/v/fenic.svg)](https://pypi.org/project/fenic/)\n[![Python versions](https://img.shields.io/pypi/pyversions/fenic.svg)](https://pypi.org/project/fenic/)\n[![License](https://img.shields.io/github/license/typedef-ai/fenic.svg)](https://github.com/typedef-ai/fenic/blob/main/LICENSE)\n[![Discord](https://img.shields.io/discord/1381706122322513952?label=Discord&logo=discord)](https://discord.gg/GdqF3J7huR)\n\n---\n\n## **Documentation**: [docs.fenic.ai](https://docs.fenic.ai/)\n\nfenic is an opinionated, PySpark-inspired DataFrame framework from typedef.ai for building AI and agentic applications. Transform unstructured and structured data into insights using familiar DataFrame operations enhanced with semantic intelligence. With first-class support for markdown, transcripts, and semantic operators, plus efficient batch inference across any model provider.\n",
    "ContentSha": "tmub1AxUb0Y4Al5Ltz67crbP453GMVUntyWUISmU7NQ=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "<!-- markdownlint-disable MD041 MD033 -->\n<div align=\"center\">\n    <picture>\n        <source media=\"(prefers-color-scheme: dark)\" srcset=\"docs/images/typedef-fenic-logo-dark.png\">\n        <img src=\"https://raw.githubusercontent.com/typedef-ai/fenic/main/docs/images/typedef-fenic-logo.png\" alt=\"fenic, by typedef\" width=\"90%\">\n    </picture>\n</div>\n\n# fenic: LLM çıkarımı için (yeniden) inşa edilen dataframe\n\n[![PyPI version](https://img.shields.io/pypi/v/fenic.svg)](https://pypi.org/project/fenic/)\n[![Python versions](https://img.shields.io/pypi/pyversions/fenic.svg)](https://pypi.org/project/fenic/)\n[![License](https://img.shields.io/github/license/typedef-ai/fenic.svg)](https://github.com/typedef-ai/fenic/blob/main/LICENSE)\n[![Discord](https://img.shields.io/discord/1381706122322513952?label=Discord&logo=discord)](https://discord.gg/GdqF3J7huR)\n\n---\n\n## **Dokümantasyon**: [docs.fenic.ai](https://docs.fenic.ai/)\n\nfenic, typedef.ai tarafından geliştirilen, PySpark'tan ilham alan, görüş bildiren bir DataFrame framework'üdür ve AI ile ajan temelli uygulamalar inşa etmek için tasarlanmıştır. Yapısal ve yapısal olmayan verileri, veri çerçevesi üzerinde alışık olduğunuz işlemleri semantik zekâ ile birleştirerek içgörüye dönüştürün. Markdown, transkriptler ve semantik operatörler için birinci sınıf destekle birlikte, herhangi bir model sağlayıcıda verimli toplu çıkarım imkânı sunar.",
    "Status": "ok"
  },
  {
    "Id": 2,
    "Content": "## Install\n\nfenic supports Python `[3.10, 3.11, 3.12]`\n\n```bash\npip install fenic\n```\n\n### LLM Provider Setup\n\nfenic requires an API key from at least one LLM provider. Set the appropriate environment variable for your chosen provider:\n\n```bash\n# For OpenAI\nexport OPENAI_API_KEY=\"your-openai-api-key\"\n\n# For Anthropic\nexport ANTHROPIC_API_KEY=\"your-anthropic-api-key\"\n\n# For Google",
    "ContentSha": "QT2GWoHGnyfwnJxlfZAk0I5rpIsEfvGEhJD38oz6lCY=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "## Kurulum\n\nfenic Python `[3.10, 3.11, 3.12]` sürümlerini destekler\n\n```bash\npip install fenic\n```\n\n### LLM Sağlayıcı Kurulumu\n\nfenic, en az bir LLM sağlayıcısından bir API anahtarı gerektirir. Seçtiğiniz sağlayıcı için uygun ortam değişkenini ayarlayın:\n\n```bash\n# OpenAI için\nexport OPENAI_API_KEY=\"openai-api-anahtarınız\"\n\n# Anthropic için\nexport ANTHROPIC_API_KEY=\"anthropic-api-anahtarınız\"\n\n# Google için",
    "Status": "ok"
  },
  {
    "Id": 3,
    "Content": "export GEMINI_API_KEY=\"your-google-api-key\"\n```\n\n## Quickstart\n\nThe fastest way to learn about fenic is by checking the examples.\n\nBelow is a quick list of the examples in this repo:\n\n| Example                                                                 | Description                                                                                                                         |\n| ----------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------- |\n| [Hello World!](examples/hello_world)                                    | Introduction to semantic extraction and classification using fenic's core operators through error log analysis.                     |\n| [Enrichment](examples/enrichment)                                       | Multi-stage DataFrames with template-based text extraction, joins, and LLM-powered transformations demonstrated via log enrichment. |\n| [Meeting Transcript Processing](examples/meeting_transcript_processing) | Native transcript parsing, Pydantic schema integration, and complex aggregations shown through meeting analysis.                    |\n| [News Analysis](examples/news_analysis)                                 | Analyze and extract insights from news articles using semantic operators and structured data processing.                            |\n| [Podcast Summarization](examples/podcast_summarization)                 | Process and summarize podcast transcripts with speaker-aware analysis and key point extraction.                                     |\n| [Semantic Join](examples/semantic_joins)                                | Instead of simple fuzzy matching, use fenic's powerful semantic join functionality to match data across tables.                     |\n| [Named Entity Recognition](examples/named_entity_recognition)           | Extract and classify named entities from text using semantic extraction and classification.                                         |\n| [Markdown Processing](examples/markdown_processing)                     | Process and transform markdown documents with structured data extraction and formatting.                                            |\n| [JSON Processing](examples/json_processing)                             | Handle complex JSON data structures with semantic operations and schema validation.                                                 |\n| [Feedback Clustering](examples/feedback_clustering)                     | Group and analyze feedback using semantic similarity and clustering operations.                                                     |\n| [Document Extraction](examples/document_extraction)                     | Extract structured information from various document formats using semantic operators.                                              |\n\n(Feel free to click any example above to jump right to its folder.)\n",
    "ContentSha": "RBvJ+qAaDZODC8rvu1sFp9QTE4SUhSKTTu/91HAxBRc=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "export GEMINI_API_KEY=\"your-google-api-key\"\n```\n\n## Hızlı Başlangıç\n\nFenic hakkında bilgi edinmenin en hızlı yolu, örneklere göz atmaktır.\n\nAşağıda bu repodaki örneklerin hızlı bir listesi bulunmaktadır:\n\n| Örnek                                                                  | Açıklama                                                                                                                            |\n| ---------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------- |\n| [Hello World!](examples/hello_world)                                   | Fenic'in temel operatörleriyle hata günlükleri üzerinden anlamsal çıkarım ve sınıflandırmaya giriş.                                |\n| [Enrichment](examples/enrichment)                                      | Şablon tabanlı metin çıkarımı, join işlemleri ve LLM destekli dönüşümlerin günlük zenginleştirme üzerinden gösterildiği çok aşamalı DataFrame'ler. |\n| [Toplantı Transkripti İşleme](examples/meeting_transcript_processing)  | Toplantı analiziyle yerel transkript ayrıştırma, Pydantic şeması entegrasyonu ve karmaşık toplulaştırma işlemleri.                  |\n| [Haber Analizi](examples/news_analysis)                                | Anlamsal operatörler ve yapılandırılmış veri işleme kullanarak haber makalelerinden içgörülerin analiz edilmesi ve çıkarılması.     |\n| [Podcast Özetleme](examples/podcast_summarization)                     | Konuşmacı farkındalığıyla podcast transkriptlerini işleyip özetleyin ve anahtar noktaları çıkarın.                                 |\n| [Anlamsal Join](examples/semantic_joins)                               | Basit benzerlik eşleştirmesi yerine fenic'in güçlü anlamsal join işlevini kullanarak tablolar arasında veri eşleştirin.            |\n| [Adlandırılmış Varlık Tanıma](examples/named_entity_recognition)       | Metinden adlandırılmış varlıkları anlamsal çıkarım ve sınıflandırma ile çıkarın ve sınıflandırın.                                   |\n| [Markdown İşleme](examples/markdown_processing)                        | Markdown belgelerini yapılandırılmış veri çıkarımı ve biçimlendirme ile işleyip dönüştürün.                                         |\n| [JSON İşleme](examples/json_processing)                                | Karmaşık JSON veri yapılarını anlamsal işlemler ve şema doğrulama ile yönetin.                                                     |\n| [Geri Bildirim Kümeleme](examples/feedback_clustering)                 | Anlamsal benzerlik ve kümeleme işlemleri kullanarak geri bildirimleri gruplayın ve analiz edin.                                    |\n| [Belge Çıkarımı](examples/document_extraction)                         | Anlamsal operatörler kullanarak çeşitli belge formatlarından yapılandırılmış bilgi çıkarın.                                        |\n\n(Yukarıdaki herhangi bir örneğe tıklayarak doğrudan ilgili klasöre gidebilirsiniz.)",
    "Status": "ok"
  },
  {
    "Id": 4,
    "Content": "## Why use fenic?\n\nfenic is an opinionated, PySpark-inspired DataFrame framework for building production AI and agentic applications.\n\nUnlike traditional data tools retrofitted for LLMs, fenic's query engine is built from the ground up with inference in mind.\n\nTransform structured and unstructured data into insights using familiar DataFrame operations enhanced with semantic intelligence. With first-class support for markdown, transcripts, and semantic operators, plus efficient batch inference across any model provider.\n\nfenic brings the reliability of traditional data pipelines to AI workloads.\n\n### Key Features\n\n#### Purpose-Built for LLM Inference\n\n- Query engine designed from scratch for AI workloads, not retrofitted\n- Automatic batch optimization for API calls\n- Built-in retry logic and rate limiting\n- Token counting and cost tracking\n\n#### Semantic Operators as First-Class Citizens",
    "ContentSha": "POPTpr2d3zFT3V0X0/NRjmMCUTjlIPBHtMTVHIRsyfM=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "## Neden fenic kullanmalı?\n\nfenic, üretim amaçlı AI ve ajan tabanlı uygulamalar oluşturmak için PySpark'tan ilham alan, görüş sahibi bir DataFrame framework'üdür.\n\nGeleneksel, LLM’ler için sonradan uyarlanmış veri araçlarının aksine, fenic’in sorgu motoru sıfırdan çıkarım (inference) göz önünde bulundurularak inşa edilmiştir.\n\nYapılandırılmış ve yapılandırılmamış verileri, semantik zekâ ile güçlendirilmiş, alışılmış DataFrame işlemleriyle içgörülere dönüştürün. Markdown, transkriptler ve semantik operatörler için birinci sınıf destek ile, herhangi bir model sağlayıcıda verimli toplu çıkarım (batch inference) imkanı sunar.\n\nfenic, geleneksel veri boru hatlarının güvenilirliğini AI iş yüklerine taşır.\n\n### Temel Özellikler\n\n#### LLM Çıkarımı İçin Özel Olarak Tasarlandı\n\n- AI iş yükleri için sıfırdan tasarlanmış sorgu motoru, sonradan uyarlanmış değildir\n- API çağrıları için otomatik toplu optimizasyon\n- Dahili yeniden deneme mantığı ve hız sınırlama\n- Token sayımı ve maliyet takibi\n\n#### Semantik Operatörler Birinci Sınıf Vatandaşlar Olarak",
    "Status": "ok"
  },
  {
    "Id": 5,
    "Content": "\n- `semantic.analyze_sentiment` - Built-in sentiment analysis\n- `semantic.classify` - Categorize text with few-shot examples\n- `semantic.extract` - Transform unstructured text into structured data with schemas\n- `semantic.group_by` - Group data by semantic similarity\n- `semantic.join` - Join DataFrames on meaning, not just values\n- `semantic.map` - Apply natural language transformations\n- `semantic.predicate` - Create predicates using natural language to filter rows\n- `semantic.reduce` - Aggregate grouped data with LLM operations\n\n#### Native Unstructured Data Support\n\nGoes beyond typical multimodal data types (audio, images) by creating specialized types for text-heavy workloads:\n\n- Markdown parsing and extraction as a first-class data type\n- Transcript processing (SRT, generic formats) with speaker and timestamp awareness\n- JSON manipulation with JQ expressions for nested data\n- Automatic text chunking with configurable overlap for long documents\n\n#### Production-Ready Infrastructure",
    "ContentSha": "NE5dPjdhTPxhAD1E+gcEg2tw/wEtQVkEuw1AGA1YwCQ=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "- `semantic.analyze_sentiment` - Yerleşik duygu analizi\n- `semantic.classify` - Az örnekli örneklerle metni kategorize etme\n- `semantic.extract` - Yapısız metni şemalarla yapılandırılmış veriye dönüştürme\n- `semantic.group_by` - Verileri anlamsal benzerliğe göre gruplandırma\n- `semantic.join` - DataFrame'leri sadece değerlerle değil, anlamla birleştirme\n- `semantic.map` - Doğal dil dönüşümleri uygulama\n- `semantic.predicate` - Satırları filtrelemek için doğal dil kullanarak koşullar oluşturma\n- `semantic.reduce` - Gruplandırılmış verileri LLM işlemleriyle toplama\n\n#### Yerel Yapısız Veri Desteği\n\nTipik çok modlu veri türlerinin (ses, görseller) ötesine geçerek, metin ağırlıklı iş yükleri için özel türler oluşturur:\n\n- Birinci sınıf bir veri türü olarak Markdown ayrıştırma ve çıkarımı\n- Konuşmacı ve zaman damgası farkındalığı ile transkript işleme (SRT, genel formatlar)\n- İç içe veriler için JQ ifadeleriyle JSON işleme\n- Uzun belgeler için yapılandırılabilir örtüşme ile otomatik metin parçalama\n\n#### Üretime Hazır Altyapı",
    "Status": "ok"
  },
  {
    "Id": 6,
    "Content": "\n- Multi-provider support (OpenAI, Anthropic, Gemini)\n- Local and cloud execution backends\n- Comprehensive error handling and logging\n- Pydantic integration for type safety\n\n#### Familiar DataFrame API\n\n- PySpark-compatible operations\n- Lazy evaluation and query optimization\n- SQL support for complex queries\n- Seamless integration with existing data pipelines\n\n### Why DataFrames for LLM and Agentic Applications?\n\nAI and agentic applications are fundamentally pipelines and workflows - exactly what DataFrame APIs were designed to handle. Rather than reinventing patterns for data transformation, filtering, and aggregation, fenic leverages decades of proven engineering practices.\n\n#### Decoupled Architecture for Better Agents\n\nfenic creates a clear separation between heavy inference tasks and real-time agent interactions. By moving batch processing out of the agent runtime, you get:\n\n- More predictable and responsive agents\n- Better resource utilization with batched LLM calls\n- Cleaner separation between planning/orchestration and execution\n",
    "ContentSha": "mT0TcKmDXUG4vMCvQ5Zt2Hov+kI1MOWz6tDxxgD3BGY=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "- Çoklu sağlayıcı desteği (OpenAI, Anthropic, Gemini)\n- Yerel ve bulut tabanlı yürütme altyapıları\n- Kapsamlı hata yönetimi ve günlükleme\n- Tür güvenliği için Pydantic entegrasyonu\n\n#### Tanıdık DataFrame API’si\n\n- PySpark ile uyumlu işlemler\n- Tembel değerlendirme ve sorgu optimizasyonu\n- Karmaşık sorgular için SQL desteği\n- Mevcut veri hatlarıyla sorunsuz entegrasyon\n\n### Neden LLM ve Ajanik Uygulamalar için DataFrame’ler?\n\nYapay zeka ve ajanik uygulamalar temelde ardışık düzenler ve iş akışlarıdır — tam olarak DataFrame API’lerinin yönetmek için tasarlandığı şey. Veri dönüştürme, filtreleme ve toplama için kalıpları yeniden icat etmek yerine, fenic onlarca yıllık kanıtlanmış mühendislik uygulamalarından yararlanır.\n\n#### Daha İyi Ajanlar İçin Ayrık Mimariler\n\nfenic, ağır çıkarım görevleri ile gerçek zamanlı ajan etkileşimleri arasında net bir ayrım oluşturur. Toplu işlemeyi ajan çalışma zamanının dışına taşıyarak şunları elde edersiniz:\n\n- Daha öngörülebilir ve duyarlı ajanlar\n- Toplu LLM çağrılarıyla daha iyi kaynak kullanımı\n- Planlama/orkestrasyon ile yürütme arasında daha temiz bir ayrım",
    "Status": "ok"
  },
  {
    "Id": 7,
    "Content": "#### Built for All Engineers\n\nDataFrames aren't just for data practitioners. The fluent, composable API design makes it accessible to any engineer:\n\n- Chain operations naturally: `df.filter(...).semantic.group_by(...)`\n- Mix imperative and declarative styles seamlessly\n- Get started quickly with familiar patterns from pandas/PySpark or SQL\n\n## Support\n\nJoin our community on [Discord](https://discord.gg/GdqF3J7huR) where you can connect with other users, ask questions, and get help with your fenic projects. Our community is always happy to welcome newcomers!\n\nIf you find fenic useful, consider giving us a ⭐ at the top of this repository. Your support helps us grow and improve the framework for everyone!\n\n## Contributing\n\nWe welcome contributions of all kinds! Whether you're interested in writing code, improving documentation, testing features, or proposing new ideas, your help is valuable to us.\n\nFor developers planning to submit code changes, we encourage you to first open an issue to discuss your ideas before creating a Pull Request. This helps ensure alignment with the project's direction and prevents duplicate efforts.\n\nPlease refer to our [contribution guidelines](https://raw.githubusercontent.com/typedef-ai/fenic/main/CONTRIBUTING.md) for detailed information about the development process and project setup.\n",
    "ContentSha": "uskg5roWGwsGUjyK072Ea16WzdZZykGudJVeAy5e46I=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "#### Tüm Mühendisler için Tasarlandı\n\nDataFrame'ler sadece veri uygulayıcıları için değildir. Akıcı ve bileşenlere ayrılabilir API tasarımı, her mühendisin erişebileceği şekilde sunulmuştur:\n\n- İşlemleri doğal olarak zincirleyin: `df.filter(...).semantic.group_by(...)`\n- İmperatif ve deklaratif stilleri sorunsuzca birleştirin\n- pandas/PySpark veya SQL'den tanıdık kalıplarla hızlıca başlayın\n\n## Destek\n\n[Discord](https://discord.gg/GdqF3J7huR) topluluğumuza katılarak diğer kullanıcılarla bağlantı kurabilir, sorular sorabilir ve fenic projelerinizde yardım alabilirsiniz. Topluluğumuz yeni gelenleri her zaman memnuniyetle karşılar!\n\nEğer fenic'i faydalı buluyorsanız, bu depoda en üstte bir ⭐ vermeyi düşünebilirsiniz. Desteğiniz, framework'ü herkes için büyütmemize ve geliştirmemize yardımcı olur!\n\n## Katkıda Bulunma\n\nHer türlü katkıya açığız! Kod yazmak, dokümantasyonu geliştirmek, özellikleri test etmek veya yeni fikirler önermekle ilgileniyorsanız, yardımınız bizim için değerlidir.\n\nKod değişiklikleri yapmayı planlayan geliştiricilerin, Pull Request oluşturmadan önce fikirlerini tartışmak üzere bir issue açmalarını öneririz. Bu, projenin yönüyle uyumun sağlanmasına ve yinelenen çabaların önlenmesine yardımcı olur.\n\nGeliştirme süreci ve proje kurulumu hakkında detaylı bilgi için lütfen [katkı yönergelerimize](https://raw.githubusercontent.com/typedef-ai/fenic/main/CONTRIBUTING.md) başvurun.",
    "Status": "ok"
  }
]