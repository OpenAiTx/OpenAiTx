[
  {
    "Id": 1,
    "Content": "<!-- markdownlint-disable MD041 MD033 -->\n<div align=\"center\">\n    <picture>\n        <source media=\"(prefers-color-scheme: dark)\" srcset=\"docs/images/typedef-fenic-logo-dark.png\">\n        <img src=\"https://raw.githubusercontent.com/typedef-ai/fenic/main/docs/images/typedef-fenic-logo.png\" alt=\"fenic, by typedef\" width=\"90%\">\n    </picture>\n</div>\n\n# fenic: the dataframe (re)built for LLM inference\n\n[![PyPI version](https://img.shields.io/pypi/v/fenic.svg)](https://pypi.org/project/fenic/)\n[![Python versions](https://img.shields.io/pypi/pyversions/fenic.svg)](https://pypi.org/project/fenic/)\n[![License](https://img.shields.io/github/license/typedef-ai/fenic.svg)](https://github.com/typedef-ai/fenic/blob/main/LICENSE)\n[![Discord](https://img.shields.io/discord/1381706122322513952?label=Discord&logo=discord)](https://discord.gg/GdqF3J7huR)\n\n---\n\n## **Documentation**: [docs.fenic.ai](https://docs.fenic.ai/)\n\nfenic is an opinionated, PySpark-inspired DataFrame framework from typedef.ai for building AI and agentic applications. Transform unstructured and structured data into insights using familiar DataFrame operations enhanced with semantic intelligence. With first-class support for markdown, transcripts, and semantic operators, plus efficient batch inference across any model provider.\n",
    "ContentSha": "tmub1AxUb0Y4Al5Ltz67crbP453GMVUntyWUISmU7NQ=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "<!-- markdownlint-disable MD041 MD033 -->\n<div align=\"center\">\n    <picture>\n        <source media=\"(prefers-color-scheme: dark)\" srcset=\"docs/images/typedef-fenic-logo-dark.png\">\n        <img src=\"https://raw.githubusercontent.com/typedef-ai/fenic/main/docs/images/typedef-fenic-logo.png\" alt=\"fenic, by typedef\" width=\"90%\">\n    </picture>\n</div>\n\n# fenic: إطار بيانات (أعيد بناؤه) لاستدلال نماذج اللغة الكبيرة\n\n[![PyPI version](https://img.shields.io/pypi/v/fenic.svg)](https://pypi.org/project/fenic/)\n[![Python versions](https://img.shields.io/pypi/pyversions/fenic.svg)](https://pypi.org/project/fenic/)\n[![License](https://img.shields.io/github/license/typedef-ai/fenic.svg)](https://github.com/typedef-ai/fenic/blob/main/LICENSE)\n[![Discord](https://img.shields.io/discord/1381706122322513952?label=Discord&logo=discord)](https://discord.gg/GdqF3J7huR)\n\n---\n\n## **التوثيق**: [docs.fenic.ai](https://docs.fenic.ai/)\n\nfenic هو إطار بيانات مستوحى من PySpark مقدم من typedef.ai لتطوير تطبيقات الذكاء الاصطناعي والتطبيقات الوكيلية. حوّل البيانات غير المهيكلة والمهيكلة إلى رؤى باستخدام عمليات إطار البيانات المألوفة والمعززة بالذكاء الدلالي. مع دعم متكامل للماركداون، والنصوص، والعوامل الدلالية، بالإضافة إلى الاستدلال الدفعي الفعال عبر أي مزود نماذج.",
    "Status": "ok"
  },
  {
    "Id": 2,
    "Content": "## Install\n\nfenic supports Python `[3.10, 3.11, 3.12]`\n\n```bash\npip install fenic\n```\n\n### LLM Provider Setup\n\nfenic requires an API key from at least one LLM provider. Set the appropriate environment variable for your chosen provider:\n\n```bash\n# For OpenAI\nexport OPENAI_API_KEY=\"your-openai-api-key\"\n\n# For Anthropic\nexport ANTHROPIC_API_KEY=\"your-anthropic-api-key\"\n\n# For Google",
    "ContentSha": "QT2GWoHGnyfwnJxlfZAk0I5rpIsEfvGEhJD38oz6lCY=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "## التثبيت\n\nيدعم fenic بايثون `[3.10, 3.11, 3.12]`\n\n```bash\npip install fenic\n```\n\n### إعداد مزود LLM\n\nيتطلب fenic مفتاح API من مزود LLM واحد على الأقل. قم بتعيين متغير البيئة المناسب لمزود الخدمة الذي اخترته:\n\n```bash\n# لـ OpenAI\nexport OPENAI_API_KEY=\"your-openai-api-key\"\n\n# لـ Anthropic\nexport ANTHROPIC_API_KEY=\"your-anthropic-api-key\"\n\n# لـ Google",
    "Status": "ok"
  },
  {
    "Id": 3,
    "Content": "export GEMINI_API_KEY=\"your-google-api-key\"\n```\n\n## Quickstart\n\nThe fastest way to learn about fenic is by checking the examples.\n\nBelow is a quick list of the examples in this repo:\n\n| Example                                                                 | Description                                                                                                                         |\n| ----------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------- |\n| [Hello World!](examples/hello_world)                                    | Introduction to semantic extraction and classification using fenic's core operators through error log analysis.                     |\n| [Enrichment](examples/enrichment)                                       | Multi-stage DataFrames with template-based text extraction, joins, and LLM-powered transformations demonstrated via log enrichment. |\n| [Meeting Transcript Processing](examples/meeting_transcript_processing) | Native transcript parsing, Pydantic schema integration, and complex aggregations shown through meeting analysis.                    |\n| [News Analysis](examples/news_analysis)                                 | Analyze and extract insights from news articles using semantic operators and structured data processing.                            |\n| [Podcast Summarization](examples/podcast_summarization)                 | Process and summarize podcast transcripts with speaker-aware analysis and key point extraction.                                     |\n| [Semantic Join](examples/semantic_joins)                                | Instead of simple fuzzy matching, use fenic's powerful semantic join functionality to match data across tables.                     |\n| [Named Entity Recognition](examples/named_entity_recognition)           | Extract and classify named entities from text using semantic extraction and classification.                                         |\n| [Markdown Processing](examples/markdown_processing)                     | Process and transform markdown documents with structured data extraction and formatting.                                            |\n| [JSON Processing](examples/json_processing)                             | Handle complex JSON data structures with semantic operations and schema validation.                                                 |\n| [Feedback Clustering](examples/feedback_clustering)                     | Group and analyze feedback using semantic similarity and clustering operations.                                                     |\n| [Document Extraction](examples/document_extraction)                     | Extract structured information from various document formats using semantic operators.                                              |\n\n(Feel free to click any example above to jump right to its folder.)\n",
    "ContentSha": "RBvJ+qAaDZODC8rvu1sFp9QTE4SUhSKTTu/91HAxBRc=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "export GEMINI_API_KEY=\"your-google-api-key\"\n```\n\n## البدء السريع\n\nأسرع طريقة للتعرف على fenic هي من خلال مراجعة الأمثلة.\n\nفيما يلي قائمة سريعة بالأمثلة الموجودة في هذا المستودع:\n\n| المثال                                                                 | الوصف                                                                                                                         |\n| ---------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------- |\n| [Hello World!](examples/hello_world)                                   | مقدمة لاستخراج وتصنيف المعنى باستخدام المشغلين الأساسيين في fenic من خلال تحليل سجل الأخطاء.                                  |\n| [Enrichment](examples/enrichment)                                      | DataFrames متعددة المراحل مع استخراج نصوص معتمد على القوالب، وعمليات ربط، وتحويلات مدعومة بنماذج LLM موضحة عبر إثراء السجلات. |\n| [معالجة نصوص الاجتماعات](examples/meeting_transcript_processing)       | تحليل النصوص الأصلية، تكامل مخطط Pydantic، وتجميعات معقدة معروضة من خلال تحليل الاجتماعات.                                 |\n| [تحليل الأخبار](examples/news_analysis)                               | تحليل واستخلاص الرؤى من المقالات الإخبارية باستخدام المشغلين الدلاليين ومعالجة البيانات المنظمة.                              |\n| [تلخيص البودكاست](examples/podcast_summarization)                     | معالجة وتلخيص نصوص البودكاست مع تحليل واعٍ للمتحدث واستخلاص النقاط الرئيسية.                                                 |\n| [الربط الدلالي](examples/semantic_joins)                               | بدلاً من المطابقة التقريبية البسيطة، استخدم إمكانيات الربط الدلالي القوية في fenic لمطابقة البيانات عبر الجداول.             |\n| [التعرف على الكيانات المسماة](examples/named_entity_recognition)       | استخراج وتصنيف الكيانات المسماة من النصوص باستخدام الاستخراج والتصنيف الدلالي.                                              |\n| [معالجة الماركداون](examples/markdown_processing)                      | معالجة وتحويل مستندات الماركداون مع استخراج بيانات منظمة وتنسيقها.                                                           |\n| [معالجة JSON](examples/json_processing)                                | التعامل مع هياكل بيانات JSON المعقدة باستخدام العمليات الدلالية والتحقق من صحة المخطط.                                        |\n| [تجميع الملاحظات](examples/feedback_clustering)                        | تجميع وتحليل الملاحظات باستخدام التشابه الدلالي وعمليات التجميع.                                                              |\n| [استخراج المستندات](examples/document_extraction)                      | استخراج المعلومات المنظمة من صيغ مستندات متنوعة باستخدام المشغلين الدلاليين.                                                |\n\n(يمكنك النقر على أي مثال أعلاه للانتقال مباشرةً إلى مجلد المثال.)",
    "Status": "ok"
  },
  {
    "Id": 4,
    "Content": "## Why use fenic?\n\nfenic is an opinionated, PySpark-inspired DataFrame framework for building production AI and agentic applications.\n\nUnlike traditional data tools retrofitted for LLMs, fenic's query engine is built from the ground up with inference in mind.\n\nTransform structured and unstructured data into insights using familiar DataFrame operations enhanced with semantic intelligence. With first-class support for markdown, transcripts, and semantic operators, plus efficient batch inference across any model provider.\n\nfenic brings the reliability of traditional data pipelines to AI workloads.\n\n### Key Features\n\n#### Purpose-Built for LLM Inference\n\n- Query engine designed from scratch for AI workloads, not retrofitted\n- Automatic batch optimization for API calls\n- Built-in retry logic and rate limiting\n- Token counting and cost tracking\n\n#### Semantic Operators as First-Class Citizens",
    "ContentSha": "POPTpr2d3zFT3V0X0/NRjmMCUTjlIPBHtMTVHIRsyfM=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "## لماذا تستخدم fenic؟\n\nfenic هو إطار عمل DataFrame مستوحى من PySpark ومُعد خصيصًا لبناء تطبيقات الذكاء الاصطناعي والتطبيقات الوكيلة في بيئات الإنتاج.\n\nعلى عكس أدوات البيانات التقليدية التي تم تعديلها لتناسب LLMs، تم بناء محرك الاستعلام في fenic من الصفر مع وضع الاستدلال في الاعتبار.\n\nحوّل البيانات الهيكلية وغير الهيكلية إلى رؤى باستخدام عمليات DataFrame المألوفة والمعززة بالذكاء الدلالي. مع دعم من الدرجة الأولى للماركداون، والنصوص، والمشغلين الدلاليين، بالإضافة إلى الاستدلال الدُفعي الفعّال عبر أي مزود نموذج.\n\nيقدم fenic موثوقية خطوط أنابيب البيانات التقليدية إلى أعباء عمل الذكاء الاصطناعي.\n\n### الميزات الرئيسية\n\n#### مصمم خصيصًا لاستدلال LLM\n\n- محرك استعلام مصمم من الصفر لأعباء عمل الذكاء الاصطناعي، وليس معدلًا\n- تحسين دُفعي تلقائي لمكالمات واجهة برمجة التطبيقات\n- منطق إعادة المحاولة المدمج وتحديد المعدل\n- عدّ الرموز وتتبع التكاليف\n\n#### المشغلون الدلاليون كمكونات أساسية",
    "Status": "ok"
  },
  {
    "Id": 5,
    "Content": "\n- `semantic.analyze_sentiment` - Built-in sentiment analysis\n- `semantic.classify` - Categorize text with few-shot examples\n- `semantic.extract` - Transform unstructured text into structured data with schemas\n- `semantic.group_by` - Group data by semantic similarity\n- `semantic.join` - Join DataFrames on meaning, not just values\n- `semantic.map` - Apply natural language transformations\n- `semantic.predicate` - Create predicates using natural language to filter rows\n- `semantic.reduce` - Aggregate grouped data with LLM operations\n\n#### Native Unstructured Data Support\n\nGoes beyond typical multimodal data types (audio, images) by creating specialized types for text-heavy workloads:\n\n- Markdown parsing and extraction as a first-class data type\n- Transcript processing (SRT, generic formats) with speaker and timestamp awareness\n- JSON manipulation with JQ expressions for nested data\n- Automatic text chunking with configurable overlap for long documents\n\n#### Production-Ready Infrastructure",
    "ContentSha": "NE5dPjdhTPxhAD1E+gcEg2tw/wEtQVkEuw1AGA1YwCQ=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "- `semantic.analyze_sentiment` - تحليل المشاعر المدمج\n- `semantic.classify` - تصنيف النص باستخدام أمثلة قليلة\n- `semantic.extract` - تحويل النص غير المنظم إلى بيانات منظمة باستخدام المخططات\n- `semantic.group_by` - تجميع البيانات حسب التشابه الدلالي\n- `semantic.join` - دمج إطارات البيانات بناءً على المعنى، وليس القيم فقط\n- `semantic.map` - تطبيق التحويلات باستخدام اللغة الطبيعية\n- `semantic.predicate` - إنشاء شروط باستخدام اللغة الطبيعية لتصفية الصفوف\n- `semantic.reduce` - تجميع البيانات المجمعة باستخدام عمليات النماذج اللغوية الكبيرة\n\n#### دعم البيانات غير المنظمة بشكل أصلي\n\nيتجاوز أنواع البيانات متعددة الوسائط المعتادة (الصوت، الصور) من خلال إنشاء أنواع متخصصة للأعمال التي تعتمد بشكل كبير على النصوص:\n\n- تحليل واستخراج Markdown كنوع بيانات من الدرجة الأولى\n- معالجة النصوص المنقولة (SRT، وصيغ عامة) مع إدراك المتحدث والطابع الزمني\n- معالجة JSON بتعابير JQ للبيانات المتداخلة\n- تقسيم النص تلقائيًا مع إمكانية ضبط التداخل للوثائق الطويلة\n\n#### بنية تحتية جاهزة للإنتاج",
    "Status": "ok"
  },
  {
    "Id": 6,
    "Content": "\n- Multi-provider support (OpenAI, Anthropic, Gemini)\n- Local and cloud execution backends\n- Comprehensive error handling and logging\n- Pydantic integration for type safety\n\n#### Familiar DataFrame API\n\n- PySpark-compatible operations\n- Lazy evaluation and query optimization\n- SQL support for complex queries\n- Seamless integration with existing data pipelines\n\n### Why DataFrames for LLM and Agentic Applications?\n\nAI and agentic applications are fundamentally pipelines and workflows - exactly what DataFrame APIs were designed to handle. Rather than reinventing patterns for data transformation, filtering, and aggregation, fenic leverages decades of proven engineering practices.\n\n#### Decoupled Architecture for Better Agents\n\nfenic creates a clear separation between heavy inference tasks and real-time agent interactions. By moving batch processing out of the agent runtime, you get:\n\n- More predictable and responsive agents\n- Better resource utilization with batched LLM calls\n- Cleaner separation between planning/orchestration and execution\n",
    "ContentSha": "mT0TcKmDXUG4vMCvQ5Zt2Hov+kI1MOWz6tDxxgD3BGY=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "- دعم متعدد المزودين (OpenAI، Anthropic، Gemini)\n- واجهات تنفيذ محلية وسحابية\n- معالجة شاملة للأخطاء وتسجيل السجلات\n- تكامل مع Pydantic لضمان سلامة الأنواع\n\n#### واجهة بيانات مألوفة (DataFrame API)\n\n- عمليات متوافقة مع PySpark\n- تقييم كسول وتحسين الاستعلامات\n- دعم SQL للاستعلامات المعقدة\n- تكامل سلس مع خطوط أنابيب البيانات القائمة\n\n### لماذا DataFrames لتطبيقات LLM والتطبيقات الوكيلة؟\n\nتطبيقات الذكاء الاصطناعي والتطبيقات الوكيلة هي في الأساس خطوط أنابيب وتدفقات عمل - وهذا بالضبط ما صُممت واجهات DataFrame للتعامل معه. بدلاً من إعادة ابتكار أنماط تحويل البيانات، والتصفية، والتجميع، تستفيد fenic من عقود من الممارسات الهندسية المثبتة.\n\n#### بنية مفصولة لمزيد من الوكلاء فعالية\n\nتخلق fenic فصلًا واضحًا بين مهام الاستدلال الثقيلة وتفاعلات الوكيل في الوقت الفعلي. من خلال نقل المعالجة الدُفعية خارج وقت تشغيل الوكيل، تحصل على:\n\n- وكلاء أكثر قابلية للتنبؤ واستجابة\n- استخدام أفضل للموارد مع استدعاءات LLM مجمّعة\n- فصل أوضح بين التخطيط/التنسيق والتنفيذ",
    "Status": "ok"
  },
  {
    "Id": 7,
    "Content": "#### Built for All Engineers\n\nDataFrames aren't just for data practitioners. The fluent, composable API design makes it accessible to any engineer:\n\n- Chain operations naturally: `df.filter(...).semantic.group_by(...)`\n- Mix imperative and declarative styles seamlessly\n- Get started quickly with familiar patterns from pandas/PySpark or SQL\n\n## Support\n\nJoin our community on [Discord](https://discord.gg/GdqF3J7huR) where you can connect with other users, ask questions, and get help with your fenic projects. Our community is always happy to welcome newcomers!\n\nIf you find fenic useful, consider giving us a ⭐ at the top of this repository. Your support helps us grow and improve the framework for everyone!\n\n## Contributing\n\nWe welcome contributions of all kinds! Whether you're interested in writing code, improving documentation, testing features, or proposing new ideas, your help is valuable to us.\n\nFor developers planning to submit code changes, we encourage you to first open an issue to discuss your ideas before creating a Pull Request. This helps ensure alignment with the project's direction and prevents duplicate efforts.\n\nPlease refer to our [contribution guidelines](https://raw.githubusercontent.com/typedef-ai/fenic/main/CONTRIBUTING.md) for detailed information about the development process and project setup.\n",
    "ContentSha": "uskg5roWGwsGUjyK072Ea16WzdZZykGudJVeAy5e46I=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "#### صُممت لجميع المهندسين\n\nإطارات البيانات ليست مخصصة فقط لممارسي البيانات. يتيح التصميم السلس وقابلية التركيب لواجهة برمجة التطبيقات الوصول إليها لأي مهندس:\n\n- ربط العمليات بشكل طبيعي: `df.filter(...).semantic.group_by(...)`\n- المزج بين الأساليب الإجرائية والتصريحية بسلاسة\n- البدء بسرعة باستخدام أنماط مألوفة من pandas/PySpark أو SQL\n\n## الدعم\n\nانضم إلى مجتمعنا على [ديسكورد](https://discord.gg/GdqF3J7huR) حيث يمكنك التواصل مع مستخدمين آخرين، وطرح الأسئلة، والحصول على المساعدة في مشاريع fenic الخاصة بك. مجتمعنا دائماً سعيد بالترحيب بالقادمين الجدد!\n\nإذا وجدت fenic مفيداً، يرجى التفكير في منحنا ⭐ في أعلى هذا المستودع. دعمك يساعدنا على النمو وتحسين الإطار للجميع!\n\n## المساهمة\n\nنرحب بجميع أنواع المساهمات! سواء كنت مهتماً بكتابة الشيفرة، أو تحسين التوثيق، أو اختبار الميزات، أو اقتراح أفكار جديدة، فإن مساعدتك قيمة بالنسبة لنا.\n\nبالنسبة للمطورين الذين يخططون لتقديم تغييرات برمجية، نشجعك على فتح قضية أولاً لمناقشة أفكارك قبل إنشاء طلب سحب. هذا يساعد على ضمان التوافق مع توجه المشروع ويمنع الجهود المكررة.\n\nيرجى الرجوع إلى [إرشادات المساهمة](https://raw.githubusercontent.com/typedef-ai/fenic/main/CONTRIBUTING.md) الخاصة بنا لمزيد من المعلومات التفصيلية حول عملية التطوير وإعداد المشروع.",
    "Status": "ok"
  }
]