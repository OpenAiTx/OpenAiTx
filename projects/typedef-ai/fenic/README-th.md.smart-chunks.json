[
  {
    "Id": 1,
    "Content": "<!-- markdownlint-disable MD041 MD033 -->\n<div align=\"center\">\n    <picture>\n        <source media=\"(prefers-color-scheme: dark)\" srcset=\"docs/images/typedef-fenic-logo-dark.png\">\n        <img src=\"https://raw.githubusercontent.com/typedef-ai/fenic/main/docs/images/typedef-fenic-logo.png\" alt=\"fenic, by typedef\" width=\"90%\">\n    </picture>\n</div>\n\n# fenic: the dataframe (re)built for LLM inference\n\n[![PyPI version](https://img.shields.io/pypi/v/fenic.svg)](https://pypi.org/project/fenic/)\n[![Python versions](https://img.shields.io/pypi/pyversions/fenic.svg)](https://pypi.org/project/fenic/)\n[![License](https://img.shields.io/github/license/typedef-ai/fenic.svg)](https://github.com/typedef-ai/fenic/blob/main/LICENSE)\n[![Discord](https://img.shields.io/discord/1381706122322513952?label=Discord&logo=discord)](https://discord.gg/GdqF3J7huR)\n\n---\n\n## **Documentation**: [docs.fenic.ai](https://docs.fenic.ai/)\n\nfenic is an opinionated, PySpark-inspired DataFrame framework from typedef.ai for building AI and agentic applications. Transform unstructured and structured data into insights using familiar DataFrame operations enhanced with semantic intelligence. With first-class support for markdown, transcripts, and semantic operators, plus efficient batch inference across any model provider.\n",
    "ContentSha": "tmub1AxUb0Y4Al5Ltz67crbP453GMVUntyWUISmU7NQ=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "<!-- markdownlint-disable MD041 MD033 -->\n<div align=\"center\">\n    <picture>\n        <source media=\"(prefers-color-scheme: dark)\" srcset=\"docs/images/typedef-fenic-logo-dark.png\">\n        <img src=\"https://raw.githubusercontent.com/typedef-ai/fenic/main/docs/images/typedef-fenic-logo.png\" alt=\"fenic, by typedef\" width=\"90%\">\n    </picture>\n</div>\n\n# fenic: dataframe ที่ (ถูก) สร้างใหม่เพื่อการ inference ของ LLM\n\n[![PyPI version](https://img.shields.io/pypi/v/fenic.svg)](https://pypi.org/project/fenic/)\n[![Python versions](https://img.shields.io/pypi/pyversions/fenic.svg)](https://pypi.org/project/fenic/)\n[![License](https://img.shields.io/github/license/typedef-ai/fenic.svg)](https://github.com/typedef-ai/fenic/blob/main/LICENSE)\n[![Discord](https://img.shields.io/discord/1381706122322513952?label=Discord&logo=discord)](https://discord.gg/GdqF3J7huR)\n\n---\n\n## **เอกสารประกอบ**: [docs.fenic.ai](https://docs.fenic.ai/)\n\nfenic คือเฟรมเวิร์ก DataFrame ที่ได้รับแรงบันดาลใจจาก PySpark จาก typedef.ai สำหรับการสร้างแอปพลิเคชัน AI และ agentic เปลี่ยนข้อมูลที่ไม่มีโครงสร้างและข้อมูลที่มีโครงสร้างให้เป็นข้อมูลเชิงลึก ด้วยการดำเนินการ DataFrame ที่คุ้นเคยซึ่งเพิ่มศักยภาพด้วยความฉลาดเชิงความหมาย รองรับ markdown, บทถอดเสียง และโอเปอเรเตอร์เชิงความหมายอย่างเต็มรูปแบบ รวมถึงการ inference แบบ batch ที่มีประสิทธิภาพกับผู้ให้บริการโมเดลใด ๆ",
    "Status": "ok"
  },
  {
    "Id": 2,
    "Content": "## Install\n\nfenic supports Python `[3.10, 3.11, 3.12]`\n\n```bash\npip install fenic\n```\n\n### LLM Provider Setup\n\nfenic requires an API key from at least one LLM provider. Set the appropriate environment variable for your chosen provider:\n\n```bash\n# For OpenAI\nexport OPENAI_API_KEY=\"your-openai-api-key\"\n\n# For Anthropic\nexport ANTHROPIC_API_KEY=\"your-anthropic-api-key\"\n\n# For Google",
    "ContentSha": "QT2GWoHGnyfwnJxlfZAk0I5rpIsEfvGEhJD38oz6lCY=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "## การติดตั้ง\n\nfenic รองรับ Python `[3.10, 3.11, 3.12]`\n\n```bash\npip install fenic\n```\n\n### การตั้งค่า LLM Provider\n\nfenic ต้องการคีย์ API จากผู้ให้บริการ LLM อย่างน้อยหนึ่งราย ตั้งค่าตัวแปรสภาพแวดล้อมให้เหมาะสมกับผู้ให้บริการที่คุณเลือก:\n\n```bash\n# สำหรับ OpenAI\nexport OPENAI_API_KEY=\"your-openai-api-key\"\n\n# สำหรับ Anthropic\nexport ANTHROPIC_API_KEY=\"your-anthropic-api-key\"\n\n# สำหรับ Google",
    "Status": "ok"
  },
  {
    "Id": 3,
    "Content": "export GEMINI_API_KEY=\"your-google-api-key\"\n```\n\n## Quickstart\n\nThe fastest way to learn about fenic is by checking the examples.\n\nBelow is a quick list of the examples in this repo:\n\n| Example                                                                 | Description                                                                                                                         |\n| ----------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------- |\n| [Hello World!](examples/hello_world)                                    | Introduction to semantic extraction and classification using fenic's core operators through error log analysis.                     |\n| [Enrichment](examples/enrichment)                                       | Multi-stage DataFrames with template-based text extraction, joins, and LLM-powered transformations demonstrated via log enrichment. |\n| [Meeting Transcript Processing](examples/meeting_transcript_processing) | Native transcript parsing, Pydantic schema integration, and complex aggregations shown through meeting analysis.                    |\n| [News Analysis](examples/news_analysis)                                 | Analyze and extract insights from news articles using semantic operators and structured data processing.                            |\n| [Podcast Summarization](examples/podcast_summarization)                 | Process and summarize podcast transcripts with speaker-aware analysis and key point extraction.                                     |\n| [Semantic Join](examples/semantic_joins)                                | Instead of simple fuzzy matching, use fenic's powerful semantic join functionality to match data across tables.                     |\n| [Named Entity Recognition](examples/named_entity_recognition)           | Extract and classify named entities from text using semantic extraction and classification.                                         |\n| [Markdown Processing](examples/markdown_processing)                     | Process and transform markdown documents with structured data extraction and formatting.                                            |\n| [JSON Processing](examples/json_processing)                             | Handle complex JSON data structures with semantic operations and schema validation.                                                 |\n| [Feedback Clustering](examples/feedback_clustering)                     | Group and analyze feedback using semantic similarity and clustering operations.                                                     |\n| [Document Extraction](examples/document_extraction)                     | Extract structured information from various document formats using semantic operators.                                              |\n\n(Feel free to click any example above to jump right to its folder.)\n",
    "ContentSha": "RBvJ+qAaDZODC8rvu1sFp9QTE4SUhSKTTu/91HAxBRc=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "export GEMINI_API_KEY=\"your-google-api-key\"\n```\n\n## เริ่มต้นอย่างรวดเร็ว\n\nวิธีที่เร็วที่สุดในการเรียนรู้เกี่ยวกับ fenic คือการตรวจสอบตัวอย่างต่าง ๆ\n\nด้านล่างนี้เป็นรายการตัวอย่างอย่างรวดเร็วใน repo นี้:\n\n| ตัวอย่าง                                                                 | คำอธิบาย                                                                                                                           |\n| ----------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------- |\n| [Hello World!](examples/hello_world)                                    | แนะนำการสกัดและจัดประเภทเชิงความหมายโดยใช้ตัวดำเนินการหลักของ fenic ผ่านการวิเคราะห์ log ข้อผิดพลาด                         |\n| [Enrichment](examples/enrichment)                                       | DataFrame หลายขั้นตอนด้วยการสกัดข้อความตามแม่แบบ การรวมข้อมูล และการแปลงข้อมูลด้วย LLM ผ่านการ enrichment log                  |\n| [Meeting Transcript Processing](examples/meeting_transcript_processing) | การแปลง transcript โดยตรง การผสาน schema ของ Pydantic และการรวมข้อมูลที่ซับซ้อนผ่านการวิเคราะห์การประชุม                        |\n| [News Analysis](examples/news_analysis)                                 | วิเคราะห์และสกัดข้อมูลเชิงลึกจากข่าวโดยใช้ตัวดำเนินการเชิงความหมายและการประมวลผลข้อมูลที่มีโครงสร้าง                         |\n| [Podcast Summarization](examples/podcast_summarization)                 | ประมวลผลและสรุป transcript ของ podcast ด้วยการวิเคราะห์ที่รับรู้ผู้พูดและการสกัดประเด็นสำคัญ                                   |\n| [Semantic Join](examples/semantic_joins)                                | แทนที่จะจับคู่แบบ fuzzy matching อย่างง่าย ให้ใช้ความสามารถ semantic join อันทรงพลังของ fenic เพื่อจับคู่ข้อมูลข้ามตาราง         |\n| [Named Entity Recognition](examples/named_entity_recognition)           | สกัดและจัดประเภท named entity จากข้อความโดยใช้การสกัดและจัดประเภทเชิงความหมาย                                                  |\n| [Markdown Processing](examples/markdown_processing)                     | ประมวลผลและแปลงเอกสาร markdown ด้วยการสกัดข้อมูลที่มีโครงสร้างและการจัดรูปแบบ                                                  |\n| [JSON Processing](examples/json_processing)                             | จัดการโครงสร้างข้อมูล JSON ที่ซับซ้อนด้วยการดำเนินการเชิงความหมายและการตรวจสอบ schema                                           |\n| [Feedback Clustering](examples/feedback_clustering)                     | จัดกลุ่มและวิเคราะห์ feedback โดยใช้ความคล้ายคลึงเชิงความหมายและการจัดกลุ่ม                                                    |\n| [Document Extraction](examples/document_extraction)                     | สกัดข้อมูลที่มีโครงสร้างจากรูปแบบเอกสารต่าง ๆ ด้วยตัวดำเนินการเชิงความหมาย                                                     |\n\n(คุณสามารถคลิกที่ตัวอย่างใดก็ได้ด้านบนเพื่อไปยังโฟลเดอร์นั้นโดยตรง)",
    "Status": "ok"
  },
  {
    "Id": 4,
    "Content": "## Why use fenic?\n\nfenic is an opinionated, PySpark-inspired DataFrame framework for building production AI and agentic applications.\n\nUnlike traditional data tools retrofitted for LLMs, fenic's query engine is built from the ground up with inference in mind.\n\nTransform structured and unstructured data into insights using familiar DataFrame operations enhanced with semantic intelligence. With first-class support for markdown, transcripts, and semantic operators, plus efficient batch inference across any model provider.\n\nfenic brings the reliability of traditional data pipelines to AI workloads.\n\n### Key Features\n\n#### Purpose-Built for LLM Inference\n\n- Query engine designed from scratch for AI workloads, not retrofitted\n- Automatic batch optimization for API calls\n- Built-in retry logic and rate limiting\n- Token counting and cost tracking\n\n#### Semantic Operators as First-Class Citizens",
    "ContentSha": "POPTpr2d3zFT3V0X0/NRjmMCUTjlIPBHtMTVHIRsyfM=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "## ทำไมต้องใช้ fenic?\n\nfenic คือเฟรมเวิร์ก DataFrame ที่มีแนวคิดเฉพาะตัว ได้แรงบันดาลใจจาก PySpark สำหรับสร้างแอปพลิเคชัน AI และ agentic ในระดับโปรดักชัน\n\nแตกต่างจากเครื่องมือจัดการข้อมูลแบบดั้งเดิมที่ถูกดัดแปลงมาใช้กับ LLMs, query engine ของ fenic ถูกสร้างขึ้นใหม่ตั้งแต่ต้นโดยคำนึงถึงงาน inference เป็นหลัก\n\nเปลี่ยนข้อมูลทั้งแบบมีโครงสร้างและไม่มีโครงสร้างให้เป็นข้อมูลเชิงลึก ด้วยการดำเนินการแบบ DataFrame ที่คุ้นเคยซึ่งเสริมด้วยปัญญากึ่งความหมาย (semantic intelligence) มีการรองรับ markdown, ถอดเสียง (transcripts) และตัวดำเนินการเชิงความหมาย (semantic operators) ในระดับสูง พร้อมทั้งการ inference แบบ batch ที่มีประสิทธิภาพกับผู้ให้บริการโมเดลทุกราย\n\nfenic นำความน่าเชื่อถือของ data pipeline แบบดั้งเดิมมาสู่เวิร์กโหลด AI\n\n### คุณสมบัติเด่น\n\n#### ออกแบบมาโดยเฉพาะสำหรับ LLM Inference\n\n- Query engine ที่ออกแบบใหม่ตั้งแต่ต้นสำหรับเวิร์กโหลด AI ไม่ใช่การดัดแปลง\n- การเพิ่มประสิทธิภาพแบบ batch สำหรับ API calls อัตโนมัติ\n- มี retry logic และ rate limiting ในตัว\n- นับจำนวน token และติดตามต้นทุน\n\n#### ตัวดำเนินการเชิงความหมายในฐานะพลเมืองชั้นหนึ่ง",
    "Status": "ok"
  },
  {
    "Id": 5,
    "Content": "\n- `semantic.analyze_sentiment` - Built-in sentiment analysis\n- `semantic.classify` - Categorize text with few-shot examples\n- `semantic.extract` - Transform unstructured text into structured data with schemas\n- `semantic.group_by` - Group data by semantic similarity\n- `semantic.join` - Join DataFrames on meaning, not just values\n- `semantic.map` - Apply natural language transformations\n- `semantic.predicate` - Create predicates using natural language to filter rows\n- `semantic.reduce` - Aggregate grouped data with LLM operations\n\n#### Native Unstructured Data Support\n\nGoes beyond typical multimodal data types (audio, images) by creating specialized types for text-heavy workloads:\n\n- Markdown parsing and extraction as a first-class data type\n- Transcript processing (SRT, generic formats) with speaker and timestamp awareness\n- JSON manipulation with JQ expressions for nested data\n- Automatic text chunking with configurable overlap for long documents\n\n#### Production-Ready Infrastructure",
    "ContentSha": "NE5dPjdhTPxhAD1E+gcEg2tw/wEtQVkEuw1AGA1YwCQ=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "- `semantic.analyze_sentiment` - การวิเคราะห์อารมณ์ความรู้สึกในตัว\n- `semantic.classify` - จัดหมวดหมู่ข้อความด้วยตัวอย่างแบบ few-shot\n- `semantic.extract` - แปลงข้อความที่ไม่มีโครงสร้างเป็นข้อมูลที่มีโครงสร้างด้วย schema\n- `semantic.group_by` - จัดกลุ่มข้อมูลตามความคล้ายคลึงทางความหมาย\n- `semantic.join` - เชื่อม DataFrame ตามความหมาย ไม่ใช่แค่ค่าข้อมูล\n- `semantic.map` - ประยุกต์การแปลงภาษาธรรมชาติ\n- `semantic.predicate` - สร้าง predicate ด้วยภาษาธรรมชาติเพื่อกรองแถวข้อมูล\n- `semantic.reduce` - สรุปข้อมูลที่ถูกจัดกลุ่มด้วยการดำเนินการของ LLM\n\n#### รองรับข้อมูลที่ไม่มีโครงสร้างโดยกำเนิด\n\nก้าวข้ามประเภทข้อมูลมัลติมีเดียทั่วไป (เสียง, รูปภาพ) ด้วยการสร้างประเภทข้อมูลเฉพาะสำหรับงานที่เน้นข้อความ:\n\n- การแยกวิเคราะห์และดึงข้อมูล Markdown เป็นประเภทข้อมูลหลัก\n- การประมวลผลคำถอดเสียง (SRT, รูปแบบทั่วไป) พร้อมรับรู้ผู้พูดและเวลา\n- การจัดการ JSON ด้วยนิพจน์ JQ สำหรับข้อมูลซ้อนกันหลายชั้น\n- การแบ่งข้อความอัตโนมัติพร้อมกำหนดการทับซ้อนสำหรับเอกสารขนาดยาว\n\n#### โครงสร้างพื้นฐานพร้อมใช้งานในงานจริง",
    "Status": "ok"
  },
  {
    "Id": 6,
    "Content": "\n- Multi-provider support (OpenAI, Anthropic, Gemini)\n- Local and cloud execution backends\n- Comprehensive error handling and logging\n- Pydantic integration for type safety\n\n#### Familiar DataFrame API\n\n- PySpark-compatible operations\n- Lazy evaluation and query optimization\n- SQL support for complex queries\n- Seamless integration with existing data pipelines\n\n### Why DataFrames for LLM and Agentic Applications?\n\nAI and agentic applications are fundamentally pipelines and workflows - exactly what DataFrame APIs were designed to handle. Rather than reinventing patterns for data transformation, filtering, and aggregation, fenic leverages decades of proven engineering practices.\n\n#### Decoupled Architecture for Better Agents\n\nfenic creates a clear separation between heavy inference tasks and real-time agent interactions. By moving batch processing out of the agent runtime, you get:\n\n- More predictable and responsive agents\n- Better resource utilization with batched LLM calls\n- Cleaner separation between planning/orchestration and execution\n",
    "ContentSha": "mT0TcKmDXUG4vMCvQ5Zt2Hov+kI1MOWz6tDxxgD3BGY=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "- รองรับผู้ให้บริการหลายราย (OpenAI, Anthropic, Gemini)\n- เบื้องหลังการประมวลผลทั้งในเครื่องและบนคลาวด์\n- การจัดการข้อผิดพลาดและการบันทึกข้อมูลอย่างครอบคลุม\n- การผสานรวมกับ Pydantic เพื่อความปลอดภัยของชนิดข้อมูล\n\n#### API ของ DataFrame ที่คุ้นเคย\n\n- การดำเนินการที่เข้ากันได้กับ PySpark\n- การประเมินค่าแบบ Lazy และการเพิ่มประสิทธิภาพการค้นหา\n- รองรับ SQL สำหรับการค้นหาที่ซับซ้อน\n- การผสานรวมอย่างไร้รอยต่อกับสายงานข้อมูลที่มีอยู่\n\n### ทำไมต้องใช้ DataFrames สำหรับ LLM และแอปพลิเคชันแบบ Agentic?\n\nแอปพลิเคชัน AI และ Agentic มีพื้นฐานเป็นสายงานและเวิร์กโฟลว์—ซึ่งเป็นสิ่งที่ DataFrame API ถูกออกแบบมาเพื่อจัดการ โดยไม่ต้องสร้างรูปแบบใหม่สำหรับการแปลงข้อมูล การกรอง และการรวมข้อมูล fenic ใช้ประโยชน์จากหลักวิศวกรรมที่ได้รับการพิสูจน์แล้วมานานหลายสิบปี\n\n#### สถาปัตยกรรมที่แยกส่วนเพื่อเอเจนต์ที่ดีกว่า\n\nfenic สร้างการแยกที่ชัดเจนระหว่างงาน inference ที่หนักกับการโต้ตอบกับเอเจนต์แบบเรียลไทม์ โดยการย้ายการประมวลผลแบบกลุ่มออกจากรันไทม์ของเอเจนต์ คุณจะได้รับ:\n\n- เอเจนต์ที่ตอบสนองและคาดเดาได้มากขึ้น\n- การใช้ทรัพยากรที่ดีขึ้นด้วยการเรียก LLM แบบกลุ่ม\n- การแยกที่ชัดเจนระหว่างการวางแผน/การกำกับดูแลกับการประมวลผล",
    "Status": "ok"
  },
  {
    "Id": 7,
    "Content": "#### Built for All Engineers\n\nDataFrames aren't just for data practitioners. The fluent, composable API design makes it accessible to any engineer:\n\n- Chain operations naturally: `df.filter(...).semantic.group_by(...)`\n- Mix imperative and declarative styles seamlessly\n- Get started quickly with familiar patterns from pandas/PySpark or SQL\n\n## Support\n\nJoin our community on [Discord](https://discord.gg/GdqF3J7huR) where you can connect with other users, ask questions, and get help with your fenic projects. Our community is always happy to welcome newcomers!\n\nIf you find fenic useful, consider giving us a ⭐ at the top of this repository. Your support helps us grow and improve the framework for everyone!\n\n## Contributing\n\nWe welcome contributions of all kinds! Whether you're interested in writing code, improving documentation, testing features, or proposing new ideas, your help is valuable to us.\n\nFor developers planning to submit code changes, we encourage you to first open an issue to discuss your ideas before creating a Pull Request. This helps ensure alignment with the project's direction and prevents duplicate efforts.\n\nPlease refer to our [contribution guidelines](https://raw.githubusercontent.com/typedef-ai/fenic/main/CONTRIBUTING.md) for detailed information about the development process and project setup.\n",
    "ContentSha": "uskg5roWGwsGUjyK072Ea16WzdZZykGudJVeAy5e46I=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "#### สร้างขึ้นเพื่อวิศวกรทุกคน\n\nDataFrame ไม่ได้มีไว้สำหรับผู้เชี่ยวชาญด้านข้อมูลเท่านั้น การออกแบบ API ที่ใช้งานได้อย่างลื่นไหลและประกอบกันได้ทำให้วิศวกรทุกคนสามารถเข้าถึงได้:\n\n- เชื่อมต่อการทำงานอย่างเป็นธรรมชาติ: `df.filter(...).semantic.group_by(...)`\n- ผสมผสานสไตล์แบบ imperative และ declarative ได้อย่างไร้รอยต่อ\n- เริ่มต้นใช้งานได้อย่างรวดเร็วด้วยรูปแบบที่คุ้นเคยจาก pandas/PySpark หรือ SQL\n\n## การสนับสนุน\n\nเข้าร่วมชุมชนของเราบน [Discord](https://discord.gg/GdqF3J7huR) ที่ซึ่งคุณสามารถเชื่อมต่อกับผู้ใช้ท่านอื่น ๆ ถามคำถาม และขอความช่วยเหลือเกี่ยวกับโปรเจกต์ fenic ของคุณ ชุมชนของเรายินดีต้อนรับสมาชิกใหม่เสมอ!\n\nหากคุณพบว่า fenic มีประโยชน์ โปรดพิจารณาให้ดาว ⭐ ที่ด้านบนของ repository นี้ การสนับสนุนของคุณช่วยให้เราพัฒนาและปรับปรุงเฟรมเวิร์กนี้สำหรับทุกคน!\n\n## การมีส่วนร่วม\n\nเรายินดีต้อนรับการมีส่วนร่วมทุกรูปแบบ! ไม่ว่าคุณจะสนใจเขียนโค้ด ปรับปรุงเอกสาร ทดสอบฟีเจอร์ หรือเสนอแนวคิดใหม่ ๆ ความช่วยเหลือของคุณมีคุณค่าสำหรับเรา\n\nสำหรับนักพัฒนาที่วางแผนจะส่งการเปลี่ยนแปลงโค้ด เราแนะนำให้คุณเปิด issue เพื่อพูดคุยไอเดียก่อนที่จะสร้าง Pull Request ซึ่งจะช่วยให้แน่ใจว่าแนวคิดของคุณสอดคล้องกับทิศทางของโปรเจกต์และป้องกันความซ้ำซ้อนในการทำงาน\n\nโปรดดู [แนวทางการมีส่วนร่วม](https://raw.githubusercontent.com/typedef-ai/fenic/main/CONTRIBUTING.md) ของเราเพื่อข้อมูลรายละเอียดเกี่ยวกับกระบวนการพัฒนาและการตั้งค่าโปรเจกต์",
    "Status": "ok"
  }
]