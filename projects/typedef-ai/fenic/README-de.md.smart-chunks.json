[
  {
    "Id": 1,
    "Content": "<!-- markdownlint-disable MD041 MD033 -->\n<div align=\"center\">\n    <picture>\n        <source media=\"(prefers-color-scheme: dark)\" srcset=\"docs/images/typedef-fenic-logo-dark.png\">\n        <img src=\"https://raw.githubusercontent.com/typedef-ai/fenic/main/docs/images/typedef-fenic-logo.png\" alt=\"fenic, by typedef\" width=\"90%\">\n    </picture>\n</div>\n\n# fenic: the dataframe (re)built for LLM inference\n\n[![PyPI version](https://img.shields.io/pypi/v/fenic.svg)](https://pypi.org/project/fenic/)\n[![Python versions](https://img.shields.io/pypi/pyversions/fenic.svg)](https://pypi.org/project/fenic/)\n[![License](https://img.shields.io/github/license/typedef-ai/fenic.svg)](https://github.com/typedef-ai/fenic/blob/main/LICENSE)\n[![Discord](https://img.shields.io/discord/1381706122322513952?label=Discord&logo=discord)](https://discord.gg/GdqF3J7huR)\n\n---\n\n## **Documentation**: [docs.fenic.ai](https://docs.fenic.ai/)\n\nfenic is an opinionated, PySpark-inspired DataFrame framework from typedef.ai for building AI and agentic applications. Transform unstructured and structured data into insights using familiar DataFrame operations enhanced with semantic intelligence. With first-class support for markdown, transcripts, and semantic operators, plus efficient batch inference across any model provider.\n",
    "ContentSha": "tmub1AxUb0Y4Al5Ltz67crbP453GMVUntyWUISmU7NQ=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "<!-- markdownlint-disable MD041 MD033 -->\n<div align=\"center\">\n    <picture>\n        <source media=\"(prefers-color-scheme: dark)\" srcset=\"docs/images/typedef-fenic-logo-dark.png\">\n        <img src=\"https://raw.githubusercontent.com/typedef-ai/fenic/main/docs/images/typedef-fenic-logo.png\" alt=\"fenic, by typedef\" width=\"90%\">\n    </picture>\n</div>\n\n# fenic: das DataFrame (neu) gebaut für LLM-Inferenz\n\n[![PyPI version](https://img.shields.io/pypi/v/fenic.svg)](https://pypi.org/project/fenic/)\n[![Python versions](https://img.shields.io/pypi/pyversions/fenic.svg)](https://pypi.org/project/fenic/)\n[![License](https://img.shields.io/github/license/typedef-ai/fenic.svg)](https://github.com/typedef-ai/fenic/blob/main/LICENSE)\n[![Discord](https://img.shields.io/discord/1381706122322513952?label=Discord&logo=discord)](https://discord.gg/GdqF3J7huR)\n\n---\n\n## **Dokumentation**: [docs.fenic.ai](https://docs.fenic.ai/)\n\nfenic ist ein meinungsstarkes, von PySpark inspiriertes DataFrame-Framework von typedef.ai für den Aufbau von KI- und agentischen Anwendungen. Transformieren Sie unstrukturierte und strukturierte Daten in Erkenntnisse mit vertrauten DataFrame-Operationen, erweitert durch semantische Intelligenz. Mit erstklassiger Unterstützung für Markdown, Transkripte und semantische Operatoren sowie effizienter Batch-Inferenz über jeden Modellanbieter hinweg.",
    "Status": "ok"
  },
  {
    "Id": 2,
    "Content": "## Install\n\nfenic supports Python `[3.10, 3.11, 3.12]`\n\n```bash\npip install fenic\n```\n\n### LLM Provider Setup\n\nfenic requires an API key from at least one LLM provider. Set the appropriate environment variable for your chosen provider:\n\n```bash\n# For OpenAI\nexport OPENAI_API_KEY=\"your-openai-api-key\"\n\n# For Anthropic\nexport ANTHROPIC_API_KEY=\"your-anthropic-api-key\"\n\n# For Google",
    "ContentSha": "QT2GWoHGnyfwnJxlfZAk0I5rpIsEfvGEhJD38oz6lCY=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "## Installation\n\nfenic unterstützt Python `[3.10, 3.11, 3.12]`\n\n```bash\npip install fenic\n```\n\n### Einrichtung des LLM-Anbieters\n\nfenic benötigt einen API-Schlüssel von mindestens einem LLM-Anbieter. Setzen Sie die entsprechende Umgebungsvariable für Ihren gewählten Anbieter:\n\n```bash\n# Für OpenAI\nexport OPENAI_API_KEY=\"Ihr-openai-api-key\"\n\n# Für Anthropic\nexport ANTHROPIC_API_KEY=\"Ihr-anthropic-api-key\"\n\n# Für Google",
    "Status": "ok"
  },
  {
    "Id": 3,
    "Content": "export GEMINI_API_KEY=\"your-google-api-key\"\n```\n\n## Quickstart\n\nThe fastest way to learn about fenic is by checking the examples.\n\nBelow is a quick list of the examples in this repo:\n\n| Example                                                                 | Description                                                                                                                         |\n| ----------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------- |\n| [Hello World!](examples/hello_world)                                    | Introduction to semantic extraction and classification using fenic's core operators through error log analysis.                     |\n| [Enrichment](examples/enrichment)                                       | Multi-stage DataFrames with template-based text extraction, joins, and LLM-powered transformations demonstrated via log enrichment. |\n| [Meeting Transcript Processing](examples/meeting_transcript_processing) | Native transcript parsing, Pydantic schema integration, and complex aggregations shown through meeting analysis.                    |\n| [News Analysis](examples/news_analysis)                                 | Analyze and extract insights from news articles using semantic operators and structured data processing.                            |\n| [Podcast Summarization](examples/podcast_summarization)                 | Process and summarize podcast transcripts with speaker-aware analysis and key point extraction.                                     |\n| [Semantic Join](examples/semantic_joins)                                | Instead of simple fuzzy matching, use fenic's powerful semantic join functionality to match data across tables.                     |\n| [Named Entity Recognition](examples/named_entity_recognition)           | Extract and classify named entities from text using semantic extraction and classification.                                         |\n| [Markdown Processing](examples/markdown_processing)                     | Process and transform markdown documents with structured data extraction and formatting.                                            |\n| [JSON Processing](examples/json_processing)                             | Handle complex JSON data structures with semantic operations and schema validation.                                                 |\n| [Feedback Clustering](examples/feedback_clustering)                     | Group and analyze feedback using semantic similarity and clustering operations.                                                     |\n| [Document Extraction](examples/document_extraction)                     | Extract structured information from various document formats using semantic operators.                                              |\n\n(Feel free to click any example above to jump right to its folder.)\n",
    "ContentSha": "RBvJ+qAaDZODC8rvu1sFp9QTE4SUhSKTTu/91HAxBRc=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "export GEMINI_API_KEY=\"your-google-api-key\"\n```\n\n## Schnellstart\n\nDer schnellste Weg, fenic kennenzulernen, ist das Durchsehen der Beispiele.\n\nUnten findest du eine kurze Liste der Beispiele in diesem Repository:\n\n| Beispiel                                                                | Beschreibung                                                                                                                         |\n| ----------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------- |\n| [Hello World!](examples/hello_world)                                    | Einführung in die semantische Extraktion und Klassifikation mithilfe der Kern-Operatoren von fenic durch Fehlerprotokollanalyse.    |\n| [Enrichment](examples/enrichment)                                       | Mehrstufige DataFrames mit vorlagenbasierter Textextraktion, Joins und LLM-gestützten Transformationen, demonstriert durch Log-Anreicherung. |\n| [Meeting Transcript Processing](examples/meeting_transcript_processing) | Native Transkript-Analyse, Pydantic-Schema-Integration und komplexe Aggregationen am Beispiel der Sitzungsanalyse.                  |\n| [News Analysis](examples/news_analysis)                                 | Analysiere und extrahiere Erkenntnisse aus Nachrichtenartikeln mit semantischen Operatoren und strukturierter Datenverarbeitung.    |\n| [Podcast Summarization](examples/podcast_summarization)                 | Verarbeite und fasse Podcast-Transkripte zusammen mit sprecherbezogener Analyse und Schlüsselpunktextraktion.                      |\n| [Semantic Join](examples/semantic_joins)                                | Statt einfacher Fuzzy-Matches nutze fenics leistungsstarke semantische Join-Funktionalität, um Daten tabellenübergreifend abzugleichen. |\n| [Named Entity Recognition](examples/named_entity_recognition)           | Extrahiere und klassifiziere benannte Entitäten aus Text mithilfe semantischer Extraktion und Klassifikation.                       |\n| [Markdown Processing](examples/markdown_processing)                     | Verarbeite und transformiere Markdown-Dokumente durch strukturierte Datenextraktion und -formatierung.                              |\n| [JSON Processing](examples/json_processing)                             | Verarbeite komplexe JSON-Datenstrukturen mit semantischen Operationen und Schema-Validierung.                                       |\n| [Feedback Clustering](examples/feedback_clustering)                     | Gruppiere und analysiere Feedback mithilfe semantischer Ähnlichkeit und Clustering-Operationen.                                     |\n| [Document Extraction](examples/document_extraction)                     | Extrahiere strukturierte Informationen aus verschiedenen Dokumentformaten mit semantischen Operatoren.                              |\n\n(Du kannst gerne auf ein beliebiges Beispiel oben klicken, um direkt zum entsprechenden Ordner zu springen.)\n",
    "Status": "ok"
  },
  {
    "Id": 4,
    "Content": "## Why use fenic?\n\nfenic is an opinionated, PySpark-inspired DataFrame framework for building production AI and agentic applications.\n\nUnlike traditional data tools retrofitted for LLMs, fenic's query engine is built from the ground up with inference in mind.\n\nTransform structured and unstructured data into insights using familiar DataFrame operations enhanced with semantic intelligence. With first-class support for markdown, transcripts, and semantic operators, plus efficient batch inference across any model provider.\n\nfenic brings the reliability of traditional data pipelines to AI workloads.\n\n### Key Features\n\n#### Purpose-Built for LLM Inference\n\n- Query engine designed from scratch for AI workloads, not retrofitted\n- Automatic batch optimization for API calls\n- Built-in retry logic and rate limiting\n- Token counting and cost tracking\n\n#### Semantic Operators as First-Class Citizens",
    "ContentSha": "POPTpr2d3zFT3V0X0/NRjmMCUTjlIPBHtMTVHIRsyfM=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "## Warum fenic verwenden?\n\nfenic ist ein meinungsstarkes, von PySpark inspiriertes DataFrame-Framework zum Aufbau produktiver KI- und agentenbasierter Anwendungen.\n\nIm Gegensatz zu traditionellen Datenwerkzeugen, die nachträglich für LLMs angepasst wurden, ist fenics Abfrage-Engine von Grund auf mit Fokus auf Inferenz entwickelt worden.\n\nTransformieren Sie strukturierte und unstrukturierte Daten in Erkenntnisse mit vertrauten DataFrame-Operationen, die durch semantische Intelligenz erweitert werden. Mit erstklassiger Unterstützung für Markdown, Transkripte und semantische Operatoren sowie effizientem Batch-Inferencing über jeden Modellanbieter.\n\nfenic bringt die Zuverlässigkeit traditioneller Datenpipelines in KI-Workloads.\n\n### Hauptfunktionen\n\n#### Speziell für LLM-Inferenz entwickelt\n\n- Abfrage-Engine von Grund auf für KI-Workloads konzipiert, nicht nachträglich angepasst\n- Automatische Batch-Optimierung für API-Aufrufe\n- Integrierte Wiederholungslogik und Ratenbegrenzung\n- Tokenzählung und Kostenverfolgung\n\n#### Semantische Operatoren als First-Class Citizens",
    "Status": "ok"
  },
  {
    "Id": 5,
    "Content": "\n- `semantic.analyze_sentiment` - Built-in sentiment analysis\n- `semantic.classify` - Categorize text with few-shot examples\n- `semantic.extract` - Transform unstructured text into structured data with schemas\n- `semantic.group_by` - Group data by semantic similarity\n- `semantic.join` - Join DataFrames on meaning, not just values\n- `semantic.map` - Apply natural language transformations\n- `semantic.predicate` - Create predicates using natural language to filter rows\n- `semantic.reduce` - Aggregate grouped data with LLM operations\n\n#### Native Unstructured Data Support\n\nGoes beyond typical multimodal data types (audio, images) by creating specialized types for text-heavy workloads:\n\n- Markdown parsing and extraction as a first-class data type\n- Transcript processing (SRT, generic formats) with speaker and timestamp awareness\n- JSON manipulation with JQ expressions for nested data\n- Automatic text chunking with configurable overlap for long documents\n\n#### Production-Ready Infrastructure",
    "ContentSha": "NE5dPjdhTPxhAD1E+gcEg2tw/wEtQVkEuw1AGA1YwCQ=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "- `semantic.analyze_sentiment` - Eingebaute Sentiment-Analyse\n- `semantic.classify` - Kategorisierung von Text mit Few-Shot-Beispielen\n- `semantic.extract` - Umwandlung von unstrukturiertem Text in strukturierte Daten mittels Schemata\n- `semantic.group_by` - Gruppierung von Daten nach semantischer Ähnlichkeit\n- `semantic.join` - Verknüpfung von DataFrames basierend auf Bedeutung, nicht nur auf Werten\n- `semantic.map` - Anwendung von Transformationen in natürlicher Sprache\n- `semantic.predicate` - Erstellung von Prädikaten mittels natürlicher Sprache zur Filterung von Zeilen\n- `semantic.reduce` - Aggregation gruppierter Daten mit LLM-Operationen\n\n#### Native Unterstützung unstrukturierter Daten\n\nGeht über typische multimodale Datentypen (Audio, Bilder) hinaus, indem spezialisierte Typen für textlastige Workloads geschaffen werden:\n\n- Markdown-Parsing und -Extraktion als erstklassiger Datentyp\n- Transkriptverarbeitung (SRT, generische Formate) mit Sprecher- und Zeitstempel-Erkennung\n- JSON-Manipulation mit JQ-Ausdrücken für verschachtelte Daten\n- Automatische Textzerlegung mit konfigurierbarer Überlappung für lange Dokumente\n\n#### Produktionsreife Infrastruktur",
    "Status": "ok"
  },
  {
    "Id": 6,
    "Content": "\n- Multi-provider support (OpenAI, Anthropic, Gemini)\n- Local and cloud execution backends\n- Comprehensive error handling and logging\n- Pydantic integration for type safety\n\n#### Familiar DataFrame API\n\n- PySpark-compatible operations\n- Lazy evaluation and query optimization\n- SQL support for complex queries\n- Seamless integration with existing data pipelines\n\n### Why DataFrames for LLM and Agentic Applications?\n\nAI and agentic applications are fundamentally pipelines and workflows - exactly what DataFrame APIs were designed to handle. Rather than reinventing patterns for data transformation, filtering, and aggregation, fenic leverages decades of proven engineering practices.\n\n#### Decoupled Architecture for Better Agents\n\nfenic creates a clear separation between heavy inference tasks and real-time agent interactions. By moving batch processing out of the agent runtime, you get:\n\n- More predictable and responsive agents\n- Better resource utilization with batched LLM calls\n- Cleaner separation between planning/orchestration and execution\n",
    "ContentSha": "mT0TcKmDXUG4vMCvQ5Zt2Hov+kI1MOWz6tDxxgD3BGY=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "- Multi-Provider-Unterstützung (OpenAI, Anthropic, Gemini)\n- Lokale und Cloud-Ausführungs-Backends\n- Umfassende Fehlerbehandlung und Protokollierung\n- Pydantic-Integration für Typsicherheit\n\n#### Vertraute DataFrame-API\n\n- PySpark-kompatible Operationen\n- Faule Auswertung und Abfrageoptimierung\n- SQL-Unterstützung für komplexe Abfragen\n- Nahtlose Integration in bestehende Datenpipelines\n\n### Warum DataFrames für LLM- und Agenten-Anwendungen?\n\nKI- und agentenbasierte Anwendungen sind im Kern Pipelines und Workflows – genau dafür wurden DataFrame-APIs entwickelt. Anstatt Muster für Datenumwandlung, Filterung und Aggregation neu zu erfinden, nutzt fenic jahrzehntelang bewährte Ingenieurpraktiken.\n\n#### Entkoppelte Architektur für bessere Agenten\n\nfenic schafft eine klare Trennung zwischen rechenintensiven Inferenzaufgaben und Echtzeit-Agenteninteraktionen. Durch das Auslagern der Batch-Verarbeitung aus der Agenten-Laufzeitumgebung erhalten Sie:\n\n- Vorhersehbarere und reaktionsschnellere Agenten\n- Bessere Ressourcenauslastung durch gebündelte LLM-Aufrufe\n- Sauberere Trennung zwischen Planung/Orchestrierung und Ausführung",
    "Status": "ok"
  },
  {
    "Id": 7,
    "Content": "#### Built for All Engineers\n\nDataFrames aren't just for data practitioners. The fluent, composable API design makes it accessible to any engineer:\n\n- Chain operations naturally: `df.filter(...).semantic.group_by(...)`\n- Mix imperative and declarative styles seamlessly\n- Get started quickly with familiar patterns from pandas/PySpark or SQL\n\n## Support\n\nJoin our community on [Discord](https://discord.gg/GdqF3J7huR) where you can connect with other users, ask questions, and get help with your fenic projects. Our community is always happy to welcome newcomers!\n\nIf you find fenic useful, consider giving us a ⭐ at the top of this repository. Your support helps us grow and improve the framework for everyone!\n\n## Contributing\n\nWe welcome contributions of all kinds! Whether you're interested in writing code, improving documentation, testing features, or proposing new ideas, your help is valuable to us.\n\nFor developers planning to submit code changes, we encourage you to first open an issue to discuss your ideas before creating a Pull Request. This helps ensure alignment with the project's direction and prevents duplicate efforts.\n\nPlease refer to our [contribution guidelines](https://raw.githubusercontent.com/typedef-ai/fenic/main/CONTRIBUTING.md) for detailed information about the development process and project setup.\n",
    "ContentSha": "uskg5roWGwsGUjyK072Ea16WzdZZykGudJVeAy5e46I=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "#### Für alle Ingenieure entwickelt\n\nDataFrames sind nicht nur für Datenpraktiker gedacht. Das flüssige, komponierbare API-Design macht sie für jeden Ingenieur zugänglich:\n\n- Verknüpfen Sie Operationen auf natürliche Weise: `df.filter(...).semantic.group_by(...)`\n- Mischen Sie imperative und deklarative Stile nahtlos\n- Starten Sie schnell mit vertrauten Mustern aus pandas/PySpark oder SQL\n\n## Support\n\nTreten Sie unserer Community auf [Discord](https://discord.gg/GdqF3J7huR) bei, wo Sie sich mit anderen Nutzern vernetzen, Fragen stellen und Hilfe zu Ihren fenic-Projekten erhalten können. Unsere Community freut sich immer, neue Mitglieder willkommen zu heißen!\n\nWenn Sie fenic nützlich finden, überlegen Sie, uns ein ⭐ am Anfang dieses Repositories zu geben. Ihre Unterstützung hilft uns, das Framework für alle weiterzuentwickeln und zu verbessern!\n\n## Beitrag leisten\n\nWir freuen uns über Beiträge jeder Art! Egal, ob Sie Code schreiben, die Dokumentation verbessern, Features testen oder neue Ideen vorschlagen möchten – Ihre Hilfe ist uns wertvoll.\n\nFür Entwickler, die Codeänderungen einreichen möchten, empfehlen wir, zunächst ein Issue zu eröffnen, um Ihre Ideen zu besprechen, bevor Sie einen Pull Request erstellen. Das trägt dazu bei, dass die Arbeit mit der Ausrichtung des Projekts übereinstimmt und doppelte Arbeiten vermieden werden.\n\nBitte beachten Sie unsere [Beitragsrichtlinien](https://raw.githubusercontent.com/typedef-ai/fenic/main/CONTRIBUTING.md) für detaillierte Informationen zum Entwicklungsprozess und zur Projektstruktur.",
    "Status": "ok"
  }
]