[
  {
    "Id": 1,
    "Content": "<!-- markdownlint-disable MD041 MD033 -->\n<div align=\"center\">\n    <picture>\n        <source media=\"(prefers-color-scheme: dark)\" srcset=\"docs/images/typedef-fenic-logo-dark.png\">\n        <img src=\"https://raw.githubusercontent.com/typedef-ai/fenic/main/docs/images/typedef-fenic-logo.png\" alt=\"fenic, by typedef\" width=\"90%\">\n    </picture>\n</div>\n\n# fenic: the dataframe (re)built for LLM inference\n\n[![PyPI version](https://img.shields.io/pypi/v/fenic.svg)](https://pypi.org/project/fenic/)\n[![Python versions](https://img.shields.io/pypi/pyversions/fenic.svg)](https://pypi.org/project/fenic/)\n[![License](https://img.shields.io/github/license/typedef-ai/fenic.svg)](https://github.com/typedef-ai/fenic/blob/main/LICENSE)\n[![Discord](https://img.shields.io/discord/1381706122322513952?label=Discord&logo=discord)](https://discord.gg/GdqF3J7huR)\n\n---\n\n## **Documentation**: [docs.fenic.ai](https://docs.fenic.ai/)\n\nfenic is an opinionated, PySpark-inspired DataFrame framework from typedef.ai for building AI and agentic applications. Transform unstructured and structured data into insights using familiar DataFrame operations enhanced with semantic intelligence. With first-class support for markdown, transcripts, and semantic operators, plus efficient batch inference across any model provider.\n",
    "ContentSha": "tmub1AxUb0Y4Al5Ltz67crbP453GMVUntyWUISmU7NQ=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "<!-- markdownlint-disable MD041 MD033 -->\n<div align=\"center\">\n    <picture>\n        <source media=\"(prefers-color-scheme: dark)\" srcset=\"docs/images/typedef-fenic-logo-dark.png\">\n        <img src=\"https://raw.githubusercontent.com/typedef-ai/fenic/main/docs/images/typedef-fenic-logo.png\" alt=\"fenic, by typedef\" width=\"90%\">\n    </picture>\n</div>\n\n# fenic: il dataframe (ri)costruito per l’inferenza LLM\n\n[![PyPI version](https://img.shields.io/pypi/v/fenic.svg)](https://pypi.org/project/fenic/)\n[![Python versions](https://img.shields.io/pypi/pyversions/fenic.svg)](https://pypi.org/project/fenic/)\n[![License](https://img.shields.io/github/license/typedef-ai/fenic.svg)](https://github.com/typedef-ai/fenic/blob/main/LICENSE)\n[![Discord](https://img.shields.io/discord/1381706122322513952?label=Discord&logo=discord)](https://discord.gg/GdqF3J7huR)\n\n---\n\n## **Documentazione**: [docs.fenic.ai](https://docs.fenic.ai/)\n\nfenic è un framework DataFrame ispirato a PySpark, proposto da typedef.ai, per la costruzione di applicazioni AI e agentiche. Trasforma dati strutturati e non strutturati in insight utilizzando operazioni DataFrame familiari, arricchite con intelligenza semantica. Supporto di prima classe per markdown, trascrizioni e operatori semantici, oltre a un’inferenza batch efficiente su qualsiasi provider di modelli.",
    "Status": "ok"
  },
  {
    "Id": 2,
    "Content": "## Install\n\nfenic supports Python `[3.10, 3.11, 3.12]`\n\n```bash\npip install fenic\n```\n\n### LLM Provider Setup\n\nfenic requires an API key from at least one LLM provider. Set the appropriate environment variable for your chosen provider:\n\n```bash\n# For OpenAI\nexport OPENAI_API_KEY=\"your-openai-api-key\"\n\n# For Anthropic\nexport ANTHROPIC_API_KEY=\"your-anthropic-api-key\"\n\n# For Google",
    "ContentSha": "QT2GWoHGnyfwnJxlfZAk0I5rpIsEfvGEhJD38oz6lCY=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "## Installazione\n\nfenic supporta Python `[3.10, 3.11, 3.12]`\n\n```bash\npip install fenic\n```\n\n### Configurazione del Provider LLM\n\nfenic richiede una chiave API da almeno un provider LLM. Imposta la variabile d’ambiente appropriata per il provider scelto:\n\n```bash\n# Per OpenAI\nexport OPENAI_API_KEY=\"la-tua-openai-api-key\"\n\n# Per Anthropic\nexport ANTHROPIC_API_KEY=\"la-tua-anthropic-api-key\"\n\n# Per Google",
    "Status": "ok"
  },
  {
    "Id": 3,
    "Content": "export GEMINI_API_KEY=\"your-google-api-key\"\n```\n\n## Quickstart\n\nThe fastest way to learn about fenic is by checking the examples.\n\nBelow is a quick list of the examples in this repo:\n\n| Example                                                                 | Description                                                                                                                         |\n| ----------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------- |\n| [Hello World!](examples/hello_world)                                    | Introduction to semantic extraction and classification using fenic's core operators through error log analysis.                     |\n| [Enrichment](examples/enrichment)                                       | Multi-stage DataFrames with template-based text extraction, joins, and LLM-powered transformations demonstrated via log enrichment. |\n| [Meeting Transcript Processing](examples/meeting_transcript_processing) | Native transcript parsing, Pydantic schema integration, and complex aggregations shown through meeting analysis.                    |\n| [News Analysis](examples/news_analysis)                                 | Analyze and extract insights from news articles using semantic operators and structured data processing.                            |\n| [Podcast Summarization](examples/podcast_summarization)                 | Process and summarize podcast transcripts with speaker-aware analysis and key point extraction.                                     |\n| [Semantic Join](examples/semantic_joins)                                | Instead of simple fuzzy matching, use fenic's powerful semantic join functionality to match data across tables.                     |\n| [Named Entity Recognition](examples/named_entity_recognition)           | Extract and classify named entities from text using semantic extraction and classification.                                         |\n| [Markdown Processing](examples/markdown_processing)                     | Process and transform markdown documents with structured data extraction and formatting.                                            |\n| [JSON Processing](examples/json_processing)                             | Handle complex JSON data structures with semantic operations and schema validation.                                                 |\n| [Feedback Clustering](examples/feedback_clustering)                     | Group and analyze feedback using semantic similarity and clustering operations.                                                     |\n| [Document Extraction](examples/document_extraction)                     | Extract structured information from various document formats using semantic operators.                                              |\n\n(Feel free to click any example above to jump right to its folder.)\n",
    "ContentSha": "RBvJ+qAaDZODC8rvu1sFp9QTE4SUhSKTTu/91HAxBRc=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "export GEMINI_API_KEY=\"your-google-api-key\"\n```\n\n## Avvio rapido\n\nIl modo più veloce per imparare a usare fenic è consultare gli esempi.\n\nDi seguito è riportato un elenco rapido degli esempi presenti in questo repository:\n\n| Esempio                                                                 | Descrizione                                                                                                                         |\n| ----------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------- |\n| [Hello World!](examples/hello_world)                                    | Introduzione all’estrazione e classificazione semantica utilizzando gli operatori principali di fenic tramite l’analisi dei log di errore.                     |\n| [Enrichment](examples/enrichment)                                       | DataFrame multi-stadio con estrazione di testo basata su template, join e trasformazioni potenziate da LLM, dimostrati tramite l’arricchimento dei log. |\n| [Meeting Transcript Processing](examples/meeting_transcript_processing) | Parsing nativo delle trascrizioni, integrazione di schemi Pydantic e aggregazioni complesse mostrate tramite l’analisi delle riunioni.                    |\n| [News Analysis](examples/news_analysis)                                 | Analizza ed estrai informazioni dagli articoli di notizie utilizzando operatori semantici ed elaborazione dati strutturata.                            |\n| [Podcast Summarization](examples/podcast_summarization)                 | Elabora e riassumi le trascrizioni di podcast con analisi consapevole del parlante ed estrazione dei punti chiave.                                     |\n| [Semantic Join](examples/semantic_joins)                                | Invece del semplice fuzzy matching, usa la potente funzionalità di join semantico di fenic per abbinare dati tra tabelle.                     |\n| [Named Entity Recognition](examples/named_entity_recognition)           | Estrai e classifica entità nominate dal testo tramite estrazione e classificazione semantica.                                         |\n| [Markdown Processing](examples/markdown_processing)                     | Elabora e trasforma documenti markdown con estrazione strutturata dei dati e formattazione.                                            |\n| [JSON Processing](examples/json_processing)                             | Gestisci strutture dati JSON complesse con operazioni semantiche e validazione degli schemi.                                                 |\n| [Feedback Clustering](examples/feedback_clustering)                     | Raggruppa e analizza i feedback utilizzando similarità semantica e operazioni di clustering.                                                     |\n| [Document Extraction](examples/document_extraction)                     | Estrai informazioni strutturate da vari formati di documenti tramite operatori semantici.                                              |\n\n(Sentiti libero di cliccare su qualsiasi esempio sopra per andare direttamente alla sua cartella.)",
    "Status": "ok"
  },
  {
    "Id": 4,
    "Content": "## Why use fenic?\n\nfenic is an opinionated, PySpark-inspired DataFrame framework for building production AI and agentic applications.\n\nUnlike traditional data tools retrofitted for LLMs, fenic's query engine is built from the ground up with inference in mind.\n\nTransform structured and unstructured data into insights using familiar DataFrame operations enhanced with semantic intelligence. With first-class support for markdown, transcripts, and semantic operators, plus efficient batch inference across any model provider.\n\nfenic brings the reliability of traditional data pipelines to AI workloads.\n\n### Key Features\n\n#### Purpose-Built for LLM Inference\n\n- Query engine designed from scratch for AI workloads, not retrofitted\n- Automatic batch optimization for API calls\n- Built-in retry logic and rate limiting\n- Token counting and cost tracking\n\n#### Semantic Operators as First-Class Citizens",
    "ContentSha": "POPTpr2d3zFT3V0X0/NRjmMCUTjlIPBHtMTVHIRsyfM=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "## Perché usare fenic?\n\nfenic è un framework DataFrame ispirato a PySpark e orientato all’opinione, progettato per costruire applicazioni AI e agentiche di produzione.\n\nA differenza degli strumenti di dati tradizionali adattati agli LLM, il motore di query di fenic è stato costruito da zero con l’inferenza in mente.\n\nTrasforma dati strutturati e non strutturati in insight utilizzando operazioni DataFrame familiari, arricchite con intelligenza semantica. Con supporto di prima classe per markdown, trascrizioni e operatori semantici, oltre a un’inferenza batch efficiente su qualsiasi provider di modelli.\n\nfenic porta l’affidabilità delle pipeline di dati tradizionali nei carichi di lavoro AI.\n\n### Caratteristiche principali\n\n#### Progettato appositamente per l’inferenza LLM\n\n- Motore di query progettato da zero per carichi di lavoro AI, non adattato\n- Ottimizzazione automatica dei batch per chiamate API\n- Logica di retry integrata e limitazione della frequenza\n- Conteggio dei token e monitoraggio dei costi\n\n#### Operatori semantici come cittadini di prima classe",
    "Status": "ok"
  },
  {
    "Id": 5,
    "Content": "\n- `semantic.analyze_sentiment` - Built-in sentiment analysis\n- `semantic.classify` - Categorize text with few-shot examples\n- `semantic.extract` - Transform unstructured text into structured data with schemas\n- `semantic.group_by` - Group data by semantic similarity\n- `semantic.join` - Join DataFrames on meaning, not just values\n- `semantic.map` - Apply natural language transformations\n- `semantic.predicate` - Create predicates using natural language to filter rows\n- `semantic.reduce` - Aggregate grouped data with LLM operations\n\n#### Native Unstructured Data Support\n\nGoes beyond typical multimodal data types (audio, images) by creating specialized types for text-heavy workloads:\n\n- Markdown parsing and extraction as a first-class data type\n- Transcript processing (SRT, generic formats) with speaker and timestamp awareness\n- JSON manipulation with JQ expressions for nested data\n- Automatic text chunking with configurable overlap for long documents\n\n#### Production-Ready Infrastructure",
    "ContentSha": "NE5dPjdhTPxhAD1E+gcEg2tw/wEtQVkEuw1AGA1YwCQ=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "- `semantic.analyze_sentiment` - Analisi del sentiment integrata\n- `semantic.classify` - Categorizzazione del testo con esempi few-shot\n- `semantic.extract` - Trasforma testo non strutturato in dati strutturati tramite schemi\n- `semantic.group_by` - Raggruppa dati per similarità semantica\n- `semantic.join` - Unisce DataFrame in base al significato, non solo ai valori\n- `semantic.map` - Applica trasformazioni in linguaggio naturale\n- `semantic.predicate` - Crea predicati usando il linguaggio naturale per filtrare le righe\n- `semantic.reduce` - Aggrega dati raggruppati con operazioni LLM\n\n#### Supporto Nativo ai Dati Non Strutturati\n\nVa oltre i tipici tipi di dati multimodali (audio, immagini) creando tipi specializzati per carichi di lavoro con molto testo:\n\n- Parsing ed estrazione Markdown come tipo di dato di prima classe\n- Elaborazione di trascrizioni (SRT, formati generici) con riconoscimento di speaker e timestamp\n- Manipolazione JSON con espressioni JQ per dati annidati\n- Suddivisione automatica del testo con sovrapposizione configurabile per documenti lunghi\n\n#### Infrastruttura Pronta per la Produzione",
    "Status": "ok"
  },
  {
    "Id": 6,
    "Content": "\n- Multi-provider support (OpenAI, Anthropic, Gemini)\n- Local and cloud execution backends\n- Comprehensive error handling and logging\n- Pydantic integration for type safety\n\n#### Familiar DataFrame API\n\n- PySpark-compatible operations\n- Lazy evaluation and query optimization\n- SQL support for complex queries\n- Seamless integration with existing data pipelines\n\n### Why DataFrames for LLM and Agentic Applications?\n\nAI and agentic applications are fundamentally pipelines and workflows - exactly what DataFrame APIs were designed to handle. Rather than reinventing patterns for data transformation, filtering, and aggregation, fenic leverages decades of proven engineering practices.\n\n#### Decoupled Architecture for Better Agents\n\nfenic creates a clear separation between heavy inference tasks and real-time agent interactions. By moving batch processing out of the agent runtime, you get:\n\n- More predictable and responsive agents\n- Better resource utilization with batched LLM calls\n- Cleaner separation between planning/orchestration and execution\n",
    "ContentSha": "mT0TcKmDXUG4vMCvQ5Zt2Hov+kI1MOWz6tDxxgD3BGY=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "- Supporto multi-provider (OpenAI, Anthropic, Gemini)\n- Backend di esecuzione locali e cloud\n- Gestione completa degli errori e logging\n- Integrazione con Pydantic per la sicurezza dei tipi\n\n#### API DataFrame Familiare\n\n- Operazioni compatibili con PySpark\n- Valutazione pigra e ottimizzazione delle query\n- Supporto SQL per query complesse\n- Integrazione senza soluzione di continuità con pipeline di dati esistenti\n\n### Perché DataFrame per Applicazioni LLM e Agentiche?\n\nLe applicazioni AI e agentiche sono fondamentalmente pipeline e flussi di lavoro - esattamente ciò per cui sono state progettate le API DataFrame. Invece di reinventare schemi per la trasformazione, il filtraggio e l’aggregazione dei dati, fenic sfrutta decenni di pratiche ingegneristiche comprovate.\n\n#### Architettura Decoupled per Agenti Migliori\n\nfenic crea una chiara separazione tra i compiti di inferenza pesante e le interazioni in tempo reale degli agenti. Spostando l’elaborazione batch fuori dal runtime dell’agente, si ottiene:\n\n- Agenti più prevedibili e reattivi\n- Migliore utilizzo delle risorse con chiamate LLM batch\n- Separazione più pulita tra pianificazione/orchestrazione ed esecuzione",
    "Status": "ok"
  },
  {
    "Id": 7,
    "Content": "#### Built for All Engineers\n\nDataFrames aren't just for data practitioners. The fluent, composable API design makes it accessible to any engineer:\n\n- Chain operations naturally: `df.filter(...).semantic.group_by(...)`\n- Mix imperative and declarative styles seamlessly\n- Get started quickly with familiar patterns from pandas/PySpark or SQL\n\n## Support\n\nJoin our community on [Discord](https://discord.gg/GdqF3J7huR) where you can connect with other users, ask questions, and get help with your fenic projects. Our community is always happy to welcome newcomers!\n\nIf you find fenic useful, consider giving us a ⭐ at the top of this repository. Your support helps us grow and improve the framework for everyone!\n\n## Contributing\n\nWe welcome contributions of all kinds! Whether you're interested in writing code, improving documentation, testing features, or proposing new ideas, your help is valuable to us.\n\nFor developers planning to submit code changes, we encourage you to first open an issue to discuss your ideas before creating a Pull Request. This helps ensure alignment with the project's direction and prevents duplicate efforts.\n\nPlease refer to our [contribution guidelines](https://raw.githubusercontent.com/typedef-ai/fenic/main/CONTRIBUTING.md) for detailed information about the development process and project setup.\n",
    "ContentSha": "uskg5roWGwsGUjyK072Ea16WzdZZykGudJVeAy5e46I=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "#### Progettato per Tutti gli Ingegneri\n\nI DataFrame non sono solo per i professionisti dei dati. Il design dell’API fluida e componibile la rende accessibile a qualsiasi ingegnere:\n\n- Collega le operazioni in modo naturale: `df.filter(...).semantic.group_by(...)`\n- Mescola senza problemi stili imperativi e dichiarativi\n- Inizia rapidamente con pattern familiari da pandas/PySpark o SQL\n\n## Supporto\n\nUnisciti alla nostra community su [Discord](https://discord.gg/GdqF3J7huR) dove puoi connetterti con altri utenti, fare domande e ricevere assistenza per i tuoi progetti fenic. La nostra community è sempre felice di accogliere nuovi arrivati!\n\nSe trovi fenic utile, considera di lasciarci una ⭐ in cima a questo repository. Il tuo supporto ci aiuta a crescere e migliorare il framework per tutti!\n\n## Contribuire\n\nAccogliamo contributi di ogni tipo! Che tu sia interessato a scrivere codice, migliorare la documentazione, testare funzionalità o proporre nuove idee, il tuo aiuto è prezioso per noi.\n\nPer gli sviluppatori che intendono inviare modifiche al codice, consigliamo di aprire prima una issue per discutere le idee prima di creare una Pull Request. Questo aiuta a garantire l’allineamento con la direzione del progetto ed evita sforzi duplicati.\n\nConsulta le nostre [linee guida per i contributi](https://raw.githubusercontent.com/typedef-ai/fenic/main/CONTRIBUTING.md) per informazioni dettagliate sul processo di sviluppo e sulla configurazione del progetto.",
    "Status": "ok"
  }
]