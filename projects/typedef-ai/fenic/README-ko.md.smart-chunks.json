[
  {
    "Id": 1,
    "Content": "<!-- markdownlint-disable MD041 MD033 -->\n<div align=\"center\">\n    <picture>\n        <source media=\"(prefers-color-scheme: dark)\" srcset=\"docs/images/typedef-fenic-logo-dark.png\">\n        <img src=\"https://raw.githubusercontent.com/typedef-ai/fenic/main/docs/images/typedef-fenic-logo.png\" alt=\"fenic, by typedef\" width=\"90%\">\n    </picture>\n</div>\n\n# fenic: the dataframe (re)built for LLM inference\n\n[![PyPI version](https://img.shields.io/pypi/v/fenic.svg)](https://pypi.org/project/fenic/)\n[![Python versions](https://img.shields.io/pypi/pyversions/fenic.svg)](https://pypi.org/project/fenic/)\n[![License](https://img.shields.io/github/license/typedef-ai/fenic.svg)](https://github.com/typedef-ai/fenic/blob/main/LICENSE)\n[![Discord](https://img.shields.io/discord/1381706122322513952?label=Discord&logo=discord)](https://discord.gg/GdqF3J7huR)\n\n---\n\n## **Documentation**: [docs.fenic.ai](https://docs.fenic.ai/)\n\nfenic is an opinionated, PySpark-inspired DataFrame framework from typedef.ai for building AI and agentic applications. Transform unstructured and structured data into insights using familiar DataFrame operations enhanced with semantic intelligence. With first-class support for markdown, transcripts, and semantic operators, plus efficient batch inference across any model provider.\n",
    "ContentSha": "tmub1AxUb0Y4Al5Ltz67crbP453GMVUntyWUISmU7NQ=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "<!-- markdownlint-disable MD041 MD033 -->\n<div align=\"center\">\n    <picture>\n        <source media=\"(prefers-color-scheme: dark)\" srcset=\"docs/images/typedef-fenic-logo-dark.png\">\n        <img src=\"https://raw.githubusercontent.com/typedef-ai/fenic/main/docs/images/typedef-fenic-logo.png\" alt=\"fenic, by typedef\" width=\"90%\">\n    </picture>\n</div>\n\n# fenic: LLM 추론을 위해 (재)구성된 데이터프레임\n\n[![PyPI version](https://img.shields.io/pypi/v/fenic.svg)](https://pypi.org/project/fenic/)\n[![Python versions](https://img.shields.io/pypi/pyversions/fenic.svg)](https://pypi.org/project/fenic/)\n[![License](https://img.shields.io/github/license/typedef-ai/fenic.svg)](https://github.com/typedef-ai/fenic/blob/main/LICENSE)\n[![Discord](https://img.shields.io/discord/1381706122322513952?label=Discord&logo=discord)](https://discord.gg/GdqF3J7huR)\n\n---\n\n## **문서**: [docs.fenic.ai](https://docs.fenic.ai/)\n\nfenic은 typedef.ai에서 개발한 PySpark에서 영감을 받은 의견 중심의 DataFrame 프레임워크로, AI 및 에이전트 기반 애플리케이션 구축을 위해 설계되었습니다. 친숙한 DataFrame 연산에 의미론적 지능을 더해 비정형 및 정형 데이터를 인사이트로 변환합니다. Markdown, 대화록, 의미론적 연산자에 대한 일급 지원과 더불어, 모든 모델 제공자에 대해 효율적인 배치 추론을 제공합니다.",
    "Status": "ok"
  },
  {
    "Id": 2,
    "Content": "## Install\n\nfenic supports Python `[3.10, 3.11, 3.12]`\n\n```bash\npip install fenic\n```\n\n### LLM Provider Setup\n\nfenic requires an API key from at least one LLM provider. Set the appropriate environment variable for your chosen provider:\n\n```bash\n# For OpenAI\nexport OPENAI_API_KEY=\"your-openai-api-key\"\n\n# For Anthropic\nexport ANTHROPIC_API_KEY=\"your-anthropic-api-key\"\n\n# For Google",
    "ContentSha": "QT2GWoHGnyfwnJxlfZAk0I5rpIsEfvGEhJD38oz6lCY=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "## 설치\n\nfenic은 Python `[3.10, 3.11, 3.12]`을 지원합니다.\n\n```bash\npip install fenic\n```\n\n### LLM 제공자 설정\n\nfenic은 최소 한 개의 LLM 제공자로부터 API 키가 필요합니다. 선택한 제공자에 맞는 환경 변수를 설정하세요:\n\n```bash\n# OpenAI의 경우\nexport OPENAI_API_KEY=\"your-openai-api-key\"\n\n# Anthropic의 경우\nexport ANTHROPIC_API_KEY=\"your-anthropic-api-key\"\n\n# Google",
    "Status": "ok"
  },
  {
    "Id": 3,
    "Content": "export GEMINI_API_KEY=\"your-google-api-key\"\n```\n\n## Quickstart\n\nThe fastest way to learn about fenic is by checking the examples.\n\nBelow is a quick list of the examples in this repo:\n\n| Example                                                                 | Description                                                                                                                         |\n| ----------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------- |\n| [Hello World!](examples/hello_world)                                    | Introduction to semantic extraction and classification using fenic's core operators through error log analysis.                     |\n| [Enrichment](examples/enrichment)                                       | Multi-stage DataFrames with template-based text extraction, joins, and LLM-powered transformations demonstrated via log enrichment. |\n| [Meeting Transcript Processing](examples/meeting_transcript_processing) | Native transcript parsing, Pydantic schema integration, and complex aggregations shown through meeting analysis.                    |\n| [News Analysis](examples/news_analysis)                                 | Analyze and extract insights from news articles using semantic operators and structured data processing.                            |\n| [Podcast Summarization](examples/podcast_summarization)                 | Process and summarize podcast transcripts with speaker-aware analysis and key point extraction.                                     |\n| [Semantic Join](examples/semantic_joins)                                | Instead of simple fuzzy matching, use fenic's powerful semantic join functionality to match data across tables.                     |\n| [Named Entity Recognition](examples/named_entity_recognition)           | Extract and classify named entities from text using semantic extraction and classification.                                         |\n| [Markdown Processing](examples/markdown_processing)                     | Process and transform markdown documents with structured data extraction and formatting.                                            |\n| [JSON Processing](examples/json_processing)                             | Handle complex JSON data structures with semantic operations and schema validation.                                                 |\n| [Feedback Clustering](examples/feedback_clustering)                     | Group and analyze feedback using semantic similarity and clustering operations.                                                     |\n| [Document Extraction](examples/document_extraction)                     | Extract structured information from various document formats using semantic operators.                                              |\n\n(Feel free to click any example above to jump right to its folder.)\n",
    "ContentSha": "RBvJ+qAaDZODC8rvu1sFp9QTE4SUhSKTTu/91HAxBRc=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\nexport GEMINI_API_KEY=\"your-google-api-key\"\n```\n\n## 빠른 시작\n\nfenic을 빠르게 배우는 가장 좋은 방법은 예제들을 살펴보는 것입니다.\n\n아래는 이 저장소에 포함된 예제들의 간단한 목록입니다:\n\n| 예제                                                                      | 설명                                                                                                                               |\n| ------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------- |\n| [Hello World!](examples/hello_world)                                      | 오류 로그 분석을 통해 fenic의 핵심 연산자를 사용한 의미론적 추출 및 분류 소개.                                                    |\n| [Enrichment](examples/enrichment)                                         | 템플릿 기반 텍스트 추출, 조인, LLM 기반 변환이 포함된 다단계 DataFrame을 로그 강화 예제로 시연.                                    |\n| [회의록 처리](examples/meeting_transcript_processing)                      | 회의 분석을 통해 네이티브 회의록 파싱, Pydantic 스키마 통합, 복잡한 집계 방법을 보여줌.                                           |\n| [뉴스 분석](examples/news_analysis)                                       | 의미 연산자와 구조화된 데이터 처리를 사용하여 뉴스 기사에서 인사이트를 분석 및 추출.                                              |\n| [팟캐스트 요약](examples/podcast_summarization)                           | 화자 인식 분석 및 주요 포인트 추출로 팟캐스트 회의록을 처리하고 요약.                                                              |\n| [의미론적 조인](examples/semantic_joins)                                  | 단순한 퍼지 매칭 대신, fenic의 강력한 의미론적 조인 기능으로 테이블 간 데이터 매칭.                                                |\n| [명명된 개체 인식](examples/named_entity_recognition)                     | 의미론적 추출 및 분류를 통해 텍스트에서 명명된 개체 추출 및 분류.                                                                  |\n| [마크다운 처리](examples/markdown_processing)                             | 구조화된 데이터 추출 및 형식 지정을 통해 마크다운 문서를 처리 및 변환.                                                             |\n| [JSON 처리](examples/json_processing)                                     | 의미 연산 및 스키마 검증을 통해 복잡한 JSON 데이터 구조 처리.                                                                      |\n| [피드백 클러스터링](examples/feedback_clustering)                         | 의미 유사도 및 클러스터링 연산을 사용하여 피드백을 그룹화 및 분석.                                                                 |\n| [문서 추출](examples/document_extraction)                                 | 의미 연산자를 사용하여 다양한 문서 형식에서 구조화된 정보 추출.                                                                    |\n\n(위 예제 중 원하는 항목을 클릭하면 해당 폴더로 바로 이동할 수 있습니다.)\n",
    "Status": "ok"
  },
  {
    "Id": 4,
    "Content": "## Why use fenic?\n\nfenic is an opinionated, PySpark-inspired DataFrame framework for building production AI and agentic applications.\n\nUnlike traditional data tools retrofitted for LLMs, fenic's query engine is built from the ground up with inference in mind.\n\nTransform structured and unstructured data into insights using familiar DataFrame operations enhanced with semantic intelligence. With first-class support for markdown, transcripts, and semantic operators, plus efficient batch inference across any model provider.\n\nfenic brings the reliability of traditional data pipelines to AI workloads.\n\n### Key Features\n\n#### Purpose-Built for LLM Inference\n\n- Query engine designed from scratch for AI workloads, not retrofitted\n- Automatic batch optimization for API calls\n- Built-in retry logic and rate limiting\n- Token counting and cost tracking\n\n#### Semantic Operators as First-Class Citizens",
    "ContentSha": "POPTpr2d3zFT3V0X0/NRjmMCUTjlIPBHtMTVHIRsyfM=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "## 왜 fenic을 사용해야 하나요?\n\nfenic은 생산용 AI 및 에이전트 애플리케이션 구축을 위해 설계된, PySpark에서 영감을 받은 의견이 반영된 DataFrame 프레임워크입니다.\n\n기존의 LLM에 맞춰 개조된 전통적인 데이터 도구와 달리, fenic의 쿼리 엔진은 추론을 염두에 두고 처음부터 설계되었습니다.\n\n익숙한 DataFrame 연산에 의미론적 지능을 더해 구조화 및 비구조화 데이터를 인사이트로 변환하세요. 마크다운, 트랜스크립트, 의미론적 연산자에 대한 일류 지원과 모든 모델 제공자에서 효율적인 배치 추론을 제공합니다.\n\nfenic은 전통적인 데이터 파이프라인의 신뢰성을 AI 워크로드에 제공합니다.\n\n### 주요 기능\n\n#### LLM 추론을 위한 목적 기반 설계\n\n- AI 워크로드를 위해 처음부터 설계된 쿼리 엔진, 개조 아님\n- API 호출의 자동 배치 최적화\n- 내장된 재시도 로직과 속도 제한\n- 토큰 카운팅 및 비용 추적\n\n#### 일류 시민으로서의 의미론적 연산자",
    "Status": "ok"
  },
  {
    "Id": 5,
    "Content": "\n- `semantic.analyze_sentiment` - Built-in sentiment analysis\n- `semantic.classify` - Categorize text with few-shot examples\n- `semantic.extract` - Transform unstructured text into structured data with schemas\n- `semantic.group_by` - Group data by semantic similarity\n- `semantic.join` - Join DataFrames on meaning, not just values\n- `semantic.map` - Apply natural language transformations\n- `semantic.predicate` - Create predicates using natural language to filter rows\n- `semantic.reduce` - Aggregate grouped data with LLM operations\n\n#### Native Unstructured Data Support\n\nGoes beyond typical multimodal data types (audio, images) by creating specialized types for text-heavy workloads:\n\n- Markdown parsing and extraction as a first-class data type\n- Transcript processing (SRT, generic formats) with speaker and timestamp awareness\n- JSON manipulation with JQ expressions for nested data\n- Automatic text chunking with configurable overlap for long documents\n\n#### Production-Ready Infrastructure",
    "ContentSha": "NE5dPjdhTPxhAD1E+gcEg2tw/wEtQVkEuw1AGA1YwCQ=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "- `semantic.analyze_sentiment` - 내장 감정 분석\n- `semantic.classify` - 몇 개의 예시로 텍스트 분류\n- `semantic.extract` - 비정형 텍스트를 스키마와 함께 구조화된 데이터로 변환\n- `semantic.group_by` - 의미적 유사성에 따라 데이터 그룹화\n- `semantic.join` - 값이 아닌 의미 기반으로 DataFrame 조인\n- `semantic.map` - 자연어 변환 적용\n- `semantic.predicate` - 자연어로 조건문을 생성해 행 필터링\n- `semantic.reduce` - LLM 연산으로 그룹화된 데이터 집계\n\n#### 네이티브 비정형 데이터 지원\n\n일반적인 멀티모달 데이터 유형(오디오, 이미지)을 넘어, 텍스트 중심 작업을 위한 특수 유형 제공:\n\n- Markdown 구문 분석 및 추출을 일급 데이터 유형으로 지원\n- 화자 및 타임스탬프 인식이 가능한 전사본 처리(SRT, 일반 포맷)\n- 중첩 데이터 처리를 위한 JQ 표현식 기반 JSON 조작\n- 긴 문서에 대한 설정 가능한 중첩 자동 텍스트 청킹\n\n#### 프로덕션 준비 인프라",
    "Status": "ok"
  },
  {
    "Id": 6,
    "Content": "\n- Multi-provider support (OpenAI, Anthropic, Gemini)\n- Local and cloud execution backends\n- Comprehensive error handling and logging\n- Pydantic integration for type safety\n\n#### Familiar DataFrame API\n\n- PySpark-compatible operations\n- Lazy evaluation and query optimization\n- SQL support for complex queries\n- Seamless integration with existing data pipelines\n\n### Why DataFrames for LLM and Agentic Applications?\n\nAI and agentic applications are fundamentally pipelines and workflows - exactly what DataFrame APIs were designed to handle. Rather than reinventing patterns for data transformation, filtering, and aggregation, fenic leverages decades of proven engineering practices.\n\n#### Decoupled Architecture for Better Agents\n\nfenic creates a clear separation between heavy inference tasks and real-time agent interactions. By moving batch processing out of the agent runtime, you get:\n\n- More predictable and responsive agents\n- Better resource utilization with batched LLM calls\n- Cleaner separation between planning/orchestration and execution\n",
    "ContentSha": "mT0TcKmDXUG4vMCvQ5Zt2Hov+kI1MOWz6tDxxgD3BGY=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "- 멀티 프로바이더 지원 (OpenAI, Anthropic, Gemini)\n- 로컬 및 클라우드 실행 백엔드\n- 포괄적인 오류 처리 및 로깅\n- 타입 안전성을 위한 Pydantic 통합\n\n#### 익숙한 DataFrame API\n\n- PySpark 호환 연산\n- 지연 평가 및 쿼리 최적화\n- 복잡한 쿼리를 위한 SQL 지원\n- 기존 데이터 파이프라인과의 원활한 통합\n\n### LLM 및 에이전트 기반 애플리케이션에 DataFrame을 사용하는 이유는 무엇인가요?\n\nAI 및 에이전트 기반 애플리케이션은 본질적으로 파이프라인과 워크플로우입니다. 이는 DataFrame API가 처리하도록 설계된 바로 그 영역입니다. 데이터 변환, 필터링, 집계를 위한 패턴을 새로 만들기보다는, fenic은 수십 년간 검증된 엔지니어링 관행을 활용합니다.\n\n#### 더 나은 에이전트를 위한 분리된 아키텍처\n\nfenic은 무거운 추론 작업과 실시간 에이전트 상호작용 간에 명확한 분리를 만듭니다. 배치 처리를 에이전트 런타임 밖으로 이동함으로써 다음과 같은 이점을 얻을 수 있습니다:\n\n- 더 예측 가능하고 반응성이 뛰어난 에이전트\n- 배치 LLM 호출로 더 나은 리소스 활용\n- 계획/오케스트레이션과 실행의 명확한 분리",
    "Status": "ok"
  },
  {
    "Id": 7,
    "Content": "#### Built for All Engineers\n\nDataFrames aren't just for data practitioners. The fluent, composable API design makes it accessible to any engineer:\n\n- Chain operations naturally: `df.filter(...).semantic.group_by(...)`\n- Mix imperative and declarative styles seamlessly\n- Get started quickly with familiar patterns from pandas/PySpark or SQL\n\n## Support\n\nJoin our community on [Discord](https://discord.gg/GdqF3J7huR) where you can connect with other users, ask questions, and get help with your fenic projects. Our community is always happy to welcome newcomers!\n\nIf you find fenic useful, consider giving us a ⭐ at the top of this repository. Your support helps us grow and improve the framework for everyone!\n\n## Contributing\n\nWe welcome contributions of all kinds! Whether you're interested in writing code, improving documentation, testing features, or proposing new ideas, your help is valuable to us.\n\nFor developers planning to submit code changes, we encourage you to first open an issue to discuss your ideas before creating a Pull Request. This helps ensure alignment with the project's direction and prevents duplicate efforts.\n\nPlease refer to our [contribution guidelines](https://raw.githubusercontent.com/typedef-ai/fenic/main/CONTRIBUTING.md) for detailed information about the development process and project setup.\n",
    "ContentSha": "uskg5roWGwsGUjyK072Ea16WzdZZykGudJVeAy5e46I=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "#### 모든 엔지니어를 위해 설계됨\n\nDataFrame은 데이터 실무자만을 위한 것이 아닙니다. 유연하고 조합 가능한 API 디자인 덕분에 모든 엔지니어가 쉽게 사용할 수 있습니다:\n\n- 자연스럽게 연산을 체이닝: `df.filter(...).semantic.group_by(...)`\n- 명령형과 선언형 스타일을 매끄럽게 혼합\n- pandas/PySpark 또는 SQL에서 익숙한 패턴으로 빠르게 시작 가능\n\n## 지원\n\n[Discord](https://discord.gg/GdqF3J7huR) 커뮤니티에 참여하여 다른 사용자들과 소통하고, 질문을 하거나, fenic 프로젝트에 대한 도움을 받을 수 있습니다. 저희 커뮤니티는 언제나 새로운 분들을 환영합니다!\n\nfenic이 유용하다면, 이 저장소 상단에서 ⭐을 눌러주세요. 여러분의 응원이 프레임워크의 성장과 개선에 큰 힘이 됩니다!\n\n## 기여하기\n\n모든 종류의 기여를 환영합니다! 코드 작성, 문서 개선, 기능 테스트, 새로운 아이디어 제안 등 어떤 형태로든 여러분의 도움이 소중합니다.\n\n코드 변경을 계획하는 개발자라면, Pull Request를 생성하기 전에 먼저 이슈를 열어 아이디어를 논의해 주시길 권장합니다. 이는 프로젝트 방향성과의 정렬을 보장하고, 중복 작업을 방지하는 데 도움이 됩니다.\n\n개발 프로세스 및 프로젝트 설정에 대한 자세한 내용은 [기여 가이드라인](https://raw.githubusercontent.com/typedef-ai/fenic/main/CONTRIBUTING.md)을 참고해 주세요.",
    "Status": "ok"
  }
]