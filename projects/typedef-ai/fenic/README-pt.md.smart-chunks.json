[
  {
    "Id": 1,
    "Content": "<!-- markdownlint-disable MD041 MD033 -->\n<div align=\"center\">\n    <picture>\n        <source media=\"(prefers-color-scheme: dark)\" srcset=\"docs/images/typedef-fenic-logo-dark.png\">\n        <img src=\"https://raw.githubusercontent.com/typedef-ai/fenic/main/docs/images/typedef-fenic-logo.png\" alt=\"fenic, by typedef\" width=\"90%\">\n    </picture>\n</div>\n\n# fenic: the dataframe (re)built for LLM inference\n\n[![PyPI version](https://img.shields.io/pypi/v/fenic.svg)](https://pypi.org/project/fenic/)\n[![Python versions](https://img.shields.io/pypi/pyversions/fenic.svg)](https://pypi.org/project/fenic/)\n[![License](https://img.shields.io/github/license/typedef-ai/fenic.svg)](https://github.com/typedef-ai/fenic/blob/main/LICENSE)\n[![Discord](https://img.shields.io/discord/1381706122322513952?label=Discord&logo=discord)](https://discord.gg/GdqF3J7huR)\n\n---\n\n## **Documentation**: [docs.fenic.ai](https://docs.fenic.ai/)\n\nfenic is an opinionated, PySpark-inspired DataFrame framework from typedef.ai for building AI and agentic applications. Transform unstructured and structured data into insights using familiar DataFrame operations enhanced with semantic intelligence. With first-class support for markdown, transcripts, and semantic operators, plus efficient batch inference across any model provider.\n",
    "ContentSha": "tmub1AxUb0Y4Al5Ltz67crbP453GMVUntyWUISmU7NQ=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "<!-- markdownlint-disable MD041 MD033 -->\n<div align=\"center\">\n    <picture>\n        <source media=\"(prefers-color-scheme: dark)\" srcset=\"docs/images/typedef-fenic-logo-dark.png\">\n        <img src=\"https://raw.githubusercontent.com/typedef-ai/fenic/main/docs/images/typedef-fenic-logo.png\" alt=\"fenic, by typedef\" width=\"90%\">\n    </picture>\n</div>\n\n# fenic: o dataframe (re)construído para inferência LLM\n\n[![Versão no PyPI](https://img.shields.io/pypi/v/fenic.svg)](https://pypi.org/project/fenic/)\n[![Versões do Python](https://img.shields.io/pypi/pyversions/fenic.svg)](https://pypi.org/project/fenic/)\n[![Licença](https://img.shields.io/github/license/typedef-ai/fenic.svg)](https://github.com/typedef-ai/fenic/blob/main/LICENSE)\n[![Discord](https://img.shields.io/discord/1381706122322513952?label=Discord&logo=discord)](https://discord.gg/GdqF3J7huR)\n\n---\n\n## **Documentação**: [docs.fenic.ai](https://docs.fenic.ai/)\n\nfenic é um framework de DataFrame opinativo, inspirado no PySpark, da typedef.ai para construir aplicações de IA e agentes. Transforme dados não estruturados e estruturados em insights usando operações familiares de DataFrame aprimoradas com inteligência semântica. Com suporte de primeira classe para markdown, transcrições e operadores semânticos, além de inferência em lote eficiente através de qualquer provedor de modelo.",
    "Status": "ok"
  },
  {
    "Id": 2,
    "Content": "## Install\n\nfenic supports Python `[3.10, 3.11, 3.12]`\n\n```bash\npip install fenic\n```\n\n### LLM Provider Setup\n\nfenic requires an API key from at least one LLM provider. Set the appropriate environment variable for your chosen provider:\n\n```bash\n# For OpenAI\nexport OPENAI_API_KEY=\"your-openai-api-key\"\n\n# For Anthropic\nexport ANTHROPIC_API_KEY=\"your-anthropic-api-key\"\n\n# For Google",
    "ContentSha": "QT2GWoHGnyfwnJxlfZAk0I5rpIsEfvGEhJD38oz6lCY=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "## Instalação\n\nfenic suporta Python `[3.10, 3.11, 3.12]`\n\n```bash\npip install fenic\n```\n\n### Configuração do Provedor de LLM\n\nfenic requer uma chave de API de pelo menos um provedor de LLM. Defina a variável de ambiente apropriada para o provedor escolhido:\n\n```bash\n# Para OpenAI\nexport OPENAI_API_KEY=\"sua-chave-api-openai\"\n\n# Para Anthropic\nexport ANTHROPIC_API_KEY=\"sua-chave-api-anthropic\"\n\n# Para Google",
    "Status": "ok"
  },
  {
    "Id": 3,
    "Content": "export GEMINI_API_KEY=\"your-google-api-key\"\n```\n\n## Quickstart\n\nThe fastest way to learn about fenic is by checking the examples.\n\nBelow is a quick list of the examples in this repo:\n\n| Example                                                                 | Description                                                                                                                         |\n| ----------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------- |\n| [Hello World!](examples/hello_world)                                    | Introduction to semantic extraction and classification using fenic's core operators through error log analysis.                     |\n| [Enrichment](examples/enrichment)                                       | Multi-stage DataFrames with template-based text extraction, joins, and LLM-powered transformations demonstrated via log enrichment. |\n| [Meeting Transcript Processing](examples/meeting_transcript_processing) | Native transcript parsing, Pydantic schema integration, and complex aggregations shown through meeting analysis.                    |\n| [News Analysis](examples/news_analysis)                                 | Analyze and extract insights from news articles using semantic operators and structured data processing.                            |\n| [Podcast Summarization](examples/podcast_summarization)                 | Process and summarize podcast transcripts with speaker-aware analysis and key point extraction.                                     |\n| [Semantic Join](examples/semantic_joins)                                | Instead of simple fuzzy matching, use fenic's powerful semantic join functionality to match data across tables.                     |\n| [Named Entity Recognition](examples/named_entity_recognition)           | Extract and classify named entities from text using semantic extraction and classification.                                         |\n| [Markdown Processing](examples/markdown_processing)                     | Process and transform markdown documents with structured data extraction and formatting.                                            |\n| [JSON Processing](examples/json_processing)                             | Handle complex JSON data structures with semantic operations and schema validation.                                                 |\n| [Feedback Clustering](examples/feedback_clustering)                     | Group and analyze feedback using semantic similarity and clustering operations.                                                     |\n| [Document Extraction](examples/document_extraction)                     | Extract structured information from various document formats using semantic operators.                                              |\n\n(Feel free to click any example above to jump right to its folder.)\n",
    "ContentSha": "RBvJ+qAaDZODC8rvu1sFp9QTE4SUhSKTTu/91HAxBRc=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "export GEMINI_API_KEY=\"sua-chave-api-do-google\"\n```\n\n## Início Rápido\n\nA maneira mais rápida de aprender sobre o fenic é conferindo os exemplos.\n\nAbaixo está uma lista rápida dos exemplos neste repositório:\n\n| Exemplo                                                                   | Descrição                                                                                                                          |\n| ------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------- |\n| [Hello World!](examples/hello_world)                                      | Introdução à extração e classificação semântica usando os operadores principais do fenic através da análise de logs de erro.       |\n| [Enriquecimento](examples/enrichment)                                     | DataFrames em múltiplas etapas com extração de texto baseada em templates, joins e transformações com LLM demonstradas via log.    |\n| [Processamento de Transcrição de Reunião](examples/meeting_transcript_processing) | Análise nativa de transcrições, integração de schemas Pydantic e agregações complexas apresentadas através da análise de reuniões. |\n| [Análise de Notícias](examples/news_analysis)                             | Analise e extraia insights de artigos de notícias utilizando operadores semânticos e processamento de dados estruturados.          |\n| [Sumarização de Podcast](examples/podcast_summarization)                  | Processe e resuma transcrições de podcasts com análise sensível ao locutor e extração de pontos-chave.                             |\n| [Join Semântico](examples/semantic_joins)                                 | Em vez de simples correspondência fuzzy, use o poderoso join semântico do fenic para casar dados entre tabelas.                    |\n| [Reconhecimento de Entidades Nomeadas](examples/named_entity_recognition) | Extraia e classifique entidades nomeadas de textos usando extração e classificação semântica.                                      |\n| [Processamento de Markdown](examples/markdown_processing)                 | Processe e transforme documentos markdown com extração de dados estruturados e formatação.                                         |\n| [Processamento de JSON](examples/json_processing)                         | Lide com estruturas de dados JSON complexas utilizando operações semânticas e validação de schema.                                 |\n| [Agrupamento de Feedback](examples/feedback_clustering)                   | Agrupe e analise feedbacks usando similaridade semântica e operações de clusterização.                                             |\n| [Extração de Documentos](examples/document_extraction)                    | Extraia informações estruturadas de vários formatos de documentos usando operadores semânticos.                                    |\n\n(Sinta-se à vontade para clicar em qualquer exemplo acima para ir diretamente à sua pasta.)",
    "Status": "ok"
  },
  {
    "Id": 4,
    "Content": "## Why use fenic?\n\nfenic is an opinionated, PySpark-inspired DataFrame framework for building production AI and agentic applications.\n\nUnlike traditional data tools retrofitted for LLMs, fenic's query engine is built from the ground up with inference in mind.\n\nTransform structured and unstructured data into insights using familiar DataFrame operations enhanced with semantic intelligence. With first-class support for markdown, transcripts, and semantic operators, plus efficient batch inference across any model provider.\n\nfenic brings the reliability of traditional data pipelines to AI workloads.\n\n### Key Features\n\n#### Purpose-Built for LLM Inference\n\n- Query engine designed from scratch for AI workloads, not retrofitted\n- Automatic batch optimization for API calls\n- Built-in retry logic and rate limiting\n- Token counting and cost tracking\n\n#### Semantic Operators as First-Class Citizens",
    "ContentSha": "POPTpr2d3zFT3V0X0/NRjmMCUTjlIPBHtMTVHIRsyfM=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "## Por que usar o fenic?\n\nfenic é um framework de DataFrame opinativo, inspirado no PySpark, para construção de aplicações de IA e agentes em produção.\n\nDiferente das ferramentas de dados tradicionais adaptadas para LLMs, o mecanismo de consulta do fenic foi criado do zero, já considerando inferência.\n\nTransforme dados estruturados e não estruturados em insights usando operações de DataFrame familiares, aprimoradas com inteligência semântica. Com suporte de primeira classe para markdown, transcrições e operadores semânticos, além de inferência em lote eficiente em qualquer provedor de modelo.\n\nfenic traz a confiabilidade dos pipelines de dados tradicionais para cargas de trabalho de IA.\n\n### Principais Recursos\n\n#### Desenvolvido para Inferência de LLM\n\n- Mecanismo de consulta projetado do zero para cargas de trabalho de IA, não adaptado\n- Otimização automática de lotes para chamadas de API\n- Lógica de retentativa embutida e limitação de taxa\n- Contagem de tokens e rastreamento de custos\n\n#### Operadores Semânticos como Cidadãos de Primeira Classe",
    "Status": "ok"
  },
  {
    "Id": 5,
    "Content": "\n- `semantic.analyze_sentiment` - Built-in sentiment analysis\n- `semantic.classify` - Categorize text with few-shot examples\n- `semantic.extract` - Transform unstructured text into structured data with schemas\n- `semantic.group_by` - Group data by semantic similarity\n- `semantic.join` - Join DataFrames on meaning, not just values\n- `semantic.map` - Apply natural language transformations\n- `semantic.predicate` - Create predicates using natural language to filter rows\n- `semantic.reduce` - Aggregate grouped data with LLM operations\n\n#### Native Unstructured Data Support\n\nGoes beyond typical multimodal data types (audio, images) by creating specialized types for text-heavy workloads:\n\n- Markdown parsing and extraction as a first-class data type\n- Transcript processing (SRT, generic formats) with speaker and timestamp awareness\n- JSON manipulation with JQ expressions for nested data\n- Automatic text chunking with configurable overlap for long documents\n\n#### Production-Ready Infrastructure",
    "ContentSha": "NE5dPjdhTPxhAD1E+gcEg2tw/wEtQVkEuw1AGA1YwCQ=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "- `semantic.analyze_sentiment` - Análise de sentimento incorporada\n- `semantic.classify` - Categorize texto com exemplos few-shot\n- `semantic.extract` - Transforme texto não estruturado em dados estruturados com esquemas\n- `semantic.group_by` - Agrupe dados por similaridade semântica\n- `semantic.join` - Una DataFrames pelo significado, não apenas pelos valores\n- `semantic.map` - Aplique transformações de linguagem natural\n- `semantic.predicate` - Crie predicados usando linguagem natural para filtrar linhas\n- `semantic.reduce` - Agregue dados agrupados com operações de LLM\n\n#### Suporte Nativo a Dados Não Estruturados\n\nVai além dos tipos de dados multimodais típicos (áudio, imagens) criando tipos especializados para cargas de trabalho com grande volume de texto:\n\n- Análise e extração de Markdown como tipo de dado de primeira classe\n- Processamento de transcrições (SRT, formatos genéricos) com reconhecimento de falante e marcação temporal\n- Manipulação de JSON com expressões JQ para dados aninhados\n- Fragmentação automática de texto com sobreposição configurável para documentos longos\n\n#### Infraestrutura Pronta para Produção",
    "Status": "ok"
  },
  {
    "Id": 6,
    "Content": "\n- Multi-provider support (OpenAI, Anthropic, Gemini)\n- Local and cloud execution backends\n- Comprehensive error handling and logging\n- Pydantic integration for type safety\n\n#### Familiar DataFrame API\n\n- PySpark-compatible operations\n- Lazy evaluation and query optimization\n- SQL support for complex queries\n- Seamless integration with existing data pipelines\n\n### Why DataFrames for LLM and Agentic Applications?\n\nAI and agentic applications are fundamentally pipelines and workflows - exactly what DataFrame APIs were designed to handle. Rather than reinventing patterns for data transformation, filtering, and aggregation, fenic leverages decades of proven engineering practices.\n\n#### Decoupled Architecture for Better Agents\n\nfenic creates a clear separation between heavy inference tasks and real-time agent interactions. By moving batch processing out of the agent runtime, you get:\n\n- More predictable and responsive agents\n- Better resource utilization with batched LLM calls\n- Cleaner separation between planning/orchestration and execution\n",
    "ContentSha": "mT0TcKmDXUG4vMCvQ5Zt2Hov+kI1MOWz6tDxxgD3BGY=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "- Suporte a múltiplos provedores (OpenAI, Anthropic, Gemini)\n- Backends de execução locais e na nuvem\n- Tratamento abrangente de erros e logging\n- Integração com Pydantic para segurança de tipos\n\n#### API Familiar de DataFrame\n\n- Operações compatíveis com PySpark\n- Avaliação preguiçosa e otimização de consultas\n- Suporte a SQL para consultas complexas\n- Integração perfeita com pipelines de dados existentes\n\n### Por que DataFrames para Aplicações LLM e Agentes?\n\nAplicações de IA e agentes são fundamentalmente pipelines e fluxos de trabalho – exatamente o que as APIs de DataFrame foram projetadas para lidar. Ao invés de reinventar padrões para transformação, filtragem e agregação de dados, o fenic aproveita décadas de práticas de engenharia comprovadas.\n\n#### Arquitetura Desacoplada para Melhores Agentes\n\nO fenic cria uma separação clara entre tarefas pesadas de inferência e interações em tempo real dos agentes. Ao mover o processamento em lote para fora do tempo de execução do agente, você obtém:\n\n- Agentes mais previsíveis e responsivos\n- Melhor utilização de recursos com chamadas LLM em lote\n- Separação mais limpa entre planejamento/orquestração e execução",
    "Status": "ok"
  },
  {
    "Id": 7,
    "Content": "#### Built for All Engineers\n\nDataFrames aren't just for data practitioners. The fluent, composable API design makes it accessible to any engineer:\n\n- Chain operations naturally: `df.filter(...).semantic.group_by(...)`\n- Mix imperative and declarative styles seamlessly\n- Get started quickly with familiar patterns from pandas/PySpark or SQL\n\n## Support\n\nJoin our community on [Discord](https://discord.gg/GdqF3J7huR) where you can connect with other users, ask questions, and get help with your fenic projects. Our community is always happy to welcome newcomers!\n\nIf you find fenic useful, consider giving us a ⭐ at the top of this repository. Your support helps us grow and improve the framework for everyone!\n\n## Contributing\n\nWe welcome contributions of all kinds! Whether you're interested in writing code, improving documentation, testing features, or proposing new ideas, your help is valuable to us.\n\nFor developers planning to submit code changes, we encourage you to first open an issue to discuss your ideas before creating a Pull Request. This helps ensure alignment with the project's direction and prevents duplicate efforts.\n\nPlease refer to our [contribution guidelines](https://raw.githubusercontent.com/typedef-ai/fenic/main/CONTRIBUTING.md) for detailed information about the development process and project setup.\n",
    "ContentSha": "uskg5roWGwsGUjyK072Ea16WzdZZykGudJVeAy5e46I=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "#### Feito para Todos os Engenheiros\n\nDataFrames não são apenas para profissionais de dados. O design da API fluente e componível a torna acessível para qualquer engenheiro:\n\n- Encadeie operações de forma natural: `df.filter(...).semantic.group_by(...)`\n- Misture estilos imperativos e declarativos perfeitamente\n- Comece rapidamente com padrões familiares do pandas/PySpark ou SQL\n\n## Suporte\n\nJunte-se à nossa comunidade no [Discord](https://discord.gg/GdqF3J7huR), onde você pode se conectar com outros usuários, fazer perguntas e obter ajuda com seus projetos fenic. Nossa comunidade está sempre feliz em receber novos membros!\n\nSe você achar o fenic útil, considere nos dar uma ⭐ no topo deste repositório. Seu apoio nos ajuda a crescer e melhorar o framework para todos!\n\n## Contribuindo\n\nAcolhemos contribuições de todos os tipos! Seja escrevendo código, melhorando a documentação, testando funcionalidades ou propondo novas ideias, sua ajuda é valiosa para nós.\n\nPara desenvolvedores que planejam enviar alterações de código, incentivamos que abram primeiro uma issue para discutir suas ideias antes de criar um Pull Request. Isso ajuda a garantir o alinhamento com a direção do projeto e evita esforços duplicados.\n\nConsulte nossas [diretrizes de contribuição](https://raw.githubusercontent.com/typedef-ai/fenic/main/CONTRIBUTING.md) para informações detalhadas sobre o processo de desenvolvimento e configuração do projeto.",
    "Status": "ok"
  }
]