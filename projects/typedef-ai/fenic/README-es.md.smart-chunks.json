[
  {
    "Id": 1,
    "Content": "<!-- markdownlint-disable MD041 MD033 -->\n<div align=\"center\">\n    <picture>\n        <source media=\"(prefers-color-scheme: dark)\" srcset=\"docs/images/typedef-fenic-logo-dark.png\">\n        <img src=\"https://raw.githubusercontent.com/typedef-ai/fenic/main/docs/images/typedef-fenic-logo.png\" alt=\"fenic, by typedef\" width=\"90%\">\n    </picture>\n</div>\n\n# fenic: the dataframe (re)built for LLM inference\n\n[![PyPI version](https://img.shields.io/pypi/v/fenic.svg)](https://pypi.org/project/fenic/)\n[![Python versions](https://img.shields.io/pypi/pyversions/fenic.svg)](https://pypi.org/project/fenic/)\n[![License](https://img.shields.io/github/license/typedef-ai/fenic.svg)](https://github.com/typedef-ai/fenic/blob/main/LICENSE)\n[![Discord](https://img.shields.io/discord/1381706122322513952?label=Discord&logo=discord)](https://discord.gg/GdqF3J7huR)\n\n---\n\n## **Documentation**: [docs.fenic.ai](https://docs.fenic.ai/)\n\nfenic is an opinionated, PySpark-inspired DataFrame framework from typedef.ai for building AI and agentic applications. Transform unstructured and structured data into insights using familiar DataFrame operations enhanced with semantic intelligence. With first-class support for markdown, transcripts, and semantic operators, plus efficient batch inference across any model provider.\n",
    "ContentSha": "tmub1AxUb0Y4Al5Ltz67crbP453GMVUntyWUISmU7NQ=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "<!-- markdownlint-disable MD041 MD033 -->\n<div align=\"center\">\n    <picture>\n        <source media=\"(prefers-color-scheme: dark)\" srcset=\"docs/images/typedef-fenic-logo-dark.png\">\n        <img src=\"https://raw.githubusercontent.com/typedef-ai/fenic/main/docs/images/typedef-fenic-logo.png\" alt=\"fenic, by typedef\" width=\"90%\">\n    </picture>\n</div>\n\n# fenic: el dataframe (re)construido para la inferencia de LLM\n\n[![Versión PyPI](https://img.shields.io/pypi/v/fenic.svg)](https://pypi.org/project/fenic/)\n[![Versiones de Python](https://img.shields.io/pypi/pyversions/fenic.svg)](https://pypi.org/project/fenic/)\n[![Licencia](https://img.shields.io/github/license/typedef-ai/fenic.svg)](https://github.com/typedef-ai/fenic/blob/main/LICENSE)\n[![Discord](https://img.shields.io/discord/1381706122322513952?label=Discord&logo=discord)](https://discord.gg/GdqF3J7huR)\n\n---\n\n## **Documentación**: [docs.fenic.ai](https://docs.fenic.ai/)\n\nfenic es un framework de DataFrame inspirado en PySpark, creado por typedef.ai, para desarrollar aplicaciones de IA y agentes. Transforma datos estructurados y no estructurados en conocimientos utilizando operaciones de DataFrame familiares, mejoradas con inteligencia semántica. Con soporte nativo para markdown, transcripciones y operadores semánticos, además de inferencia por lotes eficiente en cualquier proveedor de modelos.",
    "Status": "ok"
  },
  {
    "Id": 2,
    "Content": "## Install\n\nfenic supports Python `[3.10, 3.11, 3.12]`\n\n```bash\npip install fenic\n```\n\n### LLM Provider Setup\n\nfenic requires an API key from at least one LLM provider. Set the appropriate environment variable for your chosen provider:\n\n```bash\n# For OpenAI\nexport OPENAI_API_KEY=\"your-openai-api-key\"\n\n# For Anthropic\nexport ANTHROPIC_API_KEY=\"your-anthropic-api-key\"\n\n# For Google",
    "ContentSha": "QT2GWoHGnyfwnJxlfZAk0I5rpIsEfvGEhJD38oz6lCY=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "## Instalación\n\nfenic es compatible con Python `[3.10, 3.11, 3.12]`\n\n```bash\npip install fenic\n```\n\n### Configuración del proveedor de LLM\n\nfenic requiere una clave API de al menos un proveedor de LLM. Establece la variable de entorno adecuada para el proveedor que elijas:\n\n```bash\n# Para OpenAI\nexport OPENAI_API_KEY=\"tu-clave-api-de-openai\"\n\n# Para Anthropic\nexport ANTHROPIC_API_KEY=\"tu-clave-api-de-anthropic\"\n\n# Para Google",
    "Status": "ok"
  },
  {
    "Id": 3,
    "Content": "export GEMINI_API_KEY=\"your-google-api-key\"\n```\n\n## Quickstart\n\nThe fastest way to learn about fenic is by checking the examples.\n\nBelow is a quick list of the examples in this repo:\n\n| Example                                                                 | Description                                                                                                                         |\n| ----------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------- |\n| [Hello World!](examples/hello_world)                                    | Introduction to semantic extraction and classification using fenic's core operators through error log analysis.                     |\n| [Enrichment](examples/enrichment)                                       | Multi-stage DataFrames with template-based text extraction, joins, and LLM-powered transformations demonstrated via log enrichment. |\n| [Meeting Transcript Processing](examples/meeting_transcript_processing) | Native transcript parsing, Pydantic schema integration, and complex aggregations shown through meeting analysis.                    |\n| [News Analysis](examples/news_analysis)                                 | Analyze and extract insights from news articles using semantic operators and structured data processing.                            |\n| [Podcast Summarization](examples/podcast_summarization)                 | Process and summarize podcast transcripts with speaker-aware analysis and key point extraction.                                     |\n| [Semantic Join](examples/semantic_joins)                                | Instead of simple fuzzy matching, use fenic's powerful semantic join functionality to match data across tables.                     |\n| [Named Entity Recognition](examples/named_entity_recognition)           | Extract and classify named entities from text using semantic extraction and classification.                                         |\n| [Markdown Processing](examples/markdown_processing)                     | Process and transform markdown documents with structured data extraction and formatting.                                            |\n| [JSON Processing](examples/json_processing)                             | Handle complex JSON data structures with semantic operations and schema validation.                                                 |\n| [Feedback Clustering](examples/feedback_clustering)                     | Group and analyze feedback using semantic similarity and clustering operations.                                                     |\n| [Document Extraction](examples/document_extraction)                     | Extract structured information from various document formats using semantic operators.                                              |\n\n(Feel free to click any example above to jump right to its folder.)\n",
    "ContentSha": "RBvJ+qAaDZODC8rvu1sFp9QTE4SUhSKTTu/91HAxBRc=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "export GEMINI_API_KEY=\"tu-clave-api-de-google\"\n```\n\n## Inicio rápido\n\nLa forma más rápida de aprender sobre fenic es revisando los ejemplos.\n\nA continuación se muestra una lista rápida de los ejemplos en este repositorio:\n\n| Ejemplo                                                                 | Descripción                                                                                                                         |\n| ----------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------- |\n| [¡Hola Mundo!](examples/hello_world)                                    | Introducción a la extracción y clasificación semántica utilizando los operadores principales de fenic a través del análisis de registros de errores.                     |\n| [Enriquecimiento](examples/enrichment)                                  | DataFrames de múltiples etapas con extracción de texto basada en plantillas, joins y transformaciones potenciadas por LLM, demostradas mediante el enriquecimiento de registros. |\n| [Procesamiento de Transcripciones de Reuniones](examples/meeting_transcript_processing) | Análisis nativo de transcripciones, integración de esquemas Pydantic y agregaciones complejas mostradas a través del análisis de reuniones.                    |\n| [Análisis de Noticias](examples/news_analysis)                                 | Analiza y extrae información valiosa de artículos de noticias utilizando operadores semánticos y procesamiento de datos estructurados.                            |\n| [Resumen de Podcasts](examples/podcast_summarization)                 | Procesa y resume transcripciones de podcasts con análisis consciente de los interlocutores y extracción de puntos clave.                                     |\n| [Unión Semántica](examples/semantic_joins)                                | En lugar de una simple coincidencia difusa, utiliza la potente funcionalidad de unión semántica de fenic para emparejar datos entre tablas.                     |\n| [Reconocimiento de Entidades Nombradas](examples/named_entity_recognition)           | Extrae y clasifica entidades nombradas de texto usando extracción y clasificación semántica.                                         |\n| [Procesamiento de Markdown](examples/markdown_processing)                     | Procesa y transforma documentos markdown con extracción de datos estructurados y formateo.                                            |\n| [Procesamiento de JSON](examples/json_processing)                             | Maneja estructuras de datos JSON complejas con operaciones semánticas y validación de esquemas.                                                 |\n| [Agrupación de Retroalimentación](examples/feedback_clustering)                     | Agrupa y analiza retroalimentación usando similitud semántica y operaciones de agrupamiento.                                                     |\n| [Extracción de Documentos](examples/document_extraction)                             | Extrae información estructurada de varios formatos de documentos usando operadores semánticos.                                              |\n\n(Siéntete libre de hacer clic en cualquier ejemplo anterior para ir directamente a su carpeta.)",
    "Status": "ok"
  },
  {
    "Id": 4,
    "Content": "## Why use fenic?\n\nfenic is an opinionated, PySpark-inspired DataFrame framework for building production AI and agentic applications.\n\nUnlike traditional data tools retrofitted for LLMs, fenic's query engine is built from the ground up with inference in mind.\n\nTransform structured and unstructured data into insights using familiar DataFrame operations enhanced with semantic intelligence. With first-class support for markdown, transcripts, and semantic operators, plus efficient batch inference across any model provider.\n\nfenic brings the reliability of traditional data pipelines to AI workloads.\n\n### Key Features\n\n#### Purpose-Built for LLM Inference\n\n- Query engine designed from scratch for AI workloads, not retrofitted\n- Automatic batch optimization for API calls\n- Built-in retry logic and rate limiting\n- Token counting and cost tracking\n\n#### Semantic Operators as First-Class Citizens",
    "ContentSha": "POPTpr2d3zFT3V0X0/NRjmMCUTjlIPBHtMTVHIRsyfM=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "## ¿Por qué usar fenic?\n\nfenic es un framework de DataFrame inspirado en PySpark y con opiniones definidas, diseñado para construir aplicaciones de IA y agentes en producción.\n\nA diferencia de las herramientas de datos tradicionales adaptadas para LLMs, el motor de consultas de fenic está construido desde cero con la inferencia como objetivo principal.\n\nTransforma datos estructurados y no estructurados en insights utilizando operaciones de DataFrame familiares, mejoradas con inteligencia semántica. Con soporte de primera clase para markdown, transcripciones y operadores semánticos, además de inferencia por lotes eficiente en cualquier proveedor de modelos.\n\nfenic aporta la fiabilidad de los pipelines de datos tradicionales a las cargas de trabajo de IA.\n\n### Características clave\n\n#### Diseñado específicamente para la inferencia con LLM\n\n- Motor de consultas diseñado desde cero para cargas de trabajo de IA, no adaptado\n- Optimización automática por lotes para llamadas a API\n- Lógica de reintento incorporada y limitación de velocidad\n- Conteo de tokens y seguimiento de costos\n\n#### Operadores semánticos como ciudadanos de primera clase",
    "Status": "ok"
  },
  {
    "Id": 5,
    "Content": "\n- `semantic.analyze_sentiment` - Built-in sentiment analysis\n- `semantic.classify` - Categorize text with few-shot examples\n- `semantic.extract` - Transform unstructured text into structured data with schemas\n- `semantic.group_by` - Group data by semantic similarity\n- `semantic.join` - Join DataFrames on meaning, not just values\n- `semantic.map` - Apply natural language transformations\n- `semantic.predicate` - Create predicates using natural language to filter rows\n- `semantic.reduce` - Aggregate grouped data with LLM operations\n\n#### Native Unstructured Data Support\n\nGoes beyond typical multimodal data types (audio, images) by creating specialized types for text-heavy workloads:\n\n- Markdown parsing and extraction as a first-class data type\n- Transcript processing (SRT, generic formats) with speaker and timestamp awareness\n- JSON manipulation with JQ expressions for nested data\n- Automatic text chunking with configurable overlap for long documents\n\n#### Production-Ready Infrastructure",
    "ContentSha": "NE5dPjdhTPxhAD1E+gcEg2tw/wEtQVkEuw1AGA1YwCQ=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "- `semantic.analyze_sentiment` - Análisis de sentimiento incorporado\n- `semantic.classify` - Clasifica texto con ejemplos few-shot\n- `semantic.extract` - Transforma texto no estructurado en datos estructurados con esquemas\n- `semantic.group_by` - Agrupa datos por similitud semántica\n- `semantic.join` - Une DataFrames según el significado, no solo los valores\n- `semantic.map` - Aplica transformaciones en lenguaje natural\n- `semantic.predicate` - Crea predicados usando lenguaje natural para filtrar filas\n- `semantic.reduce` - Agrega datos agrupados con operaciones LLM\n\n#### Soporte nativo para datos no estructurados\n\nVa más allá de los tipos de datos multimodales típicos (audio, imágenes) al crear tipos especializados para cargas de trabajo centradas en texto:\n\n- Análisis y extracción de Markdown como un tipo de dato de primera clase\n- Procesamiento de transcripciones (SRT, formatos genéricos) con reconocimiento de oradores y marcas de tiempo\n- Manipulación de JSON con expresiones JQ para datos anidados\n- Fragmentación automática de texto con solapamiento configurable para documentos largos\n\n#### Infraestructura lista para producción",
    "Status": "ok"
  },
  {
    "Id": 6,
    "Content": "\n- Multi-provider support (OpenAI, Anthropic, Gemini)\n- Local and cloud execution backends\n- Comprehensive error handling and logging\n- Pydantic integration for type safety\n\n#### Familiar DataFrame API\n\n- PySpark-compatible operations\n- Lazy evaluation and query optimization\n- SQL support for complex queries\n- Seamless integration with existing data pipelines\n\n### Why DataFrames for LLM and Agentic Applications?\n\nAI and agentic applications are fundamentally pipelines and workflows - exactly what DataFrame APIs were designed to handle. Rather than reinventing patterns for data transformation, filtering, and aggregation, fenic leverages decades of proven engineering practices.\n\n#### Decoupled Architecture for Better Agents\n\nfenic creates a clear separation between heavy inference tasks and real-time agent interactions. By moving batch processing out of the agent runtime, you get:\n\n- More predictable and responsive agents\n- Better resource utilization with batched LLM calls\n- Cleaner separation between planning/orchestration and execution\n",
    "ContentSha": "mT0TcKmDXUG4vMCvQ5Zt2Hov+kI1MOWz6tDxxgD3BGY=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "- Soporte para múltiples proveedores (OpenAI, Anthropic, Gemini)\n- Backends de ejecución local y en la nube\n- Manejo de errores y registro de logs integral\n- Integración con Pydantic para seguridad de tipos\n\n#### API de DataFrame Familiar\n\n- Operaciones compatibles con PySpark\n- Evaluación perezosa y optimización de consultas\n- Soporte SQL para consultas complejas\n- Integración fluida con pipelines de datos existentes\n\n### ¿Por qué DataFrames para aplicaciones LLM y agénticas?\n\nLas aplicaciones de IA y agénticas son fundamentalmente pipelines y flujos de trabajo, exactamente para lo que fueron diseñadas las APIs de DataFrame. En lugar de reinventar patrones para la transformación, filtrado y agregación de datos, fenic aprovecha décadas de prácticas de ingeniería comprobadas.\n\n#### Arquitectura desacoplada para mejores agentes\n\nfenic crea una separación clara entre tareas de inferencia pesadas e interacciones en tiempo real de los agentes. Al mover el procesamiento por lotes fuera del tiempo de ejecución del agente, se obtiene:\n\n- Agentes más predecibles y responsivos\n- Mejor utilización de recursos con llamadas LLM por lotes\n- Separación más limpia entre la planificación/orquestación y la ejecución",
    "Status": "ok"
  },
  {
    "Id": 7,
    "Content": "#### Built for All Engineers\n\nDataFrames aren't just for data practitioners. The fluent, composable API design makes it accessible to any engineer:\n\n- Chain operations naturally: `df.filter(...).semantic.group_by(...)`\n- Mix imperative and declarative styles seamlessly\n- Get started quickly with familiar patterns from pandas/PySpark or SQL\n\n## Support\n\nJoin our community on [Discord](https://discord.gg/GdqF3J7huR) where you can connect with other users, ask questions, and get help with your fenic projects. Our community is always happy to welcome newcomers!\n\nIf you find fenic useful, consider giving us a ⭐ at the top of this repository. Your support helps us grow and improve the framework for everyone!\n\n## Contributing\n\nWe welcome contributions of all kinds! Whether you're interested in writing code, improving documentation, testing features, or proposing new ideas, your help is valuable to us.\n\nFor developers planning to submit code changes, we encourage you to first open an issue to discuss your ideas before creating a Pull Request. This helps ensure alignment with the project's direction and prevents duplicate efforts.\n\nPlease refer to our [contribution guidelines](https://raw.githubusercontent.com/typedef-ai/fenic/main/CONTRIBUTING.md) for detailed information about the development process and project setup.\n",
    "ContentSha": "uskg5roWGwsGUjyK072Ea16WzdZZykGudJVeAy5e46I=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "#### Construido para Todos los Ingenieros\n\nLos DataFrames no son solo para profesionales de datos. El diseño de la API fluida y componible la hace accesible para cualquier ingeniero:\n\n- Encadena operaciones de forma natural: `df.filter(...).semantic.group_by(...)`\n- Mezcla estilos imperativos y declarativos sin problemas\n- Comienza rápidamente con patrones familiares de pandas/PySpark o SQL\n\n## Soporte\n\nÚnete a nuestra comunidad en [Discord](https://discord.gg/GdqF3J7huR) donde puedes conectarte con otros usuarios, hacer preguntas y obtener ayuda con tus proyectos de fenic. ¡Nuestra comunidad siempre está feliz de dar la bienvenida a los recién llegados!\n\nSi encuentras útil fenic, considera darnos una ⭐ en la parte superior de este repositorio. ¡Tu apoyo nos ayuda a crecer y mejorar el framework para todos!\n\n## Contribuciones\n\n¡Damos la bienvenida a contribuciones de todo tipo! Ya sea que te interese escribir código, mejorar la documentación, probar funciones o proponer nuevas ideas, tu ayuda es valiosa para nosotros.\n\nPara los desarrolladores que planean enviar cambios de código, te animamos a abrir primero un issue para discutir tus ideas antes de crear un Pull Request. Esto ayuda a garantizar la alineación con la dirección del proyecto y evita esfuerzos duplicados.\n\nPor favor, consulta nuestras [directrices de contribución](https://raw.githubusercontent.com/typedef-ai/fenic/main/CONTRIBUTING.md) para información detallada sobre el proceso de desarrollo y la configuración del proyecto.",
    "Status": "ok"
  }
]