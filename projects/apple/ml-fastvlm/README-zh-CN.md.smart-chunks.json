[
  {
    "Id": 1,
    "Content": "# FastVLM: Efficient Vision Encoding for Vision Language Models\n\nThis is the official repository of\n**[FastVLM: Efficient Vision Encoding for Vision Language Models](https://www.arxiv.org/abs/2412.13303). (CVPR 2025)**\n\n[//]: # (![FastViTHD Performance]&#40;docs/acc_vs_latency_qwen-2.png&#41;)\n<p align=\"center\">\n<img src=\"https://raw.githubusercontent.com/apple/ml-fastvlm/main/docs/acc_vs_latency_qwen-2.png\" alt=\"Accuracy vs latency figure.\" width=\"400\"/>\n</p>\n\n### Highlights\n* We introduce FastViTHD, a novel hybrid vision encoder designed to output fewer tokens and significantly reduce encoding time for high-resolution images.  \n* Our smallest variant outperforms LLaVA-OneVision-0.5B with 85x faster Time-to-First-Token (TTFT) and 3.4x smaller vision encoder.\n* Our larger variants using Qwen2-7B LLM outperform recent works like Cambrian-1-8B while using a single image encoder with a 7.9x faster TTFT.\n* Demo iOS app to demonstrate the performance of our model on a mobile device.\n\n<table>\n<tr>\n    <td><img src=\"https://raw.githubusercontent.com/apple/ml-fastvlm/main/docs/fastvlm-counting.gif\" alt=\"FastVLM - Counting\"></td>\n    <td><img src=\"https://raw.githubusercontent.com/apple/ml-fastvlm/main/docs/fastvlm-handwriting.gif\" alt=\"FastVLM - Handwriting\"></td>\n    <td><img src=\"https://raw.githubusercontent.com/apple/ml-fastvlm/main/docs/fastvlm-emoji.gif\" alt=\"FastVLM - Emoji\"></td>\n</tr>\n</table>\n\n## Getting Started\nWe use LLaVA codebase to train FastVLM variants. In order to train or finetune your own variants, \nplease follow instructions provided in [LLaVA](https://github.com/haotian-liu/LLaVA) codebase. \nWe provide instructions for running inference with our models.   \n\n### Setup",
    "ContentSha": "wsrzx0qlxCPsMjB+1lvktAho8SXdn5iyJDVW8zmREeg=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "<translate-content># FastVLM：面向视觉语言模型的高效视觉编码\n\n这是\n**[FastVLM：面向视觉语言模型的高效视觉编码](https://www.arxiv.org/abs/2412.13303)（CVPR 2025）** 的官方仓库\n\n[//]: # (![FastViTHD Performance]&#40;docs/acc_vs_latency_qwen-2.png&#41;)\n<p align=\"center\">\n<img src=\"https://raw.githubusercontent.com/apple/ml-fastvlm/main/docs/acc_vs_latency_qwen-2.png\" alt=\"准确率与延迟图示\" width=\"400\"/>\n</p>\n\n### 亮点\n* 我们介绍了 FastViTHD，一种新颖的混合视觉编码器，旨在输出更少的令牌并显著减少高分辨率图像的编码时间。  \n* 我们最小的版本以 85 倍更快的首次令牌时间（TTFT）和 3.4 倍更小的视觉编码器性能优于 LLaVA-OneVision-0.5B。\n* 我们使用 Qwen2-7B 大型语言模型的更大版本优于 Cambrian-1-8B 等最新工作，同时使用单一图像编码器，TTFT 快 7.9 倍。\n* 提供演示 iOS 应用，展示我们模型在移动设备上的性能。\n\n<table>\n<tr>\n    <td><img src=\"https://raw.githubusercontent.com/apple/ml-fastvlm/main/docs/fastvlm-counting.gif\" alt=\"FastVLM - 计数\"></td>\n    <td><img src=\"https://raw.githubusercontent.com/apple/ml-fastvlm/main/docs/fastvlm-handwriting.gif\" alt=\"FastVLM - 手写\"></td>\n    <td><img src=\"https://raw.githubusercontent.com/apple/ml-fastvlm/main/docs/fastvlm-emoji.gif\" alt=\"FastVLM - 表情符号\"></td>\n</tr>\n</table>\n\n## 快速开始\n我们使用 LLaVA 代码库训练 FastVLM 变体。若要训练或微调您自己的变体，\n请按照 [LLaVA](https://github.com/haotian-liu/LLaVA) 代码库中提供的说明操作。\n我们提供了使用我们的模型进行推理的说明。\n\n### 安装配置</translate-content>",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "re25b1/AsVvkGcjPmitUvdEQjXbD3M1O4pzFBGIu6Gk=",
        "originContent": "# FastVLM: Efficient Vision Encoding for Vision Language Models",
        "translatedContent": "<translate-content># FastVLM：面向视觉语言模型的高效视觉编码"
      },
      {
        "row": 2,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 3,
        "rowsha": "g2344bef599vjW/bUbjaxuux4Z1PJZBH3XIqUI9oCEE=",
        "originContent": "This is the official repository of",
        "translatedContent": "这是"
      },
      {
        "row": 4,
        "rowsha": "K71zo6Tiv5ua2mrdvDXM95P+lAzeSQcl1i7M49zJsdY=",
        "originContent": "**[FastVLM: Efficient Vision Encoding for Vision Language Models](https://www.arxiv.org/abs/2412.13303). (CVPR 2025)**",
        "translatedContent": "**[FastVLM：面向视觉语言模型的高效视觉编码](https://www.arxiv.org/abs/2412.13303)（CVPR 2025）** 的官方仓库"
      },
      {
        "row": 5,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 6,
        "rowsha": "mDPE1ZCMkbjTAn1dDxuhruAQmZ+lxOPvH7Z0xwAaZEM=",
        "originContent": "[//]: # (![FastViTHD Performance]&#40;docs/acc_vs_latency_qwen-2.png&#41;)",
        "translatedContent": "[//]: # (![FastViTHD Performance]&#40;docs/acc_vs_latency_qwen-2.png&#41;)"
      },
      {
        "row": 7,
        "rowsha": "+/a9XmPwQixGFroME/GMEOLpReZZV4ARosR9orAplJY=",
        "originContent": "<p align=\"center\">",
        "translatedContent": "<p align=\"center\">"
      },
      {
        "row": 8,
        "rowsha": "SKvwjmW9xaytX3oHDq5Dg4sD4JuHSXJbqucBWd84C+8=",
        "originContent": "<img src=\"https://raw.githubusercontent.com/apple/ml-fastvlm/main/docs/acc_vs_latency_qwen-2.png\" alt=\"Accuracy vs latency figure.\" width=\"400\"/>",
        "translatedContent": "<img src=\"https://raw.githubusercontent.com/apple/ml-fastvlm/main/docs/acc_vs_latency_qwen-2.png\" alt=\"准确率与延迟图示\" width=\"400\"/>"
      },
      {
        "row": 9,
        "rowsha": "dSdvPNAZSmR86FDDSF6tkQUCVfI9qmACHOR5tThOetY=",
        "originContent": "</p>",
        "translatedContent": "</p>"
      },
      {
        "row": 10,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 11,
        "rowsha": "cxAIGfEA3El60/qMS6EjCVQ8S9ibfnDqCalf5nlplPo=",
        "originContent": "### Highlights",
        "translatedContent": "### 亮点"
      },
      {
        "row": 12,
        "rowsha": "Qbjy7m9z961IGQTLEjGRiq+qIL4qsOZ2Np9RDk1Or3k=",
        "originContent": "* We introduce FastViTHD, a novel hybrid vision encoder designed to output fewer tokens and significantly reduce encoding time for high-resolution images.  ",
        "translatedContent": "* 我们介绍了 FastViTHD，一种新颖的混合视觉编码器，旨在输出更少的令牌并显著减少高分辨率图像的编码时间。  "
      },
      {
        "row": 13,
        "rowsha": "tnIqJOspZu3EY7LtIeWupio5uTzaKW2HZLZJSPH26PQ=",
        "originContent": "* Our smallest variant outperforms LLaVA-OneVision-0.5B with 85x faster Time-to-First-Token (TTFT) and 3.4x smaller vision encoder.",
        "translatedContent": "* 我们最小的版本以 85 倍更快的首次令牌时间（TTFT）和 3.4 倍更小的视觉编码器性能优于 LLaVA-OneVision-0.5B。"
      },
      {
        "row": 14,
        "rowsha": "3LbcpEdVpjhUHayEQCb2uNiAORybizFDqCociFBcvDg=",
        "originContent": "* Our larger variants using Qwen2-7B LLM outperform recent works like Cambrian-1-8B while using a single image encoder with a 7.9x faster TTFT.",
        "translatedContent": "* 我们使用 Qwen2-7B 大型语言模型的更大版本优于 Cambrian-1-8B 等最新工作，同时使用单一图像编码器，TTFT 快 7.9 倍。"
      },
      {
        "row": 15,
        "rowsha": "GYySOSL4l7fvEzVxm+pbPTq+oZHONw2OYeWH0ZRbmoQ=",
        "originContent": "* Demo iOS app to demonstrate the performance of our model on a mobile device.",
        "translatedContent": "* 提供演示 iOS 应用，展示我们模型在移动设备上的性能。"
      },
      {
        "row": 16,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 17,
        "rowsha": "kq0DFTS69SZCm3Odp9SwOmLuj08yYNkZvbhcRxtdMkQ=",
        "originContent": "<table>",
        "translatedContent": "<table>"
      },
      {
        "row": 18,
        "rowsha": "m4TGFLRzvx0YLmLMue/0JQ+Zd9Xal1VIBS1erVxEKBU=",
        "originContent": "<tr>",
        "translatedContent": "<tr>"
      },
      {
        "row": 19,
        "rowsha": "AWO5iLlAetK3Nmw3rahwZC52gF+8V4NXryHosnjw0as=",
        "originContent": "    <td><img src=\"https://raw.githubusercontent.com/apple/ml-fastvlm/main/docs/fastvlm-counting.gif\" alt=\"FastVLM - Counting\"></td>",
        "translatedContent": "    <td><img src=\"https://raw.githubusercontent.com/apple/ml-fastvlm/main/docs/fastvlm-counting.gif\" alt=\"FastVLM - 计数\"></td>"
      },
      {
        "row": 20,
        "rowsha": "t2vGd7sN0ktBcHjog+r0mrZQ6j58MpHFhIsxkTxMKb8=",
        "originContent": "    <td><img src=\"https://raw.githubusercontent.com/apple/ml-fastvlm/main/docs/fastvlm-handwriting.gif\" alt=\"FastVLM - Handwriting\"></td>",
        "translatedContent": "    <td><img src=\"https://raw.githubusercontent.com/apple/ml-fastvlm/main/docs/fastvlm-handwriting.gif\" alt=\"FastVLM - 手写\"></td>"
      },
      {
        "row": 21,
        "rowsha": "UX8W4w2W19v7FCBTtFmRpQ6G0eJwYjHFCAAY9TyNDyM=",
        "originContent": "    <td><img src=\"https://raw.githubusercontent.com/apple/ml-fastvlm/main/docs/fastvlm-emoji.gif\" alt=\"FastVLM - Emoji\"></td>",
        "translatedContent": "    <td><img src=\"https://raw.githubusercontent.com/apple/ml-fastvlm/main/docs/fastvlm-emoji.gif\" alt=\"FastVLM - 表情符号\"></td>"
      },
      {
        "row": 22,
        "rowsha": "PtdEDOB1aSgnb7wNnHW1mo4VL3Eh6O3aBzC76+S4YE0=",
        "originContent": "</tr>",
        "translatedContent": "</tr>"
      },
      {
        "row": 23,
        "rowsha": "H+dtb55ry3VN2CLvAetudgE9ICnYQdUralLHuIqMdZM=",
        "originContent": "</table>",
        "translatedContent": "</table>"
      },
      {
        "row": 24,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 25,
        "rowsha": "xhRBNsX93gDAZr7QGoGuyvjyOQNvnsq8Qy5ThtW3pJo=",
        "originContent": "## Getting Started",
        "translatedContent": "## 快速开始"
      },
      {
        "row": 26,
        "rowsha": "UZ1F0QmkQoxf5S8hzS+qlRRTzbJgr+1whEHuq3/FbQQ=",
        "originContent": "We use LLaVA codebase to train FastVLM variants. In order to train or finetune your own variants, ",
        "translatedContent": "我们使用 LLaVA 代码库训练 FastVLM 变体。若要训练或微调您自己的变体，"
      },
      {
        "row": 27,
        "rowsha": "vXpfCE1cQ3SrbfrjVKdhNXcRnuNIAuC1ODYjmFfvEAU=",
        "originContent": "please follow instructions provided in [LLaVA](https://github.com/haotian-liu/LLaVA) codebase. ",
        "translatedContent": "请按照 [LLaVA](https://github.com/haotian-liu/LLaVA) 代码库中提供的说明操作。"
      },
      {
        "row": 28,
        "rowsha": "lInJjWomOVM0sJWaujawC9DYrHOJ3dZ00dRFm0rFLVw=",
        "originContent": "We provide instructions for running inference with our models.   ",
        "translatedContent": "我们提供了使用我们的模型进行推理的说明。"
      },
      {
        "row": 29,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 30,
        "rowsha": "iJa409tTUC9P1gTULbIw6Kod+KAUdLl5kgZl7whoChE=",
        "originContent": "### Setup",
        "translatedContent": "### 安装配置</translate-content>"
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 2,
    "Content": "```bash\nconda create -n fastvlm python=3.10\nconda activate fastvlm\npip install -e .\n```",
    "ContentSha": "T3dliF50X9Nt+qx0S9Qem9C6tFumV7uUEcvPZ0r7hO0=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\nconda create -n fastvlm python=3.10\nconda activate fastvlm\npip install -e .\n```",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "rTMjNc+qNIxb1xXDR5hEYiJw1fc4muBwuBsTXVIaIho=",
        "originContent": "```bash",
        "translatedContent": "```bash"
      },
      {
        "row": 2,
        "rowsha": "CsFYljSuqOAMOoSwDtAMwiwovcx2tjD/nemFG7SA8zA=",
        "originContent": "conda create -n fastvlm python=3.10",
        "translatedContent": "conda create -n fastvlm python=3.10"
      },
      {
        "row": 3,
        "rowsha": "uXK2931BK8Xf8HOVjoQ3QWVdxUDSP91w+UuHGRiUvXo=",
        "originContent": "conda activate fastvlm",
        "translatedContent": "conda activate fastvlm"
      },
      {
        "row": 4,
        "rowsha": "knVRIKwsU4emj9biFUgJoBjbMP5EER6U5AGxS0Ix1+Y=",
        "originContent": "pip install -e .",
        "translatedContent": "pip install -e ."
      },
      {
        "row": 5,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      }
    ],
    "IsCodeBlock": true
  },
  {
    "Id": 3,
    "Content": "\n### Model Zoo\nFor detailed information on various evaluations, please refer to our [paper](https://www.arxiv.org/abs/2412.13303).\n\n| Model        | Stage |                                            Pytorch Checkpoint (url)                                             |\n|:-------------|:-----:|:---------------------------------------------------------------------------------------------------------------:|\n| FastVLM-0.5B |   2   | [fastvlm_0.5b_stage2](https://ml-site.cdn-apple.com/datasets/fastvlm/llava-fastvithd_0.5b_stage2.zip) |\n|              |   3   | [fastvlm_0.5b_stage3](https://ml-site.cdn-apple.com/datasets/fastvlm/llava-fastvithd_0.5b_stage3.zip) |\n| FastVLM-1.5B |   2   | [fastvlm_1.5b_stage2](https://ml-site.cdn-apple.com/datasets/fastvlm/llava-fastvithd_1.5b_stage2.zip) |\n|              |   3   | [fastvlm_1.5b_stage3](https://ml-site.cdn-apple.com/datasets/fastvlm/llava-fastvithd_1.5b_stage3.zip)  |\n| FastVLM-7B   |   2   | [fastvlm_7b_stage2](https://ml-site.cdn-apple.com/datasets/fastvlm/llava-fastvithd_7b_stage2.zip)  |\n|              |   3   | [fastvlm_7b_stage3](https://ml-site.cdn-apple.com/datasets/fastvlm/llava-fastvithd_7b_stage3.zip)  |\n\nTo download all the pretrained checkpoints run the command below (note that this might take some time depending on your connection so might be good to grab ☕️ while you wait).\n",
    "ContentSha": "SOYyeTJSeV3tyVGGMFuYakkvewSGfMC0U4L2iufKo6s=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "### 模型库\n有关各种评估的详细信息，请参阅我们的[论文](https://www.arxiv.org/abs/2412.13303)。\n\n| 模型          | 阶段  |                                            Pytorch 检查点（链接）                                               |\n|:-------------|:-----:|:---------------------------------------------------------------------------------------------------------------:|\n| FastVLM-0.5B |   2   | [fastvlm_0.5b_stage2](https://ml-site.cdn-apple.com/datasets/fastvlm/llava-fastvithd_0.5b_stage2.zip) |\n|              |   3   | [fastvlm_0.5b_stage3](https://ml-site.cdn-apple.com/datasets/fastvlm/llava-fastvithd_0.5b_stage3.zip) |\n| FastVLM-1.5B |   2   | [fastvlm_1.5b_stage2](https://ml-site.cdn-apple.com/datasets/fastvlm/llava-fastvithd_1.5b_stage2.zip) |\n|              |   3   | [fastvlm_1.5b_stage3](https://ml-site.cdn-apple.com/datasets/fastvlm/llava-fastvithd_1.5b_stage3.zip)  |\n| FastVLM-7B   |   2   | [fastvlm_7b_stage2](https://ml-site.cdn-apple.com/datasets/fastvlm/llava-fastvithd_7b_stage2.zip)  |\n|              |   3   | [fastvlm_7b_stage3](https://ml-site.cdn-apple.com/datasets/fastvlm/llava-fastvithd_7b_stage3.zip)  |\n\n要下载所有预训练检查点，请运行以下命令（注意根据您的网络连接速度，这可能需要一些时间，因此等待时不妨喝杯☕️）。\n\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "### 模型库"
      },
      {
        "row": 2,
        "rowsha": "AokGAShXuFoP04pgNTbDQs5ciOX7z/y7ej0I58mh7AQ=",
        "originContent": "### Model Zoo",
        "translatedContent": "有关各种评估的详细信息，请参阅我们的[论文](https://www.arxiv.org/abs/2412.13303)。"
      },
      {
        "row": 3,
        "rowsha": "uwk92fgLGMykcUcd5kDa6goQiOvzCdLchBj+LPa5/QU=",
        "originContent": "For detailed information on various evaluations, please refer to our [paper](https://www.arxiv.org/abs/2412.13303).",
        "translatedContent": ""
      },
      {
        "row": 4,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "| 模型          | 阶段  |                                            Pytorch 检查点（链接）                                               |"
      },
      {
        "row": 5,
        "rowsha": "DR6HZSMrk0OE7uAclXxCnKuYwZMSJFR4DT6FQSQ4Kko=",
        "originContent": "| Model        | Stage |                                            Pytorch Checkpoint (url)                                             |",
        "translatedContent": "|:-------------|:-----:|:---------------------------------------------------------------------------------------------------------------:|"
      },
      {
        "row": 6,
        "rowsha": "zJtCBnmPbITmWDOpHm4ezWeHgMj4Dtv1bd1qZfUtkU4=",
        "originContent": "|:-------------|:-----:|:---------------------------------------------------------------------------------------------------------------:|",
        "translatedContent": "| FastVLM-0.5B |   2   | [fastvlm_0.5b_stage2](https://ml-site.cdn-apple.com/datasets/fastvlm/llava-fastvithd_0.5b_stage2.zip) |"
      },
      {
        "row": 7,
        "rowsha": "JRTQjuGPaigBfFOg0/qoT1Q4EvxI+72rF9fgTMnEGxM=",
        "originContent": "| FastVLM-0.5B |   2   | [fastvlm_0.5b_stage2](https://ml-site.cdn-apple.com/datasets/fastvlm/llava-fastvithd_0.5b_stage2.zip) |",
        "translatedContent": "|              |   3   | [fastvlm_0.5b_stage3](https://ml-site.cdn-apple.com/datasets/fastvlm/llava-fastvithd_0.5b_stage3.zip) |"
      },
      {
        "row": 8,
        "rowsha": "gV4nJ6znWZjfHJTMVQbvZ/QkswvsJAFVTbJf0eKontE=",
        "originContent": "|              |   3   | [fastvlm_0.5b_stage3](https://ml-site.cdn-apple.com/datasets/fastvlm/llava-fastvithd_0.5b_stage3.zip) |",
        "translatedContent": "| FastVLM-1.5B |   2   | [fastvlm_1.5b_stage2](https://ml-site.cdn-apple.com/datasets/fastvlm/llava-fastvithd_1.5b_stage2.zip) |"
      },
      {
        "row": 9,
        "rowsha": "Hc8XA1uORzx/pJ15qJ2d9IXn9Lzlkqd8cDXN8V96JNI=",
        "originContent": "| FastVLM-1.5B |   2   | [fastvlm_1.5b_stage2](https://ml-site.cdn-apple.com/datasets/fastvlm/llava-fastvithd_1.5b_stage2.zip) |",
        "translatedContent": "|              |   3   | [fastvlm_1.5b_stage3](https://ml-site.cdn-apple.com/datasets/fastvlm/llava-fastvithd_1.5b_stage3.zip)  |"
      },
      {
        "row": 10,
        "rowsha": "jiyV8Ah5kdBZdLaW+ILbKd6jbNFuimpXFzHnBFMZrw0=",
        "originContent": "|              |   3   | [fastvlm_1.5b_stage3](https://ml-site.cdn-apple.com/datasets/fastvlm/llava-fastvithd_1.5b_stage3.zip)  |",
        "translatedContent": "| FastVLM-7B   |   2   | [fastvlm_7b_stage2](https://ml-site.cdn-apple.com/datasets/fastvlm/llava-fastvithd_7b_stage2.zip)  |"
      },
      {
        "row": 11,
        "rowsha": "tf+47x25kBNqna36a5PtOQTPr1AER36VLiUOCtPG1qA=",
        "originContent": "| FastVLM-7B   |   2   | [fastvlm_7b_stage2](https://ml-site.cdn-apple.com/datasets/fastvlm/llava-fastvithd_7b_stage2.zip)  |",
        "translatedContent": "|              |   3   | [fastvlm_7b_stage3](https://ml-site.cdn-apple.com/datasets/fastvlm/llava-fastvithd_7b_stage3.zip)  |"
      },
      {
        "row": 12,
        "rowsha": "Qeue66CqMjKJnPUqJJGTtv0Ta/MACAP3EUXnIbKjZ9w=",
        "originContent": "|              |   3   | [fastvlm_7b_stage3](https://ml-site.cdn-apple.com/datasets/fastvlm/llava-fastvithd_7b_stage3.zip)  |",
        "translatedContent": ""
      },
      {
        "row": 13,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "要下载所有预训练检查点，请运行以下命令（注意根据您的网络连接速度，这可能需要一些时间，因此等待时不妨喝杯☕️）。"
      },
      {
        "row": 14,
        "rowsha": "k6ffSX+Nds0X2lXPlofrwas27Z3d51ct+GLCk9FYik0=",
        "originContent": "To download all the pretrained checkpoints run the command below (note that this might take some time depending on your connection so might be good to grab ☕️ while you wait).",
        "translatedContent": ""
      },
      {
        "row": 15,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 4,
    "Content": "```bash\nbash get_models.sh   # Files will be downloaded to `checkpoints` directory.\n```",
    "ContentSha": "wq6Hvv1Wmv/NNPVjoLg89dkODyIp4n7an5RFvX/98+I=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\nbash get_models.sh   # Files will be downloaded to `checkpoints` directory.\n```",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "rTMjNc+qNIxb1xXDR5hEYiJw1fc4muBwuBsTXVIaIho=",
        "originContent": "```bash",
        "translatedContent": "```bash"
      },
      {
        "row": 2,
        "rowsha": "yk9h1Ruku5QmQQGZU6ywdPUVw1B+CaOe8gsdlnzVwIs=",
        "originContent": "bash get_models.sh   # Files will be downloaded to `checkpoints` directory.",
        "translatedContent": "bash get_models.sh   # Files will be downloaded to `checkpoints` directory."
      },
      {
        "row": 3,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      }
    ],
    "IsCodeBlock": true
  },
  {
    "Id": 5,
    "Content": "\n### Usage Example\nTo run inference of PyTorch checkpoint, follow the instruction below",
    "ContentSha": "d8WgBdyUYsRoNoLsh7b2NX8+hwPCst7b5AkcDsyhtt8=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "### 使用示例  \n要运行PyTorch检查点的推理，请按照以下说明操作\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "### 使用示例  "
      },
      {
        "row": 2,
        "rowsha": "VL2pmH7xD+uBhvgpZPXwHbQ7euVDY/RuQBxlpsRCABU=",
        "originContent": "### Usage Example",
        "translatedContent": "要运行PyTorch检查点的推理，请按照以下说明操作"
      },
      {
        "row": 3,
        "rowsha": "6P2D/aZp3l5rnwQFu/X9PvnjletR47x2ynoDLVsJm+4=",
        "originContent": "To run inference of PyTorch checkpoint, follow the instruction below",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 6,
    "Content": "```bash\npython predict.py --model-path /path/to/checkpoint-dir \\\n                  --image-file /path/to/image.png \\\n                  --prompt \"Describe the image.\"\n```",
    "ContentSha": "azshNSSHOWT2np4N696p+W34+hbaOJsqoJ8qHV3ZEG4=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\npython predict.py --model-path /path/to/checkpoint-dir \\\n                  --image-file /path/to/image.png \\\n                  --prompt \"Describe the image.\"\n```",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "rTMjNc+qNIxb1xXDR5hEYiJw1fc4muBwuBsTXVIaIho=",
        "originContent": "```bash",
        "translatedContent": "```bash"
      },
      {
        "row": 2,
        "rowsha": "8bwtPdi5Yqezu6w3Yu7fl8ywcXJBnH85aS8WBrC2zfE=",
        "originContent": "python predict.py --model-path /path/to/checkpoint-dir \\",
        "translatedContent": "python predict.py --model-path /path/to/checkpoint-dir \\"
      },
      {
        "row": 3,
        "rowsha": "81x/XUTKjINZI0XteFbhg5+P9gJLhiiz+Keu2NgCiaE=",
        "originContent": "                  --image-file /path/to/image.png \\",
        "translatedContent": "                  --image-file /path/to/image.png \\"
      },
      {
        "row": 4,
        "rowsha": "6l8MkyWqk1EnxXDjC3BiVh5uyxPpuGs54mcf3kvZ7ws=",
        "originContent": "                  --prompt \"Describe the image.\"",
        "translatedContent": "                  --prompt \"Describe the image.\""
      },
      {
        "row": 5,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      }
    ],
    "IsCodeBlock": true
  },
  {
    "Id": 7,
    "Content": "\n### Inference on Apple Silicon\nTo run inference on Apple Silicon, pytorch checkpoints have to be exported to format \nsuitable for running on Apple Silicon, detailed instructions and code can be found [`model_export`](model_export/) subfolder.\nPlease see the README there for more details.\n\nFor convenience, we provide 3 models that are in Apple Silicon compatible format: [fastvlm_0.5b_stage3](https://ml-site.cdn-apple.com/datasets/fastvlm/llava-fastvithd_0.5b_stage3_llm.fp16.zip), \n[fastvlm_1.5b_stage3](https://ml-site.cdn-apple.com/datasets/fastvlm/llava-fastvithd_1.5b_stage3_llm.int8.zip), \n[fastvlm_7b_stage3](https://ml-site.cdn-apple.com/datasets/fastvlm/llava-fastvithd_7b_stage3_llm.int4.zip). \nWe encourage developers to export the model of their choice with the appropriate quantization levels following \nthe instructions in [`model_export`](model_export/).\n\n### Inference on Apple Devices\nTo run inference on Apple devices like iPhone, iPad or Mac, see [`app`](app/) subfolder for more details.\n\n## Citation\nIf you found this code useful, please cite the following paper:",
    "ContentSha": "l+rw94czofFmx8Iev6xIM/gmT3Nu8eH7y/iIGFP+bxA=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "### 在 Apple Silicon 上进行推理\n要在 Apple Silicon 上运行推理，pytorch 检查点必须导出为适合在 Apple Silicon 上运行的格式，详细的说明和代码可在 [`model_export`](model_export/) 子文件夹中找到。\n请参阅那里的 README 以获取更多详情。\n\n为了方便起见，我们提供了 3 个兼容 Apple Silicon 格式的模型：[fastvlm_0.5b_stage3](https://ml-site.cdn-apple.com/datasets/fastvlm/llava-fastvithd_0.5b_stage3_llm.fp16.zip)，\n[fastvlm_1.5b_stage3](https://ml-site.cdn-apple.com/datasets/fastvlm/llava-fastvithd_1.5b_stage3_llm.int8.zip)，\n[fastvlm_7b_stage3](https://ml-site.cdn-apple.com/datasets/fastvlm/llava-fastvithd_7b_stage3_llm.int4.zip)。\n我们鼓励开发者按照 [`model_export`](model_export/) 中的说明，选择合适的量化级别导出所需的模型。\n\n### 在 Apple 设备上进行推理\n要在 iPhone、iPad 或 Mac 等 Apple 设备上运行推理，请参阅 [`app`](app/) 子文件夹了解更多详情。\n\n## 引用\n如果您觉得此代码有用，请引用以下论文：\n\n\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "### 在 Apple Silicon 上进行推理"
      },
      {
        "row": 2,
        "rowsha": "NXa++l2NDMJL0bGTnvmmwTraFGTC1we15uahI5MTsa4=",
        "originContent": "### Inference on Apple Silicon",
        "translatedContent": "要在 Apple Silicon 上运行推理，pytorch 检查点必须导出为适合在 Apple Silicon 上运行的格式，详细的说明和代码可在 [`model_export`](model_export/) 子文件夹中找到。"
      },
      {
        "row": 3,
        "rowsha": "UdRodf8F0dw+XJHY8/jS68PtY0p5MyLWD3nZzAbD+Ts=",
        "originContent": "To run inference on Apple Silicon, pytorch checkpoints have to be exported to format ",
        "translatedContent": "请参阅那里的 README 以获取更多详情。"
      },
      {
        "row": 4,
        "rowsha": "v7gTQhg9cNGz5e28hvwaQy3A13t56wEmY64NhIyTq9I=",
        "originContent": "suitable for running on Apple Silicon, detailed instructions and code can be found [`model_export`](model_export/) subfolder.",
        "translatedContent": ""
      },
      {
        "row": 5,
        "rowsha": "RNkN4dwSh5GjEvk1L1Icnt4FR6ZnHeukNimIPGh4kSI=",
        "originContent": "Please see the README there for more details.",
        "translatedContent": "为了方便起见，我们提供了 3 个兼容 Apple Silicon 格式的模型：[fastvlm_0.5b_stage3](https://ml-site.cdn-apple.com/datasets/fastvlm/llava-fastvithd_0.5b_stage3_llm.fp16.zip)，"
      },
      {
        "row": 6,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "[fastvlm_1.5b_stage3](https://ml-site.cdn-apple.com/datasets/fastvlm/llava-fastvithd_1.5b_stage3_llm.int8.zip)，"
      },
      {
        "row": 7,
        "rowsha": "pUoTkqMVYHXTjqfSLPPDvSmtyNmXX2FF6n0qi8AKkRg=",
        "originContent": "For convenience, we provide 3 models that are in Apple Silicon compatible format: [fastvlm_0.5b_stage3](https://ml-site.cdn-apple.com/datasets/fastvlm/llava-fastvithd_0.5b_stage3_llm.fp16.zip), ",
        "translatedContent": "[fastvlm_7b_stage3](https://ml-site.cdn-apple.com/datasets/fastvlm/llava-fastvithd_7b_stage3_llm.int4.zip)。"
      },
      {
        "row": 8,
        "rowsha": "6irmAf7U+H5zk4YPqiiF4OUQ6gFcheOlYtKFcTiAeoI=",
        "originContent": "[fastvlm_1.5b_stage3](https://ml-site.cdn-apple.com/datasets/fastvlm/llava-fastvithd_1.5b_stage3_llm.int8.zip), ",
        "translatedContent": "我们鼓励开发者按照 [`model_export`](model_export/) 中的说明，选择合适的量化级别导出所需的模型。"
      },
      {
        "row": 9,
        "rowsha": "CXIKRsCIo8caPfEvC3afUo8GblRYobfw6kJq+Tl5vm4=",
        "originContent": "[fastvlm_7b_stage3](https://ml-site.cdn-apple.com/datasets/fastvlm/llava-fastvithd_7b_stage3_llm.int4.zip). ",
        "translatedContent": ""
      },
      {
        "row": 10,
        "rowsha": "64H2/wWYBaNOTsYAYpyBiAffep//2RUKJXNz/kk5weg=",
        "originContent": "We encourage developers to export the model of their choice with the appropriate quantization levels following ",
        "translatedContent": "### 在 Apple 设备上进行推理"
      },
      {
        "row": 11,
        "rowsha": "e/Y/2hGlJSZ+bWvzHbDJXap2BEpKLTiKSDNegATyt+o=",
        "originContent": "the instructions in [`model_export`](model_export/).",
        "translatedContent": "要在 iPhone、iPad 或 Mac 等 Apple 设备上运行推理，请参阅 [`app`](app/) 子文件夹了解更多详情。"
      },
      {
        "row": 12,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 13,
        "rowsha": "9+g0tQT/UWocVywJcp84359W/nnFHw6+VD0RsxFPU0o=",
        "originContent": "### Inference on Apple Devices",
        "translatedContent": "## 引用"
      },
      {
        "row": 14,
        "rowsha": "rSoAI+6XgZgckIbxQItfXdm1ZsSyjeBToTOTgma/Ey4=",
        "originContent": "To run inference on Apple devices like iPhone, iPad or Mac, see [`app`](app/) subfolder for more details.",
        "translatedContent": "如果您觉得此代码有用，请引用以下论文："
      },
      {
        "row": 15,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 16,
        "rowsha": "ZwTp5ajUmpHTJefyHhIKzXcG2wnB1jv8iv8cvmdcb/g=",
        "originContent": "## Citation",
        "translatedContent": ""
      },
      {
        "row": 17,
        "rowsha": "D241nVniXLP9c8MNkhjVIWtN79G45BL9pkEXHf5ROkE=",
        "originContent": "If you found this code useful, please cite the following paper:",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 8,
    "Content": "```\n@InProceedings{fastvlm2025,\n  author = {Pavan Kumar Anasosalu Vasu, Fartash Faghri, Chun-Liang Li, Cem Koc, Nate True, Albert Antony, Gokul Santhanam, James Gabriel, Peter Grasch, Oncel Tuzel, Hadi Pouransari},\n  title = {FastVLM: Efficient Vision Encoding for Vision Language Models},\n  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},\n  month = {June},\n  year = {2025},\n}\n```",
    "ContentSha": "wktJnJsNX2UAMFMXYCpdbBjqC4bOogQCLoWSAv05pPc=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```\n@InProceedings{fastvlm2025,\n  author = {Pavan Kumar Anasosalu Vasu, Fartash Faghri, Chun-Liang Li, Cem Koc, Nate True, Albert Antony, Gokul Santhanam, James Gabriel, Peter Grasch, Oncel Tuzel, Hadi Pouransari},\n  title = {FastVLM: Efficient Vision Encoding for Vision Language Models},\n  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},\n  month = {June},\n  year = {2025},\n}\n```",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      },
      {
        "row": 2,
        "rowsha": "PJ+Dbzx1scBgzlQ/eMIJeIoUZHibH7qdlpq1YiJXLIo=",
        "originContent": "@InProceedings{fastvlm2025,",
        "translatedContent": "@InProceedings{fastvlm2025,"
      },
      {
        "row": 3,
        "rowsha": "bxsxnQ41EAsvGU7G989ZnfY3L7+J2SzSL1Ib724RvMI=",
        "originContent": "  author = {Pavan Kumar Anasosalu Vasu, Fartash Faghri, Chun-Liang Li, Cem Koc, Nate True, Albert Antony, Gokul Santhanam, James Gabriel, Peter Grasch, Oncel Tuzel, Hadi Pouransari},",
        "translatedContent": "  author = {Pavan Kumar Anasosalu Vasu, Fartash Faghri, Chun-Liang Li, Cem Koc, Nate True, Albert Antony, Gokul Santhanam, James Gabriel, Peter Grasch, Oncel Tuzel, Hadi Pouransari},"
      },
      {
        "row": 4,
        "rowsha": "GqdE3lse1CZavRo9ckXarVhfHGIasKwi8iILuoFynTg=",
        "originContent": "  title = {FastVLM: Efficient Vision Encoding for Vision Language Models},",
        "translatedContent": "  title = {FastVLM: Efficient Vision Encoding for Vision Language Models},"
      },
      {
        "row": 5,
        "rowsha": "0cefqeJxOVmeOvCIZkK7RTs/2p5+7jncPiDhs6G0p7M=",
        "originContent": "  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},",
        "translatedContent": "  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},"
      },
      {
        "row": 6,
        "rowsha": "U1Izw4geK+wX4RkAbLnK9NT0MBNGq5VLS9uL46bPZVs=",
        "originContent": "  month = {June},",
        "translatedContent": "  month = {June},"
      },
      {
        "row": 7,
        "rowsha": "IbKbfF34UsZcnQSCU7je3bJsvgw8HBWO8MxHAycUz7M=",
        "originContent": "  year = {2025},",
        "translatedContent": "  year = {2025},"
      },
      {
        "row": 8,
        "rowsha": "0Qs2qnSlm89KiBhYN/ZYr682Ru/yuxbDko0OkzXpRdI=",
        "originContent": "}",
        "translatedContent": "}"
      },
      {
        "row": 9,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      }
    ],
    "IsCodeBlock": true
  },
  {
    "Id": 9,
    "Content": "\n## Acknowledgements\nOur codebase is built using multiple opensource contributions, please see [ACKNOWLEDGEMENTS](ACKNOWLEDGEMENTS) for more details. \n\n## License\nPlease check out the repository [LICENSE](LICENSE) before using the provided code and\n[LICENSE_MODEL](LICENSE_MODEL) for the released models.\n",
    "ContentSha": "9l39I30jCrjEBn9TZjuj43Rk1zD0FREHZ/k3RZXs2sc=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "## 致谢\n我们的代码库是基于多个开源贡献构建的，详细信息请参见 [ACKNOWLEDGEMENTS](ACKNOWLEDGEMENTS)。\n\n## 许可\n使用提供的代码前，请查看仓库中的 [LICENSE](LICENSE) 以及发布模型的 [LICENSE_MODEL](LICENSE_MODEL)。\n\n\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "## 致谢"
      },
      {
        "row": 2,
        "rowsha": "HvkwNudYOlwL8j/t4djBVF3hUJwHWa2r5QjmSxgq3AA=",
        "originContent": "## Acknowledgements",
        "translatedContent": "我们的代码库是基于多个开源贡献构建的，详细信息请参见 [ACKNOWLEDGEMENTS](ACKNOWLEDGEMENTS)。"
      },
      {
        "row": 3,
        "rowsha": "RJXd3com8bsu7kR/bmE4eqzaQpI0iRS5V+1VRag/Leo=",
        "originContent": "Our codebase is built using multiple opensource contributions, please see [ACKNOWLEDGEMENTS](ACKNOWLEDGEMENTS) for more details. ",
        "translatedContent": ""
      },
      {
        "row": 4,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "## 许可"
      },
      {
        "row": 5,
        "rowsha": "bFSaVtsB4CHySNjaeCiaMZfT24b+DTbTM4HQ38cR6Lw=",
        "originContent": "## License",
        "translatedContent": "使用提供的代码前，请查看仓库中的 [LICENSE](LICENSE) 以及发布模型的 [LICENSE_MODEL](LICENSE_MODEL)。"
      },
      {
        "row": 6,
        "rowsha": "H+kY5xnGhZR4AP8HXEBrI5pJl2u2T6PRw9DgjCUq7pc=",
        "originContent": "Please check out the repository [LICENSE](LICENSE) before using the provided code and",
        "translatedContent": ""
      },
      {
        "row": 7,
        "rowsha": "zuOf0YpuoKYLTi5hsnbW2+hldgBXg2bI7qG+fu8b8Pc=",
        "originContent": "[LICENSE_MODEL](LICENSE_MODEL) for the released models.",
        "translatedContent": ""
      },
      {
        "row": 8,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  }
]