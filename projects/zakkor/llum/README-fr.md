# llum

### Une interface de chat rapide, lÃ©gÃ¨re et ouverte

![image](https://github.com/user-attachments/assets/38cc47cf-06a3-4dca-8ee5-d9c9edf57903)

### FonctionnalitÃ©s clÃ©s :

- ðŸ”Œ Plusieurs fournisseurs, branchez vos clÃ©s API (stockÃ©es entiÃ¨rement localement) et vous Ãªtes prÃªt Ã  partir

  - ModÃ¨les locaux (via Ollama)
  - OpenRouter (qui vous permet d'utiliser TOUS les modÃ¨les de nombreux fournisseurs : OpenAI, Anthropic, OSS, plus de 50 autres)
  - OpenAI
  - Anthropic
  - Mistral
  - Groq

- ðŸ› ï¸ Utilisation dâ€™outils
  - Consultez `server/toolfns/toolfns.go`. Vous nâ€™avez quâ€™Ã  Ã©crire des fonctions. Le commentaire de la fonction est la description que le modÃ¨le reÃ§oit, il sait donc quoi utiliser. Cliquez sur le bouton `Sync` dans lâ€™interface web pour actualiser vos outils.
- ðŸ–¼ï¸ EntrÃ©e multimodale : tÃ©lÃ©chargez, collez ou partagez des liens vers des images
- ðŸŽ¨ GÃ©nÃ©ration dâ€™images avec DALL-E 3
- ðŸ“ Prompting multi-shot. Ã‰ditez, supprimez, rÃ©gÃ©nÃ©rez des messages, faites ce que vous voulez. Le monde est Ã  vous
- âš¡ RÃ©ponses prÃ©-remplies (lorsque supportÃ©es par le fournisseur)
- ðŸŒ Support de tous les modÃ¨les disponibles chez tous les fournisseurs
- ðŸ”„ Changement de modÃ¨le en cours de conversation
- ðŸ” Synchronisation des conversations et des clÃ©s entre appareils, chiffrÃ©e de bout en bout. Auto-hÃ©bergÃ©, ou utilisez notre instance hÃ©bergÃ©e.
- ðŸ”— Partage de conversation (si vous choisissez de partager, votre conversation doit Ãªtre stockÃ©e sur un serveur externe pour que le lien de partage soit disponible. Options de partage auto-hÃ©bergÃ©es Ã  venir. Non, je ne consulterai rien de vos donnÃ©es.)
- ðŸŒ¿ Historique de conversation en branches (comme les flÃ¨ches gauche-droite de ChatGPT que vous pouvez cliquer pour revenir Ã  une rÃ©ponse prÃ©cÃ©dente)

### ConfidentialitÃ© :

- ComplÃ¨tement privÃ© et transparent. Tout votre historique de conversation et vos clÃ©s sont stockÃ©s entiÃ¨rement localement, uniquement dans votre navigateur, sur votre appareil.

## Comment installer ?

Si vous ne souhaitez pas utiliser dâ€™outils, vous nâ€™avez rien Ã  installer. Une instance hÃ©bergÃ©e est disponible sur : https://llum.chat

Si vous voulez utiliser des outils, suivez les instructions ci-dessous.

## Binaire unique :

Le serveur dâ€™outils llum est disponible prÃ©compilÃ© en un seul binaire. [TÃ©lÃ©chargez le package prÃ©compilÃ© depuis la page des releases.](https://github.com/zakkor/llum/releases)

TÃ©lÃ©chargez le binaire pour votre plateforme, puis lancez-le, ce qui dÃ©marrera le serveur dâ€™outils :

```
./llum-darwin-amd64
Tool server running at http://localhost:8081
```

Retournez sur https://llum.chat, allez dans ParamÃ¨tres -> Appel dâ€™outil, et cliquez sur le bouton "Actualiser les outils". Vous devriez Ãªtre prÃªt Ã  partir !

### Construction du client et du serveur localement :

1. Clonez le dÃ©pÃ´t
2. Installez et dÃ©marrez le client : `npm i && npm run dev`. Le client sera accessible Ã  http://localhost:5173
3. Installez et dÃ©marrez le serveur : `cd server && go generate ./... && go build && ./server -password foobar`. Le serveur sera accessible Ã  http://localhost:8081. Vous pouvez connecter cela Ã  l'adresse du serveur dans l'interface de chat avec le mot de passe que vous avez choisi.


---

Tranlated By [Open Ai Tx](https://github.com/OpenAiTx/OpenAiTx) | Last indexed: 2025-07-29

---