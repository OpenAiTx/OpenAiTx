# llum

### Una interfaz de chat r√°pida, ligera y abierta

![image](https://github.com/user-attachments/assets/38cc47cf-06a3-4dca-8ee5-d9c9edf57903)

### Caracter√≠sticas clave:

- üîå M√∫ltiples proveedores, conecta tus claves API (almacenadas completamente localmente) y listo

  - Modelos locales (a trav√©s de Ollama)
  - OpenRouter (que te permite usar TODOS los modelos de muchos proveedores: OpenAI, Anthropic, OSS, m√°s de 50 otros)
  - OpenAI
  - Anthropic
  - Mistral
  - Groq

- üõ†Ô∏è Uso de herramientas
  - Revisa `server/toolfns/toolfns.go`. Solo necesitas escribir funciones. El comentario de la funci√≥n es la descripci√≥n que recibe el modelo, para saber qu√© usar. Haz clic en el bot√≥n `Sync` en la interfaz web para actualizar tus herramientas.
- üñºÔ∏è Entrada multimodal: sube, pega o comparte enlaces a im√°genes
- üé® Generaci√≥n de im√°genes usando DALL-E 3
- üìù Prompts multi-disparo. Tambi√©n edita, elimina, regenera mensajes, lo que quieras. El mundo es tuyo
- ‚ö° Respuestas prellenadas (donde el proveedor lo soporte)
- üåê Soporte para todos los modelos disponibles en todos los proveedores
- üîÑ Cambia de modelo en medio de la conversaci√≥n
- üîê Sincroniza chats y claves entre dispositivos, cifrado de extremo a extremo. Autoalojado, o usa nuestra instancia alojada.
- üîó Compartir conversaci√≥n (si eliges compartir, tu conversaci√≥n debe almacenarse en un servidor externo para que el enlace de compartici√≥n est√© disponible. Pr√≥ximamente opciones de compartir autoalojadas. No, no ver√© nada de tu contenido.)
- üåø Historial de conversaci√≥n ramificado (como las flechas izquierda-derecha de ChatGPT que puedes clicar para volver a una respuesta anterior)

### Privacidad:

- Completamente privada y transparente. Todo tu historial de conversaci√≥n y claves se almacenan completamente localmente, y solo en tu navegador, en tu dispositivo.

## ¬øC√≥mo instalar?

Si no quieres usar herramientas, no necesitas instalar nada. Hay una instancia alojada disponible en: https://llum.chat

Si quieres usar herramientas, contin√∫a a continuaci√≥n.

## Binario √∫nico:

El servidor de herramientas llum est√° disponible precompilado como un binario √∫nico. [Descarga el paquete precompilado desde la p√°gina de lanzamientos.](https://github.com/zakkor/llum/releases)

Descarga el binario para tu plataforma, luego ejec√∫talo, lo que iniciar√° el servidor de herramientas:

```
./llum-darwin-amd64
Tool server running at http://localhost:8081
```

Vuelve a https://llum.chat, dir√≠gete a Configuraci√≥n -> Llamada de herramientas, y haz clic en el bot√≥n "Actualizar herramientas". ¬°Deber√≠as estar listo para continuar!

### Construcci√≥n del cliente y servidor localmente:

1. Clona el repositorio
2. Instala y arranca el cliente: `npm i && npm run dev`. El cliente ser√° accesible en http://localhost:5173
3. Instala y arranca el servidor: `cd server && go generate ./... && go build && ./server -password foobar`. El servidor ser√° accesible en http://localhost:8081. Puedes conectar esto en la direcci√≥n del servidor en la interfaz de chat junto con la contrase√±a que seleccionaste.


---

Tranlated By [Open Ai Tx](https://github.com/OpenAiTx/OpenAiTx) | Last indexed: 2025-07-29

---