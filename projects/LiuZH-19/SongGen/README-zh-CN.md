# SongGenï¼šä¸€ä¸ªç”¨äºæ–‡æœ¬åˆ°æ­Œæ›²ç”Ÿæˆçš„å•é˜¶æ®µè‡ªå›å½’å˜æ¢å™¨

ğŸš€ğŸš€ğŸš€ **SongGenï¼šä¸€ä¸ªç”¨äºæ–‡æœ¬åˆ°æ­Œæ›²ç”Ÿæˆçš„å•é˜¶æ®µè‡ªå›å½’å˜æ¢å™¨** å®˜æ–¹å®ç°  
<p align="center" style="font-size: 1 em; margin-top: -1em">
<a href="https://scholar.google.com/citations?user=iELd-Q0AAAAJ">åˆ˜å­æ¶µ</a>,  
<a href="https://mark12ding.github.io/">ä¸çˆ½é”</a>,  
<a href="https://github.com/rookiexiong7/">å¼ æ™ºé›„</a>, 
<a href="https://lightdxy.github.io/">è‘£æ™“æ¯…</a>,  
<a href="https://panzhang0212.github.io/">å¼ æ”€</a>,
<a href="https://yuhangzang.github.io/">è‡§å®‡èˆª</a>,  
<a href="https://scholar.google.com/citations?user=sJkqsqkAAAAJ">æ›¹å®‡èˆª</a>, </br>  
<a href="http://dahua.site/">æ—å¤§å</a>,  
<a href="https://myownskyw7.github.io/">ç‹ä½³ç¦</a> 
</p>

<p align="center" style="font-size: 5 em; margin-top: 0.5em">
<a href="https://arxiv.org/abs/2502.13128"><img src="https://img.shields.io/badge/arXiv-<color>"></a>
<a href="https://github.com/LiuZH-19/SongGen"><img src="https://img.shields.io/badge/Code-red"></a>
<a href="https://liuzh-19.github.io/SongGen/"><img src="https://img.shields.io/badge/Demo-20d67c"></a>
<a href="https://huggingface.co/collections/LiuZH-19/songgen-a-single-stage-auto-regressive-transformer-for-text-6867ec21169d808034f6d252">
    <img src="https://img.shields.io/badge/HF-Collection-yellow"></a>
</p>





## ğŸ“œ æ–°é—»
ğŸš€ [2025/7/4] æˆ‘ä»¬å‘å¸ƒäº†è®­ç»ƒä»£ç åŠè¯¦ç»†çš„[è®­ç»ƒæŒ‡å—](https://raw.githubusercontent.com/LiuZH-19/SongGen/master/./training/README.md) ã€‚

ğŸš€ [2025/6/30] MusicCaps æµ‹è¯•é›†ç°å·²åœ¨ [HuggingfaceğŸ¤—](https://huggingface.co/datasets/LiuZH-19/MusicCaps_Test_Song) ä¸Šå¯ç”¨äºæ–‡æœ¬åˆ°æ­Œæ›²çš„è¯„ä¼°ã€‚

ğŸš€ [2025/6/27] æˆ‘ä»¬å‘å¸ƒäº† SongGen äº¤é”™æ¨¡å¼ï¼ˆè§†å¬ï¼‰æ£€æŸ¥ç‚¹ï¼Œä½äº [HuggingfaceğŸ¤—](https://huggingface.co/LiuZH-19/SongGen_interleaving_A_V)ã€‚

ğŸ‰ [2025/5/1] SongGen è¢« ICML 2025 æ¥æ”¶ï¼

ğŸš€ [2025/3/18] æˆ‘ä»¬å‘å¸ƒäº† SongGen æ··åˆä¸“ä¸šç‰ˆæ£€æŸ¥ç‚¹ï¼Œä½äº [HuggingfaceğŸ¤—](https://huggingface.co/LiuZH-19/SongGen_mixed_pro)ã€‚

ğŸš€ [2025/2/19] è®ºæ–‡([paper](https://arxiv.org/abs/2502.13128)) å’Œ [æ¼”ç¤ºé¡µé¢](https://liuzh-19.github.io/SongGen/) æ­£å¼å‘å¸ƒï¼

## ğŸ’¡ äº®ç‚¹
- ğŸ”¥ æˆ‘ä»¬æ¨å‡ºäº† SongGenï¼Œä¸€æ¬¾ç”¨äº**æ–‡æœ¬åˆ°æ­Œæ›²**ç”Ÿæˆçš„**å•é˜¶æ®µ**è‡ªå›å½’å˜æ¢å™¨ï¼Œæ”¯æŒé€šè¿‡æ­Œè¯ã€æè¿°æ–‡æœ¬åŠå¯é€‰çš„å‚è€ƒå£°éŸ³å®ç°å¤šæ ·åŒ–æ§åˆ¶ã€‚
- ğŸ”¥ SongGen æ”¯æŒ**æ··åˆ**åŠ**åŒè½¨æ¨¡å¼**ä»¥æ»¡è¶³ä¸åŒéœ€æ±‚ã€‚æˆ‘ä»¬çš„å®éªŒä¸ºä¸¤ç§æ¨¡å¼çš„ä¼˜åŒ–æä¾›äº†**å®è´µè§è§£**ã€‚
- ğŸ”¥ é€šè¿‡å‘å¸ƒ**æ¨¡å‹æƒé‡**ã€**ä»£ç **ã€**æ ‡æ³¨æ•°æ®**åŠ**é¢„å¤„ç†æµç¨‹**ï¼Œæˆ‘ä»¬æ—¨åœ¨ä¸ºæœªæ¥çš„æ­Œæ›²ç”Ÿæˆç ”ç©¶å»ºç«‹ä¸€ä¸ªç®€å•è€Œæœ‰æ•ˆçš„åŸºçº¿ã€‚
<!-- <img align="center" src="https://raw.githubusercontent.com/LiuZH-19/SongGen/master/assets/imgs/motivation1.jpg" style="  display: block;
  margin-left: auto;
  margin-right: auto;
  width: 50%;" /> -->

## ğŸ‘¨â€ğŸ’» å¾…åŠäº‹é¡¹
- [ ] å‘å¸ƒæ ‡æ³¨æ•°æ®å’Œé¢„å¤„ç†æµç¨‹
- [x] å‘å¸ƒ Musiccaps æµ‹è¯•é›†
- [x] å‘å¸ƒ SongGen è®­ç»ƒä»£ç 
- [x] å‘å¸ƒ SongGenï¼ˆäº¤é”™è§†å¬ï¼‰æ£€æŸ¥ç‚¹
- [x] å‘å¸ƒ SongGen æ··åˆä¸“ä¸šç‰ˆæ£€æŸ¥ç‚¹
- [x] å‘å¸ƒ SongGen æ¨ç†ä»£ç  
- [x] SongGen æ¼”ç¤º

## ğŸ› ï¸ ä½¿ç”¨è¯´æ˜

### 1. å®‰è£…ç¯å¢ƒå’Œä¾èµ–
```bash
git clone https://github.com/LiuZH-19/SongGen.git
cd SongGen
# We recommend using conda to create a new environment.
conda create -n songgen_env python=3.9.18 
conda activate songgen_env
# Install CUDA >= 11.8 and PyTorch, e.g.,
pip install torch==2.3.0 torchvision==0.18.0 torchaudio==2.3.0 --index-url https://download.pytorch.org/whl/cu118
pip install flash-attn==2.6.1 --no-build-isolation
```
ä»…åœ¨æ¨ç†æ¨¡å¼ä¸‹ä½¿ç”¨ SongGenï¼Œè¯·ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å®‰è£…ï¼š
```bash
pip install -e .
```
### 2. ä¸‹è½½ xcodec

ä» [ğŸ¤—](https://raw.githubusercontent.com/LiuZH-19/SongGen/master/
https://huggingface.co/ZhenYe234/xcodec/blob/main/xcodec_hubert_general_audio_v2.pth) ä¸‹è½½ X-Codec æ£€æŸ¥ç‚¹ï¼Œå¹¶å°†å…¶æ”¾ç½®åœ¨ä»¥ä¸‹ç›®å½•ï¼šSongGen/songgen/xcodec_wrapper/xcodec_infer/ckpts/general_more

```
xcodec_infer
    â”œâ”€â”€ ckpts
    â”‚   â””â”€â”€ general_more
    â”‚       â”œâ”€â”€ config_hubert_general.yaml
    â”‚       â””â”€â”€ xcodec_hubert_general_audio_v2.pth

```

### 3. è¿è¡Œæ¨ç†

#### (1). æ··åˆä¸“ä¸šæ¨¡å¼

```python
import torch
import os
from songgen import (
    VoiceBpeTokenizer,
    SongGenMixedForConditionalGeneration,
    SongGenProcessor
)
import soundfile as sf

ckpt_path = "LiuZH-19/SongGen_mixed_pro" # Path to the pretrained model
device = "cuda:0" if torch.cuda.is_available() else "cpu"
model = SongGenMixedForConditionalGeneration.from_pretrained(
    ckpt_path,
    attn_implementation='sdpa').to(device)
processor = SongGenProcessor(ckpt_path, device)

# Define input text and lyrics
lyrics = "..." # The lyrics text
text = "..." # The music description text
ref_voice_path = 'path/to/your/reference_audio.wav' # Path to reference audio, optional
separate= True # Whether to separate the vocal track from the reference voice audio

model_inputs = processor(text=text, lyrics=lyrics, ref_voice_path=ref_voice_path, separate=separate) 
generation = model.generate(**model_inputs,
                do_sample=True,
            )
audio_arr = generation.cpu().numpy().squeeze()
sf.write("songgen_out.wav", audio_arr, model.config.sampling_rate)
```



#### (2). Interleaving A-V  (Dual-track mode)
```python
import torch
import os
from songgen import (
    VoiceBpeTokenizer,
    SongGenDualTrackForConditionalGeneration,
    SongGenProcessor
)
import soundfile as sf

ckpt_path = "LiuZH-19/SongGen_interleaving_A_V" # Path to the pretrained model
device = "cuda:0" if torch.cuda.is_available() else "cpu"
model = SongGenDualTrackForConditionalGeneration.from_pretrained(
    ckpt_path,
    attn_implementation='sdpa').to(device)
processor = SongGenProcessor(ckpt_path, device)

# Define input text and lyrics
lyrics = "..." # The lyrics text
text = "..." # The music description text
ref_voice_path = 'path/to/your/reference_audio.wav' # Path to reference audio, optional
separate= True # Whether to separate the vocal track from the reference voice audio

model_inputs = processor(text=text, lyrics=lyrics, ref_voice_path=ref_voice_path, separate=True) 
generation = model.generate(**model_inputs,
                do_sample=True,
            )

acc_array = generation[0].cpu().numpy()
vocal_array = generation[1].cpu().numpy()
min_len =min(vocal_array.shape[0], acc_array.shape[0])
acc_array = acc_array[:min_len]
vocal_array = vocal_array[:min_len]
audio_arr = vocal_array + acc_array
sf.write("songgen_out.wav", audio_arr, model.config.sampling_rate)
```
### 4. è®­ç»ƒ

[è®­ç»ƒæ–‡ä»¶å¤¹](./training) åŒ…å«äº†è®­ç»ƒæˆ–å¾®è°ƒæ‚¨è‡ªå·±çš„ SongGen æ¨¡å‹çš„æ‰€æœ‰ä¿¡æ¯ã€‚è¯·å‚é˜…[è®­ç»ƒæŒ‡å—](https://raw.githubusercontent.com/LiuZH-19/SongGen/master/./training/README.md)ä»¥è·å–é€æ­¥è¯´æ˜ã€‚



## â¤ï¸ è‡´è°¢
æœ¬åº“åŸºäºå¤šä¸ªå¼€æºå·¨å¤´çš„å·¥ä½œï¼Œæ„Ÿè°¢ä»–ä»¬æä¾›çš„å·¥å…·ï¼

ç‰¹åˆ«æ„Ÿè°¢ï¼š

- [Parler-tts](https://github.com/huggingface/parler-tts)ï¼šæˆ‘ä»¬æ„å»ºçš„ä»£ç åº“åŸºç¡€ã€‚
- [X-Codec](https://github.com/zhenye234/xcodec)ï¼šæˆ‘ä»¬ç ”ç©¶ä¸­ä½¿ç”¨çš„éŸ³é¢‘ç¼–è§£ç å™¨ã€‚
- [lp-music-caps](https://github.com/seungheondoh/lp-music-caps)ï¼šä¸€ä¸ªç”ŸæˆéŸ³ä¹å­—å¹•çš„é¡¹ç›®ã€‚

æˆ‘ä»¬è¡·å¿ƒæ„Ÿè°¢ä¸€è·¯ä»¥æ¥å¾—åˆ°çš„æ”¯æŒã€‚

## â˜ï¸ é™åˆ¶ä¸æœªæ¥å·¥ä½œ

è¿™æ˜¯ä¸€ä¸ªä¸“æ³¨äº**æ–‡æœ¬åˆ°æ­Œæ›²**ç”Ÿæˆçš„**ç ”ç©¶å·¥ä½œ**ã€‚ç”±äºå½“å‰è®­ç»ƒæ•°æ®é›†çš„é™åˆ¶ï¼Œæˆ‘ä»¬çš„æ¨¡å‹ç›®å‰ä»…é™äºç”Ÿæˆæœ€é•¿30ç§’çš„è‹±æ–‡æ­Œæ›²ã€‚
ç„¶è€Œï¼Œå°½ç®¡ä»…ç”¨**2åƒå°æ—¶**æ•°æ®å’Œ**13äº¿**å‚æ•°æ¨¡å‹è®­ç»ƒï¼Œæˆ‘ä»¬çš„æ–¹æ³•å·²å±•ç¤ºå‡ºå¼ºå¤§çš„æœ‰æ•ˆæ€§å’Œç”Ÿæˆè¿è´¯å¯Œæœ‰è¡¨ç°åŠ›æ­Œæ›²çš„æ½œåŠ›ã€‚æˆ‘ä»¬ç›¸ä¿¡ï¼Œæ‰©å¤§æ•°æ®é‡å’Œæ¨¡å‹è§„æ¨¡å°†è¿›ä¸€æ­¥æå‡æ­Œè¯å¯¹é½å’ŒéŸ³ä¹æ€§ã€‚
è¯è™½å¦‚æ­¤ï¼Œæ‰©å±•æ•°æ®é›†æ—¢è€—æ—¶åˆå…·æŒ‘æˆ˜æ€§ã€‚æˆ‘ä»¬æ¬¢è¿åˆä½œå’Œè®¨è®ºï¼Œå…±åŒæ¢ç´¢æ”¹è¿›æ¨¡å‹å’Œæ‰©å±•å…¶èƒ½åŠ›çš„æ–°é€”å¾„ã€‚
å¦‚æœ‰ä»»ä½•ç–‘é—®æˆ–æ½œåœ¨åˆä½œæ„å‘ï¼Œæ¬¢è¿è”ç³»ï¼šåˆ˜å­æ¶µ (liuzihan@pjlab.org.cn) å’Œ ç‹ä½³ç¦ (wangjiaqi@pjlab.org.cn)ã€‚

## âœ’ï¸ å¼•ç”¨
å¦‚æœæˆ‘ä»¬çš„å·¥ä½œå¯¹æ‚¨çš„ç ”ç©¶æœ‰æ‰€å¸®åŠ©ï¼Œæ¬¢è¿ç‚¹èµ â­ å¹¶å¼•ç”¨ ğŸ“

```bibtex
@misc{liu2025songgen,
      title={SongGen: A Single Stage Auto-regressive Transformer for Text-to-Song Generation}, 
      author={Zihan Liu and Shuangrui Ding and Zhixiong Zhang and Xiaoyi Dong and Pan Zhang and Yuhang Zang and Yuhang Cao and Dahua Lin and Jiaqi Wang},
      year={2025},
      eprint={2502.13128},
      archivePrefix={arXiv},
      primaryClass={cs.SD},
      url={https://arxiv.org/abs/2502.13128}, 
}

```







---

Tranlated By [Open Ai Tx](https://github.com/OpenAiTx/OpenAiTx) | Last indexed: 2025-08-07

---