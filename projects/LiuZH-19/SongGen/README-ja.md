# SongGen: ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰æ­Œã¸ã®ç”Ÿæˆã®ãŸã‚ã®å˜ä¸€æ®µéšè‡ªå·±å›å¸°å‹ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼

ğŸš€ğŸš€ğŸš€ **SongGen: ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰æ­Œã¸ã®ç”Ÿæˆã®ãŸã‚ã®å˜ä¸€æ®µéšè‡ªå·±å›å¸°å‹ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼** ã®å…¬å¼å®Ÿè£…  
<p align="center" style="font-size: 1 em; margin-top: -1em">
<a href="https://scholar.google.com/citations?user=iELd-Q0AAAAJ">åŠ‰å­æ¶µ</a>,  
<a href="https://mark12ding.github.io/">ä¸çˆ½ç¿</a>,  
<a href="https://github.com/rookiexiong7/">å¼µå¿—é›„</a>, 
<a href="https://lightdxy.github.io/">è‘£æ›‰æ€¡</a>,  
<a href="https://panzhang0212.github.io/">å¼µæ”€</a>,
<a href="https://yuhangzang.github.io/">è‡§å®‡èˆª</a>,  
<a href="https://scholar.google.com/citations?user=sJkqsqkAAAAJ">æ›¹å®‡èˆª</a>, </br>  
<a href="http://dahua.site/">æ—å¤§è¯</a>,  
<a href="https://myownskyw7.github.io/">ç‹å˜‰çª</a> 
</p>

<p align="center" style="font-size: 5 em; margin-top: 0.5em">
<a href="https://arxiv.org/abs/2502.13128"><img src="https://img.shields.io/badge/arXiv-<color>"></a>
<a href="https://github.com/LiuZH-19/SongGen"><img src="https://img.shields.io/badge/Code-red"></a>
<a href="https://liuzh-19.github.io/SongGen/"><img src="https://img.shields.io/badge/Demo-20d67c"></a>
<a href="https://huggingface.co/collections/LiuZH-19/songgen-a-single-stage-auto-regressive-transformer-for-text-6867ec21169d808034f6d252">
    <img src="https://img.shields.io/badge/HF-Collection-yellow"></a>
</p>





## ğŸ“œ ãƒ‹ãƒ¥ãƒ¼ã‚¹
ğŸš€ [2025/7/4] è©³ç´°ãª[ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¬ã‚¤ãƒ‰](https://raw.githubusercontent.com/LiuZH-19/SongGen/master/./training/README.md)ã¨å…±ã«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚³ãƒ¼ãƒ‰ã‚’å…¬é–‹ã—ã¾ã—ãŸã€‚

ğŸš€ [2025/6/30] MusicCapsãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆãŒãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰æ­Œã¸ã®è©•ä¾¡ç”¨ã«[HuggingfaceğŸ¤—](https://huggingface.co/datasets/LiuZH-19/MusicCaps_Test_Song)ã§åˆ©ç”¨å¯èƒ½ã«ãªã‚Šã¾ã—ãŸã€‚

ğŸš€ [2025/6/27] SongGen Interleaving (A-V) ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’[HuggingfaceğŸ¤—](https://huggingface.co/LiuZH-19/SongGen_interleaving_A_V)ã§å…¬é–‹ã—ã¾ã—ãŸã€‚

ğŸ‰ [2025/5/1] SongGenãŒICML 2025ã«æ¡æŠã•ã‚Œã¾ã—ãŸï¼

ğŸš€ [2025/3/18] SongGen Mixed_Pro ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’[HuggingfaceğŸ¤—](https://huggingface.co/LiuZH-19/SongGen_mixed_pro)ã§å…¬é–‹ã—ã¾ã—ãŸã€‚

ğŸš€ [2025/2/19] [è«–æ–‡](https://arxiv.org/abs/2502.13128)ã¨[ãƒ‡ãƒ¢ãƒšãƒ¼ã‚¸](https://liuzh-19.github.io/SongGen/)ã‚’å…¬é–‹ã—ã¾ã—ãŸï¼

## ğŸ’¡ ãƒã‚¤ãƒ©ã‚¤ãƒˆ
- ğŸ”¥SongGenã¯ã€æ­Œè©ã€èª¬æ˜æ–‡ã€ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®å‚ç…§ãƒœã‚¤ã‚¹ã‚’é€šã˜ã¦å¤šæ§˜ãªåˆ¶å¾¡ã‚’å¯èƒ½ã«ã™ã‚‹ã€**å˜ä¸€æ®µéš**ã®è‡ªå·±å›å¸°å‹ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã«ã‚ˆã‚‹**ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰æ­Œ**ã¸ã®ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã‚’å°å…¥ã—ã¾ã™ã€‚
- ğŸ”¥SongGenã¯ã€**æ··åˆãƒ¢ãƒ¼ãƒ‰**ã¨**äºŒé‡ãƒˆãƒ©ãƒƒã‚¯ãƒ¢ãƒ¼ãƒ‰**ã®ä¸¡æ–¹ã‚’ã‚µãƒãƒ¼ãƒˆã—ã€å¤šæ§˜ãªè¦ä»¶ã«å¯¾å¿œã—ã¾ã™ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šä¸¡ãƒ¢ãƒ¼ãƒ‰ã®æœ€é©åŒ–ã«é–¢ã™ã‚‹**è²´é‡ãªçŸ¥è¦‹**ã‚’æä¾›ã—ã¾ã™ã€‚
- ğŸ”¥**ãƒ¢ãƒ‡ãƒ«é‡ã¿**ã€**ã‚³ãƒ¼ãƒ‰**ã€**æ³¨é‡ˆä»˜ããƒ‡ãƒ¼ã‚¿**ã€ãŠã‚ˆã³**å‰å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³**ã‚’å…¬é–‹ã™ã‚‹ã“ã¨ã§ã€å°†æ¥ã®æ­Œç”Ÿæˆç ”ç©¶ã®ãŸã‚ã®ã‚·ãƒ³ãƒ—ãƒ«ã§åŠ¹æœçš„ãªãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã®æ§‹ç¯‰ã‚’ç›®æŒ‡ã—ã¾ã™ã€‚
<!-- <img align="center" src="https://raw.githubusercontent.com/LiuZH-19/SongGen/master/assets/imgs/motivation1.jpg" style="  display: block;
  margin-left: auto;
  margin-right: auto;
  width: 50%;" /> -->

## ğŸ‘¨â€ğŸ’» Todo
- [ ] æ³¨é‡ˆä»˜ããƒ‡ãƒ¼ã‚¿ã¨å‰å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®å…¬é–‹
- [x] Musiccapsãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã®å…¬é–‹
- [x] SongGenãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚³ãƒ¼ãƒ‰ã®å…¬é–‹
- [x] SongGen (Interleaving A-V) ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã®å…¬é–‹
- [x] SongGen Mixed_pro ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã®å…¬é–‹
- [x] SongGenæ¨è«–ã‚³ãƒ¼ãƒ‰ã®å…¬é–‹
- [x] SongGenãƒ‡ãƒ¢

## ğŸ› ï¸ ä½¿ã„æ–¹

### 1. ç’°å¢ƒã¨ä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
```bash
git clone https://github.com/LiuZH-19/SongGen.git
cd SongGen
# We recommend using conda to create a new environment.
conda create -n songgen_env python=3.9.18 
conda activate songgen_env
# Install CUDA >= 11.8 and PyTorch, e.g.,
pip install torch==2.3.0 torchvision==0.18.0 torchaudio==2.3.0 --index-url https://download.pytorch.org/whl/cu118
pip install flash-attn==2.6.1 --no-build-isolation
```
SongGenã‚’æ¨è«–ãƒ¢ãƒ¼ãƒ‰ã®ã¿ã§ä½¿ç”¨ã™ã‚‹ã«ã¯ã€æ¬¡ã®ã‚³ãƒãƒ³ãƒ‰ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„ï¼š
```bash
pip install -e .
```
### 2. xcodecã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰

X-Codecã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’[ğŸ¤—](https://raw.githubusercontent.com/LiuZH-19/SongGen/master/
https://huggingface.co/ZhenYe234/xcodec/blob/main/xcodec_hubert_general_audio_v2.pth)ã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã€ä»¥ä¸‹ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«é…ç½®ã—ã¦ãã ã•ã„ : SongGen/songgen/xcodec_wrapper/xcodec_infer/ckpts/general_more

```
xcodec_infer
    â”œâ”€â”€ ckpts
    â”‚   â””â”€â”€ general_more
    â”‚       â”œâ”€â”€ config_hubert_general.yaml
    â”‚       â””â”€â”€ xcodec_hubert_general_audio_v2.pth

```

### 3. æ¨è«–ã‚’å®Ÿè¡Œã™ã‚‹

#### (1). ãƒŸãƒƒã‚¯ã‚¹ãƒ‰ãƒ—ãƒ­ãƒ¢ãƒ¼ãƒ‰

```python
import torch
import os
from songgen import (
    VoiceBpeTokenizer,
    SongGenMixedForConditionalGeneration,
    SongGenProcessor
)
import soundfile as sf

ckpt_path = "LiuZH-19/SongGen_mixed_pro" # Path to the pretrained model
device = "cuda:0" if torch.cuda.is_available() else "cpu"
model = SongGenMixedForConditionalGeneration.from_pretrained(
    ckpt_path,
    attn_implementation='sdpa').to(device)
processor = SongGenProcessor(ckpt_path, device)

# Define input text and lyrics
lyrics = "..." # The lyrics text
text = "..." # The music description text
ref_voice_path = 'path/to/your/reference_audio.wav' # Path to reference audio, optional
separate= True # Whether to separate the vocal track from the reference voice audio

model_inputs = processor(text=text, lyrics=lyrics, ref_voice_path=ref_voice_path, separate=separate) 
generation = model.generate(**model_inputs,
                do_sample=True,
            )
audio_arr = generation.cpu().numpy().squeeze()
sf.write("songgen_out.wav", audio_arr, model.config.sampling_rate)
```



#### (2). Interleaving A-V  (Dual-track mode)
```python
import torch
import os
from songgen import (
    VoiceBpeTokenizer,
    SongGenDualTrackForConditionalGeneration,
    SongGenProcessor
)
import soundfile as sf

ckpt_path = "LiuZH-19/SongGen_interleaving_A_V" # Path to the pretrained model
device = "cuda:0" if torch.cuda.is_available() else "cpu"
model = SongGenDualTrackForConditionalGeneration.from_pretrained(
    ckpt_path,
    attn_implementation='sdpa').to(device)
processor = SongGenProcessor(ckpt_path, device)

# Define input text and lyrics
lyrics = "..." # The lyrics text
text = "..." # The music description text
ref_voice_path = 'path/to/your/reference_audio.wav' # Path to reference audio, optional
separate= True # Whether to separate the vocal track from the reference voice audio

model_inputs = processor(text=text, lyrics=lyrics, ref_voice_path=ref_voice_path, separate=True) 
generation = model.generate(**model_inputs,
                do_sample=True,
            )

acc_array = generation[0].cpu().numpy()
vocal_array = generation[1].cpu().numpy()
min_len =min(vocal_array.shape[0], acc_array.shape[0])
acc_array = acc_array[:min_len]
vocal_array = vocal_array[:min_len]
audio_arr = vocal_array + acc_array
sf.write("songgen_out.wav", audio_arr, model.config.sampling_rate)
```
### 4. ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°

[trainingãƒ•ã‚©ãƒ«ãƒ€](./training)ã«ã¯ã€ç‹¬è‡ªã®SongGenãƒ¢ãƒ‡ãƒ«ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¾ãŸã¯ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ãŸã‚ã®ã™ã¹ã¦ã®æƒ…å ±ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚ã‚¹ãƒ†ãƒƒãƒ—ãƒã‚¤ã‚¹ãƒ†ãƒƒãƒ—ã®æ‰‹é †ã«ã¤ã„ã¦ã¯ã€[ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¬ã‚¤ãƒ‰](https://raw.githubusercontent.com/LiuZH-19/SongGen/master/./training/README.md)ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚



## â¤ï¸ è¬è¾
ã“ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¯å¤šãã®ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®å·¨äººãŸã¡ã®ä¸Šã«æ§‹ç¯‰ã•ã‚Œã¦ã„ã¾ã™ã€‚ã“ã‚Œã‚‰ã®ãƒ„ãƒ¼ãƒ«ã‚’æä¾›ã—ã¦ãã ã•ã£ãŸæ–¹ã€…ã«å¿ƒã‚ˆã‚Šæ„Ÿè¬ã„ãŸã—ã¾ã™ï¼

ç‰¹ã«æ„Ÿè¬ã‚’è¡¨ã—ãŸã„ã®ã¯ï¼š

- [Parler-tts](https://github.com/huggingface/parler-tts): ç§ãŸã¡ãŒåŸºç›¤ã¨ã—ãŸã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã€‚ 
- [X-Codec](https://github.com/zhenye234/xcodec): ç§ãŸã¡ã®ç ”ç©¶ã§ä½¿ç”¨ã•ã‚ŒãŸã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚³ãƒ¼ãƒ‡ãƒƒã‚¯ã€‚
- [lp-music-caps](https://github.com/seungheondoh/lp-music-caps): éŸ³æ¥½ã®ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ç”Ÿæˆã‚’ç›®çš„ã¨ã—ãŸãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã€‚ 

ã“ã‚Œã¾ã§ã«ã„ãŸã ã„ãŸã™ã¹ã¦ã®æ”¯æ´ã«æ·±ãæ„Ÿè¬ã—ã¦ã„ã¾ã™ã€‚

## â˜ï¸ åˆ¶é™ã¨ä»Šå¾Œã®èª²é¡Œ

ã“ã‚Œã¯**ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰æ­Œã¸ã®**ç”Ÿæˆã«ç„¦ç‚¹ã‚’å½“ã¦ãŸ**ç ”ç©¶ä½œæ¥­**ã§ã™ã€‚ç¾åœ¨ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®åˆ¶ç´„ã«ã‚ˆã‚Šã€å½“ãƒ¢ãƒ‡ãƒ«ã¯ç¾åœ¨è‹±èªã®æ­Œã®ã¿ã€æœ€å¤§30ç§’ã®ç”Ÿæˆã«é™å®šã•ã‚Œã¦ã„ã¾ã™ã€‚
ã—ã‹ã—ã€**2kæ™‚é–“**ã®ãƒ‡ãƒ¼ã‚¿ã¨**1.3B**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒ¢ãƒ‡ãƒ«ã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚Œã¦ã„ã‚‹ã«ã‚‚ã‹ã‹ã‚ã‚‰ãšã€ç§ãŸã¡ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯ä¸€è²«æ€§ãŒã‚ã‚Šè¡¨ç¾åŠ›è±Šã‹ãªæ­Œã‚’ç”Ÿæˆã™ã‚‹ä¸Šã§å¼·åŠ›ãªåŠ¹æœã¨æœ‰æœ›ãªå¯èƒ½æ€§ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã¨ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã®ä¸¡æ–¹ã‚’æ‹¡å¤§ã™ã‚‹ã“ã¨ã§ã€æ­Œè©ã®æ•´åˆæ€§ã‚„éŸ³æ¥½æ€§ãŒã•ã‚‰ã«å‘ä¸Šã™ã‚‹ã¨è€ƒãˆã¦ã„ã¾ã™ã€‚
ã¨ã¯ã„ãˆã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æ‹¡å¤§ã¯æ™‚é–“ãŒã‹ã‹ã‚Šå›°é›£ã§ã™ã€‚ãƒ¢ãƒ‡ãƒ«ã®æ”¹å–„ã¨æ©Ÿèƒ½æ‹¡å¼µã®ãŸã‚ã®æ–°ã—ã„æ–¹æ³•ã‚’æ¢æ±‚ã™ã‚‹ãŸã‚ã«ã€å”åŠ›ã‚„è­°è«–ã‚’æ­“è¿ã—ã¾ã™ã€‚
ã”è³ªå•ã‚„æ½œåœ¨çš„ãªå”åŠ›ã«ã¤ã„ã¦ã¯ã€ãŠæ°—è»½ã«ãŠå•ã„åˆã‚ã›ãã ã•ã„ï¼šZihan Liu (liuzihan@pjlab.org.cn) ã¨ Jiaqi Wang (wangjiaqi@pjlab.org.cn)ã€‚

## âœ’ï¸ å¼•ç”¨
ã‚‚ã—ç§ãŸã¡ã®ç ”ç©¶ãŒã‚ãªãŸã®ç ”ç©¶ã«å½¹ç«‹ã£ãŸå ´åˆã¯ã€ã‚¹ã‚¿ãƒ¼â­ã¨å¼•ç”¨ğŸ“ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚

```bibtex
@misc{liu2025songgen,
      title={SongGen: A Single Stage Auto-regressive Transformer for Text-to-Song Generation}, 
      author={Zihan Liu and Shuangrui Ding and Zhixiong Zhang and Xiaoyi Dong and Pan Zhang and Yuhang Zang and Yuhang Cao and Dahua Lin and Jiaqi Wang},
      year={2025},
      eprint={2502.13128},
      archivePrefix={arXiv},
      primaryClass={cs.SD},
      url={https://arxiv.org/abs/2502.13128}, 
}

```







---

Tranlated By [Open Ai Tx](https://github.com/OpenAiTx/OpenAiTx) | Last indexed: 2025-08-07

---