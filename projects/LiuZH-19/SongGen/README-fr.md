# SongGen : Un transformeur auto-r√©gressif √† √©tape unique pour la g√©n√©ration de chansons √† partir de texte

üöÄüöÄüöÄ Impl√©mentation officielle de **SongGen : Un transformeur auto-r√©gressif √† √©tape unique pour la g√©n√©ration de chansons √† partir de texte**
<p align="center" style="font-size: 1 em; margin-top: -1em">
<a href="https://scholar.google.com/citations?user=iELd-Q0AAAAJ">Zihan Liu</a>,  
<a href="https://mark12ding.github.io/">Shuangrui Ding</a>,  
<a href="https://github.com/rookiexiong7/">Zhixiong Zhang</a>, 
<a href="https://lightdxy.github.io/">Xiaoyi Dong</a>,  
<a href="https://panzhang0212.github.io/">Pan Zhang</a>,
<a href="https://yuhangzang.github.io/">Yuhang Zang</a>,  
<a href="https://scholar.google.com/citations?user=sJkqsqkAAAAJ">Yuhang Cao</a>, </br>  
<a href="http://dahua.site/">Dahua Lin</a>,  
<a href="https://myownskyw7.github.io/">Jiaqi Wang</a> 
</p>

<p align="center" style="font-size: 5 em; margin-top: 0.5em">
<a href="https://arxiv.org/abs/2502.13128"><img src="https://img.shields.io/badge/arXiv-<color>"></a>
<a href="https://github.com/LiuZH-19/SongGen"><img src="https://img.shields.io/badge/Code-red"></a>
<a href="https://liuzh-19.github.io/SongGen/"><img src="https://img.shields.io/badge/Demo-20d67c"></a>
<a href="https://huggingface.co/collections/LiuZH-19/songgen-a-single-stage-auto-regressive-transformer-for-text-6867ec21169d808034f6d252">
    <img src="https://img.shields.io/badge/HF-Collection-yellow"></a>
</p>





## üìú Actualit√©s
üöÄ [2025/7/4] Nous avons publi√© le code d'entra√Ænement avec un [guide d√©taill√©](https://raw.githubusercontent.com/LiuZH-19/SongGen/master/./training/README.md).

üöÄ [2025/6/30] Le jeu de test MusicCaps est d√©sormais disponible sur [Huggingfaceü§ó](https://huggingface.co/datasets/LiuZH-19/MusicCaps_Test_Song) pour l‚Äô√©valuation texte-√†-chanson.

üöÄ [2025/6/27] Nous avons publi√© le checkpoint de SongGen Interleaving (A-V) sur [Huggingfaceü§ó](https://huggingface.co/LiuZH-19/SongGen_interleaving_A_V).

üéâ [2025/5/1] SongGen est accept√© √† ICML 2025 !

üöÄ [2025/3/18] Nous avons publi√© le checkpoint de SongGen Mixed_Pro sur [Huggingfaceü§ó](https://huggingface.co/LiuZH-19/SongGen_mixed_pro).

üöÄ [2025/2/19] Le [papier](https://arxiv.org/abs/2502.13128) et la [page de d√©monstration](https://liuzh-19.github.io/SongGen/) sont publi√©s !

## üí° Points forts
- üî•Nous pr√©sentons SongGen, un transformeur auto-r√©gressif **√† √©tape unique** pour la g√©n√©ration **texte-√†-chanson**, offrant un contr√¥le polyvalent via les paroles, un texte descriptif, et une voix de r√©f√©rence optionnelle.
- üî•SongGen supporte √† la fois les modes **mixte** et **double-piste** pour r√©pondre √† des besoins divers. Nos exp√©riences fournissent des **insights pr√©cieux** pour optimiser les deux modes.
- üî•En publiant les **poids du mod√®le**, le **code**, les **donn√©es annot√©es** et le **pipeline de pr√©traitement**, nous visons √† √©tablir une base simple mais efficace pour les futures recherches en g√©n√©ration de chansons.
<!-- <img align="center" src="https://raw.githubusercontent.com/LiuZH-19/SongGen/master/assets/imgs/motivation1.jpg" style="  display: block;
  margin-left: auto;
  margin-right: auto;
  width: 50%;" /> -->

## üë®‚Äçüíª √Ä faire
- [ ] Publier les donn√©es annot√©es et le pipeline de pr√©traitement
- [x] Publier le jeu de test Musiccaps
- [x] Publier le code d‚Äôentra√Ænement SongGen
- [x] Publier le checkpoint SongGen (Interleaving A-V)
- [x] Publier le checkpoint SongGen Mixed_pro
- [x] Publier le code d‚Äôinf√©rence SongGen
- [x] D√©mo SongGen

## üõ†Ô∏è Utilisation

### 1. Installer l‚Äôenvironnement et les d√©pendances
```bash
git clone https://github.com/LiuZH-19/SongGen.git
cd SongGen
# We recommend using conda to create a new environment.
conda create -n songgen_env python=3.9.18 
conda activate songgen_env
# Install CUDA >= 11.8 and PyTorch, e.g.,
pip install torch==2.3.0 torchvision==0.18.0 torchaudio==2.3.0 --index-url https://download.pytorch.org/whl/cu118
pip install flash-attn==2.6.1 --no-build-isolation
```
Pour utiliser SongGen uniquement en mode inf√©rence, installez-le en utilisant¬†:
```bash
pip install -e .
```
### 2. T√©l√©charger le xcodec

T√©l√©chargez le point de contr√¥le X-Codec depuis [ü§ó](https://raw.githubusercontent.com/LiuZH-19/SongGen/master/
https://huggingface.co/ZhenYe234/xcodec/blob/main/xcodec_hubert_general_audio_v2.pth) et placez-le dans le r√©pertoire suivant : SongGen/songgen/xcodec_wrapper/xcodec_infer/ckpts/general_more

```
xcodec_infer
    ‚îú‚îÄ‚îÄ ckpts
    ‚îÇ   ‚îî‚îÄ‚îÄ general_more
    ‚îÇ       ‚îú‚îÄ‚îÄ config_hubert_general.yaml
    ‚îÇ       ‚îî‚îÄ‚îÄ xcodec_hubert_general_audio_v2.pth

```

### 3. Ex√©cuter l'inf√©rence

#### (1). Mode Pro Mixte

```python
import torch
import os
from songgen import (
    VoiceBpeTokenizer,
    SongGenMixedForConditionalGeneration,
    SongGenProcessor
)
import soundfile as sf

ckpt_path = "LiuZH-19/SongGen_mixed_pro" # Path to the pretrained model
device = "cuda:0" if torch.cuda.is_available() else "cpu"
model = SongGenMixedForConditionalGeneration.from_pretrained(
    ckpt_path,
    attn_implementation='sdpa').to(device)
processor = SongGenProcessor(ckpt_path, device)

# Define input text and lyrics
lyrics = "..." # The lyrics text
text = "..." # The music description text
ref_voice_path = 'path/to/your/reference_audio.wav' # Path to reference audio, optional
separate= True # Whether to separate the vocal track from the reference voice audio

model_inputs = processor(text=text, lyrics=lyrics, ref_voice_path=ref_voice_path, separate=separate) 
generation = model.generate(**model_inputs,
                do_sample=True,
            )
audio_arr = generation.cpu().numpy().squeeze()
sf.write("songgen_out.wav", audio_arr, model.config.sampling_rate)
```



#### (2). Interleaving A-V  (Dual-track mode)
```python
import torch
import os
from songgen import (
    VoiceBpeTokenizer,
    SongGenDualTrackForConditionalGeneration,
    SongGenProcessor
)
import soundfile as sf

ckpt_path = "LiuZH-19/SongGen_interleaving_A_V" # Path to the pretrained model
device = "cuda:0" if torch.cuda.is_available() else "cpu"
model = SongGenDualTrackForConditionalGeneration.from_pretrained(
    ckpt_path,
    attn_implementation='sdpa').to(device)
processor = SongGenProcessor(ckpt_path, device)

# Define input text and lyrics
lyrics = "..." # The lyrics text
text = "..." # The music description text
ref_voice_path = 'path/to/your/reference_audio.wav' # Path to reference audio, optional
separate= True # Whether to separate the vocal track from the reference voice audio

model_inputs = processor(text=text, lyrics=lyrics, ref_voice_path=ref_voice_path, separate=True) 
generation = model.generate(**model_inputs,
                do_sample=True,
            )

acc_array = generation[0].cpu().numpy()
vocal_array = generation[1].cpu().numpy()
min_len =min(vocal_array.shape[0], acc_array.shape[0])
acc_array = acc_array[:min_len]
vocal_array = vocal_array[:min_len]
audio_arr = vocal_array + acc_array
sf.write("songgen_out.wav", audio_arr, model.config.sampling_rate)
```

### 4. Entra√Ænement

Le [dossier d'entra√Ænement](./training) contient toutes les informations pour entra√Æner ou affiner votre propre mod√®le SongGen. Consultez le [guide d'entra√Ænement](https://raw.githubusercontent.com/LiuZH-19/SongGen/master/./training/README.md) pour des instructions √©tape par √©tape.



## ‚ù§Ô∏è Remerciements
Cette biblioth√®que s'appuie sur plusieurs g√©ants open-source, auxquels nous souhaitons adresser nos plus chaleureux remerciements pour avoir fourni ces outils !

Remerciements particuliers √† :

- [Parler-tts](https://github.com/huggingface/parler-tts) : La base de code sur laquelle nous nous sommes appuy√©s. 
- [X-Codec](https://github.com/zhenye234/xcodec) : Le codec audio utilis√© dans notre recherche.
- [lp-music-caps](https://github.com/seungheondoh/lp-music-caps) : Un projet visant √† g√©n√©rer des l√©gendes pour la musique. 

Nous appr√©cions profond√©ment tout le soutien re√ßu au cours de cette aventure.

## ‚òéÔ∏è Limites et travaux futurs

Il s'agit d'un **travail de recherche** ax√© sur la g√©n√©ration de **texte en chanson**. En raison des limites du jeu de donn√©es actuel, notre mod√®le est actuellement limit√© √† la g√©n√©ration de chansons en anglais d'une dur√©e maximale de 30 secondes.
Cependant, malgr√© un entra√Ænement sur seulement **2k heures** de donn√©es avec un mod√®le de **1,3 milliard** de param√®tres, notre approche a d√©montr√© une forte efficacit√© et un potentiel prometteur pour g√©n√©rer des chansons coh√©rentes et expressives. Nous croyons que l'augmentation des donn√©es et de la taille du mod√®le am√©liorera davantage l'alignement des paroles et la musicalit√©.
Cela dit, l'agrandissement du jeu de donn√©es est long et difficile. Nous accueillons volontiers collaborations et discussions pour explorer de nouvelles fa√ßons d'am√©liorer le mod√®le et d'√©tendre ses capacit√©s.
Pour toute question ou collaboration potentielle, n'h√©sitez pas √† contacter : Zihan Liu (liuzihan@pjlab.org.cn) et Jiaqi Wang (wangjiaqi@pjlab.org.cn).

## ‚úíÔ∏è Citation
Si vous trouvez notre travail utile pour votre recherche, merci de consid√©rer mettre une √©toile ‚≠ê et une citation üìù
```bibtex
@misc{liu2025songgen,
      title={SongGen: A Single Stage Auto-regressive Transformer for Text-to-Song Generation}, 
      author={Zihan Liu and Shuangrui Ding and Zhixiong Zhang and Xiaoyi Dong and Pan Zhang and Yuhang Zang and Yuhang Cao and Dahua Lin and Jiaqi Wang},
      year={2025},
      eprint={2502.13128},
      archivePrefix={arXiv},
      primaryClass={cs.SD},
      url={https://arxiv.org/abs/2502.13128}, 
}

```







---

Tranlated By [Open Ai Tx](https://github.com/OpenAiTx/OpenAiTx) | Last indexed: 2025-08-07

---