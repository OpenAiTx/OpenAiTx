{
  "id": 1,
  "origin": "# BIRD-INTERACT 1.0 <img src=\"https://raw.githubusercontent.com/bird-bench/BIRD-Interact/main/materials/hku-logo.jpg\" alt=\"HKU Logo\" width=\"50\" style=\"vertical-align:middle;margin-left:10px;\"> <img src=\"https://raw.githubusercontent.com/bird-bench/BIRD-Interact/main/materials/google-cloud-logo.png\" alt=\"Google Cloud Logo\" width=\"50\" style=\"vertical-align:middle;margin-left:10px;\">\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/bird-bench/BIRD-Interact/main/materials/bird_interact.png\" \n       style=\"width: 30%; min-width: 100px; display: block; margin: auto; border-radius: 15px !important;\">\n</p>\n\n\n<div style=\"display: flex; justify-content: center; align-items: center; gap: 10px;\">\n  <a href=\"https://creativecommons.org/licenses/by-sa/4.0/deed.en\">\n    <img src=\"https://img.shields.io/badge/License-CC%20By%20SA%204.0-orange.svg\" alt=\"License\">\n  </a>\n  <a href=\"https://bird-interact.github.io/\">\n    <img src=\"https://img.shields.io/badge/Leaderboard-2025-28a745.svg\" alt=\"Leaderboard\">\n  </a>\n  <a href=\"https://huggingface.co/datasets/birdsql/bird-interact-lite/tree/main\">\n    <img src=\"https://img.shields.io/badge/Dataset-HuggingFace-FFD21E.svg\" alt=\"HuggingFace\">\n  </a>\n  <a href=\"https://www.python.org/downloads/release/python-310/\">\n    <img src=\"https://img.shields.io/badge/Python-3.10+-teal.svg\" alt=\"Python\">\n  </a>\n  <a href=\"https://pypi.org/project/openai/\">\n    <img src=\"https://img.shields.io/badge/OpenAI-1.40+-beige.svg\" alt=\"OpenAI\">\n  </a>\n</div>\n\n## ðŸ§¸ Overview\n\nBIRD-INTERACT, an interactive text-to-SQL benchmark, **re-imagines Text-to-SQL evaluation via lens of dynamic interactions**.\nThe environment blends a hierarchical knowledge base, database documentation and a function-driven user simulator to recreate authentic enterprise environments across full **CRUD** operations.\nIt offers two rigorous test modes: (1) passive **Conversational Interaction** and (2) active **Agentic Interaction**, spanning 600 annotated tasks including Business Intelligence (BI), CRUD operations and etc., each guarded by executable test cases.\nTypical evaluations trigger 1,968-5,496 interaction turns between model and user simulator, while state-of-the-art reasoning models currently solve only **â‰ˆ24%** and **â‰ˆ18%** of tasks, underscoring the benchmark's challenge.\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/bird-bench/BIRD-Interact/main/materials/workflow.png\" \n       style=\"width: 100%; min-width: 100px; display: block; margin: auto; \">\n</p>\n\n### âœ… Two Evaluation Modes\n\nBIRD-INTERACT supports two evaluation modes as mentioned above:\n\n   - **c-Interact**: Conversational Interaction which is a passive mode and the workflow is fixed. The code and detailed information can be found in `bird_interact_conv`.\n   - **a-Interact**: Agentic Interaction which is an embodied active mode where the workflow is dynamic and led by models. The code and detailed information can be found in `bird_interact_agent`.\n\n\n### ðŸ£ Lite Version\n\nWe are releasing a lite version of BIRD-INTERACT, `bird-interact-lite-exp`, which includes 270 high-quality real-world tasks specifically for PostgreSQL. This is a good starting point for quick experimentation. \n\n### ðŸ¦œ Full Version\n\nThe full version of BIRD-INTERACT, `bird-interact-full`, is a comprehensive benchmark that includes 600 tasks for PostgreSQL. It covers a wide range of SQL operations and user queries. The full version is coming soon.\n\n### Model Performance Results on BIRD-INTERACT Lite\n\n#### 1. **c-Interact** Performance\n| Rank | Model Name         | Normalized Reward | Level        |\n|:------:|--------------------|:-------:|:--------------:|\n| 1    | o3-mini            | 33.04 | ðŸ† Excellent Chat |\n| 2    | GPT-4o             | 30.33 | ðŸ’Ž Good Chat      |\n| 3    | Gemini-2.0-flash   | 27.41 | ðŸ’Ž Good Chat      |\n| 4    | Claude-3.7-sonnet  | 26.60 | âœ¨ Standard       |\n| 5    | DeepSeek-R1        | 21.74 | âœ¨ Standard       |\n| 6    | Qwen3              | 20.33 | âšª Basic          |\n| 7    | DeepSeek-V3        | 15.85 | âšª Basic          |\n\n#### 2. **a-Interact** Performance\n| Rank | Model Name         | Budget Parameters* | Avg Turns/Task | Avg Cost (USD)/Task | Normalized Reward | Level            |\n|:------:|--------------------|:-------------------:|:----------------:|:---------------------:|:-------------------:|:---------------------:|\n| 1    | Claude-3.7-sonnet  | 6/6 | 15.4 | $0.6668 | 29.19 | ðŸ† Excellent Interaction |\n| 2    | o3-mini            | 6/6 | 7.8 | $0.0754 | 21.07 | ðŸ’Ž Good Interaction      |\n| 3    | DeepSeek-V3        | 6/6 | 15.6 | $0.0629 | 19.19 | ðŸ’Ž Good Interaction      |\n| 4    | Qwen3              | 6/6 | 12.5 | $0.0278 | 18.74 | âœ¨ Standard              |\n| 5    | GPT-4o             | 6/6 | 15.3 | $0.4594 | 18.37 | âœ¨ Standard              |\n| 6    | Gemini-2.0-flash   | 6/6 | 13.2 | $0.0337 | 17.26 | âšª Basic                 |\n| 7    | DeepSeek-R1        | 6/6 | 12.0 | $0.0931 | 17.07 | âšª Basic                 |\n\n> \\* Budget Parameters: Starting Budget/User Patience Budget, measured by our virtual currency *bird-coin*s <img src=\"https://raw.githubusercontent.com/bird-bench/BIRD-Interact/main/bird_interact_agent/materials/bird-coin.png\" style=\"height: 1em; vertical-align: middle;\">. Refer to [bird_interact_agent/README.md](https://raw.githubusercontent.com/bird-bench/BIRD-Interact/main/bird_interact_agent/README.md#task-setting) for more details.\n\n### Interaction-Time Scaling (ITS)\n\nInteraction-Time Scaling (ITS) refers to a model's ability to continuously increase its end performance through multi-turn interactions. When this interactive performance surpasses the model's idealized single-turn performance on a fully specified, unambiguous task, we say it satisfies the **ITS law**. As user patience grows and interaction turns accumulate, performance keeps improving, demonstrating that the model can sustain effective communication over extended dialogue. Currently, we only find claude-3-7-sonnet satisfies the ITS law.\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/bird-bench/BIRD-Interact/main/materials/interaction_scaling_law.png\" \n       style=\"width: 100%; min-width: 100px; display: block; margin: auto; \">\n</p>\n\n## ðŸ“¦ Dataset Details\n\n### Dataset Description\n\n- **Database:** The complete PostgreSQL database can be download from [the Google Drive](https://drive.google.com/file/d/1KABce6czIqL9kMyIX7i-_A0CIQoDnmyW/view). Check the [Quick Eval](#quick-eval) section for more details.\n- **data:** Each data instance contain the following main parts:\n   - `selected_database`: The name of the database.  \n   - `query`: The unambiguous user query.  \n   - `amb_user_query`: The user query with injected ambiguities.\n   - `user_query_ambiguity`: The ambiguities injected into the user query.\n   - `non_critical_ambiguity`: The non-critical ambiguities like order, limit, etc.",
  "origin_sha": "IzclqHo7LOD1iZwsnLH04ZKmHGZNpP/iNkNvMDe0viU=",
  "translate": "# BIRD-INTERACT 1.0 <img src=\"https://raw.githubusercontent.com/bird-bench/BIRD-Interact/main/materials/hku-logo.jpg\" alt=\"HKU Logo\" width=\"50\" style=\"vertical-align:middle;margin-left:10px;\"> <img src=\"https://raw.githubusercontent.com/bird-bench/BIRD-Interact/main/materials/google-cloud-logo.png\" alt=\"Google Cloud Logo\" width=\"50\" style=\"vertical-align:middle;margin-left:10px;\">\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/bird-bench/BIRD-Interact/main/materials/bird_interact.png\" \n       style=\"width: 30%; min-width: 100px; display: block; margin: auto; border-radius: 15px !important;\">\n</p>\n\n\n<div style=\"display: flex; justify-content: center; align-items: center; gap: 10px;\">\n  <a href=\"https://creativecommons.org/licenses/by-sa/4.0/deed.en\">\n    <img src=\"https://img.shields.io/badge/License-CC%20By%20SA%204.0-orange.svg\" alt=\"License\">\n  </a>\n  <a href=\"https://bird-interact.github.io/\">\n    <img src=\"https://img.shields.io/badge/Leaderboard-2025-28a745.svg\" alt=\"Leaderboard\">\n  </a>\n  <a href=\"https://huggingface.co/datasets/birdsql/bird-interact-lite/tree/main\">\n    <img src=\"https://img.shields.io/badge/Dataset-HuggingFace-FFD21E.svg\" alt=\"HuggingFace\">\n  </a>\n  <a href=\"https://www.python.org/downloads/release/python-310/\">\n    <img src=\"https://img.shields.io/badge/Python-3.10+-teal.svg\" alt=\"Python\">\n  </a>\n  <a href=\"https://pypi.org/project/openai/\">\n    <img src=\"https://img.shields.io/badge/OpenAI-1.40+-beige.svg\" alt=\"OpenAI\">\n  </a>\n</div>\n\n## ðŸ§¸ Overzicht\n\nBIRD-INTERACT, een interactieve text-to-SQL benchmark, **herdefinieert Text-to-SQL evaluatie door de lens van dynamische interacties**.\nDe omgeving combineert een hiÃ«rarchische kennisbank, database-documentatie en een functiegestuurde gebruiker-simulator om authentieke zakelijke omgevingen na te bootsen met volledige **CRUD**-operaties.\nHet biedt twee strenge testmodi: (1) passieve **Conversational Interaction** en (2) actieve **Agentic Interaction**, verspreid over 600 geannoteerde taken, waaronder Business Intelligence (BI), CRUD-operaties, enz., elk beschermd door uitvoerbare testcases.\nTypische evaluaties veroorzaken 1.968-5.496 interactierondes tussen model en gebruiker-simulator, terwijl state-of-the-art redeneermodellen momenteel slechts **â‰ˆ24%** en **â‰ˆ18%** van de taken oplossen, wat de uitdaging van de benchmark benadrukt.\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/bird-bench/BIRD-Interact/main/materials/workflow.png\" \n       style=\"width: 100%; min-width: 100px; display: block; margin: auto; \">\n</p>\n\n### âœ… Twee evaluatiemodi\n\nBIRD-INTERACT ondersteunt twee evaluatiemodi zoals hierboven genoemd:\n\n   - **c-Interact**: Conversationele Interactie, een passieve modus waarbij de workflow vastligt. De code en gedetailleerde informatie zijn te vinden in `bird_interact_conv`.\n   - **a-Interact**: Agentische Interactie, een belichaamde actieve modus waarbij de workflow dynamisch is en wordt geleid door modellen. De code en gedetailleerde informatie zijn te vinden in `bird_interact_agent`.\n\n\n### ðŸ£ Lite Versie\n\nWe brengen een lite-versie van BIRD-INTERACT uit, `bird-interact-lite-exp`, met 270 hoogwaardige real-world taken specifiek voor PostgreSQL. Dit is een goed startpunt voor snelle experimentatie.\n\n### ðŸ¦œ Volledige Versie\n\nDe volledige versie van BIRD-INTERACT, `bird-interact-full`, is een uitgebreide benchmark die 600 taken voor PostgreSQL bevat. Het dekt een breed scala aan SQL-operaties en gebruikersvragen. De volledige versie verschijnt binnenkort.\n\n### Modelprestaties op BIRD-INTERACT Lite\n\n#### 1. **c-Interact** Prestaties\n| Rang | Modelnaam          | Genormaliseerde Beloning | Niveau        |\n|:------:|--------------------|:-------:|:--------------:|\n| 1    | o3-mini            | 33.04 | ðŸ† Uitstekende Chat |\n| 2    | GPT-4o             | 30.33 | ðŸ’Ž Goede Chat      |\n| 3    | Gemini-2.0-flash   | 27.41 | ðŸ’Ž Goede Chat      |\n| 4    | Claude-3.7-sonnet  | 26.60 | âœ¨ Standaard       |\n| 5    | DeepSeek-R1        | 21.74 | âœ¨ Standaard       |\n| 6    | Qwen3              | 20.33 | âšª Basis           |\n| 7    | DeepSeek-V3        | 15.85 | âšª Basis           |\n\n#### 2. **a-Interact** Prestaties\n| Rang | Modelnaam          | Budgetparameters* | Gem. Beurten/Taak | Gem. Kosten (USD)/Taak | Genormaliseerde Beloning | Niveau            |\n|:------:|--------------------|:-------------------:|:----------------:|:---------------------:|:-------------------:|:---------------------:|\n| 1    | Claude-3.7-sonnet  | 6/6 | 15.4 | $0.6668 | 29.19 | ðŸ† Uitstekende Interactie |\n| 2    | o3-mini            | 6/6 | 7.8 | $0.0754 | 21.07 | ðŸ’Ž Goede Interactie       |\n| 3    | DeepSeek-V3        | 6/6 | 15.6 | $0.0629 | 19.19 | ðŸ’Ž Goede Interactie       |\n| 4    | Qwen3              | 6/6 | 12.5 | $0.0278 | 18.74 | âœ¨ Standaard              |\n| 5    | GPT-4o             | 6/6 | 15.3 | $0.4594 | 18.37 | âœ¨ Standaard              |\n| 6    | Gemini-2.0-flash   | 6/6 | 13.2 | $0.0337 | 17.26 | âšª Basis                  |\n| 7    | DeepSeek-R1        | 6/6 | 12.0 | $0.0931 | 17.07 | âšª Basis                  |\n\n> \\* Budgetparameters: Startbudget/Gebruiker Geduld Budget, gemeten met onze virtuele valuta *bird-coin*s <img src=\"https://raw.githubusercontent.com/bird-bench/BIRD-Interact/main/bird_interact_agent/materials/bird-coin.png\" style=\"height: 1em; vertical-align: middle;\">. Zie [bird_interact_agent/README.md](https://raw.githubusercontent.com/bird-bench/BIRD-Interact/main/bird_interact_agent/README.md#task-setting) voor meer details.\n\n### Interaction-Time Scaling (ITS)\n\nInteraction-Time Scaling (ITS) verwijst naar het vermogen van een model om zijn uiteindelijke prestatie voortdurend te verhogen via multi-turn interacties. Wanneer deze interactieve prestatie de geÃ¯dealiseerde single-turn prestatie van het model op een volledig gespecificeerde, ondubbelzinnige taak overtreft, zeggen we dat het voldoet aan de **ITS-wet**. Naarmate het gebruikersgeduld toeneemt en het aantal interacties groeit, blijft de prestatie stijgen, wat aantoont dat het model effectieve communicatie over langere dialogen kan volhouden. Momenteel vinden we alleen dat claude-3-7-sonnet voldoet aan de ITS-wet.\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/bird-bench/BIRD-Interact/main/materials/interaction_scaling_law.png\" \n       style=\"width: 100%; min-width: 100px; display: block; margin: auto; \">\n</p>\n\n## ðŸ“¦ Datasetdetails\n\n### Datasetbeschrijving\n\n- **Database:** De volledige PostgreSQL-database kan worden gedownload van [de Google Drive](https://drive.google.com/file/d/1KABce6czIqL9kMyIX7i-_A0CIQoDnmyW/view). Zie de sectie [Quick Eval](#quick-eval) voor meer details.\n- **data:** Elke data-instantie bevat de volgende hoofdonderdelen:\n   - `selected_database`: De naam van de database.  \n   - `query`: De ondubbelzinnige gebruikersvraag.  \n   - `amb_user_query`: De gebruikersvraag met toegevoegde ambiguÃ¯teiten.\n   - `user_query_ambiguity`: De ambiguÃ¯teiten die in de gebruikersvraag zijn geÃ¯njecteerd.\n   - `non_critical_ambiguity`: De niet-kritieke ambiguÃ¯teiten zoals volgorde, limiet, enz.",
  "status": "ok"
}