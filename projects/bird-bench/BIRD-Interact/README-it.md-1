{
  "id": 1,
  "origin": "# BIRD-INTERACT 1.0 <img src=\"https://raw.githubusercontent.com/bird-bench/BIRD-Interact/main/materials/hku-logo.jpg\" alt=\"HKU Logo\" width=\"50\" style=\"vertical-align:middle;margin-left:10px;\"> <img src=\"https://raw.githubusercontent.com/bird-bench/BIRD-Interact/main/materials/google-cloud-logo.png\" alt=\"Google Cloud Logo\" width=\"50\" style=\"vertical-align:middle;margin-left:10px;\">\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/bird-bench/BIRD-Interact/main/materials/bird_interact.png\" \n       style=\"width: 30%; min-width: 100px; display: block; margin: auto; border-radius: 15px !important;\">\n</p>\n\n\n<div style=\"display: flex; justify-content: center; align-items: center; gap: 10px;\">\n  <a href=\"https://creativecommons.org/licenses/by-sa/4.0/deed.en\">\n    <img src=\"https://img.shields.io/badge/License-CC%20By%20SA%204.0-orange.svg\" alt=\"License\">\n  </a>\n  <a href=\"https://bird-interact.github.io/\">\n    <img src=\"https://img.shields.io/badge/Leaderboard-2025-28a745.svg\" alt=\"Leaderboard\">\n  </a>\n  <a href=\"https://huggingface.co/datasets/birdsql/bird-interact-lite/tree/main\">\n    <img src=\"https://img.shields.io/badge/Dataset-HuggingFace-FFD21E.svg\" alt=\"HuggingFace\">\n  </a>\n  <a href=\"https://www.python.org/downloads/release/python-310/\">\n    <img src=\"https://img.shields.io/badge/Python-3.10+-teal.svg\" alt=\"Python\">\n  </a>\n  <a href=\"https://pypi.org/project/openai/\">\n    <img src=\"https://img.shields.io/badge/OpenAI-1.40+-beige.svg\" alt=\"OpenAI\">\n  </a>\n</div>\n\n## 🧸 Overview\n\nBIRD-INTERACT, an interactive text-to-SQL benchmark, **re-imagines Text-to-SQL evaluation via lens of dynamic interactions**.\nThe environment blends a hierarchical knowledge base, database documentation and a function-driven user simulator to recreate authentic enterprise environments across full **CRUD** operations.\nIt offers two rigorous test modes: (1) passive **Conversational Interaction** and (2) active **Agentic Interaction**, spanning 600 annotated tasks including Business Intelligence (BI), CRUD operations and etc., each guarded by executable test cases.\nTypical evaluations trigger 1,968-5,496 interaction turns between model and user simulator, while state-of-the-art reasoning models currently solve only **≈24%** and **≈18%** of tasks, underscoring the benchmark's challenge.\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/bird-bench/BIRD-Interact/main/materials/workflow.png\" \n       style=\"width: 100%; min-width: 100px; display: block; margin: auto; \">\n</p>\n\n### ✅ Two Evaluation Modes\n\nBIRD-INTERACT supports two evaluation modes as mentioned above:\n\n   - **c-Interact**: Conversational Interaction which is a passive mode and the workflow is fixed. The code and detailed information can be found in `bird_interact_conv`.\n   - **a-Interact**: Agentic Interaction which is an embodied active mode where the workflow is dynamic and led by models. The code and detailed information can be found in `bird_interact_agent`.\n\n\n### 🐣 Lite Version\n\nWe are releasing a lite version of BIRD-INTERACT, `bird-interact-lite-exp`, which includes 270 high-quality real-world tasks specifically for PostgreSQL. This is a good starting point for quick experimentation. \n\n### 🦜 Full Version\n\nThe full version of BIRD-INTERACT, `bird-interact-full`, is a comprehensive benchmark that includes 600 tasks for PostgreSQL. It covers a wide range of SQL operations and user queries. The full version is coming soon.\n\n### Model Performance Results on BIRD-INTERACT Lite\n\n#### 1. **c-Interact** Performance\n| Rank | Model Name         | Normalized Reward | Level        |\n|:------:|--------------------|:-------:|:--------------:|\n| 1    | o3-mini            | 33.04 | 🏆 Excellent Chat |\n| 2    | GPT-4o             | 30.33 | 💎 Good Chat      |\n| 3    | Gemini-2.0-flash   | 27.41 | 💎 Good Chat      |\n| 4    | Claude-3.7-sonnet  | 26.60 | ✨ Standard       |\n| 5    | DeepSeek-R1        | 21.74 | ✨ Standard       |\n| 6    | Qwen3              | 20.33 | ⚪ Basic          |\n| 7    | DeepSeek-V3        | 15.85 | ⚪ Basic          |\n\n#### 2. **a-Interact** Performance\n| Rank | Model Name         | Budget Parameters* | Avg Turns/Task | Avg Cost (USD)/Task | Normalized Reward | Level            |\n|:------:|--------------------|:-------------------:|:----------------:|:---------------------:|:-------------------:|:---------------------:|\n| 1    | Claude-3.7-sonnet  | 6/6 | 15.4 | $0.6668 | 29.19 | 🏆 Excellent Interaction |\n| 2    | o3-mini            | 6/6 | 7.8 | $0.0754 | 21.07 | 💎 Good Interaction      |\n| 3    | DeepSeek-V3        | 6/6 | 15.6 | $0.0629 | 19.19 | 💎 Good Interaction      |\n| 4    | Qwen3              | 6/6 | 12.5 | $0.0278 | 18.74 | ✨ Standard              |\n| 5    | GPT-4o             | 6/6 | 15.3 | $0.4594 | 18.37 | ✨ Standard              |\n| 6    | Gemini-2.0-flash   | 6/6 | 13.2 | $0.0337 | 17.26 | ⚪ Basic                 |\n| 7    | DeepSeek-R1        | 6/6 | 12.0 | $0.0931 | 17.07 | ⚪ Basic                 |\n\n> \\* Budget Parameters: Starting Budget/User Patience Budget, measured by our virtual currency *bird-coin*s <img src=\"https://raw.githubusercontent.com/bird-bench/BIRD-Interact/main/bird_interact_agent/materials/bird-coin.png\" style=\"height: 1em; vertical-align: middle;\">. Refer to [bird_interact_agent/README.md](https://raw.githubusercontent.com/bird-bench/BIRD-Interact/main/bird_interact_agent/README.md#task-setting) for more details.\n\n### Interaction-Time Scaling (ITS)\n\nInteraction-Time Scaling (ITS) refers to a model's ability to continuously increase its end performance through multi-turn interactions. When this interactive performance surpasses the model's idealized single-turn performance on a fully specified, unambiguous task, we say it satisfies the **ITS law**. As user patience grows and interaction turns accumulate, performance keeps improving, demonstrating that the model can sustain effective communication over extended dialogue. Currently, we only find claude-3-7-sonnet satisfies the ITS law.\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/bird-bench/BIRD-Interact/main/materials/interaction_scaling_law.png\" \n       style=\"width: 100%; min-width: 100px; display: block; margin: auto; \">\n</p>\n\n## 📦 Dataset Details\n\n### Dataset Description\n\n- **Database:** The complete PostgreSQL database can be download from [the Google Drive](https://drive.google.com/file/d/1KABce6czIqL9kMyIX7i-_A0CIQoDnmyW/view). Check the [Quick Eval](#quick-eval) section for more details.\n- **data:** Each data instance contain the following main parts:\n   - `selected_database`: The name of the database.  \n   - `query`: The unambiguous user query.  \n   - `amb_user_query`: The user query with injected ambiguities.\n   - `user_query_ambiguity`: The ambiguities injected into the user query.\n   - `non_critical_ambiguity`: The non-critical ambiguities like order, limit, etc.",
  "origin_sha": "IzclqHo7LOD1iZwsnLH04ZKmHGZNpP/iNkNvMDe0viU=",
  "translate": "# BIRD-INTERACT 1.0 <img src=\"https://raw.githubusercontent.com/bird-bench/BIRD-Interact/main/materials/hku-logo.jpg\" alt=\"HKU Logo\" width=\"50\" style=\"vertical-align:middle;margin-left:10px;\"> <img src=\"https://raw.githubusercontent.com/bird-bench/BIRD-Interact/main/materials/google-cloud-logo.png\" alt=\"Google Cloud Logo\" width=\"50\" style=\"vertical-align:middle;margin-left:10px;\">\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/bird-bench/BIRD-Interact/main/materials/bird_interact.png\" \n       style=\"width: 30%; min-width: 100px; display: block; margin: auto; border-radius: 15px !important;\">\n</p>\n\n\n<div style=\"display: flex; justify-content: center; align-items: center; gap: 10px;\">\n  <a href=\"https://creativecommons.org/licenses/by-sa/4.0/deed.en\">\n    <img src=\"https://img.shields.io/badge/License-CC%20By%20SA%204.0-orange.svg\" alt=\"License\">\n  </a>\n  <a href=\"https://bird-interact.github.io/\">\n    <img src=\"https://img.shields.io/badge/Leaderboard-2025-28a745.svg\" alt=\"Leaderboard\">\n  </a>\n  <a href=\"https://huggingface.co/datasets/birdsql/bird-interact-lite/tree/main\">\n    <img src=\"https://img.shields.io/badge/Dataset-HuggingFace-FFD21E.svg\" alt=\"HuggingFace\">\n  </a>\n  <a href=\"https://www.python.org/downloads/release/python-310/\">\n    <img src=\"https://img.shields.io/badge/Python-3.10+-teal.svg\" alt=\"Python\">\n  </a>\n  <a href=\"https://pypi.org/project/openai/\">\n    <img src=\"https://img.shields.io/badge/OpenAI-1.40+-beige.svg\" alt=\"OpenAI\">\n  </a>\n</div>\n\n## 🧸 Panoramica\n\nBIRD-INTERACT, un benchmark interattivo text-to-SQL, **re-immagina la valutazione Text-to-SQL attraverso la lente delle interazioni dinamiche**.\nL'ambiente fonde una base di conoscenza gerarchica, documentazione del database e un simulatore utente guidato da funzioni per ricreare ambienti aziendali autentici attraverso tutte le operazioni **CRUD**.\nOffre due rigorose modalità di test: (1) **Interazione Conversazionale** passiva e (2) **Interazione Agentica** attiva, coprendo 600 task annotati tra cui Business Intelligence (BI), operazioni CRUD ecc., ciascuno protetto da casi di test eseguibili.\nLe valutazioni tipiche attivano 1.968-5.496 turni di interazione tra modello e simulatore utente, mentre i modelli di ragionamento allo stato dell’arte risolvono attualmente solo **≈24%** e **≈18%** dei task, evidenziando la sfida del benchmark.\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/bird-bench/BIRD-Interact/main/materials/workflow.png\" \n       style=\"width: 100%; min-width: 100px; display: block; margin: auto; \">\n</p>\n\n### ✅ Due modalità di valutazione\n\nBIRD-INTERACT supporta due modalità di valutazione come sopra menzionato:\n\n   - **c-Interact**: Interazione Conversazionale, che è una modalità passiva e il workflow è fisso. Il codice e le informazioni dettagliate sono disponibili in `bird_interact_conv`.\n   - **a-Interact**: Interazione Agentica, una modalità attiva incarnata in cui il workflow è dinamico e guidato dai modelli. Il codice e le informazioni dettagliate sono disponibili in `bird_interact_agent`.\n\n\n### 🐣 Versione Lite\n\nStiamo rilasciando una versione lite di BIRD-INTERACT, `bird-interact-lite-exp`, che include 270 task reali di alta qualità specifici per PostgreSQL. È un buon punto di partenza per una sperimentazione rapida.\n\n### 🦜 Versione Completa\n\nLa versione completa di BIRD-INTERACT, `bird-interact-full`, è un benchmark completo che include 600 task per PostgreSQL. Copre un'ampia gamma di operazioni SQL e query utente. La versione completa sarà disponibile a breve.\n\n### Risultati delle prestazioni dei modelli su BIRD-INTERACT Lite\n\n#### 1. Prestazioni **c-Interact**\n| Rank | Nome Modello       | Ricompensa Normalizzata | Livello        |\n|:------:|--------------------|:-------:|:--------------:|\n| 1    | o3-mini            | 33.04 | 🏆 Chat Eccellente |\n| 2    | GPT-4o             | 30.33 | 💎 Chat Buona      |\n| 3    | Gemini-2.0-flash   | 27.41 | 💎 Chat Buona      |\n| 4    | Claude-3.7-sonnet  | 26.60 | ✨ Standard        |\n| 5    | DeepSeek-R1        | 21.74 | ✨ Standard        |\n| 6    | Qwen3              | 20.33 | ⚪ Base            |\n| 7    | DeepSeek-V3        | 15.85 | ⚪ Base            |\n\n#### 2. Prestazioni **a-Interact**\n| Rank | Nome Modello       | Parametri di Budget* | Media Turni/Task | Costo Medio (USD)/Task | Ricompensa Normalizzata | Livello                |\n|:------:|--------------------|:-------------------:|:----------------:|:---------------------:|:----------------------:|:-------------------------:|\n| 1    | Claude-3.7-sonnet  | 6/6 | 15.4 | $0.6668 | 29.19 | 🏆 Interazione Eccellente |\n| 2    | o3-mini            | 6/6 | 7.8 | $0.0754 | 21.07 | 💎 Buona Interazione      |\n| 3    | DeepSeek-V3        | 6/6 | 15.6 | $0.0629 | 19.19 | 💎 Buona Interazione      |\n| 4    | Qwen3              | 6/6 | 12.5 | $0.0278 | 18.74 | ✨ Standard               |\n| 5    | GPT-4o             | 6/6 | 15.3 | $0.4594 | 18.37 | ✨ Standard               |\n| 6    | Gemini-2.0-flash   | 6/6 | 13.2 | $0.0337 | 17.26 | ⚪ Base                   |\n| 7    | DeepSeek-R1        | 6/6 | 12.0 | $0.0931 | 17.07 | ⚪ Base                   |\n\n> \\* Parametri di Budget: Budget Iniziale/Budget di Pazienza Utente, misurato tramite la nostra valuta virtuale *bird-coin*s <img src=\"https://raw.githubusercontent.com/bird-bench/BIRD-Interact/main/bird_interact_agent/materials/bird-coin.png\" style=\"height: 1em; vertical-align: middle;\">. Fare riferimento a [bird_interact_agent/README.md](https://raw.githubusercontent.com/bird-bench/BIRD-Interact/main/bird_interact_agent/README.md#task-setting) per maggiori dettagli.\n\n### Interaction-Time Scaling (ITS)\n\nL’Interaction-Time Scaling (ITS) si riferisce alla capacità di un modello di aumentare continuamente le sue prestazioni finali tramite interazioni multi-turno. Quando questa prestazione interattiva supera la prestazione ideale del modello in una singola interazione su un task completamente specificato e non ambiguo, si dice che soddisfa la **legge ITS**. All’aumentare della pazienza dell’utente e dei turni di interazione, le prestazioni migliorano costantemente, dimostrando che il modello può sostenere una comunicazione efficace in dialoghi prolungati. Attualmente, solo claude-3-7-sonnet soddisfa la legge ITS.\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/bird-bench/BIRD-Interact/main/materials/interaction_scaling_law.png\" \n       style=\"width: 100%; min-width: 100px; display: block; margin: auto; \">\n</p>\n\n## 📦 Dettagli del Dataset\n\n### Descrizione del Dataset\n\n- **Database:** Il database PostgreSQL completo può essere scaricato da [Google Drive](https://drive.google.com/file/d/1KABce6czIqL9kMyIX7i-_A0CIQoDnmyW/view). Consulta la sezione [Quick Eval](#quick-eval) per maggiori dettagli.\n- **data:** Ogni istanza dati contiene le seguenti parti principali:\n   - `selected_database`: Il nome del database.  \n   - `query`: La query utente non ambigua.  \n   - `amb_user_query`: La query utente con ambiguità inserite.\n   - `user_query_ambiguity`: Le ambiguità inserite nella query utente.\n   - `non_critical_ambiguity`: Le ambiguità non critiche come ordine, limite, ecc.",
  "status": "ok"
}