{
  "id": 1,
  "origin": "# BIRD-INTERACT 1.0 <img src=\"https://raw.githubusercontent.com/bird-bench/BIRD-Interact/main/materials/hku-logo.jpg\" alt=\"HKU Logo\" width=\"50\" style=\"vertical-align:middle;margin-left:10px;\"> <img src=\"https://raw.githubusercontent.com/bird-bench/BIRD-Interact/main/materials/google-cloud-logo.png\" alt=\"Google Cloud Logo\" width=\"50\" style=\"vertical-align:middle;margin-left:10px;\">\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/bird-bench/BIRD-Interact/main/materials/bird_interact.png\" \n       style=\"width: 30%; min-width: 100px; display: block; margin: auto; border-radius: 15px !important;\">\n</p>\n\n\n<div style=\"display: flex; justify-content: center; align-items: center; gap: 10px;\">\n  <a href=\"https://creativecommons.org/licenses/by-sa/4.0/deed.en\">\n    <img src=\"https://img.shields.io/badge/License-CC%20By%20SA%204.0-orange.svg\" alt=\"License\">\n  </a>\n  <a href=\"https://bird-interact.github.io/\">\n    <img src=\"https://img.shields.io/badge/Leaderboard-2025-28a745.svg\" alt=\"Leaderboard\">\n  </a>\n  <a href=\"https://huggingface.co/datasets/birdsql/bird-interact-lite/tree/main\">\n    <img src=\"https://img.shields.io/badge/Dataset-HuggingFace-FFD21E.svg\" alt=\"HuggingFace\">\n  </a>\n  <a href=\"https://www.python.org/downloads/release/python-310/\">\n    <img src=\"https://img.shields.io/badge/Python-3.10+-teal.svg\" alt=\"Python\">\n  </a>\n  <a href=\"https://pypi.org/project/openai/\">\n    <img src=\"https://img.shields.io/badge/OpenAI-1.40+-beige.svg\" alt=\"OpenAI\">\n  </a>\n</div>\n\n## 🧸 Overview\n\nBIRD-INTERACT, an interactive text-to-SQL benchmark, **re-imagines Text-to-SQL evaluation via lens of dynamic interactions**.\nThe environment blends a hierarchical knowledge base, database documentation and a function-driven user simulator to recreate authentic enterprise environments across full **CRUD** operations.\nIt offers two rigorous test modes: (1) passive **Conversational Interaction** and (2) active **Agentic Interaction**, spanning 600 annotated tasks including Business Intelligence (BI), CRUD operations and etc., each guarded by executable test cases.\nTypical evaluations trigger 1,968-5,496 interaction turns between model and user simulator, while state-of-the-art reasoning models currently solve only **≈24%** and **≈18%** of tasks, underscoring the benchmark's challenge.\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/bird-bench/BIRD-Interact/main/materials/workflow.png\" \n       style=\"width: 100%; min-width: 100px; display: block; margin: auto; \">\n</p>\n\n### ✅ Two Evaluation Modes\n\nBIRD-INTERACT supports two evaluation modes as mentioned above:\n\n   - **c-Interact**: Conversational Interaction which is a passive mode and the workflow is fixed. The code and detailed information can be found in `bird_interact_conv`.\n   - **a-Interact**: Agentic Interaction which is an embodied active mode where the workflow is dynamic and led by models. The code and detailed information can be found in `bird_interact_agent`.\n\n\n### 🐣 Lite Version\n\nWe are releasing a lite version of BIRD-INTERACT, `bird-interact-lite-exp`, which includes 270 high-quality real-world tasks specifically for PostgreSQL. This is a good starting point for quick experimentation. \n\n### 🦜 Full Version\n\nThe full version of BIRD-INTERACT, `bird-interact-full`, is a comprehensive benchmark that includes 600 tasks for PostgreSQL. It covers a wide range of SQL operations and user queries. The full version is coming soon.\n\n### Model Performance Results on BIRD-INTERACT Lite\n\n#### 1. **c-Interact** Performance\n| Rank | Model Name         | Normalized Reward | Level        |\n|:------:|--------------------|:-------:|:--------------:|\n| 1    | o3-mini            | 33.04 | 🏆 Excellent Chat |\n| 2    | GPT-4o             | 30.33 | 💎 Good Chat      |\n| 3    | Gemini-2.0-flash   | 27.41 | 💎 Good Chat      |\n| 4    | Claude-3.7-sonnet  | 26.60 | ✨ Standard       |\n| 5    | DeepSeek-R1        | 21.74 | ✨ Standard       |\n| 6    | Qwen3              | 20.33 | ⚪ Basic          |\n| 7    | DeepSeek-V3        | 15.85 | ⚪ Basic          |\n\n#### 2. **a-Interact** Performance\n| Rank | Model Name         | Budget Parameters* | Avg Turns/Task | Avg Cost (USD)/Task | Normalized Reward | Level            |\n|:------:|--------------------|:-------------------:|:----------------:|:---------------------:|:-------------------:|:---------------------:|\n| 1    | Claude-3.7-sonnet  | 6/6 | 15.4 | $0.6668 | 29.19 | 🏆 Excellent Interaction |\n| 2    | o3-mini            | 6/6 | 7.8 | $0.0754 | 21.07 | 💎 Good Interaction      |\n| 3    | DeepSeek-V3        | 6/6 | 15.6 | $0.0629 | 19.19 | 💎 Good Interaction      |\n| 4    | Qwen3              | 6/6 | 12.5 | $0.0278 | 18.74 | ✨ Standard              |\n| 5    | GPT-4o             | 6/6 | 15.3 | $0.4594 | 18.37 | ✨ Standard              |\n| 6    | Gemini-2.0-flash   | 6/6 | 13.2 | $0.0337 | 17.26 | ⚪ Basic                 |\n| 7    | DeepSeek-R1        | 6/6 | 12.0 | $0.0931 | 17.07 | ⚪ Basic                 |\n\n> \\* Budget Parameters: Starting Budget/User Patience Budget, measured by our virtual currency *bird-coin*s <img src=\"https://raw.githubusercontent.com/bird-bench/BIRD-Interact/main/bird_interact_agent/materials/bird-coin.png\" style=\"height: 1em; vertical-align: middle;\">. Refer to [bird_interact_agent/README.md](https://raw.githubusercontent.com/bird-bench/BIRD-Interact/main/bird_interact_agent/README.md#task-setting) for more details.\n\n### Interaction-Time Scaling (ITS)\n\nInteraction-Time Scaling (ITS) refers to a model's ability to continuously increase its end performance through multi-turn interactions. When this interactive performance surpasses the model's idealized single-turn performance on a fully specified, unambiguous task, we say it satisfies the **ITS law**. As user patience grows and interaction turns accumulate, performance keeps improving, demonstrating that the model can sustain effective communication over extended dialogue. Currently, we only find claude-3-7-sonnet satisfies the ITS law.\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/bird-bench/BIRD-Interact/main/materials/interaction_scaling_law.png\" \n       style=\"width: 100%; min-width: 100px; display: block; margin: auto; \">\n</p>\n\n## 📦 Dataset Details\n\n### Dataset Description\n\n- **Database:** The complete PostgreSQL database can be download from [the Google Drive](https://drive.google.com/file/d/1KABce6czIqL9kMyIX7i-_A0CIQoDnmyW/view). Check the [Quick Eval](#quick-eval) section for more details.\n- **data:** Each data instance contain the following main parts:\n   - `selected_database`: The name of the database.  \n   - `query`: The unambiguous user query.  \n   - `amb_user_query`: The user query with injected ambiguities.\n   - `user_query_ambiguity`: The ambiguities injected into the user query.\n   - `non_critical_ambiguity`: The non-critical ambiguities like order, limit, etc.",
  "origin_sha": "IzclqHo7LOD1iZwsnLH04ZKmHGZNpP/iNkNvMDe0viU=",
  "translate": "# BIRD-INTERACT 1.0 <img src=\"https://raw.githubusercontent.com/bird-bench/BIRD-Interact/main/materials/hku-logo.jpg\" alt=\"HKU Logo\" width=\"50\" style=\"vertical-align:middle;margin-left:10px;\"> <img src=\"https://raw.githubusercontent.com/bird-bench/BIRD-Interact/main/materials/google-cloud-logo.png\" alt=\"Google Cloud Logo\" width=\"50\" style=\"vertical-align:middle;margin-left:10px;\">\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/bird-bench/BIRD-Interact/main/materials/bird_interact.png\" \n       style=\"width: 30%; min-width: 100px; display: block; margin: auto; border-radius: 15px !important;\">\n</p>\n\n\n<div style=\"display: flex; justify-content: center; align-items: center; gap: 10px;\">\n  <a href=\"https://creativecommons.org/licenses/by-sa/4.0/deed.en\">\n    <img src=\"https://img.shields.io/badge/License-CC%20By%20SA%204.0-orange.svg\" alt=\"License\">\n  </a>\n  <a href=\"https://bird-interact.github.io/\">\n    <img src=\"https://img.shields.io/badge/Leaderboard-2025-28a745.svg\" alt=\"Leaderboard\">\n  </a>\n  <a href=\"https://huggingface.co/datasets/birdsql/bird-interact-lite/tree/main\">\n    <img src=\"https://img.shields.io/badge/Dataset-HuggingFace-FFD21E.svg\" alt=\"HuggingFace\">\n  </a>\n  <a href=\"https://www.python.org/downloads/release/python-310/\">\n    <img src=\"https://img.shields.io/badge/Python-3.10+-teal.svg\" alt=\"Python\">\n  </a>\n  <a href=\"https://pypi.org/project/openai/\">\n    <img src=\"https://img.shields.io/badge/OpenAI-1.40+-beige.svg\" alt=\"OpenAI\">\n  </a>\n</div>\n\n## 🧸 Tổng Quan\n\nBIRD-INTERACT, một bộ chuẩn đánh giá chuyển đổi văn bản sang SQL mang tính tương tác, **tái định hình việc đánh giá Text-to-SQL qua lăng kính của các tương tác động**.\nMôi trường này kết hợp một cơ sở tri thức phân cấp, tài liệu cơ sở dữ liệu và một trình mô phỏng người dùng dựa trên chức năng để tái tạo môi trường doanh nghiệp thực tế trên toàn bộ các thao tác **CRUD**.\nNó cung cấp hai chế độ kiểm thử nghiêm ngặt: (1) **Tương tác Hội thoại** (thụ động) và (2) **Tương tác Đại lý** (chủ động), bao gồm 600 tác vụ được chú thích như Trí tuệ Doanh nghiệp (BI), thao tác CRUD, v.v., mỗi tác vụ đều có các ca kiểm thử thực thi được.\nCác lần đánh giá điển hình kích hoạt từ 1.968-5.496 lượt tương tác giữa mô hình và trình mô phỏng người dùng, trong khi các mô hình lý luận tiên tiến hiện chỉ giải quyết được **≈24%** và **≈18%** số tác vụ, nhấn mạnh mức độ thử thách của bộ chuẩn này.\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/bird-bench/BIRD-Interact/main/materials/workflow.png\" \n       style=\"width: 100%; min-width: 100px; display: block; margin: auto; \">\n</p>\n\n### ✅ Hai Chế Độ Đánh Giá\n\nBIRD-INTERACT hỗ trợ hai chế độ đánh giá như đã đề cập ở trên:\n\n   - **c-Interact**: Tương tác hội thoại, là chế độ thụ động với luồng công việc cố định. Mã nguồn và thông tin chi tiết có thể được tìm thấy trong `bird_interact_conv`.\n   - **a-Interact**: Tương tác đại lý, là chế độ chủ động nhập vai trong đó luồng công việc mang tính động và được dẫn dắt bởi các mô hình. Mã nguồn và thông tin chi tiết có thể được tìm thấy trong `bird_interact_agent`.\n\n\n### 🐣 Phiên Bản Nhẹ\n\nChúng tôi phát hành phiên bản nhẹ của BIRD-INTERACT, `bird-interact-lite-exp`, bao gồm 270 tác vụ thực tế chất lượng cao dành riêng cho PostgreSQL. Đây là điểm khởi đầu tốt cho các thử nghiệm nhanh.\n\n### 🦜 Phiên Bản Đầy Đủ\n\nPhiên bản đầy đủ của BIRD-INTERACT, `bird-interact-full`, là bộ chuẩn toàn diện bao gồm 600 tác vụ dành cho PostgreSQL. Nó bao phủ nhiều thao tác SQL và truy vấn người dùng khác nhau. Phiên bản đầy đủ sẽ sớm ra mắt.\n\n### Kết Quả Hiệu Năng Mô Hình trên BIRD-INTERACT Lite\n\n#### 1. Hiệu Năng **c-Interact**\n| Hạng | Tên Mô Hình        | Điểm Thưởng Chuẩn Hóa | Cấp Độ             |\n|:------:|--------------------|:-------:|:--------------:|\n| 1    | o3-mini            | 33.04 | 🏆 Chat Xuất Sắc |\n| 2    | GPT-4o             | 30.33 | 💎 Chat Tốt      |\n| 3    | Gemini-2.0-flash   | 27.41 | 💎 Chat Tốt      |\n| 4    | Claude-3.7-sonnet  | 26.60 | ✨ Tiêu Chuẩn     |\n| 5    | DeepSeek-R1        | 21.74 | ✨ Tiêu Chuẩn     |\n| 6    | Qwen3              | 20.33 | ⚪ Cơ Bản         |\n| 7    | DeepSeek-V3        | 15.85 | ⚪ Cơ Bản         |\n\n#### 2. Hiệu Năng **a-Interact**\n| Hạng | Tên Mô Hình        | Tham Số Ngân Sách* | Số Lượt/ Tác Vụ | Chi Phí TB (USD)/Tác Vụ | Điểm Thưởng Chuẩn Hóa | Cấp Độ                |\n|:------:|--------------------|:-------------------:|:----------------:|:---------------------:|:-------------------:|:---------------------:|\n| 1    | Claude-3.7-sonnet  | 6/6 | 15.4 | $0.6668 | 29.19 | 🏆 Tương Tác Xuất Sắc     |\n| 2    | o3-mini            | 6/6 | 7.8  | $0.0754 | 21.07 | 💎 Tương Tác Tốt          |\n| 3    | DeepSeek-V3        | 6/6 | 15.6 | $0.0629 | 19.19 | 💎 Tương Tác Tốt          |\n| 4    | Qwen3              | 6/6 | 12.5 | $0.0278 | 18.74 | ✨ Tiêu Chuẩn             |\n| 5    | GPT-4o             | 6/6 | 15.3 | $0.4594 | 18.37 | ✨ Tiêu Chuẩn             |\n| 6    | Gemini-2.0-flash   | 6/6 | 13.2 | $0.0337 | 17.26 | ⚪ Cơ Bản                 |\n| 7    | DeepSeek-R1        | 6/6 | 12.0 | $0.0931 | 17.07 | ⚪ Cơ Bản                 |\n\n> \\* Tham Số Ngân Sách: Ngân sách khởi đầu/Ngân sách kiên nhẫn của người dùng, được đo bằng tiền ảo *bird-coin*s <img src=\"https://raw.githubusercontent.com/bird-bench/BIRD-Interact/main/bird_interact_agent/materials/bird-coin.png\" style=\"height: 1em; vertical-align: middle;\">. Tham khảo [bird_interact_agent/README.md](https://raw.githubusercontent.com/bird-bench/BIRD-Interact/main/bird_interact_agent/README.md#task-setting) để biết thêm chi tiết.\n\n### Tăng Quy Mô Theo Thời Gian Tương Tác (ITS)\n\nTăng Quy Mô Theo Thời Gian Tương Tác (ITS) đề cập đến khả năng của một mô hình liên tục nâng cao hiệu quả cuối cùng thông qua các lượt tương tác đa chiều. Khi hiệu suất tương tác này vượt qua hiệu suất lý tưởng một lượt của mô hình trên tác vụ đã được chỉ định đầy đủ, không mơ hồ, ta nói rằng mô hình đáp ứng **định luật ITS**. Khi sự kiên nhẫn của người dùng tăng lên và số lượt tương tác tích lũy lại, hiệu suất tiếp tục được cải thiện, cho thấy mô hình có thể duy trì giao tiếp hiệu quả qua các cuộc hội thoại kéo dài. Hiện tại, chỉ có claude-3-7-sonnet đáp ứng định luật ITS.\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/bird-bench/BIRD-Interact/main/materials/interaction_scaling_law.png\" \n       style=\"width: 100%; min-width: 100px; display: block; margin: auto; \">\n</p>\n\n## 📦 Chi Tiết Bộ Dữ Liệu\n\n### Mô Tả Bộ Dữ Liệu\n\n- **Cơ sở dữ liệu:** Toàn bộ cơ sở dữ liệu PostgreSQL có thể được tải xuống từ [Google Drive](https://drive.google.com/file/d/1KABce6czIqL9kMyIX7i-_A0CIQoDnmyW/view). Xem thêm phần [Đánh Giá Nhanh](#quick-eval) để biết chi tiết.\n- **data:** Mỗi mẫu dữ liệu bao gồm các phần chính sau:\n   - `selected_database`: Tên của cơ sở dữ liệu.  \n   - `query`: Truy vấn người dùng không mơ hồ.  \n   - `amb_user_query`: Truy vấn người dùng đã được thêm yếu tố mơ hồ.\n   - `user_query_ambiguity`: Các yếu tố mơ hồ được thêm vào truy vấn người dùng.\n   - `non_critical_ambiguity`: Các yếu tố mơ hồ không quan trọng như thứ tự, giới hạn, v.v.",
  "status": "ok"
}