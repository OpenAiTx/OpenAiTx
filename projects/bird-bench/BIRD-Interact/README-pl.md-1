{
  "id": 1,
  "origin": "# BIRD-INTERACT 1.0 <img src=\"https://raw.githubusercontent.com/bird-bench/BIRD-Interact/main/materials/hku-logo.jpg\" alt=\"HKU Logo\" width=\"50\" style=\"vertical-align:middle;margin-left:10px;\"> <img src=\"https://raw.githubusercontent.com/bird-bench/BIRD-Interact/main/materials/google-cloud-logo.png\" alt=\"Google Cloud Logo\" width=\"50\" style=\"vertical-align:middle;margin-left:10px;\">\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/bird-bench/BIRD-Interact/main/materials/bird_interact.png\" \n       style=\"width: 30%; min-width: 100px; display: block; margin: auto; border-radius: 15px !important;\">\n</p>\n\n\n<div style=\"display: flex; justify-content: center; align-items: center; gap: 10px;\">\n  <a href=\"https://creativecommons.org/licenses/by-sa/4.0/deed.en\">\n    <img src=\"https://img.shields.io/badge/License-CC%20By%20SA%204.0-orange.svg\" alt=\"License\">\n  </a>\n  <a href=\"https://bird-interact.github.io/\">\n    <img src=\"https://img.shields.io/badge/Leaderboard-2025-28a745.svg\" alt=\"Leaderboard\">\n  </a>\n  <a href=\"https://huggingface.co/datasets/birdsql/bird-interact-lite/tree/main\">\n    <img src=\"https://img.shields.io/badge/Dataset-HuggingFace-FFD21E.svg\" alt=\"HuggingFace\">\n  </a>\n  <a href=\"https://www.python.org/downloads/release/python-310/\">\n    <img src=\"https://img.shields.io/badge/Python-3.10+-teal.svg\" alt=\"Python\">\n  </a>\n  <a href=\"https://pypi.org/project/openai/\">\n    <img src=\"https://img.shields.io/badge/OpenAI-1.40+-beige.svg\" alt=\"OpenAI\">\n  </a>\n</div>\n\n## ğŸ§¸ Overview\n\nBIRD-INTERACT, an interactive text-to-SQL benchmark, **re-imagines Text-to-SQL evaluation via lens of dynamic interactions**.\nThe environment blends a hierarchical knowledge base, database documentation and a function-driven user simulator to recreate authentic enterprise environments across full **CRUD** operations.\nIt offers two rigorous test modes: (1) passive **Conversational Interaction** and (2) active **Agentic Interaction**, spanning 600 annotated tasks including Business Intelligence (BI), CRUD operations and etc., each guarded by executable test cases.\nTypical evaluations trigger 1,968-5,496 interaction turns between model and user simulator, while state-of-the-art reasoning models currently solve only **â‰ˆ24%** and **â‰ˆ18%** of tasks, underscoring the benchmark's challenge.\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/bird-bench/BIRD-Interact/main/materials/workflow.png\" \n       style=\"width: 100%; min-width: 100px; display: block; margin: auto; \">\n</p>\n\n### âœ… Two Evaluation Modes\n\nBIRD-INTERACT supports two evaluation modes as mentioned above:\n\n   - **c-Interact**: Conversational Interaction which is a passive mode and the workflow is fixed. The code and detailed information can be found in `bird_interact_conv`.\n   - **a-Interact**: Agentic Interaction which is an embodied active mode where the workflow is dynamic and led by models. The code and detailed information can be found in `bird_interact_agent`.\n\n\n### ğŸ£ Lite Version\n\nWe are releasing a lite version of BIRD-INTERACT, `bird-interact-lite-exp`, which includes 270 high-quality real-world tasks specifically for PostgreSQL. This is a good starting point for quick experimentation. \n\n### ğŸ¦œ Full Version\n\nThe full version of BIRD-INTERACT, `bird-interact-full`, is a comprehensive benchmark that includes 600 tasks for PostgreSQL. It covers a wide range of SQL operations and user queries. The full version is coming soon.\n\n### Model Performance Results on BIRD-INTERACT Lite\n\n#### 1. **c-Interact** Performance\n| Rank | Model Name         | Normalized Reward | Level        |\n|:------:|--------------------|:-------:|:--------------:|\n| 1    | o3-mini            | 33.04 | ğŸ† Excellent Chat |\n| 2    | GPT-4o             | 30.33 | ğŸ’ Good Chat      |\n| 3    | Gemini-2.0-flash   | 27.41 | ğŸ’ Good Chat      |\n| 4    | Claude-3.7-sonnet  | 26.60 | âœ¨ Standard       |\n| 5    | DeepSeek-R1        | 21.74 | âœ¨ Standard       |\n| 6    | Qwen3              | 20.33 | âšª Basic          |\n| 7    | DeepSeek-V3        | 15.85 | âšª Basic          |\n\n#### 2. **a-Interact** Performance\n| Rank | Model Name         | Budget Parameters* | Avg Turns/Task | Avg Cost (USD)/Task | Normalized Reward | Level            |\n|:------:|--------------------|:-------------------:|:----------------:|:---------------------:|:-------------------:|:---------------------:|\n| 1    | Claude-3.7-sonnet  | 6/6 | 15.4 | $0.6668 | 29.19 | ğŸ† Excellent Interaction |\n| 2    | o3-mini            | 6/6 | 7.8 | $0.0754 | 21.07 | ğŸ’ Good Interaction      |\n| 3    | DeepSeek-V3        | 6/6 | 15.6 | $0.0629 | 19.19 | ğŸ’ Good Interaction      |\n| 4    | Qwen3              | 6/6 | 12.5 | $0.0278 | 18.74 | âœ¨ Standard              |\n| 5    | GPT-4o             | 6/6 | 15.3 | $0.4594 | 18.37 | âœ¨ Standard              |\n| 6    | Gemini-2.0-flash   | 6/6 | 13.2 | $0.0337 | 17.26 | âšª Basic                 |\n| 7    | DeepSeek-R1        | 6/6 | 12.0 | $0.0931 | 17.07 | âšª Basic                 |\n\n> \\* Budget Parameters: Starting Budget/User Patience Budget, measured by our virtual currency *bird-coin*s <img src=\"https://raw.githubusercontent.com/bird-bench/BIRD-Interact/main/bird_interact_agent/materials/bird-coin.png\" style=\"height: 1em; vertical-align: middle;\">. Refer to [bird_interact_agent/README.md](https://raw.githubusercontent.com/bird-bench/BIRD-Interact/main/bird_interact_agent/README.md#task-setting) for more details.\n\n### Interaction-Time Scaling (ITS)\n\nInteraction-Time Scaling (ITS) refers to a model's ability to continuously increase its end performance through multi-turn interactions. When this interactive performance surpasses the model's idealized single-turn performance on a fully specified, unambiguous task, we say it satisfies the **ITS law**. As user patience grows and interaction turns accumulate, performance keeps improving, demonstrating that the model can sustain effective communication over extended dialogue. Currently, we only find claude-3-7-sonnet satisfies the ITS law.\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/bird-bench/BIRD-Interact/main/materials/interaction_scaling_law.png\" \n       style=\"width: 100%; min-width: 100px; display: block; margin: auto; \">\n</p>\n\n## ğŸ“¦ Dataset Details\n\n### Dataset Description\n\n- **Database:** The complete PostgreSQL database can be download from [the Google Drive](https://drive.google.com/file/d/1KABce6czIqL9kMyIX7i-_A0CIQoDnmyW/view). Check the [Quick Eval](#quick-eval) section for more details.\n- **data:** Each data instance contain the following main parts:\n   - `selected_database`: The name of the database.  \n   - `query`: The unambiguous user query.  \n   - `amb_user_query`: The user query with injected ambiguities.\n   - `user_query_ambiguity`: The ambiguities injected into the user query.\n   - `non_critical_ambiguity`: The non-critical ambiguities like order, limit, etc.",
  "origin_sha": "IzclqHo7LOD1iZwsnLH04ZKmHGZNpP/iNkNvMDe0viU=",
  "translate": "# BIRD-INTERACT 1.0 <img src=\"https://raw.githubusercontent.com/bird-bench/BIRD-Interact/main/materials/hku-logo.jpg\" alt=\"HKU Logo\" width=\"50\" style=\"vertical-align:middle;margin-left:10px;\"> <img src=\"https://raw.githubusercontent.com/bird-bench/BIRD-Interact/main/materials/google-cloud-logo.png\" alt=\"Google Cloud Logo\" width=\"50\" style=\"vertical-align:middle;margin-left:10px;\">\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/bird-bench/BIRD-Interact/main/materials/bird_interact.png\" \n       style=\"width: 30%; min-width: 100px; display: block; margin: auto; border-radius: 15px !important;\">\n</p>\n\n\n<div style=\"display: flex; justify-content: center; align-items: center; gap: 10px;\">\n  <a href=\"https://creativecommons.org/licenses/by-sa/4.0/deed.en\">\n    <img src=\"https://img.shields.io/badge/License-CC%20By%20SA%204.0-orange.svg\" alt=\"License\">\n  </a>\n  <a href=\"https://bird-interact.github.io/\">\n    <img src=\"https://img.shields.io/badge/Leaderboard-2025-28a745.svg\" alt=\"Leaderboard\">\n  </a>\n  <a href=\"https://huggingface.co/datasets/birdsql/bird-interact-lite/tree/main\">\n    <img src=\"https://img.shields.io/badge/Dataset-HuggingFace-FFD21E.svg\" alt=\"HuggingFace\">\n  </a>\n  <a href=\"https://www.python.org/downloads/release/python-310/\">\n    <img src=\"https://img.shields.io/badge/Python-3.10+-teal.svg\" alt=\"Python\">\n  </a>\n  <a href=\"https://pypi.org/project/openai/\">\n    <img src=\"https://img.shields.io/badge/OpenAI-1.40+-beige.svg\" alt=\"OpenAI\">\n  </a>\n</div>\n\n## ğŸ§¸ PrzeglÄ…d\n\nBIRD-INTERACT, interaktywny benchmark text-to-SQL, **na nowo definiuje ewaluacjÄ™ Text-to-SQL poprzez pryzmat dynamicznych interakcji**.\nÅšrodowisko Å‚Ä…czy hierarchicznÄ… bazÄ™ wiedzy, dokumentacjÄ™ bazy danych oraz napÄ™dzany funkcjami symulator uÅ¼ytkownika, aby odtworzyÄ‡ autentyczne Å›rodowiska korporacyjne obejmujÄ…ce peÅ‚ne operacje **CRUD**.\nOferuje dwa rygorystyczne tryby testowe: (1) pasywnÄ… **InterakcjÄ™ KonwersacyjnÄ…** oraz (2) aktywnÄ… **InterakcjÄ™ AgentycznÄ…**, obejmujÄ…cÄ… 600 adnotowanych zadaÅ„, w tym Business Intelligence (BI), operacje CRUD itp., z ktÃ³rych kaÅ¼de jest chronione przez wykonywalne przypadki testowe.\nTypowa ewaluacja wywoÅ‚uje od 1 968 do 5 496 tur interakcji miÄ™dzy modelem a symulatorem uÅ¼ytkownika, podczas gdy najnowoczeÅ›niejsze modele rozumowania rozwiÄ…zujÄ… obecnie tylko **â‰ˆ24%** oraz **â‰ˆ18%** zadaÅ„, co podkreÅ›la wyzwania benchmarku.\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/bird-bench/BIRD-Interact/main/materials/workflow.png\" \n       style=\"width: 100%; min-width: 100px; display: block; margin: auto; \">\n</p>\n\n### âœ… Dwa Tryby Ewaluacji\n\nBIRD-INTERACT obsÅ‚uguje dwa tryby ewaluacji opisane powyÅ¼ej:\n\n   - **c-Interact**: Interakcja Konwersacyjna, ktÃ³ra jest trybem pasywnym, a workflow jest ustalony. Kod i szczegÃ³Å‚owe informacje znajdujÄ… siÄ™ w `bird_interact_conv`.\n   - **a-Interact**: Interakcja Agentyczna, ktÃ³ra jest ucieleÅ›nionym trybem aktywnym, gdzie workflow jest dynamiczny i prowadzony przez modele. Kod i szczegÃ³Å‚owe informacje znajdujÄ… siÄ™ w `bird_interact_agent`.\n\n\n### ğŸ£ Wersja Lite\n\nUdostÄ™pniamy wersjÄ™ lite BIRD-INTERACT, `bird-interact-lite-exp`, ktÃ³ra zawiera 270 wysokiej jakoÅ›ci zadaÅ„ rzeczywistych, przeznaczonych specjalnie dla PostgreSQL. To dobry punkt wyjÅ›cia do szybkich eksperymentÃ³w.\n\n### ğŸ¦œ Wersja PeÅ‚na\n\nPeÅ‚na wersja BIRD-INTERACT, `bird-interact-full`, to kompleksowy benchmark obejmujÄ…cy 600 zadaÅ„ dla PostgreSQL. Obejmuje szeroki zakres operacji SQL i zapytaÅ„ uÅ¼ytkownika. PeÅ‚na wersja juÅ¼ wkrÃ³tce.\n\n### Wyniki WydajnoÅ›ci Modeli na BIRD-INTERACT Lite\n\n#### 1. WydajnoÅ›Ä‡ **c-Interact**\n| Miejsce | Nazwa modelu      | Znormalizowana nagroda | Poziom           |\n|:------:|--------------------|:-------:|:--------------:|\n| 1    | o3-mini            | 33.04 | ğŸ† DoskonaÅ‚y Chat |\n| 2    | GPT-4o             | 30.33 | ğŸ’ Dobry Chat      |\n| 3    | Gemini-2.0-flash   | 27.41 | ğŸ’ Dobry Chat      |\n| 4    | Claude-3.7-sonnet  | 26.60 | âœ¨ Standard        |\n| 5    | DeepSeek-R1        | 21.74 | âœ¨ Standard        |\n| 6    | Qwen3              | 20.33 | âšª Podstawowy      |\n| 7    | DeepSeek-V3        | 15.85 | âšª Podstawowy      |\n\n#### 2. WydajnoÅ›Ä‡ **a-Interact**\n| Miejsce | Nazwa modelu      | Parametry budÅ¼etowe* | Åšr. tury/zadanie | Åšr. koszt (USD)/zadanie | Znormalizowana nagroda | Poziom                   |\n|:------:|--------------------|:-------------------:|:----------------:|:---------------------:|:---------------------:|:-------------------------:|\n| 1    | Claude-3.7-sonnet  | 6/6 | 15,4 | $0.6668 | 29.19 | ğŸ† DoskonaÅ‚a Interakcja    |\n| 2    | o3-mini            | 6/6 | 7,8  | $0.0754 | 21.07 | ğŸ’ Dobra Interakcja        |\n| 3    | DeepSeek-V3        | 6/6 | 15,6 | $0.0629 | 19.19 | ğŸ’ Dobra Interakcja        |\n| 4    | Qwen3              | 6/6 | 12,5 | $0.0278 | 18.74 | âœ¨ Standard                |\n| 5    | GPT-4o             | 6/6 | 15,3 | $0.4594 | 18.37 | âœ¨ Standard                |\n| 6    | Gemini-2.0-flash   | 6/6 | 13,2 | $0.0337 | 17.26 | âšª Podstawowy              |\n| 7    | DeepSeek-R1        | 6/6 | 12,0 | $0.0931 | 17.07 | âšª Podstawowy              |\n\n> \\* Parametry budÅ¼etowe: BudÅ¼et poczÄ…tkowy/BudÅ¼et cierpliwoÅ›ci uÅ¼ytkownika, mierzony naszÄ… wirtualnÄ… walutÄ… *bird-coin*s <img src=\"https://raw.githubusercontent.com/bird-bench/BIRD-Interact/main/bird_interact_agent/materials/bird-coin.png\" style=\"height: 1em; vertical-align: middle;\">. SzczegÃ³Å‚y w [bird_interact_agent/README.md](https://raw.githubusercontent.com/bird-bench/BIRD-Interact/main/bird_interact_agent/README.md#task-setting).\n\n### Skalowanie w Czasie Interakcji (ITS)\n\nInteraction-Time Scaling (ITS) odnosi siÄ™ do zdolnoÅ›ci modelu do ciÄ…gÅ‚ego zwiÄ™kszania koÅ„cowej wydajnoÅ›ci poprzez wieloturowÄ… interakcjÄ™. Gdy ta wydajnoÅ›Ä‡ interakcyjna przewyÅ¼sza idealizowanÄ… wydajnoÅ›Ä‡ modelu w pojedynczej turze dla w peÅ‚ni okreÅ›lonego, jednoznacznego zadania, mÃ³wimy, Å¼e speÅ‚nia on **prawo ITS**. Wraz ze wzrostem cierpliwoÅ›ci uÅ¼ytkownika i liczby tur interakcji, wydajnoÅ›Ä‡ stale siÄ™ poprawia, co pokazuje, Å¼e model jest w stanie utrzymaÄ‡ efektywnÄ… komunikacjÄ™ podczas dÅ‚uÅ¼szego dialogu. Obecnie tylko claude-3-7-sonnet speÅ‚nia prawo ITS.\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/bird-bench/BIRD-Interact/main/materials/interaction_scaling_law.png\" \n       style=\"width: 100%; min-width: 100px; display: block; margin: auto; \">\n</p>\n\n## ğŸ“¦ SzczegÃ³Å‚y Zbioru Danych\n\n### Opis Zbioru Danych\n\n- **Baza danych:** PeÅ‚nÄ… bazÄ™ danych PostgreSQL moÅ¼na pobraÄ‡ z [Google Drive](https://drive.google.com/file/d/1KABce6czIqL9kMyIX7i-_A0CIQoDnmyW/view). SprawdÅº sekcjÄ™ [Quick Eval](#quick-eval) po wiÄ™cej szczegÃ³Å‚Ã³w.\n- **data:** KaÅ¼da instancja danych zawiera nastÄ™pujÄ…ce gÅ‚Ã³wne czÄ™Å›ci:\n   - `selected_database`: Nazwa bazy danych.  \n   - `query`: Jednoznaczne zapytanie uÅ¼ytkownika.  \n   - `amb_user_query`: Zapytanie uÅ¼ytkownika z wstrzykniÄ™tymi niejednoznacznoÅ›ciami.\n   - `user_query_ambiguity`: NiejednoznacznoÅ›ci wstrzykniÄ™te do zapytania uÅ¼ytkownika.\n   - `non_critical_ambiguity`: NiejednoznacznoÅ›ci niekrytyczne, jak kolejnoÅ›Ä‡, limit, itp.",
  "status": "ok"
}