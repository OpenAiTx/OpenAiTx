{
  "id": 1,
  "origin": "# BIRD-INTERACT 1.0 <img src=\"https://raw.githubusercontent.com/bird-bench/BIRD-Interact/main/materials/hku-logo.jpg\" alt=\"HKU Logo\" width=\"50\" style=\"vertical-align:middle;margin-left:10px;\"> <img src=\"https://raw.githubusercontent.com/bird-bench/BIRD-Interact/main/materials/google-cloud-logo.png\" alt=\"Google Cloud Logo\" width=\"50\" style=\"vertical-align:middle;margin-left:10px;\">\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/bird-bench/BIRD-Interact/main/materials/bird_interact.png\" \n       style=\"width: 30%; min-width: 100px; display: block; margin: auto; border-radius: 15px !important;\">\n</p>\n\n\n<div style=\"display: flex; justify-content: center; align-items: center; gap: 10px;\">\n  <a href=\"https://creativecommons.org/licenses/by-sa/4.0/deed.en\">\n    <img src=\"https://img.shields.io/badge/License-CC%20By%20SA%204.0-orange.svg\" alt=\"License\">\n  </a>\n  <a href=\"https://bird-interact.github.io/\">\n    <img src=\"https://img.shields.io/badge/Leaderboard-2025-28a745.svg\" alt=\"Leaderboard\">\n  </a>\n  <a href=\"https://huggingface.co/datasets/birdsql/bird-interact-lite/tree/main\">\n    <img src=\"https://img.shields.io/badge/Dataset-HuggingFace-FFD21E.svg\" alt=\"HuggingFace\">\n  </a>\n  <a href=\"https://www.python.org/downloads/release/python-310/\">\n    <img src=\"https://img.shields.io/badge/Python-3.10+-teal.svg\" alt=\"Python\">\n  </a>\n  <a href=\"https://pypi.org/project/openai/\">\n    <img src=\"https://img.shields.io/badge/OpenAI-1.40+-beige.svg\" alt=\"OpenAI\">\n  </a>\n</div>\n\n## üß∏ Overview\n\nBIRD-INTERACT, an interactive text-to-SQL benchmark, **re-imagines Text-to-SQL evaluation via lens of dynamic interactions**.\nThe environment blends a hierarchical knowledge base, database documentation and a function-driven user simulator to recreate authentic enterprise environments across full **CRUD** operations.\nIt offers two rigorous test modes: (1) passive **Conversational Interaction** and (2) active **Agentic Interaction**, spanning 600 annotated tasks including Business Intelligence (BI), CRUD operations and etc., each guarded by executable test cases.\nTypical evaluations trigger 1,968-5,496 interaction turns between model and user simulator, while state-of-the-art reasoning models currently solve only **‚âà24%** and **‚âà18%** of tasks, underscoring the benchmark's challenge.\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/bird-bench/BIRD-Interact/main/materials/workflow.png\" \n       style=\"width: 100%; min-width: 100px; display: block; margin: auto; \">\n</p>\n\n### ‚úÖ Two Evaluation Modes\n\nBIRD-INTERACT supports two evaluation modes as mentioned above:\n\n   - **c-Interact**: Conversational Interaction which is a passive mode and the workflow is fixed. The code and detailed information can be found in `bird_interact_conv`.\n   - **a-Interact**: Agentic Interaction which is an embodied active mode where the workflow is dynamic and led by models. The code and detailed information can be found in `bird_interact_agent`.\n\n\n### üê£ Lite Version\n\nWe are releasing a lite version of BIRD-INTERACT, `bird-interact-lite-exp`, which includes 270 high-quality real-world tasks specifically for PostgreSQL. This is a good starting point for quick experimentation. \n\n### ü¶ú Full Version\n\nThe full version of BIRD-INTERACT, `bird-interact-full`, is a comprehensive benchmark that includes 600 tasks for PostgreSQL. It covers a wide range of SQL operations and user queries. The full version is coming soon.\n\n### Model Performance Results on BIRD-INTERACT Lite\n\n#### 1. **c-Interact** Performance\n| Rank | Model Name         | Normalized Reward | Level        |\n|:------:|--------------------|:-------:|:--------------:|\n| 1    | o3-mini            | 33.04 | üèÜ Excellent Chat |\n| 2    | GPT-4o             | 30.33 | üíé Good Chat      |\n| 3    | Gemini-2.0-flash   | 27.41 | üíé Good Chat      |\n| 4    | Claude-3.7-sonnet  | 26.60 | ‚ú® Standard       |\n| 5    | DeepSeek-R1        | 21.74 | ‚ú® Standard       |\n| 6    | Qwen3              | 20.33 | ‚ö™ Basic          |\n| 7    | DeepSeek-V3        | 15.85 | ‚ö™ Basic          |\n\n#### 2. **a-Interact** Performance\n| Rank | Model Name         | Budget Parameters* | Avg Turns/Task | Avg Cost (USD)/Task | Normalized Reward | Level            |\n|:------:|--------------------|:-------------------:|:----------------:|:---------------------:|:-------------------:|:---------------------:|\n| 1    | Claude-3.7-sonnet  | 6/6 | 15.4 | $0.6668 | 29.19 | üèÜ Excellent Interaction |\n| 2    | o3-mini            | 6/6 | 7.8 | $0.0754 | 21.07 | üíé Good Interaction      |\n| 3    | DeepSeek-V3        | 6/6 | 15.6 | $0.0629 | 19.19 | üíé Good Interaction      |\n| 4    | Qwen3              | 6/6 | 12.5 | $0.0278 | 18.74 | ‚ú® Standard              |\n| 5    | GPT-4o             | 6/6 | 15.3 | $0.4594 | 18.37 | ‚ú® Standard              |\n| 6    | Gemini-2.0-flash   | 6/6 | 13.2 | $0.0337 | 17.26 | ‚ö™ Basic                 |\n| 7    | DeepSeek-R1        | 6/6 | 12.0 | $0.0931 | 17.07 | ‚ö™ Basic                 |\n\n> \\* Budget Parameters: Starting Budget/User Patience Budget, measured by our virtual currency *bird-coin*s <img src=\"https://raw.githubusercontent.com/bird-bench/BIRD-Interact/main/bird_interact_agent/materials/bird-coin.png\" style=\"height: 1em; vertical-align: middle;\">. Refer to [bird_interact_agent/README.md](https://raw.githubusercontent.com/bird-bench/BIRD-Interact/main/bird_interact_agent/README.md#task-setting) for more details.\n\n### Interaction-Time Scaling (ITS)\n\nInteraction-Time Scaling (ITS) refers to a model's ability to continuously increase its end performance through multi-turn interactions. When this interactive performance surpasses the model's idealized single-turn performance on a fully specified, unambiguous task, we say it satisfies the **ITS law**. As user patience grows and interaction turns accumulate, performance keeps improving, demonstrating that the model can sustain effective communication over extended dialogue. Currently, we only find claude-3-7-sonnet satisfies the ITS law.\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/bird-bench/BIRD-Interact/main/materials/interaction_scaling_law.png\" \n       style=\"width: 100%; min-width: 100px; display: block; margin: auto; \">\n</p>\n\n## üì¶ Dataset Details\n\n### Dataset Description\n\n- **Database:** The complete PostgreSQL database can be download from [the Google Drive](https://drive.google.com/file/d/1KABce6czIqL9kMyIX7i-_A0CIQoDnmyW/view). Check the [Quick Eval](#quick-eval) section for more details.\n- **data:** Each data instance contain the following main parts:\n   - `selected_database`: The name of the database.  \n   - `query`: The unambiguous user query.  \n   - `amb_user_query`: The user query with injected ambiguities.\n   - `user_query_ambiguity`: The ambiguities injected into the user query.\n   - `non_critical_ambiguity`: The non-critical ambiguities like order, limit, etc.",
  "origin_sha": "IzclqHo7LOD1iZwsnLH04ZKmHGZNpP/iNkNvMDe0viU=",
  "translate": "# BIRD-INTERACT 1.0 <img src=\"https://raw.githubusercontent.com/bird-bench/BIRD-Interact/main/materials/hku-logo.jpg\" alt=\"HKU Logo\" width=\"50\" style=\"vertical-align:middle;margin-left:10px;\"> <img src=\"https://raw.githubusercontent.com/bird-bench/BIRD-Interact/main/materials/google-cloud-logo.png\" alt=\"Google Cloud Logo\" width=\"50\" style=\"vertical-align:middle;margin-left:10px;\">\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/bird-bench/BIRD-Interact/main/materials/bird_interact.png\" \n       style=\"width: 30%; min-width: 100px; display: block; margin: auto; border-radius: 15px !important;\">\n</p>\n\n\n<div style=\"display: flex; justify-content: center; align-items: center; gap: 10px;\">\n  <a href=\"https://creativecommons.org/licenses/by-sa/4.0/deed.en\">\n    <img src=\"https://img.shields.io/badge/License-CC%20By%20SA%204.0-orange.svg\" alt=\"License\">\n  </a>\n  <a href=\"https://bird-interact.github.io/\">\n    <img src=\"https://img.shields.io/badge/Leaderboard-2025-28a745.svg\" alt=\"Leaderboard\">\n  </a>\n  <a href=\"https://huggingface.co/datasets/birdsql/bird-interact-lite/tree/main\">\n    <img src=\"https://img.shields.io/badge/Dataset-HuggingFace-FFD21E.svg\" alt=\"HuggingFace\">\n  </a>\n  <a href=\"https://www.python.org/downloads/release/python-310/\">\n    <img src=\"https://img.shields.io/badge/Python-3.10+-teal.svg\" alt=\"Python\">\n  </a>\n  <a href=\"https://pypi.org/project/openai/\">\n    <img src=\"https://img.shields.io/badge/OpenAI-1.40+-beige.svg\" alt=\"OpenAI\">\n  </a>\n</div>\n\n## üß∏ Aper√ßu\n\nBIRD-INTERACT, un benchmark interactif de text-to-SQL, **r√©invente l'√©valuation Text-to-SQL √† travers le prisme des interactions dynamiques**.\nL'environnement combine une base de connaissances hi√©rarchique, une documentation de base de donn√©es et un simulateur d'utilisateur pilot√© par fonctions pour recr√©er des environnements d'entreprise authentiques couvrant l'ensemble des op√©rations **CRUD**.\nIl propose deux modes de test rigoureux : (1) **Interaction conversationnelle** passive et (2) **Interaction agentique** active, couvrant 600 t√¢ches annot√©es incluant l'intelligence d'affaires (BI), des op√©rations CRUD, etc., chacune prot√©g√©e par des cas de test ex√©cutables.\nLes √©valuations typiques d√©clenchent entre 1 968 et 5 496 tours d'interaction entre le mod√®le et le simulateur d'utilisateur, tandis que les mod√®les de raisonnement de pointe ne r√©solvent actuellement que **‚âà24%** et **‚âà18%** des t√¢ches, soulignant ainsi le d√©fi pos√© par ce benchmark.\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/bird-bench/BIRD-Interact/main/materials/workflow.png\" \n       style=\"width: 100%; min-width: 100px; display: block; margin: auto; \">\n</p>\n\n### ‚úÖ Deux modes d'√©valuation\n\nBIRD-INTERACT prend en charge deux modes d'√©valuation comme mentionn√© ci-dessus :\n\n   - **c-Interact** : Interaction conversationnelle, qui est un mode passif et dont le workflow est fixe. Le code et les informations d√©taill√©es se trouvent dans `bird_interact_conv`.\n   - **a-Interact** : Interaction agentique, qui est un mode actif incarn√© o√π le workflow est dynamique et dirig√© par les mod√®les. Le code et les informations d√©taill√©es se trouvent dans `bird_interact_agent`.\n\n\n### üê£ Version all√©g√©e\n\nNous publions une version all√©g√©e de BIRD-INTERACT, `bird-interact-lite-exp`, qui inclut 270 t√¢ches r√©elles de haute qualit√© sp√©cifiquement pour PostgreSQL. C'est un bon point de d√©part pour des exp√©rimentations rapides.\n\n### ü¶ú Version compl√®te\n\nLa version compl√®te de BIRD-INTERACT, `bird-interact-full`, est un benchmark complet qui inclut 600 t√¢ches pour PostgreSQL. Elle couvre un large √©ventail d'op√©rations SQL et de requ√™tes utilisateur. La version compl√®te arrive bient√¥t.\n\n### R√©sultats de performance des mod√®les sur BIRD-INTERACT Lite\n\n#### 1. Performance **c-Interact**\n| Rang | Nom du mod√®le      | R√©compense normalis√©e | Niveau             |\n|:------:|--------------------|:-------:|:--------------:|\n| 1    | o3-mini            | 33.04 | üèÜ Chat Excellent |\n| 2    | GPT-4o             | 30.33 | üíé Bon Chat       |\n| 3    | Gemini-2.0-flash   | 27.41 | üíé Bon Chat       |\n| 4    | Claude-3.7-sonnet  | 26.60 | ‚ú® Standard       |\n| 5    | DeepSeek-R1        | 21.74 | ‚ú® Standard       |\n| 6    | Qwen3              | 20.33 | ‚ö™ Basique        |\n| 7    | DeepSeek-V3        | 15.85 | ‚ö™ Basique        |\n\n#### 2. Performance **a-Interact**\n| Rang | Nom du mod√®le      | Param√®tres de budget* | Moy. tours/t√¢che | Co√ªt moy. (USD)/t√¢che | R√©compense normalis√©e | Niveau                |\n|:------:|--------------------|:-------------------:|:----------------:|:---------------------:|:-------------------:|:---------------------:|\n| 1    | Claude-3.7-sonnet  | 6/6 | 15.4 | $0.6668 | 29.19 | üèÜ Interaction excellente |\n| 2    | o3-mini            | 6/6 | 7.8 | $0.0754 | 21.07 | üíé Bonne interaction      |\n| 3    | DeepSeek-V3        | 6/6 | 15.6 | $0.0629 | 19.19 | üíé Bonne interaction      |\n| 4    | Qwen3              | 6/6 | 12.5 | $0.0278 | 18.74 | ‚ú® Standard              |\n| 5    | GPT-4o             | 6/6 | 15.3 | $0.4594 | 18.37 | ‚ú® Standard              |\n| 6    | Gemini-2.0-flash   | 6/6 | 13.2 | $0.0337 | 17.26 | ‚ö™ Basique               |\n| 7    | DeepSeek-R1        | 6/6 | 12.0 | $0.0931 | 17.07 | ‚ö™ Basique               |\n\n> \\* Param√®tres de budget : Budget de d√©part/Budget de patience utilisateur, mesur√©s par notre monnaie virtuelle *bird-coin*s <img src=\"https://raw.githubusercontent.com/bird-bench/BIRD-Interact/main/bird_interact_agent/materials/bird-coin.png\" style=\"height: 1em; vertical-align: middle;\">. Voir [bird_interact_agent/README.md](https://raw.githubusercontent.com/bird-bench/BIRD-Interact/main/bird_interact_agent/README.md#task-setting) pour plus de d√©tails.\n\n### √âchelle de temps d‚Äôinteraction (ITS)\n\nL‚ÄôInteraction-Time Scaling (ITS) fait r√©f√©rence √† la capacit√© d‚Äôun mod√®le √† augmenter continuellement ses performances finales gr√¢ce √† des interactions multi-tours. Lorsque cette performance interactive d√©passe celle du mod√®le dans un sc√©nario id√©al √† un seul tour sur une t√¢che enti√®rement sp√©cifi√©e et non ambigu√´, on dit qu‚Äôil satisfait √† la **loi ITS**. √Ä mesure que la patience de l‚Äôutilisateur grandit et que les tours d‚Äôinteraction s‚Äôaccumulent, la performance continue de s‚Äôam√©liorer, d√©montrant que le mod√®le peut maintenir une communication efficace sur des dialogues prolong√©s. Actuellement, seul claude-3-7-sonnet satisfait √† la loi ITS.\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/bird-bench/BIRD-Interact/main/materials/interaction_scaling_law.png\" \n       style=\"width: 100%; min-width: 100px; display: block; margin: auto; \">\n</p>\n\n## üì¶ D√©tails du jeu de donn√©es\n\n### Description du jeu de donn√©es\n\n- **Base de donn√©es :** La base de donn√©es compl√®te PostgreSQL peut √™tre t√©l√©charg√©e depuis [Google Drive](https://drive.google.com/file/d/1KABce6czIqL9kMyIX7i-_A0CIQoDnmyW/view). Consultez la section [Quick Eval](#quick-eval) pour plus de d√©tails.\n- **data :** Chaque instance de donn√©es contient les parties principales suivantes :\n   - `selected_database` : Le nom de la base de donn√©es.  \n   - `query` : La requ√™te utilisateur non ambigu√´.  \n   - `amb_user_query` : La requ√™te utilisateur avec ambigu√Øt√©s inject√©es.\n   - `user_query_ambiguity` : Les ambigu√Øt√©s inject√©es dans la requ√™te utilisateur.\n   - `non_critical_ambiguity` : Les ambigu√Øt√©s non critiques telles que l‚Äôordre, la limite, etc.",
  "status": "ok"
}