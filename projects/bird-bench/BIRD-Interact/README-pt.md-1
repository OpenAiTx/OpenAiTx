{
  "id": 1,
  "origin": "# BIRD-INTERACT 1.0 <img src=\"https://raw.githubusercontent.com/bird-bench/BIRD-Interact/main/materials/hku-logo.jpg\" alt=\"HKU Logo\" width=\"50\" style=\"vertical-align:middle;margin-left:10px;\"> <img src=\"https://raw.githubusercontent.com/bird-bench/BIRD-Interact/main/materials/google-cloud-logo.png\" alt=\"Google Cloud Logo\" width=\"50\" style=\"vertical-align:middle;margin-left:10px;\">\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/bird-bench/BIRD-Interact/main/materials/bird_interact.png\" \n       style=\"width: 30%; min-width: 100px; display: block; margin: auto; border-radius: 15px !important;\">\n</p>\n\n\n<div style=\"display: flex; justify-content: center; align-items: center; gap: 10px;\">\n  <a href=\"https://creativecommons.org/licenses/by-sa/4.0/deed.en\">\n    <img src=\"https://img.shields.io/badge/License-CC%20By%20SA%204.0-orange.svg\" alt=\"License\">\n  </a>\n  <a href=\"https://bird-interact.github.io/\">\n    <img src=\"https://img.shields.io/badge/Leaderboard-2025-28a745.svg\" alt=\"Leaderboard\">\n  </a>\n  <a href=\"https://huggingface.co/datasets/birdsql/bird-interact-lite/tree/main\">\n    <img src=\"https://img.shields.io/badge/Dataset-HuggingFace-FFD21E.svg\" alt=\"HuggingFace\">\n  </a>\n  <a href=\"https://www.python.org/downloads/release/python-310/\">\n    <img src=\"https://img.shields.io/badge/Python-3.10+-teal.svg\" alt=\"Python\">\n  </a>\n  <a href=\"https://pypi.org/project/openai/\">\n    <img src=\"https://img.shields.io/badge/OpenAI-1.40+-beige.svg\" alt=\"OpenAI\">\n  </a>\n</div>\n\n## üß∏ Overview\n\nBIRD-INTERACT, an interactive text-to-SQL benchmark, **re-imagines Text-to-SQL evaluation via lens of dynamic interactions**.\nThe environment blends a hierarchical knowledge base, database documentation and a function-driven user simulator to recreate authentic enterprise environments across full **CRUD** operations.\nIt offers two rigorous test modes: (1) passive **Conversational Interaction** and (2) active **Agentic Interaction**, spanning 600 annotated tasks including Business Intelligence (BI), CRUD operations and etc., each guarded by executable test cases.\nTypical evaluations trigger 1,968-5,496 interaction turns between model and user simulator, while state-of-the-art reasoning models currently solve only **‚âà24%** and **‚âà18%** of tasks, underscoring the benchmark's challenge.\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/bird-bench/BIRD-Interact/main/materials/workflow.png\" \n       style=\"width: 100%; min-width: 100px; display: block; margin: auto; \">\n</p>\n\n### ‚úÖ Two Evaluation Modes\n\nBIRD-INTERACT supports two evaluation modes as mentioned above:\n\n   - **c-Interact**: Conversational Interaction which is a passive mode and the workflow is fixed. The code and detailed information can be found in `bird_interact_conv`.\n   - **a-Interact**: Agentic Interaction which is an embodied active mode where the workflow is dynamic and led by models. The code and detailed information can be found in `bird_interact_agent`.\n\n\n### üê£ Lite Version\n\nWe are releasing a lite version of BIRD-INTERACT, `bird-interact-lite-exp`, which includes 270 high-quality real-world tasks specifically for PostgreSQL. This is a good starting point for quick experimentation. \n\n### ü¶ú Full Version\n\nThe full version of BIRD-INTERACT, `bird-interact-full`, is a comprehensive benchmark that includes 600 tasks for PostgreSQL. It covers a wide range of SQL operations and user queries. The full version is coming soon.\n\n### Model Performance Results on BIRD-INTERACT Lite\n\n#### 1. **c-Interact** Performance\n| Rank | Model Name         | Normalized Reward | Level        |\n|:------:|--------------------|:-------:|:--------------:|\n| 1    | o3-mini            | 33.04 | üèÜ Excellent Chat |\n| 2    | GPT-4o             | 30.33 | üíé Good Chat      |\n| 3    | Gemini-2.0-flash   | 27.41 | üíé Good Chat      |\n| 4    | Claude-3.7-sonnet  | 26.60 | ‚ú® Standard       |\n| 5    | DeepSeek-R1        | 21.74 | ‚ú® Standard       |\n| 6    | Qwen3              | 20.33 | ‚ö™ Basic          |\n| 7    | DeepSeek-V3        | 15.85 | ‚ö™ Basic          |\n\n#### 2. **a-Interact** Performance\n| Rank | Model Name         | Budget Parameters* | Avg Turns/Task | Avg Cost (USD)/Task | Normalized Reward | Level            |\n|:------:|--------------------|:-------------------:|:----------------:|:---------------------:|:-------------------:|:---------------------:|\n| 1    | Claude-3.7-sonnet  | 6/6 | 15.4 | $0.6668 | 29.19 | üèÜ Excellent Interaction |\n| 2    | o3-mini            | 6/6 | 7.8 | $0.0754 | 21.07 | üíé Good Interaction      |\n| 3    | DeepSeek-V3        | 6/6 | 15.6 | $0.0629 | 19.19 | üíé Good Interaction      |\n| 4    | Qwen3              | 6/6 | 12.5 | $0.0278 | 18.74 | ‚ú® Standard              |\n| 5    | GPT-4o             | 6/6 | 15.3 | $0.4594 | 18.37 | ‚ú® Standard              |\n| 6    | Gemini-2.0-flash   | 6/6 | 13.2 | $0.0337 | 17.26 | ‚ö™ Basic                 |\n| 7    | DeepSeek-R1        | 6/6 | 12.0 | $0.0931 | 17.07 | ‚ö™ Basic                 |\n\n> \\* Budget Parameters: Starting Budget/User Patience Budget, measured by our virtual currency *bird-coin*s <img src=\"https://raw.githubusercontent.com/bird-bench/BIRD-Interact/main/bird_interact_agent/materials/bird-coin.png\" style=\"height: 1em; vertical-align: middle;\">. Refer to [bird_interact_agent/README.md](https://raw.githubusercontent.com/bird-bench/BIRD-Interact/main/bird_interact_agent/README.md#task-setting) for more details.\n\n### Interaction-Time Scaling (ITS)\n\nInteraction-Time Scaling (ITS) refers to a model's ability to continuously increase its end performance through multi-turn interactions. When this interactive performance surpasses the model's idealized single-turn performance on a fully specified, unambiguous task, we say it satisfies the **ITS law**. As user patience grows and interaction turns accumulate, performance keeps improving, demonstrating that the model can sustain effective communication over extended dialogue. Currently, we only find claude-3-7-sonnet satisfies the ITS law.\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/bird-bench/BIRD-Interact/main/materials/interaction_scaling_law.png\" \n       style=\"width: 100%; min-width: 100px; display: block; margin: auto; \">\n</p>\n\n## üì¶ Dataset Details\n\n### Dataset Description\n\n- **Database:** The complete PostgreSQL database can be download from [the Google Drive](https://drive.google.com/file/d/1KABce6czIqL9kMyIX7i-_A0CIQoDnmyW/view). Check the [Quick Eval](#quick-eval) section for more details.\n- **data:** Each data instance contain the following main parts:\n   - `selected_database`: The name of the database.  \n   - `query`: The unambiguous user query.  \n   - `amb_user_query`: The user query with injected ambiguities.\n   - `user_query_ambiguity`: The ambiguities injected into the user query.\n   - `non_critical_ambiguity`: The non-critical ambiguities like order, limit, etc.",
  "origin_sha": "IzclqHo7LOD1iZwsnLH04ZKmHGZNpP/iNkNvMDe0viU=",
  "translate": "# BIRD-INTERACT 1.0 <img src=\"https://raw.githubusercontent.com/bird-bench/BIRD-Interact/main/materials/hku-logo.jpg\" alt=\"HKU Logo\" width=\"50\" style=\"vertical-align:middle;margin-left:10px;\"> <img src=\"https://raw.githubusercontent.com/bird-bench/BIRD-Interact/main/materials/google-cloud-logo.png\" alt=\"Google Cloud Logo\" width=\"50\" style=\"vertical-align:middle;margin-left:10px;\">\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/bird-bench/BIRD-Interact/main/materials/bird_interact.png\" \n       style=\"width: 30%; min-width: 100px; display: block; margin: auto; border-radius: 15px !important;\">\n</p>\n\n\n<div style=\"display: flex; justify-content: center; align-items: center; gap: 10px;\">\n  <a href=\"https://creativecommons.org/licenses/by-sa/4.0/deed.en\">\n    <img src=\"https://img.shields.io/badge/License-CC%20By%20SA%204.0-orange.svg\" alt=\"License\">\n  </a>\n  <a href=\"https://bird-interact.github.io/\">\n    <img src=\"https://img.shields.io/badge/Leaderboard-2025-28a745.svg\" alt=\"Leaderboard\">\n  </a>\n  <a href=\"https://huggingface.co/datasets/birdsql/bird-interact-lite/tree/main\">\n    <img src=\"https://img.shields.io/badge/Dataset-HuggingFace-FFD21E.svg\" alt=\"HuggingFace\">\n  </a>\n  <a href=\"https://www.python.org/downloads/release/python-310/\">\n    <img src=\"https://img.shields.io/badge/Python-3.10+-teal.svg\" alt=\"Python\">\n  </a>\n  <a href=\"https://pypi.org/project/openai/\">\n    <img src=\"https://img.shields.io/badge/OpenAI-1.40+-beige.svg\" alt=\"OpenAI\">\n  </a>\n</div>\n\n## üß∏ Vis√£o Geral\n\nBIRD-INTERACT, um benchmark interativo de text-to-SQL, **reimagina a avalia√ß√£o Text-to-SQL pela √≥tica de intera√ß√µes din√¢micas**.\nO ambiente combina uma base de conhecimento hier√°rquica, documenta√ß√£o de banco de dados e um simulador de usu√°rio orientado por fun√ß√µes para recriar ambientes corporativos aut√™nticos cobrindo todas as opera√ß√µes **CRUD**.\nOferece dois modos rigorosos de teste: (1) **Intera√ß√£o Conversacional** passiva e (2) **Intera√ß√£o Agente** ativa, abrangendo 600 tarefas anotadas, incluindo Business Intelligence (BI), opera√ß√µes CRUD, etc., cada uma protegida por casos de teste execut√°veis.\nAvalia√ß√µes t√≠picas disparam entre 1.968 e 5.496 rodadas de intera√ß√£o entre o modelo e o simulador de usu√°rio, enquanto modelos de racioc√≠nio de √∫ltima gera√ß√£o atualmente resolvem apenas **‚âà24%** e **‚âà18%** das tarefas, ressaltando o desafio do benchmark.\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/bird-bench/BIRD-Interact/main/materials/workflow.png\" \n       style=\"width: 100%; min-width: 100px; display: block; margin: auto; \">\n</p>\n\n### ‚úÖ Dois Modos de Avalia√ß√£o\n\nO BIRD-INTERACT suporta dois modos de avalia√ß√£o como mencionado acima:\n\n   - **c-Interact**: Intera√ß√£o Conversacional, que √© um modo passivo e o fluxo de trabalho √© fixo. O c√≥digo e informa√ß√µes detalhadas podem ser encontrados em `bird_interact_conv`.\n   - **a-Interact**: Intera√ß√£o Agente, que √© um modo ativo incorporado onde o fluxo de trabalho √© din√¢mico e liderado pelos modelos. O c√≥digo e informa√ß√µes detalhadas podem ser encontrados em `bird_interact_agent`.\n\n\n### üê£ Vers√£o Lite\n\nEstamos lan√ßando uma vers√£o lite do BIRD-INTERACT, `bird-interact-lite-exp`, que inclui 270 tarefas do mundo real de alta qualidade especificamente para PostgreSQL. √â um bom ponto de partida para experimenta√ß√µes r√°pidas. \n\n### ü¶ú Vers√£o Completa\n\nA vers√£o completa do BIRD-INTERACT, `bird-interact-full`, √© um benchmark abrangente que inclui 600 tarefas para PostgreSQL. Ela cobre uma ampla gama de opera√ß√µes SQL e consultas de usu√°rios. A vers√£o completa estar√° dispon√≠vel em breve.\n\n### Resultados de Desempenho dos Modelos no BIRD-INTERACT Lite\n\n#### 1. Desempenho **c-Interact**\n| Classifica√ß√£o | Nome do Modelo     | Recompensa Normalizada | N√≠vel               |\n|:------:|--------------------|:-------:|:--------------:|\n| 1    | o3-mini            | 33.04 | üèÜ Chat Excelente |\n| 2    | GPT-4o             | 30.33 | üíé Bom Chat       |\n| 3    | Gemini-2.0-flash   | 27.41 | üíé Bom Chat       |\n| 4    | Claude-3.7-sonnet  | 26.60 | ‚ú® Padr√£o         |\n| 5    | DeepSeek-R1        | 21.74 | ‚ú® Padr√£o         |\n| 6    | Qwen3              | 20.33 | ‚ö™ B√°sico         |\n| 7    | DeepSeek-V3        | 15.85 | ‚ö™ B√°sico         |\n\n#### 2. Desempenho **a-Interact**\n| Classifica√ß√£o | Nome do Modelo     | Par√¢metros de Or√ßamento* | M√©dia de Rodadas/Tarefa | Custo M√©dio (USD)/Tarefa | Recompensa Normalizada | N√≠vel                  |\n|:------:|--------------------|:-------------------:|:----------------:|:---------------------:|:-------------------:|:---------------------:|\n| 1    | Claude-3.7-sonnet  | 6/6 | 15,4 | $0,6668 | 29,19 | üèÜ Intera√ß√£o Excelente   |\n| 2    | o3-mini            | 6/6 | 7,8  | $0,0754 | 21,07 | üíé Boa Intera√ß√£o        |\n| 3    | DeepSeek-V3        | 6/6 | 15,6 | $0,0629 | 19,19 | üíé Boa Intera√ß√£o        |\n| 4    | Qwen3              | 6/6 | 12,5 | $0,0278 | 18,74 | ‚ú® Padr√£o               |\n| 5    | GPT-4o             | 6/6 | 15,3 | $0,4594 | 18,37 | ‚ú® Padr√£o               |\n| 6    | Gemini-2.0-flash   | 6/6 | 13,2 | $0,0337 | 17,26 | ‚ö™ B√°sico               |\n| 7    | DeepSeek-R1        | 6/6 | 12,0 | $0,0931 | 17,07 | ‚ö™ B√°sico               |\n\n> \\* Par√¢metros de Or√ßamento: Or√ßamento Inicial/Or√ßamento de Paci√™ncia do Usu√°rio, medido por nossa moeda virtual *bird-coin*s <img src=\"https://raw.githubusercontent.com/bird-bench/BIRD-Interact/main/bird_interact_agent/materials/bird-coin.png\" style=\"height: 1em; vertical-align: middle;\">. Consulte [bird_interact_agent/README.md](https://raw.githubusercontent.com/bird-bench/BIRD-Interact/main/bird_interact_agent/README.md#task-setting) para mais detalhes.\n\n### Escalabilidade no Tempo de Intera√ß√£o (ITS)\n\nA Escalabilidade no Tempo de Intera√ß√£o (ITS) refere-se √† capacidade de um modelo de aumentar continuamente seu desempenho final por meio de intera√ß√µes de m√∫ltiplas rodadas. Quando esse desempenho interativo supera o desempenho idealizado do modelo em uma √∫nica rodada em uma tarefa totalmente especificada e n√£o amb√≠gua, dizemos que ele satisfaz a **lei ITS**. √Ä medida que a paci√™ncia do usu√°rio cresce e as rodadas de intera√ß√£o se acumulam, o desempenho continua melhorando, demonstrando que o modelo pode manter uma comunica√ß√£o eficaz ao longo de um di√°logo prolongado. Atualmente, apenas o claude-3-7-sonnet satisfaz a lei ITS.\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/bird-bench/BIRD-Interact/main/materials/interaction_scaling_law.png\" \n       style=\"width: 100%; min-width: 100px; display: block; margin: auto; \">\n</p>\n\n## üì¶ Detalhes do Conjunto de Dados\n\n### Descri√ß√£o do Conjunto de Dados\n\n- **Banco de Dados:** O banco de dados PostgreSQL completo pode ser baixado do [Google Drive](https://drive.google.com/file/d/1KABce6czIqL9kMyIX7i-_A0CIQoDnmyW/view). Veja a se√ß√£o [Quick Eval](#quick-eval) para mais detalhes.\n- **data:** Cada inst√¢ncia de dado cont√©m as seguintes partes principais:\n   - `selected_database`: O nome do banco de dados.  \n   - `query`: A consulta do usu√°rio sem ambiguidades.  \n   - `amb_user_query`: A consulta do usu√°rio com ambiguidades injetadas.\n   - `user_query_ambiguity`: As ambiguidades injetadas na consulta do usu√°rio.\n   - `non_critical_ambiguity`: As ambiguidades n√£o cr√≠ticas como ordem, limite, etc.",
  "status": "ok"
}