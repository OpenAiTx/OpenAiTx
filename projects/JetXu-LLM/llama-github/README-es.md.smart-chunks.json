[
  {
    "Id": 1,
    "Content": "# llama-github\n\n[Detail Document] https://deepwiki.com/JetXu-LLM/llama-github\n\n[![PyPI version](https://badge.fury.io/py/llama-github.svg)](https://badge.fury.io/py/llama-github)\n[![Downloads](https://static.pepy.tech/badge/Llama-github)](https://pepy.tech/project/Llama-github)\n[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)\n\nLlama-github is a powerful tool that helps you retrieve(based on Agentic RAG) the most relevant code snippets, issues, and repository information from GitHub based on your queries, transforming them into valuable knowledge context. It empowers LLM Chatbots, AI Agents, and Auto-dev Agents to solve complex coding tasks. Whether you're a developer looking for quick solutions or an engineer implementing advanced Auto Dev AI Agents, llama-github makes it easy and efficient.\n\nIf you like this project or believe it has potential, please give it a ‚≠êÔ∏è. Your support is our greatest motivation!\n\n## Architecture\n![High Level Architecture](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/./docs/high_level_architecture.drawio.svg)\n\n## Installation",
    "ContentSha": "TZmxyaoSVzegm0TJMJvowqs2RLRV2vw3TmLRyiZUZyA=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "# llama-github\n\n[Documento Detallado] https://deepwiki.com/JetXu-LLM/llama-github\n\n[![Versi√≥n PyPI](https://badge.fury.io/py/llama-github.svg)](https://badge.fury.io/py/llama-github)\n[![Descargas](https://static.pepy.tech/badge/Llama-github)](https://pepy.tech/project/Llama-github)\n[![Licencia](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)\n\nLlama-github es una herramienta poderosa que te ayuda a recuperar (basado en Agentic RAG) los fragmentos de c√≥digo, issues e informaci√≥n del repositorio m√°s relevantes de GitHub seg√∫n tus consultas, transform√°ndolos en un contexto de conocimiento valioso. Potencia chatbots LLM, agentes de IA y agentes Auto-dev para resolver tareas de codificaci√≥n complejas. Ya seas un desarrollador buscando soluciones r√°pidas o un ingeniero implementando avanzados agentes Auto Dev IA, llama-github lo hace f√°cil y eficiente.\n\nSi te gusta este proyecto o crees que tiene potencial, por favor dale una ‚≠êÔ∏è. ¬°Tu apoyo es nuestra mayor motivaci√≥n!\n\n## Arquitectura\n![Arquitectura de Alto Nivel](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/./docs/high_level_architecture.drawio.svg)\n\n## Instalaci√≥n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "cAI8B2fw5xCydddeNcosOFY2wrQw8An1lrdomk97KBc=",
        "originContent": "# llama-github",
        "translatedContent": "# llama-github"
      },
      {
        "row": 2,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 3,
        "rowsha": "jSTPMiMb5qDjmRYlxqDSx6zbsKYKOv4c6HQQgjbDUqo=",
        "originContent": "[Detail Document] https://deepwiki.com/JetXu-LLM/llama-github",
        "translatedContent": "[Documento Detallado] https://deepwiki.com/JetXu-LLM/llama-github"
      },
      {
        "row": 4,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 5,
        "rowsha": "48lo1Cg6fyAcQl554s/7eKSc41UYvSn/CD6yxtLVgjY=",
        "originContent": "[![PyPI version](https://badge.fury.io/py/llama-github.svg)](https://badge.fury.io/py/llama-github)",
        "translatedContent": "[![Versi√≥n PyPI](https://badge.fury.io/py/llama-github.svg)](https://badge.fury.io/py/llama-github)"
      },
      {
        "row": 6,
        "rowsha": "VG3AfiYLkBPipFZPAt/fJt5jj8aI773UKbmI1Z/kc2M=",
        "originContent": "[![Downloads](https://static.pepy.tech/badge/Llama-github)](https://pepy.tech/project/Llama-github)",
        "translatedContent": "[![Descargas](https://static.pepy.tech/badge/Llama-github)](https://pepy.tech/project/Llama-github)"
      },
      {
        "row": 7,
        "rowsha": "U0vs77tGfFYY+r4ScaOhTOZDgt8vSKCUyj59tU13ZtE=",
        "originContent": "[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)",
        "translatedContent": "[![Licencia](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)"
      },
      {
        "row": 8,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 9,
        "rowsha": "y7xsY1R0s8pmwDQukNS2PQ5JqK6CRs8AwuPrZkBKiT8=",
        "originContent": "Llama-github is a powerful tool that helps you retrieve(based on Agentic RAG) the most relevant code snippets, issues, and repository information from GitHub based on your queries, transforming them into valuable knowledge context. It empowers LLM Chatbots, AI Agents, and Auto-dev Agents to solve complex coding tasks. Whether you're a developer looking for quick solutions or an engineer implementing advanced Auto Dev AI Agents, llama-github makes it easy and efficient.",
        "translatedContent": "Llama-github es una herramienta poderosa que te ayuda a recuperar (basado en Agentic RAG) los fragmentos de c√≥digo, issues e informaci√≥n del repositorio m√°s relevantes de GitHub seg√∫n tus consultas, transform√°ndolos en un contexto de conocimiento valioso. Potencia chatbots LLM, agentes de IA y agentes Auto-dev para resolver tareas de codificaci√≥n complejas. Ya seas un desarrollador buscando soluciones r√°pidas o un ingeniero implementando avanzados agentes Auto Dev IA, llama-github lo hace f√°cil y eficiente."
      },
      {
        "row": 10,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 11,
        "rowsha": "6h9r25r7afHOT0YHlaj7xv1WU2JfjWqSqLUM7UgJNfQ=",
        "originContent": "If you like this project or believe it has potential, please give it a ‚≠êÔ∏è. Your support is our greatest motivation!",
        "translatedContent": "Si te gusta este proyecto o crees que tiene potencial, por favor dale una ‚≠êÔ∏è. ¬°Tu apoyo es nuestra mayor motivaci√≥n!"
      },
      {
        "row": 12,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 13,
        "rowsha": "p+VkcrEb08g4vIGZYB9aVScRKgA8afv5WwErwTVzoZM=",
        "originContent": "## Architecture",
        "translatedContent": "## Arquitectura"
      },
      {
        "row": 14,
        "rowsha": "TiSukfY/+ter5MJ39DMtNdHlqRXwhZFkP3uTdAfvA0c=",
        "originContent": "![High Level Architecture](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/./docs/high_level_architecture.drawio.svg)",
        "translatedContent": "![Arquitectura de Alto Nivel](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/./docs/high_level_architecture.drawio.svg)"
      },
      {
        "row": 15,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 16,
        "rowsha": "oV0SUDvwD2VN8Gi9nlr2JZ2xcDrASmE2W5kc5SVX5eo=",
        "originContent": "## Installation",
        "translatedContent": "## Instalaci√≥n"
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 2,
    "Content": "```\npip install llama-github\n```",
    "ContentSha": "A7Ioj19mKQ2poo2/SNNEl/PUNM9x+13/7/ncgppdcgY=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```\npip install llama-github\n```",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      },
      {
        "row": 2,
        "rowsha": "HUzQ8Fuh/Wg8Hu8KR8bezJLbFVpPKMpf5Pa7xDY6vYM=",
        "originContent": "pip install llama-github",
        "translatedContent": "pip install llama-github"
      },
      {
        "row": 3,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      }
    ],
    "IsCodeBlock": true
  },
  {
    "Id": 3,
    "Content": "\n## Usage\n\nHere's a simple example of how to use llama-github:\n",
    "ContentSha": "oqzkRVGHtTMxKJniKYy+bJRBu/B3l8AYVVo5suNCmR4=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "\n## Uso\n\nAqu√≠ hay un ejemplo simple de c√≥mo usar llama-github:\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 2,
        "rowsha": "Y7/WGgVhslWiyqCi463Qkcp+Mn8voGpAfLsv80G4WNg=",
        "originContent": "## Usage",
        "translatedContent": "## Uso"
      },
      {
        "row": 3,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 4,
        "rowsha": "4zRpXijfFggW+Fd/VZ8qaLkuJwnjePE96Hy1hPxOIRE=",
        "originContent": "Here's a simple example of how to use llama-github:",
        "translatedContent": "Aqu√≠ hay un ejemplo simple de c√≥mo usar llama-github:"
      },
      {
        "row": 5,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 4,
    "Content": "```python\nfrom llama_github import GithubRAG\n\n# Initialize GithubRAG with your credentials\ngithub_rag = GithubRAG(\n    github_access_token=\"your_github_access_token\", \n    openai_api_key=\"your_openai_api_key\", # Optional in Simple Mode\n    jina_api_key=\"your_jina_api_key\" # Optional - unless you want high concurrency production deployment (s.jina.ai API will be used in llama-github)\n)\n\n# Retrieve context for a coding question (simple_mode is default set to False)\nquery = \"How to create a NumPy array in Python?\"\ncontext = github_rag.retrieve_context(\n    query, # In professional mode, one query will take nearly 1 min to generate final contexts. You could set log level to INFO to monitor the retrieval progress\n    # simple_mode = True\n)\n\nprint(context)\n```",
    "ContentSha": "HXBtstD3V5wfKLk68/A2T/KFqRB/TtW5s0tq89CzhFU=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```python\nfrom llama_github import GithubRAG\n\n# Initialize GithubRAG with your credentials\ngithub_rag = GithubRAG(\n    github_access_token=\"your_github_access_token\", \n    openai_api_key=\"your_openai_api_key\", # Optional in Simple Mode\n    jina_api_key=\"your_jina_api_key\" # Optional - unless you want high concurrency production deployment (s.jina.ai API will be used in llama-github)\n)\n\n# Retrieve context for a coding question (simple_mode is default set to False)\nquery = \"How to create a NumPy array in Python?\"\ncontext = github_rag.retrieve_context(\n    query, # In professional mode, one query will take nearly 1 min to generate final contexts. You could set log level to INFO to monitor the retrieval progress\n    # simple_mode = True\n)\n\nprint(context)\n```",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "uDnRsrcDV2kZVI2wi9EA58m+F4ILdr1bvjhqNlB+wSc=",
        "originContent": "```python",
        "translatedContent": "```python"
      },
      {
        "row": 2,
        "rowsha": "hA5UQDttQHKAwB+ESl7GqyiAa1AotkDZYMGTRuo/AoY=",
        "originContent": "from llama_github import GithubRAG",
        "translatedContent": "from llama_github import GithubRAG"
      },
      {
        "row": 3,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 4,
        "rowsha": "/Xio12pWjWQxdHtqP9gkrQo8FvXup5Rnp8m6s9rWQoA=",
        "originContent": "# Initialize GithubRAG with your credentials",
        "translatedContent": "# Initialize GithubRAG with your credentials"
      },
      {
        "row": 5,
        "rowsha": "Z/GdSwf7Zfjb56iNk/lrSDiBY4vaKvdGc5F3qO5IgSQ=",
        "originContent": "github_rag = GithubRAG(",
        "translatedContent": "github_rag = GithubRAG("
      },
      {
        "row": 6,
        "rowsha": "DCUT+XvqWQMhTvTxgZeTkNrf6sB1egP0ataQmEq//Do=",
        "originContent": "    github_access_token=\"your_github_access_token\", ",
        "translatedContent": "    github_access_token=\"your_github_access_token\", "
      },
      {
        "row": 7,
        "rowsha": "7hDiOA+9nEfENa9R7NEJW8WSnmj71txD0Ndrw3HjngM=",
        "originContent": "    openai_api_key=\"your_openai_api_key\", # Optional in Simple Mode",
        "translatedContent": "    openai_api_key=\"your_openai_api_key\", # Optional in Simple Mode"
      },
      {
        "row": 8,
        "rowsha": "3gER4AqcTSuWLMk5yIWdhwT240c1f6O0Qk92225ZuVU=",
        "originContent": "    jina_api_key=\"your_jina_api_key\" # Optional - unless you want high concurrency production deployment (s.jina.ai API will be used in llama-github)",
        "translatedContent": "    jina_api_key=\"your_jina_api_key\" # Optional - unless you want high concurrency production deployment (s.jina.ai API will be used in llama-github)"
      },
      {
        "row": 9,
        "rowsha": "ul7FHQekrA6VFghwRDHVmgKyGk6VGswQUFqNxAfFAe4=",
        "originContent": ")",
        "translatedContent": ")"
      },
      {
        "row": 10,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 11,
        "rowsha": "U1SUJQpzS8NM2yh7MFPYJl5dQ6gq/MR813WqTX952X0=",
        "originContent": "# Retrieve context for a coding question (simple_mode is default set to False)",
        "translatedContent": "# Retrieve context for a coding question (simple_mode is default set to False)"
      },
      {
        "row": 12,
        "rowsha": "ZXVeMLKgPJjdKhiZ9CK5U4oP9OsdwnWdpg8zNqEI+58=",
        "originContent": "query = \"How to create a NumPy array in Python?\"",
        "translatedContent": "query = \"How to create a NumPy array in Python?\""
      },
      {
        "row": 13,
        "rowsha": "tMIfL+j+gxN0VAT5YvCwzTJ6i5aIIY3fcw3LxJWoTrQ=",
        "originContent": "context = github_rag.retrieve_context(",
        "translatedContent": "context = github_rag.retrieve_context("
      },
      {
        "row": 14,
        "rowsha": "Q1vTmUoyeud2ZNyE6iVCY7OriQi61Wg6NLrSyM9pVLE=",
        "originContent": "    query, # In professional mode, one query will take nearly 1 min to generate final contexts. You could set log level to INFO to monitor the retrieval progress",
        "translatedContent": "    query, # In professional mode, one query will take nearly 1 min to generate final contexts. You could set log level to INFO to monitor the retrieval progress"
      },
      {
        "row": 15,
        "rowsha": "uvb8HENvYITO6V3XF0E9tyqODM0Be+CdeIuXZsYj/CA=",
        "originContent": "    # simple_mode = True",
        "translatedContent": "    # simple_mode = True"
      },
      {
        "row": 16,
        "rowsha": "ul7FHQekrA6VFghwRDHVmgKyGk6VGswQUFqNxAfFAe4=",
        "originContent": ")",
        "translatedContent": ")"
      },
      {
        "row": 17,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 18,
        "rowsha": "ZZEcMA2fivnNWsWr7Vg5FUhhpwQQJ/ThJU+S148t13E=",
        "originContent": "print(context)",
        "translatedContent": "print(context)"
      },
      {
        "row": 19,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      }
    ],
    "IsCodeBlock": true
  },
  {
    "Id": 5,
    "Content": "\nFor more advanced usage and examples, please refer to the [documentation](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/docs/usage.md).\n\n## Key Features\n\n- **üîç Intelligent GitHub Retrieval**: Harness the power of llama-github to retrieve highly relevant code snippets, issues, and repository information from GitHub based on user queries. Our advanced retrieval techniques ensure you find the most pertinent information quickly and efficiently.\n\n- **‚ö° Repository Pool Caching**: Llama-github has an innovative repository pool caching mechanism. By caching repositories (including READMEs, structures, code, and issues) across threads, llama-github significantly accelerates GitHub search retrieval efficiency and minimizes the consumption of GitHub API tokens. Deploy llama-github in multi-threaded production environments with confidence, knowing that it will perform optimally and save you valuable resources.\n\n- **üß† LLM-Powered Question Analysis**: Leverage state-of-the-art language models to analyze user questions and generate highly effective search strategies and criteria. Llama-github intelligently breaks down complex queries, ensuring that you retrieve the most relevant information from GitHub's vast repository network.\n\n- **üìö Comprehensive Context Generation**: Generate rich, contextually relevant answers by seamlessly combining information retrieved from GitHub with the reasoning capabilities of advanced language models. Llama-github excels at handling even the most complex and lengthy questions, providing comprehensive and insightful responses that include extensive context to support your development needs.\n\n- **üöÄ Asynchronous Processing Excellence**: Llama-github is built from the ground up to leverage the full potential of asynchronous programming. With meticulously implemented asynchronous mechanisms woven throughout the codebase, llama-github can handle multiple requests concurrently, significantly boosting overall performance. Experience the difference as llama-github efficiently manages high-volume workloads without compromising on speed or quality.\n\n- **üîß Flexible LLM Integration**: Easily integrate llama-github with various LLM providers, embedding models, and reranking models to tailor the library's capabilities to your specific requirements. Our extensible architecture allows you to customize and enhance llama-github's functionality, ensuring that it adapts seamlessly to your unique development environment.\n\n- **üîí Robust Authentication Options**: Llama-github supports both personal access tokens and GitHub App authentication, providing you with the flexibility to integrate it into different development setups. Whether you're an individual developer or working within an organizational context, llama-github has you covered with secure and reliable authentication mechanisms.\n\n- **üõ†Ô∏è Logging and Error Handling**: We understand the importance of smooth operations and easy troubleshooting. That's why llama-github comes equipped with comprehensive logging and error handling mechanisms. Gain deep insights into the library's behavior, quickly diagnose issues, and maintain a stable and reliable development workflow.\n\n## ü§ñ Try Our AI-Powered PR Review Assistant: LlamaPReview\n\nIf you find llama-github useful, you might also be interested in our AI-powered GitHub PR review assistant, LlamaPReview. It's designed to complement your development workflow and further enhance code quality.\n\n### Key Features of LlamaPReview:\n- üöÄ One-click installation, zero configuration required, fully auto-run\n- üíØ Currently free to use - no credit card or payment info needed\n- üß† AI-powered, automatic PR reviews with deep code understanding\n- üåê Supports multiple programming languages\n\n**LlamaPReview utilizes llama-github's advanced context retrieval and LLM-powered analysis** to provide intelligent, context-aware code reviews. It's like having a senior developer, armed with the full context of your repository, review every PR automatically!\n\nüëâ [Install LlamaPReview Now](https://github.com/marketplace/llamapreview/) (Free)\n\nBy using llama-github for context retrieval and LlamaPReview for code reviews, you can create a powerful, AI-enhanced development environment.\n\n## Vision and Roadmap\n\n### Vision\n\nOur vision is to become a pivotal module in the future of AI-driven development solutions, seamlessly integrating with GitHub to empower LLMs in automatically resolving complex coding tasks.\n\n![Vision Architecture](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/./docs/vision.drawio.svg)\n\n### Roadmap\n\nFor a detailed view of our project roadmap, please visit our [Project Roadmap](https://github.com/users/JetXu-LLM/projects/2).\n\n## Acknowledgments\n\nWe would like to express our gratitude to the following open-source projects for their support and contributions:\n\n- **[LangChain](https://github.com/langchain-ai/langchain)**: For providing the foundational framework that empowers the LLM prompting and processing capabilities in llama-github.\n- **[Jina.ai](https://github.com/jina-ai/reader)**: For offering s.jina.ai API and open source reranker and embedding models that enhance the accuracy and relevance of the generated contexts in llama-github.\n\nTheir contributions have been instrumental in the development of llama-github, and we highly recommend checking out their projects for more innovative solutions.\n\n## Contributing\n\nWe welcome contributions to llama-github! Please see our [contributing guidelines](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/CONTRIBUTING.md) for more information.\n\n## License\n\nThis project is licensed under the terms of the Apache 2.0 license. See the [LICENSE](LICENSE) file for more details.\n\n## Contact\n\nIf you have any questions, suggestions, or feedback, please feel free to reach out to us at [Jet Xu's email](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/mailto:Voldemort.xu@foxmail.com).\n\n---\n\nThank you for choosing llama-github! We hope this library enhances your AI development experience and helps you build powerful applications with ease.\n",
    "ContentSha": "9uwuSakxESmyLicwqpb9te9XJtaLzK41aW7HGRKfVFM=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "Para un uso y ejemplos m√°s avanzados, por favor consulte la [documentaci√≥n](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/docs/usage.md).\n\n## Caracter√≠sticas clave\n\n- **üîç Recuperaci√≥n inteligente de GitHub**: Aproveche el poder de llama-github para recuperar fragmentos de c√≥digo altamente relevantes, issues e informaci√≥n de repositorios en GitHub basados en consultas de usuarios. Nuestras t√©cnicas avanzadas de recuperaci√≥n aseguran que encuentre la informaci√≥n m√°s pertinente r√°pida y eficientemente.\n\n- **‚ö° Cach√© del pool de repositorios**: Llama-github cuenta con un innovador mecanismo de cach√© del pool de repositorios. Al almacenar en cach√© repositorios (incluyendo READMEs, estructuras, c√≥digo y issues) a trav√©s de hilos, llama-github acelera significativamente la eficiencia de b√∫squeda en GitHub y minimiza el consumo de tokens de la API de GitHub. Despliegue llama-github en entornos de producci√≥n multihilo con confianza, sabiendo que funcionar√° de manera √≥ptima y ahorrar√° valiosos recursos.\n\n- **üß† An√°lisis de preguntas impulsado por LLM**: Aproveche modelos de lenguaje de √∫ltima generaci√≥n para analizar preguntas de usuarios y generar estrategias y criterios de b√∫squeda altamente efectivos. Llama-github descompone inteligentemente consultas complejas, garantizando que recupere la informaci√≥n m√°s relevante de la vasta red de repositorios de GitHub.\n\n- **üìö Generaci√≥n de contexto integral**: Genere respuestas ricas y contextualmente relevantes combinando sin problemas la informaci√≥n recuperada de GitHub con las capacidades de razonamiento de modelos de lenguaje avanzados. Llama-github sobresale manejando incluso las preguntas m√°s complejas y extensas, proporcionando respuestas completas y perspicaces que incluyen un contexto amplio para apoyar sus necesidades de desarrollo.\n\n- **üöÄ Excelencia en procesamiento asincr√≥nico**: Llama-github est√° construido desde cero para aprovechar todo el potencial de la programaci√≥n asincr√≥nica. Con mecanismos asincr√≥nicos meticulosamente implementados a lo largo del c√≥digo, llama-github puede manejar m√∫ltiples solicitudes simult√°neamente, aumentando significativamente el rendimiento general. Experimente la diferencia mientras llama-github gestiona eficientemente cargas de trabajo de alto volumen sin comprometer velocidad ni calidad.\n\n- **üîß Integraci√≥n flexible de LLM**: Integre f√°cilmente llama-github con diversos proveedores de LLM, modelos de incrustaci√≥n y modelos de reranking para adaptar las capacidades de la biblioteca a sus requerimientos espec√≠ficos. Nuestra arquitectura extensible le permite personalizar y mejorar la funcionalidad de llama-github, asegurando que se adapte sin problemas a su entorno de desarrollo √∫nico.\n\n- **üîí Opciones robustas de autenticaci√≥n**: Llama-github soporta tanto tokens de acceso personal como autenticaci√≥n mediante GitHub App, brind√°ndole flexibilidad para integrarlo en diferentes configuraciones de desarrollo. Ya sea que sea un desarrollador individual o trabaje dentro de un contexto organizacional, llama-github le ofrece mecanismos de autenticaci√≥n seguros y confiables.\n\n- **üõ†Ô∏è Registro y manejo de errores**: Entendemos la importancia de operaciones fluidas y una resoluci√≥n de problemas sencilla. Por eso llama-github viene equipado con mecanismos comprensivos de registro y manejo de errores. Obtenga informaci√≥n profunda sobre el comportamiento de la biblioteca, diagnostique problemas r√°pidamente y mantenga un flujo de trabajo de desarrollo estable y confiable.\n\n## ü§ñ Pruebe nuestro asistente de revisi√≥n de PR impulsado por IA: LlamaPReview\n\nSi encuentra √∫til llama-github, tambi√©n podr√≠a interesarle nuestro asistente de revisi√≥n de PR de GitHub impulsado por IA, LlamaPReview. Est√° dise√±ado para complementar su flujo de trabajo de desarrollo y mejorar a√∫n m√°s la calidad del c√≥digo.\n\n### Caracter√≠sticas clave de LlamaPReview:\n- üöÄ Instalaci√≥n con un clic, sin configuraci√≥n requerida, ejecuci√≥n totalmente autom√°tica\n- üíØ Actualmente gratuito - no se necesita tarjeta de cr√©dito ni informaci√≥n de pago\n- üß† Revisiones autom√°ticas de PR impulsadas por IA con profunda comprensi√≥n del c√≥digo\n- üåê Soporta m√∫ltiples lenguajes de programaci√≥n\n\n**LlamaPReview utiliza la avanzada recuperaci√≥n de contexto de llama-github y el an√°lisis potenciado por LLM** para proporcionar revisiones de c√≥digo inteligentes y conscientes del contexto. ¬°Es como tener un desarrollador senior, armado con el contexto completo de su repositorio, revisando cada PR autom√°ticamente!\n\nüëâ [Instale LlamaPReview ahora](https://github.com/marketplace/llamapreview/) (Gratis)\n\nUsando llama-github para la recuperaci√≥n de contexto y LlamaPReview para revisiones de c√≥digo, puede crear un entorno de desarrollo potente y potenciado por IA.\n\n## Visi√≥n y hoja de ruta\n\n### Visi√≥n\n\nNuestra visi√≥n es convertirnos en un m√≥dulo clave en el futuro de las soluciones de desarrollo impulsadas por IA, integr√°ndonos perfectamente con GitHub para capacitar a los LLM en la resoluci√≥n autom√°tica de tareas complejas de codificaci√≥n.\n\n![Arquitectura de la visi√≥n](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/./docs/vision.drawio.svg)\n\n### Hoja de ruta\n\nPara una vista detallada de nuestra hoja de ruta del proyecto, por favor visite nuestro [Roadmap del proyecto](https://github.com/users/JetXu-LLM/projects/2).\n\n## Agradecimientos\n\nQueremos expresar nuestra gratitud a los siguientes proyectos de c√≥digo abierto por su apoyo y contribuciones:\n\n- **[LangChain](https://github.com/langchain-ai/langchain)**: Por proporcionar el marco fundamental que potencia las capacidades de prompting y procesamiento de LLM en llama-github.\n- **[Jina.ai](https://github.com/jina-ai/reader)**: Por ofrecer la API s.jina.ai y modelos de reranking e incrustaci√≥n de c√≥digo abierto que mejoran la precisi√≥n y relevancia de los contextos generados en llama-github.\n\nSus contribuciones han sido instrumentales en el desarrollo de llama-github, y recomendamos ampliamente revisar sus proyectos para m√°s soluciones innovadoras.\n\n## Contribuciones\n\n¬°Damos la bienvenida a contribuciones para llama-github! Por favor consulte nuestras [directrices de contribuci√≥n](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/CONTRIBUTING.md) para m√°s informaci√≥n.\n\n## Licencia\n\nEste proyecto est√° licenciado bajo los t√©rminos de la licencia Apache 2.0. Consulte el archivo [LICENSE](LICENSE) para m√°s detalles.\n\n## Contacto\n\nSi tiene alguna pregunta, sugerencia o comentario, no dude en contactarnos en el [correo electr√≥nico de Jet Xu](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/mailto:Voldemort.xu@foxmail.com).\n\n---\n\n¬°Gracias por elegir llama-github! Esperamos que esta biblioteca mejore su experiencia en desarrollo con IA y le ayude a construir aplicaciones potentes con facilidad.\n\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "Para un uso y ejemplos m√°s avanzados, por favor consulte la [documentaci√≥n](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/docs/usage.md)."
      },
      {
        "row": 2,
        "rowsha": "zrMByz3uboJewll5VwM0OlM3JCc+dvchgXugvMGdZyA=",
        "originContent": "For more advanced usage and examples, please refer to the [documentation](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/docs/usage.md).",
        "translatedContent": ""
      },
      {
        "row": 3,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "## Caracter√≠sticas clave"
      },
      {
        "row": 4,
        "rowsha": "khTPM/+Q4D8FMdf3qgrMDcjDejggkuMl1+JmWZMODFI=",
        "originContent": "## Key Features",
        "translatedContent": ""
      },
      {
        "row": 5,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "- **üîç Recuperaci√≥n inteligente de GitHub**: Aproveche el poder de llama-github para recuperar fragmentos de c√≥digo altamente relevantes, issues e informaci√≥n de repositorios en GitHub basados en consultas de usuarios. Nuestras t√©cnicas avanzadas de recuperaci√≥n aseguran que encuentre la informaci√≥n m√°s pertinente r√°pida y eficientemente."
      },
      {
        "row": 6,
        "rowsha": "DfE9NcmRSF011JyFgs3cD/a2VQqPhp+XXqaTnhAtBwc=",
        "originContent": "- **üîç Intelligent GitHub Retrieval**: Harness the power of llama-github to retrieve highly relevant code snippets, issues, and repository information from GitHub based on user queries. Our advanced retrieval techniques ensure you find the most pertinent information quickly and efficiently.",
        "translatedContent": ""
      },
      {
        "row": 7,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "- **‚ö° Cach√© del pool de repositorios**: Llama-github cuenta con un innovador mecanismo de cach√© del pool de repositorios. Al almacenar en cach√© repositorios (incluyendo READMEs, estructuras, c√≥digo y issues) a trav√©s de hilos, llama-github acelera significativamente la eficiencia de b√∫squeda en GitHub y minimiza el consumo de tokens de la API de GitHub. Despliegue llama-github en entornos de producci√≥n multihilo con confianza, sabiendo que funcionar√° de manera √≥ptima y ahorrar√° valiosos recursos."
      },
      {
        "row": 8,
        "rowsha": "OtNyTLgFLD0QDlCwfKWcttMbckHUBj2YJNKV9r+Uc54=",
        "originContent": "- **‚ö° Repository Pool Caching**: Llama-github has an innovative repository pool caching mechanism. By caching repositories (including READMEs, structures, code, and issues) across threads, llama-github significantly accelerates GitHub search retrieval efficiency and minimizes the consumption of GitHub API tokens. Deploy llama-github in multi-threaded production environments with confidence, knowing that it will perform optimally and save you valuable resources.",
        "translatedContent": ""
      },
      {
        "row": 9,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "- **üß† An√°lisis de preguntas impulsado por LLM**: Aproveche modelos de lenguaje de √∫ltima generaci√≥n para analizar preguntas de usuarios y generar estrategias y criterios de b√∫squeda altamente efectivos. Llama-github descompone inteligentemente consultas complejas, garantizando que recupere la informaci√≥n m√°s relevante de la vasta red de repositorios de GitHub."
      },
      {
        "row": 10,
        "rowsha": "JeXb8RZZhv2Wmw97j628XoyPreY+fMdIPsxoUQiEvzw=",
        "originContent": "- **üß† LLM-Powered Question Analysis**: Leverage state-of-the-art language models to analyze user questions and generate highly effective search strategies and criteria. Llama-github intelligently breaks down complex queries, ensuring that you retrieve the most relevant information from GitHub's vast repository network.",
        "translatedContent": ""
      },
      {
        "row": 11,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "- **üìö Generaci√≥n de contexto integral**: Genere respuestas ricas y contextualmente relevantes combinando sin problemas la informaci√≥n recuperada de GitHub con las capacidades de razonamiento de modelos de lenguaje avanzados. Llama-github sobresale manejando incluso las preguntas m√°s complejas y extensas, proporcionando respuestas completas y perspicaces que incluyen un contexto amplio para apoyar sus necesidades de desarrollo."
      },
      {
        "row": 12,
        "rowsha": "yA7pWfx0KVCXQ2Eo49pVkbLR+DABI/mKnMw/tj/sCL0=",
        "originContent": "- **üìö Comprehensive Context Generation**: Generate rich, contextually relevant answers by seamlessly combining information retrieved from GitHub with the reasoning capabilities of advanced language models. Llama-github excels at handling even the most complex and lengthy questions, providing comprehensive and insightful responses that include extensive context to support your development needs.",
        "translatedContent": ""
      },
      {
        "row": 13,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "- **üöÄ Excelencia en procesamiento asincr√≥nico**: Llama-github est√° construido desde cero para aprovechar todo el potencial de la programaci√≥n asincr√≥nica. Con mecanismos asincr√≥nicos meticulosamente implementados a lo largo del c√≥digo, llama-github puede manejar m√∫ltiples solicitudes simult√°neamente, aumentando significativamente el rendimiento general. Experimente la diferencia mientras llama-github gestiona eficientemente cargas de trabajo de alto volumen sin comprometer velocidad ni calidad."
      },
      {
        "row": 14,
        "rowsha": "qku0KFnzN0JDJsFtvSnr1U47mAfoIMLCUgoTAF0FV2Q=",
        "originContent": "- **üöÄ Asynchronous Processing Excellence**: Llama-github is built from the ground up to leverage the full potential of asynchronous programming. With meticulously implemented asynchronous mechanisms woven throughout the codebase, llama-github can handle multiple requests concurrently, significantly boosting overall performance. Experience the difference as llama-github efficiently manages high-volume workloads without compromising on speed or quality.",
        "translatedContent": ""
      },
      {
        "row": 15,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "- **üîß Integraci√≥n flexible de LLM**: Integre f√°cilmente llama-github con diversos proveedores de LLM, modelos de incrustaci√≥n y modelos de reranking para adaptar las capacidades de la biblioteca a sus requerimientos espec√≠ficos. Nuestra arquitectura extensible le permite personalizar y mejorar la funcionalidad de llama-github, asegurando que se adapte sin problemas a su entorno de desarrollo √∫nico."
      },
      {
        "row": 16,
        "rowsha": "0g6jkIpIeIIz2Gt8w6I2VAjPUz51+RDJs7fxVchaN/k=",
        "originContent": "- **üîß Flexible LLM Integration**: Easily integrate llama-github with various LLM providers, embedding models, and reranking models to tailor the library's capabilities to your specific requirements. Our extensible architecture allows you to customize and enhance llama-github's functionality, ensuring that it adapts seamlessly to your unique development environment.",
        "translatedContent": ""
      },
      {
        "row": 17,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "- **üîí Opciones robustas de autenticaci√≥n**: Llama-github soporta tanto tokens de acceso personal como autenticaci√≥n mediante GitHub App, brind√°ndole flexibilidad para integrarlo en diferentes configuraciones de desarrollo. Ya sea que sea un desarrollador individual o trabaje dentro de un contexto organizacional, llama-github le ofrece mecanismos de autenticaci√≥n seguros y confiables."
      },
      {
        "row": 18,
        "rowsha": "WH0+zgaxAP/W/KtIygVDuxydKTKp6imCYyXpqvXpjaM=",
        "originContent": "- **üîí Robust Authentication Options**: Llama-github supports both personal access tokens and GitHub App authentication, providing you with the flexibility to integrate it into different development setups. Whether you're an individual developer or working within an organizational context, llama-github has you covered with secure and reliable authentication mechanisms.",
        "translatedContent": ""
      },
      {
        "row": 19,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "- **üõ†Ô∏è Registro y manejo de errores**: Entendemos la importancia de operaciones fluidas y una resoluci√≥n de problemas sencilla. Por eso llama-github viene equipado con mecanismos comprensivos de registro y manejo de errores. Obtenga informaci√≥n profunda sobre el comportamiento de la biblioteca, diagnostique problemas r√°pidamente y mantenga un flujo de trabajo de desarrollo estable y confiable."
      },
      {
        "row": 20,
        "rowsha": "IYhTxjMvy72M7T9kEBfrXUNMz08qwsXzETVoE3WSNyQ=",
        "originContent": "- **üõ†Ô∏è Logging and Error Handling**: We understand the importance of smooth operations and easy troubleshooting. That's why llama-github comes equipped with comprehensive logging and error handling mechanisms. Gain deep insights into the library's behavior, quickly diagnose issues, and maintain a stable and reliable development workflow.",
        "translatedContent": ""
      },
      {
        "row": 21,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "## ü§ñ Pruebe nuestro asistente de revisi√≥n de PR impulsado por IA: LlamaPReview"
      },
      {
        "row": 22,
        "rowsha": "QDeqAvaQEIQHPYjwq2KF5Bw3a76EiPq7ebbsGNKcRI8=",
        "originContent": "## ü§ñ Try Our AI-Powered PR Review Assistant: LlamaPReview",
        "translatedContent": ""
      },
      {
        "row": 23,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "Si encuentra √∫til llama-github, tambi√©n podr√≠a interesarle nuestro asistente de revisi√≥n de PR de GitHub impulsado por IA, LlamaPReview. Est√° dise√±ado para complementar su flujo de trabajo de desarrollo y mejorar a√∫n m√°s la calidad del c√≥digo."
      },
      {
        "row": 24,
        "rowsha": "laWUe+J402emMP2V1JeMqFpYefA8HTKWoI+lq7NfoyE=",
        "originContent": "If you find llama-github useful, you might also be interested in our AI-powered GitHub PR review assistant, LlamaPReview. It's designed to complement your development workflow and further enhance code quality.",
        "translatedContent": ""
      },
      {
        "row": 25,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "### Caracter√≠sticas clave de LlamaPReview:"
      },
      {
        "row": 26,
        "rowsha": "J3M87xxuLQISS/m0fiv7phjnw7mYaznst6rel6n7MyY=",
        "originContent": "### Key Features of LlamaPReview:",
        "translatedContent": "- üöÄ Instalaci√≥n con un clic, sin configuraci√≥n requerida, ejecuci√≥n totalmente autom√°tica"
      },
      {
        "row": 27,
        "rowsha": "dGBd2SxNdlW1UATPSu01Iq95yCVz8fXbl7xxHqDYI7E=",
        "originContent": "- üöÄ One-click installation, zero configuration required, fully auto-run",
        "translatedContent": "- üíØ Actualmente gratuito - no se necesita tarjeta de cr√©dito ni informaci√≥n de pago"
      },
      {
        "row": 28,
        "rowsha": "EP9hYUs4aYVAzXcYQyCGf3bjwo64OjAsqQHIN75oW60=",
        "originContent": "- üíØ Currently free to use - no credit card or payment info needed",
        "translatedContent": "- üß† Revisiones autom√°ticas de PR impulsadas por IA con profunda comprensi√≥n del c√≥digo"
      },
      {
        "row": 29,
        "rowsha": "jjWF/iUqSzPriHJ5iiFIq0Q6Pzx+gzPlnLu0Z4wmsSg=",
        "originContent": "- üß† AI-powered, automatic PR reviews with deep code understanding",
        "translatedContent": "- üåê Soporta m√∫ltiples lenguajes de programaci√≥n"
      },
      {
        "row": 30,
        "rowsha": "Dsl+HsDM5NGI480TDo6eaFqgDcaofr3TDhLbUghSXhU=",
        "originContent": "- üåê Supports multiple programming languages",
        "translatedContent": ""
      },
      {
        "row": 31,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "**LlamaPReview utiliza la avanzada recuperaci√≥n de contexto de llama-github y el an√°lisis potenciado por LLM** para proporcionar revisiones de c√≥digo inteligentes y conscientes del contexto. ¬°Es como tener un desarrollador senior, armado con el contexto completo de su repositorio, revisando cada PR autom√°ticamente!"
      },
      {
        "row": 32,
        "rowsha": "GrzJg4j2iz94pupBQwJnFffhmsJ5IO9OkhqYvj0QEmo=",
        "originContent": "**LlamaPReview utilizes llama-github's advanced context retrieval and LLM-powered analysis** to provide intelligent, context-aware code reviews. It's like having a senior developer, armed with the full context of your repository, review every PR automatically!",
        "translatedContent": ""
      },
      {
        "row": 33,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "üëâ [Instale LlamaPReview ahora](https://github.com/marketplace/llamapreview/) (Gratis)"
      },
      {
        "row": 34,
        "rowsha": "4qGUTknerL/UTVikcUjFHvKzZlWho9opuf58fSIypyk=",
        "originContent": "üëâ [Install LlamaPReview Now](https://github.com/marketplace/llamapreview/) (Free)",
        "translatedContent": ""
      },
      {
        "row": 35,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "Usando llama-github para la recuperaci√≥n de contexto y LlamaPReview para revisiones de c√≥digo, puede crear un entorno de desarrollo potente y potenciado por IA."
      },
      {
        "row": 36,
        "rowsha": "luTTMbXm2ikxAkHhFfh2iG9uPEwMYBRd2lolUoOY+3o=",
        "originContent": "By using llama-github for context retrieval and LlamaPReview for code reviews, you can create a powerful, AI-enhanced development environment.",
        "translatedContent": ""
      },
      {
        "row": 37,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "## Visi√≥n y hoja de ruta"
      },
      {
        "row": 38,
        "rowsha": "W2b655gztUgECPmTnBIkK/WbBo7d68AbNAjMtkHS5xY=",
        "originContent": "## Vision and Roadmap",
        "translatedContent": ""
      },
      {
        "row": 39,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "### Visi√≥n"
      },
      {
        "row": 40,
        "rowsha": "Ewakmoa/Yb8fcDlChA12w7kAXVMFh8OrCLwVCTwIl84=",
        "originContent": "### Vision",
        "translatedContent": ""
      },
      {
        "row": 41,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "Nuestra visi√≥n es convertirnos en un m√≥dulo clave en el futuro de las soluciones de desarrollo impulsadas por IA, integr√°ndonos perfectamente con GitHub para capacitar a los LLM en la resoluci√≥n autom√°tica de tareas complejas de codificaci√≥n."
      },
      {
        "row": 42,
        "rowsha": "0e6GYQC4W2Y8Ky5Q9UNeMwDc+ebEjDIUb9h4gSLQJaI=",
        "originContent": "Our vision is to become a pivotal module in the future of AI-driven development solutions, seamlessly integrating with GitHub to empower LLMs in automatically resolving complex coding tasks.",
        "translatedContent": ""
      },
      {
        "row": 43,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "![Arquitectura de la visi√≥n](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/./docs/vision.drawio.svg)"
      },
      {
        "row": 44,
        "rowsha": "e3eGMrQR9LxN0lPlezIImRzi4tUu6n/GFfZsq5SBP4I=",
        "originContent": "![Vision Architecture](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/./docs/vision.drawio.svg)",
        "translatedContent": ""
      },
      {
        "row": 45,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "### Hoja de ruta"
      },
      {
        "row": 46,
        "rowsha": "Q0D6oxy93TTXOZDvIiuco/ghaytG064tWvZdnLoKnOw=",
        "originContent": "### Roadmap",
        "translatedContent": ""
      },
      {
        "row": 47,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "Para una vista detallada de nuestra hoja de ruta del proyecto, por favor visite nuestro [Roadmap del proyecto](https://github.com/users/JetXu-LLM/projects/2)."
      },
      {
        "row": 48,
        "rowsha": "UHmL4/lEZk2jitjRxUVuHtD8JilL4OTzFLbU8R72Ymc=",
        "originContent": "For a detailed view of our project roadmap, please visit our [Project Roadmap](https://github.com/users/JetXu-LLM/projects/2).",
        "translatedContent": ""
      },
      {
        "row": 49,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "## Agradecimientos"
      },
      {
        "row": 50,
        "rowsha": "N66ywbuGccMYNTyswaMSnFOlWqX+iaYP/myGJqr1tHo=",
        "originContent": "## Acknowledgments",
        "translatedContent": ""
      },
      {
        "row": 51,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "Queremos expresar nuestra gratitud a los siguientes proyectos de c√≥digo abierto por su apoyo y contribuciones:"
      },
      {
        "row": 52,
        "rowsha": "WodCIp8BqxoCo7bxE7dxagf/Dvpvw7nWeECf0qG6FGI=",
        "originContent": "We would like to express our gratitude to the following open-source projects for their support and contributions:",
        "translatedContent": ""
      },
      {
        "row": 53,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "- **[LangChain](https://github.com/langchain-ai/langchain)**: Por proporcionar el marco fundamental que potencia las capacidades de prompting y procesamiento de LLM en llama-github."
      },
      {
        "row": 54,
        "rowsha": "HBIRZKkbsYOXsJY2Xepu1VxTAAdh869qSnsGbJ0cIg0=",
        "originContent": "- **[LangChain](https://github.com/langchain-ai/langchain)**: For providing the foundational framework that empowers the LLM prompting and processing capabilities in llama-github.",
        "translatedContent": "- **[Jina.ai](https://github.com/jina-ai/reader)**: Por ofrecer la API s.jina.ai y modelos de reranking e incrustaci√≥n de c√≥digo abierto que mejoran la precisi√≥n y relevancia de los contextos generados en llama-github."
      },
      {
        "row": 55,
        "rowsha": "l7sjWwbh0OUJwk4+yJE2ZbVGypyaPrzI1YYMP7Uw9X0=",
        "originContent": "- **[Jina.ai](https://github.com/jina-ai/reader)**: For offering s.jina.ai API and open source reranker and embedding models that enhance the accuracy and relevance of the generated contexts in llama-github.",
        "translatedContent": ""
      },
      {
        "row": 56,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "Sus contribuciones han sido instrumentales en el desarrollo de llama-github, y recomendamos ampliamente revisar sus proyectos para m√°s soluciones innovadoras."
      },
      {
        "row": 57,
        "rowsha": "hrChp1vDZFs3UZia39niD4Kx9hT0wKUMxSSiiyYyi7A=",
        "originContent": "Their contributions have been instrumental in the development of llama-github, and we highly recommend checking out their projects for more innovative solutions.",
        "translatedContent": ""
      },
      {
        "row": 58,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "## Contribuciones"
      },
      {
        "row": 59,
        "rowsha": "R5ZPLZ4vkE9tjX5qe8QB7AkTfWZsuNTGFLFKMp2KUzM=",
        "originContent": "## Contributing",
        "translatedContent": ""
      },
      {
        "row": 60,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "¬°Damos la bienvenida a contribuciones para llama-github! Por favor consulte nuestras [directrices de contribuci√≥n](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/CONTRIBUTING.md) para m√°s informaci√≥n."
      },
      {
        "row": 61,
        "rowsha": "JUWgAoIn9VhOEzmNL5dlAlHwcmo7N2Rm2GNx0g5Rijs=",
        "originContent": "We welcome contributions to llama-github! Please see our [contributing guidelines](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/CONTRIBUTING.md) for more information.",
        "translatedContent": ""
      },
      {
        "row": 62,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "## Licencia"
      },
      {
        "row": 63,
        "rowsha": "bFSaVtsB4CHySNjaeCiaMZfT24b+DTbTM4HQ38cR6Lw=",
        "originContent": "## License",
        "translatedContent": ""
      },
      {
        "row": 64,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "Este proyecto est√° licenciado bajo los t√©rminos de la licencia Apache 2.0. Consulte el archivo [LICENSE](LICENSE) para m√°s detalles."
      },
      {
        "row": 65,
        "rowsha": "hUzQdbczna0Cd3FyH+bhS5SWBDzmVQyA+nCi/UZO6VI=",
        "originContent": "This project is licensed under the terms of the Apache 2.0 license. See the [LICENSE](LICENSE) file for more details.",
        "translatedContent": ""
      },
      {
        "row": 66,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "## Contacto"
      },
      {
        "row": 67,
        "rowsha": "ZX9nbduzXgvmAaK8yTd+tNgwR7cV79HXV/+xbvL8suw=",
        "originContent": "## Contact",
        "translatedContent": ""
      },
      {
        "row": 68,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "Si tiene alguna pregunta, sugerencia o comentario, no dude en contactarnos en el [correo electr√≥nico de Jet Xu](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/mailto:Voldemort.xu@foxmail.com)."
      },
      {
        "row": 69,
        "rowsha": "sZud9u8DDdJRsIyc+T0tdusx1FWC0pdv0Yn2hhndP9o=",
        "originContent": "If you have any questions, suggestions, or feedback, please feel free to reach out to us at [Jet Xu's email](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/mailto:Voldemort.xu@foxmail.com).",
        "translatedContent": ""
      },
      {
        "row": 70,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "---"
      },
      {
        "row": 71,
        "rowsha": "yz+R1U7uMOU+NbK5mQX3Dxae1Un9eJCdPawt78ntjTs=",
        "originContent": "---",
        "translatedContent": ""
      },
      {
        "row": 72,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "¬°Gracias por elegir llama-github! Esperamos que esta biblioteca mejore su experiencia en desarrollo con IA y le ayude a construir aplicaciones potentes con facilidad."
      },
      {
        "row": 73,
        "rowsha": "98t5imS5RZt8kUxGAXqZcPmlZMcru27Gl/g31hb3g/c=",
        "originContent": "Thank you for choosing llama-github! We hope this library enhances your AI development experience and helps you build powerful applications with ease.",
        "translatedContent": ""
      },
      {
        "row": 74,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  }
]