[
  {
    "Id": 1,
    "Content": "\n<div align=\"right\">\n  <details>\n    <summary >üåê Language</summary>\n    <div>\n      <div align=\"center\">\n        <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=en\">English</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=zh-CN\">ÁÆÄ‰Ωì‰∏≠Êñá</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=zh-TW\">ÁπÅÈ´î‰∏≠Êñá</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=ja\">Êó•Êú¨Ë™û</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=ko\">ÌïúÍµ≠Ïñ¥</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=hi\">‡§π‡§ø‡§®‡•ç‡§¶‡•Ä</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=th\">‡πÑ‡∏ó‡∏¢</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=fr\">Fran√ßais</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=de\">Deutsch</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=es\">Espa√±ol</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=it\">Italiano</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=ru\">–†—É—Å—Å–∫–∏–π</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=pt\">Portugu√™s</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=nl\">Nederlands</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=pl\">Polski</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=ar\">ÿßŸÑÿπÿ±ÿ®Ÿäÿ©</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=fa\">ŸÅÿßÿ±ÿ≥€å</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=tr\">T√ºrk√ße</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=vi\">Ti·∫øng Vi·ªát</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=id\">Bahasa Indonesia</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=as\">‡¶Ö‡¶∏‡¶Æ‡ßÄ‡¶Ø‡¶º‡¶æ</\n      </div>\n    </div>\n  </details>\n</div>\n\n# llama-github\n\n[Detail Document] https://deepwiki.com/JetXu-LLM/llama-github\n\n[![PyPI version](https://badge.fury.io/py/llama-github.svg)](https://badge.fury.io/py/llama-github)\n[![Downloads](https://static.pepy.tech/badge/Llama-github)](https://pepy.tech/project/Llama-github)\n[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)\n\nLlama-github is a powerful tool that helps you retrieve(based on Agentic RAG) the most relevant code snippets, issues, and repository information from GitHub based on your queries, transforming them into valuable knowledge context. It empowers LLM Chatbots, AI Agents, and Auto-dev Agents to solve complex coding tasks. Whether you're a developer looking for quick solutions or an engineer implementing advanced Auto Dev AI Agents, llama-github makes it easy and efficient.\n\nIf you like this project or believe it has potential, please give it a ‚≠êÔ∏è. Your support is our greatest motivation!\n\n## Architecture\n![High Level Architecture](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/./docs/high_level_architecture.drawio.svg)\n\n## Installation",
    "ContentSha": "luGjPJ0t2eUH+w8RDBgGqCVyQiIo+mel0icgkq5phQc=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "\n<div align=\"right\">\n  <details>\n    <summary >üåê Ng√¥n ng·ªØ</summary>\n    <div>\n      <div align=\"center\">\n        <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=en\">English</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=zh-CN\">ÁÆÄ‰Ωì‰∏≠Êñá</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=zh-TW\">ÁπÅÈ´î‰∏≠Êñá</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=ja\">Êó•Êú¨Ë™û</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=ko\">ÌïúÍµ≠Ïñ¥</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=hi\">‡§π‡§ø‡§®‡•ç‡§¶‡•Ä</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=th\">‡πÑ‡∏ó‡∏¢</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=fr\">Fran√ßais</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=de\">Deutsch</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=es\">Espa√±ol</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=it\">Italiano</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=ru\">–†—É—Å—Å–∫–∏–π</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=pt\">Portugu√™s</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=nl\">Nederlands</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=pl\">Polski</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=ar\">ÿßŸÑÿπÿ±ÿ®Ÿäÿ©</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=fa\">ŸÅÿßÿ±ÿ≥€å</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=tr\">T√ºrk√ße</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=vi\">Ti·∫øng Vi·ªát</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=id\">Bahasa Indonesia</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=as\">‡¶Ö‡¶∏‡¶Æ‡ßÄ‡¶Ø‡¶º‡¶æ</\n      </div>\n    </div>\n  </details>\n</div>\n\n# llama-github\n\n[T√†i li·ªáu chi ti·∫øt] https://deepwiki.com/JetXu-LLM/llama-github\n\n[![Phi√™n b·∫£n PyPI](https://badge.fury.io/py/llama-github.svg)](https://badge.fury.io/py/llama-github)\n[![L∆∞·ª£t t·∫£i v·ªÅ](https://static.pepy.tech/badge/Llama-github)](https://pepy.tech/project/Llama-github)\n[![Gi·∫•y ph√©p](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)\n\nLlama-github l√† m·ªôt c√¥ng c·ª• m·∫°nh m·∫Ω gi√∫p b·∫°n truy xu·∫•t (d·ª±a tr√™n Agentic RAG) c√°c ƒëo·∫°n m√£, v·∫•n ƒë·ªÅ v√† th√¥ng tin kho l∆∞u tr·ªØ ph√π h·ª£p nh·∫•t t·ª´ GitHub d·ª±a tr√™n truy v·∫•n c·ªßa b·∫°n, chuy·ªÉn ƒë·ªïi ch√∫ng th√†nh ng·ªØ c·∫£nh ki·∫øn th·ª©c gi√° tr·ªã. N√≥ tƒÉng c∆∞·ªùng cho c√°c Chatbot LLM, AI Agent v√† Auto-dev Agent ƒë·ªÉ gi·∫£i quy·∫øt c√°c nhi·ªám v·ª• l·∫≠p tr√¨nh ph·ª©c t·∫°p. D√π b·∫°n l√† l·∫≠p tr√¨nh vi√™n c·∫ßn gi·∫£i ph√°p nhanh hay k·ªπ s∆∞ tri·ªÉn khai c√°c Auto Dev AI Agent ti√™n ti·∫øn, llama-github ƒë·ªÅu gi√∫p c√¥ng vi·ªác tr·ªü n√™n d·ªÖ d√†ng v√† hi·ªáu qu·∫£.\n\nN·∫øu b·∫°n th√≠ch d·ª± √°n n√†y ho·∫∑c tin r·∫±ng n√≥ c√≥ ti·ªÅm nƒÉng, h√£y cho m·ªôt ‚≠êÔ∏è. S·ª± ·ªßng h·ªô c·ªßa b·∫°n l√† ƒë·ªông l·ª±c l·ªõn nh·∫•t c·ªßa ch√∫ng t√¥i!\n\n## Ki·∫øn tr√∫c\n![Ki·∫øn tr√∫c c·∫•p cao](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/./docs/high_level_architecture.drawio.svg)\n\n## C√†i ƒë·∫∑t",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 2,
        "rowsha": "cWgam+tnnXudu7i74+ahMEGk/A9dQS+EwWLAIfi3dHk=",
        "originContent": "<div align=\"right\">",
        "translatedContent": "<div align=\"right\">"
      },
      {
        "row": 3,
        "rowsha": "orOcu5ARna/hb3RUkj6dBI8pHTM3WHeTvby17l5E0h0=",
        "originContent": "  <details>",
        "translatedContent": "  <details>"
      },
      {
        "row": 4,
        "rowsha": "TtgkLzblnvP0q9aAIVXt6s2LczXjy5k+QvHKcU0/5Ms=",
        "originContent": "    <summary >üåê Language</summary>",
        "translatedContent": "    <summary >üåê Ng√¥n ng·ªØ</summary>"
      },
      {
        "row": 5,
        "rowsha": "fZtk4rPTAJEEslnbhSVkHEcPlsctYSzAV7CDPL3rJmA=",
        "originContent": "    <div>",
        "translatedContent": "    <div>"
      },
      {
        "row": 6,
        "rowsha": "9KQxOeJSigvTmGWO+mtnl8kZY9zQfueoy8sk4lYm09Q=",
        "originContent": "      <div align=\"center\">",
        "translatedContent": "      <div align=\"center\">"
      },
      {
        "row": 7,
        "rowsha": "HkJ4Gkepsmtc5YEEOiqUG3+NzfI0rf4IVUDgqFAmscs=",
        "originContent": "        <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=en\">English</a>",
        "translatedContent": "        <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=en\">English</a>"
      },
      {
        "row": 8,
        "rowsha": "SS8k2BQkHAHxyWP2X90nPl4mRZWm3fwXGqGF7mjnz18=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=zh-CN\">ÁÆÄ‰Ωì‰∏≠Êñá</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=zh-CN\">ÁÆÄ‰Ωì‰∏≠Êñá</a>"
      },
      {
        "row": 9,
        "rowsha": "VrMYTJ2mzoZzeIKdl57fntnJgzWRQqxW+Hh05WTobsc=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=zh-TW\">ÁπÅÈ´î‰∏≠Êñá</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=zh-TW\">ÁπÅÈ´î‰∏≠Êñá</a>"
      },
      {
        "row": 10,
        "rowsha": "c+DqTRbRnir4FoupjpEksFzVENBVWRYltmlpDbwQZmM=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=ja\">Êó•Êú¨Ë™û</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=ja\">Êó•Êú¨Ë™û</a>"
      },
      {
        "row": 11,
        "rowsha": "Tm7I5B+gkMpCeJ3LR+BslLE5wbSUneyFmLReBj+Kuws=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=ko\">ÌïúÍµ≠Ïñ¥</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=ko\">ÌïúÍµ≠Ïñ¥</a>"
      },
      {
        "row": 12,
        "rowsha": "wfZ0J7KdM7EX/cxK3wFAeE2ngExW4GfEYqHcAGlGx0w=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=hi\">‡§π‡§ø‡§®‡•ç‡§¶‡•Ä</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=hi\">‡§π‡§ø‡§®‡•ç‡§¶‡•Ä</a>"
      },
      {
        "row": 13,
        "rowsha": "y2QtQCnUvpYYte3U998DjX4FmVJMdwyXZ6wpYmbQkLE=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=th\">‡πÑ‡∏ó‡∏¢</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=th\">‡πÑ‡∏ó‡∏¢</a>"
      },
      {
        "row": 14,
        "rowsha": "zIupl7qEGAUFd0PjTxnqfYLAOYVxukVObZ2TvLzJhFI=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=fr\">Fran√ßais</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=fr\">Fran√ßais</a>"
      },
      {
        "row": 15,
        "rowsha": "NeTDxlUu1SaaYA+ZU+IrCgYKslSqZUFfuhtr46HJnA0=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=de\">Deutsch</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=de\">Deutsch</a>"
      },
      {
        "row": 16,
        "rowsha": "0ltGddRJZJCJAdD4E6lPYrnG+o9jxtvzFgZ6J422BVM=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=es\">Espa√±ol</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=es\">Espa√±ol</a>"
      },
      {
        "row": 17,
        "rowsha": "bzUdBLPtDNoKHOYQKJtE2KKD9trvdid+RiSJUXJ06jY=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=it\">Italiano</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=it\">Italiano</a>"
      },
      {
        "row": 18,
        "rowsha": "0pozScPeqLIHLCyJkRlRQjDqqKb8HWwWqCv6uaxalEY=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=ru\">–†—É—Å—Å–∫–∏–π</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=ru\">–†—É—Å—Å–∫–∏–π</a>"
      },
      {
        "row": 19,
        "rowsha": "ACT6kxJUtjo44NDX/ea/HxspYPgjmIuENrgcnxQYNEc=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=pt\">Portugu√™s</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=pt\">Portugu√™s</a>"
      },
      {
        "row": 20,
        "rowsha": "P5r7piMIRIzTPNX8NrKqGo+P1glz8ZRuJCLyQL24/LA=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=nl\">Nederlands</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=nl\">Nederlands</a>"
      },
      {
        "row": 21,
        "rowsha": "ZGMoXno6QdwcE1MCQ6a+39T9cMR9m1YyVj19nEOHOR8=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=pl\">Polski</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=pl\">Polski</a>"
      },
      {
        "row": 22,
        "rowsha": "VKZ+5aGayrqfPfJYP0j0/ap6ocirm1axw5vVvu7xsEE=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=ar\">ÿßŸÑÿπÿ±ÿ®Ÿäÿ©</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=ar\">ÿßŸÑÿπÿ±ÿ®Ÿäÿ©</a>"
      },
      {
        "row": 23,
        "rowsha": "CWIbKiayiPOGqPcuulT54J/JKB9czskFXkMCgTgHrZs=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=fa\">ŸÅÿßÿ±ÿ≥€å</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=fa\">ŸÅÿßÿ±ÿ≥€å</a>"
      },
      {
        "row": 24,
        "rowsha": "I1WcwpKhgv19NGCtlw+KLX03QSTLreFKCC9Ta0pFqIs=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=tr\">T√ºrk√ße</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=tr\">T√ºrk√ße</a>"
      },
      {
        "row": 25,
        "rowsha": "gIl9QJ2GwM0yfNYEXpcS2/xbtyKJbynqn4H4tnOyU2c=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=vi\">Ti·∫øng Vi·ªát</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=vi\">Ti·∫øng Vi·ªát</a>"
      },
      {
        "row": 26,
        "rowsha": "sMhilkGyfjhl6TXDHf4CKYnKDjhJR8fFg2lWQtaLDKc=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=id\">Bahasa Indonesia</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=id\">Bahasa Indonesia</a>"
      },
      {
        "row": 27,
        "rowsha": "SFIUIQN+2TXGoifui/NZlin5QtiRQtdF5of1FBBu7Gk=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=as\">‡¶Ö‡¶∏‡¶Æ‡ßÄ‡¶Ø‡¶º‡¶æ</",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=as\">‡¶Ö‡¶∏‡¶Æ‡ßÄ‡¶Ø‡¶º‡¶æ</"
      },
      {
        "row": 28,
        "rowsha": "0OM5wNEm0TO56MEBvQzL7AUZM7/3OpgIeqRf2zFre3Q=",
        "originContent": "      </div>",
        "translatedContent": "      </div>"
      },
      {
        "row": 29,
        "rowsha": "fcjTfY+fs8YnY5slBs1sZvWPAqEQR7tzaBDO54skkGQ=",
        "originContent": "    </div>",
        "translatedContent": "    </div>"
      },
      {
        "row": 30,
        "rowsha": "+fQNH2ldI7UM/rqRscP3hUSWAmw1HvQ2wEKDN8JagT0=",
        "originContent": "  </details>",
        "translatedContent": "  </details>"
      },
      {
        "row": 31,
        "rowsha": "qsMmUbEPVnxGG5tPJV1vsfpoWbU2jYvZpRr5IKshzyM=",
        "originContent": "</div>",
        "translatedContent": "</div>"
      },
      {
        "row": 32,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 33,
        "rowsha": "cAI8B2fw5xCydddeNcosOFY2wrQw8An1lrdomk97KBc=",
        "originContent": "# llama-github",
        "translatedContent": "# llama-github"
      },
      {
        "row": 34,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 35,
        "rowsha": "jSTPMiMb5qDjmRYlxqDSx6zbsKYKOv4c6HQQgjbDUqo=",
        "originContent": "[Detail Document] https://deepwiki.com/JetXu-LLM/llama-github",
        "translatedContent": "[T√†i li·ªáu chi ti·∫øt] https://deepwiki.com/JetXu-LLM/llama-github"
      },
      {
        "row": 36,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 37,
        "rowsha": "48lo1Cg6fyAcQl554s/7eKSc41UYvSn/CD6yxtLVgjY=",
        "originContent": "[![PyPI version](https://badge.fury.io/py/llama-github.svg)](https://badge.fury.io/py/llama-github)",
        "translatedContent": "[![Phi√™n b·∫£n PyPI](https://badge.fury.io/py/llama-github.svg)](https://badge.fury.io/py/llama-github)"
      },
      {
        "row": 38,
        "rowsha": "VG3AfiYLkBPipFZPAt/fJt5jj8aI773UKbmI1Z/kc2M=",
        "originContent": "[![Downloads](https://static.pepy.tech/badge/Llama-github)](https://pepy.tech/project/Llama-github)",
        "translatedContent": "[![L∆∞·ª£t t·∫£i v·ªÅ](https://static.pepy.tech/badge/Llama-github)](https://pepy.tech/project/Llama-github)"
      },
      {
        "row": 39,
        "rowsha": "U0vs77tGfFYY+r4ScaOhTOZDgt8vSKCUyj59tU13ZtE=",
        "originContent": "[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)",
        "translatedContent": "[![Gi·∫•y ph√©p](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)"
      },
      {
        "row": 40,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 41,
        "rowsha": "y7xsY1R0s8pmwDQukNS2PQ5JqK6CRs8AwuPrZkBKiT8=",
        "originContent": "Llama-github is a powerful tool that helps you retrieve(based on Agentic RAG) the most relevant code snippets, issues, and repository information from GitHub based on your queries, transforming them into valuable knowledge context. It empowers LLM Chatbots, AI Agents, and Auto-dev Agents to solve complex coding tasks. Whether you're a developer looking for quick solutions or an engineer implementing advanced Auto Dev AI Agents, llama-github makes it easy and efficient.",
        "translatedContent": "Llama-github l√† m·ªôt c√¥ng c·ª• m·∫°nh m·∫Ω gi√∫p b·∫°n truy xu·∫•t (d·ª±a tr√™n Agentic RAG) c√°c ƒëo·∫°n m√£, v·∫•n ƒë·ªÅ v√† th√¥ng tin kho l∆∞u tr·ªØ ph√π h·ª£p nh·∫•t t·ª´ GitHub d·ª±a tr√™n truy v·∫•n c·ªßa b·∫°n, chuy·ªÉn ƒë·ªïi ch√∫ng th√†nh ng·ªØ c·∫£nh ki·∫øn th·ª©c gi√° tr·ªã. N√≥ tƒÉng c∆∞·ªùng cho c√°c Chatbot LLM, AI Agent v√† Auto-dev Agent ƒë·ªÉ gi·∫£i quy·∫øt c√°c nhi·ªám v·ª• l·∫≠p tr√¨nh ph·ª©c t·∫°p. D√π b·∫°n l√† l·∫≠p tr√¨nh vi√™n c·∫ßn gi·∫£i ph√°p nhanh hay k·ªπ s∆∞ tri·ªÉn khai c√°c Auto Dev AI Agent ti√™n ti·∫øn, llama-github ƒë·ªÅu gi√∫p c√¥ng vi·ªác tr·ªü n√™n d·ªÖ d√†ng v√† hi·ªáu qu·∫£."
      },
      {
        "row": 42,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 43,
        "rowsha": "6h9r25r7afHOT0YHlaj7xv1WU2JfjWqSqLUM7UgJNfQ=",
        "originContent": "If you like this project or believe it has potential, please give it a ‚≠êÔ∏è. Your support is our greatest motivation!",
        "translatedContent": "N·∫øu b·∫°n th√≠ch d·ª± √°n n√†y ho·∫∑c tin r·∫±ng n√≥ c√≥ ti·ªÅm nƒÉng, h√£y cho m·ªôt ‚≠êÔ∏è. S·ª± ·ªßng h·ªô c·ªßa b·∫°n l√† ƒë·ªông l·ª±c l·ªõn nh·∫•t c·ªßa ch√∫ng t√¥i!"
      },
      {
        "row": 44,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 45,
        "rowsha": "p+VkcrEb08g4vIGZYB9aVScRKgA8afv5WwErwTVzoZM=",
        "originContent": "## Architecture",
        "translatedContent": "## Ki·∫øn tr√∫c"
      },
      {
        "row": 46,
        "rowsha": "TiSukfY/+ter5MJ39DMtNdHlqRXwhZFkP3uTdAfvA0c=",
        "originContent": "![High Level Architecture](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/./docs/high_level_architecture.drawio.svg)",
        "translatedContent": "![Ki·∫øn tr√∫c c·∫•p cao](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/./docs/high_level_architecture.drawio.svg)"
      },
      {
        "row": 47,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 48,
        "rowsha": "oV0SUDvwD2VN8Gi9nlr2JZ2xcDrASmE2W5kc5SVX5eo=",
        "originContent": "## Installation",
        "translatedContent": "## C√†i ƒë·∫∑t"
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 2,
    "Content": "```\npip install llama-github\n```",
    "ContentSha": "A7Ioj19mKQ2poo2/SNNEl/PUNM9x+13/7/ncgppdcgY=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```\npip install llama-github\n```",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      },
      {
        "row": 2,
        "rowsha": "HUzQ8Fuh/Wg8Hu8KR8bezJLbFVpPKMpf5Pa7xDY6vYM=",
        "originContent": "pip install llama-github",
        "translatedContent": "pip install llama-github"
      },
      {
        "row": 3,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      }
    ],
    "IsCodeBlock": true
  },
  {
    "Id": 3,
    "Content": "\n## Usage\n\nHere's a simple example of how to use llama-github:\n",
    "ContentSha": "oqzkRVGHtTMxKJniKYy+bJRBu/B3l8AYVVo5suNCmR4=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "\n## S·ª≠ d·ª•ng\n\nD∆∞·ªõi ƒë√¢y l√† m·ªôt v√≠ d·ª• ƒë∆°n gi·∫£n v·ªÅ c√°ch s·ª≠ d·ª•ng llama-github:\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 2,
        "rowsha": "Y7/WGgVhslWiyqCi463Qkcp+Mn8voGpAfLsv80G4WNg=",
        "originContent": "## Usage",
        "translatedContent": "## S·ª≠ d·ª•ng"
      },
      {
        "row": 3,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 4,
        "rowsha": "4zRpXijfFggW+Fd/VZ8qaLkuJwnjePE96Hy1hPxOIRE=",
        "originContent": "Here's a simple example of how to use llama-github:",
        "translatedContent": "D∆∞·ªõi ƒë√¢y l√† m·ªôt v√≠ d·ª• ƒë∆°n gi·∫£n v·ªÅ c√°ch s·ª≠ d·ª•ng llama-github:"
      },
      {
        "row": 5,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 4,
    "Content": "```python\nfrom llama_github import GithubRAG\n\n# Initialize GithubRAG with your credentials\ngithub_rag = GithubRAG(\n    github_access_token=\"your_github_access_token\", \n    openai_api_key=\"your_openai_api_key\", # Optional in Simple Mode\n    jina_api_key=\"your_jina_api_key\" # Optional - unless you want high concurrency production deployment (s.jina.ai API will be used in llama-github)\n)\n\n# Retrieve context for a coding question (simple_mode is default set to False)\nquery = \"How to create a NumPy array in Python?\"\ncontext = github_rag.retrieve_context(\n    query, # In professional mode, one query will take nearly 1 min to generate final contexts. You could set log level to INFO to monitor the retrieval progress\n    # simple_mode = True\n)\n\nprint(context)\n```",
    "ContentSha": "HXBtstD3V5wfKLk68/A2T/KFqRB/TtW5s0tq89CzhFU=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```python\nfrom llama_github import GithubRAG\n\n# Initialize GithubRAG with your credentials\ngithub_rag = GithubRAG(\n    github_access_token=\"your_github_access_token\", \n    openai_api_key=\"your_openai_api_key\", # Optional in Simple Mode\n    jina_api_key=\"your_jina_api_key\" # Optional - unless you want high concurrency production deployment (s.jina.ai API will be used in llama-github)\n)\n\n# Retrieve context for a coding question (simple_mode is default set to False)\nquery = \"How to create a NumPy array in Python?\"\ncontext = github_rag.retrieve_context(\n    query, # In professional mode, one query will take nearly 1 min to generate final contexts. You could set log level to INFO to monitor the retrieval progress\n    # simple_mode = True\n)\n\nprint(context)\n```",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "uDnRsrcDV2kZVI2wi9EA58m+F4ILdr1bvjhqNlB+wSc=",
        "originContent": "```python",
        "translatedContent": "```python"
      },
      {
        "row": 2,
        "rowsha": "hA5UQDttQHKAwB+ESl7GqyiAa1AotkDZYMGTRuo/AoY=",
        "originContent": "from llama_github import GithubRAG",
        "translatedContent": "from llama_github import GithubRAG"
      },
      {
        "row": 3,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 4,
        "rowsha": "/Xio12pWjWQxdHtqP9gkrQo8FvXup5Rnp8m6s9rWQoA=",
        "originContent": "# Initialize GithubRAG with your credentials",
        "translatedContent": "# Initialize GithubRAG with your credentials"
      },
      {
        "row": 5,
        "rowsha": "Z/GdSwf7Zfjb56iNk/lrSDiBY4vaKvdGc5F3qO5IgSQ=",
        "originContent": "github_rag = GithubRAG(",
        "translatedContent": "github_rag = GithubRAG("
      },
      {
        "row": 6,
        "rowsha": "DCUT+XvqWQMhTvTxgZeTkNrf6sB1egP0ataQmEq//Do=",
        "originContent": "    github_access_token=\"your_github_access_token\", ",
        "translatedContent": "    github_access_token=\"your_github_access_token\", "
      },
      {
        "row": 7,
        "rowsha": "7hDiOA+9nEfENa9R7NEJW8WSnmj71txD0Ndrw3HjngM=",
        "originContent": "    openai_api_key=\"your_openai_api_key\", # Optional in Simple Mode",
        "translatedContent": "    openai_api_key=\"your_openai_api_key\", # Optional in Simple Mode"
      },
      {
        "row": 8,
        "rowsha": "3gER4AqcTSuWLMk5yIWdhwT240c1f6O0Qk92225ZuVU=",
        "originContent": "    jina_api_key=\"your_jina_api_key\" # Optional - unless you want high concurrency production deployment (s.jina.ai API will be used in llama-github)",
        "translatedContent": "    jina_api_key=\"your_jina_api_key\" # Optional - unless you want high concurrency production deployment (s.jina.ai API will be used in llama-github)"
      },
      {
        "row": 9,
        "rowsha": "ul7FHQekrA6VFghwRDHVmgKyGk6VGswQUFqNxAfFAe4=",
        "originContent": ")",
        "translatedContent": ")"
      },
      {
        "row": 10,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 11,
        "rowsha": "U1SUJQpzS8NM2yh7MFPYJl5dQ6gq/MR813WqTX952X0=",
        "originContent": "# Retrieve context for a coding question (simple_mode is default set to False)",
        "translatedContent": "# Retrieve context for a coding question (simple_mode is default set to False)"
      },
      {
        "row": 12,
        "rowsha": "ZXVeMLKgPJjdKhiZ9CK5U4oP9OsdwnWdpg8zNqEI+58=",
        "originContent": "query = \"How to create a NumPy array in Python?\"",
        "translatedContent": "query = \"How to create a NumPy array in Python?\""
      },
      {
        "row": 13,
        "rowsha": "tMIfL+j+gxN0VAT5YvCwzTJ6i5aIIY3fcw3LxJWoTrQ=",
        "originContent": "context = github_rag.retrieve_context(",
        "translatedContent": "context = github_rag.retrieve_context("
      },
      {
        "row": 14,
        "rowsha": "Q1vTmUoyeud2ZNyE6iVCY7OriQi61Wg6NLrSyM9pVLE=",
        "originContent": "    query, # In professional mode, one query will take nearly 1 min to generate final contexts. You could set log level to INFO to monitor the retrieval progress",
        "translatedContent": "    query, # In professional mode, one query will take nearly 1 min to generate final contexts. You could set log level to INFO to monitor the retrieval progress"
      },
      {
        "row": 15,
        "rowsha": "uvb8HENvYITO6V3XF0E9tyqODM0Be+CdeIuXZsYj/CA=",
        "originContent": "    # simple_mode = True",
        "translatedContent": "    # simple_mode = True"
      },
      {
        "row": 16,
        "rowsha": "ul7FHQekrA6VFghwRDHVmgKyGk6VGswQUFqNxAfFAe4=",
        "originContent": ")",
        "translatedContent": ")"
      },
      {
        "row": 17,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 18,
        "rowsha": "ZZEcMA2fivnNWsWr7Vg5FUhhpwQQJ/ThJU+S148t13E=",
        "originContent": "print(context)",
        "translatedContent": "print(context)"
      },
      {
        "row": 19,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      }
    ],
    "IsCodeBlock": true
  },
  {
    "Id": 5,
    "Content": "\nFor more advanced usage and examples, please refer to the [documentation](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/docs/usage.md).\n\n## Key Features\n\n- **üîç Intelligent GitHub Retrieval**: Harness the power of llama-github to retrieve highly relevant code snippets, issues, and repository information from GitHub based on user queries. Our advanced retrieval techniques ensure you find the most pertinent information quickly and efficiently.\n\n- **‚ö° Repository Pool Caching**: Llama-github has an innovative repository pool caching mechanism. By caching repositories (including READMEs, structures, code, and issues) across threads, llama-github significantly accelerates GitHub search retrieval efficiency and minimizes the consumption of GitHub API tokens. Deploy llama-github in multi-threaded production environments with confidence, knowing that it will perform optimally and save you valuable resources.\n\n- **üß† LLM-Powered Question Analysis**: Leverage state-of-the-art language models to analyze user questions and generate highly effective search strategies and criteria. Llama-github intelligently breaks down complex queries, ensuring that you retrieve the most relevant information from GitHub's vast repository network.\n\n- **üìö Comprehensive Context Generation**: Generate rich, contextually relevant answers by seamlessly combining information retrieved from GitHub with the reasoning capabilities of advanced language models. Llama-github excels at handling even the most complex and lengthy questions, providing comprehensive and insightful responses that include extensive context to support your development needs.\n\n- **üöÄ Asynchronous Processing Excellence**: Llama-github is built from the ground up to leverage the full potential of asynchronous programming. With meticulously implemented asynchronous mechanisms woven throughout the codebase, llama-github can handle multiple requests concurrently, significantly boosting overall performance. Experience the difference as llama-github efficiently manages high-volume workloads without compromising on speed or quality.\n\n- **üîß Flexible LLM Integration**: Easily integrate llama-github with various LLM providers, embedding models, and reranking models to tailor the library's capabilities to your specific requirements. Our extensible architecture allows you to customize and enhance llama-github's functionality, ensuring that it adapts seamlessly to your unique development environment.\n\n- **üîí Robust Authentication Options**: Llama-github supports both personal access tokens and GitHub App authentication, providing you with the flexibility to integrate it into different development setups. Whether you're an individual developer or working within an organizational context, llama-github has you covered with secure and reliable authentication mechanisms.\n\n- **üõ†Ô∏è Logging and Error Handling**: We understand the importance of smooth operations and easy troubleshooting. That's why llama-github comes equipped with comprehensive logging and error handling mechanisms. Gain deep insights into the library's behavior, quickly diagnose issues, and maintain a stable and reliable development workflow.\n\n## ü§ñ Try Our AI-Powered PR Review Assistant: LlamaPReview\n\nIf you find llama-github useful, you might also be interested in our AI-powered GitHub PR review assistant, LlamaPReview. It's designed to complement your development workflow and further enhance code quality.\n\n### Key Features of LlamaPReview:\n- üöÄ One-click installation, zero configuration required, fully auto-run\n- üíØ Currently free to use - no credit card or payment info needed\n- üß† AI-powered, automatic PR reviews with deep code understanding\n- üåê Supports multiple programming languages\n\n**LlamaPReview utilizes llama-github's advanced context retrieval and LLM-powered analysis** to provide intelligent, context-aware code reviews. It's like having a senior developer, armed with the full context of your repository, review every PR automatically!\n\nüëâ [Install LlamaPReview Now](https://github.com/marketplace/llamapreview/) (Free)\n\nBy using llama-github for context retrieval and LlamaPReview for code reviews, you can create a powerful, AI-enhanced development environment.\n\n## Vision and Roadmap\n\n### Vision\n\nOur vision is to become a pivotal module in the future of AI-driven development solutions, seamlessly integrating with GitHub to empower LLMs in automatically resolving complex coding tasks.\n\n![Vision Architecture](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/./docs/vision.drawio.svg)\n\n### Roadmap\n\nFor a detailed view of our project roadmap, please visit our [Project Roadmap](https://github.com/users/JetXu-LLM/projects/2).\n\n## Acknowledgments\n\nWe would like to express our gratitude to the following open-source projects for their support and contributions:\n\n- **[LangChain](https://github.com/langchain-ai/langchain)**: For providing the foundational framework that empowers the LLM prompting and processing capabilities in llama-github.\n- **[Jina.ai](https://github.com/jina-ai/reader)**: For offering s.jina.ai API and open source reranker and embedding models that enhance the accuracy and relevance of the generated contexts in llama-github.\n\nTheir contributions have been instrumental in the development of llama-github, and we highly recommend checking out their projects for more innovative solutions.\n\n## Contributing\n\nWe welcome contributions to llama-github! Please see our [contributing guidelines](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/CONTRIBUTING.md) for more information.\n\n## License\n\nThis project is licensed under the terms of the Apache 2.0 license. See the [LICENSE](LICENSE) file for more details.\n\n## Contact\n\nIf you have any questions, suggestions, or feedback, please feel free to reach out to us at [Jet Xu's email](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/mailto:Voldemort.xu@foxmail.com).\n\n---\n\nThank you for choosing llama-github! We hope this library enhances your AI development experience and helps you build powerful applications with ease.\n",
    "ContentSha": "9uwuSakxESmyLicwqpb9te9XJtaLzK41aW7HGRKfVFM=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "ƒê·ªÉ s·ª≠ d·ª•ng n√¢ng cao h∆°n v√† xem c√°c v√≠ d·ª•, vui l√≤ng tham kh·∫£o [t√†i li·ªáu h∆∞·ªõng d·∫´n](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/docs/usage.md).\n\n## C√°c T√≠nh NƒÉng Ch√≠nh\n\n- **üîç Truy xu·∫•t GitHub th√¥ng minh**: T·∫≠n d·ª•ng s·ª©c m·∫°nh c·ªßa llama-github ƒë·ªÉ truy xu·∫•t c√°c ƒëo·∫°n m√£, v·∫•n ƒë·ªÅ, v√† th√¥ng tin kho l∆∞u tr·ªØ li√™n quan nh·∫•t t·ª´ GitHub d·ª±a tr√™n truy v·∫•n c·ªßa ng∆∞·ªùi d√πng. K·ªπ thu·∫≠t truy xu·∫•t ti√™n ti·∫øn ƒë·∫£m b·∫£o b·∫°n t√¨m th·∫•y th√¥ng tin ph√π h·ª£p nh·∫•t m·ªôt c√°ch nhanh ch√≥ng v√† hi·ªáu qu·∫£.\n\n- **‚ö° B·ªô nh·ªõ ƒë·ªám kho l∆∞u tr·ªØ**: Llama-github c√≥ c∆° ch·∫ø b·ªô nh·ªõ ƒë·ªám kho l∆∞u tr·ªØ s√°ng t·∫°o. B·∫±ng c√°ch l∆∞u ƒë·ªám kho l∆∞u tr·ªØ (bao g·ªìm README, c·∫•u tr√∫c, m√£ ngu·ªìn v√† v·∫•n ƒë·ªÅ) gi·ªØa c√°c lu·ªìng, llama-github tƒÉng t·ªëc ƒë√°ng k·ªÉ hi·ªáu su·∫•t truy xu·∫•t GitHub v√† gi·∫£m thi·ªÉu ti√™u hao token API GitHub. Tri·ªÉn khai llama-github trong m√¥i tr∆∞·ªùng s·∫£n xu·∫•t ƒëa lu·ªìng m·ªôt c√°ch t·ª± tin, ƒë·∫£m b·∫£o hi·ªáu nƒÉng t·ªëi ∆∞u v√† ti·∫øt ki·ªám t√†i nguy√™n qu√Ω gi√°.\n\n- **üß† Ph√¢n t√≠ch c√¢u h·ªèi b·∫±ng LLM**: T·∫≠n d·ª•ng c√°c m√¥ h√¨nh ng√¥n ng·ªØ ti√™n ti·∫øn ƒë·ªÉ ph√¢n t√≠ch c√¢u h·ªèi v√† t·∫°o ra c√°c chi·∫øn l∆∞·ª£c t√¨m ki·∫øm hi·ªáu qu·∫£. Llama-github ph√¢n t√≠ch th√¥ng minh c√°c truy v·∫•n ph·ª©c t·∫°p, ƒë·∫£m b·∫£o b·∫°n l·∫•y ƒë∆∞·ª£c th√¥ng tin ph√π h·ª£p nh·∫•t t·ª´ m·∫°ng l∆∞·ªõi kho l∆∞u tr·ªØ r·ªông l·ªõn c·ªßa GitHub.\n\n- **üìö Sinh ng·ªØ c·∫£nh to√†n di·ªán**: T·∫°o ra c√°c c√¢u tr·∫£ l·ªùi gi√†u ng·ªØ c·∫£nh b·∫±ng c√°ch k·∫øt h·ª£p li·ªÅn m·∫°ch th√¥ng tin truy xu·∫•t t·ª´ GitHub v·ªõi kh·∫£ nƒÉng suy lu·∫≠n c·ªßa c√°c m√¥ h√¨nh ng√¥n ng·ªØ hi·ªán ƒë·∫°i. Llama-github xu·∫•t s·∫Øc trong x·ª≠ l√Ω c√°c c√¢u h·ªèi ph·ª©c t·∫°p, d√†i, cung c·∫•p ph·∫£n h·ªìi to√†n di·ªán, s√¢u s·∫Øc k√®m theo nhi·ªÅu ng·ªØ c·∫£nh h·ªó tr·ª£ nhu c·∫ßu ph√°t tri·ªÉn c·ªßa b·∫°n.\n\n- **üöÄ X·ª≠ l√Ω b·∫•t ƒë·ªìng b·ªô xu·∫•t s·∫Øc**: Llama-github ƒë∆∞·ª£c x√¢y d·ª±ng t·ª´ ƒë·∫ßu ƒë·ªÉ t·∫≠n d·ª•ng t·ªëi ƒëa l·∫≠p tr√¨nh b·∫•t ƒë·ªìng b·ªô. V·ªõi c√°c c∆° ch·∫ø b·∫•t ƒë·ªìng b·ªô ƒë∆∞·ª£c tri·ªÉn khai t·ªâ m·ªâ xuy√™n su·ªët m√£ ngu·ªìn, llama-github c√≥ th·ªÉ x·ª≠ l√Ω nhi·ªÅu y√™u c·∫ßu c√πng l√∫c, tƒÉng ƒë√°ng k·ªÉ hi·ªáu su·∫•t t·ªïng th·ªÉ. C·∫£m nh·∫≠n s·ª± kh√°c bi·ªát khi llama-github qu·∫£n l√Ω kh·ªëi l∆∞·ª£ng c√¥ng vi·ªác l·ªõn m√† kh√¥ng ·∫£nh h∆∞·ªüng ƒë·∫øn t·ªëc ƒë·ªô ho·∫∑c ch·∫•t l∆∞·ª£ng.\n\n- **üîß T√≠ch h·ª£p LLM linh ho·∫°t**: D·ªÖ d√†ng t√≠ch h·ª£p llama-github v·ªõi nhi·ªÅu nh√† cung c·∫•p LLM, m√¥ h√¨nh embedding, v√† m√¥ h√¨nh reranking ƒë·ªÉ ƒëi·ªÅu ch·ªânh kh·∫£ nƒÉng th∆∞ vi·ªán theo y√™u c·∫ßu c·ªßa b·∫°n. Ki·∫øn tr√∫c m·ªü r·ªông cho ph√©p b·∫°n t√πy ch·ªânh v√† n√¢ng cao ch·ª©c nƒÉng, ƒë·∫£m b·∫£o th√≠ch nghi li·ªÅn m·∫°ch v·ªõi m√¥i tr∆∞·ªùng ph√°t tri·ªÉn ri√™ng bi·ªát.\n\n- **üîí X√°c th·ª±c b·∫£o m·∫≠t m·∫°nh m·∫Ω**: Llama-github h·ªó tr·ª£ c·∫£ token truy c·∫≠p c√° nh√¢n v√† x√°c th·ª±c GitHub App, cung c·∫•p linh ho·∫°t khi t√≠ch h·ª£p v√†o c√°c m√¥i tr∆∞·ªùng ph√°t tri·ªÉn kh√°c nhau. D√π b·∫°n l√† l·∫≠p tr√¨nh vi√™n c√° nh√¢n hay l√†m vi·ªác trong t·ªï ch·ª©c, llama-github ƒë·ªÅu ƒë√°p ·ª©ng v·ªõi c∆° ch·∫ø x√°c th·ª±c an to√†n, tin c·∫≠y.\n\n- **üõ†Ô∏è Ghi log v√† x·ª≠ l√Ω l·ªói**: Ch√∫ng t√¥i hi·ªÉu t·∫ßm quan tr·ªçng c·ªßa v·∫≠n h√†nh m∆∞·ª£t m√† v√† d·ªÖ d√†ng kh·∫Øc ph·ª•c s·ª± c·ªë. V√¨ v·∫≠y, llama-github ƒë∆∞·ª£c trang b·ªã h·ªá th·ªëng ghi log v√† x·ª≠ l√Ω l·ªói to√†n di·ªán. Hi·ªÉu r√µ h√†nh vi th∆∞ vi·ªán, nhanh ch√≥ng ch·∫©n ƒëo√°n v·∫•n ƒë·ªÅ v√† duy tr√¨ quy tr√¨nh ph√°t tri·ªÉn ·ªïn ƒë·ªãnh, tin c·∫≠y.\n\n## ü§ñ Th·ª≠ Tr·ª£ L√Ω ƒê√°nh Gi√° PR AI: LlamaPReview\n\nN·∫øu b·∫°n th·∫•y llama-github h·ªØu √≠ch, b·∫°n c≈©ng c√≥ th·ªÉ quan t√¢m ƒë·∫øn tr·ª£ l√Ω ƒë√°nh gi√° PR GitHub d√πng AI, LlamaPReview. C√¥ng c·ª• n√†y ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ b·ªï sung quy tr√¨nh ph√°t tri·ªÉn v√† n√¢ng cao ch·∫•t l∆∞·ª£ng m√£ ngu·ªìn.\n\n### C√°c t√≠nh nƒÉng ch√≠nh c·ªßa LlamaPReview:\n- üöÄ C√†i ƒë·∫∑t m·ªôt l·∫ßn b·∫•m, kh√¥ng c·∫ßn c·∫•u h√¨nh, t·ª± ƒë·ªông ho√†n to√†n\n- üíØ Hi·ªán t·∫°i s·ª≠ d·ª•ng mi·ªÖn ph√≠ - kh√¥ng c·∫ßn th·∫ª t√≠n d·ª•ng ho·∫∑c th√¥ng tin thanh to√°n\n- üß† ƒê√°nh gi√° PR t·ª± ƒë·ªông b·∫±ng AI v·ªõi hi·ªÉu bi·∫øt s√¢u v·ªÅ m√£ ngu·ªìn\n- üåê H·ªó tr·ª£ nhi·ªÅu ng√¥n ng·ªØ l·∫≠p tr√¨nh\n\n**LlamaPReview s·ª≠ d·ª•ng truy xu·∫•t ng·ªØ c·∫£nh n√¢ng cao v√† ph√¢n t√≠ch LLM c·ªßa llama-github** ƒë·ªÉ cung c·∫•p ƒë√°nh gi√° m√£ th√¥ng minh, nh·∫≠n th·ª©c ng·ªØ c·∫£nh. Gi·ªëng nh∆∞ c√≥ m·ªôt l·∫≠p tr√¨nh vi√™n k·ª≥ c·ª±u, n·∫Øm r√µ to√†n b·ªô kho l∆∞u tr·ªØ, t·ª± ƒë·ªông ki·ªÉm tra t·ª´ng PR cho b·∫°n!\n\nüëâ [C√†i ƒë·∫∑t LlamaPReview ngay](https://github.com/marketplace/llamapreview/) (Mi·ªÖn ph√≠)\n\nB·∫±ng c√°ch s·ª≠ d·ª•ng llama-github ƒë·ªÉ truy xu·∫•t ng·ªØ c·∫£nh v√† LlamaPReview ƒë·ªÉ ƒë√°nh gi√° m√£, b·∫°n c√≥ th·ªÉ t·∫°o ra m√¥i tr∆∞·ªùng ph√°t tri·ªÉn m·∫°nh m·∫Ω, tƒÉng c∆∞·ªùng b·ªüi AI.\n\n## T·∫ßm Nh√¨n v√† L·ªô Tr√¨nh\n\n### T·∫ßm Nh√¨n\n\nT·∫ßm nh√¨n c·ªßa ch√∫ng t√¥i l√† tr·ªü th√†nh m·ªôt m√¥-ƒëun then ch·ªët trong t∆∞∆°ng lai c√°c gi·∫£i ph√°p ph√°t tri·ªÉn d·ª±a tr√™n AI, t√≠ch h·ª£p li·ªÅn m·∫°ch v·ªõi GitHub ƒë·ªÉ gi√∫p LLM t·ª± ƒë·ªông gi·∫£i quy·∫øt c√°c t√°c v·ª• m√£ h√≥a ph·ª©c t·∫°p.\n\n![Ki·∫øn tr√∫c T·∫ßm nh√¨n](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/./docs/vision.drawio.svg)\n\n### L·ªô Tr√¨nh\n\nƒê·ªÉ xem chi ti·∫øt l·ªô tr√¨nh d·ª± √°n, vui l√≤ng truy c·∫≠p [L·ªô tr√¨nh D·ª± √°n](https://github.com/users/JetXu-LLM/projects/2).\n\n## L·ªùi C·∫£m ∆†n\n\nCh√∫ng t√¥i xin g·ª≠i l·ªùi c·∫£m ∆°n ƒë·∫øn c√°c d·ª± √°n m√£ ngu·ªìn m·ªü sau ƒë√¢y v√¨ s·ª± h·ªó tr·ª£ v√† ƒë√≥ng g√≥p c·ªßa h·ªç:\n\n- **[LangChain](https://github.com/langchain-ai/langchain)**: ƒê√£ cung c·∫•p n·ªÅn t·∫£ng khung gi√∫p tƒÉng c∆∞·ªùng kh·∫£ nƒÉng prompting v√† x·ª≠ l√Ω LLM cho llama-github.\n- **[Jina.ai](https://github.com/jina-ai/reader)**: ƒê√£ cung c·∫•p API s.jina.ai v√† c√°c m√¥ h√¨nh reranker, embedding m√£ ngu·ªìn m·ªü gi√∫p tƒÉng ƒë·ªô ch√≠nh x√°c v√† li√™n quan c·ªßa ng·ªØ c·∫£nh sinh ra trong llama-github.\n\nS·ª± ƒë√≥ng g√≥p c·ªßa h·ªç l√† r·∫•t quan tr·ªçng ƒë·ªëi v·ªõi s·ª± ph√°t tri·ªÉn c·ªßa llama-github, ch√∫ng t√¥i khuy·∫øn kh√≠ch b·∫°n tham kh·∫£o c√°c d·ª± √°n n√†y ƒë·ªÉ kh√°m ph√° th√™m c√°c gi·∫£i ph√°p s√°ng t·∫°o.\n\n## ƒê√≥ng G√≥p\n\nCh√∫ng t√¥i hoan ngh√™nh m·ªçi ƒë√≥ng g√≥p cho llama-github! Vui l√≤ng xem [h∆∞·ªõng d·∫´n ƒë√≥ng g√≥p](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/CONTRIBUTING.md) ƒë·ªÉ bi·∫øt th√™m chi ti·∫øt.\n\n## Gi·∫•y Ph√©p\n\nD·ª± √°n n√†y ƒë∆∞·ª£c c·∫•p ph√©p theo c√°c ƒëi·ªÅu kho·∫£n c·ªßa gi·∫•y ph√©p Apache 2.0. Xem t·ªáp [LICENSE](LICENSE) ƒë·ªÉ bi·∫øt th√™m chi ti·∫øt.\n\n## Li√™n H·ªá\n\nN·∫øu b·∫°n c√≥ b·∫•t k·ª≥ c√¢u h·ªèi, ƒë·ªÅ xu·∫•t ho·∫∑c ph·∫£n h·ªìi n√†o, vui l√≤ng li√™n h·ªá v·ªõi ch√∫ng t√¥i qua [email c·ªßa Jet Xu](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/mailto:Voldemort.xu@foxmail.com).\n\n---\n\nC·∫£m ∆°n b·∫°n ƒë√£ l·ª±a ch·ªçn llama-github! Ch√∫ng t√¥i hy v·ªçng th∆∞ vi·ªán n√†y s·∫Ω n√¢ng cao tr·∫£i nghi·ªám ph√°t tri·ªÉn AI c·ªßa b·∫°n v√† gi√∫p b·∫°n x√¢y d·ª±ng c√°c ·ª©ng d·ª•ng m·∫°nh m·∫Ω m·ªôt c√°ch d·ªÖ d√†ng.\n\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "ƒê·ªÉ s·ª≠ d·ª•ng n√¢ng cao h∆°n v√† xem c√°c v√≠ d·ª•, vui l√≤ng tham kh·∫£o [t√†i li·ªáu h∆∞·ªõng d·∫´n](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/docs/usage.md)."
      },
      {
        "row": 2,
        "rowsha": "zrMByz3uboJewll5VwM0OlM3JCc+dvchgXugvMGdZyA=",
        "originContent": "For more advanced usage and examples, please refer to the [documentation](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/docs/usage.md).",
        "translatedContent": ""
      },
      {
        "row": 3,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "## C√°c T√≠nh NƒÉng Ch√≠nh"
      },
      {
        "row": 4,
        "rowsha": "khTPM/+Q4D8FMdf3qgrMDcjDejggkuMl1+JmWZMODFI=",
        "originContent": "## Key Features",
        "translatedContent": ""
      },
      {
        "row": 5,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "- **üîç Truy xu·∫•t GitHub th√¥ng minh**: T·∫≠n d·ª•ng s·ª©c m·∫°nh c·ªßa llama-github ƒë·ªÉ truy xu·∫•t c√°c ƒëo·∫°n m√£, v·∫•n ƒë·ªÅ, v√† th√¥ng tin kho l∆∞u tr·ªØ li√™n quan nh·∫•t t·ª´ GitHub d·ª±a tr√™n truy v·∫•n c·ªßa ng∆∞·ªùi d√πng. K·ªπ thu·∫≠t truy xu·∫•t ti√™n ti·∫øn ƒë·∫£m b·∫£o b·∫°n t√¨m th·∫•y th√¥ng tin ph√π h·ª£p nh·∫•t m·ªôt c√°ch nhanh ch√≥ng v√† hi·ªáu qu·∫£."
      },
      {
        "row": 6,
        "rowsha": "DfE9NcmRSF011JyFgs3cD/a2VQqPhp+XXqaTnhAtBwc=",
        "originContent": "- **üîç Intelligent GitHub Retrieval**: Harness the power of llama-github to retrieve highly relevant code snippets, issues, and repository information from GitHub based on user queries. Our advanced retrieval techniques ensure you find the most pertinent information quickly and efficiently.",
        "translatedContent": ""
      },
      {
        "row": 7,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "- **‚ö° B·ªô nh·ªõ ƒë·ªám kho l∆∞u tr·ªØ**: Llama-github c√≥ c∆° ch·∫ø b·ªô nh·ªõ ƒë·ªám kho l∆∞u tr·ªØ s√°ng t·∫°o. B·∫±ng c√°ch l∆∞u ƒë·ªám kho l∆∞u tr·ªØ (bao g·ªìm README, c·∫•u tr√∫c, m√£ ngu·ªìn v√† v·∫•n ƒë·ªÅ) gi·ªØa c√°c lu·ªìng, llama-github tƒÉng t·ªëc ƒë√°ng k·ªÉ hi·ªáu su·∫•t truy xu·∫•t GitHub v√† gi·∫£m thi·ªÉu ti√™u hao token API GitHub. Tri·ªÉn khai llama-github trong m√¥i tr∆∞·ªùng s·∫£n xu·∫•t ƒëa lu·ªìng m·ªôt c√°ch t·ª± tin, ƒë·∫£m b·∫£o hi·ªáu nƒÉng t·ªëi ∆∞u v√† ti·∫øt ki·ªám t√†i nguy√™n qu√Ω gi√°."
      },
      {
        "row": 8,
        "rowsha": "OtNyTLgFLD0QDlCwfKWcttMbckHUBj2YJNKV9r+Uc54=",
        "originContent": "- **‚ö° Repository Pool Caching**: Llama-github has an innovative repository pool caching mechanism. By caching repositories (including READMEs, structures, code, and issues) across threads, llama-github significantly accelerates GitHub search retrieval efficiency and minimizes the consumption of GitHub API tokens. Deploy llama-github in multi-threaded production environments with confidence, knowing that it will perform optimally and save you valuable resources.",
        "translatedContent": ""
      },
      {
        "row": 9,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "- **üß† Ph√¢n t√≠ch c√¢u h·ªèi b·∫±ng LLM**: T·∫≠n d·ª•ng c√°c m√¥ h√¨nh ng√¥n ng·ªØ ti√™n ti·∫øn ƒë·ªÉ ph√¢n t√≠ch c√¢u h·ªèi v√† t·∫°o ra c√°c chi·∫øn l∆∞·ª£c t√¨m ki·∫øm hi·ªáu qu·∫£. Llama-github ph√¢n t√≠ch th√¥ng minh c√°c truy v·∫•n ph·ª©c t·∫°p, ƒë·∫£m b·∫£o b·∫°n l·∫•y ƒë∆∞·ª£c th√¥ng tin ph√π h·ª£p nh·∫•t t·ª´ m·∫°ng l∆∞·ªõi kho l∆∞u tr·ªØ r·ªông l·ªõn c·ªßa GitHub."
      },
      {
        "row": 10,
        "rowsha": "JeXb8RZZhv2Wmw97j628XoyPreY+fMdIPsxoUQiEvzw=",
        "originContent": "- **üß† LLM-Powered Question Analysis**: Leverage state-of-the-art language models to analyze user questions and generate highly effective search strategies and criteria. Llama-github intelligently breaks down complex queries, ensuring that you retrieve the most relevant information from GitHub's vast repository network.",
        "translatedContent": ""
      },
      {
        "row": 11,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "- **üìö Sinh ng·ªØ c·∫£nh to√†n di·ªán**: T·∫°o ra c√°c c√¢u tr·∫£ l·ªùi gi√†u ng·ªØ c·∫£nh b·∫±ng c√°ch k·∫øt h·ª£p li·ªÅn m·∫°ch th√¥ng tin truy xu·∫•t t·ª´ GitHub v·ªõi kh·∫£ nƒÉng suy lu·∫≠n c·ªßa c√°c m√¥ h√¨nh ng√¥n ng·ªØ hi·ªán ƒë·∫°i. Llama-github xu·∫•t s·∫Øc trong x·ª≠ l√Ω c√°c c√¢u h·ªèi ph·ª©c t·∫°p, d√†i, cung c·∫•p ph·∫£n h·ªìi to√†n di·ªán, s√¢u s·∫Øc k√®m theo nhi·ªÅu ng·ªØ c·∫£nh h·ªó tr·ª£ nhu c·∫ßu ph√°t tri·ªÉn c·ªßa b·∫°n."
      },
      {
        "row": 12,
        "rowsha": "yA7pWfx0KVCXQ2Eo49pVkbLR+DABI/mKnMw/tj/sCL0=",
        "originContent": "- **üìö Comprehensive Context Generation**: Generate rich, contextually relevant answers by seamlessly combining information retrieved from GitHub with the reasoning capabilities of advanced language models. Llama-github excels at handling even the most complex and lengthy questions, providing comprehensive and insightful responses that include extensive context to support your development needs.",
        "translatedContent": ""
      },
      {
        "row": 13,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "- **üöÄ X·ª≠ l√Ω b·∫•t ƒë·ªìng b·ªô xu·∫•t s·∫Øc**: Llama-github ƒë∆∞·ª£c x√¢y d·ª±ng t·ª´ ƒë·∫ßu ƒë·ªÉ t·∫≠n d·ª•ng t·ªëi ƒëa l·∫≠p tr√¨nh b·∫•t ƒë·ªìng b·ªô. V·ªõi c√°c c∆° ch·∫ø b·∫•t ƒë·ªìng b·ªô ƒë∆∞·ª£c tri·ªÉn khai t·ªâ m·ªâ xuy√™n su·ªët m√£ ngu·ªìn, llama-github c√≥ th·ªÉ x·ª≠ l√Ω nhi·ªÅu y√™u c·∫ßu c√πng l√∫c, tƒÉng ƒë√°ng k·ªÉ hi·ªáu su·∫•t t·ªïng th·ªÉ. C·∫£m nh·∫≠n s·ª± kh√°c bi·ªát khi llama-github qu·∫£n l√Ω kh·ªëi l∆∞·ª£ng c√¥ng vi·ªác l·ªõn m√† kh√¥ng ·∫£nh h∆∞·ªüng ƒë·∫øn t·ªëc ƒë·ªô ho·∫∑c ch·∫•t l∆∞·ª£ng."
      },
      {
        "row": 14,
        "rowsha": "qku0KFnzN0JDJsFtvSnr1U47mAfoIMLCUgoTAF0FV2Q=",
        "originContent": "- **üöÄ Asynchronous Processing Excellence**: Llama-github is built from the ground up to leverage the full potential of asynchronous programming. With meticulously implemented asynchronous mechanisms woven throughout the codebase, llama-github can handle multiple requests concurrently, significantly boosting overall performance. Experience the difference as llama-github efficiently manages high-volume workloads without compromising on speed or quality.",
        "translatedContent": ""
      },
      {
        "row": 15,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "- **üîß T√≠ch h·ª£p LLM linh ho·∫°t**: D·ªÖ d√†ng t√≠ch h·ª£p llama-github v·ªõi nhi·ªÅu nh√† cung c·∫•p LLM, m√¥ h√¨nh embedding, v√† m√¥ h√¨nh reranking ƒë·ªÉ ƒëi·ªÅu ch·ªânh kh·∫£ nƒÉng th∆∞ vi·ªán theo y√™u c·∫ßu c·ªßa b·∫°n. Ki·∫øn tr√∫c m·ªü r·ªông cho ph√©p b·∫°n t√πy ch·ªânh v√† n√¢ng cao ch·ª©c nƒÉng, ƒë·∫£m b·∫£o th√≠ch nghi li·ªÅn m·∫°ch v·ªõi m√¥i tr∆∞·ªùng ph√°t tri·ªÉn ri√™ng bi·ªát."
      },
      {
        "row": 16,
        "rowsha": "0g6jkIpIeIIz2Gt8w6I2VAjPUz51+RDJs7fxVchaN/k=",
        "originContent": "- **üîß Flexible LLM Integration**: Easily integrate llama-github with various LLM providers, embedding models, and reranking models to tailor the library's capabilities to your specific requirements. Our extensible architecture allows you to customize and enhance llama-github's functionality, ensuring that it adapts seamlessly to your unique development environment.",
        "translatedContent": ""
      },
      {
        "row": 17,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "- **üîí X√°c th·ª±c b·∫£o m·∫≠t m·∫°nh m·∫Ω**: Llama-github h·ªó tr·ª£ c·∫£ token truy c·∫≠p c√° nh√¢n v√† x√°c th·ª±c GitHub App, cung c·∫•p linh ho·∫°t khi t√≠ch h·ª£p v√†o c√°c m√¥i tr∆∞·ªùng ph√°t tri·ªÉn kh√°c nhau. D√π b·∫°n l√† l·∫≠p tr√¨nh vi√™n c√° nh√¢n hay l√†m vi·ªác trong t·ªï ch·ª©c, llama-github ƒë·ªÅu ƒë√°p ·ª©ng v·ªõi c∆° ch·∫ø x√°c th·ª±c an to√†n, tin c·∫≠y."
      },
      {
        "row": 18,
        "rowsha": "WH0+zgaxAP/W/KtIygVDuxydKTKp6imCYyXpqvXpjaM=",
        "originContent": "- **üîí Robust Authentication Options**: Llama-github supports both personal access tokens and GitHub App authentication, providing you with the flexibility to integrate it into different development setups. Whether you're an individual developer or working within an organizational context, llama-github has you covered with secure and reliable authentication mechanisms.",
        "translatedContent": ""
      },
      {
        "row": 19,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "- **üõ†Ô∏è Ghi log v√† x·ª≠ l√Ω l·ªói**: Ch√∫ng t√¥i hi·ªÉu t·∫ßm quan tr·ªçng c·ªßa v·∫≠n h√†nh m∆∞·ª£t m√† v√† d·ªÖ d√†ng kh·∫Øc ph·ª•c s·ª± c·ªë. V√¨ v·∫≠y, llama-github ƒë∆∞·ª£c trang b·ªã h·ªá th·ªëng ghi log v√† x·ª≠ l√Ω l·ªói to√†n di·ªán. Hi·ªÉu r√µ h√†nh vi th∆∞ vi·ªán, nhanh ch√≥ng ch·∫©n ƒëo√°n v·∫•n ƒë·ªÅ v√† duy tr√¨ quy tr√¨nh ph√°t tri·ªÉn ·ªïn ƒë·ªãnh, tin c·∫≠y."
      },
      {
        "row": 20,
        "rowsha": "IYhTxjMvy72M7T9kEBfrXUNMz08qwsXzETVoE3WSNyQ=",
        "originContent": "- **üõ†Ô∏è Logging and Error Handling**: We understand the importance of smooth operations and easy troubleshooting. That's why llama-github comes equipped with comprehensive logging and error handling mechanisms. Gain deep insights into the library's behavior, quickly diagnose issues, and maintain a stable and reliable development workflow.",
        "translatedContent": ""
      },
      {
        "row": 21,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "## ü§ñ Th·ª≠ Tr·ª£ L√Ω ƒê√°nh Gi√° PR AI: LlamaPReview"
      },
      {
        "row": 22,
        "rowsha": "QDeqAvaQEIQHPYjwq2KF5Bw3a76EiPq7ebbsGNKcRI8=",
        "originContent": "## ü§ñ Try Our AI-Powered PR Review Assistant: LlamaPReview",
        "translatedContent": ""
      },
      {
        "row": 23,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "N·∫øu b·∫°n th·∫•y llama-github h·ªØu √≠ch, b·∫°n c≈©ng c√≥ th·ªÉ quan t√¢m ƒë·∫øn tr·ª£ l√Ω ƒë√°nh gi√° PR GitHub d√πng AI, LlamaPReview. C√¥ng c·ª• n√†y ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ b·ªï sung quy tr√¨nh ph√°t tri·ªÉn v√† n√¢ng cao ch·∫•t l∆∞·ª£ng m√£ ngu·ªìn."
      },
      {
        "row": 24,
        "rowsha": "laWUe+J402emMP2V1JeMqFpYefA8HTKWoI+lq7NfoyE=",
        "originContent": "If you find llama-github useful, you might also be interested in our AI-powered GitHub PR review assistant, LlamaPReview. It's designed to complement your development workflow and further enhance code quality.",
        "translatedContent": ""
      },
      {
        "row": 25,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "### C√°c t√≠nh nƒÉng ch√≠nh c·ªßa LlamaPReview:"
      },
      {
        "row": 26,
        "rowsha": "J3M87xxuLQISS/m0fiv7phjnw7mYaznst6rel6n7MyY=",
        "originContent": "### Key Features of LlamaPReview:",
        "translatedContent": "- üöÄ C√†i ƒë·∫∑t m·ªôt l·∫ßn b·∫•m, kh√¥ng c·∫ßn c·∫•u h√¨nh, t·ª± ƒë·ªông ho√†n to√†n"
      },
      {
        "row": 27,
        "rowsha": "dGBd2SxNdlW1UATPSu01Iq95yCVz8fXbl7xxHqDYI7E=",
        "originContent": "- üöÄ One-click installation, zero configuration required, fully auto-run",
        "translatedContent": "- üíØ Hi·ªán t·∫°i s·ª≠ d·ª•ng mi·ªÖn ph√≠ - kh√¥ng c·∫ßn th·∫ª t√≠n d·ª•ng ho·∫∑c th√¥ng tin thanh to√°n"
      },
      {
        "row": 28,
        "rowsha": "EP9hYUs4aYVAzXcYQyCGf3bjwo64OjAsqQHIN75oW60=",
        "originContent": "- üíØ Currently free to use - no credit card or payment info needed",
        "translatedContent": "- üß† ƒê√°nh gi√° PR t·ª± ƒë·ªông b·∫±ng AI v·ªõi hi·ªÉu bi·∫øt s√¢u v·ªÅ m√£ ngu·ªìn"
      },
      {
        "row": 29,
        "rowsha": "jjWF/iUqSzPriHJ5iiFIq0Q6Pzx+gzPlnLu0Z4wmsSg=",
        "originContent": "- üß† AI-powered, automatic PR reviews with deep code understanding",
        "translatedContent": "- üåê H·ªó tr·ª£ nhi·ªÅu ng√¥n ng·ªØ l·∫≠p tr√¨nh"
      },
      {
        "row": 30,
        "rowsha": "Dsl+HsDM5NGI480TDo6eaFqgDcaofr3TDhLbUghSXhU=",
        "originContent": "- üåê Supports multiple programming languages",
        "translatedContent": ""
      },
      {
        "row": 31,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "**LlamaPReview s·ª≠ d·ª•ng truy xu·∫•t ng·ªØ c·∫£nh n√¢ng cao v√† ph√¢n t√≠ch LLM c·ªßa llama-github** ƒë·ªÉ cung c·∫•p ƒë√°nh gi√° m√£ th√¥ng minh, nh·∫≠n th·ª©c ng·ªØ c·∫£nh. Gi·ªëng nh∆∞ c√≥ m·ªôt l·∫≠p tr√¨nh vi√™n k·ª≥ c·ª±u, n·∫Øm r√µ to√†n b·ªô kho l∆∞u tr·ªØ, t·ª± ƒë·ªông ki·ªÉm tra t·ª´ng PR cho b·∫°n!"
      },
      {
        "row": 32,
        "rowsha": "GrzJg4j2iz94pupBQwJnFffhmsJ5IO9OkhqYvj0QEmo=",
        "originContent": "**LlamaPReview utilizes llama-github's advanced context retrieval and LLM-powered analysis** to provide intelligent, context-aware code reviews. It's like having a senior developer, armed with the full context of your repository, review every PR automatically!",
        "translatedContent": ""
      },
      {
        "row": 33,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "üëâ [C√†i ƒë·∫∑t LlamaPReview ngay](https://github.com/marketplace/llamapreview/) (Mi·ªÖn ph√≠)"
      },
      {
        "row": 34,
        "rowsha": "4qGUTknerL/UTVikcUjFHvKzZlWho9opuf58fSIypyk=",
        "originContent": "üëâ [Install LlamaPReview Now](https://github.com/marketplace/llamapreview/) (Free)",
        "translatedContent": ""
      },
      {
        "row": 35,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "B·∫±ng c√°ch s·ª≠ d·ª•ng llama-github ƒë·ªÉ truy xu·∫•t ng·ªØ c·∫£nh v√† LlamaPReview ƒë·ªÉ ƒë√°nh gi√° m√£, b·∫°n c√≥ th·ªÉ t·∫°o ra m√¥i tr∆∞·ªùng ph√°t tri·ªÉn m·∫°nh m·∫Ω, tƒÉng c∆∞·ªùng b·ªüi AI."
      },
      {
        "row": 36,
        "rowsha": "luTTMbXm2ikxAkHhFfh2iG9uPEwMYBRd2lolUoOY+3o=",
        "originContent": "By using llama-github for context retrieval and LlamaPReview for code reviews, you can create a powerful, AI-enhanced development environment.",
        "translatedContent": ""
      },
      {
        "row": 37,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "## T·∫ßm Nh√¨n v√† L·ªô Tr√¨nh"
      },
      {
        "row": 38,
        "rowsha": "W2b655gztUgECPmTnBIkK/WbBo7d68AbNAjMtkHS5xY=",
        "originContent": "## Vision and Roadmap",
        "translatedContent": ""
      },
      {
        "row": 39,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "### T·∫ßm Nh√¨n"
      },
      {
        "row": 40,
        "rowsha": "Ewakmoa/Yb8fcDlChA12w7kAXVMFh8OrCLwVCTwIl84=",
        "originContent": "### Vision",
        "translatedContent": ""
      },
      {
        "row": 41,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "T·∫ßm nh√¨n c·ªßa ch√∫ng t√¥i l√† tr·ªü th√†nh m·ªôt m√¥-ƒëun then ch·ªët trong t∆∞∆°ng lai c√°c gi·∫£i ph√°p ph√°t tri·ªÉn d·ª±a tr√™n AI, t√≠ch h·ª£p li·ªÅn m·∫°ch v·ªõi GitHub ƒë·ªÉ gi√∫p LLM t·ª± ƒë·ªông gi·∫£i quy·∫øt c√°c t√°c v·ª• m√£ h√≥a ph·ª©c t·∫°p."
      },
      {
        "row": 42,
        "rowsha": "0e6GYQC4W2Y8Ky5Q9UNeMwDc+ebEjDIUb9h4gSLQJaI=",
        "originContent": "Our vision is to become a pivotal module in the future of AI-driven development solutions, seamlessly integrating with GitHub to empower LLMs in automatically resolving complex coding tasks.",
        "translatedContent": ""
      },
      {
        "row": 43,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "![Ki·∫øn tr√∫c T·∫ßm nh√¨n](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/./docs/vision.drawio.svg)"
      },
      {
        "row": 44,
        "rowsha": "e3eGMrQR9LxN0lPlezIImRzi4tUu6n/GFfZsq5SBP4I=",
        "originContent": "![Vision Architecture](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/./docs/vision.drawio.svg)",
        "translatedContent": ""
      },
      {
        "row": 45,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "### L·ªô Tr√¨nh"
      },
      {
        "row": 46,
        "rowsha": "Q0D6oxy93TTXOZDvIiuco/ghaytG064tWvZdnLoKnOw=",
        "originContent": "### Roadmap",
        "translatedContent": ""
      },
      {
        "row": 47,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "ƒê·ªÉ xem chi ti·∫øt l·ªô tr√¨nh d·ª± √°n, vui l√≤ng truy c·∫≠p [L·ªô tr√¨nh D·ª± √°n](https://github.com/users/JetXu-LLM/projects/2)."
      },
      {
        "row": 48,
        "rowsha": "UHmL4/lEZk2jitjRxUVuHtD8JilL4OTzFLbU8R72Ymc=",
        "originContent": "For a detailed view of our project roadmap, please visit our [Project Roadmap](https://github.com/users/JetXu-LLM/projects/2).",
        "translatedContent": ""
      },
      {
        "row": 49,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "## L·ªùi C·∫£m ∆†n"
      },
      {
        "row": 50,
        "rowsha": "N66ywbuGccMYNTyswaMSnFOlWqX+iaYP/myGJqr1tHo=",
        "originContent": "## Acknowledgments",
        "translatedContent": ""
      },
      {
        "row": 51,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "Ch√∫ng t√¥i xin g·ª≠i l·ªùi c·∫£m ∆°n ƒë·∫øn c√°c d·ª± √°n m√£ ngu·ªìn m·ªü sau ƒë√¢y v√¨ s·ª± h·ªó tr·ª£ v√† ƒë√≥ng g√≥p c·ªßa h·ªç:"
      },
      {
        "row": 52,
        "rowsha": "WodCIp8BqxoCo7bxE7dxagf/Dvpvw7nWeECf0qG6FGI=",
        "originContent": "We would like to express our gratitude to the following open-source projects for their support and contributions:",
        "translatedContent": ""
      },
      {
        "row": 53,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "- **[LangChain](https://github.com/langchain-ai/langchain)**: ƒê√£ cung c·∫•p n·ªÅn t·∫£ng khung gi√∫p tƒÉng c∆∞·ªùng kh·∫£ nƒÉng prompting v√† x·ª≠ l√Ω LLM cho llama-github."
      },
      {
        "row": 54,
        "rowsha": "HBIRZKkbsYOXsJY2Xepu1VxTAAdh869qSnsGbJ0cIg0=",
        "originContent": "- **[LangChain](https://github.com/langchain-ai/langchain)**: For providing the foundational framework that empowers the LLM prompting and processing capabilities in llama-github.",
        "translatedContent": "- **[Jina.ai](https://github.com/jina-ai/reader)**: ƒê√£ cung c·∫•p API s.jina.ai v√† c√°c m√¥ h√¨nh reranker, embedding m√£ ngu·ªìn m·ªü gi√∫p tƒÉng ƒë·ªô ch√≠nh x√°c v√† li√™n quan c·ªßa ng·ªØ c·∫£nh sinh ra trong llama-github."
      },
      {
        "row": 55,
        "rowsha": "l7sjWwbh0OUJwk4+yJE2ZbVGypyaPrzI1YYMP7Uw9X0=",
        "originContent": "- **[Jina.ai](https://github.com/jina-ai/reader)**: For offering s.jina.ai API and open source reranker and embedding models that enhance the accuracy and relevance of the generated contexts in llama-github.",
        "translatedContent": ""
      },
      {
        "row": 56,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "S·ª± ƒë√≥ng g√≥p c·ªßa h·ªç l√† r·∫•t quan tr·ªçng ƒë·ªëi v·ªõi s·ª± ph√°t tri·ªÉn c·ªßa llama-github, ch√∫ng t√¥i khuy·∫øn kh√≠ch b·∫°n tham kh·∫£o c√°c d·ª± √°n n√†y ƒë·ªÉ kh√°m ph√° th√™m c√°c gi·∫£i ph√°p s√°ng t·∫°o."
      },
      {
        "row": 57,
        "rowsha": "hrChp1vDZFs3UZia39niD4Kx9hT0wKUMxSSiiyYyi7A=",
        "originContent": "Their contributions have been instrumental in the development of llama-github, and we highly recommend checking out their projects for more innovative solutions.",
        "translatedContent": ""
      },
      {
        "row": 58,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "## ƒê√≥ng G√≥p"
      },
      {
        "row": 59,
        "rowsha": "R5ZPLZ4vkE9tjX5qe8QB7AkTfWZsuNTGFLFKMp2KUzM=",
        "originContent": "## Contributing",
        "translatedContent": ""
      },
      {
        "row": 60,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "Ch√∫ng t√¥i hoan ngh√™nh m·ªçi ƒë√≥ng g√≥p cho llama-github! Vui l√≤ng xem [h∆∞·ªõng d·∫´n ƒë√≥ng g√≥p](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/CONTRIBUTING.md) ƒë·ªÉ bi·∫øt th√™m chi ti·∫øt."
      },
      {
        "row": 61,
        "rowsha": "JUWgAoIn9VhOEzmNL5dlAlHwcmo7N2Rm2GNx0g5Rijs=",
        "originContent": "We welcome contributions to llama-github! Please see our [contributing guidelines](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/CONTRIBUTING.md) for more information.",
        "translatedContent": ""
      },
      {
        "row": 62,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "## Gi·∫•y Ph√©p"
      },
      {
        "row": 63,
        "rowsha": "bFSaVtsB4CHySNjaeCiaMZfT24b+DTbTM4HQ38cR6Lw=",
        "originContent": "## License",
        "translatedContent": ""
      },
      {
        "row": 64,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "D·ª± √°n n√†y ƒë∆∞·ª£c c·∫•p ph√©p theo c√°c ƒëi·ªÅu kho·∫£n c·ªßa gi·∫•y ph√©p Apache 2.0. Xem t·ªáp [LICENSE](LICENSE) ƒë·ªÉ bi·∫øt th√™m chi ti·∫øt."
      },
      {
        "row": 65,
        "rowsha": "hUzQdbczna0Cd3FyH+bhS5SWBDzmVQyA+nCi/UZO6VI=",
        "originContent": "This project is licensed under the terms of the Apache 2.0 license. See the [LICENSE](LICENSE) file for more details.",
        "translatedContent": ""
      },
      {
        "row": 66,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "## Li√™n H·ªá"
      },
      {
        "row": 67,
        "rowsha": "ZX9nbduzXgvmAaK8yTd+tNgwR7cV79HXV/+xbvL8suw=",
        "originContent": "## Contact",
        "translatedContent": ""
      },
      {
        "row": 68,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "N·∫øu b·∫°n c√≥ b·∫•t k·ª≥ c√¢u h·ªèi, ƒë·ªÅ xu·∫•t ho·∫∑c ph·∫£n h·ªìi n√†o, vui l√≤ng li√™n h·ªá v·ªõi ch√∫ng t√¥i qua [email c·ªßa Jet Xu](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/mailto:Voldemort.xu@foxmail.com)."
      },
      {
        "row": 69,
        "rowsha": "sZud9u8DDdJRsIyc+T0tdusx1FWC0pdv0Yn2hhndP9o=",
        "originContent": "If you have any questions, suggestions, or feedback, please feel free to reach out to us at [Jet Xu's email](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/mailto:Voldemort.xu@foxmail.com).",
        "translatedContent": ""
      },
      {
        "row": 70,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "---"
      },
      {
        "row": 71,
        "rowsha": "yz+R1U7uMOU+NbK5mQX3Dxae1Un9eJCdPawt78ntjTs=",
        "originContent": "---",
        "translatedContent": ""
      },
      {
        "row": 72,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "C·∫£m ∆°n b·∫°n ƒë√£ l·ª±a ch·ªçn llama-github! Ch√∫ng t√¥i hy v·ªçng th∆∞ vi·ªán n√†y s·∫Ω n√¢ng cao tr·∫£i nghi·ªám ph√°t tri·ªÉn AI c·ªßa b·∫°n v√† gi√∫p b·∫°n x√¢y d·ª±ng c√°c ·ª©ng d·ª•ng m·∫°nh m·∫Ω m·ªôt c√°ch d·ªÖ d√†ng."
      },
      {
        "row": 73,
        "rowsha": "98t5imS5RZt8kUxGAXqZcPmlZMcru27Gl/g31hb3g/c=",
        "originContent": "Thank you for choosing llama-github! We hope this library enhances your AI development experience and helps you build powerful applications with ease.",
        "translatedContent": ""
      },
      {
        "row": 74,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  }
]