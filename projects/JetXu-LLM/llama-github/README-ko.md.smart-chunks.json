[
  {
    "Id": 1,
    "Content": "\n<div align=\"right\">\n  <details>\n    <summary >🌐 Language</summary>\n    <div>\n      <div align=\"center\">\n        <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=en\">English</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=zh-CN\">简体中文</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=zh-TW\">繁體中文</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=ja\">日本語</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=ko\">한국어</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=hi\">हिन्दी</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=th\">ไทย</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=fr\">Français</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=de\">Deutsch</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=es\">Español</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=it\">Italiano</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=ru\">Русский</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=pt\">Português</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=nl\">Nederlands</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=pl\">Polski</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=ar\">العربية</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=fa\">فارسی</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=tr\">Türkçe</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=vi\">Tiếng Việt</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=id\">Bahasa Indonesia</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=as\">অসমীয়া</\n      </div>\n    </div>\n  </details>\n</div>\n\n# llama-github\n\n[Detail Document] https://deepwiki.com/JetXu-LLM/llama-github\n\n[![PyPI version](https://badge.fury.io/py/llama-github.svg)](https://badge.fury.io/py/llama-github)\n[![Downloads](https://static.pepy.tech/badge/Llama-github)](https://pepy.tech/project/Llama-github)\n[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)\n\nLlama-github is a powerful tool that helps you retrieve(based on Agentic RAG) the most relevant code snippets, issues, and repository information from GitHub based on your queries, transforming them into valuable knowledge context. It empowers LLM Chatbots, AI Agents, and Auto-dev Agents to solve complex coding tasks. Whether you're a developer looking for quick solutions or an engineer implementing advanced Auto Dev AI Agents, llama-github makes it easy and efficient.\n\nIf you like this project or believe it has potential, please give it a ⭐️. Your support is our greatest motivation!\n\n## Architecture\n![High Level Architecture](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/./docs/high_level_architecture.drawio.svg)\n\n## Installation",
    "ContentSha": "luGjPJ0t2eUH+w8RDBgGqCVyQiIo+mel0icgkq5phQc=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "\n<div align=\"right\">\n  <details>\n    <summary >🌐 언어</summary>\n    <div>\n      <div align=\"center\">\n        <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=en\">English</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=zh-CN\">简体中文</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=zh-TW\">繁體中文</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=ja\">日本語</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=ko\">한국어</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=hi\">हिन्दी</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=th\">ไทย</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=fr\">Français</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=de\">Deutsch</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=es\">Español</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=it\">Italiano</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=ru\">Русский</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=pt\">Português</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=nl\">Nederlands</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=pl\">Polski</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=ar\">العربية</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=fa\">فارسی</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=tr\">Türkçe</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=vi\">Tiếng Việt</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=id\">Bahasa Indonesia</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=as\">অসমীয়া</\n      </div>\n    </div>\n  </details>\n</div>\n\n# llama-github\n\n[상세 문서] https://deepwiki.com/JetXu-LLM/llama-github\n\n[![PyPI 버전](https://badge.fury.io/py/llama-github.svg)](https://badge.fury.io/py/llama-github)\n[![다운로드](https://static.pepy.tech/badge/Llama-github)](https://pepy.tech/project/Llama-github)\n[![라이선스](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)\n\nLlama-github는 Agentic RAG 기반으로 GitHub에서 가장 관련 있는 코드 스니펫, 이슈, 저장소 정보를 쿼리에 따라 검색하여 가치 있는 지식 컨텍스트로 변환하는 강력한 도구입니다. 이 도구는 LLM 챗봇, AI 에이전트, Auto-dev 에이전트가 복잡한 코딩 작업을 해결할 수 있도록 지원합니다. 빠른 솔루션이 필요한 개발자이든, 고급 Auto Dev AI 에이전트를 구현하는 엔지니어이든, llama-github를 통해 쉽고 효율적으로 작업할 수 있습니다.\n\n이 프로젝트가 마음에 들거나 잠재력이 있다고 생각하신다면, 꼭 ⭐️를 눌러주세요. 여러분의 응원이 저희의 가장 큰 동기입니다!\n\n## 아키텍처\n![고수준 아키텍처](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/./docs/high_level_architecture.drawio.svg)\n\n## 설치",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 2,
        "rowsha": "cWgam+tnnXudu7i74+ahMEGk/A9dQS+EwWLAIfi3dHk=",
        "originContent": "<div align=\"right\">",
        "translatedContent": "<div align=\"right\">"
      },
      {
        "row": 3,
        "rowsha": "orOcu5ARna/hb3RUkj6dBI8pHTM3WHeTvby17l5E0h0=",
        "originContent": "  <details>",
        "translatedContent": "  <details>"
      },
      {
        "row": 4,
        "rowsha": "TtgkLzblnvP0q9aAIVXt6s2LczXjy5k+QvHKcU0/5Ms=",
        "originContent": "    <summary >🌐 Language</summary>",
        "translatedContent": "    <summary >🌐 언어</summary>"
      },
      {
        "row": 5,
        "rowsha": "fZtk4rPTAJEEslnbhSVkHEcPlsctYSzAV7CDPL3rJmA=",
        "originContent": "    <div>",
        "translatedContent": "    <div>"
      },
      {
        "row": 6,
        "rowsha": "9KQxOeJSigvTmGWO+mtnl8kZY9zQfueoy8sk4lYm09Q=",
        "originContent": "      <div align=\"center\">",
        "translatedContent": "      <div align=\"center\">"
      },
      {
        "row": 7,
        "rowsha": "HkJ4Gkepsmtc5YEEOiqUG3+NzfI0rf4IVUDgqFAmscs=",
        "originContent": "        <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=en\">English</a>",
        "translatedContent": "        <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=en\">English</a>"
      },
      {
        "row": 8,
        "rowsha": "SS8k2BQkHAHxyWP2X90nPl4mRZWm3fwXGqGF7mjnz18=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=zh-CN\">简体中文</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=zh-CN\">简体中文</a>"
      },
      {
        "row": 9,
        "rowsha": "VrMYTJ2mzoZzeIKdl57fntnJgzWRQqxW+Hh05WTobsc=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=zh-TW\">繁體中文</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=zh-TW\">繁體中文</a>"
      },
      {
        "row": 10,
        "rowsha": "c+DqTRbRnir4FoupjpEksFzVENBVWRYltmlpDbwQZmM=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=ja\">日本語</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=ja\">日本語</a>"
      },
      {
        "row": 11,
        "rowsha": "Tm7I5B+gkMpCeJ3LR+BslLE5wbSUneyFmLReBj+Kuws=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=ko\">한국어</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=ko\">한국어</a>"
      },
      {
        "row": 12,
        "rowsha": "wfZ0J7KdM7EX/cxK3wFAeE2ngExW4GfEYqHcAGlGx0w=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=hi\">हिन्दी</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=hi\">हिन्दी</a>"
      },
      {
        "row": 13,
        "rowsha": "y2QtQCnUvpYYte3U998DjX4FmVJMdwyXZ6wpYmbQkLE=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=th\">ไทย</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=th\">ไทย</a>"
      },
      {
        "row": 14,
        "rowsha": "zIupl7qEGAUFd0PjTxnqfYLAOYVxukVObZ2TvLzJhFI=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=fr\">Français</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=fr\">Français</a>"
      },
      {
        "row": 15,
        "rowsha": "NeTDxlUu1SaaYA+ZU+IrCgYKslSqZUFfuhtr46HJnA0=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=de\">Deutsch</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=de\">Deutsch</a>"
      },
      {
        "row": 16,
        "rowsha": "0ltGddRJZJCJAdD4E6lPYrnG+o9jxtvzFgZ6J422BVM=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=es\">Español</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=es\">Español</a>"
      },
      {
        "row": 17,
        "rowsha": "bzUdBLPtDNoKHOYQKJtE2KKD9trvdid+RiSJUXJ06jY=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=it\">Italiano</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=it\">Italiano</a>"
      },
      {
        "row": 18,
        "rowsha": "0pozScPeqLIHLCyJkRlRQjDqqKb8HWwWqCv6uaxalEY=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=ru\">Русский</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=ru\">Русский</a>"
      },
      {
        "row": 19,
        "rowsha": "ACT6kxJUtjo44NDX/ea/HxspYPgjmIuENrgcnxQYNEc=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=pt\">Português</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=pt\">Português</a>"
      },
      {
        "row": 20,
        "rowsha": "P5r7piMIRIzTPNX8NrKqGo+P1glz8ZRuJCLyQL24/LA=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=nl\">Nederlands</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=nl\">Nederlands</a>"
      },
      {
        "row": 21,
        "rowsha": "ZGMoXno6QdwcE1MCQ6a+39T9cMR9m1YyVj19nEOHOR8=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=pl\">Polski</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=pl\">Polski</a>"
      },
      {
        "row": 22,
        "rowsha": "VKZ+5aGayrqfPfJYP0j0/ap6ocirm1axw5vVvu7xsEE=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=ar\">العربية</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=ar\">العربية</a>"
      },
      {
        "row": 23,
        "rowsha": "CWIbKiayiPOGqPcuulT54J/JKB9czskFXkMCgTgHrZs=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=fa\">فارسی</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=fa\">فارسی</a>"
      },
      {
        "row": 24,
        "rowsha": "I1WcwpKhgv19NGCtlw+KLX03QSTLreFKCC9Ta0pFqIs=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=tr\">Türkçe</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=tr\">Türkçe</a>"
      },
      {
        "row": 25,
        "rowsha": "gIl9QJ2GwM0yfNYEXpcS2/xbtyKJbynqn4H4tnOyU2c=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=vi\">Tiếng Việt</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=vi\">Tiếng Việt</a>"
      },
      {
        "row": 26,
        "rowsha": "sMhilkGyfjhl6TXDHf4CKYnKDjhJR8fFg2lWQtaLDKc=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=id\">Bahasa Indonesia</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=id\">Bahasa Indonesia</a>"
      },
      {
        "row": 27,
        "rowsha": "SFIUIQN+2TXGoifui/NZlin5QtiRQtdF5of1FBBu7Gk=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=as\">অসমীয়া</",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=as\">অসমীয়া</"
      },
      {
        "row": 28,
        "rowsha": "0OM5wNEm0TO56MEBvQzL7AUZM7/3OpgIeqRf2zFre3Q=",
        "originContent": "      </div>",
        "translatedContent": "      </div>"
      },
      {
        "row": 29,
        "rowsha": "fcjTfY+fs8YnY5slBs1sZvWPAqEQR7tzaBDO54skkGQ=",
        "originContent": "    </div>",
        "translatedContent": "    </div>"
      },
      {
        "row": 30,
        "rowsha": "+fQNH2ldI7UM/rqRscP3hUSWAmw1HvQ2wEKDN8JagT0=",
        "originContent": "  </details>",
        "translatedContent": "  </details>"
      },
      {
        "row": 31,
        "rowsha": "qsMmUbEPVnxGG5tPJV1vsfpoWbU2jYvZpRr5IKshzyM=",
        "originContent": "</div>",
        "translatedContent": "</div>"
      },
      {
        "row": 32,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 33,
        "rowsha": "cAI8B2fw5xCydddeNcosOFY2wrQw8An1lrdomk97KBc=",
        "originContent": "# llama-github",
        "translatedContent": "# llama-github"
      },
      {
        "row": 34,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 35,
        "rowsha": "jSTPMiMb5qDjmRYlxqDSx6zbsKYKOv4c6HQQgjbDUqo=",
        "originContent": "[Detail Document] https://deepwiki.com/JetXu-LLM/llama-github",
        "translatedContent": "[상세 문서] https://deepwiki.com/JetXu-LLM/llama-github"
      },
      {
        "row": 36,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 37,
        "rowsha": "48lo1Cg6fyAcQl554s/7eKSc41UYvSn/CD6yxtLVgjY=",
        "originContent": "[![PyPI version](https://badge.fury.io/py/llama-github.svg)](https://badge.fury.io/py/llama-github)",
        "translatedContent": "[![PyPI 버전](https://badge.fury.io/py/llama-github.svg)](https://badge.fury.io/py/llama-github)"
      },
      {
        "row": 38,
        "rowsha": "VG3AfiYLkBPipFZPAt/fJt5jj8aI773UKbmI1Z/kc2M=",
        "originContent": "[![Downloads](https://static.pepy.tech/badge/Llama-github)](https://pepy.tech/project/Llama-github)",
        "translatedContent": "[![다운로드](https://static.pepy.tech/badge/Llama-github)](https://pepy.tech/project/Llama-github)"
      },
      {
        "row": 39,
        "rowsha": "U0vs77tGfFYY+r4ScaOhTOZDgt8vSKCUyj59tU13ZtE=",
        "originContent": "[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)",
        "translatedContent": "[![라이선스](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)"
      },
      {
        "row": 40,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 41,
        "rowsha": "y7xsY1R0s8pmwDQukNS2PQ5JqK6CRs8AwuPrZkBKiT8=",
        "originContent": "Llama-github is a powerful tool that helps you retrieve(based on Agentic RAG) the most relevant code snippets, issues, and repository information from GitHub based on your queries, transforming them into valuable knowledge context. It empowers LLM Chatbots, AI Agents, and Auto-dev Agents to solve complex coding tasks. Whether you're a developer looking for quick solutions or an engineer implementing advanced Auto Dev AI Agents, llama-github makes it easy and efficient.",
        "translatedContent": "Llama-github는 Agentic RAG 기반으로 GitHub에서 가장 관련 있는 코드 스니펫, 이슈, 저장소 정보를 쿼리에 따라 검색하여 가치 있는 지식 컨텍스트로 변환하는 강력한 도구입니다. 이 도구는 LLM 챗봇, AI 에이전트, Auto-dev 에이전트가 복잡한 코딩 작업을 해결할 수 있도록 지원합니다. 빠른 솔루션이 필요한 개발자이든, 고급 Auto Dev AI 에이전트를 구현하는 엔지니어이든, llama-github를 통해 쉽고 효율적으로 작업할 수 있습니다."
      },
      {
        "row": 42,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 43,
        "rowsha": "6h9r25r7afHOT0YHlaj7xv1WU2JfjWqSqLUM7UgJNfQ=",
        "originContent": "If you like this project or believe it has potential, please give it a ⭐️. Your support is our greatest motivation!",
        "translatedContent": "이 프로젝트가 마음에 들거나 잠재력이 있다고 생각하신다면, 꼭 ⭐️를 눌러주세요. 여러분의 응원이 저희의 가장 큰 동기입니다!"
      },
      {
        "row": 44,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 45,
        "rowsha": "p+VkcrEb08g4vIGZYB9aVScRKgA8afv5WwErwTVzoZM=",
        "originContent": "## Architecture",
        "translatedContent": "## 아키텍처"
      },
      {
        "row": 46,
        "rowsha": "TiSukfY/+ter5MJ39DMtNdHlqRXwhZFkP3uTdAfvA0c=",
        "originContent": "![High Level Architecture](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/./docs/high_level_architecture.drawio.svg)",
        "translatedContent": "![고수준 아키텍처](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/./docs/high_level_architecture.drawio.svg)"
      },
      {
        "row": 47,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 48,
        "rowsha": "oV0SUDvwD2VN8Gi9nlr2JZ2xcDrASmE2W5kc5SVX5eo=",
        "originContent": "## Installation",
        "translatedContent": "## 설치"
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 2,
    "Content": "```\npip install llama-github\n```",
    "ContentSha": "A7Ioj19mKQ2poo2/SNNEl/PUNM9x+13/7/ncgppdcgY=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```\npip install llama-github\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 3,
    "Content": "\n## Usage\n\nHere's a simple example of how to use llama-github:\n",
    "ContentSha": "oqzkRVGHtTMxKJniKYy+bJRBu/B3l8AYVVo5suNCmR4=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "## 사용법\n\nllama-github를 사용하는 간단한 예제는 다음과 같습니다:\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 4,
    "Content": "```python\nfrom llama_github import GithubRAG\n\n# Initialize GithubRAG with your credentials\ngithub_rag = GithubRAG(\n    github_access_token=\"your_github_access_token\", \n    openai_api_key=\"your_openai_api_key\", # Optional in Simple Mode\n    jina_api_key=\"your_jina_api_key\" # Optional - unless you want high concurrency production deployment (s.jina.ai API will be used in llama-github)\n)\n\n# Retrieve context for a coding question (simple_mode is default set to False)\nquery = \"How to create a NumPy array in Python?\"\ncontext = github_rag.retrieve_context(\n    query, # In professional mode, one query will take nearly 1 min to generate final contexts. You could set log level to INFO to monitor the retrieval progress\n    # simple_mode = True\n)\n\nprint(context)\n```",
    "ContentSha": "HXBtstD3V5wfKLk68/A2T/KFqRB/TtW5s0tq89CzhFU=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```python\nfrom llama_github import GithubRAG\n\n# Initialize GithubRAG with your credentials\ngithub_rag = GithubRAG(\n    github_access_token=\"your_github_access_token\", \n    openai_api_key=\"your_openai_api_key\", # Optional in Simple Mode\n    jina_api_key=\"your_jina_api_key\" # Optional - unless you want high concurrency production deployment (s.jina.ai API will be used in llama-github)\n)\n\n# Retrieve context for a coding question (simple_mode is default set to False)\nquery = \"How to create a NumPy array in Python?\"\ncontext = github_rag.retrieve_context(\n    query, # In professional mode, one query will take nearly 1 min to generate final contexts. You could set log level to INFO to monitor the retrieval progress\n    # simple_mode = True\n)\n\nprint(context)\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 5,
    "Content": "\nFor more advanced usage and examples, please refer to the [documentation](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/docs/usage.md).\n\n## Key Features\n\n- **🔍 Intelligent GitHub Retrieval**: Harness the power of llama-github to retrieve highly relevant code snippets, issues, and repository information from GitHub based on user queries. Our advanced retrieval techniques ensure you find the most pertinent information quickly and efficiently.\n\n- **⚡ Repository Pool Caching**: Llama-github has an innovative repository pool caching mechanism. By caching repositories (including READMEs, structures, code, and issues) across threads, llama-github significantly accelerates GitHub search retrieval efficiency and minimizes the consumption of GitHub API tokens. Deploy llama-github in multi-threaded production environments with confidence, knowing that it will perform optimally and save you valuable resources.\n\n- **🧠 LLM-Powered Question Analysis**: Leverage state-of-the-art language models to analyze user questions and generate highly effective search strategies and criteria. Llama-github intelligently breaks down complex queries, ensuring that you retrieve the most relevant information from GitHub's vast repository network.\n\n- **📚 Comprehensive Context Generation**: Generate rich, contextually relevant answers by seamlessly combining information retrieved from GitHub with the reasoning capabilities of advanced language models. Llama-github excels at handling even the most complex and lengthy questions, providing comprehensive and insightful responses that include extensive context to support your development needs.\n\n- **🚀 Asynchronous Processing Excellence**: Llama-github is built from the ground up to leverage the full potential of asynchronous programming. With meticulously implemented asynchronous mechanisms woven throughout the codebase, llama-github can handle multiple requests concurrently, significantly boosting overall performance. Experience the difference as llama-github efficiently manages high-volume workloads without compromising on speed or quality.\n\n- **🔧 Flexible LLM Integration**: Easily integrate llama-github with various LLM providers, embedding models, and reranking models to tailor the library's capabilities to your specific requirements. Our extensible architecture allows you to customize and enhance llama-github's functionality, ensuring that it adapts seamlessly to your unique development environment.\n\n- **🔒 Robust Authentication Options**: Llama-github supports both personal access tokens and GitHub App authentication, providing you with the flexibility to integrate it into different development setups. Whether you're an individual developer or working within an organizational context, llama-github has you covered with secure and reliable authentication mechanisms.\n\n- **🛠️ Logging and Error Handling**: We understand the importance of smooth operations and easy troubleshooting. That's why llama-github comes equipped with comprehensive logging and error handling mechanisms. Gain deep insights into the library's behavior, quickly diagnose issues, and maintain a stable and reliable development workflow.\n\n## 🤖 Try Our AI-Powered PR Review Assistant: LlamaPReview\n\nIf you find llama-github useful, you might also be interested in our AI-powered GitHub PR review assistant, LlamaPReview. It's designed to complement your development workflow and further enhance code quality.\n\n### Key Features of LlamaPReview:\n- 🚀 One-click installation, zero configuration required, fully auto-run\n- 💯 Currently free to use - no credit card or payment info needed\n- 🧠 AI-powered, automatic PR reviews with deep code understanding\n- 🌐 Supports multiple programming languages\n\n**LlamaPReview utilizes llama-github's advanced context retrieval and LLM-powered analysis** to provide intelligent, context-aware code reviews. It's like having a senior developer, armed with the full context of your repository, review every PR automatically!\n\n👉 [Install LlamaPReview Now](https://github.com/marketplace/llamapreview/) (Free)\n\nBy using llama-github for context retrieval and LlamaPReview for code reviews, you can create a powerful, AI-enhanced development environment.\n\n## Vision and Roadmap\n\n### Vision\n\nOur vision is to become a pivotal module in the future of AI-driven development solutions, seamlessly integrating with GitHub to empower LLMs in automatically resolving complex coding tasks.\n\n![Vision Architecture](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/./docs/vision.drawio.svg)\n\n### Roadmap\n\nFor a detailed view of our project roadmap, please visit our [Project Roadmap](https://github.com/users/JetXu-LLM/projects/2).\n\n## Acknowledgments\n\nWe would like to express our gratitude to the following open-source projects for their support and contributions:\n\n- **[LangChain](https://github.com/langchain-ai/langchain)**: For providing the foundational framework that empowers the LLM prompting and processing capabilities in llama-github.\n- **[Jina.ai](https://github.com/jina-ai/reader)**: For offering s.jina.ai API and open source reranker and embedding models that enhance the accuracy and relevance of the generated contexts in llama-github.\n\nTheir contributions have been instrumental in the development of llama-github, and we highly recommend checking out their projects for more innovative solutions.\n\n## Contributing\n\nWe welcome contributions to llama-github! Please see our [contributing guidelines](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/CONTRIBUTING.md) for more information.\n\n## License\n\nThis project is licensed under the terms of the Apache 2.0 license. See the [LICENSE](LICENSE) file for more details.\n\n## Contact\n\nIf you have any questions, suggestions, or feedback, please feel free to reach out to us at [Jet Xu's email](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/mailto:Voldemort.xu@foxmail.com).\n\n---\n\nThank you for choosing llama-github! We hope this library enhances your AI development experience and helps you build powerful applications with ease.\n",
    "ContentSha": "9uwuSakxESmyLicwqpb9te9XJtaLzK41aW7HGRKfVFM=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "더 고급 사용법과 예제는 [문서](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/docs/usage.md)를 참고하세요.\n\n## 주요 기능\n\n- **🔍 지능형 GitHub 검색**: llama-github의 강력한 기능을 활용하여 사용자 쿼리에 기반한 관련성 높은 코드 스니펫, 이슈, 저장소 정보를 GitHub에서 검색합니다. 고급 검색 기법으로 가장 적합한 정보를 빠르고 효율적으로 찾아드립니다.\n\n- **⚡ 저장소 풀 캐싱**: llama-github는 혁신적인 저장소 풀 캐싱 메커니즘을 갖추고 있습니다. 쓰레드 간에 저장소(README, 구조, 코드, 이슈 포함)를 캐싱하여 GitHub 검색 속도를 크게 향상시키고 API 토큰 사용을 최소화합니다. 다중 쓰레드 프로덕션 환경에서도 최적의 성능과 자원 절약을 보장합니다.\n\n- **🧠 LLM 기반 질문 분석**: 최첨단 언어 모델을 활용해 사용자 질문을 분석하고 효과적인 검색 전략과 기준을 생성합니다. llama-github는 복잡한 쿼리를 지능적으로 분해하여 광범위한 GitHub 저장소 네트워크에서 가장 관련성 높은 정보를 찾아냅니다.\n\n- **📚 포괄적 컨텍스트 생성**: GitHub에서 검색한 정보를 최첨단 언어 모델의 추론 능력과 매끄럽게 결합하여 풍부하고 상황에 맞는 답변을 생성합니다. 복잡하고 긴 질문도 뛰어나게 처리하여 개발에 필요한 광범위한 컨텍스트를 포함한 통찰력 있는 답변을 제공합니다.\n\n- **🚀 비동기 처리 최적화**: llama-github는 비동기 프로그래밍의 모든 잠재력을 활용하도록 처음부터 설계되었습니다. 코드베이스 전반에 세심하게 구현된 비동기 메커니즘으로 여러 요청을 동시에 처리하며 전반적인 성능을 크게 향상시킵니다. 많은 작업량도 속도나 품질 저하 없이 효율적으로 관리하는 차이를 경험해보세요.\n\n- **🔧 유연한 LLM 통합**: 다양한 LLM 제공자, 임베딩 모델, 재순위 모델과 쉽게 통합하여 라이브러리 기능을 맞춤화할 수 있습니다. 확장 가능한 아키텍처로 llama-github 기능을 환경에 맞게 자유롭게 조정하고 향상시킬 수 있습니다.\n\n- **🔒 강력한 인증 옵션**: 개인 액세스 토큰과 GitHub 앱 인증 모두를 지원하여 다양한 개발 환경에 유연하게 통합할 수 있습니다. 개인 개발자부터 조직 환경까지 안전하고 신뢰할 수 있는 인증 메커니즘을 제공합니다.\n\n- **🛠️ 로깅 및 오류 처리**: 원활한 운영과 간편한 문제 해결의 중요성을 잘 알고 있습니다. 이에 따라 llama-github는 포괄적인 로깅과 오류 처리 메커니즘을 갖추고 있어 라이브러리 동작을 깊이 파악하고 문제를 신속히 진단하며 안정적인 개발 워크플로우를 유지할 수 있습니다.\n\n## 🤖 AI 기반 PR 리뷰 도우미: LlamaPReview 체험하기\n\nllama-github가 유용하다면 AI 기반 GitHub PR 리뷰 도우미인 LlamaPReview도 관심 가질 만합니다. 개발 워크플로우를 보완하고 코드 품질을 한층 높여줍니다.\n\n### LlamaPReview 주요 기능:\n- 🚀 원클릭 설치, 설정 불필요, 완전 자동 실행\n- 💯 현재 무료 사용 - 신용카드나 결제 정보 필요 없음\n- 🧠 AI 기반 자동 PR 리뷰, 깊은 코드 이해력 탑재\n- 🌐 다중 프로그래밍 언어 지원\n\n**LlamaPReview는 llama-github의 고급 컨텍스트 검색과 LLM 분석을 활용**하여 지능적이고 상황 인지적인 코드 리뷰를 제공합니다. 마치 선임 개발자가 저장소 전체 컨텍스트를 파악한 상태로 모든 PR을 자동 검토하는 것과 같습니다!\n\n👉 [지금 LlamaPReview 설치](https://github.com/marketplace/llamapreview/) (무료)\n\nllama-github의 컨텍스트 검색과 LlamaPReview의 코드 리뷰를 함께 사용하면 강력한 AI 강화 개발 환경을 구축할 수 있습니다.\n\n## 비전 및 로드맵\n\n### 비전\n\n우리의 비전은 AI 기반 개발 솔루션의 핵심 모듈로 자리매김하여 GitHub와 원활하게 통합, LLM이 복잡한 코딩 과제를 자동으로 해결하도록 지원하는 것입니다.\n\n![Vision Architecture](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/./docs/vision.drawio.svg)\n\n### 로드맵\n\n프로젝트 로드맵의 자세한 내용을 보려면 [프로젝트 로드맵](https://github.com/users/JetXu-LLM/projects/2)을 방문하세요.\n\n## 감사의 글\n\n다음 오픈소스 프로젝트들의 지원과 기여에 감사드립니다:\n\n- **[LangChain](https://github.com/langchain-ai/langchain)**: llama-github 내 LLM 프롬프트 및 처리 기능의 기반 프레임워크를 제공합니다.\n- **[Jina.ai](https://github.com/jina-ai/reader)**: s.jina.ai API와 오픈소스 재순위 및 임베딩 모델을 제공하여 llama-github의 컨텍스트 생성 정확도와 관련성을 높입니다.\n\n이들의 기여가 llama-github 개발에 큰 도움이 되었으며, 더 혁신적인 솔루션을 위해 이들 프로젝트를 적극 추천합니다.\n\n## 기여하기\n\nllama-github에 대한 기여를 환영합니다! 자세한 내용은 [기여 가이드라인](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/CONTRIBUTING.md)을 참고하세요.\n\n## 라이선스\n\n본 프로젝트는 Apache 2.0 라이선스에 따라 배포됩니다. 자세한 내용은 [LICENSE](LICENSE) 파일을 참조하세요.\n\n## 연락처\n\n질문, 제안, 피드백이 있으시면 언제든지 [Jet Xu의 이메일](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/mailto:Voldemort.xu@foxmail.com)로 연락해 주세요.\n\n---\n\nllama-github를 선택해 주셔서 감사합니다! 이 라이브러리가 AI 개발 경험을 향상시키고 강력한 애플리케이션을 쉽게 구축하는 데 도움이 되길 바랍니다.\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  }
]