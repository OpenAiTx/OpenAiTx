[
  {
    "Id": 1,
    "Content": "\n<div align=\"right\">\n  <details>\n    <summary >üåê Language</summary>\n    <div>\n      <div align=\"center\">\n        <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=en\">English</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=zh-CN\">ÁÆÄ‰Ωì‰∏≠Êñá</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=zh-TW\">ÁπÅÈ´î‰∏≠Êñá</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=ja\">Êó•Êú¨Ë™û</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=ko\">ÌïúÍµ≠Ïñ¥</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=hi\">‡§π‡§ø‡§®‡•ç‡§¶‡•Ä</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=th\">‡πÑ‡∏ó‡∏¢</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=fr\">Fran√ßais</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=de\">Deutsch</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=es\">Espa√±ol</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=it\">Italiano</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=ru\">–†—É—Å—Å–∫–∏–π</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=pt\">Portugu√™s</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=nl\">Nederlands</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=pl\">Polski</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=ar\">ÿßŸÑÿπÿ±ÿ®Ÿäÿ©</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=fa\">ŸÅÿßÿ±ÿ≥€å</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=tr\">T√ºrk√ße</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=vi\">Ti·∫øng Vi·ªát</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=id\">Bahasa Indonesia</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=as\">‡¶Ö‡¶∏‡¶Æ‡ßÄ‡¶Ø‡¶º‡¶æ</\n      </div>\n    </div>\n  </details>\n</div>\n\n# llama-github\n\n[Detail Document] https://deepwiki.com/JetXu-LLM/llama-github\n\n[![PyPI version](https://badge.fury.io/py/llama-github.svg)](https://badge.fury.io/py/llama-github)\n[![Downloads](https://static.pepy.tech/badge/Llama-github)](https://pepy.tech/project/Llama-github)\n[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)\n\nLlama-github is a powerful tool that helps you retrieve(based on Agentic RAG) the most relevant code snippets, issues, and repository information from GitHub based on your queries, transforming them into valuable knowledge context. It empowers LLM Chatbots, AI Agents, and Auto-dev Agents to solve complex coding tasks. Whether you're a developer looking for quick solutions or an engineer implementing advanced Auto Dev AI Agents, llama-github makes it easy and efficient.\n\nIf you like this project or believe it has potential, please give it a ‚≠êÔ∏è. Your support is our greatest motivation!\n\n## Architecture\n![High Level Architecture](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/./docs/high_level_architecture.drawio.svg)\n\n## Installation",
    "ContentSha": "luGjPJ0t2eUH+w8RDBgGqCVyQiIo+mel0icgkq5phQc=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "\n<div align=\"right\">\n  <details>\n    <summary >üåê Lingua</summary>\n    <div>\n      <div align=\"center\">\n        <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=en\">English</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=zh-CN\">ÁÆÄ‰Ωì‰∏≠Êñá</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=zh-TW\">ÁπÅÈ´î‰∏≠Êñá</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=ja\">Êó•Êú¨Ë™û</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=ko\">ÌïúÍµ≠Ïñ¥</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=hi\">‡§π‡§ø‡§®‡•ç‡§¶‡•Ä</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=th\">‡πÑ‡∏ó‡∏¢</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=fr\">Fran√ßais</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=de\">Deutsch</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=es\">Espa√±ol</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=it\">Italiano</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=ru\">–†—É—Å—Å–∫–∏–π</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=pt\">Portugu√™s</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=nl\">Nederlands</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=pl\">Polski</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=ar\">ÿßŸÑÿπÿ±ÿ®Ÿäÿ©</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=fa\">ŸÅÿßÿ±ÿ≥€å</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=tr\">T√ºrk√ße</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=vi\">Ti·∫øng Vi·ªát</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=id\">Bahasa Indonesia</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=as\">‡¶Ö‡¶∏‡¶Æ‡ßÄ‡¶Ø‡¶º‡¶æ</\n      </div>\n    </div>\n  </details>\n</div>\n\n# llama-github\n\n[Documento Dettagliato] https://deepwiki.com/JetXu-LLM/llama-github\n\n[![Versione PyPI](https://badge.fury.io/py/llama-github.svg)](https://badge.fury.io/py/llama-github)\n[![Download](https://static.pepy.tech/badge/Llama-github)](https://pepy.tech/project/Llama-github)\n[![Licenza](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)\n\nLlama-github √® un potente strumento che ti aiuta a recuperare (basato su Agentic RAG) i frammenti di codice, le issue e le informazioni sui repository pi√π rilevanti da GitHub in base alle tue query, trasformandoli in un contesto di conoscenza prezioso. Potenzia Chatbot LLM, Agenti AI e Auto-dev Agent per risolvere compiti di codifica complessi. Che tu sia uno sviluppatore alla ricerca di soluzioni rapide o un ingegnere che implementa avanzati Agenti AI per Auto Dev, llama-github rende tutto semplice ed efficiente.\n\nSe ti piace questo progetto o pensi che abbia del potenziale, lasciaci una ‚≠êÔ∏è. Il tuo supporto √® la nostra pi√π grande motivazione!\n\n## Architettura\n![Architettura di Alto Livello](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/./docs/high_level_architecture.drawio.svg)\n\n## Installazione",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 2,
        "rowsha": "cWgam+tnnXudu7i74+ahMEGk/A9dQS+EwWLAIfi3dHk=",
        "originContent": "<div align=\"right\">",
        "translatedContent": "<div align=\"right\">"
      },
      {
        "row": 3,
        "rowsha": "orOcu5ARna/hb3RUkj6dBI8pHTM3WHeTvby17l5E0h0=",
        "originContent": "  <details>",
        "translatedContent": "  <details>"
      },
      {
        "row": 4,
        "rowsha": "TtgkLzblnvP0q9aAIVXt6s2LczXjy5k+QvHKcU0/5Ms=",
        "originContent": "    <summary >üåê Language</summary>",
        "translatedContent": "    <summary >üåê Lingua</summary>"
      },
      {
        "row": 5,
        "rowsha": "fZtk4rPTAJEEslnbhSVkHEcPlsctYSzAV7CDPL3rJmA=",
        "originContent": "    <div>",
        "translatedContent": "    <div>"
      },
      {
        "row": 6,
        "rowsha": "9KQxOeJSigvTmGWO+mtnl8kZY9zQfueoy8sk4lYm09Q=",
        "originContent": "      <div align=\"center\">",
        "translatedContent": "      <div align=\"center\">"
      },
      {
        "row": 7,
        "rowsha": "HkJ4Gkepsmtc5YEEOiqUG3+NzfI0rf4IVUDgqFAmscs=",
        "originContent": "        <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=en\">English</a>",
        "translatedContent": "        <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=en\">English</a>"
      },
      {
        "row": 8,
        "rowsha": "SS8k2BQkHAHxyWP2X90nPl4mRZWm3fwXGqGF7mjnz18=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=zh-CN\">ÁÆÄ‰Ωì‰∏≠Êñá</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=zh-CN\">ÁÆÄ‰Ωì‰∏≠Êñá</a>"
      },
      {
        "row": 9,
        "rowsha": "VrMYTJ2mzoZzeIKdl57fntnJgzWRQqxW+Hh05WTobsc=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=zh-TW\">ÁπÅÈ´î‰∏≠Êñá</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=zh-TW\">ÁπÅÈ´î‰∏≠Êñá</a>"
      },
      {
        "row": 10,
        "rowsha": "c+DqTRbRnir4FoupjpEksFzVENBVWRYltmlpDbwQZmM=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=ja\">Êó•Êú¨Ë™û</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=ja\">Êó•Êú¨Ë™û</a>"
      },
      {
        "row": 11,
        "rowsha": "Tm7I5B+gkMpCeJ3LR+BslLE5wbSUneyFmLReBj+Kuws=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=ko\">ÌïúÍµ≠Ïñ¥</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=ko\">ÌïúÍµ≠Ïñ¥</a>"
      },
      {
        "row": 12,
        "rowsha": "wfZ0J7KdM7EX/cxK3wFAeE2ngExW4GfEYqHcAGlGx0w=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=hi\">‡§π‡§ø‡§®‡•ç‡§¶‡•Ä</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=hi\">‡§π‡§ø‡§®‡•ç‡§¶‡•Ä</a>"
      },
      {
        "row": 13,
        "rowsha": "y2QtQCnUvpYYte3U998DjX4FmVJMdwyXZ6wpYmbQkLE=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=th\">‡πÑ‡∏ó‡∏¢</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=th\">‡πÑ‡∏ó‡∏¢</a>"
      },
      {
        "row": 14,
        "rowsha": "zIupl7qEGAUFd0PjTxnqfYLAOYVxukVObZ2TvLzJhFI=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=fr\">Fran√ßais</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=fr\">Fran√ßais</a>"
      },
      {
        "row": 15,
        "rowsha": "NeTDxlUu1SaaYA+ZU+IrCgYKslSqZUFfuhtr46HJnA0=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=de\">Deutsch</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=de\">Deutsch</a>"
      },
      {
        "row": 16,
        "rowsha": "0ltGddRJZJCJAdD4E6lPYrnG+o9jxtvzFgZ6J422BVM=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=es\">Espa√±ol</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=es\">Espa√±ol</a>"
      },
      {
        "row": 17,
        "rowsha": "bzUdBLPtDNoKHOYQKJtE2KKD9trvdid+RiSJUXJ06jY=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=it\">Italiano</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=it\">Italiano</a>"
      },
      {
        "row": 18,
        "rowsha": "0pozScPeqLIHLCyJkRlRQjDqqKb8HWwWqCv6uaxalEY=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=ru\">–†—É—Å—Å–∫–∏–π</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=ru\">–†—É—Å—Å–∫–∏–π</a>"
      },
      {
        "row": 19,
        "rowsha": "ACT6kxJUtjo44NDX/ea/HxspYPgjmIuENrgcnxQYNEc=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=pt\">Portugu√™s</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=pt\">Portugu√™s</a>"
      },
      {
        "row": 20,
        "rowsha": "P5r7piMIRIzTPNX8NrKqGo+P1glz8ZRuJCLyQL24/LA=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=nl\">Nederlands</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=nl\">Nederlands</a>"
      },
      {
        "row": 21,
        "rowsha": "ZGMoXno6QdwcE1MCQ6a+39T9cMR9m1YyVj19nEOHOR8=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=pl\">Polski</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=pl\">Polski</a>"
      },
      {
        "row": 22,
        "rowsha": "VKZ+5aGayrqfPfJYP0j0/ap6ocirm1axw5vVvu7xsEE=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=ar\">ÿßŸÑÿπÿ±ÿ®Ÿäÿ©</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=ar\">ÿßŸÑÿπÿ±ÿ®Ÿäÿ©</a>"
      },
      {
        "row": 23,
        "rowsha": "CWIbKiayiPOGqPcuulT54J/JKB9czskFXkMCgTgHrZs=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=fa\">ŸÅÿßÿ±ÿ≥€å</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=fa\">ŸÅÿßÿ±ÿ≥€å</a>"
      },
      {
        "row": 24,
        "rowsha": "I1WcwpKhgv19NGCtlw+KLX03QSTLreFKCC9Ta0pFqIs=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=tr\">T√ºrk√ße</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=tr\">T√ºrk√ße</a>"
      },
      {
        "row": 25,
        "rowsha": "gIl9QJ2GwM0yfNYEXpcS2/xbtyKJbynqn4H4tnOyU2c=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=vi\">Ti·∫øng Vi·ªát</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=vi\">Ti·∫øng Vi·ªát</a>"
      },
      {
        "row": 26,
        "rowsha": "sMhilkGyfjhl6TXDHf4CKYnKDjhJR8fFg2lWQtaLDKc=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=id\">Bahasa Indonesia</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=id\">Bahasa Indonesia</a>"
      },
      {
        "row": 27,
        "rowsha": "SFIUIQN+2TXGoifui/NZlin5QtiRQtdF5of1FBBu7Gk=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=as\">‡¶Ö‡¶∏‡¶Æ‡ßÄ‡¶Ø‡¶º‡¶æ</",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=as\">‡¶Ö‡¶∏‡¶Æ‡ßÄ‡¶Ø‡¶º‡¶æ</"
      },
      {
        "row": 28,
        "rowsha": "0OM5wNEm0TO56MEBvQzL7AUZM7/3OpgIeqRf2zFre3Q=",
        "originContent": "      </div>",
        "translatedContent": "      </div>"
      },
      {
        "row": 29,
        "rowsha": "fcjTfY+fs8YnY5slBs1sZvWPAqEQR7tzaBDO54skkGQ=",
        "originContent": "    </div>",
        "translatedContent": "    </div>"
      },
      {
        "row": 30,
        "rowsha": "+fQNH2ldI7UM/rqRscP3hUSWAmw1HvQ2wEKDN8JagT0=",
        "originContent": "  </details>",
        "translatedContent": "  </details>"
      },
      {
        "row": 31,
        "rowsha": "qsMmUbEPVnxGG5tPJV1vsfpoWbU2jYvZpRr5IKshzyM=",
        "originContent": "</div>",
        "translatedContent": "</div>"
      },
      {
        "row": 32,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 33,
        "rowsha": "cAI8B2fw5xCydddeNcosOFY2wrQw8An1lrdomk97KBc=",
        "originContent": "# llama-github",
        "translatedContent": "# llama-github"
      },
      {
        "row": 34,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 35,
        "rowsha": "jSTPMiMb5qDjmRYlxqDSx6zbsKYKOv4c6HQQgjbDUqo=",
        "originContent": "[Detail Document] https://deepwiki.com/JetXu-LLM/llama-github",
        "translatedContent": "[Documento Dettagliato] https://deepwiki.com/JetXu-LLM/llama-github"
      },
      {
        "row": 36,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 37,
        "rowsha": "48lo1Cg6fyAcQl554s/7eKSc41UYvSn/CD6yxtLVgjY=",
        "originContent": "[![PyPI version](https://badge.fury.io/py/llama-github.svg)](https://badge.fury.io/py/llama-github)",
        "translatedContent": "[![Versione PyPI](https://badge.fury.io/py/llama-github.svg)](https://badge.fury.io/py/llama-github)"
      },
      {
        "row": 38,
        "rowsha": "VG3AfiYLkBPipFZPAt/fJt5jj8aI773UKbmI1Z/kc2M=",
        "originContent": "[![Downloads](https://static.pepy.tech/badge/Llama-github)](https://pepy.tech/project/Llama-github)",
        "translatedContent": "[![Download](https://static.pepy.tech/badge/Llama-github)](https://pepy.tech/project/Llama-github)"
      },
      {
        "row": 39,
        "rowsha": "U0vs77tGfFYY+r4ScaOhTOZDgt8vSKCUyj59tU13ZtE=",
        "originContent": "[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)",
        "translatedContent": "[![Licenza](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)"
      },
      {
        "row": 40,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 41,
        "rowsha": "y7xsY1R0s8pmwDQukNS2PQ5JqK6CRs8AwuPrZkBKiT8=",
        "originContent": "Llama-github is a powerful tool that helps you retrieve(based on Agentic RAG) the most relevant code snippets, issues, and repository information from GitHub based on your queries, transforming them into valuable knowledge context. It empowers LLM Chatbots, AI Agents, and Auto-dev Agents to solve complex coding tasks. Whether you're a developer looking for quick solutions or an engineer implementing advanced Auto Dev AI Agents, llama-github makes it easy and efficient.",
        "translatedContent": "Llama-github √® un potente strumento che ti aiuta a recuperare (basato su Agentic RAG) i frammenti di codice, le issue e le informazioni sui repository pi√π rilevanti da GitHub in base alle tue query, trasformandoli in un contesto di conoscenza prezioso. Potenzia Chatbot LLM, Agenti AI e Auto-dev Agent per risolvere compiti di codifica complessi. Che tu sia uno sviluppatore alla ricerca di soluzioni rapide o un ingegnere che implementa avanzati Agenti AI per Auto Dev, llama-github rende tutto semplice ed efficiente."
      },
      {
        "row": 42,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 43,
        "rowsha": "6h9r25r7afHOT0YHlaj7xv1WU2JfjWqSqLUM7UgJNfQ=",
        "originContent": "If you like this project or believe it has potential, please give it a ‚≠êÔ∏è. Your support is our greatest motivation!",
        "translatedContent": "Se ti piace questo progetto o pensi che abbia del potenziale, lasciaci una ‚≠êÔ∏è. Il tuo supporto √® la nostra pi√π grande motivazione!"
      },
      {
        "row": 44,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 45,
        "rowsha": "p+VkcrEb08g4vIGZYB9aVScRKgA8afv5WwErwTVzoZM=",
        "originContent": "## Architecture",
        "translatedContent": "## Architettura"
      },
      {
        "row": 46,
        "rowsha": "TiSukfY/+ter5MJ39DMtNdHlqRXwhZFkP3uTdAfvA0c=",
        "originContent": "![High Level Architecture](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/./docs/high_level_architecture.drawio.svg)",
        "translatedContent": "![Architettura di Alto Livello](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/./docs/high_level_architecture.drawio.svg)"
      },
      {
        "row": 47,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 48,
        "rowsha": "oV0SUDvwD2VN8Gi9nlr2JZ2xcDrASmE2W5kc5SVX5eo=",
        "originContent": "## Installation",
        "translatedContent": "## Installazione"
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 2,
    "Content": "```\npip install llama-github\n```",
    "ContentSha": "A7Ioj19mKQ2poo2/SNNEl/PUNM9x+13/7/ncgppdcgY=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```\npip install llama-github\n```",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      },
      {
        "row": 2,
        "rowsha": "HUzQ8Fuh/Wg8Hu8KR8bezJLbFVpPKMpf5Pa7xDY6vYM=",
        "originContent": "pip install llama-github",
        "translatedContent": "pip install llama-github"
      },
      {
        "row": 3,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      }
    ],
    "IsCodeBlock": true
  },
  {
    "Id": 3,
    "Content": "\n## Usage\n\nHere's a simple example of how to use llama-github:\n",
    "ContentSha": "oqzkRVGHtTMxKJniKYy+bJRBu/B3l8AYVVo5suNCmR4=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "\n## Utilizzo\n\nEcco un semplice esempio su come utilizzare llama-github:\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 2,
        "rowsha": "Y7/WGgVhslWiyqCi463Qkcp+Mn8voGpAfLsv80G4WNg=",
        "originContent": "## Usage",
        "translatedContent": "## Utilizzo"
      },
      {
        "row": 3,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 4,
        "rowsha": "4zRpXijfFggW+Fd/VZ8qaLkuJwnjePE96Hy1hPxOIRE=",
        "originContent": "Here's a simple example of how to use llama-github:",
        "translatedContent": "Ecco un semplice esempio su come utilizzare llama-github:"
      },
      {
        "row": 5,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 4,
    "Content": "```python\nfrom llama_github import GithubRAG\n\n# Initialize GithubRAG with your credentials\ngithub_rag = GithubRAG(\n    github_access_token=\"your_github_access_token\", \n    openai_api_key=\"your_openai_api_key\", # Optional in Simple Mode\n    jina_api_key=\"your_jina_api_key\" # Optional - unless you want high concurrency production deployment (s.jina.ai API will be used in llama-github)\n)\n\n# Retrieve context for a coding question (simple_mode is default set to False)\nquery = \"How to create a NumPy array in Python?\"\ncontext = github_rag.retrieve_context(\n    query, # In professional mode, one query will take nearly 1 min to generate final contexts. You could set log level to INFO to monitor the retrieval progress\n    # simple_mode = True\n)\n\nprint(context)\n```",
    "ContentSha": "HXBtstD3V5wfKLk68/A2T/KFqRB/TtW5s0tq89CzhFU=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```python\nfrom llama_github import GithubRAG\n\n# Initialize GithubRAG with your credentials\ngithub_rag = GithubRAG(\n    github_access_token=\"your_github_access_token\", \n    openai_api_key=\"your_openai_api_key\", # Optional in Simple Mode\n    jina_api_key=\"your_jina_api_key\" # Optional - unless you want high concurrency production deployment (s.jina.ai API will be used in llama-github)\n)\n\n# Retrieve context for a coding question (simple_mode is default set to False)\nquery = \"How to create a NumPy array in Python?\"\ncontext = github_rag.retrieve_context(\n    query, # In professional mode, one query will take nearly 1 min to generate final contexts. You could set log level to INFO to monitor the retrieval progress\n    # simple_mode = True\n)\n\nprint(context)\n```",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "uDnRsrcDV2kZVI2wi9EA58m+F4ILdr1bvjhqNlB+wSc=",
        "originContent": "```python",
        "translatedContent": "```python"
      },
      {
        "row": 2,
        "rowsha": "hA5UQDttQHKAwB+ESl7GqyiAa1AotkDZYMGTRuo/AoY=",
        "originContent": "from llama_github import GithubRAG",
        "translatedContent": "from llama_github import GithubRAG"
      },
      {
        "row": 3,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 4,
        "rowsha": "/Xio12pWjWQxdHtqP9gkrQo8FvXup5Rnp8m6s9rWQoA=",
        "originContent": "# Initialize GithubRAG with your credentials",
        "translatedContent": "# Initialize GithubRAG with your credentials"
      },
      {
        "row": 5,
        "rowsha": "Z/GdSwf7Zfjb56iNk/lrSDiBY4vaKvdGc5F3qO5IgSQ=",
        "originContent": "github_rag = GithubRAG(",
        "translatedContent": "github_rag = GithubRAG("
      },
      {
        "row": 6,
        "rowsha": "DCUT+XvqWQMhTvTxgZeTkNrf6sB1egP0ataQmEq//Do=",
        "originContent": "    github_access_token=\"your_github_access_token\", ",
        "translatedContent": "    github_access_token=\"your_github_access_token\", "
      },
      {
        "row": 7,
        "rowsha": "7hDiOA+9nEfENa9R7NEJW8WSnmj71txD0Ndrw3HjngM=",
        "originContent": "    openai_api_key=\"your_openai_api_key\", # Optional in Simple Mode",
        "translatedContent": "    openai_api_key=\"your_openai_api_key\", # Optional in Simple Mode"
      },
      {
        "row": 8,
        "rowsha": "3gER4AqcTSuWLMk5yIWdhwT240c1f6O0Qk92225ZuVU=",
        "originContent": "    jina_api_key=\"your_jina_api_key\" # Optional - unless you want high concurrency production deployment (s.jina.ai API will be used in llama-github)",
        "translatedContent": "    jina_api_key=\"your_jina_api_key\" # Optional - unless you want high concurrency production deployment (s.jina.ai API will be used in llama-github)"
      },
      {
        "row": 9,
        "rowsha": "ul7FHQekrA6VFghwRDHVmgKyGk6VGswQUFqNxAfFAe4=",
        "originContent": ")",
        "translatedContent": ")"
      },
      {
        "row": 10,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 11,
        "rowsha": "U1SUJQpzS8NM2yh7MFPYJl5dQ6gq/MR813WqTX952X0=",
        "originContent": "# Retrieve context for a coding question (simple_mode is default set to False)",
        "translatedContent": "# Retrieve context for a coding question (simple_mode is default set to False)"
      },
      {
        "row": 12,
        "rowsha": "ZXVeMLKgPJjdKhiZ9CK5U4oP9OsdwnWdpg8zNqEI+58=",
        "originContent": "query = \"How to create a NumPy array in Python?\"",
        "translatedContent": "query = \"How to create a NumPy array in Python?\""
      },
      {
        "row": 13,
        "rowsha": "tMIfL+j+gxN0VAT5YvCwzTJ6i5aIIY3fcw3LxJWoTrQ=",
        "originContent": "context = github_rag.retrieve_context(",
        "translatedContent": "context = github_rag.retrieve_context("
      },
      {
        "row": 14,
        "rowsha": "Q1vTmUoyeud2ZNyE6iVCY7OriQi61Wg6NLrSyM9pVLE=",
        "originContent": "    query, # In professional mode, one query will take nearly 1 min to generate final contexts. You could set log level to INFO to monitor the retrieval progress",
        "translatedContent": "    query, # In professional mode, one query will take nearly 1 min to generate final contexts. You could set log level to INFO to monitor the retrieval progress"
      },
      {
        "row": 15,
        "rowsha": "uvb8HENvYITO6V3XF0E9tyqODM0Be+CdeIuXZsYj/CA=",
        "originContent": "    # simple_mode = True",
        "translatedContent": "    # simple_mode = True"
      },
      {
        "row": 16,
        "rowsha": "ul7FHQekrA6VFghwRDHVmgKyGk6VGswQUFqNxAfFAe4=",
        "originContent": ")",
        "translatedContent": ")"
      },
      {
        "row": 17,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 18,
        "rowsha": "ZZEcMA2fivnNWsWr7Vg5FUhhpwQQJ/ThJU+S148t13E=",
        "originContent": "print(context)",
        "translatedContent": "print(context)"
      },
      {
        "row": 19,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      }
    ],
    "IsCodeBlock": true
  },
  {
    "Id": 5,
    "Content": "\nFor more advanced usage and examples, please refer to the [documentation](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/docs/usage.md).\n\n## Key Features\n\n- **üîç Intelligent GitHub Retrieval**: Harness the power of llama-github to retrieve highly relevant code snippets, issues, and repository information from GitHub based on user queries. Our advanced retrieval techniques ensure you find the most pertinent information quickly and efficiently.\n\n- **‚ö° Repository Pool Caching**: Llama-github has an innovative repository pool caching mechanism. By caching repositories (including READMEs, structures, code, and issues) across threads, llama-github significantly accelerates GitHub search retrieval efficiency and minimizes the consumption of GitHub API tokens. Deploy llama-github in multi-threaded production environments with confidence, knowing that it will perform optimally and save you valuable resources.\n\n- **üß† LLM-Powered Question Analysis**: Leverage state-of-the-art language models to analyze user questions and generate highly effective search strategies and criteria. Llama-github intelligently breaks down complex queries, ensuring that you retrieve the most relevant information from GitHub's vast repository network.\n\n- **üìö Comprehensive Context Generation**: Generate rich, contextually relevant answers by seamlessly combining information retrieved from GitHub with the reasoning capabilities of advanced language models. Llama-github excels at handling even the most complex and lengthy questions, providing comprehensive and insightful responses that include extensive context to support your development needs.\n\n- **üöÄ Asynchronous Processing Excellence**: Llama-github is built from the ground up to leverage the full potential of asynchronous programming. With meticulously implemented asynchronous mechanisms woven throughout the codebase, llama-github can handle multiple requests concurrently, significantly boosting overall performance. Experience the difference as llama-github efficiently manages high-volume workloads without compromising on speed or quality.\n\n- **üîß Flexible LLM Integration**: Easily integrate llama-github with various LLM providers, embedding models, and reranking models to tailor the library's capabilities to your specific requirements. Our extensible architecture allows you to customize and enhance llama-github's functionality, ensuring that it adapts seamlessly to your unique development environment.\n\n- **üîí Robust Authentication Options**: Llama-github supports both personal access tokens and GitHub App authentication, providing you with the flexibility to integrate it into different development setups. Whether you're an individual developer or working within an organizational context, llama-github has you covered with secure and reliable authentication mechanisms.\n\n- **üõ†Ô∏è Logging and Error Handling**: We understand the importance of smooth operations and easy troubleshooting. That's why llama-github comes equipped with comprehensive logging and error handling mechanisms. Gain deep insights into the library's behavior, quickly diagnose issues, and maintain a stable and reliable development workflow.\n\n## ü§ñ Try Our AI-Powered PR Review Assistant: LlamaPReview\n\nIf you find llama-github useful, you might also be interested in our AI-powered GitHub PR review assistant, LlamaPReview. It's designed to complement your development workflow and further enhance code quality.\n\n### Key Features of LlamaPReview:\n- üöÄ One-click installation, zero configuration required, fully auto-run\n- üíØ Currently free to use - no credit card or payment info needed\n- üß† AI-powered, automatic PR reviews with deep code understanding\n- üåê Supports multiple programming languages\n\n**LlamaPReview utilizes llama-github's advanced context retrieval and LLM-powered analysis** to provide intelligent, context-aware code reviews. It's like having a senior developer, armed with the full context of your repository, review every PR automatically!\n\nüëâ [Install LlamaPReview Now](https://github.com/marketplace/llamapreview/) (Free)\n\nBy using llama-github for context retrieval and LlamaPReview for code reviews, you can create a powerful, AI-enhanced development environment.\n\n## Vision and Roadmap\n\n### Vision\n\nOur vision is to become a pivotal module in the future of AI-driven development solutions, seamlessly integrating with GitHub to empower LLMs in automatically resolving complex coding tasks.\n\n![Vision Architecture](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/./docs/vision.drawio.svg)\n\n### Roadmap\n\nFor a detailed view of our project roadmap, please visit our [Project Roadmap](https://github.com/users/JetXu-LLM/projects/2).\n\n## Acknowledgments\n\nWe would like to express our gratitude to the following open-source projects for their support and contributions:\n\n- **[LangChain](https://github.com/langchain-ai/langchain)**: For providing the foundational framework that empowers the LLM prompting and processing capabilities in llama-github.\n- **[Jina.ai](https://github.com/jina-ai/reader)**: For offering s.jina.ai API and open source reranker and embedding models that enhance the accuracy and relevance of the generated contexts in llama-github.\n\nTheir contributions have been instrumental in the development of llama-github, and we highly recommend checking out their projects for more innovative solutions.\n\n## Contributing\n\nWe welcome contributions to llama-github! Please see our [contributing guidelines](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/CONTRIBUTING.md) for more information.\n\n## License\n\nThis project is licensed under the terms of the Apache 2.0 license. See the [LICENSE](LICENSE) file for more details.\n\n## Contact\n\nIf you have any questions, suggestions, or feedback, please feel free to reach out to us at [Jet Xu's email](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/mailto:Voldemort.xu@foxmail.com).\n\n---\n\nThank you for choosing llama-github! We hope this library enhances your AI development experience and helps you build powerful applications with ease.\n",
    "ContentSha": "9uwuSakxESmyLicwqpb9te9XJtaLzK41aW7HGRKfVFM=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "\nPer un utilizzo pi√π avanzato ed esempi, consulta la [documentazione](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/docs/usage.md).\n\n## Caratteristiche Principali\n\n- **üîç Recupero Intelligente da GitHub**: Sfrutta la potenza di llama-github per recuperare snippet di codice, issue e informazioni sui repository altamente pertinenti da GitHub in base alle richieste dell‚Äôutente. Le nostre tecniche avanzate di recupero assicurano che tu possa trovare rapidamente ed efficientemente le informazioni pi√π rilevanti.\n\n- **‚ö° Caching del Pool di Repository**: Llama-github possiede un innovativo meccanismo di caching del pool di repository. Caching dei repository (inclusi README, strutture, codice e issue) attraverso i thread, llama-github accelera notevolmente l‚Äôefficienza del recupero delle ricerche su GitHub e minimizza il consumo di token API GitHub. Distribuisci llama-github in ambienti di produzione multi-thread con fiducia, sapendo che funzioner√† al meglio e ti far√† risparmiare risorse preziose.\n\n- **üß† Analisi delle Domande Basata su LLM**: Sfrutta modelli linguistici all‚Äôavanguardia per analizzare le domande degli utenti e generare strategie e criteri di ricerca altamente efficaci. Llama-github scompone intelligentemente query complesse, assicurando che tu possa recuperare le informazioni pi√π pertinenti dalla vasta rete di repository di GitHub.\n\n- **üìö Generazione di Contesto Completa**: Genera risposte ricche e contestualmente rilevanti combinando senza problemi le informazioni recuperate da GitHub con le capacit√† di ragionamento dei modelli linguistici avanzati. Llama-github eccelle nella gestione di domande anche molto complesse e lunghe, fornendo risposte approfondite e ricche di contesto per supportare le tue esigenze di sviluppo.\n\n- **üöÄ Eccellenza nell‚ÄôElaborazione Asincrona**: Llama-github √® costruito da zero per sfruttare il pieno potenziale della programmazione asincrona. Con meccanismi asincroni implementati meticolosamente in tutto il codice, llama-github pu√≤ gestire pi√π richieste contemporaneamente, aumentando notevolmente le prestazioni complessive. Prova la differenza mentre llama-github gestisce efficientemente carichi di lavoro elevati senza compromettere velocit√† o qualit√†.\n\n- **üîß Integrazione Flessibile con LLM**: Integra facilmente llama-github con diversi provider LLM, modelli di embedding e modelli di reranking per adattare le capacit√† della libreria ai tuoi requisiti specifici. La nostra architettura estensibile ti consente di personalizzare e migliorare le funzionalit√† di llama-github, assicurando un‚Äôintegrazione fluida con il tuo ambiente di sviluppo.\n\n- **üîí Opzioni di Autenticazione Robuste**: Llama-github supporta sia i token di accesso personale sia l‚Äôautenticazione tramite GitHub App, offrendoti la flessibilit√† per integrarlo in diversi ambienti di sviluppo. Che tu sia uno sviluppatore individuale o lavori in un contesto organizzativo, llama-github ti offre meccanismi di autenticazione sicuri e affidabili.\n\n- **üõ†Ô∏è Logging e Gestione Errori**: Comprendiamo l‚Äôimportanza di un funzionamento fluido e di una facile risoluzione dei problemi. Per questo llama-github √® dotato di meccanismi completi di logging e gestione degli errori. Ottieni approfondimenti dettagliati sul comportamento della libreria, diagnostica rapidamente i problemi e mantieni un workflow di sviluppo stabile e affidabile.\n\n## ü§ñ Prova il Nostro Assistant AI per la Revisione PR: LlamaPReview\n\nSe trovi utile llama-github, potresti essere interessato anche al nostro assistente AI per la revisione di PR su GitHub, LlamaPReview. √à progettato per integrare il tuo workflow di sviluppo e migliorare ulteriormente la qualit√† del codice.\n\n### Caratteristiche Principali di LlamaPReview:\n- üöÄ Installazione con un clic, nessuna configurazione richiesta, esecuzione completamente automatica\n- üíØ Attualmente gratuito - nessuna carta di credito o pagamento richiesto\n- üß† Recensioni PR automatiche, basate su AI, con profonda comprensione del codice\n- üåê Supporta molteplici linguaggi di programmazione\n\n**LlamaPReview utilizza il recupero di contesto avanzato e l‚Äôanalisi LLM di llama-github** per offrire revisioni intelligenti e consapevoli del contesto. √à come avere un senior developer, armato del contesto completo del tuo repository, che rivede ogni PR automaticamente!\n\nüëâ [Installa LlamaPReview Ora](https://github.com/marketplace/llamapreview/) (Gratis)\n\nUtilizzando llama-github per il recupero del contesto e LlamaPReview per le revisioni del codice, puoi creare un potente ambiente di sviluppo potenziato dall‚ÄôAI.\n\n## Visione e Roadmap\n\n### Visione\n\nLa nostra visione √® diventare un modulo fondamentale nel futuro delle soluzioni di sviluppo guidate dall‚ÄôAI, integrandoci perfettamente con GitHub per consentire agli LLM di risolvere automaticamente compiti di coding complessi.\n\n![Vision Architecture](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/./docs/vision.drawio.svg)\n\n### Roadmap\n\nPer una panoramica dettagliata della nostra roadmap, visita il nostro [Project Roadmap](https://github.com/users/JetXu-LLM/projects/2).\n\n## Riconoscimenti\n\nDesideriamo esprimere la nostra gratitudine ai seguenti progetti open-source per il loro supporto e contributo:\n\n- **[LangChain](https://github.com/langchain-ai/langchain)**: Per aver fornito il framework di base che potenzia le capacit√† di prompting e processing LLM in llama-github.\n- **[Jina.ai](https://github.com/jina-ai/reader)**: Per aver offerto API s.jina.ai e modelli open source di reranking ed embedding che migliorano la precisione e la pertinenza dei contesti generati in llama-github.\n\nI loro contributi sono stati fondamentali per lo sviluppo di llama-github e raccomandiamo vivamente di esplorare i loro progetti per altre soluzioni innovative.\n\n## Contribuire\n\nAccogliamo con piacere i contributi a llama-github! Consulta le nostre [linee guida per i contributi](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/CONTRIBUTING.md) per maggiori informazioni.\n\n## Licenza\n\nQuesto progetto √® rilasciato secondo i termini della licenza Apache 2.0. Consulta il file [LICENSE](LICENSE) per maggiori dettagli.\n\n## Contatti\n\nSe hai domande, suggerimenti o feedback, sentiti libero di contattarci a [l‚Äôemail di Jet Xu](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/mailto:Voldemort.xu@foxmail.com).\n\n---\n\nGrazie per aver scelto llama-github! Speriamo che questa libreria migliori la tua esperienza di sviluppo AI e ti aiuti a costruire potenti applicazioni con facilit√†.\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 2,
        "rowsha": "zrMByz3uboJewll5VwM0OlM3JCc+dvchgXugvMGdZyA=",
        "originContent": "For more advanced usage and examples, please refer to the [documentation](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/docs/usage.md).",
        "translatedContent": "Per un utilizzo pi√π avanzato ed esempi, consulta la [documentazione](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/docs/usage.md)."
      },
      {
        "row": 3,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 4,
        "rowsha": "khTPM/+Q4D8FMdf3qgrMDcjDejggkuMl1+JmWZMODFI=",
        "originContent": "## Key Features",
        "translatedContent": "## Caratteristiche Principali"
      },
      {
        "row": 5,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 6,
        "rowsha": "DfE9NcmRSF011JyFgs3cD/a2VQqPhp+XXqaTnhAtBwc=",
        "originContent": "- **üîç Intelligent GitHub Retrieval**: Harness the power of llama-github to retrieve highly relevant code snippets, issues, and repository information from GitHub based on user queries. Our advanced retrieval techniques ensure you find the most pertinent information quickly and efficiently.",
        "translatedContent": "- **üîç Recupero Intelligente da GitHub**: Sfrutta la potenza di llama-github per recuperare snippet di codice, issue e informazioni sui repository altamente pertinenti da GitHub in base alle richieste dell‚Äôutente. Le nostre tecniche avanzate di recupero assicurano che tu possa trovare rapidamente ed efficientemente le informazioni pi√π rilevanti."
      },
      {
        "row": 7,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 8,
        "rowsha": "OtNyTLgFLD0QDlCwfKWcttMbckHUBj2YJNKV9r+Uc54=",
        "originContent": "- **‚ö° Repository Pool Caching**: Llama-github has an innovative repository pool caching mechanism. By caching repositories (including READMEs, structures, code, and issues) across threads, llama-github significantly accelerates GitHub search retrieval efficiency and minimizes the consumption of GitHub API tokens. Deploy llama-github in multi-threaded production environments with confidence, knowing that it will perform optimally and save you valuable resources.",
        "translatedContent": "- **‚ö° Caching del Pool di Repository**: Llama-github possiede un innovativo meccanismo di caching del pool di repository. Caching dei repository (inclusi README, strutture, codice e issue) attraverso i thread, llama-github accelera notevolmente l‚Äôefficienza del recupero delle ricerche su GitHub e minimizza il consumo di token API GitHub. Distribuisci llama-github in ambienti di produzione multi-thread con fiducia, sapendo che funzioner√† al meglio e ti far√† risparmiare risorse preziose."
      },
      {
        "row": 9,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 10,
        "rowsha": "JeXb8RZZhv2Wmw97j628XoyPreY+fMdIPsxoUQiEvzw=",
        "originContent": "- **üß† LLM-Powered Question Analysis**: Leverage state-of-the-art language models to analyze user questions and generate highly effective search strategies and criteria. Llama-github intelligently breaks down complex queries, ensuring that you retrieve the most relevant information from GitHub's vast repository network.",
        "translatedContent": "- **üß† Analisi delle Domande Basata su LLM**: Sfrutta modelli linguistici all‚Äôavanguardia per analizzare le domande degli utenti e generare strategie e criteri di ricerca altamente efficaci. Llama-github scompone intelligentemente query complesse, assicurando che tu possa recuperare le informazioni pi√π pertinenti dalla vasta rete di repository di GitHub."
      },
      {
        "row": 11,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 12,
        "rowsha": "yA7pWfx0KVCXQ2Eo49pVkbLR+DABI/mKnMw/tj/sCL0=",
        "originContent": "- **üìö Comprehensive Context Generation**: Generate rich, contextually relevant answers by seamlessly combining information retrieved from GitHub with the reasoning capabilities of advanced language models. Llama-github excels at handling even the most complex and lengthy questions, providing comprehensive and insightful responses that include extensive context to support your development needs.",
        "translatedContent": "- **üìö Generazione di Contesto Completa**: Genera risposte ricche e contestualmente rilevanti combinando senza problemi le informazioni recuperate da GitHub con le capacit√† di ragionamento dei modelli linguistici avanzati. Llama-github eccelle nella gestione di domande anche molto complesse e lunghe, fornendo risposte approfondite e ricche di contesto per supportare le tue esigenze di sviluppo."
      },
      {
        "row": 13,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 14,
        "rowsha": "qku0KFnzN0JDJsFtvSnr1U47mAfoIMLCUgoTAF0FV2Q=",
        "originContent": "- **üöÄ Asynchronous Processing Excellence**: Llama-github is built from the ground up to leverage the full potential of asynchronous programming. With meticulously implemented asynchronous mechanisms woven throughout the codebase, llama-github can handle multiple requests concurrently, significantly boosting overall performance. Experience the difference as llama-github efficiently manages high-volume workloads without compromising on speed or quality.",
        "translatedContent": "- **üöÄ Eccellenza nell‚ÄôElaborazione Asincrona**: Llama-github √® costruito da zero per sfruttare il pieno potenziale della programmazione asincrona. Con meccanismi asincroni implementati meticolosamente in tutto il codice, llama-github pu√≤ gestire pi√π richieste contemporaneamente, aumentando notevolmente le prestazioni complessive. Prova la differenza mentre llama-github gestisce efficientemente carichi di lavoro elevati senza compromettere velocit√† o qualit√†."
      },
      {
        "row": 15,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 16,
        "rowsha": "0g6jkIpIeIIz2Gt8w6I2VAjPUz51+RDJs7fxVchaN/k=",
        "originContent": "- **üîß Flexible LLM Integration**: Easily integrate llama-github with various LLM providers, embedding models, and reranking models to tailor the library's capabilities to your specific requirements. Our extensible architecture allows you to customize and enhance llama-github's functionality, ensuring that it adapts seamlessly to your unique development environment.",
        "translatedContent": "- **üîß Integrazione Flessibile con LLM**: Integra facilmente llama-github con diversi provider LLM, modelli di embedding e modelli di reranking per adattare le capacit√† della libreria ai tuoi requisiti specifici. La nostra architettura estensibile ti consente di personalizzare e migliorare le funzionalit√† di llama-github, assicurando un‚Äôintegrazione fluida con il tuo ambiente di sviluppo."
      },
      {
        "row": 17,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 18,
        "rowsha": "WH0+zgaxAP/W/KtIygVDuxydKTKp6imCYyXpqvXpjaM=",
        "originContent": "- **üîí Robust Authentication Options**: Llama-github supports both personal access tokens and GitHub App authentication, providing you with the flexibility to integrate it into different development setups. Whether you're an individual developer or working within an organizational context, llama-github has you covered with secure and reliable authentication mechanisms.",
        "translatedContent": "- **üîí Opzioni di Autenticazione Robuste**: Llama-github supporta sia i token di accesso personale sia l‚Äôautenticazione tramite GitHub App, offrendoti la flessibilit√† per integrarlo in diversi ambienti di sviluppo. Che tu sia uno sviluppatore individuale o lavori in un contesto organizzativo, llama-github ti offre meccanismi di autenticazione sicuri e affidabili."
      },
      {
        "row": 19,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 20,
        "rowsha": "IYhTxjMvy72M7T9kEBfrXUNMz08qwsXzETVoE3WSNyQ=",
        "originContent": "- **üõ†Ô∏è Logging and Error Handling**: We understand the importance of smooth operations and easy troubleshooting. That's why llama-github comes equipped with comprehensive logging and error handling mechanisms. Gain deep insights into the library's behavior, quickly diagnose issues, and maintain a stable and reliable development workflow.",
        "translatedContent": "- **üõ†Ô∏è Logging e Gestione Errori**: Comprendiamo l‚Äôimportanza di un funzionamento fluido e di una facile risoluzione dei problemi. Per questo llama-github √® dotato di meccanismi completi di logging e gestione degli errori. Ottieni approfondimenti dettagliati sul comportamento della libreria, diagnostica rapidamente i problemi e mantieni un workflow di sviluppo stabile e affidabile."
      },
      {
        "row": 21,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 22,
        "rowsha": "QDeqAvaQEIQHPYjwq2KF5Bw3a76EiPq7ebbsGNKcRI8=",
        "originContent": "## ü§ñ Try Our AI-Powered PR Review Assistant: LlamaPReview",
        "translatedContent": "## ü§ñ Prova il Nostro Assistant AI per la Revisione PR: LlamaPReview"
      },
      {
        "row": 23,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 24,
        "rowsha": "laWUe+J402emMP2V1JeMqFpYefA8HTKWoI+lq7NfoyE=",
        "originContent": "If you find llama-github useful, you might also be interested in our AI-powered GitHub PR review assistant, LlamaPReview. It's designed to complement your development workflow and further enhance code quality.",
        "translatedContent": "Se trovi utile llama-github, potresti essere interessato anche al nostro assistente AI per la revisione di PR su GitHub, LlamaPReview. √à progettato per integrare il tuo workflow di sviluppo e migliorare ulteriormente la qualit√† del codice."
      },
      {
        "row": 25,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 26,
        "rowsha": "J3M87xxuLQISS/m0fiv7phjnw7mYaznst6rel6n7MyY=",
        "originContent": "### Key Features of LlamaPReview:",
        "translatedContent": "### Caratteristiche Principali di LlamaPReview:"
      },
      {
        "row": 27,
        "rowsha": "dGBd2SxNdlW1UATPSu01Iq95yCVz8fXbl7xxHqDYI7E=",
        "originContent": "- üöÄ One-click installation, zero configuration required, fully auto-run",
        "translatedContent": "- üöÄ Installazione con un clic, nessuna configurazione richiesta, esecuzione completamente automatica"
      },
      {
        "row": 28,
        "rowsha": "EP9hYUs4aYVAzXcYQyCGf3bjwo64OjAsqQHIN75oW60=",
        "originContent": "- üíØ Currently free to use - no credit card or payment info needed",
        "translatedContent": "- üíØ Attualmente gratuito - nessuna carta di credito o pagamento richiesto"
      },
      {
        "row": 29,
        "rowsha": "jjWF/iUqSzPriHJ5iiFIq0Q6Pzx+gzPlnLu0Z4wmsSg=",
        "originContent": "- üß† AI-powered, automatic PR reviews with deep code understanding",
        "translatedContent": "- üß† Recensioni PR automatiche, basate su AI, con profonda comprensione del codice"
      },
      {
        "row": 30,
        "rowsha": "Dsl+HsDM5NGI480TDo6eaFqgDcaofr3TDhLbUghSXhU=",
        "originContent": "- üåê Supports multiple programming languages",
        "translatedContent": "- üåê Supporta molteplici linguaggi di programmazione"
      },
      {
        "row": 31,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 32,
        "rowsha": "GrzJg4j2iz94pupBQwJnFffhmsJ5IO9OkhqYvj0QEmo=",
        "originContent": "**LlamaPReview utilizes llama-github's advanced context retrieval and LLM-powered analysis** to provide intelligent, context-aware code reviews. It's like having a senior developer, armed with the full context of your repository, review every PR automatically!",
        "translatedContent": "**LlamaPReview utilizza il recupero di contesto avanzato e l‚Äôanalisi LLM di llama-github** per offrire revisioni intelligenti e consapevoli del contesto. √à come avere un senior developer, armato del contesto completo del tuo repository, che rivede ogni PR automaticamente!"
      },
      {
        "row": 33,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 34,
        "rowsha": "4qGUTknerL/UTVikcUjFHvKzZlWho9opuf58fSIypyk=",
        "originContent": "üëâ [Install LlamaPReview Now](https://github.com/marketplace/llamapreview/) (Free)",
        "translatedContent": "üëâ [Installa LlamaPReview Ora](https://github.com/marketplace/llamapreview/) (Gratis)"
      },
      {
        "row": 35,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 36,
        "rowsha": "luTTMbXm2ikxAkHhFfh2iG9uPEwMYBRd2lolUoOY+3o=",
        "originContent": "By using llama-github for context retrieval and LlamaPReview for code reviews, you can create a powerful, AI-enhanced development environment.",
        "translatedContent": "Utilizzando llama-github per il recupero del contesto e LlamaPReview per le revisioni del codice, puoi creare un potente ambiente di sviluppo potenziato dall‚ÄôAI."
      },
      {
        "row": 37,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 38,
        "rowsha": "W2b655gztUgECPmTnBIkK/WbBo7d68AbNAjMtkHS5xY=",
        "originContent": "## Vision and Roadmap",
        "translatedContent": "## Visione e Roadmap"
      },
      {
        "row": 39,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 40,
        "rowsha": "Ewakmoa/Yb8fcDlChA12w7kAXVMFh8OrCLwVCTwIl84=",
        "originContent": "### Vision",
        "translatedContent": "### Visione"
      },
      {
        "row": 41,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 42,
        "rowsha": "0e6GYQC4W2Y8Ky5Q9UNeMwDc+ebEjDIUb9h4gSLQJaI=",
        "originContent": "Our vision is to become a pivotal module in the future of AI-driven development solutions, seamlessly integrating with GitHub to empower LLMs in automatically resolving complex coding tasks.",
        "translatedContent": "La nostra visione √® diventare un modulo fondamentale nel futuro delle soluzioni di sviluppo guidate dall‚ÄôAI, integrandoci perfettamente con GitHub per consentire agli LLM di risolvere automaticamente compiti di coding complessi."
      },
      {
        "row": 43,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 44,
        "rowsha": "e3eGMrQR9LxN0lPlezIImRzi4tUu6n/GFfZsq5SBP4I=",
        "originContent": "![Vision Architecture](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/./docs/vision.drawio.svg)",
        "translatedContent": "![Vision Architecture](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/./docs/vision.drawio.svg)"
      },
      {
        "row": 45,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 46,
        "rowsha": "Q0D6oxy93TTXOZDvIiuco/ghaytG064tWvZdnLoKnOw=",
        "originContent": "### Roadmap",
        "translatedContent": "### Roadmap"
      },
      {
        "row": 47,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 48,
        "rowsha": "UHmL4/lEZk2jitjRxUVuHtD8JilL4OTzFLbU8R72Ymc=",
        "originContent": "For a detailed view of our project roadmap, please visit our [Project Roadmap](https://github.com/users/JetXu-LLM/projects/2).",
        "translatedContent": "Per una panoramica dettagliata della nostra roadmap, visita il nostro [Project Roadmap](https://github.com/users/JetXu-LLM/projects/2)."
      },
      {
        "row": 49,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 50,
        "rowsha": "N66ywbuGccMYNTyswaMSnFOlWqX+iaYP/myGJqr1tHo=",
        "originContent": "## Acknowledgments",
        "translatedContent": "## Riconoscimenti"
      },
      {
        "row": 51,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 52,
        "rowsha": "WodCIp8BqxoCo7bxE7dxagf/Dvpvw7nWeECf0qG6FGI=",
        "originContent": "We would like to express our gratitude to the following open-source projects for their support and contributions:",
        "translatedContent": "Desideriamo esprimere la nostra gratitudine ai seguenti progetti open-source per il loro supporto e contributo:"
      },
      {
        "row": 53,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 54,
        "rowsha": "HBIRZKkbsYOXsJY2Xepu1VxTAAdh869qSnsGbJ0cIg0=",
        "originContent": "- **[LangChain](https://github.com/langchain-ai/langchain)**: For providing the foundational framework that empowers the LLM prompting and processing capabilities in llama-github.",
        "translatedContent": "- **[LangChain](https://github.com/langchain-ai/langchain)**: Per aver fornito il framework di base che potenzia le capacit√† di prompting e processing LLM in llama-github."
      },
      {
        "row": 55,
        "rowsha": "l7sjWwbh0OUJwk4+yJE2ZbVGypyaPrzI1YYMP7Uw9X0=",
        "originContent": "- **[Jina.ai](https://github.com/jina-ai/reader)**: For offering s.jina.ai API and open source reranker and embedding models that enhance the accuracy and relevance of the generated contexts in llama-github.",
        "translatedContent": "- **[Jina.ai](https://github.com/jina-ai/reader)**: Per aver offerto API s.jina.ai e modelli open source di reranking ed embedding che migliorano la precisione e la pertinenza dei contesti generati in llama-github."
      },
      {
        "row": 56,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 57,
        "rowsha": "hrChp1vDZFs3UZia39niD4Kx9hT0wKUMxSSiiyYyi7A=",
        "originContent": "Their contributions have been instrumental in the development of llama-github, and we highly recommend checking out their projects for more innovative solutions.",
        "translatedContent": "I loro contributi sono stati fondamentali per lo sviluppo di llama-github e raccomandiamo vivamente di esplorare i loro progetti per altre soluzioni innovative."
      },
      {
        "row": 58,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 59,
        "rowsha": "R5ZPLZ4vkE9tjX5qe8QB7AkTfWZsuNTGFLFKMp2KUzM=",
        "originContent": "## Contributing",
        "translatedContent": "## Contribuire"
      },
      {
        "row": 60,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 61,
        "rowsha": "JUWgAoIn9VhOEzmNL5dlAlHwcmo7N2Rm2GNx0g5Rijs=",
        "originContent": "We welcome contributions to llama-github! Please see our [contributing guidelines](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/CONTRIBUTING.md) for more information.",
        "translatedContent": "Accogliamo con piacere i contributi a llama-github! Consulta le nostre [linee guida per i contributi](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/CONTRIBUTING.md) per maggiori informazioni."
      },
      {
        "row": 62,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 63,
        "rowsha": "bFSaVtsB4CHySNjaeCiaMZfT24b+DTbTM4HQ38cR6Lw=",
        "originContent": "## License",
        "translatedContent": "## Licenza"
      },
      {
        "row": 64,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 65,
        "rowsha": "hUzQdbczna0Cd3FyH+bhS5SWBDzmVQyA+nCi/UZO6VI=",
        "originContent": "This project is licensed under the terms of the Apache 2.0 license. See the [LICENSE](LICENSE) file for more details.",
        "translatedContent": "Questo progetto √® rilasciato secondo i termini della licenza Apache 2.0. Consulta il file [LICENSE](LICENSE) per maggiori dettagli."
      },
      {
        "row": 66,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 67,
        "rowsha": "ZX9nbduzXgvmAaK8yTd+tNgwR7cV79HXV/+xbvL8suw=",
        "originContent": "## Contact",
        "translatedContent": "## Contatti"
      },
      {
        "row": 68,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 69,
        "rowsha": "sZud9u8DDdJRsIyc+T0tdusx1FWC0pdv0Yn2hhndP9o=",
        "originContent": "If you have any questions, suggestions, or feedback, please feel free to reach out to us at [Jet Xu's email](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/mailto:Voldemort.xu@foxmail.com).",
        "translatedContent": "Se hai domande, suggerimenti o feedback, sentiti libero di contattarci a [l‚Äôemail di Jet Xu](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/mailto:Voldemort.xu@foxmail.com)."
      },
      {
        "row": 70,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 71,
        "rowsha": "yz+R1U7uMOU+NbK5mQX3Dxae1Un9eJCdPawt78ntjTs=",
        "originContent": "---",
        "translatedContent": "---"
      },
      {
        "row": 72,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 73,
        "rowsha": "98t5imS5RZt8kUxGAXqZcPmlZMcru27Gl/g31hb3g/c=",
        "originContent": "Thank you for choosing llama-github! We hope this library enhances your AI development experience and helps you build powerful applications with ease.",
        "translatedContent": "Grazie per aver scelto llama-github! Speriamo che questa libreria migliori la tua esperienza di sviluppo AI e ti aiuti a costruire potenti applicazioni con facilit√†."
      },
      {
        "row": 74,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  }
]