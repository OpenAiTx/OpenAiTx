[
  {
    "Id": 1,
    "Content": "# llama-github\n\n[Detail Document] https://deepwiki.com/JetXu-LLM/llama-github\n\n[![PyPI version](https://badge.fury.io/py/llama-github.svg)](https://badge.fury.io/py/llama-github)\n[![Downloads](https://static.pepy.tech/badge/Llama-github)](https://pepy.tech/project/Llama-github)\n[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)\n\nLlama-github is a powerful tool that helps you retrieve(based on Agentic RAG) the most relevant code snippets, issues, and repository information from GitHub based on your queries, transforming them into valuable knowledge context. It empowers LLM Chatbots, AI Agents, and Auto-dev Agents to solve complex coding tasks. Whether you're a developer looking for quick solutions or an engineer implementing advanced Auto Dev AI Agents, llama-github makes it easy and efficient.\n\nIf you like this project or believe it has potential, please give it a â­ï¸. Your support is our greatest motivation!\n\n## Architecture\n![High Level Architecture](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/./docs/high_level_architecture.drawio.svg)\n\n## Installation",
    "ContentSha": "TZmxyaoSVzegm0TJMJvowqs2RLRV2vw3TmLRyiZUZyA=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "# llama-github\n\n[è©³ç´°ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ] https://deepwiki.com/JetXu-LLM/llama-github\n\n[![PyPI ãƒãƒ¼ã‚¸ãƒ§ãƒ³](https://badge.fury.io/py/llama-github.svg)](https://badge.fury.io/py/llama-github)\n[![ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ•°](https://static.pepy.tech/badge/Llama-github)](https://pepy.tech/project/Llama-github)\n[![ãƒ©ã‚¤ã‚»ãƒ³ã‚¹](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)\n\nLlama-githubã¯ã€Agentic RAGã«åŸºã¥ã„ã¦ã€GitHubã‹ã‚‰ã‚¯ã‚¨ãƒªã«åŸºã¥ã„ãŸæœ€ã‚‚é–¢é€£æ€§ã®é«˜ã„ã‚³ãƒ¼ãƒ‰ã‚¹ãƒ‹ãƒšãƒƒãƒˆã€ã‚¤ã‚·ãƒ¥ãƒ¼ã€ãŠã‚ˆã³ãƒªãƒã‚¸ãƒˆãƒªæƒ…å ±ã‚’å–å¾—ã—ã€ãã‚Œã‚‰ã‚’ä¾¡å€¤ã‚ã‚‹çŸ¥è­˜ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›ã™ã‚‹å¼·åŠ›ãªãƒ„ãƒ¼ãƒ«ã§ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€LLMãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã€AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã€Auto-devã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒè¤‡é›‘ãªã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚¿ã‚¹ã‚¯ã‚’è§£æ±ºã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚è¿…é€Ÿãªã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æ±‚ã‚ã‚‹é–‹ç™ºè€…ã§ã‚‚ã€é«˜åº¦ãªAuto Dev AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’å®Ÿè£…ã™ã‚‹ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã§ã‚‚ã€llama-githubã¯ç°¡å˜ã‹ã¤åŠ¹ç‡çš„ã«åˆ©ç”¨ã§ãã¾ã™ã€‚\n\nã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’æ°—ã«å…¥ã£ãŸã‚Šã€å¯èƒ½æ€§ã‚’æ„Ÿã˜ãŸå ´åˆã¯ã€ãœã²â­ï¸ã‚’ãŠé¡˜ã„ã—ã¾ã™ã€‚çš†æ§˜ã®ã‚µãƒãƒ¼ãƒˆãŒç§ãŸã¡ã®æœ€å¤§ã®åŠ±ã¿ã§ã™ï¼\n\n## ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£\n![ãƒã‚¤ãƒ¬ãƒ™ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/./docs/high_level_architecture.drawio.svg)\n\n## ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "cAI8B2fw5xCydddeNcosOFY2wrQw8An1lrdomk97KBc=",
        "originContent": "# llama-github",
        "translatedContent": "# llama-github"
      },
      {
        "row": 2,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 3,
        "rowsha": "jSTPMiMb5qDjmRYlxqDSx6zbsKYKOv4c6HQQgjbDUqo=",
        "originContent": "[Detail Document] https://deepwiki.com/JetXu-LLM/llama-github",
        "translatedContent": "[è©³ç´°ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ] https://deepwiki.com/JetXu-LLM/llama-github"
      },
      {
        "row": 4,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 5,
        "rowsha": "48lo1Cg6fyAcQl554s/7eKSc41UYvSn/CD6yxtLVgjY=",
        "originContent": "[![PyPI version](https://badge.fury.io/py/llama-github.svg)](https://badge.fury.io/py/llama-github)",
        "translatedContent": "[![PyPI ãƒãƒ¼ã‚¸ãƒ§ãƒ³](https://badge.fury.io/py/llama-github.svg)](https://badge.fury.io/py/llama-github)"
      },
      {
        "row": 6,
        "rowsha": "VG3AfiYLkBPipFZPAt/fJt5jj8aI773UKbmI1Z/kc2M=",
        "originContent": "[![Downloads](https://static.pepy.tech/badge/Llama-github)](https://pepy.tech/project/Llama-github)",
        "translatedContent": "[![ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ•°](https://static.pepy.tech/badge/Llama-github)](https://pepy.tech/project/Llama-github)"
      },
      {
        "row": 7,
        "rowsha": "U0vs77tGfFYY+r4ScaOhTOZDgt8vSKCUyj59tU13ZtE=",
        "originContent": "[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)",
        "translatedContent": "[![ãƒ©ã‚¤ã‚»ãƒ³ã‚¹](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)"
      },
      {
        "row": 8,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 9,
        "rowsha": "y7xsY1R0s8pmwDQukNS2PQ5JqK6CRs8AwuPrZkBKiT8=",
        "originContent": "Llama-github is a powerful tool that helps you retrieve(based on Agentic RAG) the most relevant code snippets, issues, and repository information from GitHub based on your queries, transforming them into valuable knowledge context. It empowers LLM Chatbots, AI Agents, and Auto-dev Agents to solve complex coding tasks. Whether you're a developer looking for quick solutions or an engineer implementing advanced Auto Dev AI Agents, llama-github makes it easy and efficient.",
        "translatedContent": "Llama-githubã¯ã€Agentic RAGã«åŸºã¥ã„ã¦ã€GitHubã‹ã‚‰ã‚¯ã‚¨ãƒªã«åŸºã¥ã„ãŸæœ€ã‚‚é–¢é€£æ€§ã®é«˜ã„ã‚³ãƒ¼ãƒ‰ã‚¹ãƒ‹ãƒšãƒƒãƒˆã€ã‚¤ã‚·ãƒ¥ãƒ¼ã€ãŠã‚ˆã³ãƒªãƒã‚¸ãƒˆãƒªæƒ…å ±ã‚’å–å¾—ã—ã€ãã‚Œã‚‰ã‚’ä¾¡å€¤ã‚ã‚‹çŸ¥è­˜ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›ã™ã‚‹å¼·åŠ›ãªãƒ„ãƒ¼ãƒ«ã§ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€LLMãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã€AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã€Auto-devã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒè¤‡é›‘ãªã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚¿ã‚¹ã‚¯ã‚’è§£æ±ºã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚è¿…é€Ÿãªã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æ±‚ã‚ã‚‹é–‹ç™ºè€…ã§ã‚‚ã€é«˜åº¦ãªAuto Dev AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’å®Ÿè£…ã™ã‚‹ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã§ã‚‚ã€llama-githubã¯ç°¡å˜ã‹ã¤åŠ¹ç‡çš„ã«åˆ©ç”¨ã§ãã¾ã™ã€‚"
      },
      {
        "row": 10,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 11,
        "rowsha": "6h9r25r7afHOT0YHlaj7xv1WU2JfjWqSqLUM7UgJNfQ=",
        "originContent": "If you like this project or believe it has potential, please give it a â­ï¸. Your support is our greatest motivation!",
        "translatedContent": "ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’æ°—ã«å…¥ã£ãŸã‚Šã€å¯èƒ½æ€§ã‚’æ„Ÿã˜ãŸå ´åˆã¯ã€ãœã²â­ï¸ã‚’ãŠé¡˜ã„ã—ã¾ã™ã€‚çš†æ§˜ã®ã‚µãƒãƒ¼ãƒˆãŒç§ãŸã¡ã®æœ€å¤§ã®åŠ±ã¿ã§ã™ï¼"
      },
      {
        "row": 12,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 13,
        "rowsha": "p+VkcrEb08g4vIGZYB9aVScRKgA8afv5WwErwTVzoZM=",
        "originContent": "## Architecture",
        "translatedContent": "## ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£"
      },
      {
        "row": 14,
        "rowsha": "TiSukfY/+ter5MJ39DMtNdHlqRXwhZFkP3uTdAfvA0c=",
        "originContent": "![High Level Architecture](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/./docs/high_level_architecture.drawio.svg)",
        "translatedContent": "![ãƒã‚¤ãƒ¬ãƒ™ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/./docs/high_level_architecture.drawio.svg)"
      },
      {
        "row": 15,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 16,
        "rowsha": "oV0SUDvwD2VN8Gi9nlr2JZ2xcDrASmE2W5kc5SVX5eo=",
        "originContent": "## Installation",
        "translatedContent": "## ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«"
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 2,
    "Content": "```\npip install llama-github\n```",
    "ContentSha": "A7Ioj19mKQ2poo2/SNNEl/PUNM9x+13/7/ncgppdcgY=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```\npip install llama-github\n```",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      },
      {
        "row": 2,
        "rowsha": "HUzQ8Fuh/Wg8Hu8KR8bezJLbFVpPKMpf5Pa7xDY6vYM=",
        "originContent": "pip install llama-github",
        "translatedContent": "pip install llama-github"
      },
      {
        "row": 3,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      }
    ],
    "IsCodeBlock": true
  },
  {
    "Id": 3,
    "Content": "\n## Usage\n\nHere's a simple example of how to use llama-github:\n",
    "ContentSha": "oqzkRVGHtTMxKJniKYy+bJRBu/B3l8AYVVo5suNCmR4=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "\n## ä½¿ç”¨æ–¹æ³•\n\nã“ã“ã§ã¯ã€llama-githubã®ç°¡å˜ãªä½¿ç”¨ä¾‹ã‚’ç¤ºã—ã¾ã™:\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 2,
        "rowsha": "Y7/WGgVhslWiyqCi463Qkcp+Mn8voGpAfLsv80G4WNg=",
        "originContent": "## Usage",
        "translatedContent": "## ä½¿ç”¨æ–¹æ³•"
      },
      {
        "row": 3,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 4,
        "rowsha": "4zRpXijfFggW+Fd/VZ8qaLkuJwnjePE96Hy1hPxOIRE=",
        "originContent": "Here's a simple example of how to use llama-github:",
        "translatedContent": "ã“ã“ã§ã¯ã€llama-githubã®ç°¡å˜ãªä½¿ç”¨ä¾‹ã‚’ç¤ºã—ã¾ã™:"
      },
      {
        "row": 5,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 4,
    "Content": "```python\nfrom llama_github import GithubRAG\n\n# Initialize GithubRAG with your credentials\ngithub_rag = GithubRAG(\n    github_access_token=\"your_github_access_token\", \n    openai_api_key=\"your_openai_api_key\", # Optional in Simple Mode\n    jina_api_key=\"your_jina_api_key\" # Optional - unless you want high concurrency production deployment (s.jina.ai API will be used in llama-github)\n)\n\n# Retrieve context for a coding question (simple_mode is default set to False)\nquery = \"How to create a NumPy array in Python?\"\ncontext = github_rag.retrieve_context(\n    query, # In professional mode, one query will take nearly 1 min to generate final contexts. You could set log level to INFO to monitor the retrieval progress\n    # simple_mode = True\n)\n\nprint(context)\n```",
    "ContentSha": "HXBtstD3V5wfKLk68/A2T/KFqRB/TtW5s0tq89CzhFU=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```python\nfrom llama_github import GithubRAG\n\n# Initialize GithubRAG with your credentials\ngithub_rag = GithubRAG(\n    github_access_token=\"your_github_access_token\", \n    openai_api_key=\"your_openai_api_key\", # Optional in Simple Mode\n    jina_api_key=\"your_jina_api_key\" # Optional - unless you want high concurrency production deployment (s.jina.ai API will be used in llama-github)\n)\n\n# Retrieve context for a coding question (simple_mode is default set to False)\nquery = \"How to create a NumPy array in Python?\"\ncontext = github_rag.retrieve_context(\n    query, # In professional mode, one query will take nearly 1 min to generate final contexts. You could set log level to INFO to monitor the retrieval progress\n    # simple_mode = True\n)\n\nprint(context)\n```",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "uDnRsrcDV2kZVI2wi9EA58m+F4ILdr1bvjhqNlB+wSc=",
        "originContent": "```python",
        "translatedContent": "```python"
      },
      {
        "row": 2,
        "rowsha": "hA5UQDttQHKAwB+ESl7GqyiAa1AotkDZYMGTRuo/AoY=",
        "originContent": "from llama_github import GithubRAG",
        "translatedContent": "from llama_github import GithubRAG"
      },
      {
        "row": 3,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 4,
        "rowsha": "/Xio12pWjWQxdHtqP9gkrQo8FvXup5Rnp8m6s9rWQoA=",
        "originContent": "# Initialize GithubRAG with your credentials",
        "translatedContent": "# Initialize GithubRAG with your credentials"
      },
      {
        "row": 5,
        "rowsha": "Z/GdSwf7Zfjb56iNk/lrSDiBY4vaKvdGc5F3qO5IgSQ=",
        "originContent": "github_rag = GithubRAG(",
        "translatedContent": "github_rag = GithubRAG("
      },
      {
        "row": 6,
        "rowsha": "DCUT+XvqWQMhTvTxgZeTkNrf6sB1egP0ataQmEq//Do=",
        "originContent": "    github_access_token=\"your_github_access_token\", ",
        "translatedContent": "    github_access_token=\"your_github_access_token\", "
      },
      {
        "row": 7,
        "rowsha": "7hDiOA+9nEfENa9R7NEJW8WSnmj71txD0Ndrw3HjngM=",
        "originContent": "    openai_api_key=\"your_openai_api_key\", # Optional in Simple Mode",
        "translatedContent": "    openai_api_key=\"your_openai_api_key\", # Optional in Simple Mode"
      },
      {
        "row": 8,
        "rowsha": "3gER4AqcTSuWLMk5yIWdhwT240c1f6O0Qk92225ZuVU=",
        "originContent": "    jina_api_key=\"your_jina_api_key\" # Optional - unless you want high concurrency production deployment (s.jina.ai API will be used in llama-github)",
        "translatedContent": "    jina_api_key=\"your_jina_api_key\" # Optional - unless you want high concurrency production deployment (s.jina.ai API will be used in llama-github)"
      },
      {
        "row": 9,
        "rowsha": "ul7FHQekrA6VFghwRDHVmgKyGk6VGswQUFqNxAfFAe4=",
        "originContent": ")",
        "translatedContent": ")"
      },
      {
        "row": 10,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 11,
        "rowsha": "U1SUJQpzS8NM2yh7MFPYJl5dQ6gq/MR813WqTX952X0=",
        "originContent": "# Retrieve context for a coding question (simple_mode is default set to False)",
        "translatedContent": "# Retrieve context for a coding question (simple_mode is default set to False)"
      },
      {
        "row": 12,
        "rowsha": "ZXVeMLKgPJjdKhiZ9CK5U4oP9OsdwnWdpg8zNqEI+58=",
        "originContent": "query = \"How to create a NumPy array in Python?\"",
        "translatedContent": "query = \"How to create a NumPy array in Python?\""
      },
      {
        "row": 13,
        "rowsha": "tMIfL+j+gxN0VAT5YvCwzTJ6i5aIIY3fcw3LxJWoTrQ=",
        "originContent": "context = github_rag.retrieve_context(",
        "translatedContent": "context = github_rag.retrieve_context("
      },
      {
        "row": 14,
        "rowsha": "Q1vTmUoyeud2ZNyE6iVCY7OriQi61Wg6NLrSyM9pVLE=",
        "originContent": "    query, # In professional mode, one query will take nearly 1 min to generate final contexts. You could set log level to INFO to monitor the retrieval progress",
        "translatedContent": "    query, # In professional mode, one query will take nearly 1 min to generate final contexts. You could set log level to INFO to monitor the retrieval progress"
      },
      {
        "row": 15,
        "rowsha": "uvb8HENvYITO6V3XF0E9tyqODM0Be+CdeIuXZsYj/CA=",
        "originContent": "    # simple_mode = True",
        "translatedContent": "    # simple_mode = True"
      },
      {
        "row": 16,
        "rowsha": "ul7FHQekrA6VFghwRDHVmgKyGk6VGswQUFqNxAfFAe4=",
        "originContent": ")",
        "translatedContent": ")"
      },
      {
        "row": 17,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 18,
        "rowsha": "ZZEcMA2fivnNWsWr7Vg5FUhhpwQQJ/ThJU+S148t13E=",
        "originContent": "print(context)",
        "translatedContent": "print(context)"
      },
      {
        "row": 19,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      }
    ],
    "IsCodeBlock": true
  },
  {
    "Id": 5,
    "Content": "\nFor more advanced usage and examples, please refer to the [documentation](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/docs/usage.md).\n\n## Key Features\n\n- **ğŸ” Intelligent GitHub Retrieval**: Harness the power of llama-github to retrieve highly relevant code snippets, issues, and repository information from GitHub based on user queries. Our advanced retrieval techniques ensure you find the most pertinent information quickly and efficiently.\n\n- **âš¡ Repository Pool Caching**: Llama-github has an innovative repository pool caching mechanism. By caching repositories (including READMEs, structures, code, and issues) across threads, llama-github significantly accelerates GitHub search retrieval efficiency and minimizes the consumption of GitHub API tokens. Deploy llama-github in multi-threaded production environments with confidence, knowing that it will perform optimally and save you valuable resources.\n\n- **ğŸ§  LLM-Powered Question Analysis**: Leverage state-of-the-art language models to analyze user questions and generate highly effective search strategies and criteria. Llama-github intelligently breaks down complex queries, ensuring that you retrieve the most relevant information from GitHub's vast repository network.\n\n- **ğŸ“š Comprehensive Context Generation**: Generate rich, contextually relevant answers by seamlessly combining information retrieved from GitHub with the reasoning capabilities of advanced language models. Llama-github excels at handling even the most complex and lengthy questions, providing comprehensive and insightful responses that include extensive context to support your development needs.\n\n- **ğŸš€ Asynchronous Processing Excellence**: Llama-github is built from the ground up to leverage the full potential of asynchronous programming. With meticulously implemented asynchronous mechanisms woven throughout the codebase, llama-github can handle multiple requests concurrently, significantly boosting overall performance. Experience the difference as llama-github efficiently manages high-volume workloads without compromising on speed or quality.\n\n- **ğŸ”§ Flexible LLM Integration**: Easily integrate llama-github with various LLM providers, embedding models, and reranking models to tailor the library's capabilities to your specific requirements. Our extensible architecture allows you to customize and enhance llama-github's functionality, ensuring that it adapts seamlessly to your unique development environment.\n\n- **ğŸ”’ Robust Authentication Options**: Llama-github supports both personal access tokens and GitHub App authentication, providing you with the flexibility to integrate it into different development setups. Whether you're an individual developer or working within an organizational context, llama-github has you covered with secure and reliable authentication mechanisms.\n\n- **ğŸ› ï¸ Logging and Error Handling**: We understand the importance of smooth operations and easy troubleshooting. That's why llama-github comes equipped with comprehensive logging and error handling mechanisms. Gain deep insights into the library's behavior, quickly diagnose issues, and maintain a stable and reliable development workflow.\n\n## ğŸ¤– Try Our AI-Powered PR Review Assistant: LlamaPReview\n\nIf you find llama-github useful, you might also be interested in our AI-powered GitHub PR review assistant, LlamaPReview. It's designed to complement your development workflow and further enhance code quality.\n\n### Key Features of LlamaPReview:\n- ğŸš€ One-click installation, zero configuration required, fully auto-run\n- ğŸ’¯ Currently free to use - no credit card or payment info needed\n- ğŸ§  AI-powered, automatic PR reviews with deep code understanding\n- ğŸŒ Supports multiple programming languages\n\n**LlamaPReview utilizes llama-github's advanced context retrieval and LLM-powered analysis** to provide intelligent, context-aware code reviews. It's like having a senior developer, armed with the full context of your repository, review every PR automatically!\n\nğŸ‘‰ [Install LlamaPReview Now](https://github.com/marketplace/llamapreview/) (Free)\n\nBy using llama-github for context retrieval and LlamaPReview for code reviews, you can create a powerful, AI-enhanced development environment.\n\n## Vision and Roadmap\n\n### Vision\n\nOur vision is to become a pivotal module in the future of AI-driven development solutions, seamlessly integrating with GitHub to empower LLMs in automatically resolving complex coding tasks.\n\n![Vision Architecture](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/./docs/vision.drawio.svg)\n\n### Roadmap\n\nFor a detailed view of our project roadmap, please visit our [Project Roadmap](https://github.com/users/JetXu-LLM/projects/2).\n\n## Acknowledgments\n\nWe would like to express our gratitude to the following open-source projects for their support and contributions:\n\n- **[LangChain](https://github.com/langchain-ai/langchain)**: For providing the foundational framework that empowers the LLM prompting and processing capabilities in llama-github.\n- **[Jina.ai](https://github.com/jina-ai/reader)**: For offering s.jina.ai API and open source reranker and embedding models that enhance the accuracy and relevance of the generated contexts in llama-github.\n\nTheir contributions have been instrumental in the development of llama-github, and we highly recommend checking out their projects for more innovative solutions.\n\n## Contributing\n\nWe welcome contributions to llama-github! Please see our [contributing guidelines](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/CONTRIBUTING.md) for more information.\n\n## License\n\nThis project is licensed under the terms of the Apache 2.0 license. See the [LICENSE](LICENSE) file for more details.\n\n## Contact\n\nIf you have any questions, suggestions, or feedback, please feel free to reach out to us at [Jet Xu's email](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/mailto:Voldemort.xu@foxmail.com).\n\n---\n\nThank you for choosing llama-github! We hope this library enhances your AI development experience and helps you build powerful applications with ease.\n",
    "ContentSha": "9uwuSakxESmyLicwqpb9te9XJtaLzK41aW7HGRKfVFM=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "ã‚ˆã‚Šé«˜åº¦ãªä½¿ç”¨ä¾‹ã‚„è©³ç´°ã«ã¤ã„ã¦ã¯ã€[ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/docs/usage.md)ã‚’ã”å‚ç…§ãã ã•ã„ã€‚\n\n## ä¸»ãªç‰¹å¾´\n\n- **ğŸ” ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆãªGitHubæ¤œç´¢**ï¼šãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚¯ã‚¨ãƒªã«åŸºã¥ãã€llama-githubã®åŠ›ã‚’æ´»ç”¨ã—ã¦GitHubã‹ã‚‰é–¢é€£æ€§ã®é«˜ã„ã‚³ãƒ¼ãƒ‰ã‚¹ãƒ‹ãƒšãƒƒãƒˆã€ã‚¤ã‚·ãƒ¥ãƒ¼ã€ãƒªãƒã‚¸ãƒˆãƒªæƒ…å ±ã‚’å–å¾—ã—ã¾ã™ã€‚é«˜åº¦ãªæ¤œç´¢æŠ€è¡“ã«ã‚ˆã‚Šã€æœ€ã‚‚é©åˆ‡ãªæƒ…å ±ã‚’è¿…é€Ÿã‹ã¤åŠ¹ç‡çš„ã«è¦‹ã¤ã‘å‡ºã—ã¾ã™ã€‚\n\n- **âš¡ ãƒªãƒã‚¸ãƒˆãƒªãƒ—ãƒ¼ãƒ«ã‚­ãƒ£ãƒƒã‚·ãƒ¥**ï¼šllama-githubã¯é©æ–°çš„ãªãƒªãƒã‚¸ãƒˆãƒªãƒ—ãƒ¼ãƒ«ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ©Ÿæ§‹ã‚’å‚™ãˆã¦ã„ã¾ã™ã€‚ã‚¹ãƒ¬ãƒƒãƒ‰é–“ã§ãƒªãƒã‚¸ãƒˆãƒªï¼ˆREADMEã€æ§‹é€ ã€ã‚³ãƒ¼ãƒ‰ã€ã‚¤ã‚·ãƒ¥ãƒ¼ã‚’å«ã‚€ï¼‰ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã™ã‚‹ã“ã¨ã§ã€GitHubæ¤œç´¢ã®å–å¾—åŠ¹ç‡ã‚’å¤§å¹…ã«å‘ä¸Šã•ã›ã€GitHub APIãƒˆãƒ¼ã‚¯ãƒ³ã®æ¶ˆè²»ã‚’æœ€å°é™ã«æŠ‘ãˆã¾ã™ã€‚ãƒãƒ«ãƒã‚¹ãƒ¬ãƒƒãƒ‰ã®æœ¬ç•ªç’°å¢ƒã«è‡ªä¿¡ã‚’æŒã£ã¦å°å…¥ã§ãã€æœ€é©ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¨è²´é‡ãªãƒªã‚½ãƒ¼ã‚¹ã®ç¯€ç´„ã‚’å®Ÿç¾ã—ã¾ã™ã€‚\n\n- **ğŸ§  LLMã«ã‚ˆã‚‹è³ªå•åˆ†æ**ï¼šæœ€å…ˆç«¯ã®è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’æ´»ç”¨ã—ã¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã‚’åˆ†æã—ã€é«˜ç²¾åº¦ãªæ¤œç´¢æˆ¦ç•¥ã¨åŸºæº–ã‚’ç”Ÿæˆã—ã¾ã™ã€‚llama-githubã¯è¤‡é›‘ãªã‚¯ã‚¨ãƒªã‚’è³¢ãåˆ†è§£ã—ã€GitHubã®è†¨å¤§ãªãƒªãƒã‚¸ãƒˆãƒªãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‹ã‚‰æœ€ã‚‚é–¢é€£æ€§ã®é«˜ã„æƒ…å ±ã‚’å–å¾—ã—ã¾ã™ã€‚\n\n- **ğŸ“š åŒ…æ‹¬çš„ãªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ**ï¼šGitHubã‹ã‚‰å–å¾—ã—ãŸæƒ…å ±ã¨é«˜åº¦ãªè¨€èªãƒ¢ãƒ‡ãƒ«ã®æ¨è«–èƒ½åŠ›ã‚’ã‚·ãƒ¼ãƒ ãƒ¬ã‚¹ã«çµ„ã¿åˆã‚ã›ã€è±Šã‹ã§æ–‡è„ˆã«å³ã—ãŸå›ç­”ã‚’ç”Ÿæˆã—ã¾ã™ã€‚llama-githubã¯è¤‡é›‘ã§é•·å¤§ãªè³ªå•ã«ã‚‚å„ªã‚Œã¦å¯¾å¿œã—ã€é–‹ç™ºãƒ‹ãƒ¼ã‚ºã‚’æ”¯æ´ã™ã‚‹åºƒç¯„ãªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å«ã‚€åŒ…æ‹¬çš„ã§æ´å¯Ÿã«æº€ã¡ãŸå¿œç­”ã‚’æä¾›ã—ã¾ã™ã€‚\n\n- **ğŸš€ éåŒæœŸå‡¦ç†ã®å„ªä½æ€§**ï¼šllama-githubã¯éåŒæœŸãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã®æ½œåœ¨èƒ½åŠ›ã‚’æœ€å¤§é™ã«æ´»ç”¨ã™ã‚‹ã‚ˆã†ã«è¨­è¨ˆã•ã‚Œã¦ã„ã¾ã™ã€‚ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹å…¨ä½“ã«ç·»å¯†ã«å®Ÿè£…ã•ã‚ŒãŸéåŒæœŸãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã«ã‚ˆã‚Šã€è¤‡æ•°ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’åŒæ™‚ã«å‡¦ç†ã§ãã€å…¨ä½“ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å¤§å¹…ã«å‘ä¸Šã•ã›ã¾ã™ã€‚llama-githubãŒé«˜é€Ÿã‹ã¤é«˜å“è³ªã‚’æãªã†ã“ã¨ãªãå¤§é‡ã®ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰ã‚’åŠ¹ç‡çš„ã«ç®¡ç†ã™ã‚‹é•ã„ã‚’ä½“é¨“ã—ã¦ãã ã•ã„ã€‚\n\n- **ğŸ”§ æŸ”è»ŸãªLLMçµ±åˆ**ï¼šã•ã¾ã–ã¾ãªLLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã€åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã€å†ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«ã¨å®¹æ˜“ã«çµ±åˆã—ã€ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®æ©Ÿèƒ½ã‚’ç‰¹å®šã®è¦ä»¶ã«åˆã‚ã›ã¦èª¿æ•´ã§ãã¾ã™ã€‚æ‹¡å¼µå¯èƒ½ãªã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã«ã‚ˆã‚Šã€llama-githubã®æ©Ÿèƒ½ã‚’ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºãŠã‚ˆã³å¼·åŒ–ã—ã€ç‹¬è‡ªã®é–‹ç™ºç’°å¢ƒã«ã‚·ãƒ¼ãƒ ãƒ¬ã‚¹ã«é©å¿œã•ã›ã‚‹ã“ã¨ãŒå¯èƒ½ã§ã™ã€‚\n\n- **ğŸ”’ å¼·å›ºãªèªè¨¼ã‚ªãƒ—ã‚·ãƒ§ãƒ³**ï¼šllama-githubã¯å€‹äººã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³ã¨GitHub Appèªè¨¼ã®ä¸¡æ–¹ã‚’ã‚µãƒãƒ¼ãƒˆã—ã€ã•ã¾ã–ã¾ãªé–‹ç™ºç’°å¢ƒã«æŸ”è»Ÿã«çµ±åˆã§ãã¾ã™ã€‚å€‹äººé–‹ç™ºè€…ã§ã‚‚çµ„ç¹”å†…ã§ã‚‚ã€å®‰å…¨ã§ä¿¡é ¼æ€§ã®é«˜ã„èªè¨¼ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’æä¾›ã—ã¾ã™ã€‚\n\n- **ğŸ› ï¸ ãƒ­ã‚®ãƒ³ã‚°ã¨ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°**ï¼šã‚¹ãƒ ãƒ¼ã‚ºãªé‹ç”¨ã¨å®¹æ˜“ãªãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã®é‡è¦æ€§ã‚’ç†è§£ã—ã¦ã„ã¾ã™ã€‚llama-githubã«ã¯åŒ…æ‹¬çš„ãªãƒ­ã‚®ãƒ³ã‚°ã¨ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°æ©Ÿæ§‹ãŒå‚™ã‚ã£ã¦ãŠã‚Šã€ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®æŒ™å‹•ã‚’æ·±ãæŠŠæ¡ã—ã€å•é¡Œã‚’è¿…é€Ÿã«è¨ºæ–­ã—ã€å®‰å®šã—ãŸä¿¡é ¼æ€§ã®é«˜ã„é–‹ç™ºãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’ç¶­æŒã§ãã¾ã™ã€‚\n\n## ğŸ¤– AIæ­è¼‰ã®PRãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã€ŒLlamaPReviewã€ã‚’ãŠè©¦ã—ãã ã•ã„\n\nllama-githubãŒãŠå½¹ã«ç«‹ã¦ã‚‹å ´åˆã€AIæ­è¼‰ã®GitHub PRãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã€ŒLlamaPReviewã€ã‚‚ã”æ¤œè¨ãã ã•ã„ã€‚é–‹ç™ºãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’è£œå®Œã—ã€ã‚³ãƒ¼ãƒ‰å“è³ªã‚’ã•ã‚‰ã«å‘ä¸Šã•ã›ã‚‹ã“ã¨ã‚’ç›®çš„ã¨ã—ã¦ã„ã¾ã™ã€‚\n\n### LlamaPReviewã®ä¸»ãªç‰¹å¾´ï¼š\n- ğŸš€ ãƒ¯ãƒ³ã‚¯ãƒªãƒƒã‚¯ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã€è¨­å®šä¸è¦ã§å®Œå…¨è‡ªå‹•å®Ÿè¡Œ\n- ğŸ’¯ ç¾åœ¨ç„¡æ–™ã§ä½¿ç”¨å¯èƒ½ - ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆã‚«ãƒ¼ãƒ‰ã‚„æ”¯æ‰•ã„æƒ…å ±ã¯ä¸è¦\n- ğŸ§  AIæ­è¼‰ã§æ·±ã„ã‚³ãƒ¼ãƒ‰ç†è§£ã«ã‚ˆã‚‹è‡ªå‹•PRãƒ¬ãƒ“ãƒ¥ãƒ¼\n- ğŸŒ è¤‡æ•°ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªã«å¯¾å¿œ\n\n**LlamaPReviewã¯llama-githubã®é«˜åº¦ãªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå–å¾—ã¨LLMã«ã‚ˆã‚‹åˆ†æã‚’æ´»ç”¨ã—**ã€ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆã§æ–‡è„ˆã‚’è€ƒæ…®ã—ãŸã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’æä¾›ã—ã¾ã™ã€‚ãƒªãƒã‚¸ãƒˆãƒªã®å…¨ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å‚™ãˆãŸã‚·ãƒ‹ã‚¢é–‹ç™ºè€…ãŒã™ã¹ã¦ã®PRã‚’è‡ªå‹•çš„ã«ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã¦ãã‚Œã‚‹ã‹ã®ã‚ˆã†ã§ã™ï¼\n\nğŸ‘‰ [ä»Šã™ãLlamaPReviewã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«](https://github.com/marketplace/llamapreview/)ï¼ˆç„¡æ–™ï¼‰\n\nllama-githubã«ã‚ˆã‚‹ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå–å¾—ã¨LlamaPReviewã«ã‚ˆã‚‹ã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®çµ„ã¿åˆã‚ã›ã§ã€å¼·åŠ›ãªAIå¼·åŒ–é–‹ç™ºç’°å¢ƒã‚’æ§‹ç¯‰ã§ãã¾ã™ã€‚\n\n## ãƒ“ã‚¸ãƒ§ãƒ³ã¨ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—\n\n### ãƒ“ã‚¸ãƒ§ãƒ³\n\nç§ãŸã¡ã®ãƒ“ã‚¸ãƒ§ãƒ³ã¯ã€AIé§†å‹•ã®é–‹ç™ºã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã®æœªæ¥ã«ãŠã„ã¦é‡è¦ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¨ãªã‚Šã€GitHubã¨ã‚·ãƒ¼ãƒ ãƒ¬ã‚¹ã«çµ±åˆã—ã¦LLMãŒè¤‡é›‘ãªã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°èª²é¡Œã‚’è‡ªå‹•çš„ã«è§£æ±ºã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹ã“ã¨ã§ã™ã€‚\n\n![Vision Architecture](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/./docs/vision.drawio.svg)\n\n### ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—\n\nãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®è©³ç´°ãªãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—ã¯ã€[ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—](https://github.com/users/JetXu-LLM/projects/2)ã‚’ã”è¦§ãã ã•ã„ã€‚\n\n## è¬è¾\n\næ¬¡ã®ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«æ„Ÿè¬ã®æ„ã‚’è¡¨ã—ã¾ã™ã€‚å½¼ã‚‰ã®æ”¯æ´ã¨è²¢çŒ®ã«ã‚ˆã‚Šã€llama-githubã®é–‹ç™ºãŒå¯èƒ½ã¨ãªã‚Šã¾ã—ãŸã€‚\n\n- **[LangChain](https://github.com/langchain-ai/langchain)**ï¼šllama-githubã®LLMãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŠã‚ˆã³å‡¦ç†æ©Ÿèƒ½ã‚’æ”¯ãˆã‚‹åŸºç›¤ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’æä¾›ã€‚\n- **[Jina.ai](https://github.com/jina-ai/reader)**ï¼šs.jina.ai APIãŠã‚ˆã³ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®å†ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«ã¨åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã‚’æä¾›ã—ã€llama-githubã®ç”Ÿæˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®ç²¾åº¦ã¨é–¢é€£æ€§ã‚’å‘ä¸Šã€‚\n\nå½¼ã‚‰ã®è²¢çŒ®ã¯llama-githubã®é–‹ç™ºã«ä¸å¯æ¬ ã§ã‚ã‚Šã€ã‚ˆã‚Šé©æ–°çš„ãªã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æ¢ã—ã¦ã„ã‚‹æ–¹ã«ã¯ãœã²å½¼ã‚‰ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’ãƒã‚§ãƒƒã‚¯ã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚\n\n## è²¢çŒ®ã«ã¤ã„ã¦\n\nllama-githubã¸ã®è²¢çŒ®ã‚’æ­“è¿ã—ã¾ã™ï¼è©³ç´°ã¯[è²¢çŒ®ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/CONTRIBUTING.md)ã‚’ã”è¦§ãã ã•ã„ã€‚\n\n## ãƒ©ã‚¤ã‚»ãƒ³ã‚¹\n\næœ¬ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯Apache 2.0ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã®ä¸‹ã§æä¾›ã•ã‚Œã¦ã„ã¾ã™ã€‚è©³ç´°ã¯[LICENSE](LICENSE)ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã”è¦§ãã ã•ã„ã€‚\n\n## ãŠå•ã„åˆã‚ã›\n\nã”è³ªå•ã€ã”ææ¡ˆã€ã”æ„è¦‹ãŒã”ã–ã„ã¾ã—ãŸã‚‰ã€[Jet Xuã®ãƒ¡ãƒ¼ãƒ«](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/mailto:Voldemort.xu@foxmail.com)ã¾ã§ãŠæ°—è»½ã«ã”é€£çµ¡ãã ã•ã„ã€‚\n\n---\n\nllama-githubã‚’ãŠé¸ã³ã„ãŸã ãã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ï¼ã“ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒçš†æ§˜ã®AIé–‹ç™ºä½“é¨“ã‚’å‘ä¸Šã•ã›ã€å¼·åŠ›ãªã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³æ§‹ç¯‰ã®åŠ©ã‘ã¨ãªã‚‹ã“ã¨ã‚’é¡˜ã£ã¦ã„ã¾ã™ã€‚\n\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "ã‚ˆã‚Šé«˜åº¦ãªä½¿ç”¨ä¾‹ã‚„è©³ç´°ã«ã¤ã„ã¦ã¯ã€[ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/docs/usage.md)ã‚’ã”å‚ç…§ãã ã•ã„ã€‚"
      },
      {
        "row": 2,
        "rowsha": "zrMByz3uboJewll5VwM0OlM3JCc+dvchgXugvMGdZyA=",
        "originContent": "For more advanced usage and examples, please refer to the [documentation](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/docs/usage.md).",
        "translatedContent": ""
      },
      {
        "row": 3,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "## ä¸»ãªç‰¹å¾´"
      },
      {
        "row": 4,
        "rowsha": "khTPM/+Q4D8FMdf3qgrMDcjDejggkuMl1+JmWZMODFI=",
        "originContent": "## Key Features",
        "translatedContent": ""
      },
      {
        "row": 5,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "- **ğŸ” ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆãªGitHubæ¤œç´¢**ï¼šãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚¯ã‚¨ãƒªã«åŸºã¥ãã€llama-githubã®åŠ›ã‚’æ´»ç”¨ã—ã¦GitHubã‹ã‚‰é–¢é€£æ€§ã®é«˜ã„ã‚³ãƒ¼ãƒ‰ã‚¹ãƒ‹ãƒšãƒƒãƒˆã€ã‚¤ã‚·ãƒ¥ãƒ¼ã€ãƒªãƒã‚¸ãƒˆãƒªæƒ…å ±ã‚’å–å¾—ã—ã¾ã™ã€‚é«˜åº¦ãªæ¤œç´¢æŠ€è¡“ã«ã‚ˆã‚Šã€æœ€ã‚‚é©åˆ‡ãªæƒ…å ±ã‚’è¿…é€Ÿã‹ã¤åŠ¹ç‡çš„ã«è¦‹ã¤ã‘å‡ºã—ã¾ã™ã€‚"
      },
      {
        "row": 6,
        "rowsha": "DfE9NcmRSF011JyFgs3cD/a2VQqPhp+XXqaTnhAtBwc=",
        "originContent": "- **ğŸ” Intelligent GitHub Retrieval**: Harness the power of llama-github to retrieve highly relevant code snippets, issues, and repository information from GitHub based on user queries. Our advanced retrieval techniques ensure you find the most pertinent information quickly and efficiently.",
        "translatedContent": ""
      },
      {
        "row": 7,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "- **âš¡ ãƒªãƒã‚¸ãƒˆãƒªãƒ—ãƒ¼ãƒ«ã‚­ãƒ£ãƒƒã‚·ãƒ¥**ï¼šllama-githubã¯é©æ–°çš„ãªãƒªãƒã‚¸ãƒˆãƒªãƒ—ãƒ¼ãƒ«ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ©Ÿæ§‹ã‚’å‚™ãˆã¦ã„ã¾ã™ã€‚ã‚¹ãƒ¬ãƒƒãƒ‰é–“ã§ãƒªãƒã‚¸ãƒˆãƒªï¼ˆREADMEã€æ§‹é€ ã€ã‚³ãƒ¼ãƒ‰ã€ã‚¤ã‚·ãƒ¥ãƒ¼ã‚’å«ã‚€ï¼‰ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã™ã‚‹ã“ã¨ã§ã€GitHubæ¤œç´¢ã®å–å¾—åŠ¹ç‡ã‚’å¤§å¹…ã«å‘ä¸Šã•ã›ã€GitHub APIãƒˆãƒ¼ã‚¯ãƒ³ã®æ¶ˆè²»ã‚’æœ€å°é™ã«æŠ‘ãˆã¾ã™ã€‚ãƒãƒ«ãƒã‚¹ãƒ¬ãƒƒãƒ‰ã®æœ¬ç•ªç’°å¢ƒã«è‡ªä¿¡ã‚’æŒã£ã¦å°å…¥ã§ãã€æœ€é©ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¨è²´é‡ãªãƒªã‚½ãƒ¼ã‚¹ã®ç¯€ç´„ã‚’å®Ÿç¾ã—ã¾ã™ã€‚"
      },
      {
        "row": 8,
        "rowsha": "OtNyTLgFLD0QDlCwfKWcttMbckHUBj2YJNKV9r+Uc54=",
        "originContent": "- **âš¡ Repository Pool Caching**: Llama-github has an innovative repository pool caching mechanism. By caching repositories (including READMEs, structures, code, and issues) across threads, llama-github significantly accelerates GitHub search retrieval efficiency and minimizes the consumption of GitHub API tokens. Deploy llama-github in multi-threaded production environments with confidence, knowing that it will perform optimally and save you valuable resources.",
        "translatedContent": ""
      },
      {
        "row": 9,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "- **ğŸ§  LLMã«ã‚ˆã‚‹è³ªå•åˆ†æ**ï¼šæœ€å…ˆç«¯ã®è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’æ´»ç”¨ã—ã¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã‚’åˆ†æã—ã€é«˜ç²¾åº¦ãªæ¤œç´¢æˆ¦ç•¥ã¨åŸºæº–ã‚’ç”Ÿæˆã—ã¾ã™ã€‚llama-githubã¯è¤‡é›‘ãªã‚¯ã‚¨ãƒªã‚’è³¢ãåˆ†è§£ã—ã€GitHubã®è†¨å¤§ãªãƒªãƒã‚¸ãƒˆãƒªãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‹ã‚‰æœ€ã‚‚é–¢é€£æ€§ã®é«˜ã„æƒ…å ±ã‚’å–å¾—ã—ã¾ã™ã€‚"
      },
      {
        "row": 10,
        "rowsha": "JeXb8RZZhv2Wmw97j628XoyPreY+fMdIPsxoUQiEvzw=",
        "originContent": "- **ğŸ§  LLM-Powered Question Analysis**: Leverage state-of-the-art language models to analyze user questions and generate highly effective search strategies and criteria. Llama-github intelligently breaks down complex queries, ensuring that you retrieve the most relevant information from GitHub's vast repository network.",
        "translatedContent": ""
      },
      {
        "row": 11,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "- **ğŸ“š åŒ…æ‹¬çš„ãªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ**ï¼šGitHubã‹ã‚‰å–å¾—ã—ãŸæƒ…å ±ã¨é«˜åº¦ãªè¨€èªãƒ¢ãƒ‡ãƒ«ã®æ¨è«–èƒ½åŠ›ã‚’ã‚·ãƒ¼ãƒ ãƒ¬ã‚¹ã«çµ„ã¿åˆã‚ã›ã€è±Šã‹ã§æ–‡è„ˆã«å³ã—ãŸå›ç­”ã‚’ç”Ÿæˆã—ã¾ã™ã€‚llama-githubã¯è¤‡é›‘ã§é•·å¤§ãªè³ªå•ã«ã‚‚å„ªã‚Œã¦å¯¾å¿œã—ã€é–‹ç™ºãƒ‹ãƒ¼ã‚ºã‚’æ”¯æ´ã™ã‚‹åºƒç¯„ãªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å«ã‚€åŒ…æ‹¬çš„ã§æ´å¯Ÿã«æº€ã¡ãŸå¿œç­”ã‚’æä¾›ã—ã¾ã™ã€‚"
      },
      {
        "row": 12,
        "rowsha": "yA7pWfx0KVCXQ2Eo49pVkbLR+DABI/mKnMw/tj/sCL0=",
        "originContent": "- **ğŸ“š Comprehensive Context Generation**: Generate rich, contextually relevant answers by seamlessly combining information retrieved from GitHub with the reasoning capabilities of advanced language models. Llama-github excels at handling even the most complex and lengthy questions, providing comprehensive and insightful responses that include extensive context to support your development needs.",
        "translatedContent": ""
      },
      {
        "row": 13,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "- **ğŸš€ éåŒæœŸå‡¦ç†ã®å„ªä½æ€§**ï¼šllama-githubã¯éåŒæœŸãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã®æ½œåœ¨èƒ½åŠ›ã‚’æœ€å¤§é™ã«æ´»ç”¨ã™ã‚‹ã‚ˆã†ã«è¨­è¨ˆã•ã‚Œã¦ã„ã¾ã™ã€‚ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹å…¨ä½“ã«ç·»å¯†ã«å®Ÿè£…ã•ã‚ŒãŸéåŒæœŸãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã«ã‚ˆã‚Šã€è¤‡æ•°ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’åŒæ™‚ã«å‡¦ç†ã§ãã€å…¨ä½“ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å¤§å¹…ã«å‘ä¸Šã•ã›ã¾ã™ã€‚llama-githubãŒé«˜é€Ÿã‹ã¤é«˜å“è³ªã‚’æãªã†ã“ã¨ãªãå¤§é‡ã®ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰ã‚’åŠ¹ç‡çš„ã«ç®¡ç†ã™ã‚‹é•ã„ã‚’ä½“é¨“ã—ã¦ãã ã•ã„ã€‚"
      },
      {
        "row": 14,
        "rowsha": "qku0KFnzN0JDJsFtvSnr1U47mAfoIMLCUgoTAF0FV2Q=",
        "originContent": "- **ğŸš€ Asynchronous Processing Excellence**: Llama-github is built from the ground up to leverage the full potential of asynchronous programming. With meticulously implemented asynchronous mechanisms woven throughout the codebase, llama-github can handle multiple requests concurrently, significantly boosting overall performance. Experience the difference as llama-github efficiently manages high-volume workloads without compromising on speed or quality.",
        "translatedContent": ""
      },
      {
        "row": 15,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "- **ğŸ”§ æŸ”è»ŸãªLLMçµ±åˆ**ï¼šã•ã¾ã–ã¾ãªLLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã€åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã€å†ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«ã¨å®¹æ˜“ã«çµ±åˆã—ã€ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®æ©Ÿèƒ½ã‚’ç‰¹å®šã®è¦ä»¶ã«åˆã‚ã›ã¦èª¿æ•´ã§ãã¾ã™ã€‚æ‹¡å¼µå¯èƒ½ãªã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã«ã‚ˆã‚Šã€llama-githubã®æ©Ÿèƒ½ã‚’ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºãŠã‚ˆã³å¼·åŒ–ã—ã€ç‹¬è‡ªã®é–‹ç™ºç’°å¢ƒã«ã‚·ãƒ¼ãƒ ãƒ¬ã‚¹ã«é©å¿œã•ã›ã‚‹ã“ã¨ãŒå¯èƒ½ã§ã™ã€‚"
      },
      {
        "row": 16,
        "rowsha": "0g6jkIpIeIIz2Gt8w6I2VAjPUz51+RDJs7fxVchaN/k=",
        "originContent": "- **ğŸ”§ Flexible LLM Integration**: Easily integrate llama-github with various LLM providers, embedding models, and reranking models to tailor the library's capabilities to your specific requirements. Our extensible architecture allows you to customize and enhance llama-github's functionality, ensuring that it adapts seamlessly to your unique development environment.",
        "translatedContent": ""
      },
      {
        "row": 17,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "- **ğŸ”’ å¼·å›ºãªèªè¨¼ã‚ªãƒ—ã‚·ãƒ§ãƒ³**ï¼šllama-githubã¯å€‹äººã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³ã¨GitHub Appèªè¨¼ã®ä¸¡æ–¹ã‚’ã‚µãƒãƒ¼ãƒˆã—ã€ã•ã¾ã–ã¾ãªé–‹ç™ºç’°å¢ƒã«æŸ”è»Ÿã«çµ±åˆã§ãã¾ã™ã€‚å€‹äººé–‹ç™ºè€…ã§ã‚‚çµ„ç¹”å†…ã§ã‚‚ã€å®‰å…¨ã§ä¿¡é ¼æ€§ã®é«˜ã„èªè¨¼ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’æä¾›ã—ã¾ã™ã€‚"
      },
      {
        "row": 18,
        "rowsha": "WH0+zgaxAP/W/KtIygVDuxydKTKp6imCYyXpqvXpjaM=",
        "originContent": "- **ğŸ”’ Robust Authentication Options**: Llama-github supports both personal access tokens and GitHub App authentication, providing you with the flexibility to integrate it into different development setups. Whether you're an individual developer or working within an organizational context, llama-github has you covered with secure and reliable authentication mechanisms.",
        "translatedContent": ""
      },
      {
        "row": 19,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "- **ğŸ› ï¸ ãƒ­ã‚®ãƒ³ã‚°ã¨ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°**ï¼šã‚¹ãƒ ãƒ¼ã‚ºãªé‹ç”¨ã¨å®¹æ˜“ãªãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã®é‡è¦æ€§ã‚’ç†è§£ã—ã¦ã„ã¾ã™ã€‚llama-githubã«ã¯åŒ…æ‹¬çš„ãªãƒ­ã‚®ãƒ³ã‚°ã¨ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°æ©Ÿæ§‹ãŒå‚™ã‚ã£ã¦ãŠã‚Šã€ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®æŒ™å‹•ã‚’æ·±ãæŠŠæ¡ã—ã€å•é¡Œã‚’è¿…é€Ÿã«è¨ºæ–­ã—ã€å®‰å®šã—ãŸä¿¡é ¼æ€§ã®é«˜ã„é–‹ç™ºãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’ç¶­æŒã§ãã¾ã™ã€‚"
      },
      {
        "row": 20,
        "rowsha": "IYhTxjMvy72M7T9kEBfrXUNMz08qwsXzETVoE3WSNyQ=",
        "originContent": "- **ğŸ› ï¸ Logging and Error Handling**: We understand the importance of smooth operations and easy troubleshooting. That's why llama-github comes equipped with comprehensive logging and error handling mechanisms. Gain deep insights into the library's behavior, quickly diagnose issues, and maintain a stable and reliable development workflow.",
        "translatedContent": ""
      },
      {
        "row": 21,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "## ğŸ¤– AIæ­è¼‰ã®PRãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã€ŒLlamaPReviewã€ã‚’ãŠè©¦ã—ãã ã•ã„"
      },
      {
        "row": 22,
        "rowsha": "QDeqAvaQEIQHPYjwq2KF5Bw3a76EiPq7ebbsGNKcRI8=",
        "originContent": "## ğŸ¤– Try Our AI-Powered PR Review Assistant: LlamaPReview",
        "translatedContent": ""
      },
      {
        "row": 23,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "llama-githubãŒãŠå½¹ã«ç«‹ã¦ã‚‹å ´åˆã€AIæ­è¼‰ã®GitHub PRãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã€ŒLlamaPReviewã€ã‚‚ã”æ¤œè¨ãã ã•ã„ã€‚é–‹ç™ºãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’è£œå®Œã—ã€ã‚³ãƒ¼ãƒ‰å“è³ªã‚’ã•ã‚‰ã«å‘ä¸Šã•ã›ã‚‹ã“ã¨ã‚’ç›®çš„ã¨ã—ã¦ã„ã¾ã™ã€‚"
      },
      {
        "row": 24,
        "rowsha": "laWUe+J402emMP2V1JeMqFpYefA8HTKWoI+lq7NfoyE=",
        "originContent": "If you find llama-github useful, you might also be interested in our AI-powered GitHub PR review assistant, LlamaPReview. It's designed to complement your development workflow and further enhance code quality.",
        "translatedContent": ""
      },
      {
        "row": 25,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "### LlamaPReviewã®ä¸»ãªç‰¹å¾´ï¼š"
      },
      {
        "row": 26,
        "rowsha": "J3M87xxuLQISS/m0fiv7phjnw7mYaznst6rel6n7MyY=",
        "originContent": "### Key Features of LlamaPReview:",
        "translatedContent": "- ğŸš€ ãƒ¯ãƒ³ã‚¯ãƒªãƒƒã‚¯ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã€è¨­å®šä¸è¦ã§å®Œå…¨è‡ªå‹•å®Ÿè¡Œ"
      },
      {
        "row": 27,
        "rowsha": "dGBd2SxNdlW1UATPSu01Iq95yCVz8fXbl7xxHqDYI7E=",
        "originContent": "- ğŸš€ One-click installation, zero configuration required, fully auto-run",
        "translatedContent": "- ğŸ’¯ ç¾åœ¨ç„¡æ–™ã§ä½¿ç”¨å¯èƒ½ - ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆã‚«ãƒ¼ãƒ‰ã‚„æ”¯æ‰•ã„æƒ…å ±ã¯ä¸è¦"
      },
      {
        "row": 28,
        "rowsha": "EP9hYUs4aYVAzXcYQyCGf3bjwo64OjAsqQHIN75oW60=",
        "originContent": "- ğŸ’¯ Currently free to use - no credit card or payment info needed",
        "translatedContent": "- ğŸ§  AIæ­è¼‰ã§æ·±ã„ã‚³ãƒ¼ãƒ‰ç†è§£ã«ã‚ˆã‚‹è‡ªå‹•PRãƒ¬ãƒ“ãƒ¥ãƒ¼"
      },
      {
        "row": 29,
        "rowsha": "jjWF/iUqSzPriHJ5iiFIq0Q6Pzx+gzPlnLu0Z4wmsSg=",
        "originContent": "- ğŸ§  AI-powered, automatic PR reviews with deep code understanding",
        "translatedContent": "- ğŸŒ è¤‡æ•°ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªã«å¯¾å¿œ"
      },
      {
        "row": 30,
        "rowsha": "Dsl+HsDM5NGI480TDo6eaFqgDcaofr3TDhLbUghSXhU=",
        "originContent": "- ğŸŒ Supports multiple programming languages",
        "translatedContent": ""
      },
      {
        "row": 31,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "**LlamaPReviewã¯llama-githubã®é«˜åº¦ãªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå–å¾—ã¨LLMã«ã‚ˆã‚‹åˆ†æã‚’æ´»ç”¨ã—**ã€ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆã§æ–‡è„ˆã‚’è€ƒæ…®ã—ãŸã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’æä¾›ã—ã¾ã™ã€‚ãƒªãƒã‚¸ãƒˆãƒªã®å…¨ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å‚™ãˆãŸã‚·ãƒ‹ã‚¢é–‹ç™ºè€…ãŒã™ã¹ã¦ã®PRã‚’è‡ªå‹•çš„ã«ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã¦ãã‚Œã‚‹ã‹ã®ã‚ˆã†ã§ã™ï¼"
      },
      {
        "row": 32,
        "rowsha": "GrzJg4j2iz94pupBQwJnFffhmsJ5IO9OkhqYvj0QEmo=",
        "originContent": "**LlamaPReview utilizes llama-github's advanced context retrieval and LLM-powered analysis** to provide intelligent, context-aware code reviews. It's like having a senior developer, armed with the full context of your repository, review every PR automatically!",
        "translatedContent": ""
      },
      {
        "row": 33,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "ğŸ‘‰ [ä»Šã™ãLlamaPReviewã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«](https://github.com/marketplace/llamapreview/)ï¼ˆç„¡æ–™ï¼‰"
      },
      {
        "row": 34,
        "rowsha": "4qGUTknerL/UTVikcUjFHvKzZlWho9opuf58fSIypyk=",
        "originContent": "ğŸ‘‰ [Install LlamaPReview Now](https://github.com/marketplace/llamapreview/) (Free)",
        "translatedContent": ""
      },
      {
        "row": 35,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "llama-githubã«ã‚ˆã‚‹ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå–å¾—ã¨LlamaPReviewã«ã‚ˆã‚‹ã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®çµ„ã¿åˆã‚ã›ã§ã€å¼·åŠ›ãªAIå¼·åŒ–é–‹ç™ºç’°å¢ƒã‚’æ§‹ç¯‰ã§ãã¾ã™ã€‚"
      },
      {
        "row": 36,
        "rowsha": "luTTMbXm2ikxAkHhFfh2iG9uPEwMYBRd2lolUoOY+3o=",
        "originContent": "By using llama-github for context retrieval and LlamaPReview for code reviews, you can create a powerful, AI-enhanced development environment.",
        "translatedContent": ""
      },
      {
        "row": 37,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "## ãƒ“ã‚¸ãƒ§ãƒ³ã¨ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—"
      },
      {
        "row": 38,
        "rowsha": "W2b655gztUgECPmTnBIkK/WbBo7d68AbNAjMtkHS5xY=",
        "originContent": "## Vision and Roadmap",
        "translatedContent": ""
      },
      {
        "row": 39,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "### ãƒ“ã‚¸ãƒ§ãƒ³"
      },
      {
        "row": 40,
        "rowsha": "Ewakmoa/Yb8fcDlChA12w7kAXVMFh8OrCLwVCTwIl84=",
        "originContent": "### Vision",
        "translatedContent": ""
      },
      {
        "row": 41,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "ç§ãŸã¡ã®ãƒ“ã‚¸ãƒ§ãƒ³ã¯ã€AIé§†å‹•ã®é–‹ç™ºã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã®æœªæ¥ã«ãŠã„ã¦é‡è¦ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¨ãªã‚Šã€GitHubã¨ã‚·ãƒ¼ãƒ ãƒ¬ã‚¹ã«çµ±åˆã—ã¦LLMãŒè¤‡é›‘ãªã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°èª²é¡Œã‚’è‡ªå‹•çš„ã«è§£æ±ºã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹ã“ã¨ã§ã™ã€‚"
      },
      {
        "row": 42,
        "rowsha": "0e6GYQC4W2Y8Ky5Q9UNeMwDc+ebEjDIUb9h4gSLQJaI=",
        "originContent": "Our vision is to become a pivotal module in the future of AI-driven development solutions, seamlessly integrating with GitHub to empower LLMs in automatically resolving complex coding tasks.",
        "translatedContent": ""
      },
      {
        "row": 43,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "![Vision Architecture](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/./docs/vision.drawio.svg)"
      },
      {
        "row": 44,
        "rowsha": "e3eGMrQR9LxN0lPlezIImRzi4tUu6n/GFfZsq5SBP4I=",
        "originContent": "![Vision Architecture](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/./docs/vision.drawio.svg)",
        "translatedContent": ""
      },
      {
        "row": 45,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "### ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—"
      },
      {
        "row": 46,
        "rowsha": "Q0D6oxy93TTXOZDvIiuco/ghaytG064tWvZdnLoKnOw=",
        "originContent": "### Roadmap",
        "translatedContent": ""
      },
      {
        "row": 47,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®è©³ç´°ãªãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—ã¯ã€[ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—](https://github.com/users/JetXu-LLM/projects/2)ã‚’ã”è¦§ãã ã•ã„ã€‚"
      },
      {
        "row": 48,
        "rowsha": "UHmL4/lEZk2jitjRxUVuHtD8JilL4OTzFLbU8R72Ymc=",
        "originContent": "For a detailed view of our project roadmap, please visit our [Project Roadmap](https://github.com/users/JetXu-LLM/projects/2).",
        "translatedContent": ""
      },
      {
        "row": 49,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "## è¬è¾"
      },
      {
        "row": 50,
        "rowsha": "N66ywbuGccMYNTyswaMSnFOlWqX+iaYP/myGJqr1tHo=",
        "originContent": "## Acknowledgments",
        "translatedContent": ""
      },
      {
        "row": 51,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "æ¬¡ã®ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«æ„Ÿè¬ã®æ„ã‚’è¡¨ã—ã¾ã™ã€‚å½¼ã‚‰ã®æ”¯æ´ã¨è²¢çŒ®ã«ã‚ˆã‚Šã€llama-githubã®é–‹ç™ºãŒå¯èƒ½ã¨ãªã‚Šã¾ã—ãŸã€‚"
      },
      {
        "row": 52,
        "rowsha": "WodCIp8BqxoCo7bxE7dxagf/Dvpvw7nWeECf0qG6FGI=",
        "originContent": "We would like to express our gratitude to the following open-source projects for their support and contributions:",
        "translatedContent": ""
      },
      {
        "row": 53,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "- **[LangChain](https://github.com/langchain-ai/langchain)**ï¼šllama-githubã®LLMãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŠã‚ˆã³å‡¦ç†æ©Ÿèƒ½ã‚’æ”¯ãˆã‚‹åŸºç›¤ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’æä¾›ã€‚"
      },
      {
        "row": 54,
        "rowsha": "HBIRZKkbsYOXsJY2Xepu1VxTAAdh869qSnsGbJ0cIg0=",
        "originContent": "- **[LangChain](https://github.com/langchain-ai/langchain)**: For providing the foundational framework that empowers the LLM prompting and processing capabilities in llama-github.",
        "translatedContent": "- **[Jina.ai](https://github.com/jina-ai/reader)**ï¼šs.jina.ai APIãŠã‚ˆã³ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®å†ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«ã¨åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã‚’æä¾›ã—ã€llama-githubã®ç”Ÿæˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®ç²¾åº¦ã¨é–¢é€£æ€§ã‚’å‘ä¸Šã€‚"
      },
      {
        "row": 55,
        "rowsha": "l7sjWwbh0OUJwk4+yJE2ZbVGypyaPrzI1YYMP7Uw9X0=",
        "originContent": "- **[Jina.ai](https://github.com/jina-ai/reader)**: For offering s.jina.ai API and open source reranker and embedding models that enhance the accuracy and relevance of the generated contexts in llama-github.",
        "translatedContent": ""
      },
      {
        "row": 56,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "å½¼ã‚‰ã®è²¢çŒ®ã¯llama-githubã®é–‹ç™ºã«ä¸å¯æ¬ ã§ã‚ã‚Šã€ã‚ˆã‚Šé©æ–°çš„ãªã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æ¢ã—ã¦ã„ã‚‹æ–¹ã«ã¯ãœã²å½¼ã‚‰ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’ãƒã‚§ãƒƒã‚¯ã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚"
      },
      {
        "row": 57,
        "rowsha": "hrChp1vDZFs3UZia39niD4Kx9hT0wKUMxSSiiyYyi7A=",
        "originContent": "Their contributions have been instrumental in the development of llama-github, and we highly recommend checking out their projects for more innovative solutions.",
        "translatedContent": ""
      },
      {
        "row": 58,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "## è²¢çŒ®ã«ã¤ã„ã¦"
      },
      {
        "row": 59,
        "rowsha": "R5ZPLZ4vkE9tjX5qe8QB7AkTfWZsuNTGFLFKMp2KUzM=",
        "originContent": "## Contributing",
        "translatedContent": ""
      },
      {
        "row": 60,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "llama-githubã¸ã®è²¢çŒ®ã‚’æ­“è¿ã—ã¾ã™ï¼è©³ç´°ã¯[è²¢çŒ®ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/CONTRIBUTING.md)ã‚’ã”è¦§ãã ã•ã„ã€‚"
      },
      {
        "row": 61,
        "rowsha": "JUWgAoIn9VhOEzmNL5dlAlHwcmo7N2Rm2GNx0g5Rijs=",
        "originContent": "We welcome contributions to llama-github! Please see our [contributing guidelines](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/CONTRIBUTING.md) for more information.",
        "translatedContent": ""
      },
      {
        "row": 62,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "## ãƒ©ã‚¤ã‚»ãƒ³ã‚¹"
      },
      {
        "row": 63,
        "rowsha": "bFSaVtsB4CHySNjaeCiaMZfT24b+DTbTM4HQ38cR6Lw=",
        "originContent": "## License",
        "translatedContent": ""
      },
      {
        "row": 64,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "æœ¬ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯Apache 2.0ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã®ä¸‹ã§æä¾›ã•ã‚Œã¦ã„ã¾ã™ã€‚è©³ç´°ã¯[LICENSE](LICENSE)ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã”è¦§ãã ã•ã„ã€‚"
      },
      {
        "row": 65,
        "rowsha": "hUzQdbczna0Cd3FyH+bhS5SWBDzmVQyA+nCi/UZO6VI=",
        "originContent": "This project is licensed under the terms of the Apache 2.0 license. See the [LICENSE](LICENSE) file for more details.",
        "translatedContent": ""
      },
      {
        "row": 66,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "## ãŠå•ã„åˆã‚ã›"
      },
      {
        "row": 67,
        "rowsha": "ZX9nbduzXgvmAaK8yTd+tNgwR7cV79HXV/+xbvL8suw=",
        "originContent": "## Contact",
        "translatedContent": ""
      },
      {
        "row": 68,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "ã”è³ªå•ã€ã”ææ¡ˆã€ã”æ„è¦‹ãŒã”ã–ã„ã¾ã—ãŸã‚‰ã€[Jet Xuã®ãƒ¡ãƒ¼ãƒ«](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/mailto:Voldemort.xu@foxmail.com)ã¾ã§ãŠæ°—è»½ã«ã”é€£çµ¡ãã ã•ã„ã€‚"
      },
      {
        "row": 69,
        "rowsha": "sZud9u8DDdJRsIyc+T0tdusx1FWC0pdv0Yn2hhndP9o=",
        "originContent": "If you have any questions, suggestions, or feedback, please feel free to reach out to us at [Jet Xu's email](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/mailto:Voldemort.xu@foxmail.com).",
        "translatedContent": ""
      },
      {
        "row": 70,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "---"
      },
      {
        "row": 71,
        "rowsha": "yz+R1U7uMOU+NbK5mQX3Dxae1Un9eJCdPawt78ntjTs=",
        "originContent": "---",
        "translatedContent": ""
      },
      {
        "row": 72,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "llama-githubã‚’ãŠé¸ã³ã„ãŸã ãã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ï¼ã“ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒçš†æ§˜ã®AIé–‹ç™ºä½“é¨“ã‚’å‘ä¸Šã•ã›ã€å¼·åŠ›ãªã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³æ§‹ç¯‰ã®åŠ©ã‘ã¨ãªã‚‹ã“ã¨ã‚’é¡˜ã£ã¦ã„ã¾ã™ã€‚"
      },
      {
        "row": 73,
        "rowsha": "98t5imS5RZt8kUxGAXqZcPmlZMcru27Gl/g31hb3g/c=",
        "originContent": "Thank you for choosing llama-github! We hope this library enhances your AI development experience and helps you build powerful applications with ease.",
        "translatedContent": ""
      },
      {
        "row": 74,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  }
]