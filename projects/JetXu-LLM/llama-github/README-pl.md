
<div align="right">
  <details>
    <summary >ğŸŒ JÄ™zyk</summary>
    <div>
      <div align="center">
        <a href="https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=en">English</a>
        | <a href="https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=zh-CN">ç®€ä½“ä¸­æ–‡</a>
        | <a href="https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=zh-TW">ç¹é«”ä¸­æ–‡</a>
        | <a href="https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=ja">æ—¥æœ¬èª</a>
        | <a href="https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=ko">í•œêµ­ì–´</a>
        | <a href="https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=hi">à¤¹à¤¿à¤¨à¥à¤¦à¥€</a>
        | <a href="https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=th">à¹„à¸—à¸¢</a>
        | <a href="https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=fr">FranÃ§ais</a>
        | <a href="https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=de">Deutsch</a>
        | <a href="https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=es">EspaÃ±ol</a>
        | <a href="https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=it">Italiano</a>
        | <a href="https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=ru">Ğ ÑƒÑÑĞºĞ¸Ğ¹</a>
        | <a href="https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=pt">PortuguÃªs</a>
        | <a href="https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=nl">Nederlands</a>
        | <a href="https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=pl">Polski</a>
        | <a href="https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=ar">Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©</a>
        | <a href="https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=fa">ÙØ§Ø±Ø³ÛŒ</a>
        | <a href="https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=tr">TÃ¼rkÃ§e</a>
        | <a href="https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=vi">Tiáº¿ng Viá»‡t</a>
        | <a href="https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=id">Bahasa Indonesia</a>
        | <a href="https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=as">à¦…à¦¸à¦®à§€à¦¯à¦¼à¦¾</
      </div>
    </div>
  </details>
</div>

# llama-github

[SzczegÃ³Å‚owy dokument] https://deepwiki.com/JetXu-LLM/llama-github

[![Wersja PyPI](https://badge.fury.io/py/llama-github.svg)](https://badge.fury.io/py/llama-github)
[![Pobrania](https://static.pepy.tech/badge/Llama-github)](https://pepy.tech/project/Llama-github)
[![Licencja](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)

Llama-github to potÄ™Å¼ne narzÄ™dzie, ktÃ³re pomaga wyszukiwaÄ‡ (w oparciu o Agentic RAG) najbardziej istotne fragmenty kodu, zgÅ‚oszenia i informacje o repozytorium z GitHub na podstawie Twoich zapytaÅ„, przeksztaÅ‚cajÄ…c je w wartoÅ›ciowy kontekst wiedzy. NarzÄ™dzie to umoÅ¼liwia chatbotom LLM, agentom AI oraz Auto-dev Agentom rozwiÄ…zywanie zÅ‚oÅ¼onych zadaÅ„ programistycznych. NiezaleÅ¼nie od tego, czy jesteÅ› programistÄ… szukajÄ…cym szybkich rozwiÄ…zaÅ„, czy inÅ¼ynierem wdraÅ¼ajÄ…cym zaawansowane Auto Dev AI Agents, llama-github sprawia, Å¼e jest to Å‚atwe i wydajne.

JeÅ›li podoba Ci siÄ™ ten projekt lub uwaÅ¼asz, Å¼e ma on potencjaÅ‚, prosimy o zostawienie â­ï¸. Twoje wsparcie jest dla nas najwiÄ™kszÄ… motywacjÄ…!

## Architektura
![Architektura wysokiego poziomu](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/./docs/high_level_architecture.drawio.svg)

## Instalacja
```
pip install llama-github
```

## UÅ¼ytkowanie

Oto prosty przykÅ‚ad, jak uÅ¼ywaÄ‡ llama-github:

```python
from llama_github import GithubRAG

# Initialize GithubRAG with your credentials
github_rag = GithubRAG(
    github_access_token="your_github_access_token", 
    openai_api_key="your_openai_api_key", # Optional in Simple Mode
    jina_api_key="your_jina_api_key" # Optional - unless you want high concurrency production deployment (s.jina.ai API will be used in llama-github)
)

# Retrieve context for a coding question (simple_mode is default set to False)
query = "How to create a NumPy array in Python?"
context = github_rag.retrieve_context(
    query, # In professional mode, one query will take nearly 1 min to generate final contexts. You could set log level to INFO to monitor the retrieval progress
    # simple_mode = True
)

print(context)
```

Aby uzyskaÄ‡ bardziej zaawansowane przykÅ‚ady uÅ¼ycia, zapoznaj siÄ™ z [dokumentacjÄ…](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/docs/usage.md).

## Kluczowe funkcje

- **ğŸ” Inteligentne pobieranie z GitHub**: Wykorzystaj moc llama-github do pobierania najbardziej trafnych fragmentÃ³w kodu, zgÅ‚oszeÅ„ i informacji o repozytoriach z GitHub na podstawie zapytaÅ„ uÅ¼ytkownika. Nasze zaawansowane techniki wyszukiwania zapewniajÄ… szybkie i skuteczne znajdowanie najwaÅ¼niejszych informacji.

- **âš¡ PamiÄ™Ä‡ podrÄ™czna puli repozytoriÃ³w**: Llama-github posiada innowacyjny mechanizm pamiÄ™ci podrÄ™cznej puli repozytoriÃ³w. DziÄ™ki buforowaniu repozytoriÃ³w (w tym plikÃ³w README, struktury, kodu i zgÅ‚oszeÅ„) miÄ™dzy wÄ…tkami, llama-github znacznie przyspiesza wydajnoÅ›Ä‡ wyszukiwania na GitHub i minimalizuje zuÅ¼ycie tokenÃ³w API GitHub. WdraÅ¼aj llama-github w Å›rodowiskach wielowÄ…tkowych bez obaw o wydajnoÅ›Ä‡ i oszczÄ™dnoÅ›Ä‡ zasobÃ³w.

- **ğŸ§  Analiza pytaÅ„ oparta na LLM**: Skorzystaj z najnowoczeÅ›niejszych modeli jÄ™zykowych do analizy pytaÅ„ uÅ¼ytkownikÃ³w oraz generowania skutecznych strategii i kryteriÃ³w wyszukiwania. Llama-github inteligentnie rozkÅ‚ada zÅ‚oÅ¼one zapytania, zapewniajÄ…c dostÄ™p do najbardziej trafnych informacji z ogromnej sieci repozytoriÃ³w GitHub.

- **ğŸ“š Kompleksowe generowanie kontekstu**: Generuj bogate, kontekstowo trafne odpowiedzi, pÅ‚ynnie Å‚Ä…czÄ…c informacje pobrane z GitHub z moÅ¼liwoÅ›ciami rozumowania zaawansowanych modeli jÄ™zykowych. Llama-github doskonale radzi sobie nawet z najbardziej zÅ‚oÅ¼onymi i dÅ‚ugimi pytaniami, dostarczajÄ…c szczegÃ³Å‚owych odpowiedzi wraz z szerokim kontekstem wspierajÄ…cym Twoje potrzeby programistyczne.

- **ğŸš€ DoskonaÅ‚oÅ›Ä‡ przetwarzania asynchronicznego**: Llama-github zostaÅ‚ stworzony od podstaw, aby w peÅ‚ni wykorzystaÄ‡ potencjaÅ‚ programowania asynchronicznego. DziÄ™ki starannie zaimplementowanym mechanizmom asynchronicznym w caÅ‚ej bazie kodu, llama-github obsÅ‚uguje wiele Å¼Ä…daÅ„ jednoczeÅ›nie, znaczÄ…co zwiÄ™kszajÄ…c wydajnoÅ›Ä‡. Przekonaj siÄ™, jak efektywnie zarzÄ…dza duÅ¼ym obciÄ…Å¼eniem bez utraty szybkoÅ›ci i jakoÅ›ci.

- **ğŸ”§ Elastyczna integracja z LLM**: Åatwo integruj llama-github z rÃ³Å¼nymi dostawcami LLM, modelami embedding i reranking, dostosowujÄ…c moÅ¼liwoÅ›ci biblioteki do wÅ‚asnych wymagaÅ„. Nasza rozszerzalna architektura pozwala na personalizacjÄ™ i rozbudowÄ™ funkcjonalnoÅ›ci llama-github, dziÄ™ki czemu pÅ‚ynnie dopasuje siÄ™ do Twojego Å›rodowiska deweloperskiego.

- **ğŸ”’ Solidne opcje uwierzytelniania**: Llama-github obsÅ‚uguje zarÃ³wno tokeny dostÄ™pu osobistego, jak i uwierzytelnianie za pomocÄ… GitHub App, dajÄ…c elastycznoÅ›Ä‡ integracji w rÃ³Å¼nych Å›rodowiskach programistycznych. NiezaleÅ¼nie od tego, czy jesteÅ› indywidualnym deweloperem, czy pracujesz w organizacji, llama-github zapewnia bezpieczne i niezawodne mechanizmy uwierzytelniania.

- **ğŸ› ï¸ Logowanie i obsÅ‚uga bÅ‚Ä™dÃ³w**: Rozumiemy, jak waÅ¼na jest pÅ‚ynna obsÅ‚uga i Å‚atwe rozwiÄ…zywanie problemÃ³w. Dlatego llama-github wyposaÅ¼ony jest w kompleksowy system logowania i obsÅ‚ugi bÅ‚Ä™dÃ³w. Uzyskaj wglÄ…d w dziaÅ‚anie biblioteki, szybko diagnozuj problemy i utrzymuj stabilny oraz niezawodny workflow deweloperski.

## ğŸ¤– WyprÃ³buj naszego AI-asystenta do przeglÄ…du PR: LlamaPReview

JeÅ›li uwaÅ¼asz, Å¼e llama-github jest przydatny, moÅ¼e zainteresuje CiÄ™ takÅ¼e nasz AI-asystent do przeglÄ…du PR na GitHub, LlamaPReview. ZostaÅ‚ zaprojektowany, by uzupeÅ‚niÄ‡ TwÃ³j workflow programistyczny i dodatkowo poprawiÄ‡ jakoÅ›Ä‡ kodu.

### Kluczowe funkcje LlamaPReview:
- ğŸš€ Instalacja jednym klikniÄ™ciem, zero konfiguracji, peÅ‚na automatyzacja
- ğŸ’¯ Obecnie darmowy - nie wymaga karty ani pÅ‚atnoÅ›ci
- ğŸ§  Automatyczne, AI-napÄ™dzane przeglÄ…dy PR z gÅ‚Ä™bokim zrozumieniem kodu
- ğŸŒ ObsÅ‚uga wielu jÄ™zykÃ³w programowania

**LlamaPReview wykorzystuje zaawansowane pobieranie kontekstu oraz analizÄ™ LLM z llama-github**, by zapewniÄ‡ inteligentne, kontekstowe przeglÄ…dy kodu. To jakbyÅ› miaÅ‚ starszego programistÄ™, ktÃ³ry zna caÅ‚y kontekst repozytorium i automatycznie przeglÄ…da kaÅ¼dy PR!

ğŸ‘‰ [Zainstaluj LlamaPReview teraz](https://github.com/marketplace/llamapreview/) (Darmowe)

KorzystajÄ…c z llama-github do pobierania kontekstu i LlamaPReview do przeglÄ…dÃ³w kodu, tworzysz potÄ™Å¼ne, AI-wspierane Å›rodowisko deweloperskie.

## Wizja i plan rozwoju

### Wizja

NaszÄ… wizjÄ… jest staÄ‡ siÄ™ kluczowym moduÅ‚em w przyszÅ‚oÅ›ci rozwiÄ…zaÅ„ opartych na AI, integrujÄ…cym siÄ™ z GitHub w celu umoÅ¼liwienia LLM automatycznego rozwiÄ…zywania zÅ‚oÅ¼onych zadaÅ„ programistycznych.

![Architektura wizji](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/./docs/vision.drawio.svg)

### Plan rozwoju

Aby zobaczyÄ‡ szczegÃ³Å‚owy plan rozwoju projektu, odwiedÅº nasz [Project Roadmap](https://github.com/users/JetXu-LLM/projects/2).

## PodziÄ™kowania

ChcielibyÅ›my podziÄ™kowaÄ‡ nastÄ™pujÄ…cym projektom open-source za ich wsparcie i wkÅ‚ad:

- **[LangChain](https://github.com/langchain-ai/langchain)**: Za dostarczenie podstawowego frameworka, ktÃ³ry umoÅ¼liwia wywoÅ‚ywanie i przetwarzanie LLM w llama-github.
- **[Jina.ai](https://github.com/jina-ai/reader)**: Za udostÄ™pnienie API s.jina.ai oraz otwartoÅºrÃ³dÅ‚owych modeli rerankera i embedding, ktÃ³re zwiÄ™kszajÄ… trafnoÅ›Ä‡ i dokÅ‚adnoÅ›Ä‡ generowanych kontekstÃ³w w llama-github.

Ich wkÅ‚ad byÅ‚ kluczowy dla rozwoju llama-github i gorÄ…co polecamy ich projekty, jeÅ›li szukasz innowacyjnych rozwiÄ…zaÅ„.

## WkÅ‚ad w projekt

ZachÄ™camy do wspÃ³Å‚tworzenia llama-github! Zapoznaj siÄ™ z [wytycznymi dla kontrybutorÃ³w](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/CONTRIBUTING.md), by dowiedzieÄ‡ siÄ™ wiÄ™cej.

## Licencja

Ten projekt jest licencjonowany na zasadach licencji Apache 2.0. SzczegÃ³Å‚y znajdziesz w pliku [LICENSE](LICENSE).

## Kontakt

W razie pytaÅ„, sugestii lub opinii, skontaktuj siÄ™ z nami na [e-mail Jet Xu](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/mailto:Voldemort.xu@foxmail.com).

---

DziÄ™kujemy za wybÃ³r llama-github! Mamy nadziejÄ™, Å¼e biblioteka ulepszy Twoje doÅ›wiadczenia z AI i pomoÅ¼e Ci tworzyÄ‡ potÄ™Å¼ne aplikacje z Å‚atwoÅ›ciÄ….


---

Tranlated By [Open Ai Tx](https://github.com/OpenAiTx/OpenAiTx) | Last indexed: 2025-07-28

---