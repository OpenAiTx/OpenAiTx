[
  {
    "Id": 1,
    "Content": "\n<div align=\"right\">\n  <details>\n    <summary >üåê Language</summary>\n    <div>\n      <div align=\"center\">\n        <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=en\">English</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=zh-CN\">ÁÆÄ‰Ωì‰∏≠Êñá</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=zh-TW\">ÁπÅÈ´î‰∏≠Êñá</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=ja\">Êó•Êú¨Ë™û</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=ko\">ÌïúÍµ≠Ïñ¥</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=hi\">‡§π‡§ø‡§®‡•ç‡§¶‡•Ä</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=th\">‡πÑ‡∏ó‡∏¢</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=fr\">Fran√ßais</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=de\">Deutsch</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=es\">Espa√±ol</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=it\">Italiano</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=ru\">–†—É—Å—Å–∫–∏–π</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=pt\">Portugu√™s</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=nl\">Nederlands</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=pl\">Polski</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=ar\">ÿßŸÑÿπÿ±ÿ®Ÿäÿ©</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=fa\">ŸÅÿßÿ±ÿ≥€å</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=tr\">T√ºrk√ße</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=vi\">Ti·∫øng Vi·ªát</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=id\">Bahasa Indonesia</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=as\">‡¶Ö‡¶∏‡¶Æ‡ßÄ‡¶Ø‡¶º‡¶æ</\n      </div>\n    </div>\n  </details>\n</div>\n\n# llama-github\n\n[Detail Document] https://deepwiki.com/JetXu-LLM/llama-github\n\n[![PyPI version](https://badge.fury.io/py/llama-github.svg)](https://badge.fury.io/py/llama-github)\n[![Downloads](https://static.pepy.tech/badge/Llama-github)](https://pepy.tech/project/Llama-github)\n[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)\n\nLlama-github is a powerful tool that helps you retrieve(based on Agentic RAG) the most relevant code snippets, issues, and repository information from GitHub based on your queries, transforming them into valuable knowledge context. It empowers LLM Chatbots, AI Agents, and Auto-dev Agents to solve complex coding tasks. Whether you're a developer looking for quick solutions or an engineer implementing advanced Auto Dev AI Agents, llama-github makes it easy and efficient.\n\nIf you like this project or believe it has potential, please give it a ‚≠êÔ∏è. Your support is our greatest motivation!\n\n## Architecture\n![High Level Architecture](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/./docs/high_level_architecture.drawio.svg)\n\n## Installation",
    "ContentSha": "luGjPJ0t2eUH+w8RDBgGqCVyQiIo+mel0icgkq5phQc=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "<div align=\"right\">\n  <details>\n    <summary >üåê Idioma</summary>\n    <div>\n      <div align=\"center\">\n        <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=en\">English</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=zh-CN\">ÁÆÄ‰Ωì‰∏≠Êñá</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=zh-TW\">ÁπÅÈ´î‰∏≠Êñá</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=ja\">Êó•Êú¨Ë™û</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=ko\">ÌïúÍµ≠Ïñ¥</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=hi\">‡§π‡§ø‡§®‡•ç‡§¶‡•Ä</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=th\">‡πÑ‡∏ó‡∏¢</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=fr\">Fran√ßais</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=de\">Deutsch</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=es\">Espa√±ol</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=it\">Italiano</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=ru\">–†—É—Å—Å–∫–∏–π</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=pt\">Portugu√™s</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=nl\">Nederlands</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=pl\">Polski</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=ar\">ÿßŸÑÿπÿ±ÿ®Ÿäÿ©</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=fa\">ŸÅÿßÿ±ÿ≥€å</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=tr\">T√ºrk√ße</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=vi\">Ti·∫øng Vi·ªát</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=id\">Bahasa Indonesia</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=as\">‡¶Ö‡¶∏‡¶Æ‡ßÄ‡¶Ø‡¶º‡¶æ</\n      </div>\n    </div>\n  </details>\n</div>\n\n# llama-github\n\n[Documento Detalhado] https://deepwiki.com/JetXu-LLM/llama-github\n\n[![Vers√£o PyPI](https://badge.fury.io/py/llama-github.svg)](https://badge.fury.io/py/llama-github)\n[![Downloads](https://static.pepy.tech/badge/Llama-github)](https://pepy.tech/project/Llama-github)\n[![Licen√ßa](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)\n\nLlama-github √© uma ferramenta poderosa que ajuda voc√™ a recuperar (baseado em Agentic RAG) os trechos de c√≥digo, issues e informa√ß√µes de reposit√≥rio mais relevantes do GitHub com base em suas consultas, transformando-os em um contexto de conhecimento valioso. Ele potencializa Chatbots LLM, Agentes de IA e Agentes Auto-dev para resolver tarefas complexas de codifica√ß√£o. Seja voc√™ um desenvolvedor em busca de solu√ß√µes r√°pidas ou um engenheiro implementando Agentes Avan√ßados de Auto Dev IA, o llama-github torna tudo mais f√°cil e eficiente.\n\nSe voc√™ gosta deste projeto ou acredita que ele tem potencial, por favor, deixe uma ‚≠êÔ∏è. Seu apoio √© nossa maior motiva√ß√£o!\n\n## Arquitetura\n![Arquitetura de Alto N√≠vel](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/./docs/high_level_architecture.drawio.svg)\n\n## Instala√ß√£o\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "<div align=\"right\">"
      },
      {
        "row": 2,
        "rowsha": "cWgam+tnnXudu7i74+ahMEGk/A9dQS+EwWLAIfi3dHk=",
        "originContent": "<div align=\"right\">",
        "translatedContent": "  <details>"
      },
      {
        "row": 3,
        "rowsha": "orOcu5ARna/hb3RUkj6dBI8pHTM3WHeTvby17l5E0h0=",
        "originContent": "  <details>",
        "translatedContent": "    <summary >üåê Idioma</summary>"
      },
      {
        "row": 4,
        "rowsha": "TtgkLzblnvP0q9aAIVXt6s2LczXjy5k+QvHKcU0/5Ms=",
        "originContent": "    <summary >üåê Language</summary>",
        "translatedContent": "    <div>"
      },
      {
        "row": 5,
        "rowsha": "fZtk4rPTAJEEslnbhSVkHEcPlsctYSzAV7CDPL3rJmA=",
        "originContent": "    <div>",
        "translatedContent": "      <div align=\"center\">"
      },
      {
        "row": 6,
        "rowsha": "9KQxOeJSigvTmGWO+mtnl8kZY9zQfueoy8sk4lYm09Q=",
        "originContent": "      <div align=\"center\">",
        "translatedContent": "        <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=en\">English</a>"
      },
      {
        "row": 7,
        "rowsha": "HkJ4Gkepsmtc5YEEOiqUG3+NzfI0rf4IVUDgqFAmscs=",
        "originContent": "        <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=en\">English</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=zh-CN\">ÁÆÄ‰Ωì‰∏≠Êñá</a>"
      },
      {
        "row": 8,
        "rowsha": "SS8k2BQkHAHxyWP2X90nPl4mRZWm3fwXGqGF7mjnz18=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=zh-CN\">ÁÆÄ‰Ωì‰∏≠Êñá</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=zh-TW\">ÁπÅÈ´î‰∏≠Êñá</a>"
      },
      {
        "row": 9,
        "rowsha": "VrMYTJ2mzoZzeIKdl57fntnJgzWRQqxW+Hh05WTobsc=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=zh-TW\">ÁπÅÈ´î‰∏≠Êñá</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=ja\">Êó•Êú¨Ë™û</a>"
      },
      {
        "row": 10,
        "rowsha": "c+DqTRbRnir4FoupjpEksFzVENBVWRYltmlpDbwQZmM=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=ja\">Êó•Êú¨Ë™û</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=ko\">ÌïúÍµ≠Ïñ¥</a>"
      },
      {
        "row": 11,
        "rowsha": "Tm7I5B+gkMpCeJ3LR+BslLE5wbSUneyFmLReBj+Kuws=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=ko\">ÌïúÍµ≠Ïñ¥</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=hi\">‡§π‡§ø‡§®‡•ç‡§¶‡•Ä</a>"
      },
      {
        "row": 12,
        "rowsha": "wfZ0J7KdM7EX/cxK3wFAeE2ngExW4GfEYqHcAGlGx0w=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=hi\">‡§π‡§ø‡§®‡•ç‡§¶‡•Ä</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=th\">‡πÑ‡∏ó‡∏¢</a>"
      },
      {
        "row": 13,
        "rowsha": "y2QtQCnUvpYYte3U998DjX4FmVJMdwyXZ6wpYmbQkLE=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=th\">‡πÑ‡∏ó‡∏¢</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=fr\">Fran√ßais</a>"
      },
      {
        "row": 14,
        "rowsha": "zIupl7qEGAUFd0PjTxnqfYLAOYVxukVObZ2TvLzJhFI=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=fr\">Fran√ßais</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=de\">Deutsch</a>"
      },
      {
        "row": 15,
        "rowsha": "NeTDxlUu1SaaYA+ZU+IrCgYKslSqZUFfuhtr46HJnA0=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=de\">Deutsch</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=es\">Espa√±ol</a>"
      },
      {
        "row": 16,
        "rowsha": "0ltGddRJZJCJAdD4E6lPYrnG+o9jxtvzFgZ6J422BVM=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=es\">Espa√±ol</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=it\">Italiano</a>"
      },
      {
        "row": 17,
        "rowsha": "bzUdBLPtDNoKHOYQKJtE2KKD9trvdid+RiSJUXJ06jY=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=it\">Italiano</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=ru\">–†—É—Å—Å–∫–∏–π</a>"
      },
      {
        "row": 18,
        "rowsha": "0pozScPeqLIHLCyJkRlRQjDqqKb8HWwWqCv6uaxalEY=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=ru\">–†—É—Å—Å–∫–∏–π</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=pt\">Portugu√™s</a>"
      },
      {
        "row": 19,
        "rowsha": "ACT6kxJUtjo44NDX/ea/HxspYPgjmIuENrgcnxQYNEc=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=pt\">Portugu√™s</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=nl\">Nederlands</a>"
      },
      {
        "row": 20,
        "rowsha": "P5r7piMIRIzTPNX8NrKqGo+P1glz8ZRuJCLyQL24/LA=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=nl\">Nederlands</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=pl\">Polski</a>"
      },
      {
        "row": 21,
        "rowsha": "ZGMoXno6QdwcE1MCQ6a+39T9cMR9m1YyVj19nEOHOR8=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=pl\">Polski</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=ar\">ÿßŸÑÿπÿ±ÿ®Ÿäÿ©</a>"
      },
      {
        "row": 22,
        "rowsha": "VKZ+5aGayrqfPfJYP0j0/ap6ocirm1axw5vVvu7xsEE=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=ar\">ÿßŸÑÿπÿ±ÿ®Ÿäÿ©</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=fa\">ŸÅÿßÿ±ÿ≥€å</a>"
      },
      {
        "row": 23,
        "rowsha": "CWIbKiayiPOGqPcuulT54J/JKB9czskFXkMCgTgHrZs=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=fa\">ŸÅÿßÿ±ÿ≥€å</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=tr\">T√ºrk√ße</a>"
      },
      {
        "row": 24,
        "rowsha": "I1WcwpKhgv19NGCtlw+KLX03QSTLreFKCC9Ta0pFqIs=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=tr\">T√ºrk√ße</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=vi\">Ti·∫øng Vi·ªát</a>"
      },
      {
        "row": 25,
        "rowsha": "gIl9QJ2GwM0yfNYEXpcS2/xbtyKJbynqn4H4tnOyU2c=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=vi\">Ti·∫øng Vi·ªát</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=id\">Bahasa Indonesia</a>"
      },
      {
        "row": 26,
        "rowsha": "sMhilkGyfjhl6TXDHf4CKYnKDjhJR8fFg2lWQtaLDKc=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=id\">Bahasa Indonesia</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=as\">‡¶Ö‡¶∏‡¶Æ‡ßÄ‡¶Ø‡¶º‡¶æ</"
      },
      {
        "row": 27,
        "rowsha": "SFIUIQN+2TXGoifui/NZlin5QtiRQtdF5of1FBBu7Gk=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=as\">‡¶Ö‡¶∏‡¶Æ‡ßÄ‡¶Ø‡¶º‡¶æ</",
        "translatedContent": "      </div>"
      },
      {
        "row": 28,
        "rowsha": "0OM5wNEm0TO56MEBvQzL7AUZM7/3OpgIeqRf2zFre3Q=",
        "originContent": "      </div>",
        "translatedContent": "    </div>"
      },
      {
        "row": 29,
        "rowsha": "fcjTfY+fs8YnY5slBs1sZvWPAqEQR7tzaBDO54skkGQ=",
        "originContent": "    </div>",
        "translatedContent": "  </details>"
      },
      {
        "row": 30,
        "rowsha": "+fQNH2ldI7UM/rqRscP3hUSWAmw1HvQ2wEKDN8JagT0=",
        "originContent": "  </details>",
        "translatedContent": "</div>"
      },
      {
        "row": 31,
        "rowsha": "qsMmUbEPVnxGG5tPJV1vsfpoWbU2jYvZpRr5IKshzyM=",
        "originContent": "</div>",
        "translatedContent": ""
      },
      {
        "row": 32,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "# llama-github"
      },
      {
        "row": 33,
        "rowsha": "cAI8B2fw5xCydddeNcosOFY2wrQw8An1lrdomk97KBc=",
        "originContent": "# llama-github",
        "translatedContent": ""
      },
      {
        "row": 34,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "[Documento Detalhado] https://deepwiki.com/JetXu-LLM/llama-github"
      },
      {
        "row": 35,
        "rowsha": "jSTPMiMb5qDjmRYlxqDSx6zbsKYKOv4c6HQQgjbDUqo=",
        "originContent": "[Detail Document] https://deepwiki.com/JetXu-LLM/llama-github",
        "translatedContent": ""
      },
      {
        "row": 36,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "[![Vers√£o PyPI](https://badge.fury.io/py/llama-github.svg)](https://badge.fury.io/py/llama-github)"
      },
      {
        "row": 37,
        "rowsha": "48lo1Cg6fyAcQl554s/7eKSc41UYvSn/CD6yxtLVgjY=",
        "originContent": "[![PyPI version](https://badge.fury.io/py/llama-github.svg)](https://badge.fury.io/py/llama-github)",
        "translatedContent": "[![Downloads](https://static.pepy.tech/badge/Llama-github)](https://pepy.tech/project/Llama-github)"
      },
      {
        "row": 38,
        "rowsha": "VG3AfiYLkBPipFZPAt/fJt5jj8aI773UKbmI1Z/kc2M=",
        "originContent": "[![Downloads](https://static.pepy.tech/badge/Llama-github)](https://pepy.tech/project/Llama-github)",
        "translatedContent": "[![Licen√ßa](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)"
      },
      {
        "row": 39,
        "rowsha": "U0vs77tGfFYY+r4ScaOhTOZDgt8vSKCUyj59tU13ZtE=",
        "originContent": "[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)",
        "translatedContent": ""
      },
      {
        "row": 40,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "Llama-github √© uma ferramenta poderosa que ajuda voc√™ a recuperar (baseado em Agentic RAG) os trechos de c√≥digo, issues e informa√ß√µes de reposit√≥rio mais relevantes do GitHub com base em suas consultas, transformando-os em um contexto de conhecimento valioso. Ele potencializa Chatbots LLM, Agentes de IA e Agentes Auto-dev para resolver tarefas complexas de codifica√ß√£o. Seja voc√™ um desenvolvedor em busca de solu√ß√µes r√°pidas ou um engenheiro implementando Agentes Avan√ßados de Auto Dev IA, o llama-github torna tudo mais f√°cil e eficiente."
      },
      {
        "row": 41,
        "rowsha": "y7xsY1R0s8pmwDQukNS2PQ5JqK6CRs8AwuPrZkBKiT8=",
        "originContent": "Llama-github is a powerful tool that helps you retrieve(based on Agentic RAG) the most relevant code snippets, issues, and repository information from GitHub based on your queries, transforming them into valuable knowledge context. It empowers LLM Chatbots, AI Agents, and Auto-dev Agents to solve complex coding tasks. Whether you're a developer looking for quick solutions or an engineer implementing advanced Auto Dev AI Agents, llama-github makes it easy and efficient.",
        "translatedContent": ""
      },
      {
        "row": 42,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "Se voc√™ gosta deste projeto ou acredita que ele tem potencial, por favor, deixe uma ‚≠êÔ∏è. Seu apoio √© nossa maior motiva√ß√£o!"
      },
      {
        "row": 43,
        "rowsha": "6h9r25r7afHOT0YHlaj7xv1WU2JfjWqSqLUM7UgJNfQ=",
        "originContent": "If you like this project or believe it has potential, please give it a ‚≠êÔ∏è. Your support is our greatest motivation!",
        "translatedContent": ""
      },
      {
        "row": 44,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "## Arquitetura"
      },
      {
        "row": 45,
        "rowsha": "p+VkcrEb08g4vIGZYB9aVScRKgA8afv5WwErwTVzoZM=",
        "originContent": "## Architecture",
        "translatedContent": "![Arquitetura de Alto N√≠vel](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/./docs/high_level_architecture.drawio.svg)"
      },
      {
        "row": 46,
        "rowsha": "TiSukfY/+ter5MJ39DMtNdHlqRXwhZFkP3uTdAfvA0c=",
        "originContent": "![High Level Architecture](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/./docs/high_level_architecture.drawio.svg)",
        "translatedContent": ""
      },
      {
        "row": 47,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "## Instala√ß√£o"
      },
      {
        "row": 48,
        "rowsha": "oV0SUDvwD2VN8Gi9nlr2JZ2xcDrASmE2W5kc5SVX5eo=",
        "originContent": "## Installation",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 2,
    "Content": "```\npip install llama-github\n```",
    "ContentSha": "A7Ioj19mKQ2poo2/SNNEl/PUNM9x+13/7/ncgppdcgY=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```\npip install llama-github\n```",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      },
      {
        "row": 2,
        "rowsha": "HUzQ8Fuh/Wg8Hu8KR8bezJLbFVpPKMpf5Pa7xDY6vYM=",
        "originContent": "pip install llama-github",
        "translatedContent": "pip install llama-github"
      },
      {
        "row": 3,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      }
    ],
    "IsCodeBlock": true
  },
  {
    "Id": 3,
    "Content": "\n## Usage\n\nHere's a simple example of how to use llama-github:\n",
    "ContentSha": "oqzkRVGHtTMxKJniKYy+bJRBu/B3l8AYVVo5suNCmR4=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "\n## Uso\n\nAqui est√° um exemplo simples de como usar o llama-github:\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 2,
        "rowsha": "Y7/WGgVhslWiyqCi463Qkcp+Mn8voGpAfLsv80G4WNg=",
        "originContent": "## Usage",
        "translatedContent": "## Uso"
      },
      {
        "row": 3,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 4,
        "rowsha": "4zRpXijfFggW+Fd/VZ8qaLkuJwnjePE96Hy1hPxOIRE=",
        "originContent": "Here's a simple example of how to use llama-github:",
        "translatedContent": "Aqui est√° um exemplo simples de como usar o llama-github:"
      },
      {
        "row": 5,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 4,
    "Content": "```python\nfrom llama_github import GithubRAG\n\n# Initialize GithubRAG with your credentials\ngithub_rag = GithubRAG(\n    github_access_token=\"your_github_access_token\", \n    openai_api_key=\"your_openai_api_key\", # Optional in Simple Mode\n    jina_api_key=\"your_jina_api_key\" # Optional - unless you want high concurrency production deployment (s.jina.ai API will be used in llama-github)\n)\n\n# Retrieve context for a coding question (simple_mode is default set to False)\nquery = \"How to create a NumPy array in Python?\"\ncontext = github_rag.retrieve_context(\n    query, # In professional mode, one query will take nearly 1 min to generate final contexts. You could set log level to INFO to monitor the retrieval progress\n    # simple_mode = True\n)\n\nprint(context)\n```",
    "ContentSha": "HXBtstD3V5wfKLk68/A2T/KFqRB/TtW5s0tq89CzhFU=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```python\nfrom llama_github import GithubRAG\n\n# Initialize GithubRAG with your credentials\ngithub_rag = GithubRAG(\n    github_access_token=\"your_github_access_token\", \n    openai_api_key=\"your_openai_api_key\", # Optional in Simple Mode\n    jina_api_key=\"your_jina_api_key\" # Optional - unless you want high concurrency production deployment (s.jina.ai API will be used in llama-github)\n)\n\n# Retrieve context for a coding question (simple_mode is default set to False)\nquery = \"How to create a NumPy array in Python?\"\ncontext = github_rag.retrieve_context(\n    query, # In professional mode, one query will take nearly 1 min to generate final contexts. You could set log level to INFO to monitor the retrieval progress\n    # simple_mode = True\n)\n\nprint(context)\n```",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "uDnRsrcDV2kZVI2wi9EA58m+F4ILdr1bvjhqNlB+wSc=",
        "originContent": "```python",
        "translatedContent": "```python"
      },
      {
        "row": 2,
        "rowsha": "hA5UQDttQHKAwB+ESl7GqyiAa1AotkDZYMGTRuo/AoY=",
        "originContent": "from llama_github import GithubRAG",
        "translatedContent": "from llama_github import GithubRAG"
      },
      {
        "row": 3,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 4,
        "rowsha": "/Xio12pWjWQxdHtqP9gkrQo8FvXup5Rnp8m6s9rWQoA=",
        "originContent": "# Initialize GithubRAG with your credentials",
        "translatedContent": "# Initialize GithubRAG with your credentials"
      },
      {
        "row": 5,
        "rowsha": "Z/GdSwf7Zfjb56iNk/lrSDiBY4vaKvdGc5F3qO5IgSQ=",
        "originContent": "github_rag = GithubRAG(",
        "translatedContent": "github_rag = GithubRAG("
      },
      {
        "row": 6,
        "rowsha": "DCUT+XvqWQMhTvTxgZeTkNrf6sB1egP0ataQmEq//Do=",
        "originContent": "    github_access_token=\"your_github_access_token\", ",
        "translatedContent": "    github_access_token=\"your_github_access_token\", "
      },
      {
        "row": 7,
        "rowsha": "7hDiOA+9nEfENa9R7NEJW8WSnmj71txD0Ndrw3HjngM=",
        "originContent": "    openai_api_key=\"your_openai_api_key\", # Optional in Simple Mode",
        "translatedContent": "    openai_api_key=\"your_openai_api_key\", # Optional in Simple Mode"
      },
      {
        "row": 8,
        "rowsha": "3gER4AqcTSuWLMk5yIWdhwT240c1f6O0Qk92225ZuVU=",
        "originContent": "    jina_api_key=\"your_jina_api_key\" # Optional - unless you want high concurrency production deployment (s.jina.ai API will be used in llama-github)",
        "translatedContent": "    jina_api_key=\"your_jina_api_key\" # Optional - unless you want high concurrency production deployment (s.jina.ai API will be used in llama-github)"
      },
      {
        "row": 9,
        "rowsha": "ul7FHQekrA6VFghwRDHVmgKyGk6VGswQUFqNxAfFAe4=",
        "originContent": ")",
        "translatedContent": ")"
      },
      {
        "row": 10,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 11,
        "rowsha": "U1SUJQpzS8NM2yh7MFPYJl5dQ6gq/MR813WqTX952X0=",
        "originContent": "# Retrieve context for a coding question (simple_mode is default set to False)",
        "translatedContent": "# Retrieve context for a coding question (simple_mode is default set to False)"
      },
      {
        "row": 12,
        "rowsha": "ZXVeMLKgPJjdKhiZ9CK5U4oP9OsdwnWdpg8zNqEI+58=",
        "originContent": "query = \"How to create a NumPy array in Python?\"",
        "translatedContent": "query = \"How to create a NumPy array in Python?\""
      },
      {
        "row": 13,
        "rowsha": "tMIfL+j+gxN0VAT5YvCwzTJ6i5aIIY3fcw3LxJWoTrQ=",
        "originContent": "context = github_rag.retrieve_context(",
        "translatedContent": "context = github_rag.retrieve_context("
      },
      {
        "row": 14,
        "rowsha": "Q1vTmUoyeud2ZNyE6iVCY7OriQi61Wg6NLrSyM9pVLE=",
        "originContent": "    query, # In professional mode, one query will take nearly 1 min to generate final contexts. You could set log level to INFO to monitor the retrieval progress",
        "translatedContent": "    query, # In professional mode, one query will take nearly 1 min to generate final contexts. You could set log level to INFO to monitor the retrieval progress"
      },
      {
        "row": 15,
        "rowsha": "uvb8HENvYITO6V3XF0E9tyqODM0Be+CdeIuXZsYj/CA=",
        "originContent": "    # simple_mode = True",
        "translatedContent": "    # simple_mode = True"
      },
      {
        "row": 16,
        "rowsha": "ul7FHQekrA6VFghwRDHVmgKyGk6VGswQUFqNxAfFAe4=",
        "originContent": ")",
        "translatedContent": ")"
      },
      {
        "row": 17,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 18,
        "rowsha": "ZZEcMA2fivnNWsWr7Vg5FUhhpwQQJ/ThJU+S148t13E=",
        "originContent": "print(context)",
        "translatedContent": "print(context)"
      },
      {
        "row": 19,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      }
    ],
    "IsCodeBlock": true
  },
  {
    "Id": 5,
    "Content": "\nFor more advanced usage and examples, please refer to the [documentation](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/docs/usage.md).\n\n## Key Features\n\n- **üîç Intelligent GitHub Retrieval**: Harness the power of llama-github to retrieve highly relevant code snippets, issues, and repository information from GitHub based on user queries. Our advanced retrieval techniques ensure you find the most pertinent information quickly and efficiently.\n\n- **‚ö° Repository Pool Caching**: Llama-github has an innovative repository pool caching mechanism. By caching repositories (including READMEs, structures, code, and issues) across threads, llama-github significantly accelerates GitHub search retrieval efficiency and minimizes the consumption of GitHub API tokens. Deploy llama-github in multi-threaded production environments with confidence, knowing that it will perform optimally and save you valuable resources.\n\n- **üß† LLM-Powered Question Analysis**: Leverage state-of-the-art language models to analyze user questions and generate highly effective search strategies and criteria. Llama-github intelligently breaks down complex queries, ensuring that you retrieve the most relevant information from GitHub's vast repository network.\n\n- **üìö Comprehensive Context Generation**: Generate rich, contextually relevant answers by seamlessly combining information retrieved from GitHub with the reasoning capabilities of advanced language models. Llama-github excels at handling even the most complex and lengthy questions, providing comprehensive and insightful responses that include extensive context to support your development needs.\n\n- **üöÄ Asynchronous Processing Excellence**: Llama-github is built from the ground up to leverage the full potential of asynchronous programming. With meticulously implemented asynchronous mechanisms woven throughout the codebase, llama-github can handle multiple requests concurrently, significantly boosting overall performance. Experience the difference as llama-github efficiently manages high-volume workloads without compromising on speed or quality.\n\n- **üîß Flexible LLM Integration**: Easily integrate llama-github with various LLM providers, embedding models, and reranking models to tailor the library's capabilities to your specific requirements. Our extensible architecture allows you to customize and enhance llama-github's functionality, ensuring that it adapts seamlessly to your unique development environment.\n\n- **üîí Robust Authentication Options**: Llama-github supports both personal access tokens and GitHub App authentication, providing you with the flexibility to integrate it into different development setups. Whether you're an individual developer or working within an organizational context, llama-github has you covered with secure and reliable authentication mechanisms.\n\n- **üõ†Ô∏è Logging and Error Handling**: We understand the importance of smooth operations and easy troubleshooting. That's why llama-github comes equipped with comprehensive logging and error handling mechanisms. Gain deep insights into the library's behavior, quickly diagnose issues, and maintain a stable and reliable development workflow.\n\n## ü§ñ Try Our AI-Powered PR Review Assistant: LlamaPReview\n\nIf you find llama-github useful, you might also be interested in our AI-powered GitHub PR review assistant, LlamaPReview. It's designed to complement your development workflow and further enhance code quality.\n\n### Key Features of LlamaPReview:\n- üöÄ One-click installation, zero configuration required, fully auto-run\n- üíØ Currently free to use - no credit card or payment info needed\n- üß† AI-powered, automatic PR reviews with deep code understanding\n- üåê Supports multiple programming languages\n\n**LlamaPReview utilizes llama-github's advanced context retrieval and LLM-powered analysis** to provide intelligent, context-aware code reviews. It's like having a senior developer, armed with the full context of your repository, review every PR automatically!\n\nüëâ [Install LlamaPReview Now](https://github.com/marketplace/llamapreview/) (Free)\n\nBy using llama-github for context retrieval and LlamaPReview for code reviews, you can create a powerful, AI-enhanced development environment.\n\n## Vision and Roadmap\n\n### Vision\n\nOur vision is to become a pivotal module in the future of AI-driven development solutions, seamlessly integrating with GitHub to empower LLMs in automatically resolving complex coding tasks.\n\n![Vision Architecture](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/./docs/vision.drawio.svg)\n\n### Roadmap\n\nFor a detailed view of our project roadmap, please visit our [Project Roadmap](https://github.com/users/JetXu-LLM/projects/2).\n\n## Acknowledgments\n\nWe would like to express our gratitude to the following open-source projects for their support and contributions:\n\n- **[LangChain](https://github.com/langchain-ai/langchain)**: For providing the foundational framework that empowers the LLM prompting and processing capabilities in llama-github.\n- **[Jina.ai](https://github.com/jina-ai/reader)**: For offering s.jina.ai API and open source reranker and embedding models that enhance the accuracy and relevance of the generated contexts in llama-github.\n\nTheir contributions have been instrumental in the development of llama-github, and we highly recommend checking out their projects for more innovative solutions.\n\n## Contributing\n\nWe welcome contributions to llama-github! Please see our [contributing guidelines](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/CONTRIBUTING.md) for more information.\n\n## License\n\nThis project is licensed under the terms of the Apache 2.0 license. See the [LICENSE](LICENSE) file for more details.\n\n## Contact\n\nIf you have any questions, suggestions, or feedback, please feel free to reach out to us at [Jet Xu's email](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/mailto:Voldemort.xu@foxmail.com).\n\n---\n\nThank you for choosing llama-github! We hope this library enhances your AI development experience and helps you build powerful applications with ease.\n",
    "ContentSha": "9uwuSakxESmyLicwqpb9te9XJtaLzK41aW7HGRKfVFM=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "Para usos mais avan√ßados e exemplos, consulte a [documenta√ß√£o](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/docs/usage.md).\n\n## Principais Funcionalidades\n\n- **üîç Recupera√ß√£o Inteligente do GitHub**: Aproveite o poder do llama-github para recuperar trechos de c√≥digo altamente relevantes, issues e informa√ß√µes de reposit√≥rios do GitHub com base nas consultas do usu√°rio. Nossas t√©cnicas avan√ßadas de recupera√ß√£o garantem que voc√™ encontre as informa√ß√µes mais pertinentes de forma r√°pida e eficiente.\n\n- **‚ö° Cache de Pool de Reposit√≥rios**: O llama-github possui um mecanismo inovador de cache de pool de reposit√≥rios. Ao armazenar em cache reposit√≥rios (incluindo READMEs, estruturas, c√≥digo e issues) entre threads, o llama-github acelera significativamente a efici√™ncia de busca no GitHub e minimiza o consumo de tokens da API do GitHub. Implante o llama-github em ambientes de produ√ß√£o multithread com confian√ßa, sabendo que ele ter√° desempenho ideal e economizar√° recursos valiosos.\n\n- **üß† An√°lise de Perguntas com LLM**: Aproveite modelos de linguagem de √∫ltima gera√ß√£o para analisar perguntas dos usu√°rios e gerar estrat√©gias e crit√©rios de busca altamente eficazes. O llama-github decomp√µe inteligentemente consultas complexas, garantindo que voc√™ recupere as informa√ß√µes mais relevantes da vasta rede de reposit√≥rios do GitHub.\n\n- **üìö Gera√ß√£o de Contexto Abrangente**: Gere respostas ricas e contextualmente relevantes, combinando perfeitamente informa√ß√µes recuperadas do GitHub com a capacidade de racioc√≠nio de modelos de linguagem avan√ßados. O llama-github se destaca ao lidar com quest√µes complexas e extensas, fornecendo respostas completas e perspicazes que incluem amplo contexto para apoiar suas necessidades de desenvolvimento.\n\n- **üöÄ Excel√™ncia em Processamento Ass√≠ncrono**: O llama-github foi constru√≠do do zero para aproveitar todo o potencial da programa√ß√£o ass√≠ncrona. Com mecanismos ass√≠ncronos meticulosamente implementados em todo o c√≥digo, o llama-github pode lidar com v√°rias requisi√ß√µes simultaneamente, aumentando significativamente o desempenho geral. Experimente a diferen√ßa enquanto o llama-github gerencia eficientemente cargas de trabalho de alto volume sem comprometer a velocidade ou qualidade.\n\n- **üîß Integra√ß√£o Flex√≠vel com LLMs**: Integre facilmente o llama-github com diversos provedores de LLMs, modelos de embedding e modelos de reranking para adaptar as capacidades da biblioteca √†s suas necessidades espec√≠ficas. Nossa arquitetura extens√≠vel permite personalizar e aprimorar a funcionalidade do llama-github, garantindo que ele se adapte perfeitamente ao seu ambiente de desenvolvimento.\n\n- **üîí Op√ß√µes Robusta de Autentica√ß√£o**: O llama-github suporta tanto tokens de acesso pessoal quanto autentica√ß√£o via GitHub App, oferecendo flexibilidade para integr√°-lo em diferentes ambientes de desenvolvimento. Seja voc√™ um desenvolvedor individual ou atuando em um contexto organizacional, o llama-github oferece mecanismos de autentica√ß√£o seguros e confi√°veis.\n\n- **üõ†Ô∏è Log e Tratamento de Erros**: Entendemos a import√¢ncia de opera√ß√µes suaves e f√°cil solu√ß√£o de problemas. Por isso, o llama-github vem equipado com mecanismos abrangentes de log e tratamento de erros. Obtenha insights detalhados sobre o comportamento da biblioteca, diagnostique problemas rapidamente e mantenha um fluxo de trabalho de desenvolvimento est√°vel e confi√°vel.\n\n## ü§ñ Experimente Nosso Assistente de Revis√£o de PR com IA: LlamaPReview\n\nSe voc√™ acha o llama-github √∫til, talvez tamb√©m se interesse por nosso assistente de revis√£o de PR do GitHub com IA, o LlamaPReview. Ele foi projetado para complementar seu fluxo de desenvolvimento e aprimorar ainda mais a qualidade do c√≥digo.\n\n### Principais Funcionalidades do LlamaPReview:\n- üöÄ Instala√ß√£o com um clique, zero configura√ß√£o, totalmente autom√°tico\n- üíØ Atualmente gratuito para uso - n√£o requer cart√£o de cr√©dito ou informa√ß√µes de pagamento\n- üß† Revis√µes autom√°ticas de PR com IA e compreens√£o profunda de c√≥digo\n- üåê Suporta m√∫ltiplas linguagens de programa√ß√£o\n\n**O LlamaPReview utiliza a recupera√ß√£o de contexto avan√ßada do llama-github e an√°lise com LLM** para fornecer revis√µes de c√≥digo inteligentes e com contexto. √â como ter um desenvolvedor s√™nior, munido de todo o contexto do seu reposit√≥rio, revisando cada PR automaticamente!\n\nüëâ [Instale o LlamaPReview Agora](https://github.com/marketplace/llamapreview/) (Gr√°tis)\n\nAo usar o llama-github para recupera√ß√£o de contexto e o LlamaPReview para revis√µes de c√≥digo, voc√™ pode criar um ambiente de desenvolvimento poderoso e aprimorado por IA.\n\n## Vis√£o e Roteiro\n\n### Vis√£o\n\nNossa vis√£o √© nos tornarmos um m√≥dulo fundamental no futuro das solu√ß√µes de desenvolvimento orientadas por IA, integrando-se perfeitamente ao GitHub para capacitar LLMs a resolver automaticamente tarefas complexas de codifica√ß√£o.\n\n![Arquitetura da Vis√£o](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/./docs/vision.drawio.svg)\n\n### Roteiro\n\nPara uma vis√£o detalhada do nosso roteiro do projeto, visite nosso [Roteiro do Projeto](https://github.com/users/JetXu-LLM/projects/2).\n\n## Agradecimentos\n\nGostar√≠amos de expressar nossa gratid√£o aos seguintes projetos open-source por seu apoio e contribui√ß√µes:\n\n- **[LangChain](https://github.com/langchain-ai/langchain)**: Por fornecer a estrutura fundamental que potencializa as capacidades de prompting e processamento de LLM no llama-github.\n- **[Jina.ai](https://github.com/jina-ai/reader)**: Por oferecer a API s.jina.ai e modelos open source de reranker e embedding que aprimoram a precis√£o e relev√¢ncia dos contextos gerados no llama-github.\n\nSuas contribui√ß√µes foram fundamentais para o desenvolvimento do llama-github, e recomendamos fortemente que voc√™ confira seus projetos para mais solu√ß√µes inovadoras.\n\n## Contribuindo\n\nContribui√ß√µes para o llama-github s√£o bem-vindas! Consulte nossas [diretrizes de contribui√ß√£o](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/CONTRIBUTING.md) para mais informa√ß√µes.\n\n## Licen√ßa\n\nEste projeto est√° licenciado sob os termos da licen√ßa Apache 2.0. Veja o arquivo [LICENSE](LICENSE) para mais detalhes.\n\n## Contato\n\nSe voc√™ tiver d√∫vidas, sugest√µes ou coment√°rios, fique √† vontade para entrar em contato conosco pelo [email do Jet Xu](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/mailto:Voldemort.xu@foxmail.com).\n\n---\n\nObrigado por escolher o llama-github! Esperamos que esta biblioteca aprimore sua experi√™ncia de desenvolvimento com IA e ajude voc√™ a construir aplica√ß√µes poderosas com facilidade.\n\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "Para usos mais avan√ßados e exemplos, consulte a [documenta√ß√£o](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/docs/usage.md)."
      },
      {
        "row": 2,
        "rowsha": "zrMByz3uboJewll5VwM0OlM3JCc+dvchgXugvMGdZyA=",
        "originContent": "For more advanced usage and examples, please refer to the [documentation](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/docs/usage.md).",
        "translatedContent": ""
      },
      {
        "row": 3,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "## Principais Funcionalidades"
      },
      {
        "row": 4,
        "rowsha": "khTPM/+Q4D8FMdf3qgrMDcjDejggkuMl1+JmWZMODFI=",
        "originContent": "## Key Features",
        "translatedContent": ""
      },
      {
        "row": 5,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "- **üîç Recupera√ß√£o Inteligente do GitHub**: Aproveite o poder do llama-github para recuperar trechos de c√≥digo altamente relevantes, issues e informa√ß√µes de reposit√≥rios do GitHub com base nas consultas do usu√°rio. Nossas t√©cnicas avan√ßadas de recupera√ß√£o garantem que voc√™ encontre as informa√ß√µes mais pertinentes de forma r√°pida e eficiente."
      },
      {
        "row": 6,
        "rowsha": "DfE9NcmRSF011JyFgs3cD/a2VQqPhp+XXqaTnhAtBwc=",
        "originContent": "- **üîç Intelligent GitHub Retrieval**: Harness the power of llama-github to retrieve highly relevant code snippets, issues, and repository information from GitHub based on user queries. Our advanced retrieval techniques ensure you find the most pertinent information quickly and efficiently.",
        "translatedContent": ""
      },
      {
        "row": 7,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "- **‚ö° Cache de Pool de Reposit√≥rios**: O llama-github possui um mecanismo inovador de cache de pool de reposit√≥rios. Ao armazenar em cache reposit√≥rios (incluindo READMEs, estruturas, c√≥digo e issues) entre threads, o llama-github acelera significativamente a efici√™ncia de busca no GitHub e minimiza o consumo de tokens da API do GitHub. Implante o llama-github em ambientes de produ√ß√£o multithread com confian√ßa, sabendo que ele ter√° desempenho ideal e economizar√° recursos valiosos."
      },
      {
        "row": 8,
        "rowsha": "OtNyTLgFLD0QDlCwfKWcttMbckHUBj2YJNKV9r+Uc54=",
        "originContent": "- **‚ö° Repository Pool Caching**: Llama-github has an innovative repository pool caching mechanism. By caching repositories (including READMEs, structures, code, and issues) across threads, llama-github significantly accelerates GitHub search retrieval efficiency and minimizes the consumption of GitHub API tokens. Deploy llama-github in multi-threaded production environments with confidence, knowing that it will perform optimally and save you valuable resources.",
        "translatedContent": ""
      },
      {
        "row": 9,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "- **üß† An√°lise de Perguntas com LLM**: Aproveite modelos de linguagem de √∫ltima gera√ß√£o para analisar perguntas dos usu√°rios e gerar estrat√©gias e crit√©rios de busca altamente eficazes. O llama-github decomp√µe inteligentemente consultas complexas, garantindo que voc√™ recupere as informa√ß√µes mais relevantes da vasta rede de reposit√≥rios do GitHub."
      },
      {
        "row": 10,
        "rowsha": "JeXb8RZZhv2Wmw97j628XoyPreY+fMdIPsxoUQiEvzw=",
        "originContent": "- **üß† LLM-Powered Question Analysis**: Leverage state-of-the-art language models to analyze user questions and generate highly effective search strategies and criteria. Llama-github intelligently breaks down complex queries, ensuring that you retrieve the most relevant information from GitHub's vast repository network.",
        "translatedContent": ""
      },
      {
        "row": 11,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "- **üìö Gera√ß√£o de Contexto Abrangente**: Gere respostas ricas e contextualmente relevantes, combinando perfeitamente informa√ß√µes recuperadas do GitHub com a capacidade de racioc√≠nio de modelos de linguagem avan√ßados. O llama-github se destaca ao lidar com quest√µes complexas e extensas, fornecendo respostas completas e perspicazes que incluem amplo contexto para apoiar suas necessidades de desenvolvimento."
      },
      {
        "row": 12,
        "rowsha": "yA7pWfx0KVCXQ2Eo49pVkbLR+DABI/mKnMw/tj/sCL0=",
        "originContent": "- **üìö Comprehensive Context Generation**: Generate rich, contextually relevant answers by seamlessly combining information retrieved from GitHub with the reasoning capabilities of advanced language models. Llama-github excels at handling even the most complex and lengthy questions, providing comprehensive and insightful responses that include extensive context to support your development needs.",
        "translatedContent": ""
      },
      {
        "row": 13,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "- **üöÄ Excel√™ncia em Processamento Ass√≠ncrono**: O llama-github foi constru√≠do do zero para aproveitar todo o potencial da programa√ß√£o ass√≠ncrona. Com mecanismos ass√≠ncronos meticulosamente implementados em todo o c√≥digo, o llama-github pode lidar com v√°rias requisi√ß√µes simultaneamente, aumentando significativamente o desempenho geral. Experimente a diferen√ßa enquanto o llama-github gerencia eficientemente cargas de trabalho de alto volume sem comprometer a velocidade ou qualidade."
      },
      {
        "row": 14,
        "rowsha": "qku0KFnzN0JDJsFtvSnr1U47mAfoIMLCUgoTAF0FV2Q=",
        "originContent": "- **üöÄ Asynchronous Processing Excellence**: Llama-github is built from the ground up to leverage the full potential of asynchronous programming. With meticulously implemented asynchronous mechanisms woven throughout the codebase, llama-github can handle multiple requests concurrently, significantly boosting overall performance. Experience the difference as llama-github efficiently manages high-volume workloads without compromising on speed or quality.",
        "translatedContent": ""
      },
      {
        "row": 15,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "- **üîß Integra√ß√£o Flex√≠vel com LLMs**: Integre facilmente o llama-github com diversos provedores de LLMs, modelos de embedding e modelos de reranking para adaptar as capacidades da biblioteca √†s suas necessidades espec√≠ficas. Nossa arquitetura extens√≠vel permite personalizar e aprimorar a funcionalidade do llama-github, garantindo que ele se adapte perfeitamente ao seu ambiente de desenvolvimento."
      },
      {
        "row": 16,
        "rowsha": "0g6jkIpIeIIz2Gt8w6I2VAjPUz51+RDJs7fxVchaN/k=",
        "originContent": "- **üîß Flexible LLM Integration**: Easily integrate llama-github with various LLM providers, embedding models, and reranking models to tailor the library's capabilities to your specific requirements. Our extensible architecture allows you to customize and enhance llama-github's functionality, ensuring that it adapts seamlessly to your unique development environment.",
        "translatedContent": ""
      },
      {
        "row": 17,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "- **üîí Op√ß√µes Robusta de Autentica√ß√£o**: O llama-github suporta tanto tokens de acesso pessoal quanto autentica√ß√£o via GitHub App, oferecendo flexibilidade para integr√°-lo em diferentes ambientes de desenvolvimento. Seja voc√™ um desenvolvedor individual ou atuando em um contexto organizacional, o llama-github oferece mecanismos de autentica√ß√£o seguros e confi√°veis."
      },
      {
        "row": 18,
        "rowsha": "WH0+zgaxAP/W/KtIygVDuxydKTKp6imCYyXpqvXpjaM=",
        "originContent": "- **üîí Robust Authentication Options**: Llama-github supports both personal access tokens and GitHub App authentication, providing you with the flexibility to integrate it into different development setups. Whether you're an individual developer or working within an organizational context, llama-github has you covered with secure and reliable authentication mechanisms.",
        "translatedContent": ""
      },
      {
        "row": 19,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "- **üõ†Ô∏è Log e Tratamento de Erros**: Entendemos a import√¢ncia de opera√ß√µes suaves e f√°cil solu√ß√£o de problemas. Por isso, o llama-github vem equipado com mecanismos abrangentes de log e tratamento de erros. Obtenha insights detalhados sobre o comportamento da biblioteca, diagnostique problemas rapidamente e mantenha um fluxo de trabalho de desenvolvimento est√°vel e confi√°vel."
      },
      {
        "row": 20,
        "rowsha": "IYhTxjMvy72M7T9kEBfrXUNMz08qwsXzETVoE3WSNyQ=",
        "originContent": "- **üõ†Ô∏è Logging and Error Handling**: We understand the importance of smooth operations and easy troubleshooting. That's why llama-github comes equipped with comprehensive logging and error handling mechanisms. Gain deep insights into the library's behavior, quickly diagnose issues, and maintain a stable and reliable development workflow.",
        "translatedContent": ""
      },
      {
        "row": 21,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "## ü§ñ Experimente Nosso Assistente de Revis√£o de PR com IA: LlamaPReview"
      },
      {
        "row": 22,
        "rowsha": "QDeqAvaQEIQHPYjwq2KF5Bw3a76EiPq7ebbsGNKcRI8=",
        "originContent": "## ü§ñ Try Our AI-Powered PR Review Assistant: LlamaPReview",
        "translatedContent": ""
      },
      {
        "row": 23,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "Se voc√™ acha o llama-github √∫til, talvez tamb√©m se interesse por nosso assistente de revis√£o de PR do GitHub com IA, o LlamaPReview. Ele foi projetado para complementar seu fluxo de desenvolvimento e aprimorar ainda mais a qualidade do c√≥digo."
      },
      {
        "row": 24,
        "rowsha": "laWUe+J402emMP2V1JeMqFpYefA8HTKWoI+lq7NfoyE=",
        "originContent": "If you find llama-github useful, you might also be interested in our AI-powered GitHub PR review assistant, LlamaPReview. It's designed to complement your development workflow and further enhance code quality.",
        "translatedContent": ""
      },
      {
        "row": 25,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "### Principais Funcionalidades do LlamaPReview:"
      },
      {
        "row": 26,
        "rowsha": "J3M87xxuLQISS/m0fiv7phjnw7mYaznst6rel6n7MyY=",
        "originContent": "### Key Features of LlamaPReview:",
        "translatedContent": "- üöÄ Instala√ß√£o com um clique, zero configura√ß√£o, totalmente autom√°tico"
      },
      {
        "row": 27,
        "rowsha": "dGBd2SxNdlW1UATPSu01Iq95yCVz8fXbl7xxHqDYI7E=",
        "originContent": "- üöÄ One-click installation, zero configuration required, fully auto-run",
        "translatedContent": "- üíØ Atualmente gratuito para uso - n√£o requer cart√£o de cr√©dito ou informa√ß√µes de pagamento"
      },
      {
        "row": 28,
        "rowsha": "EP9hYUs4aYVAzXcYQyCGf3bjwo64OjAsqQHIN75oW60=",
        "originContent": "- üíØ Currently free to use - no credit card or payment info needed",
        "translatedContent": "- üß† Revis√µes autom√°ticas de PR com IA e compreens√£o profunda de c√≥digo"
      },
      {
        "row": 29,
        "rowsha": "jjWF/iUqSzPriHJ5iiFIq0Q6Pzx+gzPlnLu0Z4wmsSg=",
        "originContent": "- üß† AI-powered, automatic PR reviews with deep code understanding",
        "translatedContent": "- üåê Suporta m√∫ltiplas linguagens de programa√ß√£o"
      },
      {
        "row": 30,
        "rowsha": "Dsl+HsDM5NGI480TDo6eaFqgDcaofr3TDhLbUghSXhU=",
        "originContent": "- üåê Supports multiple programming languages",
        "translatedContent": ""
      },
      {
        "row": 31,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "**O LlamaPReview utiliza a recupera√ß√£o de contexto avan√ßada do llama-github e an√°lise com LLM** para fornecer revis√µes de c√≥digo inteligentes e com contexto. √â como ter um desenvolvedor s√™nior, munido de todo o contexto do seu reposit√≥rio, revisando cada PR automaticamente!"
      },
      {
        "row": 32,
        "rowsha": "GrzJg4j2iz94pupBQwJnFffhmsJ5IO9OkhqYvj0QEmo=",
        "originContent": "**LlamaPReview utilizes llama-github's advanced context retrieval and LLM-powered analysis** to provide intelligent, context-aware code reviews. It's like having a senior developer, armed with the full context of your repository, review every PR automatically!",
        "translatedContent": ""
      },
      {
        "row": 33,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "üëâ [Instale o LlamaPReview Agora](https://github.com/marketplace/llamapreview/) (Gr√°tis)"
      },
      {
        "row": 34,
        "rowsha": "4qGUTknerL/UTVikcUjFHvKzZlWho9opuf58fSIypyk=",
        "originContent": "üëâ [Install LlamaPReview Now](https://github.com/marketplace/llamapreview/) (Free)",
        "translatedContent": ""
      },
      {
        "row": 35,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "Ao usar o llama-github para recupera√ß√£o de contexto e o LlamaPReview para revis√µes de c√≥digo, voc√™ pode criar um ambiente de desenvolvimento poderoso e aprimorado por IA."
      },
      {
        "row": 36,
        "rowsha": "luTTMbXm2ikxAkHhFfh2iG9uPEwMYBRd2lolUoOY+3o=",
        "originContent": "By using llama-github for context retrieval and LlamaPReview for code reviews, you can create a powerful, AI-enhanced development environment.",
        "translatedContent": ""
      },
      {
        "row": 37,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "## Vis√£o e Roteiro"
      },
      {
        "row": 38,
        "rowsha": "W2b655gztUgECPmTnBIkK/WbBo7d68AbNAjMtkHS5xY=",
        "originContent": "## Vision and Roadmap",
        "translatedContent": ""
      },
      {
        "row": 39,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "### Vis√£o"
      },
      {
        "row": 40,
        "rowsha": "Ewakmoa/Yb8fcDlChA12w7kAXVMFh8OrCLwVCTwIl84=",
        "originContent": "### Vision",
        "translatedContent": ""
      },
      {
        "row": 41,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "Nossa vis√£o √© nos tornarmos um m√≥dulo fundamental no futuro das solu√ß√µes de desenvolvimento orientadas por IA, integrando-se perfeitamente ao GitHub para capacitar LLMs a resolver automaticamente tarefas complexas de codifica√ß√£o."
      },
      {
        "row": 42,
        "rowsha": "0e6GYQC4W2Y8Ky5Q9UNeMwDc+ebEjDIUb9h4gSLQJaI=",
        "originContent": "Our vision is to become a pivotal module in the future of AI-driven development solutions, seamlessly integrating with GitHub to empower LLMs in automatically resolving complex coding tasks.",
        "translatedContent": ""
      },
      {
        "row": 43,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "![Arquitetura da Vis√£o](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/./docs/vision.drawio.svg)"
      },
      {
        "row": 44,
        "rowsha": "e3eGMrQR9LxN0lPlezIImRzi4tUu6n/GFfZsq5SBP4I=",
        "originContent": "![Vision Architecture](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/./docs/vision.drawio.svg)",
        "translatedContent": ""
      },
      {
        "row": 45,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "### Roteiro"
      },
      {
        "row": 46,
        "rowsha": "Q0D6oxy93TTXOZDvIiuco/ghaytG064tWvZdnLoKnOw=",
        "originContent": "### Roadmap",
        "translatedContent": ""
      },
      {
        "row": 47,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "Para uma vis√£o detalhada do nosso roteiro do projeto, visite nosso [Roteiro do Projeto](https://github.com/users/JetXu-LLM/projects/2)."
      },
      {
        "row": 48,
        "rowsha": "UHmL4/lEZk2jitjRxUVuHtD8JilL4OTzFLbU8R72Ymc=",
        "originContent": "For a detailed view of our project roadmap, please visit our [Project Roadmap](https://github.com/users/JetXu-LLM/projects/2).",
        "translatedContent": ""
      },
      {
        "row": 49,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "## Agradecimentos"
      },
      {
        "row": 50,
        "rowsha": "N66ywbuGccMYNTyswaMSnFOlWqX+iaYP/myGJqr1tHo=",
        "originContent": "## Acknowledgments",
        "translatedContent": ""
      },
      {
        "row": 51,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "Gostar√≠amos de expressar nossa gratid√£o aos seguintes projetos open-source por seu apoio e contribui√ß√µes:"
      },
      {
        "row": 52,
        "rowsha": "WodCIp8BqxoCo7bxE7dxagf/Dvpvw7nWeECf0qG6FGI=",
        "originContent": "We would like to express our gratitude to the following open-source projects for their support and contributions:",
        "translatedContent": ""
      },
      {
        "row": 53,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "- **[LangChain](https://github.com/langchain-ai/langchain)**: Por fornecer a estrutura fundamental que potencializa as capacidades de prompting e processamento de LLM no llama-github."
      },
      {
        "row": 54,
        "rowsha": "HBIRZKkbsYOXsJY2Xepu1VxTAAdh869qSnsGbJ0cIg0=",
        "originContent": "- **[LangChain](https://github.com/langchain-ai/langchain)**: For providing the foundational framework that empowers the LLM prompting and processing capabilities in llama-github.",
        "translatedContent": "- **[Jina.ai](https://github.com/jina-ai/reader)**: Por oferecer a API s.jina.ai e modelos open source de reranker e embedding que aprimoram a precis√£o e relev√¢ncia dos contextos gerados no llama-github."
      },
      {
        "row": 55,
        "rowsha": "l7sjWwbh0OUJwk4+yJE2ZbVGypyaPrzI1YYMP7Uw9X0=",
        "originContent": "- **[Jina.ai](https://github.com/jina-ai/reader)**: For offering s.jina.ai API and open source reranker and embedding models that enhance the accuracy and relevance of the generated contexts in llama-github.",
        "translatedContent": ""
      },
      {
        "row": 56,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "Suas contribui√ß√µes foram fundamentais para o desenvolvimento do llama-github, e recomendamos fortemente que voc√™ confira seus projetos para mais solu√ß√µes inovadoras."
      },
      {
        "row": 57,
        "rowsha": "hrChp1vDZFs3UZia39niD4Kx9hT0wKUMxSSiiyYyi7A=",
        "originContent": "Their contributions have been instrumental in the development of llama-github, and we highly recommend checking out their projects for more innovative solutions.",
        "translatedContent": ""
      },
      {
        "row": 58,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "## Contribuindo"
      },
      {
        "row": 59,
        "rowsha": "R5ZPLZ4vkE9tjX5qe8QB7AkTfWZsuNTGFLFKMp2KUzM=",
        "originContent": "## Contributing",
        "translatedContent": ""
      },
      {
        "row": 60,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "Contribui√ß√µes para o llama-github s√£o bem-vindas! Consulte nossas [diretrizes de contribui√ß√£o](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/CONTRIBUTING.md) para mais informa√ß√µes."
      },
      {
        "row": 61,
        "rowsha": "JUWgAoIn9VhOEzmNL5dlAlHwcmo7N2Rm2GNx0g5Rijs=",
        "originContent": "We welcome contributions to llama-github! Please see our [contributing guidelines](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/CONTRIBUTING.md) for more information.",
        "translatedContent": ""
      },
      {
        "row": 62,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "## Licen√ßa"
      },
      {
        "row": 63,
        "rowsha": "bFSaVtsB4CHySNjaeCiaMZfT24b+DTbTM4HQ38cR6Lw=",
        "originContent": "## License",
        "translatedContent": ""
      },
      {
        "row": 64,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "Este projeto est√° licenciado sob os termos da licen√ßa Apache 2.0. Veja o arquivo [LICENSE](LICENSE) para mais detalhes."
      },
      {
        "row": 65,
        "rowsha": "hUzQdbczna0Cd3FyH+bhS5SWBDzmVQyA+nCi/UZO6VI=",
        "originContent": "This project is licensed under the terms of the Apache 2.0 license. See the [LICENSE](LICENSE) file for more details.",
        "translatedContent": ""
      },
      {
        "row": 66,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "## Contato"
      },
      {
        "row": 67,
        "rowsha": "ZX9nbduzXgvmAaK8yTd+tNgwR7cV79HXV/+xbvL8suw=",
        "originContent": "## Contact",
        "translatedContent": ""
      },
      {
        "row": 68,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "Se voc√™ tiver d√∫vidas, sugest√µes ou coment√°rios, fique √† vontade para entrar em contato conosco pelo [email do Jet Xu](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/mailto:Voldemort.xu@foxmail.com)."
      },
      {
        "row": 69,
        "rowsha": "sZud9u8DDdJRsIyc+T0tdusx1FWC0pdv0Yn2hhndP9o=",
        "originContent": "If you have any questions, suggestions, or feedback, please feel free to reach out to us at [Jet Xu's email](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/mailto:Voldemort.xu@foxmail.com).",
        "translatedContent": ""
      },
      {
        "row": 70,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "---"
      },
      {
        "row": 71,
        "rowsha": "yz+R1U7uMOU+NbK5mQX3Dxae1Un9eJCdPawt78ntjTs=",
        "originContent": "---",
        "translatedContent": ""
      },
      {
        "row": 72,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "Obrigado por escolher o llama-github! Esperamos que esta biblioteca aprimore sua experi√™ncia de desenvolvimento com IA e ajude voc√™ a construir aplica√ß√µes poderosas com facilidade."
      },
      {
        "row": 73,
        "rowsha": "98t5imS5RZt8kUxGAXqZcPmlZMcru27Gl/g31hb3g/c=",
        "originContent": "Thank you for choosing llama-github! We hope this library enhances your AI development experience and helps you build powerful applications with ease.",
        "translatedContent": ""
      },
      {
        "row": 74,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  }
]