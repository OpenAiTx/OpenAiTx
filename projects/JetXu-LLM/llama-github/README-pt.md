<div align="right">
  <details>
    <summary >üåê Idioma</summary>
    <div>
      <div align="center">
        <a href="https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=en">English</a>
        | <a href="https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=zh-CN">ÁÆÄ‰Ωì‰∏≠Êñá</a>
        | <a href="https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=zh-TW">ÁπÅÈ´î‰∏≠Êñá</a>
        | <a href="https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=ja">Êó•Êú¨Ë™û</a>
        | <a href="https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=ko">ÌïúÍµ≠Ïñ¥</a>
        | <a href="https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=hi">‡§π‡§ø‡§®‡•ç‡§¶‡•Ä</a>
        | <a href="https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=th">‡πÑ‡∏ó‡∏¢</a>
        | <a href="https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=fr">Fran√ßais</a>
        | <a href="https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=de">Deutsch</a>
        | <a href="https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=es">Espa√±ol</a>
        | <a href="https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=it">Italiano</a>
        | <a href="https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=ru">–†—É—Å—Å–∫–∏–π</a>
        | <a href="https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=pt">Portugu√™s</a>
        | <a href="https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=nl">Nederlands</a>
        | <a href="https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=pl">Polski</a>
        | <a href="https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=ar">ÿßŸÑÿπÿ±ÿ®Ÿäÿ©</a>
        | <a href="https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=fa">ŸÅÿßÿ±ÿ≥€å</a>
        | <a href="https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=tr">T√ºrk√ße</a>
        | <a href="https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=vi">Ti·∫øng Vi·ªát</a>
        | <a href="https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=id">Bahasa Indonesia</a>
        | <a href="https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=as">‡¶Ö‡¶∏‡¶Æ‡ßÄ‡¶Ø‡¶º‡¶æ</
      </div>
    </div>
  </details>
</div>

# llama-github

[Documento Detalhado] https://deepwiki.com/JetXu-LLM/llama-github

[![Vers√£o PyPI](https://badge.fury.io/py/llama-github.svg)](https://badge.fury.io/py/llama-github)
[![Downloads](https://static.pepy.tech/badge/Llama-github)](https://pepy.tech/project/Llama-github)
[![Licen√ßa](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)

Llama-github √© uma ferramenta poderosa que ajuda voc√™ a recuperar (baseado em Agentic RAG) os trechos de c√≥digo, issues e informa√ß√µes de reposit√≥rio mais relevantes do GitHub com base em suas consultas, transformando-os em um contexto de conhecimento valioso. Ele potencializa Chatbots LLM, Agentes de IA e Agentes Auto-dev para resolver tarefas complexas de codifica√ß√£o. Seja voc√™ um desenvolvedor em busca de solu√ß√µes r√°pidas ou um engenheiro implementando Agentes Avan√ßados de Auto Dev IA, o llama-github torna tudo mais f√°cil e eficiente.

Se voc√™ gosta deste projeto ou acredita que ele tem potencial, por favor, deixe uma ‚≠êÔ∏è. Seu apoio √© nossa maior motiva√ß√£o!

## Arquitetura
![Arquitetura de Alto N√≠vel](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/./docs/high_level_architecture.drawio.svg)

## Instala√ß√£o

```
pip install llama-github
```

## Uso

Aqui est√° um exemplo simples de como usar o llama-github:

```python
from llama_github import GithubRAG

# Initialize GithubRAG with your credentials
github_rag = GithubRAG(
    github_access_token="your_github_access_token", 
    openai_api_key="your_openai_api_key", # Optional in Simple Mode
    jina_api_key="your_jina_api_key" # Optional - unless you want high concurrency production deployment (s.jina.ai API will be used in llama-github)
)

# Retrieve context for a coding question (simple_mode is default set to False)
query = "How to create a NumPy array in Python?"
context = github_rag.retrieve_context(
    query, # In professional mode, one query will take nearly 1 min to generate final contexts. You could set log level to INFO to monitor the retrieval progress
    # simple_mode = True
)

print(context)
```
Para usos mais avan√ßados e exemplos, consulte a [documenta√ß√£o](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/docs/usage.md).

## Principais Funcionalidades

- **üîç Recupera√ß√£o Inteligente do GitHub**: Aproveite o poder do llama-github para recuperar trechos de c√≥digo altamente relevantes, issues e informa√ß√µes de reposit√≥rios do GitHub com base nas consultas do usu√°rio. Nossas t√©cnicas avan√ßadas de recupera√ß√£o garantem que voc√™ encontre as informa√ß√µes mais pertinentes de forma r√°pida e eficiente.

- **‚ö° Cache de Pool de Reposit√≥rios**: O llama-github possui um mecanismo inovador de cache de pool de reposit√≥rios. Ao armazenar em cache reposit√≥rios (incluindo READMEs, estruturas, c√≥digo e issues) entre threads, o llama-github acelera significativamente a efici√™ncia de busca no GitHub e minimiza o consumo de tokens da API do GitHub. Implante o llama-github em ambientes de produ√ß√£o multithread com confian√ßa, sabendo que ele ter√° desempenho ideal e economizar√° recursos valiosos.

- **üß† An√°lise de Perguntas com LLM**: Aproveite modelos de linguagem de √∫ltima gera√ß√£o para analisar perguntas dos usu√°rios e gerar estrat√©gias e crit√©rios de busca altamente eficazes. O llama-github decomp√µe inteligentemente consultas complexas, garantindo que voc√™ recupere as informa√ß√µes mais relevantes da vasta rede de reposit√≥rios do GitHub.

- **üìö Gera√ß√£o de Contexto Abrangente**: Gere respostas ricas e contextualmente relevantes, combinando perfeitamente informa√ß√µes recuperadas do GitHub com a capacidade de racioc√≠nio de modelos de linguagem avan√ßados. O llama-github se destaca ao lidar com quest√µes complexas e extensas, fornecendo respostas completas e perspicazes que incluem amplo contexto para apoiar suas necessidades de desenvolvimento.

- **üöÄ Excel√™ncia em Processamento Ass√≠ncrono**: O llama-github foi constru√≠do do zero para aproveitar todo o potencial da programa√ß√£o ass√≠ncrona. Com mecanismos ass√≠ncronos meticulosamente implementados em todo o c√≥digo, o llama-github pode lidar com v√°rias requisi√ß√µes simultaneamente, aumentando significativamente o desempenho geral. Experimente a diferen√ßa enquanto o llama-github gerencia eficientemente cargas de trabalho de alto volume sem comprometer a velocidade ou qualidade.

- **üîß Integra√ß√£o Flex√≠vel com LLMs**: Integre facilmente o llama-github com diversos provedores de LLMs, modelos de embedding e modelos de reranking para adaptar as capacidades da biblioteca √†s suas necessidades espec√≠ficas. Nossa arquitetura extens√≠vel permite personalizar e aprimorar a funcionalidade do llama-github, garantindo que ele se adapte perfeitamente ao seu ambiente de desenvolvimento.

- **üîí Op√ß√µes Robusta de Autentica√ß√£o**: O llama-github suporta tanto tokens de acesso pessoal quanto autentica√ß√£o via GitHub App, oferecendo flexibilidade para integr√°-lo em diferentes ambientes de desenvolvimento. Seja voc√™ um desenvolvedor individual ou atuando em um contexto organizacional, o llama-github oferece mecanismos de autentica√ß√£o seguros e confi√°veis.

- **üõ†Ô∏è Log e Tratamento de Erros**: Entendemos a import√¢ncia de opera√ß√µes suaves e f√°cil solu√ß√£o de problemas. Por isso, o llama-github vem equipado com mecanismos abrangentes de log e tratamento de erros. Obtenha insights detalhados sobre o comportamento da biblioteca, diagnostique problemas rapidamente e mantenha um fluxo de trabalho de desenvolvimento est√°vel e confi√°vel.

## ü§ñ Experimente Nosso Assistente de Revis√£o de PR com IA: LlamaPReview

Se voc√™ acha o llama-github √∫til, talvez tamb√©m se interesse por nosso assistente de revis√£o de PR do GitHub com IA, o LlamaPReview. Ele foi projetado para complementar seu fluxo de desenvolvimento e aprimorar ainda mais a qualidade do c√≥digo.

### Principais Funcionalidades do LlamaPReview:
- üöÄ Instala√ß√£o com um clique, zero configura√ß√£o, totalmente autom√°tico
- üíØ Atualmente gratuito para uso - n√£o requer cart√£o de cr√©dito ou informa√ß√µes de pagamento
- üß† Revis√µes autom√°ticas de PR com IA e compreens√£o profunda de c√≥digo
- üåê Suporta m√∫ltiplas linguagens de programa√ß√£o

**O LlamaPReview utiliza a recupera√ß√£o de contexto avan√ßada do llama-github e an√°lise com LLM** para fornecer revis√µes de c√≥digo inteligentes e com contexto. √â como ter um desenvolvedor s√™nior, munido de todo o contexto do seu reposit√≥rio, revisando cada PR automaticamente!

üëâ [Instale o LlamaPReview Agora](https://github.com/marketplace/llamapreview/) (Gr√°tis)

Ao usar o llama-github para recupera√ß√£o de contexto e o LlamaPReview para revis√µes de c√≥digo, voc√™ pode criar um ambiente de desenvolvimento poderoso e aprimorado por IA.

## Vis√£o e Roteiro

### Vis√£o

Nossa vis√£o √© nos tornarmos um m√≥dulo fundamental no futuro das solu√ß√µes de desenvolvimento orientadas por IA, integrando-se perfeitamente ao GitHub para capacitar LLMs a resolver automaticamente tarefas complexas de codifica√ß√£o.

![Arquitetura da Vis√£o](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/./docs/vision.drawio.svg)

### Roteiro

Para uma vis√£o detalhada do nosso roteiro do projeto, visite nosso [Roteiro do Projeto](https://github.com/users/JetXu-LLM/projects/2).

## Agradecimentos

Gostar√≠amos de expressar nossa gratid√£o aos seguintes projetos open-source por seu apoio e contribui√ß√µes:

- **[LangChain](https://github.com/langchain-ai/langchain)**: Por fornecer a estrutura fundamental que potencializa as capacidades de prompting e processamento de LLM no llama-github.
- **[Jina.ai](https://github.com/jina-ai/reader)**: Por oferecer a API s.jina.ai e modelos open source de reranker e embedding que aprimoram a precis√£o e relev√¢ncia dos contextos gerados no llama-github.

Suas contribui√ß√µes foram fundamentais para o desenvolvimento do llama-github, e recomendamos fortemente que voc√™ confira seus projetos para mais solu√ß√µes inovadoras.

## Contribuindo

Contribui√ß√µes para o llama-github s√£o bem-vindas! Consulte nossas [diretrizes de contribui√ß√£o](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/CONTRIBUTING.md) para mais informa√ß√µes.

## Licen√ßa

Este projeto est√° licenciado sob os termos da licen√ßa Apache 2.0. Veja o arquivo [LICENSE](LICENSE) para mais detalhes.

## Contato

Se voc√™ tiver d√∫vidas, sugest√µes ou coment√°rios, fique √† vontade para entrar em contato conosco pelo [email do Jet Xu](https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/mailto:Voldemort.xu@foxmail.com).

---

Obrigado por escolher o llama-github! Esperamos que esta biblioteca aprimore sua experi√™ncia de desenvolvimento com IA e ajude voc√™ a construir aplica√ß√µes poderosas com facilidade.



---

Tranlated By [Open Ai Tx](https://github.com/OpenAiTx/OpenAiTx) | Last indexed: 2025-07-28

---