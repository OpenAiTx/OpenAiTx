[
  {
    "Id": 1,
    "Content": "\n<div align=\"right\">\n  <details>\n    <summary >ğŸŒ Language</summary>\n    <div>\n      <div align=\"center\">\n        <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=en\">English</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=zh-CN\">ç®€ä½“ä¸­æ–‡</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=zh-TW\">ç¹é«”ä¸­æ–‡</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=ja\">æ—¥æœ¬èª</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=ko\">í•œêµ­ì–´</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=hi\">à¤¹à¤¿à¤¨à¥à¤¦à¥€</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=th\">à¹„à¸—à¸¢</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=fr\">FranÃ§ais</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=de\">Deutsch</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=es\">EspaÃ±ol</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=it\">Italiano</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=ru\">Ğ ÑƒÑÑĞºĞ¸Ğ¹</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=pt\">PortuguÃªs</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=nl\">Nederlands</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=pl\">Polski</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=ar\">Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=fa\">ÙØ§Ø±Ø³ÛŒ</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=tr\">TÃ¼rkÃ§e</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=vi\">Tiáº¿ng Viá»‡t</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=id\">Bahasa Indonesia</a>\n      </div>\n    </div>\n  </details>\n</div>\n\n<div align=\"center\">\n\n# ğŸš€ No Time to Train!  \n### Training-Free Reference-Based Instance Segmentation  \n[![GitHub](https://img.shields.io/badge/%E2%80%8B-No%20Time%20To%20Train-black?logo=github)](https://github.com/miquel-espinosa/no-time-to-train)\n[![Website](https://img.shields.io/badge/ğŸŒ-Project%20Page-grey)](https://miquel-espinosa.github.io/no-time-to-train/)\n[![arXiv](https://img.shields.io/badge/arXiv-2507.02798-b31b1b)](https://arxiv.org/abs/2507.02798)\n\n**State-of-the-art (Papers with Code)**",
    "ContentSha": "lG1vuwmuqLt4d95/PBMz1H5HG0r+JfvC/FVnqNQvTnM=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "\n<div align=\"right\">\n  <details>\n    <summary >ğŸŒ èªè¨€</summary>\n    <div>\n      <div align=\"center\">\n        <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=en\">English</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=zh-CN\">ç®€ä½“ä¸­æ–‡</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=zh-TW\">ç¹é«”ä¸­æ–‡</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=ja\">æ—¥æœ¬èª</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=ko\">í•œêµ­ì–´</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=hi\">à¤¹à¤¿à¤¨à¥à¤¦à¥€</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=th\">à¹„à¸—à¸¢</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=fr\">FranÃ§ais</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=de\">Deutsch</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=es\">EspaÃ±ol</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=it\">Italiano</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=ru\">Ğ ÑƒÑÑĞºĞ¸Ğ¹</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=pt\">PortuguÃªs</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=nl\">Nederlands</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=pl\">Polski</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=ar\">Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=fa\">ÙØ§Ø±Ø³ÛŒ</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=tr\">TÃ¼rkÃ§e</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=vi\">Tiáº¿ng Viá»‡t</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=id\">Bahasa Indonesia</a>\n      </div>\n    </div>\n  </details>\n</div>\n\n<div align=\"center\">\n\n# ğŸš€ æ²’æœ‰æ™‚é–“è¨“ç·´ï¼  \n### ç„¡éœ€è¨“ç·´çš„åƒè€ƒå¼å¯¦ä¾‹åˆ†å‰²  \n[![GitHub](https://img.shields.io/badge/%E2%80%8B-No%20Time%20To%20Train-black?logo=github)](https://github.com/miquel-espinosa/no-time-to-train)\n[![Website](https://img.shields.io/badge/ğŸŒ-Project%20Page-grey)](https://miquel-espinosa.github.io/no-time-to-train/)\n[![arXiv](https://img.shields.io/badge/arXiv-2507.02798-b31b1b)](https://arxiv.org/abs/2507.02798)\n\n**æœ€å…ˆé€²æŠ€è¡“ï¼ˆPapers with Codeï¼‰**",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 2,
    "Content": "\n[**_SOTA 1-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-1-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/badge/State%20of%20the%20Art-Few--Shot%20Object%20Detection%20on%20MS--COCO%20(1--shot)-21CBCE?style=flat&logo=paperswithcode)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-1-shot?p=no-time-to-train-training-free-reference)\n\n[**_SOTA 10-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-10-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/badge/State%20of%20the%20Art-Few--Shot%20Object%20Detection%20on%20MS--COCO%20(10--shot)-21CBCE?style=flat&logo=paperswithcode)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-10-shot?p=no-time-to-train-training-free-reference)\n\n[**_SOTA 30-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-30-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/badge/State%20of%20the%20Art-Few--Shot%20Object%20Detection%20on%20MS--COCO%20(30--shot)-21CBCE?style=flat&logo=paperswithcode)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-30-shot?p=no-time-to-train-training-free-reference)\n\n<!-- [**_SOTA 1-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-1-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/no-time-to-train-training-free-reference/few-shot-object-detection-on-ms-coco-1-shot)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-1-shot?p=no-time-to-train-training-free-reference)\n\n[**_SOTA 10-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-10-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/no-time-to-train-training-free-reference/few-shot-object-detection-on-ms-coco-10-shot)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-10-shot?p=no-time-to-train-training-free-reference)\n\n[**_SOTA 30-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-30-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/no-time-to-train-training-free-reference/few-shot-object-detection-on-ms-coco-30-shot)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-30-shot?p=no-time-to-train-training-free-reference) -->\n\n</div>\n\n---\n\n> ğŸš¨ **Update (22nd July 2025):** Instructions for custom datasets have been added!\n> \n> ğŸ”” **Update (16th July 2025):** Code has been updated with instructions!\n\n---\n\n## ğŸ“‹ Table of Contents\n\n- [ğŸ¯ Highlights](#-highlights)\n- [ğŸ“œ Abstract](#-abstract)\n- [ğŸ§  Architecture](#-architecture)\n- [ğŸ› ï¸ Installation instructions](#ï¸-installation-instructions)\n  - [1. Clone the repository](#1-clone-the-repository)\n  - [2. Create conda environment](#2-create-conda-environment)\n  - [3. Install SAM2 and DinoV2](#3-install-sam2-and-dinov2)\n  - [4. Download datasets](#4-download-datasets)\n  - [5. Download SAM2 and DinoV2 checkpoints](#5-download-sam2-and-dinov2-checkpoints)\n- [ğŸ“Š Inference code: Reproduce 30-shot SOTA results in Few-shot COCO](#-inference-code)\n  - [0. Create reference set](#0-create-reference-set)\n  - [1. Fill memory with references](#1-fill-memory-with-references)\n  - [2. Post-process memory bank](#2-post-process-memory-bank)\n  - [3. Inference on target images](#3-inference-on-target-images)\n  - [Results](#results)",
    "ContentSha": "+yQ5ol79RNsk2le3no6dLpgaMzuy0Nh4xdRCmVNp8FE=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "[**_SOTA 1-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-1-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/badge/State%20of%20the%20Art-Few--Shot%20Object%20Detection%20on%20MS--COCO%20(1--shot)-21CBCE?style=flat&logo=paperswithcode)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-1-shot?p=no-time-to-train-training-free-reference)\n\n[**_SOTA 10-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-10-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/badge/State%20of%20the%20Art-Few--Shot%20Object%20Detection%20on%20MS--COCO%20(10--shot)-21CBCE?style=flat&logo=paperswithcode)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-10-shot?p=no-time-to-train-training-free-reference)\n\n[**_SOTA 30-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-30-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/badge/State%20of%20the%20Art-Few--Shot%20Object%20Detection%20on%20MS--COCO%20(30--shot)-21CBCE?style=flat&logo=paperswithcode)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-30-shot?p=no-time-to-train-training-free-reference)\n\n<!-- [**_SOTA 1-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-1-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/no-time-to-train-training-free-reference/few-shot-object-detection-on-ms-coco-1-shot)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-1-shot?p=no-time-to-train-training-free-reference)\n\n[**_SOTA 10-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-10-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/no-time-to-train-training-free-reference/few-shot-object-detection-on-ms-coco-10-shot)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-10-shot?p=no-time-to-train-training-free-reference)\n\n[**_SOTA 30-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-30-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/no-time-to-train-training-free-reference/few-shot-object-detection-on-ms-coco-30-shot)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-30-shot?p=no-time-to-train-training-free-reference) -->\n\n</div>\n\n---\n\n> ğŸš¨ **æ›´æ–°ï¼ˆ2025å¹´7æœˆ22æ—¥ï¼‰ï¼š** å·²æ–°å¢è‡ªè¨‚è³‡æ–™é›†çš„æ“ä½œèªªæ˜ï¼\n> \n> ğŸ”” **æ›´æ–°ï¼ˆ2025å¹´7æœˆ16æ—¥ï¼‰ï¼š** ç¨‹å¼ç¢¼å·²æ›´æ–°ä¸¦é™„ä¸Šæ“ä½œæŒ‡å¼•ï¼\n\n---\n\n## ğŸ“‹ ç›®éŒ„\n\n- [ğŸ¯ é‡é»](#-highlights)\n- [ğŸ“œ æ‘˜è¦](#-abstract)\n- [ğŸ§  æ¶æ§‹](#-architecture)\n- [ğŸ› ï¸ å®‰è£èªªæ˜](#ï¸-installation-instructions)\n  - [1. è¤‡è£½ç¨‹å¼åº«](#1-clone-the-repository)\n  - [2. å»ºç«‹ conda ç’°å¢ƒ](#2-create-conda-environment)\n  - [3. å®‰è£ SAM2 èˆ‡ DinoV2](#3-install-sam2-and-dinov2)\n  - [4. ä¸‹è¼‰è³‡æ–™é›†](#4-download-datasets)\n  - [5. ä¸‹è¼‰ SAM2 èˆ‡ DinoV2 æª¢æŸ¥é»](#5-download-sam2-and-dinov2-checkpoints)\n- [ğŸ“Š æ¨è«–ç¨‹å¼ï¼šé‡ç¾ Few-shot COCO 30-shot SOTA çµæœ](#-inference-code)\n  - [0. å»ºç«‹åƒè€ƒé›†](#0-create-reference-set)\n  - [1. ä»¥åƒè€ƒè³‡æ–™å¡«å……è¨˜æ†¶é«”](#1-fill-memory-with-references)\n  - [2. å¾Œè™•ç†è¨˜æ†¶é«”åº«](#2-post-process-memory-bank)\n  - [3. åœ¨ç›®æ¨™å½±åƒä¸Šé€²è¡Œæ¨è«–](#3-inference-on-target-images)\n  - [çµæœ](#results)\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 3,
    "Content": "- [ğŸ” Custom dataset](#-custom-dataset)\n  - [0. Prepare a custom dataset â›µğŸ¦](#0-prepare-a-custom-dataset)\n  - [0.1 If only bbox annotations are available](#01-if-only-bbox-annotations-are-available)\n  - [0.2 Convert coco annotations to pickle file](#02-convert-coco-annotations-to-pickle-file)\n  - [1. Fill memory with references](#1-fill-memory-with-references)\n  - [2. Post-process memory bank](#2-post-process-memory-bank)\n- [ğŸ“š Citation](#-citation)\n\n\n## ğŸ¯ Highlights\n- ğŸ’¡ **Training-Free**: No fine-tuning, no prompt engineeringâ€”just a reference image.  \n- ğŸ–¼ï¸ **Reference-Based**: Segment new objects using just a few examples.  \n- ğŸ”¥ **SOTA Performance**: Outperforms previous training-free approaches on COCO, PASCAL VOC, and Cross-Domain FSOD.\n\n**Links:**\n- ğŸ§¾ [**arXiv Paper**](https://arxiv.org/abs/2507.02798)  \n- ğŸŒ [**Project Website**](https://miquel-espinosa.github.io/no-time-to-train/)  \n- ğŸ“ˆ [**Papers with Code**](https://paperswithcode.com/paper/no-time-to-train-training-free-reference)\n\n## ğŸ“œ Abstract\n",
    "ContentSha": "HKE5vt8IwUJiOubYYPHCrRXZ3fqCpGqVFP3Xj5VV+p4=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "- [ğŸ” è‡ªè¨‚è³‡æ–™é›†](#-custom-dataset)\n  - [0. æº–å‚™è‡ªè¨‚è³‡æ–™é›† â›µğŸ¦](#0-prepare-a-custom-dataset)\n  - [0.1 åƒ…æœ‰é‚Šç•Œæ¡†è¨»é‡‹æ™‚](#01-if-only-bbox-annotations-are-available)\n  - [0.2 å°‡ COCO è¨»é‡‹è½‰æ›ç‚º pickle æª”æ¡ˆ](#02-convert-coco-annotations-to-pickle-file)\n  - [1. ä»¥åƒè€ƒè³‡æ–™å¡«å……è¨˜æ†¶é«”](#1-fill-memory-with-references)\n  - [2. è¨˜æ†¶åº«å¾Œè™•ç†](#2-post-process-memory-bank)\n- [ğŸ“š å¼•ç”¨](#-citation)\n\n\n## ğŸ¯ äº®é»\n- ğŸ’¡ **å…è¨“ç·´**ï¼šç„¡éœ€å¾®èª¿ã€ç„¡éœ€æç¤ºå·¥ç¨‹â€”åªéœ€ä¸€å¼µåƒè€ƒå½±åƒã€‚  \n- ğŸ–¼ï¸ **åƒè€ƒå¼**ï¼šåƒ…ç”¨å°‘é‡ç¯„ä¾‹å³å¯åˆ†å‰²æ–°ç‰©ä»¶ã€‚  \n- ğŸ”¥ **SOTA æ•ˆèƒ½**ï¼šåœ¨ COCOã€PASCAL VOC åŠè·¨é ˜åŸŸ FSOD ä¸Šè¶…è¶Šæ—¢æœ‰å…è¨“ç·´æ–¹æ³•ã€‚\n\n**é€£çµï¼š**\n- ğŸ§¾ [**arXiv è«–æ–‡**](https://arxiv.org/abs/2507.02798)  \n- ğŸŒ [**å°ˆæ¡ˆç¶²ç«™**](https://miquel-espinosa.github.io/no-time-to-train/)  \n- ğŸ“ˆ [**Papers with Code**](https://paperswithcode.com/paper/no-time-to-train-training-free-reference)\n\n## ğŸ“œ æ‘˜è¦\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 4,
    "Content": "> The performance of image segmentation models has historically been constrained by the high cost of collecting large-scale annotated data. The Segment Anything Model (SAM) alleviates this original problem through a promptable, semantics-agnostic, segmentation paradigm and yet still requires manual visual-prompts or complex domain-dependent prompt-generation rules to process a new image. Towards reducing this new burden, our work investigates the task of object segmentation when provided with, alternatively, only a small set of reference images. Our key insight is to leverage strong semantic priors, as learned by foundation models, to identify corresponding regions between a reference and a target image. We find that correspondences enable automatic generation of instance-level segmentation masks for downstream tasks and instantiate our ideas via a multi-stage, training-free method incorporating (1) memory bank construction; (2) representation aggregation and (3) semantic-aware feature matching. Our experiments show significant improvements on segmentation metrics, leading to state-of-the-art performance on COCO FSOD (36.8% nAP), PASCAL VOC Few-Shot (71.2% nAP50) and outperforming existing training-free approaches on the Cross-Domain FSOD benchmark (22.4% nAP).",
    "ContentSha": "f62KYkH46xSV0RKRpAlERSF/nhSETk2RE3WyAIz5gDw=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "> The performance of image segmentation models has historically been constrained by the high cost of collecting large-scale annotated data. The Segment Anything Model (SAM) alleviates this original problem through a promptable, semantics-agnostic, segmentation paradigm and yet still requires manual visual-prompts or complex domain-dependent prompt-generation rules to process a new image. Towards reducing this new burden, our work investigates the task of object segmentation when provided with, alternatively, only a small set of reference images. Our key insight is to leverage strong semantic priors, as learned by foundation models, to identify corresponding regions between a reference and a target image. We find that correspondences enable automatic generation of instance-level segmentation masks for downstream tasks and instantiate our ideas via a multi-stage, training-free method incorporating (1) memory bank construction; (2) representation aggregation and (3) semantic-aware feature matching. Our experiments show significant improvements on segmentation metrics, leading to state-of-the-art performance on COCO FSOD (36.8% nAP), PASCAL VOC Few-Shot (71.2% nAP50) and outperforming existing training-free approaches on the Cross-Domain FSOD benchmark (22.4% nAP).",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 5,
    "Content": "\n![cdfsod-results-final-comic-sans-min](https://github.com/user-attachments/assets/ab302c02-c080-4042-99fc-0e181ba8abb9)\n\n\n## ğŸ§  Architecture\n\n![training-free-architecture-comic-sans-min](https://github.com/user-attachments/assets/d84dd83a-505e-45a0-8ce3-98e1838017f9)\n\n\n## ğŸ› ï¸ Installation instructions\n\n### 1. Clone the repository\n",
    "ContentSha": "V4xbbzEUhNFOhqp3BaqWeY1MaXeaFR8RD3QR6DHJiVo=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "\n![cdfsod-results-final-comic-sans-min](https://github.com/user-attachments/assets/ab302c02-c080-4042-99fc-0e181ba8abb9)\n\n\n## ğŸ§  Architecture\n\n![training-free-architecture-comic-sans-min](https://github.com/user-attachments/assets/d84dd83a-505e-45a0-8ce3-98e1838017f9)\n\n\n## ğŸ› ï¸ Installation instructions\n\n### 1. Clone the repository\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 6,
    "Content": "```bash\ngit clone https://github.com/miquel-espinosa/no-time-to-train.git\ncd no-time-to-train\n```",
    "ContentSha": "FqsX96SwjKeMnD8rrDrd4pfjW32n5SRf0jXIvB4WHz4=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\ngit clone https://github.com/miquel-espinosa/no-time-to-train.git\ncd no-time-to-train\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 7,
    "Content": "\n### 2. Create conda environment\n\nWe will create a conda environment with the required packages.",
    "ContentSha": "xkwDa/DvfDApk69cNg5ORagN7Utfcos+yCxRpQNn6gk=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "### 2. å»ºç«‹ conda ç’°å¢ƒ\n\næˆ‘å€‘å°‡å»ºç«‹ä¸€å€‹åŒ…å«æ‰€éœ€å¥—ä»¶çš„ conda ç’°å¢ƒã€‚\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 8,
    "Content": "```bash\nconda env create -f environment.yml\nconda activate no-time-to-train\n```",
    "ContentSha": "W1AlselK7qAC1MpunsXhTPA8MG+kwjbpodKBkImFaio=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\nconda env create -f environment.yml\nconda activate no-time-to-train\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 9,
    "Content": "\n### 3. Install SAM2 and DinoV2\n\nWe will install SAM2 and DinoV2 from source.",
    "ContentSha": "qhWNaaTVSpemTiKekSRF2dWJYxX636VdhL+lPiso28M=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "### 3. å®‰è£ SAM2 å’Œ DinoV2\n\næˆ‘å€‘å°‡å¾åŸå§‹ç¢¼å®‰è£ SAM2 å’Œ DinoV2ã€‚\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 10,
    "Content": "```bash\npip install -e .\ncd dinov2\npip install -e .\ncd ..\n```",
    "ContentSha": "dMsjJwa9nz+HHMLijmYZdlLh6FmDBGmNlHxywBzbEg4=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\npip install -e .\ncd dinov2\npip install -e .\ncd ..\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 11,
    "Content": "\n### 4. Download datasets\n\nPlease download COCO dataset and place it in `data/coco`\n\n### 5. Download SAM2 and DinoV2 checkpoints\n\nWe will download the exact SAM2 checkpoints used in the paper.\n(Note, however, that SAM2.1 checkpoints are already available and might perform better.)\n",
    "ContentSha": "LTXcwC9KGMiPIiBLXtQVF6Wdi9d19gVIUBX6F+tGTqE=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "### 4. ä¸‹è¼‰æ•¸æ“šé›†\n\nè«‹ä¸‹è¼‰ COCO æ•¸æ“šé›†ä¸¦å°‡å…¶æ”¾ç½®æ–¼ `data/coco`\n\n### 5. ä¸‹è¼‰ SAM2 å’Œ DinoV2 æ¬Šé‡æª”\n\næˆ‘å€‘å°‡ä¸‹è¼‰è«–æ–‡ä¸­ä½¿ç”¨çš„ SAM2 æ¬Šé‡æª”ã€‚\nï¼ˆä½†è«‹æ³¨æ„ï¼ŒSAM2.1 æ¬Šé‡æª”å·²ç¶“å¯ç”¨ï¼Œä¸”å¯èƒ½æœ‰æ›´å¥½çš„è¡¨ç¾ã€‚ï¼‰\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 12,
    "Content": "```bash\nmkdir -p checkpoints/dinov2\ncd checkpoints\nwget https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_large.pt\ncd dinov2\nwget https://dl.fbaipublicfiles.com/dinov2/dinov2_vitl14/dinov2_vitl14_pretrain.pth\ncd ../..\n```",
    "ContentSha": "Q/LddAGtfunblX1eLTx7t3Vs+C74LtCdgP/HQ3gIJgk=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\nmkdir -p checkpoints/dinov2\ncd checkpoints\nwget https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_large.pt\ncd dinov2\nwget https://dl.fbaipublicfiles.com/dinov2/dinov2_vitl14/dinov2_vitl14_pretrain.pth\ncd ../..\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 13,
    "Content": "\n\n## ğŸ“Š Inference code\n\nâš ï¸ Disclaimer: This is research code â€” expect a bit of chaos!\n\n### Reproducing 30-shot SOTA results in Few-shot COCO\n\nDefine useful variables and create a folder for results:\n",
    "ContentSha": "q8hVlrVr+ps2xB/JxM3tKtF/KxoLX4PepxohltYehb8=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "## ğŸ“Š æ¨è«–ç¨‹å¼ç¢¼\n\nâš ï¸ å…è²¬è²æ˜ï¼šé€™æ˜¯ç ”ç©¶ç”¨ç¨‹å¼ç¢¼â€”â€”è«‹é æœŸæœƒæœ‰ä¸€äº›æ··äº‚ï¼\n\n### åœ¨ Few-shot COCO ä¸­é‡ç¾ 30-shot SOTA çµæœ\n\nå®šç¾©æœ‰ç”¨çš„è®Šæ•¸ä¸¦ç‚ºçµæœå»ºç«‹è³‡æ–™å¤¾ï¼š\n\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 14,
    "Content": "```bash\nCONFIG=./no_time_to_train/new_exps/coco_fewshot_10shot_Sam2L.yaml\nCLASS_SPLIT=\"few_shot_classes\"\nRESULTS_DIR=work_dirs/few_shot_results\nSHOTS=30\nSEED=33\nGPUS=4\n\nmkdir -p $RESULTS_DIR\nFILENAME=few_shot_${SHOTS}shot_seed${SEED}.pkl\n```",
    "ContentSha": "R03PMGcFnYnvttqgfztGnWdoyJeXMyxFUN7tyR4kpy8=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\nCONFIG=./no_time_to_train/new_exps/coco_fewshot_10shot_Sam2L.yaml\nCLASS_SPLIT=\"few_shot_classes\"\nRESULTS_DIR=work_dirs/few_shot_results\nSHOTS=30\nSEED=33\nGPUS=4\n\nmkdir -p $RESULTS_DIR\nFILENAME=few_shot_${SHOTS}shot_seed${SEED}.pkl\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 15,
    "Content": "\n#### 0. Create reference set\n",
    "ContentSha": "1XrtmJBqIS+6/RHkWmwwopPgE4d3ho+bdPLXEG612YQ=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "#### 0. å»ºç«‹åƒè€ƒé›†\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 16,
    "Content": "```bash\npython no_time_to_train/dataset/few_shot_sampling.py \\\n        --n-shot $SHOTS \\\n        --out-path ${RESULTS_DIR}/${FILENAME} \\\n        --seed $SEED \\\n        --dataset $CLASS_SPLIT\n```",
    "ContentSha": "XMsc+nj2n5gsZtjFdl6ErjVKLXgBoPIrungxtY9mDss=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\npython no_time_to_train/dataset/few_shot_sampling.py \\\n        --n-shot $SHOTS \\\n        --out-path ${RESULTS_DIR}/${FILENAME} \\\n        --seed $SEED \\\n        --dataset $CLASS_SPLIT\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 17,
    "Content": "\n#### 1. Fill memory with references\n",
    "ContentSha": "v8E00SBwAimb411iJf1DGyTZxexOPmC/xK0/B+XBH1g=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "#### 1. ç”¨åƒè€ƒå¡«å……è¨˜æ†¶é«”\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 18,
    "Content": "```bash\npython run_lightening.py test --config $CONFIG \\\n                              --model.test_mode fill_memory \\\n                              --out_path ${RESULTS_DIR}/memory.ckpt \\\n                              --model.init_args.model_cfg.memory_bank_cfg.length $SHOTS \\\n                              --model.init_args.dataset_cfgs.fill_memory.memory_pkl ${RESULTS_DIR}/${FILENAME} \\\n                              --model.init_args.dataset_cfgs.fill_memory.memory_length $SHOTS \\\n                              --model.init_args.dataset_cfgs.fill_memory.class_split $CLASS_SPLIT \\\n                              --trainer.logger.save_dir ${RESULTS_DIR}/ \\\n                              --trainer.devices $GPUS\n```",
    "ContentSha": "1pVePuzaIdQCE/Nx0VoaWhFswuB5Jh1Z68Cw/2D8RkM=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\npython run_lightening.py test --config $CONFIG \\\n                              --model.test_mode fill_memory \\\n                              --out_path ${RESULTS_DIR}/memory.ckpt \\\n                              --model.init_args.model_cfg.memory_bank_cfg.length $SHOTS \\\n                              --model.init_args.dataset_cfgs.fill_memory.memory_pkl ${RESULTS_DIR}/${FILENAME} \\\n                              --model.init_args.dataset_cfgs.fill_memory.memory_length $SHOTS \\\n                              --model.init_args.dataset_cfgs.fill_memory.class_split $CLASS_SPLIT \\\n                              --trainer.logger.save_dir ${RESULTS_DIR}/ \\\n                              --trainer.devices $GPUS\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 19,
    "Content": "\n#### 2. Post-process memory bank\n",
    "ContentSha": "3A9quGczCnAQeUTcoJVGYLTQapI5nQ5aSj7AZIhGFJw=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "#### 2. å¾Œè™•ç†è¨˜æ†¶é«”åº«\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 20,
    "Content": "```bash\npython run_lightening.py test --config $CONFIG \\\n                              --model.test_mode postprocess_memory \\\n                              --model.init_args.model_cfg.memory_bank_cfg.length $SHOTS \\\n                              --ckpt_path ${RESULTS_DIR}/memory.ckpt \\\n                              --out_path ${RESULTS_DIR}/memory_postprocessed.ckpt \\\n                              --trainer.devices 1\n```",
    "ContentSha": "45qs8EyMtDUKs5A3rrQcJQXl6OIbI6s0rKOOnHmYURs=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\npython run_lightening.py test --config $CONFIG \\\n                              --model.test_mode postprocess_memory \\\n                              --model.init_args.model_cfg.memory_bank_cfg.length $SHOTS \\\n                              --ckpt_path ${RESULTS_DIR}/memory.ckpt \\\n                              --out_path ${RESULTS_DIR}/memory_postprocessed.ckpt \\\n                              --trainer.devices 1\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 21,
    "Content": "\n#### 3. Inference on target images\n",
    "ContentSha": "73CbGioqWaTULTrw0roBLoZCxgBgtmJVFDc7RHluH0g=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "#### 3. åœ¨ç›®æ¨™å½±åƒä¸Šé€²è¡Œæ¨è«–\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 22,
    "Content": "```bash\npython run_lightening.py test --config $CONFIG  \\\n                              --ckpt_path ${RESULTS_DIR}/memory_postprocessed.ckpt \\\n                              --model.init_args.test_mode test \\\n                              --model.init_args.model_cfg.memory_bank_cfg.length $SHOTS \\\n                              --model.init_args.model_cfg.dataset_name $CLASS_SPLIT \\\n                              --model.init_args.dataset_cfgs.test.class_split $CLASS_SPLIT \\\n                              --trainer.logger.save_dir ${RESULTS_DIR}/ \\\n                              --trainer.devices $GPUS\n```",
    "ContentSha": "vbKXVEs47fJ5oF8vLkHVM2ofFMx1hKBBgQF9JAgp2Jo=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\npython run_lightening.py test --config $CONFIG  \\\n                              --ckpt_path ${RESULTS_DIR}/memory_postprocessed.ckpt \\\n                              --model.init_args.test_mode test \\\n                              --model.init_args.model_cfg.memory_bank_cfg.length $SHOTS \\\n                              --model.init_args.model_cfg.dataset_name $CLASS_SPLIT \\\n                              --model.init_args.dataset_cfgs.test.class_split $CLASS_SPLIT \\\n                              --trainer.logger.save_dir ${RESULTS_DIR}/ \\\n                              --trainer.devices $GPUS\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 23,
    "Content": "\nIf you'd like to see inference results online (as they are computed), add the argument:",
    "ContentSha": "Dp4E3gH6hSg659jJwzXukrsk5Jl8KA5ymhMGoz6L/wc=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "å¦‚æœæ‚¨å¸Œæœ›åœ¨ç·šæŸ¥çœ‹æ¨è«–çµæœï¼ˆåœ¨è¨ˆç®—æ™‚å³æ™‚é¡¯ç¤ºï¼‰ï¼Œè«‹æ·»åŠ ä»¥ä¸‹åƒæ•¸ï¼š\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 24,
    "Content": "```bash\n    --model.init_args.model_cfg.test.online_vis True\n```",
    "ContentSha": "mbu//ROEScsc0zLyvi3r1BPFxMrHWk/o7rqLvu03LTA=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\n    --model.init_args.model_cfg.test.online_vis True\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 25,
    "Content": "To adjust the score threshold `score_thr` parameter, add the argument (for example, visualising all instances with score higher than `0.4`):",
    "ContentSha": "qweycVV6vcVlQTeQ2dS1zGx5GmbYXYcZs6oNjQhUwNI=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "è¦èª¿æ•´åˆ†æ•¸é–¾å€¼ `score_thr` åƒæ•¸ï¼Œè«‹æ·»åŠ è©²åƒæ•¸ï¼ˆä¾‹å¦‚ï¼Œåƒ…é¡¯ç¤ºåˆ†æ•¸é«˜æ–¼ `0.4` çš„æ‰€æœ‰å¯¦ä¾‹ï¼‰ï¼š",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 26,
    "Content": "```bash\n    --model.init_args.model_cfg.test.vis_thr 0.4\n```",
    "ContentSha": "af/rWDR0jwUHbKw+uPDz7J5oeScBvpa9U5qwCYxo0Pg=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\n    --model.init_args.model_cfg.test.vis_thr 0.4\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 27,
    "Content": "Images will now be saved in `results_analysis/few_shot_classes/`. The image on the left shows the ground truth, the image on the right shows the segmented instances found by our training-free method.\n\nNote that in this example we are using the `few_shot_classes` split, thus, we should only expect to see segmented instances of the classes in this split (not all classes in COCO).\n\n#### Results\n\nAfter running all images in the validation set, you should obtain:\n",
    "ContentSha": "UYiVB+AwL2aAWVmV805O2tsw2jw3cL3t1ysHKuWCd28=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "åœ–åƒç¾åœ¨å°‡è¢«å„²å­˜åœ¨ `results_analysis/few_shot_classes/`ã€‚å·¦å´çš„åœ–åƒé¡¯ç¤ºäº†çœŸå¯¦æ¨™è¨»ï¼Œå³å´çš„åœ–åƒå‰‡é¡¯ç¤ºäº†æˆ‘å€‘ç„¡éœ€è¨“ç·´æ–¹æ³•æ‰¾åˆ°çš„åˆ†å‰²å¯¦ä¾‹ã€‚\n\nè«‹æ³¨æ„ï¼Œåœ¨é€™å€‹ä¾‹å­ä¸­æˆ‘å€‘ä½¿ç”¨çš„æ˜¯ `few_shot_classes` åˆ†å‰²ï¼Œå› æ­¤ï¼Œæˆ‘å€‘æ‡‰è©²åªæœƒçœ‹åˆ°é€™å€‹åˆ†å‰²ä¸­çš„é¡åˆ¥åˆ†å‰²å¯¦ä¾‹ï¼ˆè€Œä¸æ˜¯ COCO ä¸­çš„æ‰€æœ‰é¡åˆ¥ï¼‰ã€‚\n\n#### çµæœ\n\nåœ¨é‹è¡Œå®Œé©—è­‰é›†ä¸­çš„æ‰€æœ‰åœ–åƒå¾Œï¼Œä½ æ‡‰è©²æœƒå¾—åˆ°ï¼š\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 28,
    "Content": "```\nBBOX RESULTS:\n  Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.368\n\nSEGM RESULTS:\n  Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.342\n```",
    "ContentSha": "ch7itB3Sk8oLc3U+lNJGI3BV57wpOMkabTBsUiqzHDU=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```\nBBOX RESULTS:\n  Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.368\n\nSEGM RESULTS:\n  Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.342\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 29,
    "Content": "---\n\n## ğŸ” Custom dataset\n\nWe provide the instructions for running our pipeline on a custom dataset. Annotation format are always in COCO format.\n\n> **TLDR;** To directly see how to run full pipeline on *custom datasets*, find `scripts/matching_cdfsod_pipeline.sh` together with example scripts of CD-FSOD datasets (e.g. `scripts/dior_fish.sh`)\n\n### 0. Prepare a custom dataset â›µğŸ¦\n\nLet's imagine we want to detect **boats**â›µ and **birds**ğŸ¦ in a custom dataset. To use our method we will need:\n- At least 1 *annotated* reference image for each class (i.e. 1 reference image for boat and 1 reference image for bird)\n- Multiple target images to find instances of our desired classes.\n\nWe have prepared a toy script to create a custom dataset with coco images, for a **1-shot** setting.",
    "ContentSha": "IPUeWphY2t966UmztjMo0ja/aOT1Wd0H0rkyNv8xt9Y=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "---\n\n## ğŸ” è‡ªè¨‚è³‡æ–™é›†\n\næˆ‘å€‘æä¾›äº†åœ¨è‡ªè¨‚è³‡æ–™é›†ä¸Šé‹è¡Œæˆ‘å€‘æµç¨‹çš„æ“ä½œèªªæ˜ã€‚è¨»é‡‹æ ¼å¼ä¸€å¾‹æ¡ç”¨ COCO æ ¼å¼ã€‚\n\n> **ç¸½çµï¼›** è‹¥è¦ç›´æ¥æŸ¥çœ‹å¦‚ä½•åœ¨*è‡ªè¨‚è³‡æ–™é›†*ä¸Šé‹è¡Œå®Œæ•´æµç¨‹ï¼Œè«‹åƒè€ƒ `scripts/matching_cdfsod_pipeline.sh` ä»¥åŠ CD-FSOD è³‡æ–™é›†çš„ç¯„ä¾‹è…³æœ¬ï¼ˆä¾‹å¦‚ `scripts/dior_fish.sh`ï¼‰\n\n### 0. æº–å‚™è‡ªè¨‚è³‡æ–™é›† â›µğŸ¦\n\nå‡è¨­æˆ‘å€‘æƒ³åœ¨è‡ªè¨‚è³‡æ–™é›†ä¸­åµæ¸¬**èˆ¹éš»**â›µå’Œ**é³¥é¡**ğŸ¦ã€‚è¦ä½¿ç”¨æˆ‘å€‘çš„æ–¹æ³•ï¼Œæ‚¨éœ€è¦ï¼š\n- æ¯å€‹é¡åˆ¥è‡³å°‘ 1 å¼µ*å·²è¨»é‡‹*çš„åƒè€ƒåœ–ç‰‡ï¼ˆå³ 1 å¼µèˆ¹çš„åƒè€ƒåœ–ç‰‡å’Œ 1 å¼µé³¥çš„åƒè€ƒåœ–ç‰‡ï¼‰\n- å¤šå¼µç›®æ¨™åœ–ç‰‡ï¼Œç”¨ä»¥å°‹æ‰¾æˆ‘å€‘ç›®æ¨™é¡åˆ¥çš„å¯¦ä¾‹ã€‚\n\næˆ‘å€‘å·²æº–å‚™äº†ä¸€å€‹ç°¡æ˜“è…³æœ¬ï¼Œèƒ½å¤ ä»¥ coco åœ–ç‰‡å‰µå»ºè‡ªè¨‚è³‡æ–™é›†ï¼Œé©ç”¨æ–¼**1-shot**è¨­ç½®ã€‚",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 30,
    "Content": "```bash\nmkdir -p data/my_custom_dataset\npython scripts/make_custom_dataset.py\n```",
    "ContentSha": "QqoeCMR6ke4ax/152QCJr8NiqoIlKNt5rN0t2zxaRtM=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\nmkdir -p data/my_custom_dataset\npython scripts/make_custom_dataset.py\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 31,
    "Content": "This will create a custom dataset with the following folder structure:",
    "ContentSha": "9JGOKHf/Hqbdn+b2OqaUnKIYD8GGf7jwfM9mTbUtoP4=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "é€™å°‡æœƒå»ºç«‹ä¸€å€‹å…·æœ‰ä»¥ä¸‹è³‡æ–™å¤¾çµæ§‹çš„è‡ªè¨‚è³‡æ–™é›†ï¼š",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 32,
    "Content": "```\ndata/my_custom_dataset/\n    â”œâ”€â”€ annotations/\n    â”‚   â”œâ”€â”€ custom_references.json\n    â”‚   â”œâ”€â”€ custom_targets.json\n    â”‚   â””â”€â”€ references_visualisations/\n    â”‚       â”œâ”€â”€ bird_1.jpg\n    â”‚       â””â”€â”€ boat_1.jpg\n    â””â”€â”€ images/\n        â”œâ”€â”€ 429819.jpg\n        â”œâ”€â”€ 101435.jpg\n        â””â”€â”€ (all target and reference images)\n```",
    "ContentSha": "Bj/IFZkQUfkoGUwynry3llvasPwDhX0B0JgBYl9vuQE=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```\ndata/my_custom_dataset/\n    â”œâ”€â”€ annotations/\n    â”‚   â”œâ”€â”€ custom_references.json\n    â”‚   â”œâ”€â”€ custom_targets.json\n    â”‚   â””â”€â”€ references_visualisations/\n    â”‚       â”œâ”€â”€ bird_1.jpg\n    â”‚       â””â”€â”€ boat_1.jpg\n    â””â”€â”€ images/\n        â”œâ”€â”€ 429819.jpg\n        â”œâ”€â”€ 101435.jpg\n        â””â”€â”€ (all target and reference images)\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 33,
    "Content": "\n**Reference images visualisation (1-shot):**\n\n| 1-shot Reference Image for BIRD ğŸ¦ | 1-shot Reference Image for BOAT â›µ |\n|:---------------------------------:|:----------------------------------:|\n| <img src=\"https://github.com/user-attachments/assets/e59e580d-a7db-42ac-b386-892af211fc85\" alt=\"bird_1\" width=\"500\"/> | <img src=\"https://github.com/user-attachments/assets/f94ee025-ae37-4a45-9c3e-0cfe8f8cd2bc\" alt=\"boat_1\" width=\"500\"/> |\n\n\n### 0.1 If only bbox annotations are available\n\nWe also provide a script to generate instance-level segmentation masks by using SAM2. This is useful if you only have bounding box annotations available for the reference images.\n",
    "ContentSha": "24nxqSCUluTBmTCEJTeg5Xoe4qe7qXxstVNWjA2/zVk=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "**åƒè€ƒåœ–ç‰‡è¦–è¦ºåŒ–ï¼ˆ1-shotï¼‰ï¼š**\n\n| BIRD ğŸ¦ çš„ 1-shot åƒè€ƒåœ–ç‰‡ | BOAT â›µ çš„ 1-shot åƒè€ƒåœ–ç‰‡ |\n|:---------------------------:|:----------------------------:|\n| <img src=\"https://github.com/user-attachments/assets/e59e580d-a7db-42ac-b386-892af211fc85\" alt=\"bird_1\" width=\"500\"/> | <img src=\"https://github.com/user-attachments/assets/f94ee025-ae37-4a45-9c3e-0cfe8f8cd2bc\" alt=\"boat_1\" width=\"500\"/> |\n\n\n### 0.1 åƒ…æœ‰ bbox æ¨™è¨»æ™‚\n\næˆ‘å€‘ä¹Ÿæä¾›ä¸€å€‹è…³æœ¬ï¼Œåˆ©ç”¨ SAM2 ç”Ÿæˆå¯¦ä¾‹ç´šåˆ†å‰²é®ç½©ã€‚é€™åœ¨åƒ…æœ‰åƒè€ƒåœ–ç‰‡çš„é‚Šç•Œæ¡†æ¨™è¨»æ™‚éå¸¸æœ‰ç”¨ã€‚\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 34,
    "Content": "```bash\n# Download sam_h checkpoint. Feel free to use more recent checkpoints (note: code might need to be adapted)\nwget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth -O checkpoints/sam_vit_h_4b8939.pth\n# Run automatic instance segmentation from ground truth bounding boxes.\npython no_time_to_train/dataset/sam_bbox_to_segm_batch.py \\\n    --input_json data/my_custom_dataset/annotations/custom_references.json \\\n    --image_dir data/my_custom_dataset/images \\\n    --sam_checkpoint checkpoints/sam_vit_h_4b8939.pth \\\n    --model_type vit_h \\\n    --device cuda \\\n    --batch_size 8 \\\n    --visualize\n```",
    "ContentSha": "MZFLWMxUY4Y3eseQiE2eVYRMs3mR83iZMQq1RJqVFCc=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\n# Download sam_h checkpoint. Feel free to use more recent checkpoints (note: code might need to be adapted)\nwget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth -O checkpoints/sam_vit_h_4b8939.pth\n# Run automatic instance segmentation from ground truth bounding boxes.\npython no_time_to_train/dataset/sam_bbox_to_segm_batch.py \\\n    --input_json data/my_custom_dataset/annotations/custom_references.json \\\n    --image_dir data/my_custom_dataset/images \\\n    --sam_checkpoint checkpoints/sam_vit_h_4b8939.pth \\\n    --model_type vit_h \\\n    --device cuda \\\n    --batch_size 8 \\\n    --visualize\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 35,
    "Content": "\n**Reference images with instance-level segmentation masks (generated by SAM2 from gt bounding boxes, 1-shot):**\n\nVisualisation of the generated segmentation masks are saved in `data/my_custom_dataset/annotations/custom_references_with_SAM_segm/references_visualisations/`.\n\n\n| 1-shot Reference Image for BIRD ğŸ¦ (automatically segmented with SAM) | 1-shot Reference Image for BOAT â›µ (automatically segmented with SAM) |\n|:---------------------------------:|:----------------------------------:|\n| <img src=\"https://github.com/user-attachments/assets/65d38dc4-1454-43cd-9600-e8efc67b3a82\" alt=\"bird_1_with_SAM_segm\" width=\"500\"/> | <img src=\"https://github.com/user-attachments/assets/43a558ad-50ca-4715-8285-9aa3268843c6\" alt=\"boat_1_with_SAM_segm\" width=\"500\"/> |\n\n\n### 0.2 Convert coco annotations to pickle file\n",
    "ContentSha": "0a8ACnuaKmeocwoJUK+xvmctljcu8ZJdT00xJXlyJ5w=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "**å¸¶æœ‰å¯¦ä¾‹ç´šåˆ†å‰²é®ç½©çš„åƒè€ƒåœ–åƒï¼ˆç”± SAM2 æ ¹æ“š gt é‚Šç•Œæ¡†ç”Ÿæˆï¼Œ1-shotï¼‰ï¼š**\n\nç”¢ç”Ÿçš„åˆ†å‰²é®ç½©è¦–è¦ºåŒ–çµæœå·²å„²å­˜åœ¨ `data/my_custom_dataset/annotations/custom_references_with_SAM_segm/references_visualisations/`ã€‚\n\n| BIRD ğŸ¦ çš„ 1-shot åƒè€ƒåœ–åƒï¼ˆä½¿ç”¨ SAM è‡ªå‹•åˆ†å‰²ï¼‰ | BOAT â›µ çš„ 1-shot åƒè€ƒåœ–åƒï¼ˆä½¿ç”¨ SAM è‡ªå‹•åˆ†å‰²ï¼‰ |\n|:---------------------------------:|:----------------------------------:|\n| <img src=\"https://github.com/user-attachments/assets/65d38dc4-1454-43cd-9600-e8efc67b3a82\" alt=\"bird_1_with_SAM_segm\" width=\"500\"/> | <img src=\"https://github.com/user-attachments/assets/43a558ad-50ca-4715-8285-9aa3268843c6\" alt=\"boat_1_with_SAM_segm\" width=\"500\"/> |\n\n### 0.2 å°‡ coco æ¨™è¨»è½‰æ›ç‚º pickle æª”æ¡ˆ\n\n\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 36,
    "Content": "```bash\npython no_time_to_train/dataset/coco_to_pkl.py \\\n    data/my_custom_dataset/annotations/custom_references_with_segm.json \\\n    data/my_custom_dataset/annotations/custom_references_with_segm.pkl \\\n    1\n```",
    "ContentSha": "PSo9jaMX0pVKgHl0ecq9duQGpy1rMpXUU1iB4a8YzJM=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\npython no_time_to_train/dataset/coco_to_pkl.py \\\n    data/my_custom_dataset/annotations/custom_references_with_segm.json \\\n    data/my_custom_dataset/annotations/custom_references_with_segm.pkl \\\n    1\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 37,
    "Content": "\n### 1. Fill memory with references\n\nFirst, define useful variables and create a folder for results. For correct visualisation of labels, class names should be ordered by category id as appears in the json file. E.g. `bird` has category id `16`, `boat` has category id `9`. Thus, `CAT_NAMES=boat,bird`.\n",
    "ContentSha": "97iqG4pEnvNDE6ERpjfa2nL6RAtTIXJXwjJwqU/SNCg=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "### 1. ä»¥åƒè€ƒè³‡æ–™å¡«å……è¨˜æ†¶é«”\n\né¦–å…ˆï¼Œå®šç¾©æœ‰ç”¨çš„è®Šæ•¸ä¸¦å»ºç«‹ä¸€å€‹ç”¨æ–¼å„²å­˜çµæœçš„è³‡æ–™å¤¾ã€‚ç‚ºäº†æ­£ç¢ºé¡¯ç¤ºæ¨™ç±¤ï¼Œé¡åˆ¥åç¨±æ‡‰æŒ‰ç…§ json æª”æ¡ˆä¸­å‡ºç¾çš„é¡åˆ¥ id é †åºæ’åˆ—ã€‚ä¾‹å¦‚ï¼Œ`bird` çš„é¡åˆ¥ id ç‚º `16`ï¼Œ`boat` çš„é¡åˆ¥ id ç‚º `9`ã€‚å› æ­¤ï¼Œ`CAT_NAMES=boat,bird`ã€‚\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 38,
    "Content": "```bash\nDATASET_NAME=my_custom_dataset\nDATASET_PATH=data/my_custom_dataset\nCAT_NAMES=boat,bird\nCATEGORY_NUM=2\nSHOT=1\nYAML_PATH=no_time_to_train/pl_configs/matching_cdfsod_template.yaml\nPATH_TO_SAVE_CKPTS=./tmp_ckpts/my_custom_dataset\nmkdir -p $PATH_TO_SAVE_CKPTS\n```",
    "ContentSha": "mJIX4bJBaFbcwT8YfLR0V4w6qjU7MQEh3u6k2gtPrvw=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\nDATASET_NAME=my_custom_dataset\nDATASET_PATH=data/my_custom_dataset\nCAT_NAMES=boat,bird\nCATEGORY_NUM=2\nSHOT=1\nYAML_PATH=no_time_to_train/pl_configs/matching_cdfsod_template.yaml\nPATH_TO_SAVE_CKPTS=./tmp_ckpts/my_custom_dataset\nmkdir -p $PATH_TO_SAVE_CKPTS\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 39,
    "Content": "\nRun step 1:",
    "ContentSha": "PqClefvNhYLjlZsfjndNSKUJEy6R+goO4h/8KMDA1P0=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "åŸ·è¡Œæ­¥é©Ÿ 1ï¼š\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 40,
    "Content": "```bash\npython run_lightening.py test --config $YAML_PATH \\\n    --model.test_mode fill_memory \\\n    --out_path $PATH_TO_SAVE_CKPTS/$DATASET_NAME\\_$SHOT\\_refs_memory.pth \\\n    --model.init_args.dataset_cfgs.fill_memory.root $DATASET_PATH/images \\\n    --model.init_args.dataset_cfgs.fill_memory.json_file $DATASET_PATH/annotations/custom_references_with_segm.json \\\n    --model.init_args.dataset_cfgs.fill_memory.memory_pkl $DATASET_PATH/annotations/custom_references_with_segm.pkl \\\n    --model.init_args.dataset_cfgs.fill_memory.memory_length $SHOT \\\n    --model.init_args.dataset_cfgs.fill_memory.cat_names $CAT_NAMES \\\n    --model.init_args.model_cfg.dataset_name $DATASET_NAME \\\n    --model.init_args.model_cfg.memory_bank_cfg.length $SHOT \\\n    --model.init_args.model_cfg.memory_bank_cfg.category_num $CATEGORY_NUM \\\n    --trainer.devices 1\n```",
    "ContentSha": "wLZindeEKqrTUIIF55tL8lmaW4jWIZ2bdw6bj/1U9TU=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\npython run_lightening.py test --config $YAML_PATH \\\n    --model.test_mode fill_memory \\\n    --out_path $PATH_TO_SAVE_CKPTS/$DATASET_NAME\\_$SHOT\\_refs_memory.pth \\\n    --model.init_args.dataset_cfgs.fill_memory.root $DATASET_PATH/images \\\n    --model.init_args.dataset_cfgs.fill_memory.json_file $DATASET_PATH/annotations/custom_references_with_segm.json \\\n    --model.init_args.dataset_cfgs.fill_memory.memory_pkl $DATASET_PATH/annotations/custom_references_with_segm.pkl \\\n    --model.init_args.dataset_cfgs.fill_memory.memory_length $SHOT \\\n    --model.init_args.dataset_cfgs.fill_memory.cat_names $CAT_NAMES \\\n    --model.init_args.model_cfg.dataset_name $DATASET_NAME \\\n    --model.init_args.model_cfg.memory_bank_cfg.length $SHOT \\\n    --model.init_args.model_cfg.memory_bank_cfg.category_num $CATEGORY_NUM \\\n    --trainer.devices 1\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 41,
    "Content": "\n### 2. Post-process memory bank\n",
    "ContentSha": "39oOsuQIXM8TjT8ASLmZI0OpSbUSAT4d7YEHU7S2uqQ=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "### 2. å¾Œè™•ç†è¨˜æ†¶é«”åº«\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 42,
    "Content": "```bash\npython run_lightening.py test --config $YAML_PATH \\\n    --model.test_mode postprocess_memory \\\n    --ckpt_path $PATH_TO_SAVE_CKPTS/$DATASET_NAME\\_$SHOT\\_refs_memory.pth \\\n    --out_path $PATH_TO_SAVE_CKPTS/$DATASET_NAME\\_$SHOT\\_refs_memory_postprocessed.pth \\\n    --model.init_args.model_cfg.dataset_name $DATASET_NAME \\\n    --model.init_args.model_cfg.memory_bank_cfg.length $SHOT \\\n    --model.init_args.model_cfg.memory_bank_cfg.category_num $CATEGORY_NUM \\\n    --trainer.devices 1\n```",
    "ContentSha": "49JIaRecImNonhL7aGKB3JsAkgDw76Irci38QcuVb8k=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\npython run_lightening.py test --config $YAML_PATH \\\n    --model.test_mode postprocess_memory \\\n    --ckpt_path $PATH_TO_SAVE_CKPTS/$DATASET_NAME\\_$SHOT\\_refs_memory.pth \\\n    --out_path $PATH_TO_SAVE_CKPTS/$DATASET_NAME\\_$SHOT\\_refs_memory_postprocessed.pth \\\n    --model.init_args.model_cfg.dataset_name $DATASET_NAME \\\n    --model.init_args.model_cfg.memory_bank_cfg.length $SHOT \\\n    --model.init_args.model_cfg.memory_bank_cfg.category_num $CATEGORY_NUM \\\n    --trainer.devices 1\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 43,
    "Content": "\n#### 2.1 Visualise post-processed memory bank\n",
    "ContentSha": "Pz+UrI1n9P9i9DChpNd/m3unfj17ZqVz3PnHMyK+5XU=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "\n#### 2.1 è¦–è¦ºåŒ–å¾Œè™•ç†è¨˜æ†¶é«”åº«\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 2,
        "rowsha": "zA9xPuN6grCmDtzemkhLkPyW7qI+l8F89v7W60063mQ=",
        "originContent": "#### 2.1 Visualise post-processed memory bank",
        "translatedContent": "#### 2.1 è¦–è¦ºåŒ–å¾Œè™•ç†è¨˜æ†¶é«”åº«"
      },
      {
        "row": 3,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 44,
    "Content": "```bash\npython run_lightening.py test --config $YAML_PATH \\\n    --model.test_mode vis_memory \\\n    --ckpt_path $PATH_TO_SAVE_CKPTS/$DATASET_NAME\\_$SHOT\\_refs_memory_postprocessed.pth \\\n    --model.init_args.dataset_cfgs.fill_memory.root $DATASET_PATH/images \\\n    --model.init_args.dataset_cfgs.fill_memory.json_file $DATASET_PATH/annotations/custom_references_with_segm.json \\\n    --model.init_args.dataset_cfgs.fill_memory.memory_pkl $DATASET_PATH/annotations/custom_references_with_segm.pkl \\\n    --model.init_args.dataset_cfgs.fill_memory.memory_length $SHOT \\\n    --model.init_args.dataset_cfgs.fill_memory.cat_names $CAT_NAMES \\\n    --model.init_args.model_cfg.dataset_name $DATASET_NAME \\\n    --model.init_args.model_cfg.memory_bank_cfg.length $SHOT \\\n    --model.init_args.model_cfg.memory_bank_cfg.category_num $CATEGORY_NUM \\\n    --trainer.devices 1\n```",
    "ContentSha": "2C9ilXiP+W/SLak7O3FNtKLBBgCCWOswHD8qb+mug1w=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\npython run_lightening.py test --config $YAML_PATH \\\n    --model.test_mode vis_memory \\\n    --ckpt_path $PATH_TO_SAVE_CKPTS/$DATASET_NAME\\_$SHOT\\_refs_memory_postprocessed.pth \\\n    --model.init_args.dataset_cfgs.fill_memory.root $DATASET_PATH/images \\\n    --model.init_args.dataset_cfgs.fill_memory.json_file $DATASET_PATH/annotations/custom_references_with_segm.json \\\n    --model.init_args.dataset_cfgs.fill_memory.memory_pkl $DATASET_PATH/annotations/custom_references_with_segm.pkl \\\n    --model.init_args.dataset_cfgs.fill_memory.memory_length $SHOT \\\n    --model.init_args.dataset_cfgs.fill_memory.cat_names $CAT_NAMES \\\n    --model.init_args.model_cfg.dataset_name $DATASET_NAME \\\n    --model.init_args.model_cfg.memory_bank_cfg.length $SHOT \\\n    --model.init_args.model_cfg.memory_bank_cfg.category_num $CATEGORY_NUM \\\n    --trainer.devices 1\n```",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "rTMjNc+qNIxb1xXDR5hEYiJw1fc4muBwuBsTXVIaIho=",
        "originContent": "```bash",
        "translatedContent": "```bash"
      },
      {
        "row": 2,
        "rowsha": "3ETYk+lXCmWw9FFEJ+wILd+zQZjjy0tb7XEaA2ooWes=",
        "originContent": "python run_lightening.py test --config $YAML_PATH \\",
        "translatedContent": "python run_lightening.py test --config $YAML_PATH \\"
      },
      {
        "row": 3,
        "rowsha": "sv7jXy1+zlYZ8hhMVNvjEq7J8BT4RkJJ2afn2CFyHyk=",
        "originContent": "    --model.test_mode vis_memory \\",
        "translatedContent": "    --model.test_mode vis_memory \\"
      },
      {
        "row": 4,
        "rowsha": "YaLMccWSufRiTsk+GoOYdBhkbklyP1j280Pi7lKtRsc=",
        "originContent": "    --ckpt_path $PATH_TO_SAVE_CKPTS/$DATASET_NAME\\_$SHOT\\_refs_memory_postprocessed.pth \\",
        "translatedContent": "    --ckpt_path $PATH_TO_SAVE_CKPTS/$DATASET_NAME\\_$SHOT\\_refs_memory_postprocessed.pth \\"
      },
      {
        "row": 5,
        "rowsha": "+BumbXTQ220P4SshjpoA32nDp/jwiCWbKFKYVi5RYXc=",
        "originContent": "    --model.init_args.dataset_cfgs.fill_memory.root $DATASET_PATH/images \\",
        "translatedContent": "    --model.init_args.dataset_cfgs.fill_memory.root $DATASET_PATH/images \\"
      },
      {
        "row": 6,
        "rowsha": "0QT7QmjYkqhfRshvsrRJCFd1cBt2OEEaPr2ax0WhEPA=",
        "originContent": "    --model.init_args.dataset_cfgs.fill_memory.json_file $DATASET_PATH/annotations/custom_references_with_segm.json \\",
        "translatedContent": "    --model.init_args.dataset_cfgs.fill_memory.json_file $DATASET_PATH/annotations/custom_references_with_segm.json \\"
      },
      {
        "row": 7,
        "rowsha": "SWrctgl0L7Kdk4nV2WBDVityuZNXBo7ZP3vjpFq3q+Y=",
        "originContent": "    --model.init_args.dataset_cfgs.fill_memory.memory_pkl $DATASET_PATH/annotations/custom_references_with_segm.pkl \\",
        "translatedContent": "    --model.init_args.dataset_cfgs.fill_memory.memory_pkl $DATASET_PATH/annotations/custom_references_with_segm.pkl \\"
      },
      {
        "row": 8,
        "rowsha": "ajwBbsJuNblaKhLCmbsz4NzIAKPocJiMx8opaUw7JHc=",
        "originContent": "    --model.init_args.dataset_cfgs.fill_memory.memory_length $SHOT \\",
        "translatedContent": "    --model.init_args.dataset_cfgs.fill_memory.memory_length $SHOT \\"
      },
      {
        "row": 9,
        "rowsha": "CMOv5nGBSogT0gO7wMGjvPW4XkomwTa82Tj0iD9Y3FQ=",
        "originContent": "    --model.init_args.dataset_cfgs.fill_memory.cat_names $CAT_NAMES \\",
        "translatedContent": "    --model.init_args.dataset_cfgs.fill_memory.cat_names $CAT_NAMES \\"
      },
      {
        "row": 10,
        "rowsha": "kjbTFgGn3Au3NL6CMgQDK2RpX6DraWPljNvBjaZwD/Q=",
        "originContent": "    --model.init_args.model_cfg.dataset_name $DATASET_NAME \\",
        "translatedContent": "    --model.init_args.model_cfg.dataset_name $DATASET_NAME \\"
      },
      {
        "row": 11,
        "rowsha": "I/do2Okczknn/9X/8y5Tan5Adh+bBdjM83mpNMTgU1Q=",
        "originContent": "    --model.init_args.model_cfg.memory_bank_cfg.length $SHOT \\",
        "translatedContent": "    --model.init_args.model_cfg.memory_bank_cfg.length $SHOT \\"
      },
      {
        "row": 12,
        "rowsha": "7Cn+uZ9khgahObEB4bul8QUBZse0UStnwto6jY94u64=",
        "originContent": "    --model.init_args.model_cfg.memory_bank_cfg.category_num $CATEGORY_NUM \\",
        "translatedContent": "    --model.init_args.model_cfg.memory_bank_cfg.category_num $CATEGORY_NUM \\"
      },
      {
        "row": 13,
        "rowsha": "MaGbj/BQoWys9ayvwnfa9LJa4GU85A541/zZC+Xlgzo=",
        "originContent": "    --trainer.devices 1",
        "translatedContent": "    --trainer.devices 1"
      },
      {
        "row": 14,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      }
    ],
    "IsCodeBlock": true
  },
  {
    "Id": 45,
    "Content": "PCA and K-means visualisations for the memory bank images are stored in `results_analysis/memory_vis/my_custom_dataset`.\n\n### 3. Inference on target images\n\nIf `ONLINE_VIS` is set to True, prediction results will be saved in `results_analysis/my_custom_dataset/` and displayed as they are computed. NOTE that running with online visualisation is much slower.\n\nFeel free to change the score threshold `VIS_THR` to see more or less segmented instances.",
    "ContentSha": "4E7c2MViriAoxOfwY+eeCB/D3hPi2EsbE37pTJqGFn8=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "è¨˜æ†¶åº«å½±åƒçš„ PCA åŠ K-means è¦–è¦ºåŒ–çµæœå„²å­˜åœ¨ `results_analysis/memory_vis/my_custom_dataset`ã€‚\n\n### 3. å°ç›®æ¨™å½±åƒé€²è¡Œæ¨è«–\n\nå¦‚æœå°‡ `ONLINE_VIS` è¨­ç‚º Trueï¼Œé æ¸¬çµæœæœƒå„²å­˜åœ¨ `results_analysis/my_custom_dataset/`ï¼Œä¸¦åœ¨è¨ˆç®—æ™‚å³æ™‚é¡¯ç¤ºã€‚è«‹æ³¨æ„ï¼Œé–‹å•Ÿå³æ™‚è¦–è¦ºåŒ–æœƒå¤§å¹…é™ä½é‹è¡Œé€Ÿåº¦ã€‚\n\næ­¡è¿èª¿æ•´åˆ†æ•¸é–¾å€¼ `VIS_THR`ï¼Œä»¥æŸ¥çœ‹æ›´å¤šæˆ–æ›´å°‘åˆ†å‰²çš„å¯¦ä¾‹ã€‚",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "v06/j8pVoIsYKBBWpbMfxpIB8qMIcJbM2tdkKJl/cIE=",
        "originContent": "PCA and K-means visualisations for the memory bank images are stored in `results_analysis/memory_vis/my_custom_dataset`.",
        "translatedContent": "è¨˜æ†¶åº«å½±åƒçš„ PCA åŠ K-means è¦–è¦ºåŒ–çµæœå„²å­˜åœ¨ `results_analysis/memory_vis/my_custom_dataset`ã€‚"
      },
      {
        "row": 2,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 3,
        "rowsha": "mgJPj3vIyTELe8bZmHn4RAZnA8e/rUDydk+y7d9nDPM=",
        "originContent": "### 3. Inference on target images",
        "translatedContent": "### 3. å°ç›®æ¨™å½±åƒé€²è¡Œæ¨è«–"
      },
      {
        "row": 4,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 5,
        "rowsha": "YM++GYWJ+d+mCXMS9tSUVlwWGrHkv3G/JLx27lurQ0U=",
        "originContent": "If `ONLINE_VIS` is set to True, prediction results will be saved in `results_analysis/my_custom_dataset/` and displayed as they are computed. NOTE that running with online visualisation is much slower.",
        "translatedContent": "å¦‚æœå°‡ `ONLINE_VIS` è¨­ç‚º Trueï¼Œé æ¸¬çµæœæœƒå„²å­˜åœ¨ `results_analysis/my_custom_dataset/`ï¼Œä¸¦åœ¨è¨ˆç®—æ™‚å³æ™‚é¡¯ç¤ºã€‚è«‹æ³¨æ„ï¼Œé–‹å•Ÿå³æ™‚è¦–è¦ºåŒ–æœƒå¤§å¹…é™ä½é‹è¡Œé€Ÿåº¦ã€‚"
      },
      {
        "row": 6,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 7,
        "rowsha": "XNhHBadyh3RCBpAmQ14NYnkh3kQ6nLbAWUU5I0lwtn8=",
        "originContent": "Feel free to change the score threshold `VIS_THR` to see more or less segmented instances.",
        "translatedContent": "æ­¡è¿èª¿æ•´åˆ†æ•¸é–¾å€¼ `VIS_THR`ï¼Œä»¥æŸ¥çœ‹æ›´å¤šæˆ–æ›´å°‘åˆ†å‰²çš„å¯¦ä¾‹ã€‚"
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 46,
    "Content": "```bash\nONLINE_VIS=True\nVIS_THR=0.4\npython run_lightening.py test --config $YAML_PATH \\\n    --model.test_mode test \\\n    --ckpt_path $PATH_TO_SAVE_CKPTS/$DATASET_NAME\\_$SHOT\\_refs_memory_postprocessed.pth \\\n    --model.init_args.model_cfg.dataset_name $DATASET_NAME \\\n    --model.init_args.model_cfg.memory_bank_cfg.length $SHOT \\\n    --model.init_args.model_cfg.memory_bank_cfg.category_num $CATEGORY_NUM \\\n    --model.init_args.model_cfg.test.imgs_path $DATASET_PATH/images \\\n    --model.init_args.model_cfg.test.online_vis $ONLINE_VIS \\\n    --model.init_args.model_cfg.test.vis_thr $VIS_THR \\\n    --model.init_args.dataset_cfgs.test.root $DATASET_PATH/images \\\n    --model.init_args.dataset_cfgs.test.json_file $DATASET_PATH/annotations/custom_targets.json \\\n    --model.init_args.dataset_cfgs.test.cat_names $CAT_NAMES \\\n    --trainer.devices 1\n```",
    "ContentSha": "WwpzFHhc6G71aipZFN/unoGoH913SXlW3RG98ipcK1k=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\nONLINE_VIS=True\nVIS_THR=0.4\npython run_lightening.py test --config $YAML_PATH \\\n    --model.test_mode test \\\n    --ckpt_path $PATH_TO_SAVE_CKPTS/$DATASET_NAME\\_$SHOT\\_refs_memory_postprocessed.pth \\\n    --model.init_args.model_cfg.dataset_name $DATASET_NAME \\\n    --model.init_args.model_cfg.memory_bank_cfg.length $SHOT \\\n    --model.init_args.model_cfg.memory_bank_cfg.category_num $CATEGORY_NUM \\\n    --model.init_args.model_cfg.test.imgs_path $DATASET_PATH/images \\\n    --model.init_args.model_cfg.test.online_vis $ONLINE_VIS \\\n    --model.init_args.model_cfg.test.vis_thr $VIS_THR \\\n    --model.init_args.dataset_cfgs.test.root $DATASET_PATH/images \\\n    --model.init_args.dataset_cfgs.test.json_file $DATASET_PATH/annotations/custom_targets.json \\\n    --model.init_args.dataset_cfgs.test.cat_names $CAT_NAMES \\\n    --trainer.devices 1\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 47,
    "Content": "\n### Results\n\nPerformance metrics (with the exact same parameters as commands above) should be:\n",
    "ContentSha": "qUh629YPJLLYOXeHGSusGSWIYdfgfMGmHPttF+Zq0tU=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "### çµæœ\n\næ€§èƒ½æŒ‡æ¨™ï¼ˆä½¿ç”¨èˆ‡ä¸Šè¿°æŒ‡ä»¤å®Œå…¨ç›¸åŒçš„åƒæ•¸ï¼‰æ‡‰å¦‚ä¸‹æ‰€ç¤ºï¼š\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 48,
    "Content": "```\nBBOX RESULTS:\n  Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.478\n\nSEGM RESULTS:\n  Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.458\n```",
    "ContentSha": "EqM8BsGgWhI+q5ZgXp4DOk8Wayw3iQnYToBVZntlyVI=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```\nBBOX RESULTS:\n  Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.478\n\nSEGM RESULTS:\n  Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.458\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 49,
    "Content": "\nVisual results are saved in `results_analysis/my_custom_dataset/`. Note that our method works for false negatives, that is, images that do not contain any instances of the desired classes.\n\n*Click images to enlarge â¬‡ï¸*\n\n| Target image with boats â›µ (left GT, right predictions) | Target image with birds ğŸ¦ (left GT, right predictions) |\n|:----------------------:|:----------------------:|\n| ![000000459673](https://github.com/user-attachments/assets/678dc15a-dd3b-49d5-9287-6290da16aa6b) | ![000000407180](https://github.com/user-attachments/assets/fe306e48-af49-4d83-ac82-76fac6c456d1) |\n\n| Target image with boats and birds â›µğŸ¦ (left GT, right predictions) | Target image without boats or birds ğŸš« (left GT, right predictions) |\n|:---------------------------------:|:----------------------------------:|\n| ![000000517410](https://github.com/user-attachments/assets/9849b227-7f43-43d7-81ea-58010a623ad5) | ![000000460598](https://github.com/user-attachments/assets/7587700c-e09d-4cf6-8590-3df129c2568e) |\n\n\n## ğŸ“š Citation\n\nIf you use this work, please cite us:\n",
    "ContentSha": "tEYR4ra1661R2TKfAxblzhr7EHrPwy5JI69dHQuD/mM=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "è¦–è¦ºçµæœå·²å„²å­˜åœ¨ `results_analysis/my_custom_dataset/`ã€‚è«‹æ³¨æ„ï¼Œæˆ‘å€‘çš„æ–¹æ³•é©ç”¨æ–¼å½é™°æ€§ï¼Œä¹Ÿå°±æ˜¯é‚£äº›ä¸åŒ…å«ä»»ä½•ç›®æ¨™é¡åˆ¥å¯¦ä¾‹çš„å½±åƒã€‚\n\n*é»æ“Šåœ–ç‰‡ä»¥æ”¾å¤§ â¬‡ï¸*\n\n| å«æœ‰èˆ¹éš»çš„ç›®æ¨™å½±åƒ â›µï¼ˆå·¦ç‚ºGTï¼Œå³ç‚ºé æ¸¬ï¼‰ | å«æœ‰é³¥é¡çš„ç›®æ¨™å½±åƒ ğŸ¦ï¼ˆå·¦ç‚ºGTï¼Œå³ç‚ºé æ¸¬ï¼‰ |\n|:----------------------:|:----------------------:|\n| ![000000459673](https://github.com/user-attachments/assets/678dc15a-dd3b-49d5-9287-6290da16aa6b) | ![000000407180](https://github.com/user-attachments/assets/fe306e48-af49-4d83-ac82-76fac6c456d1) |\n\n| å«æœ‰èˆ¹éš»èˆ‡é³¥é¡çš„ç›®æ¨™å½±åƒ â›µğŸ¦ï¼ˆå·¦ç‚ºGTï¼Œå³ç‚ºé æ¸¬ï¼‰ | ä¸å«èˆ¹éš»æˆ–é³¥é¡çš„ç›®æ¨™å½±åƒ ğŸš«ï¼ˆå·¦ç‚ºGTï¼Œå³ç‚ºé æ¸¬ï¼‰ |\n|:---------------------------------:|:----------------------------------:|\n| ![000000517410](https://github.com/user-attachments/assets/9849b227-7f43-43d7-81ea-58010a623ad5) | ![000000460598](https://github.com/user-attachments/assets/7587700c-e09d-4cf6-8590-3df129c2568e) |\n\n\n## ğŸ“š å¼•ç”¨\n\nå¦‚æœæ‚¨ä½¿ç”¨æœ¬ç ”ç©¶ï¼Œè«‹å¼•ç”¨æˆ‘å€‘ï¼š\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 50,
    "Content": "```bibtex\n@article{espinosa2025notimetotrain,\n  title={No time to train! Training-Free Reference-Based Instance Segmentation},\n  author={Miguel Espinosa and Chenhongyi Yang and Linus Ericsson and Steven McDonagh and Elliot J. Crowley},\n  journal={arXiv preprint arXiv:2507.02798},\n  year={2025},\n  primaryclass={cs.CV}\n}\n```",
    "ContentSha": "wkySuPRHWTRGorn0rwSBqyUnW5RNg9LVe0O7npcbKSs=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bibtex\n@article{espinosa2025notimetotrain,\n  title={No time to train! Training-Free Reference-Based Instance Segmentation},\n  author={Miguel Espinosa and Chenhongyi Yang and Linus Ericsson and Steven McDonagh and Elliot J. Crowley},\n  journal={arXiv preprint arXiv:2507.02798},\n  year={2025},\n  primaryclass={cs.CV}\n}\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 51,
    "Content": "",
    "ContentSha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  }
]