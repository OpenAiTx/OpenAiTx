[
  {
    "Id": 1,
    "Content": "\n<div align=\"right\">\n  <details>\n    <summary >ğŸŒ Language</summary>\n    <div>\n      <div align=\"center\">\n        <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=en\">English</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=zh-CN\">ç®€ä½“ä¸­æ–‡</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=zh-TW\">ç¹é«”ä¸­æ–‡</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=ja\">æ—¥æœ¬èª</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=ko\">í•œêµ­ì–´</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=hi\">à¤¹à¤¿à¤¨à¥à¤¦à¥€</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=th\">à¹„à¸—à¸¢</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=fr\">FranÃ§ais</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=de\">Deutsch</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=es\">EspaÃ±ol</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=it\">Italiano</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=ru\">Ğ ÑƒÑÑĞºĞ¸Ğ¹</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=pt\">PortuguÃªs</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=nl\">Nederlands</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=pl\">Polski</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=ar\">Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=fa\">ÙØ§Ø±Ø³ÛŒ</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=tr\">TÃ¼rkÃ§e</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=vi\">Tiáº¿ng Viá»‡t</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=id\">Bahasa Indonesia</a>\n      </div>\n    </div>\n  </details>\n</div>\n\n<div align=\"center\">\n\n# ğŸš€ No Time to Train!  \n### Training-Free Reference-Based Instance Segmentation  \n[![GitHub](https://img.shields.io/badge/%E2%80%8B-No%20Time%20To%20Train-black?logo=github)](https://github.com/miquel-espinosa/no-time-to-train)\n[![Website](https://img.shields.io/badge/ğŸŒ-Project%20Page-grey)](https://miquel-espinosa.github.io/no-time-to-train/)\n[![arXiv](https://img.shields.io/badge/arXiv-2507.02798-b31b1b)](https://arxiv.org/abs/2507.02798)\n\n**State-of-the-art (Papers with Code)**",
    "ContentSha": "lG1vuwmuqLt4d95/PBMz1H5HG0r+JfvC/FVnqNQvTnM=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "\n<div align=\"right\">\n  <details>\n    <summary >ğŸŒ è¨€èª</summary>\n    <div>\n      <div align=\"center\">\n        <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=en\">English</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=zh-CN\">ç®€ä½“ä¸­æ–‡</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=zh-TW\">ç¹é«”ä¸­æ–‡</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=ja\">æ—¥æœ¬èª</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=ko\">í•œêµ­ì–´</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=hi\">à¤¹à¤¿à¤¨à¥à¤¦à¥€</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=th\">à¹„à¸—à¸¢</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=fr\">FranÃ§ais</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=de\">Deutsch</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=es\">EspaÃ±ol</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=it\">Italiano</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=ru\">Ğ ÑƒÑÑĞºĞ¸Ğ¹</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=pt\">PortuguÃªs</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=nl\">Nederlands</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=pl\">Polski</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=ar\">Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=fa\">ÙØ§Ø±Ø³ÛŒ</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=tr\">TÃ¼rkÃ§e</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=vi\">Tiáº¿ng Viá»‡t</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=id\">Bahasa Indonesia</a>\n      </div>\n    </div>\n  </details>\n</div>\n\n<div align=\"center\">\n\n# ğŸš€ ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹æ™‚é–“ãŒãªã„ï¼  \n### ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¸è¦ãªãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹ãƒ™ãƒ¼ã‚¹ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³  \n[![GitHub](https://img.shields.io/badge/%E2%80%8B-No%20Time%20To%20Train-black?logo=github)](https://github.com/miquel-espinosa/no-time-to-train)\n[![Website](https://img.shields.io/badge/ğŸŒ-Project%20Page-grey)](https://miquel-espinosa.github.io/no-time-to-train/)\n[![arXiv](https://img.shields.io/badge/arXiv-2507.02798-b31b1b)](https://arxiv.org/abs/2507.02798)\n\n**æœ€å…ˆç«¯ï¼ˆPapers with Codeï¼‰**",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 2,
    "Content": "\n[**_SOTA 1-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-1-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/badge/State%20of%20the%20Art-Few--Shot%20Object%20Detection%20on%20MS--COCO%20(1--shot)-21CBCE?style=flat&logo=paperswithcode)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-1-shot?p=no-time-to-train-training-free-reference)\n\n[**_SOTA 10-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-10-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/badge/State%20of%20the%20Art-Few--Shot%20Object%20Detection%20on%20MS--COCO%20(10--shot)-21CBCE?style=flat&logo=paperswithcode)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-10-shot?p=no-time-to-train-training-free-reference)\n\n[**_SOTA 30-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-30-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/badge/State%20of%20the%20Art-Few--Shot%20Object%20Detection%20on%20MS--COCO%20(30--shot)-21CBCE?style=flat&logo=paperswithcode)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-30-shot?p=no-time-to-train-training-free-reference)\n\n<!-- [**_SOTA 1-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-1-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/no-time-to-train-training-free-reference/few-shot-object-detection-on-ms-coco-1-shot)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-1-shot?p=no-time-to-train-training-free-reference)\n\n[**_SOTA 10-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-10-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/no-time-to-train-training-free-reference/few-shot-object-detection-on-ms-coco-10-shot)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-10-shot?p=no-time-to-train-training-free-reference)\n\n[**_SOTA 30-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-30-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/no-time-to-train-training-free-reference/few-shot-object-detection-on-ms-coco-30-shot)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-30-shot?p=no-time-to-train-training-free-reference) -->\n\n</div>\n\n---\n\n> ğŸš¨ **Update (22nd July 2025):** Instructions for custom datasets have been added!\n> \n> ğŸ”” **Update (16th July 2025):** Code has been updated with instructions!\n\n---\n\n## ğŸ“‹ Table of Contents\n\n- [ğŸ¯ Highlights](#-highlights)\n- [ğŸ“œ Abstract](#-abstract)\n- [ğŸ§  Architecture](#-architecture)\n- [ğŸ› ï¸ Installation instructions](#ï¸-installation-instructions)\n  - [1. Clone the repository](#1-clone-the-repository)\n  - [2. Create conda environment](#2-create-conda-environment)\n  - [3. Install SAM2 and DinoV2](#3-install-sam2-and-dinov2)\n  - [4. Download datasets](#4-download-datasets)\n  - [5. Download SAM2 and DinoV2 checkpoints](#5-download-sam2-and-dinov2-checkpoints)\n- [ğŸ“Š Inference code: Reproduce 30-shot SOTA results in Few-shot COCO](#-inference-code)\n  - [0. Create reference set](#0-create-reference-set)\n  - [1. Fill memory with references](#1-fill-memory-with-references)\n  - [2. Post-process memory bank](#2-post-process-memory-bank)\n  - [3. Inference on target images](#3-inference-on-target-images)\n  - [Results](#results)",
    "ContentSha": "+yQ5ol79RNsk2le3no6dLpgaMzuy0Nh4xdRCmVNp8FE=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "[**_SOTA 1-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-1-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/badge/State%20of%20the%20Art-Few--Shot%20Object%20Detection%20on%20MS--COCO%20(1--shot)-21CBCE?style=flat&logo=paperswithcode)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-1-shot?p=no-time-to-train-training-free-reference)\n\n[**_SOTA 10-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-10-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/badge/State%20of%20the%20Art-Few--Shot%20Object%20Detection%20on%20MS--COCO%20(10--shot)-21CBCE?style=flat&logo=paperswithcode)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-10-shot?p=no-time-to-train-training-free-reference)\n\n[**_SOTA 30-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-30-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/badge/State%20of%20the%20Art-Few--Shot%20Object%20Detection%20on%20MS--COCO%20(30--shot)-21CBCE?style=flat&logo=paperswithcode)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-30-shot?p=no-time-to-train-training-free-reference)\n\n<!-- [**_SOTA 1-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-1-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/no-time-to-train-training-free-reference/few-shot-object-detection-on-ms-coco-1-shot)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-1-shot?p=no-time-to-train-training-free-reference)\n\n[**_SOTA 10-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-10-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/no-time-to-train-training-free-reference/few-shot-object-detection-on-ms-coco-10-shot)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-10-shot?p=no-time-to-train-training-free-reference)\n\n[**_SOTA 30-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-30-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/no-time-to-train-training-free-reference/few-shot-object-detection-on-ms-coco-30-shot)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-30-shot?p=no-time-to-train-training-free-reference) -->\n\n</div>\n\n---\n\n> ğŸš¨ **æ›´æ–° (2025å¹´7æœˆ22æ—¥):** ã‚«ã‚¹ã‚¿ãƒ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æ‰‹é †ãŒè¿½åŠ ã•ã‚Œã¾ã—ãŸï¼\n> \n> ğŸ”” **æ›´æ–° (2025å¹´7æœˆ16æ—¥):** ã‚³ãƒ¼ãƒ‰ãŒæ‰‹é †ä»˜ãã§æ›´æ–°ã•ã‚Œã¾ã—ãŸï¼\n\n---\n\n## ğŸ“‹ ç›®æ¬¡\n\n- [ğŸ¯ ãƒã‚¤ãƒ©ã‚¤ãƒˆ](#-highlights)\n- [ğŸ“œ ã‚¢ãƒ–ã‚¹ãƒˆãƒ©ã‚¯ãƒˆ](#-abstract)\n- [ğŸ§  ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£](#-architecture)\n- [ğŸ› ï¸ ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ‰‹é †](#ï¸-installation-instructions)\n  - [1. ãƒªãƒã‚¸ãƒˆãƒªã®ã‚¯ãƒ­ãƒ¼ãƒ³](#1-clone-the-repository)\n  - [2. condaç’°å¢ƒã®ä½œæˆ](#2-create-conda-environment)\n  - [3. SAM2ã¨DinoV2ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«](#3-install-sam2-and-dinov2)\n  - [4. ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰](#4-download-datasets)\n  - [5. SAM2ã¨DinoV2ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰](#5-download-sam2-and-dinov2-checkpoints)\n- [ğŸ“Š æ¨è«–ã‚³ãƒ¼ãƒ‰ï¼šFew-shot COCOã§30-shot SOTAçµæœã®å†ç¾](#-inference-code)\n  - [0. å‚ç…§ã‚»ãƒƒãƒˆã®ä½œæˆ](#0-create-reference-set)\n  - [1. ãƒ¡ãƒ¢ãƒªã«å‚ç…§ã‚’æ ¼ç´](#1-fill-memory-with-references)\n  - [2. ãƒ¡ãƒ¢ãƒªãƒãƒ³ã‚¯ã®å¾Œå‡¦ç†](#2-post-process-memory-bank)\n  - [3. ã‚¿ãƒ¼ã‚²ãƒƒãƒˆç”»åƒã§æ¨è«–](#3-inference-on-target-images)\n  - [çµæœ](#results)\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 3,
    "Content": "- [ğŸ” Custom dataset](#-custom-dataset)\n  - [0. Prepare a custom dataset â›µğŸ¦](#0-prepare-a-custom-dataset)\n  - [0.1 If only bbox annotations are available](#01-if-only-bbox-annotations-are-available)\n  - [0.2 Convert coco annotations to pickle file](#02-convert-coco-annotations-to-pickle-file)\n  - [1. Fill memory with references](#1-fill-memory-with-references)\n  - [2. Post-process memory bank](#2-post-process-memory-bank)\n- [ğŸ“š Citation](#-citation)\n\n\n## ğŸ¯ Highlights\n- ğŸ’¡ **Training-Free**: No fine-tuning, no prompt engineeringâ€”just a reference image.  \n- ğŸ–¼ï¸ **Reference-Based**: Segment new objects using just a few examples.  \n- ğŸ”¥ **SOTA Performance**: Outperforms previous training-free approaches on COCO, PASCAL VOC, and Cross-Domain FSOD.\n\n**Links:**\n- ğŸ§¾ [**arXiv Paper**](https://arxiv.org/abs/2507.02798)  \n- ğŸŒ [**Project Website**](https://miquel-espinosa.github.io/no-time-to-train/)  \n- ğŸ“ˆ [**Papers with Code**](https://paperswithcode.com/paper/no-time-to-train-training-free-reference)\n\n## ğŸ“œ Abstract\n",
    "ContentSha": "HKE5vt8IwUJiOubYYPHCrRXZ3fqCpGqVFP3Xj5VV+p4=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "- [ğŸ” ã‚«ã‚¹ã‚¿ãƒ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ](#-custom-dataset)\n  - [0. ã‚«ã‚¹ã‚¿ãƒ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æº–å‚™ â›µğŸ¦](#0-prepare-a-custom-dataset)\n  - [0.1 ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã®ã¿åˆ©ç”¨å¯èƒ½ãªå ´åˆ](#01-if-only-bbox-annotations-are-available)\n  - [0.2 COCOã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’pickleãƒ•ã‚¡ã‚¤ãƒ«ã«å¤‰æ›](#02-convert-coco-annotations-to-pickle-file)\n  - [1. ãƒ¡ãƒ¢ãƒªã«å‚ç…§ã‚’æ ¼ç´](#1-fill-memory-with-references)\n  - [2. ãƒ¡ãƒ¢ãƒªãƒãƒ³ã‚¯ã®å¾Œå‡¦ç†](#2-post-process-memory-bank)\n- [ğŸ“š å¼•ç”¨](#-citation)\n\n\n## ğŸ¯ ãƒã‚¤ãƒ©ã‚¤ãƒˆ\n- ğŸ’¡ **å­¦ç¿’ä¸è¦**: ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚‚ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­è¨ˆã‚‚ä¸è¦â€•â€•å‚ç…§ç”»åƒã®ã¿ã€‚  \n- ğŸ–¼ï¸ **å‚ç…§ãƒ™ãƒ¼ã‚¹**: å°‘æ•°ã®ä¾‹ã ã‘ã§æ–°è¦ç‰©ä½“ã‚’ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã€‚  \n- ğŸ”¥ **SOTAæ€§èƒ½**: COCOã€PASCAL VOCã€Cross-Domain FSODã«ã¦å¾“æ¥ã®å­¦ç¿’ä¸è¦æ‰‹æ³•ã‚’ä¸Šå›ã‚‹ã€‚\n\n**ãƒªãƒ³ã‚¯:**\n- ğŸ§¾ [**arXivè«–æ–‡**](https://arxiv.org/abs/2507.02798)  \n- ğŸŒ [**ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆWebã‚µã‚¤ãƒˆ**](https://miquel-espinosa.github.io/no-time-to-train/)  \n- ğŸ“ˆ [**Papers with Code**](https://paperswithcode.com/paper/no-time-to-train-training-free-reference)\n\n## ğŸ“œ ã‚¢ãƒ–ã‚¹ãƒˆãƒ©ã‚¯ãƒˆ\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 4,
    "Content": "> The performance of image segmentation models has historically been constrained by the high cost of collecting large-scale annotated data. The Segment Anything Model (SAM) alleviates this original problem through a promptable, semantics-agnostic, segmentation paradigm and yet still requires manual visual-prompts or complex domain-dependent prompt-generation rules to process a new image. Towards reducing this new burden, our work investigates the task of object segmentation when provided with, alternatively, only a small set of reference images. Our key insight is to leverage strong semantic priors, as learned by foundation models, to identify corresponding regions between a reference and a target image. We find that correspondences enable automatic generation of instance-level segmentation masks for downstream tasks and instantiate our ideas via a multi-stage, training-free method incorporating (1) memory bank construction; (2) representation aggregation and (3) semantic-aware feature matching. Our experiments show significant improvements on segmentation metrics, leading to state-of-the-art performance on COCO FSOD (36.8% nAP), PASCAL VOC Few-Shot (71.2% nAP50) and outperforming existing training-free approaches on the Cross-Domain FSOD benchmark (22.4% nAP).",
    "ContentSha": "f62KYkH46xSV0RKRpAlERSF/nhSETk2RE3WyAIz5gDw=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "> The performance of image segmentation models has historically been constrained by the high cost of collecting large-scale annotated data. The Segment Anything Model (SAM) alleviates this original problem through a promptable, semantics-agnostic, segmentation paradigm and yet still requires manual visual-prompts or complex domain-dependent prompt-generation rules to process a new image. Towards reducing this new burden, our work investigates the task of object segmentation when provided with, alternatively, only a small set of reference images. Our key insight is to leverage strong semantic priors, as learned by foundation models, to identify corresponding regions between a reference and a target image. We find that correspondences enable automatic generation of instance-level segmentation masks for downstream tasks and instantiate our ideas via a multi-stage, training-free method incorporating (1) memory bank construction; (2) representation aggregation and (3) semantic-aware feature matching. Our experiments show significant improvements on segmentation metrics, leading to state-of-the-art performance on COCO FSOD (36.8% nAP), PASCAL VOC Few-Shot (71.2% nAP50) and outperforming existing training-free approaches on the Cross-Domain FSOD benchmark (22.4% nAP).",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 5,
    "Content": "\n![cdfsod-results-final-comic-sans-min](https://github.com/user-attachments/assets/ab302c02-c080-4042-99fc-0e181ba8abb9)\n\n\n## ğŸ§  Architecture\n\n![training-free-architecture-comic-sans-min](https://github.com/user-attachments/assets/d84dd83a-505e-45a0-8ce3-98e1838017f9)\n\n\n## ğŸ› ï¸ Installation instructions\n\n### 1. Clone the repository\n",
    "ContentSha": "V4xbbzEUhNFOhqp3BaqWeY1MaXeaFR8RD3QR6DHJiVo=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "\n![cdfsod-results-final-comic-sans-min](https://github.com/user-attachments/assets/ab302c02-c080-4042-99fc-0e181ba8abb9)\n\n\n## ğŸ§  Architecture\n\n![training-free-architecture-comic-sans-min](https://github.com/user-attachments/assets/d84dd83a-505e-45a0-8ce3-98e1838017f9)\n\n\n## ğŸ› ï¸ Installation instructions\n\n### 1. Clone the repository\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 6,
    "Content": "```bash\ngit clone https://github.com/miquel-espinosa/no-time-to-train.git\ncd no-time-to-train\n```",
    "ContentSha": "FqsX96SwjKeMnD8rrDrd4pfjW32n5SRf0jXIvB4WHz4=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\ngit clone https://github.com/miquel-espinosa/no-time-to-train.git\ncd no-time-to-train\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 7,
    "Content": "\n### 2. Create conda environment\n\nWe will create a conda environment with the required packages.",
    "ContentSha": "xkwDa/DvfDApk69cNg5ORagN7Utfcos+yCxRpQNn6gk=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "### 2. condaç’°å¢ƒã®ä½œæˆ\n\nå¿…è¦ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’å«ã‚€condaç’°å¢ƒã‚’ä½œæˆã—ã¾ã™ã€‚\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 8,
    "Content": "```bash\nconda env create -f environment.yml\nconda activate no-time-to-train\n```",
    "ContentSha": "W1AlselK7qAC1MpunsXhTPA8MG+kwjbpodKBkImFaio=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\nconda env create -f environment.yml\nconda activate no-time-to-train\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 9,
    "Content": "\n### 3. Install SAM2 and DinoV2\n\nWe will install SAM2 and DinoV2 from source.",
    "ContentSha": "qhWNaaTVSpemTiKekSRF2dWJYxX636VdhL+lPiso28M=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "### 3. SAM2 ã¨ DinoV2 ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n\nSAM2 ã¨ DinoV2 ã‚’ã‚½ãƒ¼ã‚¹ã‹ã‚‰ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™ã€‚\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 10,
    "Content": "```bash\npip install -e .\ncd dinov2\npip install -e .\ncd ..\n```",
    "ContentSha": "dMsjJwa9nz+HHMLijmYZdlLh6FmDBGmNlHxywBzbEg4=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\npip install -e .\ncd dinov2\npip install -e .\ncd ..\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 11,
    "Content": "\n### 4. Download datasets\n\nPlease download COCO dataset and place it in `data/coco`\n\n### 5. Download SAM2 and DinoV2 checkpoints\n\nWe will download the exact SAM2 checkpoints used in the paper.\n(Note, however, that SAM2.1 checkpoints are already available and might perform better.)\n",
    "ContentSha": "LTXcwC9KGMiPIiBLXtQVF6Wdi9d19gVIUBX6F+tGTqE=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "### 4. ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n\nCOCOãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã€`data/coco` ã«é…ç½®ã—ã¦ãã ã•ã„ã€‚\n\n### 5. SAM2ãŠã‚ˆã³DinoV2ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n\nè«–æ–‡ã§ä½¿ç”¨ã•ã‚ŒãŸæ­£ç¢ºãªSAM2ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚\nï¼ˆãŸã ã—ã€SAM2.1ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã¯ã™ã§ã«åˆ©ç”¨å¯èƒ½ã§ã‚ã‚Šã€ã‚ˆã‚Šè‰¯ã„æ€§èƒ½ã‚’ç¤ºã™å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ï¼‰\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 12,
    "Content": "```bash\nmkdir -p checkpoints/dinov2\ncd checkpoints\nwget https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_large.pt\ncd dinov2\nwget https://dl.fbaipublicfiles.com/dinov2/dinov2_vitl14/dinov2_vitl14_pretrain.pth\ncd ../..\n```",
    "ContentSha": "Q/LddAGtfunblX1eLTx7t3Vs+C74LtCdgP/HQ3gIJgk=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\nmkdir -p checkpoints/dinov2\ncd checkpoints\nwget https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_large.pt\ncd dinov2\nwget https://dl.fbaipublicfiles.com/dinov2/dinov2_vitl14/dinov2_vitl14_pretrain.pth\ncd ../..\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 13,
    "Content": "\n\n## ğŸ“Š Inference code\n\nâš ï¸ Disclaimer: This is research code â€” expect a bit of chaos!\n\n### Reproducing 30-shot SOTA results in Few-shot COCO\n\nDefine useful variables and create a folder for results:\n",
    "ContentSha": "q8hVlrVr+ps2xB/JxM3tKtF/KxoLX4PepxohltYehb8=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "<translate-content>\n\n## ğŸ“Š æ¨è«–ã‚³ãƒ¼ãƒ‰\n\nâš ï¸ å…è²¬äº‹é …ï¼šã“ã‚Œã¯ç ”ç©¶ç”¨ã‚³ãƒ¼ãƒ‰ã§ã™ â€” å¤šå°‘ã®æ··ä¹±ã¯ã”å®¹èµ¦ãã ã•ã„ï¼\n\n### Few-shot COCOã§30ã‚·ãƒ§ãƒƒãƒˆSOTAçµæœã®å†ç¾\n\næœ‰ç”¨ãªå¤‰æ•°ã‚’å®šç¾©ã—ã€çµæœç”¨ã®ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆã—ã¾ã™ï¼š\n</translate-content>",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 14,
    "Content": "```bash\nCONFIG=./no_time_to_train/new_exps/coco_fewshot_10shot_Sam2L.yaml\nCLASS_SPLIT=\"few_shot_classes\"\nRESULTS_DIR=work_dirs/few_shot_results\nSHOTS=30\nSEED=33\nGPUS=4\n\nmkdir -p $RESULTS_DIR\nFILENAME=few_shot_${SHOTS}shot_seed${SEED}.pkl\n```",
    "ContentSha": "R03PMGcFnYnvttqgfztGnWdoyJeXMyxFUN7tyR4kpy8=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\nCONFIG=./no_time_to_train/new_exps/coco_fewshot_10shot_Sam2L.yaml\nCLASS_SPLIT=\"few_shot_classes\"\nRESULTS_DIR=work_dirs/few_shot_results\nSHOTS=30\nSEED=33\nGPUS=4\n\nmkdir -p $RESULTS_DIR\nFILENAME=few_shot_${SHOTS}shot_seed${SEED}.pkl\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 15,
    "Content": "\n#### 0. Create reference set\n",
    "ContentSha": "1XrtmJBqIS+6/RHkWmwwopPgE4d3ho+bdPLXEG612YQ=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "#### 0. å‚ç…§ã‚»ãƒƒãƒˆã®ä½œæˆ\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 16,
    "Content": "```bash\npython no_time_to_train/dataset/few_shot_sampling.py \\\n        --n-shot $SHOTS \\\n        --out-path ${RESULTS_DIR}/${FILENAME} \\\n        --seed $SEED \\\n        --dataset $CLASS_SPLIT\n```",
    "ContentSha": "XMsc+nj2n5gsZtjFdl6ErjVKLXgBoPIrungxtY9mDss=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\npython no_time_to_train/dataset/few_shot_sampling.py \\\n        --n-shot $SHOTS \\\n        --out-path ${RESULTS_DIR}/${FILENAME} \\\n        --seed $SEED \\\n        --dataset $CLASS_SPLIT\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 17,
    "Content": "\n#### 1. Fill memory with references\n",
    "ContentSha": "v8E00SBwAimb411iJf1DGyTZxexOPmC/xK0/B+XBH1g=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "#### 1. å‚ç…§ã§ãƒ¡ãƒ¢ãƒªã‚’åŸ‹ã‚ã‚‹\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 18,
    "Content": "```bash\npython run_lightening.py test --config $CONFIG \\\n                              --model.test_mode fill_memory \\\n                              --out_path ${RESULTS_DIR}/memory.ckpt \\\n                              --model.init_args.model_cfg.memory_bank_cfg.length $SHOTS \\\n                              --model.init_args.dataset_cfgs.fill_memory.memory_pkl ${RESULTS_DIR}/${FILENAME} \\\n                              --model.init_args.dataset_cfgs.fill_memory.memory_length $SHOTS \\\n                              --model.init_args.dataset_cfgs.fill_memory.class_split $CLASS_SPLIT \\\n                              --trainer.logger.save_dir ${RESULTS_DIR}/ \\\n                              --trainer.devices $GPUS\n```",
    "ContentSha": "1pVePuzaIdQCE/Nx0VoaWhFswuB5Jh1Z68Cw/2D8RkM=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\npython run_lightening.py test --config $CONFIG \\\n                              --model.test_mode fill_memory \\\n                              --out_path ${RESULTS_DIR}/memory.ckpt \\\n                              --model.init_args.model_cfg.memory_bank_cfg.length $SHOTS \\\n                              --model.init_args.dataset_cfgs.fill_memory.memory_pkl ${RESULTS_DIR}/${FILENAME} \\\n                              --model.init_args.dataset_cfgs.fill_memory.memory_length $SHOTS \\\n                              --model.init_args.dataset_cfgs.fill_memory.class_split $CLASS_SPLIT \\\n                              --trainer.logger.save_dir ${RESULTS_DIR}/ \\\n                              --trainer.devices $GPUS\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 19,
    "Content": "\n#### 2. Post-process memory bank\n",
    "ContentSha": "3A9quGczCnAQeUTcoJVGYLTQapI5nQ5aSj7AZIhGFJw=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "#### 2. ãƒã‚¹ãƒˆãƒ—ãƒ­ã‚»ã‚¹ãƒ¡ãƒ¢ãƒªãƒãƒ³ã‚¯\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 20,
    "Content": "```bash\npython run_lightening.py test --config $CONFIG \\\n                              --model.test_mode postprocess_memory \\\n                              --model.init_args.model_cfg.memory_bank_cfg.length $SHOTS \\\n                              --ckpt_path ${RESULTS_DIR}/memory.ckpt \\\n                              --out_path ${RESULTS_DIR}/memory_postprocessed.ckpt \\\n                              --trainer.devices 1\n```",
    "ContentSha": "45qs8EyMtDUKs5A3rrQcJQXl6OIbI6s0rKOOnHmYURs=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\npython run_lightening.py test --config $CONFIG \\\n                              --model.test_mode postprocess_memory \\\n                              --model.init_args.model_cfg.memory_bank_cfg.length $SHOTS \\\n                              --ckpt_path ${RESULTS_DIR}/memory.ckpt \\\n                              --out_path ${RESULTS_DIR}/memory_postprocessed.ckpt \\\n                              --trainer.devices 1\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 21,
    "Content": "\n#### 3. Inference on target images\n",
    "ContentSha": "73CbGioqWaTULTrw0roBLoZCxgBgtmJVFDc7RHluH0g=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "#### 3. å¯¾è±¡ç”»åƒã«å¯¾ã™ã‚‹æ¨è«–\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 22,
    "Content": "```bash\npython run_lightening.py test --config $CONFIG  \\\n                              --ckpt_path ${RESULTS_DIR}/memory_postprocessed.ckpt \\\n                              --model.init_args.test_mode test \\\n                              --model.init_args.model_cfg.memory_bank_cfg.length $SHOTS \\\n                              --model.init_args.model_cfg.dataset_name $CLASS_SPLIT \\\n                              --model.init_args.dataset_cfgs.test.class_split $CLASS_SPLIT \\\n                              --trainer.logger.save_dir ${RESULTS_DIR}/ \\\n                              --trainer.devices $GPUS\n```",
    "ContentSha": "vbKXVEs47fJ5oF8vLkHVM2ofFMx1hKBBgQF9JAgp2Jo=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\npython run_lightening.py test --config $CONFIG  \\\n                              --ckpt_path ${RESULTS_DIR}/memory_postprocessed.ckpt \\\n                              --model.init_args.test_mode test \\\n                              --model.init_args.model_cfg.memory_bank_cfg.length $SHOTS \\\n                              --model.init_args.model_cfg.dataset_name $CLASS_SPLIT \\\n                              --model.init_args.dataset_cfgs.test.class_split $CLASS_SPLIT \\\n                              --trainer.logger.save_dir ${RESULTS_DIR}/ \\\n                              --trainer.devices $GPUS\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 23,
    "Content": "\nIf you'd like to see inference results online (as they are computed), add the argument:",
    "ContentSha": "Dp4E3gH6hSg659jJwzXukrsk5Jl8KA5ymhMGoz6L/wc=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "æ¨è«–çµæœã‚’ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã§ï¼ˆè¨ˆç®—ã•ã‚Œã‚‹ã¨åŒæ™‚ã«ï¼‰è¡¨ç¤ºã—ãŸã„å ´åˆã¯ã€æ¬¡ã®å¼•æ•°ã‚’è¿½åŠ ã—ã¦ãã ã•ã„:\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 24,
    "Content": "```bash\n    --model.init_args.model_cfg.test.online_vis True\n```",
    "ContentSha": "mbu//ROEScsc0zLyvi3r1BPFxMrHWk/o7rqLvu03LTA=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\n    --model.init_args.model_cfg.test.online_vis True\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 25,
    "Content": "To adjust the score threshold `score_thr` parameter, add the argument (for example, visualising all instances with score higher than `0.4`):",
    "ContentSha": "qweycVV6vcVlQTeQ2dS1zGx5GmbYXYcZs6oNjQhUwNI=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "ã‚¹ã‚³ã‚¢é–¾å€¤ `score_thr` ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’èª¿æ•´ã™ã‚‹ã«ã¯ã€å¼•æ•°ã‚’è¿½åŠ ã—ã¾ã™ï¼ˆä¾‹ï¼šã‚¹ã‚³ã‚¢ãŒ `0.4` ã‚ˆã‚Šé«˜ã„ã™ã¹ã¦ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å¯è¦–åŒ–ã™ã‚‹å ´åˆï¼‰ã€‚",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 26,
    "Content": "```bash\n    --model.init_args.model_cfg.test.vis_thr 0.4\n```",
    "ContentSha": "af/rWDR0jwUHbKw+uPDz7J5oeScBvpa9U5qwCYxo0Pg=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\n    --model.init_args.model_cfg.test.vis_thr 0.4\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 27,
    "Content": "Images will now be saved in `results_analysis/few_shot_classes/`. The image on the left shows the ground truth, the image on the right shows the segmented instances found by our training-free method.\n\nNote that in this example we are using the `few_shot_classes` split, thus, we should only expect to see segmented instances of the classes in this split (not all classes in COCO).\n\n#### Results\n\nAfter running all images in the validation set, you should obtain:\n",
    "ContentSha": "UYiVB+AwL2aAWVmV805O2tsw2jw3cL3t1ysHKuWCd28=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "ç”»åƒã¯ `results_analysis/few_shot_classes/` ã«ä¿å­˜ã•ã‚Œã¾ã™ã€‚å·¦å´ã®ç”»åƒã¯æ­£è§£ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã€å³å´ã®ç”»åƒã¯æˆ‘ã€…ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¸è¦ã®æ‰‹æ³•ã§æ¤œå‡ºã•ã‚ŒãŸã‚»ã‚°ãƒ¡ãƒ³ãƒˆåŒ–ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚\n\nã“ã®ä¾‹ã§ã¯ `few_shot_classes` åˆ†å‰²ã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹ãŸã‚ã€ã“ã®åˆ†å‰²ã«å«ã¾ã‚Œã‚‹ã‚¯ãƒ©ã‚¹ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®ã¿ãŒã‚»ã‚°ãƒ¡ãƒ³ãƒˆåŒ–ã•ã‚Œã‚‹ã“ã¨ãŒæœŸå¾…ã•ã‚Œã¾ã™ï¼ˆCOCOã®ã™ã¹ã¦ã®ã‚¯ãƒ©ã‚¹ã§ã¯ã‚ã‚Šã¾ã›ã‚“ï¼‰ã€‚\n\n#### çµæœ\n\nãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚»ãƒƒãƒˆå†…ã®ã™ã¹ã¦ã®ç”»åƒã‚’å‡¦ç†ã—ãŸå¾Œã€ä»¥ä¸‹ã®ã‚‚ã®ãŒå¾—ã‚‰ã‚Œã‚‹ã¯ãšã§ã™ï¼š\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 28,
    "Content": "```\nBBOX RESULTS:\n  Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.368\n\nSEGM RESULTS:\n  Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.342\n```",
    "ContentSha": "ch7itB3Sk8oLc3U+lNJGI3BV57wpOMkabTBsUiqzHDU=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```\nBBOX RESULTS:\n  Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.368\n\nSEGM RESULTS:\n  Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.342\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 29,
    "Content": "---\n\n## ğŸ” Custom dataset\n\nWe provide the instructions for running our pipeline on a custom dataset. Annotation format are always in COCO format.\n\n> **TLDR;** To directly see how to run full pipeline on *custom datasets*, find `scripts/matching_cdfsod_pipeline.sh` together with example scripts of CD-FSOD datasets (e.g. `scripts/dior_fish.sh`)\n\n### 0. Prepare a custom dataset â›µğŸ¦\n\nLet's imagine we want to detect **boats**â›µ and **birds**ğŸ¦ in a custom dataset. To use our method we will need:\n- At least 1 *annotated* reference image for each class (i.e. 1 reference image for boat and 1 reference image for bird)\n- Multiple target images to find instances of our desired classes.\n\nWe have prepared a toy script to create a custom dataset with coco images, for a **1-shot** setting.",
    "ContentSha": "IPUeWphY2t966UmztjMo0ja/aOT1Wd0H0rkyNv8xt9Y=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "---\n\n## ğŸ” ã‚«ã‚¹ã‚¿ãƒ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ\n\næœ¬ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ã‚«ã‚¹ã‚¿ãƒ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§å®Ÿè¡Œã™ã‚‹æ‰‹é †ã‚’æä¾›ã—ã¾ã™ã€‚ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³å½¢å¼ã¯å¸¸ã«COCOãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§ã™ã€‚\n\n> **TLDR;** *ã‚«ã‚¹ã‚¿ãƒ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ*ã§ãƒ•ãƒ«ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å®Ÿè¡Œã™ã‚‹æ–¹æ³•ã‚’ç›´æ¥ç¢ºèªã—ãŸã„å ´åˆã¯ã€`scripts/matching_cdfsod_pipeline.sh`ãŠã‚ˆã³CD-FSODãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ä¾‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆä¾‹ï¼š`scripts/dior_fish.sh`ï¼‰ã‚’ã”è¦§ãã ã•ã„ã€‚\n\n### 0. ã‚«ã‚¹ã‚¿ãƒ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æº–å‚™ â›µğŸ¦\n\nã‚«ã‚¹ã‚¿ãƒ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§**ãƒœãƒ¼ãƒˆ**â›µã¨**é³¥**ğŸ¦ã‚’æ¤œå‡ºã—ãŸã„ã¨ä»®å®šã—ã¾ã™ã€‚æœ¬æ‰‹æ³•ã‚’åˆ©ç”¨ã™ã‚‹ã«ã¯ä»¥ä¸‹ãŒå¿…è¦ã§ã™ï¼š\n- å„ã‚¯ãƒ©ã‚¹ã”ã¨ã«å°‘ãªãã¨ã‚‚1æšã®*ã‚¢ãƒãƒ†ãƒ¼ãƒˆæ¸ˆã¿*å‚ç…§ç”»åƒï¼ˆä¾‹ï¼šãƒœãƒ¼ãƒˆç”¨1æšã€é³¥ç”¨1æšï¼‰\n- å¯¾è±¡ã‚¯ãƒ©ã‚¹ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’è¦‹ã¤ã‘ã‚‹ãŸã‚ã®è¤‡æ•°ã®ã‚¿ãƒ¼ã‚²ãƒƒãƒˆç”»åƒ\n\nCOCOç”»åƒã‚’ç”¨ã„ã¦ã‚«ã‚¹ã‚¿ãƒ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆã™ã‚‹ãƒˆã‚¤ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ç”¨æ„ã—ã¦ãŠã‚Šã€**1-shot**è¨­å®šã«å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 30,
    "Content": "```bash\nmkdir -p data/my_custom_dataset\npython scripts/make_custom_dataset.py\n```",
    "ContentSha": "QqoeCMR6ke4ax/152QCJr8NiqoIlKNt5rN0t2zxaRtM=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\nmkdir -p data/my_custom_dataset\npython scripts/make_custom_dataset.py\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 31,
    "Content": "This will create a custom dataset with the following folder structure:",
    "ContentSha": "9JGOKHf/Hqbdn+b2OqaUnKIYD8GGf7jwfM9mTbUtoP4=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "ã“ã‚Œã«ã‚ˆã‚Šã€ä»¥ä¸‹ã®ãƒ•ã‚©ãƒ«ãƒ€æ§‹é€ ã‚’æŒã¤ã‚«ã‚¹ã‚¿ãƒ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒä½œæˆã•ã‚Œã¾ã™ã€‚",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 32,
    "Content": "```\ndata/my_custom_dataset/\n    â”œâ”€â”€ annotations/\n    â”‚   â”œâ”€â”€ custom_references.json\n    â”‚   â”œâ”€â”€ custom_targets.json\n    â”‚   â””â”€â”€ references_visualisations/\n    â”‚       â”œâ”€â”€ bird_1.jpg\n    â”‚       â””â”€â”€ boat_1.jpg\n    â””â”€â”€ images/\n        â”œâ”€â”€ 429819.jpg\n        â”œâ”€â”€ 101435.jpg\n        â””â”€â”€ (all target and reference images)\n```",
    "ContentSha": "Bj/IFZkQUfkoGUwynry3llvasPwDhX0B0JgBYl9vuQE=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```\ndata/my_custom_dataset/\n    â”œâ”€â”€ annotations/\n    â”‚   â”œâ”€â”€ custom_references.json\n    â”‚   â”œâ”€â”€ custom_targets.json\n    â”‚   â””â”€â”€ references_visualisations/\n    â”‚       â”œâ”€â”€ bird_1.jpg\n    â”‚       â””â”€â”€ boat_1.jpg\n    â””â”€â”€ images/\n        â”œâ”€â”€ 429819.jpg\n        â”œâ”€â”€ 101435.jpg\n        â””â”€â”€ (all target and reference images)\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 33,
    "Content": "\n**Reference images visualisation (1-shot):**\n\n| 1-shot Reference Image for BIRD ğŸ¦ | 1-shot Reference Image for BOAT â›µ |\n|:---------------------------------:|:----------------------------------:|\n| <img src=\"https://github.com/user-attachments/assets/e59e580d-a7db-42ac-b386-892af211fc85\" alt=\"bird_1\" width=\"500\"/> | <img src=\"https://github.com/user-attachments/assets/f94ee025-ae37-4a45-9c3e-0cfe8f8cd2bc\" alt=\"boat_1\" width=\"500\"/> |\n\n\n### 0.1 If only bbox annotations are available\n\nWe also provide a script to generate instance-level segmentation masks by using SAM2. This is useful if you only have bounding box annotations available for the reference images.\n",
    "ContentSha": "24nxqSCUluTBmTCEJTeg5Xoe4qe7qXxstVNWjA2/zVk=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "**å‚ç…§ç”»åƒã®å¯è¦–åŒ–ï¼ˆ1ã‚·ãƒ§ãƒƒãƒˆï¼‰ï¼š**\n\n| BIRD ğŸ¦ ã®1ã‚·ãƒ§ãƒƒãƒˆå‚ç…§ç”»åƒ | BOAT â›µ ã®1ã‚·ãƒ§ãƒƒãƒˆå‚ç…§ç”»åƒ |\n|:-----------------------------:|:------------------------------:|\n| <img src=\"https://github.com/user-attachments/assets/e59e580d-a7db-42ac-b386-892af211fc85\" alt=\"bird_1\" width=\"500\"/> | <img src=\"https://github.com/user-attachments/assets/f94ee025-ae37-4a45-9c3e-0cfe8f8cd2bc\" alt=\"boat_1\" width=\"500\"/> |\n\n\n### 0.1 ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã®ã¿ãŒåˆ©ç”¨å¯èƒ½ãªå ´åˆ\n\nå‚ç…§ç”»åƒã«ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã—ã‹ãªã„å ´åˆã«ã‚‚å¯¾å¿œã§ãã‚‹ã‚ˆã†ã€SAM2ã‚’ç”¨ã„ã¦ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ãƒ¬ãƒ™ãƒ«ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒã‚¹ã‚¯ã‚’ç”Ÿæˆã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚‚æä¾›ã—ã¦ã„ã¾ã™ã€‚\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 34,
    "Content": "```bash\n# Download sam_h checkpoint. Feel free to use more recent checkpoints (note: code might need to be adapted)\nwget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth -O checkpoints/sam_vit_h_4b8939.pth\n# Run automatic instance segmentation from ground truth bounding boxes.\npython no_time_to_train/dataset/sam_bbox_to_segm_batch.py \\\n    --input_json data/my_custom_dataset/annotations/custom_references.json \\\n    --image_dir data/my_custom_dataset/images \\\n    --sam_checkpoint checkpoints/sam_vit_h_4b8939.pth \\\n    --model_type vit_h \\\n    --device cuda \\\n    --batch_size 8 \\\n    --visualize\n```",
    "ContentSha": "MZFLWMxUY4Y3eseQiE2eVYRMs3mR83iZMQq1RJqVFCc=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\n# Download sam_h checkpoint. Feel free to use more recent checkpoints (note: code might need to be adapted)\nwget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth -O checkpoints/sam_vit_h_4b8939.pth\n# Run automatic instance segmentation from ground truth bounding boxes.\npython no_time_to_train/dataset/sam_bbox_to_segm_batch.py \\\n    --input_json data/my_custom_dataset/annotations/custom_references.json \\\n    --image_dir data/my_custom_dataset/images \\\n    --sam_checkpoint checkpoints/sam_vit_h_4b8939.pth \\\n    --model_type vit_h \\\n    --device cuda \\\n    --batch_size 8 \\\n    --visualize\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 35,
    "Content": "\n**Reference images with instance-level segmentation masks (generated by SAM2 from gt bounding boxes, 1-shot):**\n\nVisualisation of the generated segmentation masks are saved in `data/my_custom_dataset/annotations/custom_references_with_SAM_segm/references_visualisations/`.\n\n\n| 1-shot Reference Image for BIRD ğŸ¦ (automatically segmented with SAM) | 1-shot Reference Image for BOAT â›µ (automatically segmented with SAM) |\n|:---------------------------------:|:----------------------------------:|\n| <img src=\"https://github.com/user-attachments/assets/65d38dc4-1454-43cd-9600-e8efc67b3a82\" alt=\"bird_1_with_SAM_segm\" width=\"500\"/> | <img src=\"https://github.com/user-attachments/assets/43a558ad-50ca-4715-8285-9aa3268843c6\" alt=\"boat_1_with_SAM_segm\" width=\"500\"/> |\n\n\n### 0.2 Convert coco annotations to pickle file\n",
    "ContentSha": "0a8ACnuaKmeocwoJUK+xvmctljcu8ZJdT00xJXlyJ5w=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "**ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ãƒ¬ãƒ™ãƒ«ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒã‚¹ã‚¯ä»˜ãå‚ç…§ç”»åƒï¼ˆgtãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã‹ã‚‰SAM2ã§ç”Ÿæˆã€1-shotï¼‰ï¼š**\n\nç”Ÿæˆã•ã‚ŒãŸã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒã‚¹ã‚¯ã®å¯è¦–åŒ–ã¯ã€`data/my_custom_dataset/annotations/custom_references_with_SAM_segm/references_visualisations/` ã«ä¿å­˜ã•ã‚Œã¦ã„ã¾ã™ã€‚\n\n\n| BIRD ğŸ¦ ã®1-shotå‚ç…§ç”»åƒï¼ˆSAMã§è‡ªå‹•ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåŒ–ï¼‰ | BOAT â›µ ã®1-shotå‚ç…§ç”»åƒï¼ˆSAMã§è‡ªå‹•ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåŒ–ï¼‰ |\n|:---------------------------------:|:----------------------------------:|\n| <img src=\"https://github.com/user-attachments/assets/65d38dc4-1454-43cd-9600-e8efc67b3a82\" alt=\"bird_1_with_SAM_segm\" width=\"500\"/> | <img src=\"https://github.com/user-attachments/assets/43a558ad-50ca-4715-8285-9aa3268843c6\" alt=\"boat_1_with_SAM_segm\" width=\"500\"/> |\n\n\n### 0.2 cocoã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’pickleãƒ•ã‚¡ã‚¤ãƒ«ã«å¤‰æ›\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 36,
    "Content": "```bash\npython no_time_to_train/dataset/coco_to_pkl.py \\\n    data/my_custom_dataset/annotations/custom_references_with_segm.json \\\n    data/my_custom_dataset/annotations/custom_references_with_segm.pkl \\\n    1\n```",
    "ContentSha": "PSo9jaMX0pVKgHl0ecq9duQGpy1rMpXUU1iB4a8YzJM=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\npython no_time_to_train/dataset/coco_to_pkl.py \\\n    data/my_custom_dataset/annotations/custom_references_with_segm.json \\\n    data/my_custom_dataset/annotations/custom_references_with_segm.pkl \\\n    1\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 37,
    "Content": "\n### 1. Fill memory with references\n\nFirst, define useful variables and create a folder for results. For correct visualisation of labels, class names should be ordered by category id as appears in the json file. E.g. `bird` has category id `16`, `boat` has category id `9`. Thus, `CAT_NAMES=boat,bird`.\n",
    "ContentSha": "97iqG4pEnvNDE6ERpjfa2nL6RAtTIXJXwjJwqU/SNCg=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "### 1. å‚ç…§ã§ãƒ¡ãƒ¢ãƒªã‚’åŸ‹ã‚ã‚‹\n\næœ€åˆã«ã€ä¾¿åˆ©ãªå¤‰æ•°ã‚’å®šç¾©ã—ã€çµæœç”¨ã®ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆã—ã¾ã™ã€‚ãƒ©ãƒ™ãƒ«ã‚’æ­£ã—ãå¯è¦–åŒ–ã™ã‚‹ãŸã‚ã«ã¯ã€ã‚¯ãƒ©ã‚¹åã‚’jsonãƒ•ã‚¡ã‚¤ãƒ«ã«è¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹ã‚«ãƒ†ã‚´ãƒªIDé †ã«ä¸¦ã¹ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ä¾‹ï¼š`bird` ã®ã‚«ãƒ†ã‚´ãƒªIDã¯ `16`ã€`boat` ã®ã‚«ãƒ†ã‚´ãƒªIDã¯ `9` ã§ã™ã€‚ã—ãŸãŒã£ã¦ã€`CAT_NAMES=boat,bird` ã¨ãªã‚Šã¾ã™ã€‚\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 38,
    "Content": "```bash\nDATASET_NAME=my_custom_dataset\nDATASET_PATH=data/my_custom_dataset\nCAT_NAMES=boat,bird\nCATEGORY_NUM=2\nSHOT=1\nYAML_PATH=no_time_to_train/pl_configs/matching_cdfsod_template.yaml\nPATH_TO_SAVE_CKPTS=./tmp_ckpts/my_custom_dataset\nmkdir -p $PATH_TO_SAVE_CKPTS\n```",
    "ContentSha": "mJIX4bJBaFbcwT8YfLR0V4w6qjU7MQEh3u6k2gtPrvw=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\nDATASET_NAME=my_custom_dataset\nDATASET_PATH=data/my_custom_dataset\nCAT_NAMES=boat,bird\nCATEGORY_NUM=2\nSHOT=1\nYAML_PATH=no_time_to_train/pl_configs/matching_cdfsod_template.yaml\nPATH_TO_SAVE_CKPTS=./tmp_ckpts/my_custom_dataset\nmkdir -p $PATH_TO_SAVE_CKPTS\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 39,
    "Content": "\nRun step 1:",
    "ContentSha": "PqClefvNhYLjlZsfjndNSKUJEy6R+goO4h/8KMDA1P0=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "ã‚¹ãƒ†ãƒƒãƒ—1ã‚’å®Ÿè¡Œã—ã¾ã™ï¼š\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 40,
    "Content": "```bash\npython run_lightening.py test --config $YAML_PATH \\\n    --model.test_mode fill_memory \\\n    --out_path $PATH_TO_SAVE_CKPTS/$DATASET_NAME\\_$SHOT\\_refs_memory.pth \\\n    --model.init_args.dataset_cfgs.fill_memory.root $DATASET_PATH/images \\\n    --model.init_args.dataset_cfgs.fill_memory.json_file $DATASET_PATH/annotations/custom_references_with_segm.json \\\n    --model.init_args.dataset_cfgs.fill_memory.memory_pkl $DATASET_PATH/annotations/custom_references_with_segm.pkl \\\n    --model.init_args.dataset_cfgs.fill_memory.memory_length $SHOT \\\n    --model.init_args.dataset_cfgs.fill_memory.cat_names $CAT_NAMES \\\n    --model.init_args.model_cfg.dataset_name $DATASET_NAME \\\n    --model.init_args.model_cfg.memory_bank_cfg.length $SHOT \\\n    --model.init_args.model_cfg.memory_bank_cfg.category_num $CATEGORY_NUM \\\n    --trainer.devices 1\n```",
    "ContentSha": "wLZindeEKqrTUIIF55tL8lmaW4jWIZ2bdw6bj/1U9TU=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\npython run_lightening.py test --config $YAML_PATH \\\n    --model.test_mode fill_memory \\\n    --out_path $PATH_TO_SAVE_CKPTS/$DATASET_NAME\\_$SHOT\\_refs_memory.pth \\\n    --model.init_args.dataset_cfgs.fill_memory.root $DATASET_PATH/images \\\n    --model.init_args.dataset_cfgs.fill_memory.json_file $DATASET_PATH/annotations/custom_references_with_segm.json \\\n    --model.init_args.dataset_cfgs.fill_memory.memory_pkl $DATASET_PATH/annotations/custom_references_with_segm.pkl \\\n    --model.init_args.dataset_cfgs.fill_memory.memory_length $SHOT \\\n    --model.init_args.dataset_cfgs.fill_memory.cat_names $CAT_NAMES \\\n    --model.init_args.model_cfg.dataset_name $DATASET_NAME \\\n    --model.init_args.model_cfg.memory_bank_cfg.length $SHOT \\\n    --model.init_args.model_cfg.memory_bank_cfg.category_num $CATEGORY_NUM \\\n    --trainer.devices 1\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 41,
    "Content": "\n### 2. Post-process memory bank\n",
    "ContentSha": "39oOsuQIXM8TjT8ASLmZI0OpSbUSAT4d7YEHU7S2uqQ=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "### 2. ãƒã‚¹ãƒˆãƒ—ãƒ­ã‚»ã‚¹ãƒ¡ãƒ¢ãƒªãƒãƒ³ã‚¯\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 42,
    "Content": "```bash\npython run_lightening.py test --config $YAML_PATH \\\n    --model.test_mode postprocess_memory \\\n    --ckpt_path $PATH_TO_SAVE_CKPTS/$DATASET_NAME\\_$SHOT\\_refs_memory.pth \\\n    --out_path $PATH_TO_SAVE_CKPTS/$DATASET_NAME\\_$SHOT\\_refs_memory_postprocessed.pth \\\n    --model.init_args.model_cfg.dataset_name $DATASET_NAME \\\n    --model.init_args.model_cfg.memory_bank_cfg.length $SHOT \\\n    --model.init_args.model_cfg.memory_bank_cfg.category_num $CATEGORY_NUM \\\n    --trainer.devices 1\n```",
    "ContentSha": "49JIaRecImNonhL7aGKB3JsAkgDw76Irci38QcuVb8k=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\npython run_lightening.py test --config $YAML_PATH \\\n    --model.test_mode postprocess_memory \\\n    --ckpt_path $PATH_TO_SAVE_CKPTS/$DATASET_NAME\\_$SHOT\\_refs_memory.pth \\\n    --out_path $PATH_TO_SAVE_CKPTS/$DATASET_NAME\\_$SHOT\\_refs_memory_postprocessed.pth \\\n    --model.init_args.model_cfg.dataset_name $DATASET_NAME \\\n    --model.init_args.model_cfg.memory_bank_cfg.length $SHOT \\\n    --model.init_args.model_cfg.memory_bank_cfg.category_num $CATEGORY_NUM \\\n    --trainer.devices 1\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 43,
    "Content": "\n#### 2.1 Visualise post-processed memory bank\n",
    "ContentSha": "Pz+UrI1n9P9i9DChpNd/m3unfj17ZqVz3PnHMyK+5XU=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "\n#### 2.1 å¾Œå‡¦ç†ã•ã‚ŒãŸãƒ¡ãƒ¢ãƒªãƒãƒ³ã‚¯ã®å¯è¦–åŒ–\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 2,
        "rowsha": "zA9xPuN6grCmDtzemkhLkPyW7qI+l8F89v7W60063mQ=",
        "originContent": "#### 2.1 Visualise post-processed memory bank",
        "translatedContent": "#### 2.1 å¾Œå‡¦ç†ã•ã‚ŒãŸãƒ¡ãƒ¢ãƒªãƒãƒ³ã‚¯ã®å¯è¦–åŒ–"
      },
      {
        "row": 3,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 44,
    "Content": "```bash\npython run_lightening.py test --config $YAML_PATH \\\n    --model.test_mode vis_memory \\\n    --ckpt_path $PATH_TO_SAVE_CKPTS/$DATASET_NAME\\_$SHOT\\_refs_memory_postprocessed.pth \\\n    --model.init_args.dataset_cfgs.fill_memory.root $DATASET_PATH/images \\\n    --model.init_args.dataset_cfgs.fill_memory.json_file $DATASET_PATH/annotations/custom_references_with_segm.json \\\n    --model.init_args.dataset_cfgs.fill_memory.memory_pkl $DATASET_PATH/annotations/custom_references_with_segm.pkl \\\n    --model.init_args.dataset_cfgs.fill_memory.memory_length $SHOT \\\n    --model.init_args.dataset_cfgs.fill_memory.cat_names $CAT_NAMES \\\n    --model.init_args.model_cfg.dataset_name $DATASET_NAME \\\n    --model.init_args.model_cfg.memory_bank_cfg.length $SHOT \\\n    --model.init_args.model_cfg.memory_bank_cfg.category_num $CATEGORY_NUM \\\n    --trainer.devices 1\n```",
    "ContentSha": "2C9ilXiP+W/SLak7O3FNtKLBBgCCWOswHD8qb+mug1w=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\npython run_lightening.py test --config $YAML_PATH \\\n    --model.test_mode vis_memory \\\n    --ckpt_path $PATH_TO_SAVE_CKPTS/$DATASET_NAME\\_$SHOT\\_refs_memory_postprocessed.pth \\\n    --model.init_args.dataset_cfgs.fill_memory.root $DATASET_PATH/images \\\n    --model.init_args.dataset_cfgs.fill_memory.json_file $DATASET_PATH/annotations/custom_references_with_segm.json \\\n    --model.init_args.dataset_cfgs.fill_memory.memory_pkl $DATASET_PATH/annotations/custom_references_with_segm.pkl \\\n    --model.init_args.dataset_cfgs.fill_memory.memory_length $SHOT \\\n    --model.init_args.dataset_cfgs.fill_memory.cat_names $CAT_NAMES \\\n    --model.init_args.model_cfg.dataset_name $DATASET_NAME \\\n    --model.init_args.model_cfg.memory_bank_cfg.length $SHOT \\\n    --model.init_args.model_cfg.memory_bank_cfg.category_num $CATEGORY_NUM \\\n    --trainer.devices 1\n```",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "rTMjNc+qNIxb1xXDR5hEYiJw1fc4muBwuBsTXVIaIho=",
        "originContent": "```bash",
        "translatedContent": "```bash"
      },
      {
        "row": 2,
        "rowsha": "3ETYk+lXCmWw9FFEJ+wILd+zQZjjy0tb7XEaA2ooWes=",
        "originContent": "python run_lightening.py test --config $YAML_PATH \\",
        "translatedContent": "python run_lightening.py test --config $YAML_PATH \\"
      },
      {
        "row": 3,
        "rowsha": "sv7jXy1+zlYZ8hhMVNvjEq7J8BT4RkJJ2afn2CFyHyk=",
        "originContent": "    --model.test_mode vis_memory \\",
        "translatedContent": "    --model.test_mode vis_memory \\"
      },
      {
        "row": 4,
        "rowsha": "YaLMccWSufRiTsk+GoOYdBhkbklyP1j280Pi7lKtRsc=",
        "originContent": "    --ckpt_path $PATH_TO_SAVE_CKPTS/$DATASET_NAME\\_$SHOT\\_refs_memory_postprocessed.pth \\",
        "translatedContent": "    --ckpt_path $PATH_TO_SAVE_CKPTS/$DATASET_NAME\\_$SHOT\\_refs_memory_postprocessed.pth \\"
      },
      {
        "row": 5,
        "rowsha": "+BumbXTQ220P4SshjpoA32nDp/jwiCWbKFKYVi5RYXc=",
        "originContent": "    --model.init_args.dataset_cfgs.fill_memory.root $DATASET_PATH/images \\",
        "translatedContent": "    --model.init_args.dataset_cfgs.fill_memory.root $DATASET_PATH/images \\"
      },
      {
        "row": 6,
        "rowsha": "0QT7QmjYkqhfRshvsrRJCFd1cBt2OEEaPr2ax0WhEPA=",
        "originContent": "    --model.init_args.dataset_cfgs.fill_memory.json_file $DATASET_PATH/annotations/custom_references_with_segm.json \\",
        "translatedContent": "    --model.init_args.dataset_cfgs.fill_memory.json_file $DATASET_PATH/annotations/custom_references_with_segm.json \\"
      },
      {
        "row": 7,
        "rowsha": "SWrctgl0L7Kdk4nV2WBDVityuZNXBo7ZP3vjpFq3q+Y=",
        "originContent": "    --model.init_args.dataset_cfgs.fill_memory.memory_pkl $DATASET_PATH/annotations/custom_references_with_segm.pkl \\",
        "translatedContent": "    --model.init_args.dataset_cfgs.fill_memory.memory_pkl $DATASET_PATH/annotations/custom_references_with_segm.pkl \\"
      },
      {
        "row": 8,
        "rowsha": "ajwBbsJuNblaKhLCmbsz4NzIAKPocJiMx8opaUw7JHc=",
        "originContent": "    --model.init_args.dataset_cfgs.fill_memory.memory_length $SHOT \\",
        "translatedContent": "    --model.init_args.dataset_cfgs.fill_memory.memory_length $SHOT \\"
      },
      {
        "row": 9,
        "rowsha": "CMOv5nGBSogT0gO7wMGjvPW4XkomwTa82Tj0iD9Y3FQ=",
        "originContent": "    --model.init_args.dataset_cfgs.fill_memory.cat_names $CAT_NAMES \\",
        "translatedContent": "    --model.init_args.dataset_cfgs.fill_memory.cat_names $CAT_NAMES \\"
      },
      {
        "row": 10,
        "rowsha": "kjbTFgGn3Au3NL6CMgQDK2RpX6DraWPljNvBjaZwD/Q=",
        "originContent": "    --model.init_args.model_cfg.dataset_name $DATASET_NAME \\",
        "translatedContent": "    --model.init_args.model_cfg.dataset_name $DATASET_NAME \\"
      },
      {
        "row": 11,
        "rowsha": "I/do2Okczknn/9X/8y5Tan5Adh+bBdjM83mpNMTgU1Q=",
        "originContent": "    --model.init_args.model_cfg.memory_bank_cfg.length $SHOT \\",
        "translatedContent": "    --model.init_args.model_cfg.memory_bank_cfg.length $SHOT \\"
      },
      {
        "row": 12,
        "rowsha": "7Cn+uZ9khgahObEB4bul8QUBZse0UStnwto6jY94u64=",
        "originContent": "    --model.init_args.model_cfg.memory_bank_cfg.category_num $CATEGORY_NUM \\",
        "translatedContent": "    --model.init_args.model_cfg.memory_bank_cfg.category_num $CATEGORY_NUM \\"
      },
      {
        "row": 13,
        "rowsha": "MaGbj/BQoWys9ayvwnfa9LJa4GU85A541/zZC+Xlgzo=",
        "originContent": "    --trainer.devices 1",
        "translatedContent": "    --trainer.devices 1"
      },
      {
        "row": 14,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      }
    ],
    "IsCodeBlock": true
  },
  {
    "Id": 45,
    "Content": "PCA and K-means visualisations for the memory bank images are stored in `results_analysis/memory_vis/my_custom_dataset`.\n\n### 3. Inference on target images\n\nIf `ONLINE_VIS` is set to True, prediction results will be saved in `results_analysis/my_custom_dataset/` and displayed as they are computed. NOTE that running with online visualisation is much slower.\n\nFeel free to change the score threshold `VIS_THR` to see more or less segmented instances.",
    "ContentSha": "4E7c2MViriAoxOfwY+eeCB/D3hPi2EsbE37pTJqGFn8=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "ãƒ¡ãƒ¢ãƒªãƒãƒ³ã‚¯ç”»åƒã®PCAãŠã‚ˆã³K-meanså¯è¦–åŒ–çµæœã¯ `results_analysis/memory_vis/my_custom_dataset` ã«ä¿å­˜ã•ã‚Œã¾ã™ã€‚\n\n### 3. ã‚¿ãƒ¼ã‚²ãƒƒãƒˆç”»åƒã§ã®æ¨è«–\n\n`ONLINE_VIS` ãŒTrueã«è¨­å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã€äºˆæ¸¬çµæœã¯ `results_analysis/my_custom_dataset/` ã«ä¿å­˜ã•ã‚Œã€è¨ˆç®—ã•ã‚Œã‚‹ã¨åŒæ™‚ã«è¡¨ç¤ºã•ã‚Œã¾ã™ã€‚ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å¯è¦–åŒ–ã‚’æœ‰åŠ¹ã«ã™ã‚‹ã¨ã€å‡¦ç†é€Ÿåº¦ãŒå¤§å¹…ã«é…ããªã‚‹ã“ã¨ã«æ³¨æ„ã—ã¦ãã ã•ã„ã€‚\n\nã‚»ã‚°ãƒ¡ãƒ³ãƒˆåŒ–ã•ã‚ŒãŸã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®è¡¨ç¤ºæ•°ã‚’å¢—æ¸›ã•ã›ãŸã„å ´åˆã¯ã€ã‚¹ã‚³ã‚¢é–¾å€¤ `VIS_THR` ã‚’è‡ªç”±ã«å¤‰æ›´ã—ã¦ãã ã•ã„ã€‚",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "v06/j8pVoIsYKBBWpbMfxpIB8qMIcJbM2tdkKJl/cIE=",
        "originContent": "PCA and K-means visualisations for the memory bank images are stored in `results_analysis/memory_vis/my_custom_dataset`.",
        "translatedContent": "ãƒ¡ãƒ¢ãƒªãƒãƒ³ã‚¯ç”»åƒã®PCAãŠã‚ˆã³K-meanså¯è¦–åŒ–çµæœã¯ `results_analysis/memory_vis/my_custom_dataset` ã«ä¿å­˜ã•ã‚Œã¾ã™ã€‚"
      },
      {
        "row": 2,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 3,
        "rowsha": "mgJPj3vIyTELe8bZmHn4RAZnA8e/rUDydk+y7d9nDPM=",
        "originContent": "### 3. Inference on target images",
        "translatedContent": "### 3. ã‚¿ãƒ¼ã‚²ãƒƒãƒˆç”»åƒã§ã®æ¨è«–"
      },
      {
        "row": 4,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 5,
        "rowsha": "YM++GYWJ+d+mCXMS9tSUVlwWGrHkv3G/JLx27lurQ0U=",
        "originContent": "If `ONLINE_VIS` is set to True, prediction results will be saved in `results_analysis/my_custom_dataset/` and displayed as they are computed. NOTE that running with online visualisation is much slower.",
        "translatedContent": "`ONLINE_VIS` ãŒTrueã«è¨­å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã€äºˆæ¸¬çµæœã¯ `results_analysis/my_custom_dataset/` ã«ä¿å­˜ã•ã‚Œã€è¨ˆç®—ã•ã‚Œã‚‹ã¨åŒæ™‚ã«è¡¨ç¤ºã•ã‚Œã¾ã™ã€‚ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å¯è¦–åŒ–ã‚’æœ‰åŠ¹ã«ã™ã‚‹ã¨ã€å‡¦ç†é€Ÿåº¦ãŒå¤§å¹…ã«é…ããªã‚‹ã“ã¨ã«æ³¨æ„ã—ã¦ãã ã•ã„ã€‚"
      },
      {
        "row": 6,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 7,
        "rowsha": "XNhHBadyh3RCBpAmQ14NYnkh3kQ6nLbAWUU5I0lwtn8=",
        "originContent": "Feel free to change the score threshold `VIS_THR` to see more or less segmented instances.",
        "translatedContent": "ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåŒ–ã•ã‚ŒãŸã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®è¡¨ç¤ºæ•°ã‚’å¢—æ¸›ã•ã›ãŸã„å ´åˆã¯ã€ã‚¹ã‚³ã‚¢é–¾å€¤ `VIS_THR` ã‚’è‡ªç”±ã«å¤‰æ›´ã—ã¦ãã ã•ã„ã€‚"
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 46,
    "Content": "```bash\nONLINE_VIS=True\nVIS_THR=0.4\npython run_lightening.py test --config $YAML_PATH \\\n    --model.test_mode test \\\n    --ckpt_path $PATH_TO_SAVE_CKPTS/$DATASET_NAME\\_$SHOT\\_refs_memory_postprocessed.pth \\\n    --model.init_args.model_cfg.dataset_name $DATASET_NAME \\\n    --model.init_args.model_cfg.memory_bank_cfg.length $SHOT \\\n    --model.init_args.model_cfg.memory_bank_cfg.category_num $CATEGORY_NUM \\\n    --model.init_args.model_cfg.test.imgs_path $DATASET_PATH/images \\\n    --model.init_args.model_cfg.test.online_vis $ONLINE_VIS \\\n    --model.init_args.model_cfg.test.vis_thr $VIS_THR \\\n    --model.init_args.dataset_cfgs.test.root $DATASET_PATH/images \\\n    --model.init_args.dataset_cfgs.test.json_file $DATASET_PATH/annotations/custom_targets.json \\\n    --model.init_args.dataset_cfgs.test.cat_names $CAT_NAMES \\\n    --trainer.devices 1\n```",
    "ContentSha": "WwpzFHhc6G71aipZFN/unoGoH913SXlW3RG98ipcK1k=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\nONLINE_VIS=True\nVIS_THR=0.4\npython run_lightening.py test --config $YAML_PATH \\\n    --model.test_mode test \\\n    --ckpt_path $PATH_TO_SAVE_CKPTS/$DATASET_NAME\\_$SHOT\\_refs_memory_postprocessed.pth \\\n    --model.init_args.model_cfg.dataset_name $DATASET_NAME \\\n    --model.init_args.model_cfg.memory_bank_cfg.length $SHOT \\\n    --model.init_args.model_cfg.memory_bank_cfg.category_num $CATEGORY_NUM \\\n    --model.init_args.model_cfg.test.imgs_path $DATASET_PATH/images \\\n    --model.init_args.model_cfg.test.online_vis $ONLINE_VIS \\\n    --model.init_args.model_cfg.test.vis_thr $VIS_THR \\\n    --model.init_args.dataset_cfgs.test.root $DATASET_PATH/images \\\n    --model.init_args.dataset_cfgs.test.json_file $DATASET_PATH/annotations/custom_targets.json \\\n    --model.init_args.dataset_cfgs.test.cat_names $CAT_NAMES \\\n    --trainer.devices 1\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 47,
    "Content": "\n### Results\n\nPerformance metrics (with the exact same parameters as commands above) should be:\n",
    "ContentSha": "qUh629YPJLLYOXeHGSusGSWIYdfgfMGmHPttF+Zq0tU=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "### çµæœ\n\nãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™ï¼ˆä¸Šè¨˜ã®ã‚³ãƒãƒ³ãƒ‰ã¨å…¨ãåŒã˜ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ï¼‰ã¯æ¬¡ã®ã¨ãŠã‚Šã§ã™ã€‚\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 48,
    "Content": "```\nBBOX RESULTS:\n  Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.478\n\nSEGM RESULTS:\n  Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.458\n```",
    "ContentSha": "EqM8BsGgWhI+q5ZgXp4DOk8Wayw3iQnYToBVZntlyVI=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```\nBBOX RESULTS:\n  Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.478\n\nSEGM RESULTS:\n  Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.458\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 49,
    "Content": "\nVisual results are saved in `results_analysis/my_custom_dataset/`. Note that our method works for false negatives, that is, images that do not contain any instances of the desired classes.\n\n*Click images to enlarge â¬‡ï¸*\n\n| Target image with boats â›µ (left GT, right predictions) | Target image with birds ğŸ¦ (left GT, right predictions) |\n|:----------------------:|:----------------------:|\n| ![000000459673](https://github.com/user-attachments/assets/678dc15a-dd3b-49d5-9287-6290da16aa6b) | ![000000407180](https://github.com/user-attachments/assets/fe306e48-af49-4d83-ac82-76fac6c456d1) |\n\n| Target image with boats and birds â›µğŸ¦ (left GT, right predictions) | Target image without boats or birds ğŸš« (left GT, right predictions) |\n|:---------------------------------:|:----------------------------------:|\n| ![000000517410](https://github.com/user-attachments/assets/9849b227-7f43-43d7-81ea-58010a623ad5) | ![000000460598](https://github.com/user-attachments/assets/7587700c-e09d-4cf6-8590-3df129c2568e) |\n\n\n## ğŸ“š Citation\n\nIf you use this work, please cite us:\n",
    "ContentSha": "tEYR4ra1661R2TKfAxblzhr7EHrPwy5JI69dHQuD/mM=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "`results_analysis/my_custom_dataset/` ã«è¦–è¦šçš„ãªçµæœãŒä¿å­˜ã•ã‚Œã¾ã™ã€‚ãªãŠã€æœ¬æ‰‹æ³•ã¯å½é™°æ€§ã€ã™ãªã‚ã¡ç›®çš„ã‚¯ãƒ©ã‚¹ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ãŒå«ã¾ã‚Œã¦ã„ãªã„ç”»åƒã«ã‚‚å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚\n\n*ç”»åƒã‚’ã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã¨æ‹¡å¤§è¡¨ç¤ºã•ã‚Œã¾ã™ â¬‡ï¸*\n\n| ãƒœãƒ¼ãƒˆãŒã‚ã‚‹ã‚¿ãƒ¼ã‚²ãƒƒãƒˆç”»åƒ â›µï¼ˆå·¦ï¼šGTã€å³ï¼šäºˆæ¸¬ï¼‰ | é³¥ãŒã„ã‚‹ã‚¿ãƒ¼ã‚²ãƒƒãƒˆç”»åƒ ğŸ¦ï¼ˆå·¦ï¼šGTã€å³ï¼šäºˆæ¸¬ï¼‰ |\n|:----------------------:|:----------------------:|\n| ![000000459673](https://github.com/user-attachments/assets/678dc15a-dd3b-49d5-9287-6290da16aa6b) | ![000000407180](https://github.com/user-attachments/assets/fe306e48-af49-4d83-ac82-76fac6c456d1) |\n\n| ãƒœãƒ¼ãƒˆã¨é³¥ãŒã‚ã‚‹ã‚¿ãƒ¼ã‚²ãƒƒãƒˆç”»åƒ â›µğŸ¦ï¼ˆå·¦ï¼šGTã€å³ï¼šäºˆæ¸¬ï¼‰ | ãƒœãƒ¼ãƒˆã‚„é³¥ãŒã„ãªã„ã‚¿ãƒ¼ã‚²ãƒƒãƒˆç”»åƒ ğŸš«ï¼ˆå·¦ï¼šGTã€å³ï¼šäºˆæ¸¬ï¼‰ |\n|:---------------------------------:|:----------------------------------:|\n| ![000000517410](https://github.com/user-attachments/assets/9849b227-7f43-43d7-81ea-58010a623ad5) | ![000000460598](https://github.com/user-attachments/assets/7587700c-e09d-4cf6-8590-3df129c2568e) |\n\n\n## ğŸ“š å¼•ç”¨\n\næœ¬ç ”ç©¶ã‚’ä½¿ç”¨ã•ã‚Œã‚‹å ´åˆã¯ã€ä»¥ä¸‹ã®ã‚ˆã†ã«å¼•ç”¨ã—ã¦ãã ã•ã„:\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 50,
    "Content": "```bibtex\n@article{espinosa2025notimetotrain,\n  title={No time to train! Training-Free Reference-Based Instance Segmentation},\n  author={Miguel Espinosa and Chenhongyi Yang and Linus Ericsson and Steven McDonagh and Elliot J. Crowley},\n  journal={arXiv preprint arXiv:2507.02798},\n  year={2025},\n  primaryclass={cs.CV}\n}\n```",
    "ContentSha": "wkySuPRHWTRGorn0rwSBqyUnW5RNg9LVe0O7npcbKSs=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bibtex\n@article{espinosa2025notimetotrain,\n  title={No time to train! Training-Free Reference-Based Instance Segmentation},\n  author={Miguel Espinosa and Chenhongyi Yang and Linus Ericsson and Steven McDonagh and Elliot J. Crowley},\n  journal={arXiv preprint arXiv:2507.02798},\n  year={2025},\n  primaryclass={cs.CV}\n}\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 51,
    "Content": "",
    "ContentSha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  }
]