<div align="right">
  <details>
    <summary >ğŸŒ è¯­è¨€</summary>
    <div>
      <div align="center">
        <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=en">English</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=zh-CN">ç®€ä½“ä¸­æ–‡</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=zh-TW">ç¹é«”ä¸­æ–‡</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=ja">æ—¥æœ¬èª</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=ko">í•œêµ­ì–´</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=hi">à¤¹à¤¿à¤¨à¥à¤¦à¥€</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=th">à¹„à¸—à¸¢</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=fr">FranÃ§ais</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=de">Deutsch</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=es">EspaÃ±ol</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=it">Italiano</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=ru">Ğ ÑƒÑÑĞºĞ¸Ğ¹</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=pt">PortuguÃªs</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=nl">Nederlands</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=pl">Polski</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=ar">Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=fa">ÙØ§Ø±Ø³ÛŒ</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=tr">TÃ¼rkÃ§e</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=vi">Tiáº¿ng Viá»‡t</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=id">Bahasa Indonesia</a>
      </div>
    </div>
  </details>
</div>

<div align="center">

# ğŸš€ æ²¡æ—¶é—´è®­ç»ƒï¼
### æ— éœ€è®­ç»ƒçš„åŸºäºå‚è€ƒçš„å®ä¾‹åˆ†å‰²
[![GitHub](https://img.shields.io/badge/%E2%80%8B-No%20Time%20To%20Train-black?logo=github)](https://github.com/miquel-espinosa/no-time-to-train)
[![Website](https://img.shields.io/badge/ğŸŒ-Project%20Page-grey)](https://miquel-espinosa.github.io/no-time-to-train/)
[![arXiv](https://img.shields.io/badge/arXiv-2507.02798-b31b1b)](https://arxiv.org/abs/2507.02798)

**æœ€æ–°æŠ€æœ¯ï¼ˆPapers with Codeï¼‰**

[**_SOTA 1-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-1-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/badge/State%20of%20the%20Art-Few--Shot%20Object%20Detection%20on%20MS--COCO%20(1--shot)-21CBCE?style=flat&logo=paperswithcode)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-1-shot?p=no-time-to-train-training-free-reference)

[**_SOTA 10-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-10-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/badge/State%20of%20the%20Art-Few--Shot%20Object%20Detection%20on%20MS--COCO%20(10--shot)-21CBCE?style=flat&logo=paperswithcode)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-10-shot?p=no-time-to-train-training-free-reference)

[**_SOTA 30-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-30-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/badge/State%20of%20the%20Art-Few--Shot%20Object%20Detection%20on%20MS--COCO%20(30--shot)-21CBCE?style=flat&logo=paperswithcode)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-30-shot?p=no-time-to-train-training-free-reference)

<!-- [**_SOTA 1-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-1-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/no-time-to-train-training-free-reference/few-shot-object-detection-on-ms-coco-1-shot)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-1-shot?p=no-time-to-train-training-free-reference)

[**_SOTA 10-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-10-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/no-time-to-train-training-free-reference/few-shot-object-detection-on-ms-coco-10-shot)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-10-shot?p=no-time-to-train-training-free-reference)

[**_SOTA 30-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-30-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/no-time-to-train-training-free-reference/few-shot-object-detection-on-ms-coco-30-shot)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-30-shot?p=no-time-to-train-training-free-reference) -->

</div>

---

> ğŸš¨ **æ›´æ–°ï¼ˆ2025å¹´7æœˆ22æ—¥ï¼‰ï¼š** å·²æ·»åŠ è‡ªå®šä¹‰æ•°æ®é›†çš„ä½¿ç”¨è¯´æ˜ï¼
> 
> ğŸ”” **æ›´æ–°ï¼ˆ2025å¹´7æœˆ16æ—¥ï¼‰ï¼š** ä»£ç å·²æ›´æ–°å¹¶é™„å¸¦ä½¿ç”¨è¯´æ˜ï¼

---

## ğŸ“‹ ç›®å½•

- [ğŸ¯ äº®ç‚¹](#-äº®ç‚¹)
- [ğŸ“œ æ‘˜è¦](#-æ‘˜è¦)
- [ğŸ§  æ¶æ„](#-æ¶æ„)
- [ğŸ› ï¸ å®‰è£…è¯´æ˜](#ï¸-å®‰è£…è¯´æ˜)
  - [1. å…‹éš†ä»“åº“](#1-å…‹éš†ä»“åº“)
  - [2. åˆ›å»ºcondaç¯å¢ƒ](#2-åˆ›å»ºcondaç¯å¢ƒ)
  - [3. å®‰è£…SAM2å’ŒDinoV2](#3-å®‰è£…sam2å’Œdinov2)
  - [4. ä¸‹è½½æ•°æ®é›†](#4-ä¸‹è½½æ•°æ®é›†)
  - [5. ä¸‹è½½SAM2å’ŒDinoV2æ£€æŸ¥ç‚¹](#5-ä¸‹è½½sam2å’Œdinov2æ£€æŸ¥ç‚¹)
- [ğŸ“Š æ¨ç†ä»£ç ï¼šåœ¨Few-shot COCOä¸Šå¤ç°30-shot SOTAç»“æœ](#-æ¨ç†ä»£ç )
  - [0. åˆ›å»ºå‚è€ƒé›†](#0-åˆ›å»ºå‚è€ƒé›†)
  - [1. ç”¨å‚è€ƒå¡«å……å†…å­˜](#1-ç”¨å‚è€ƒå¡«å……å†…å­˜)
  - [2. åå¤„ç†å†…å­˜åº“](#2-åå¤„ç†å†…å­˜åº“)
  - [3. ç›®æ ‡å›¾åƒæ¨ç†](#3-ç›®æ ‡å›¾åƒæ¨ç†)
  - [ç»“æœ](#ç»“æœ)
- [ğŸ” è‡ªå®šä¹‰æ•°æ®é›†](#-è‡ªå®šä¹‰æ•°æ®é›†)
  - [0. å‡†å¤‡è‡ªå®šä¹‰æ•°æ®é›† â›µğŸ¦](#0-å‡†å¤‡è‡ªå®šä¹‰æ•°æ®é›†)
  - [0.1 ä»…æœ‰bboxæ ‡æ³¨æ—¶](#01-ä»…æœ‰bboxæ ‡æ³¨æ—¶)
  - [0.2 å°†cocoæ ‡æ³¨è½¬ä¸ºpickleæ–‡ä»¶](#02-å°†cocoæ ‡æ³¨è½¬ä¸ºpickleæ–‡ä»¶)
  - [1. ç”¨å‚è€ƒå¡«å……å†…å­˜](#1-ç”¨å‚è€ƒå¡«å……å†…å­˜)
  - [2. åå¤„ç†å†…å­˜åº“](#2-åå¤„ç†å†…å­˜åº“)
- [ğŸ“š å¼•ç”¨](#-å¼•ç”¨)


## ğŸ¯ äº®ç‚¹
- ğŸ’¡ **æ— éœ€è®­ç»ƒ**ï¼šæ— éœ€å¾®è°ƒï¼Œæ— éœ€æç¤ºå·¥ç¨‹â€”â€”åªéœ€ä¸€å¼ å‚è€ƒå›¾ç‰‡ã€‚
- ğŸ–¼ï¸ **åŸºäºå‚è€ƒ**ï¼šåªéœ€å°‘é‡æ ·ä¾‹å³å¯åˆ†å‰²æ–°ç›®æ ‡ã€‚
- ğŸ”¥ **SOTAè¡¨ç°**ï¼šåœ¨COCOã€PASCAL VOCå’Œè·¨åŸŸFSODä¸Šä¼˜äºä»¥å¾€çš„æ— è®­ç»ƒæ–¹æ³•ã€‚

**é“¾æ¥ï¼š**
- ğŸ§¾ [**arXivè®ºæ–‡**](https://arxiv.org/abs/2507.02798)
- ğŸŒ [**é¡¹ç›®ç½‘ç«™**](https://miquel-espinosa.github.io/no-time-to-train/)
- ğŸ“ˆ [**Papers with Code**](https://paperswithcode.com/paper/no-time-to-train-training-free-reference)

## ğŸ“œ æ‘˜è¦


> The performance of image segmentation models has historically been constrained by the high cost of collecting large-scale annotated data. The Segment Anything Model (SAM) alleviates this original problem through a promptable, semantics-agnostic, segmentation paradigm and yet still requires manual visual-prompts or complex domain-dependent prompt-generation rules to process a new image. Towards reducing this new burden, our work investigates the task of object segmentation when provided with, alternatively, only a small set of reference images. Our key insight is to leverage strong semantic priors, as learned by foundation models, to identify corresponding regions between a reference and a target image. We find that correspondences enable automatic generation of instance-level segmentation masks for downstream tasks and instantiate our ideas via a multi-stage, training-free method incorporating (1) memory bank construction; (2) representation aggregation and (3) semantic-aware feature matching. Our experiments show significant improvements on segmentation metrics, leading to state-of-the-art performance on COCO FSOD (36.8% nAP), PASCAL VOC Few-Shot (71.2% nAP50) and outperforming existing training-free approaches on the Cross-Domain FSOD benchmark (22.4% nAP).

![cdfsod-results-final-comic-sans-min](https://github.com/user-attachments/assets/ab302c02-c080-4042-99fc-0e181ba8abb9)


## ğŸ§  Architecture

![training-free-architecture-comic-sans-min](https://github.com/user-attachments/assets/d84dd83a-505e-45a0-8ce3-98e1838017f9)


## ğŸ› ï¸ Installation instructions

### 1. Clone the repository

```bash
git clone https://github.com/miquel-espinosa/no-time-to-train.git
cd no-time-to-train
```
### 2. åˆ›å»º conda ç¯å¢ƒ

æˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ªåŒ…å«æ‰€éœ€è½¯ä»¶åŒ…çš„ conda ç¯å¢ƒã€‚

```bash
conda env create -f environment.yml
conda activate no-time-to-train
```
### 3. å®‰è£… SAM2 å’Œ DinoV2

æˆ‘ä»¬å°†ä»æºç å®‰è£… SAM2 å’Œ DinoV2ã€‚

```bash
pip install -e .
cd dinov2
pip install -e .
cd ..
```
### 4. ä¸‹è½½æ•°æ®é›†

è¯·ä¸‹è½½ COCO æ•°æ®é›†å¹¶å°†å…¶æ”¾ç½®åœ¨ `data/coco`

### 5. ä¸‹è½½ SAM2 å’Œ DinoV2 æ£€æŸ¥ç‚¹

æˆ‘ä»¬å°†ä¸‹è½½è®ºæ–‡ä¸­ä½¿ç”¨çš„ç¡®åˆ‡ SAM2 æ£€æŸ¥ç‚¹ã€‚
ï¼ˆä½†è¯·æ³¨æ„ï¼ŒSAM2.1 æ£€æŸ¥ç‚¹å·²ç»å¯ç”¨ï¼Œä¸”å¯èƒ½è¡¨ç°æ›´å¥½ã€‚ï¼‰


```bash
mkdir -p checkpoints/dinov2
cd checkpoints
wget https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_large.pt
cd dinov2
wget https://dl.fbaipublicfiles.com/dinov2/dinov2_vitl14/dinov2_vitl14_pretrain.pth
cd ../..
```



## ğŸ“Š æ¨ç†ä»£ç 

âš ï¸ å…è´£å£°æ˜ï¼šè¿™æ˜¯ç ”ç©¶ä»£ç â€”â€”å¯èƒ½ä¼šæœ‰äº›æ··ä¹±ï¼

### åœ¨å°‘é‡æ ·æœ¬ COCO ä¸­å¤ç° 30-shot SOTA ç»“æœ

å®šä¹‰æœ‰ç”¨çš„å˜é‡å¹¶åˆ›å»ºç»“æœæ–‡ä»¶å¤¹ï¼š


```bash
CONFIG=./no_time_to_train/new_exps/coco_fewshot_10shot_Sam2L.yaml
CLASS_SPLIT="few_shot_classes"
RESULTS_DIR=work_dirs/few_shot_results
SHOTS=30
SEED=33
GPUS=4

mkdir -p $RESULTS_DIR
FILENAME=few_shot_${SHOTS}shot_seed${SEED}.pkl
```
#### 0. åˆ›å»ºå‚è€ƒé›†


```bash
python no_time_to_train/dataset/few_shot_sampling.py \
        --n-shot $SHOTS \
        --out-path ${RESULTS_DIR}/${FILENAME} \
        --seed $SEED \
        --dataset $CLASS_SPLIT
```
#### 1. ä½¿ç”¨å¼•ç”¨å¡«å……å†…å­˜


```bash
python run_lightening.py test --config $CONFIG \
                              --model.test_mode fill_memory \
                              --out_path ${RESULTS_DIR}/memory.ckpt \
                              --model.init_args.model_cfg.memory_bank_cfg.length $SHOTS \
                              --model.init_args.dataset_cfgs.fill_memory.memory_pkl ${RESULTS_DIR}/${FILENAME} \
                              --model.init_args.dataset_cfgs.fill_memory.memory_length $SHOTS \
                              --model.init_args.dataset_cfgs.fill_memory.class_split $CLASS_SPLIT \
                              --trainer.logger.save_dir ${RESULTS_DIR}/ \
                              --trainer.devices $GPUS
```
#### 2. åå¤„ç†å†…å­˜åº“


```bash
python run_lightening.py test --config $CONFIG \
                              --model.test_mode postprocess_memory \
                              --model.init_args.model_cfg.memory_bank_cfg.length $SHOTS \
                              --ckpt_path ${RESULTS_DIR}/memory.ckpt \
                              --out_path ${RESULTS_DIR}/memory_postprocessed.ckpt \
                              --trainer.devices 1
```
#### 3. å¯¹ç›®æ ‡å›¾åƒçš„æ¨æ–­


```bash
python run_lightening.py test --config $CONFIG  \
                              --ckpt_path ${RESULTS_DIR}/memory_postprocessed.ckpt \
                              --model.init_args.test_mode test \
                              --model.init_args.model_cfg.memory_bank_cfg.length $SHOTS \
                              --model.init_args.model_cfg.dataset_name $CLASS_SPLIT \
                              --model.init_args.dataset_cfgs.test.class_split $CLASS_SPLIT \
                              --trainer.logger.save_dir ${RESULTS_DIR}/ \
                              --trainer.devices $GPUS
```
å¦‚æœæ‚¨å¸Œæœ›åœ¨çº¿æŸ¥çœ‹æ¨ç†ç»“æœï¼ˆåœ¨è®¡ç®—æ—¶æ˜¾ç¤ºï¼‰ï¼Œè¯·å–æ¶ˆæ³¨é‡Š `no_time_to_train/models/Sam2MatchingBaseline_noAMG.py` æ–‡ä»¶ä¸­ç¬¬ 1746-1749 è¡Œ [é“¾æ¥](https://github.com/miquel-espinosa/no-time-to-train/blob/main/no_time_to_train/models/Sam2MatchingBaseline_noAMG.py#L1746)ã€‚
æ ¹æ®éœ€è¦è°ƒæ•´åˆ†æ•°é˜ˆå€¼å‚æ•° `score_thr`ï¼Œä»¥æŸ¥çœ‹æ›´å¤šæˆ–æ›´å°‘çš„åˆ†å‰²å®ä¾‹ã€‚
å›¾ç‰‡ç°åœ¨å°†è¢«ä¿å­˜åœ¨ `results_analysis/few_shot_classes/` ç›®å½•ä¸­ã€‚å·¦ä¾§å›¾ç‰‡æ˜¾ç¤ºçœŸå®æ ‡ç­¾ï¼Œå³ä¾§å›¾ç‰‡æ˜¾ç¤ºæˆ‘ä»¬æ— è®­ç»ƒæ–¹æ³•æ‰¾åˆ°çš„åˆ†å‰²å®ä¾‹ã€‚

è¯·æ³¨æ„ï¼Œåœ¨æœ¬ä¾‹ä¸­æˆ‘ä»¬ä½¿ç”¨çš„æ˜¯ `few_shot_classes` åˆ’åˆ†ï¼Œå› æ­¤ï¼Œæˆ‘ä»¬åªåº”æœŸæœ›çœ‹åˆ°è¯¥åˆ’åˆ†ä¸­çš„ç±»åˆ«è¢«åˆ†å‰²å‡ºæ¥çš„å®ä¾‹ï¼ˆè€Œä¸æ˜¯ COCO ä¸­çš„æ‰€æœ‰ç±»åˆ«ï¼‰ã€‚

#### ç»“æœ

åœ¨è¿è¡Œå®ŒéªŒè¯é›†ä¸­çš„æ‰€æœ‰å›¾ç‰‡åï¼Œæ‚¨åº”è¯¥ä¼šå¾—åˆ°ï¼š


```
BBOX RESULTS:
  Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.368

SEGM RESULTS:
  Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.342
```
---

## ğŸ” è‡ªå®šä¹‰æ•°æ®é›†

æˆ‘ä»¬æä¾›äº†åœ¨è‡ªå®šä¹‰æ•°æ®é›†ä¸Šè¿è¡Œæˆ‘ä»¬æµæ°´çº¿çš„è¯´æ˜ã€‚æ ‡æ³¨æ ¼å¼å§‹ç»ˆä¸º COCO æ ¼å¼ã€‚

> **ç®€è¦è¯´æ˜ï¼š** æƒ³ç›´æ¥äº†è§£å¦‚ä½•åœ¨*è‡ªå®šä¹‰æ•°æ®é›†*ä¸Šè¿è¡Œå®Œæ•´æµæ°´çº¿ï¼Œè¯·å‚è€ƒ `scripts/matching_cdfsod_pipeline.sh` ä»¥åŠ CD-FSOD æ•°æ®é›†çš„ç¤ºä¾‹è„šæœ¬ï¼ˆå¦‚ `scripts/dior_fish.sh`ï¼‰

### 0. å‡†å¤‡è‡ªå®šä¹‰æ•°æ®é›† â›µğŸ¦

å‡è®¾æˆ‘ä»¬æƒ³åœ¨è‡ªå®šä¹‰æ•°æ®é›†ä¸­æ£€æµ‹**èˆ¹åª**â›µ å’Œ**é¸Ÿç±»**ğŸ¦ã€‚ä½¿ç”¨æˆ‘ä»¬çš„æ–¹æ³•éœ€è¦ï¼š
- æ¯ä¸ªç±»åˆ«è‡³å°‘æœ‰ 1 å¼ *æ ‡æ³¨*çš„å‚è€ƒå›¾ç‰‡ï¼ˆå³ 1 å¼ èˆ¹çš„å‚è€ƒå›¾ç‰‡å’Œ 1 å¼ é¸Ÿçš„å‚è€ƒå›¾ç‰‡ï¼‰
- å¤šå¼ ç›®æ ‡å›¾ç‰‡ï¼Œç”¨äºå¯»æ‰¾æˆ‘ä»¬æ‰€éœ€ç±»åˆ«çš„å®ä¾‹ã€‚

æˆ‘ä»¬å·²ç»å‡†å¤‡äº†ä¸€ä¸ªç©å…·è„šæœ¬ï¼Œåˆ©ç”¨ coco å›¾ç‰‡åˆ›å»ºä¸€ä¸ª**1-shot**è®¾ç½®çš„è‡ªå®šä¹‰æ•°æ®é›†ã€‚
```bash
python scripts/make_custom_dataset.py
```
è¿™å°†åˆ›å»ºä¸€ä¸ªå…·æœ‰ä»¥ä¸‹æ–‡ä»¶å¤¹ç»“æ„çš„è‡ªå®šä¹‰æ•°æ®é›†ï¼š
```
data/my_custom_dataset/
    â”œâ”€â”€ annotations/
    â”‚   â”œâ”€â”€ custom_references.json
    â”‚   â”œâ”€â”€ custom_targets.json
    â”‚   â””â”€â”€ references_visualisations/
    â”‚       â”œâ”€â”€ bird_1.jpg
    â”‚       â””â”€â”€ boat_1.jpg
    â””â”€â”€ images/
        â”œâ”€â”€ 429819.jpg
        â”œâ”€â”€ 101435.jpg
        â””â”€â”€ (all target and reference images)
```
**å‚è€ƒå›¾åƒå¯è§†åŒ–ï¼ˆ1-shotï¼‰ï¼š**

| é¸Ÿç±» ğŸ¦ çš„1-shotå‚è€ƒå›¾åƒ | èˆ¹åª â›µ çš„1-shotå‚è€ƒå›¾åƒ |
|:----------------------:|:-----------------------:|
| <img src="https://github.com/user-attachments/assets/e59e580d-a7db-42ac-b386-892af211fc85" alt="bird_1" width="500"/> | <img src="https://github.com/user-attachments/assets/f94ee025-ae37-4a45-9c3e-0cfe8f8cd2bc" alt="boat_1" width="500"/> |


### 0.1 å¦‚æœåªæä¾›äº†bboxæ ‡æ³¨

æˆ‘ä»¬è¿˜æä¾›äº†ä¸€ä¸ªè„šæœ¬ï¼Œåˆ©ç”¨SAM2ç”Ÿæˆå®ä¾‹çº§åˆ†å‰²æ©ç ã€‚å¦‚æœæ‚¨ä»…æœ‰å‚è€ƒå›¾åƒçš„è¾¹ç•Œæ¡†ï¼ˆbounding boxï¼‰æ ‡æ³¨ï¼Œè¿™å°†éå¸¸æœ‰ç”¨ã€‚


```bash
# Download sam_h checkpoint. Feel free to use more recent checkpoints (note: code might need to be adapted)
wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth -O checkpoints/sam_vit_h_4b8939.pth
# Run automatic instance segmentation from ground truth bounding boxes.
python no_time_to_train/dataset/sam_bbox_to_segm_batch.py \
    --input_json data/my_custom_dataset/annotations/custom_references.json \
    --image_dir data/my_custom_dataset/images \
    --sam_checkpoint checkpoints/sam_vit_h_4b8939.pth \
    --model_type vit_h \
    --device cuda \
    --batch_size 8 \
    --visualize
```
**å‚è€ƒå›¾åƒåŠå…¶å®ä¾‹çº§åˆ†å‰²æ©ç ï¼ˆç”± SAM2 æ ¹æ® gt è¾¹ç•Œæ¡†ç”Ÿæˆï¼Œ1-shotï¼‰ï¼š**

ç”Ÿæˆçš„åˆ†å‰²æ©ç çš„å¯è§†åŒ–ç»“æœä¿å­˜åœ¨ `data/my_custom_dataset/annotations/custom_references_with_SAM_segm/references_visualisations/`ã€‚


| BIRD ğŸ¦ çš„ 1-shot å‚è€ƒå›¾åƒï¼ˆç”¨ SAM è‡ªåŠ¨åˆ†å‰²ï¼‰ | BOAT â›µ çš„ 1-shot å‚è€ƒå›¾åƒï¼ˆç”¨ SAM è‡ªåŠ¨åˆ†å‰²ï¼‰ |
|:---------------------------------:|:----------------------------------:|
| <img src="https://github.com/user-attachments/assets/65d38dc4-1454-43cd-9600-e8efc67b3a82" alt="bird_1_with_SAM_segm" width="500"/> | <img src="https://github.com/user-attachments/assets/43a558ad-50ca-4715-8285-9aa3268843c6" alt="boat_1_with_SAM_segm" width="500"/> |


### 0.2 å°† coco æ ‡æ³¨è½¬æ¢ä¸º pickle æ–‡ä»¶


```bash
python no_time_to_train/dataset/coco_to_pkl.py \
    data/my_custom_dataset/annotations/custom_references_with_segm.json \
    data/my_custom_dataset/annotations/custom_references_with_segm.pkl \
    1
```
### 1. ç”¨å¼•ç”¨å¡«å……å†…å­˜

é¦–å…ˆï¼Œå®šä¹‰æœ‰ç”¨çš„å˜é‡å¹¶ä¸ºç»“æœåˆ›å»ºä¸€ä¸ªæ–‡ä»¶å¤¹ã€‚ä¸ºäº†æ­£ç¡®æ˜¾ç¤ºæ ‡ç­¾ï¼Œç±»åˆ«åç§°åº”æŒ‰ json æ–‡ä»¶ä¸­å‡ºç°çš„ç±»åˆ« id é¡ºåºæ’åˆ—ã€‚ä¾‹å¦‚ï¼Œ`bird` çš„ç±»åˆ« id æ˜¯ `16`ï¼Œ`boat` çš„ç±»åˆ« id æ˜¯ `9`ã€‚å› æ­¤ï¼Œ`CAT_NAMES=boat,bird`ã€‚


```bash
DATASET_NAME=my_custom_dataset
DATASET_PATH=data/my_custom_dataset
CAT_NAMES=boat,bird
CATEGORY_NUM=2
SHOT=1
YAML_PATH=no_time_to_train/pl_configs/matching_cdfsod_template.yaml
PATH_TO_SAVE_CKPTS=./tmp_ckpts/my_custom_dataset
mkdir -p $PATH_TO_SAVE_CKPTS
```
è¿è¡Œæ­¥éª¤ 1ï¼š

```bash
python run_lightening.py test --config $YAML_PATH \
    --model.test_mode fill_memory \
    --out_path $PATH_TO_SAVE_CKPTS/$DATASET_NAME\_$SHOT\_refs_memory.pth \
    --model.init_args.dataset_cfgs.fill_memory.root $DATASET_PATH/images \
    --model.init_args.dataset_cfgs.fill_memory.json_file $DATASET_PATH/annotations/custom_references_with_segm.json \
    --model.init_args.dataset_cfgs.fill_memory.memory_pkl $DATASET_PATH/annotations/custom_references_with_segm.pkl \
    --model.init_args.dataset_cfgs.fill_memory.memory_length $SHOT \
    --model.init_args.dataset_cfgs.fill_memory.cat_names $CAT_NAMES \
    --model.init_args.model_cfg.dataset_name $DATASET_NAME \
    --model.init_args.model_cfg.memory_bank_cfg.length $SHOT \
    --model.init_args.model_cfg.memory_bank_cfg.category_num $CATEGORY_NUM \
    --trainer.devices 1
```
### 2. åå¤„ç†å­˜å‚¨åº“


```bash
python run_lightening.py test --config $YAML_PATH \
    --model.test_mode postprocess_memory \
    --ckpt_path $PATH_TO_SAVE_CKPTS/$DATASET_NAME\_$SHOT\_refs_memory.pth \
    --out_path $PATH_TO_SAVE_CKPTS/$DATASET_NAME\_$SHOT\_refs_memory_postprocessed.pth \
    --model.init_args.model_cfg.dataset_name $DATASET_NAME \
    --model.init_args.model_cfg.memory_bank_cfg.length $SHOT \
    --model.init_args.model_cfg.memory_bank_cfg.category_num $CATEGORY_NUM \
    --trainer.devices 1
```
### 3. å¯¹ç›®æ ‡å›¾åƒè¿›è¡Œæ¨ç†

å¦‚æœå°† `ONLINE_VIS` è®¾ç½®ä¸º Trueï¼Œé¢„æµ‹ç»“æœå°†ä¿å­˜åœ¨ `results_analysis/my_custom_dataset/` å¹¶åœ¨è®¡ç®—æ—¶æ˜¾ç¤ºã€‚è¯·æ³¨æ„ï¼Œå¼€å¯åœ¨çº¿å¯è§†åŒ–ä¼šå¤§å¤§é™ä½è¿è¡Œé€Ÿåº¦ã€‚

å¯ä»¥è‡ªç”±ä¿®æ”¹åˆ†æ•°é˜ˆå€¼ `VIS_THR` ä»¥æŸ¥çœ‹æ›´å¤šæˆ–æ›´å°‘çš„åˆ†å‰²å®ä¾‹ã€‚

```bash
ONLINE_VIS=True
VIS_THR=0.4
python run_lightening.py test --config $YAML_PATH \
    --model.test_mode test \
    --ckpt_path $PATH_TO_SAVE_CKPTS/$DATASET_NAME\_$SHOT\_refs_memory_postprocessed.pth \
    --model.init_args.model_cfg.dataset_name $DATASET_NAME \
    --model.init_args.model_cfg.memory_bank_cfg.length $SHOT \
    --model.init_args.model_cfg.memory_bank_cfg.category_num $CATEGORY_NUM \
    --model.init_args.model_cfg.test.imgs_path $DATASET_PATH/images \
    --model.init_args.model_cfg.test.online_vis $ONLINE_VIS \
    --model.init_args.model_cfg.test.vis_thr $VIS_THR \
    --model.init_args.dataset_cfgs.test.root $DATASET_PATH/images \
    --model.init_args.dataset_cfgs.test.json_file $DATASET_PATH/annotations/custom_targets.json \
    --model.init_args.dataset_cfgs.test.cat_names $CAT_NAMES \
    --trainer.devices 1
```
### ç»“æœ

æ€§èƒ½æŒ‡æ ‡ï¼ˆä½¿ç”¨ä¸ä¸Šè¿°å‘½ä»¤å®Œå…¨ç›¸åŒçš„å‚æ•°ï¼‰åº”ä¸ºï¼š


```
BBOX RESULTS:
  Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.478

SEGM RESULTS:
  Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.458
```
å¯è§†åŒ–ç»“æœä¿å­˜åœ¨ `results_analysis/my_custom_dataset/`ã€‚è¯·æ³¨æ„ï¼Œæˆ‘ä»¬çš„æ–¹æ³•é€‚ç”¨äºå‡é˜´æ€§ï¼Œå³ä¸åŒ…å«ä»»ä½•ç›®æ ‡ç±»åˆ«å®ä¾‹çš„å›¾åƒã€‚

*ç‚¹å‡»å›¾ç‰‡æ”¾å¤§ â¬‡ï¸*

| åŒ…å«èˆ¹åªçš„ç›®æ ‡å›¾åƒ â›µï¼ˆå·¦ä¸ºGTï¼Œå³ä¸ºé¢„æµ‹ï¼‰ | åŒ…å«é¸Ÿç±»çš„ç›®æ ‡å›¾åƒ ğŸ¦ï¼ˆå·¦ä¸ºGTï¼Œå³ä¸ºé¢„æµ‹ï¼‰ |
|:----------------------:|:----------------------:|
| ![000000459673](https://github.com/user-attachments/assets/678dc15a-dd3b-49d5-9287-6290da16aa6b) | ![000000407180](https://github.com/user-attachments/assets/fe306e48-af49-4d83-ac82-76fac6c456d1) |

| åŒæ—¶åŒ…å«èˆ¹åªå’Œé¸Ÿç±»çš„ç›®æ ‡å›¾åƒ â›µğŸ¦ï¼ˆå·¦ä¸ºGTï¼Œå³ä¸ºé¢„æµ‹ï¼‰ | ä¸å«èˆ¹åªå’Œé¸Ÿç±»çš„ç›®æ ‡å›¾åƒ ğŸš«ï¼ˆå·¦ä¸ºGTï¼Œå³ä¸ºé¢„æµ‹ï¼‰ |
|:---------------------------------:|:----------------------------------:|
| ![000000517410](https://github.com/user-attachments/assets/9849b227-7f43-43d7-81ea-58010a623ad5) | ![000000460598](https://github.com/user-attachments/assets/7587700c-e09d-4cf6-8590-3df129c2568e) |


## ğŸ“š å¼•ç”¨

å¦‚æœæ‚¨ä½¿ç”¨äº†æœ¬å·¥ä½œï¼Œè¯·å¼•ç”¨æˆ‘ä»¬ï¼š


```bibtex
@article{espinosa2025notimetotrain,
  title={No time to train! Training-Free Reference-Based Instance Segmentation},
  author={Miguel Espinosa and Chenhongyi Yang and Linus Ericsson and Steven McDonagh and Elliot J. Crowley},
  journal={arXiv preprint arXiv:2507.02798},
  year={2025},
  primaryclass={cs.CV}
}
```


---

Tranlated By [Open Ai Tx](https://github.com/OpenAiTx/OpenAiTx) | Last indexed: 2025-07-24

---