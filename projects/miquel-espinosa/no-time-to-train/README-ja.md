
<div align="right">
  <details>
    <summary >ğŸŒ è¨€èª</summary>
    <div>
      <div align="center">
        <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=en">English</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=zh-CN">ç®€ä½“ä¸­æ–‡</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=zh-TW">ç¹é«”ä¸­æ–‡</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=ja">æ—¥æœ¬èª</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=ko">í•œêµ­ì–´</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=hi">à¤¹à¤¿à¤¨à¥à¤¦à¥€</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=th">à¹„à¸—à¸¢</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=fr">FranÃ§ais</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=de">Deutsch</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=es">EspaÃ±ol</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=it">Italiano</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=ru">Ğ ÑƒÑÑĞºĞ¸Ğ¹</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=pt">PortuguÃªs</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=nl">Nederlands</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=pl">Polski</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=ar">Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=fa">ÙØ§Ø±Ø³ÛŒ</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=tr">TÃ¼rkÃ§e</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=vi">Tiáº¿ng Viá»‡t</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=id">Bahasa Indonesia</a>
      </div>
    </div>
  </details>
</div>

<div align="center">

# ğŸš€ ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹æ™‚é–“ãŒãªã„ï¼  
### ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¸è¦ãªãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹ãƒ™ãƒ¼ã‚¹ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³  
[![GitHub](https://img.shields.io/badge/%E2%80%8B-No%20Time%20To%20Train-black?logo=github)](https://github.com/miquel-espinosa/no-time-to-train)
[![Website](https://img.shields.io/badge/ğŸŒ-Project%20Page-grey)](https://miquel-espinosa.github.io/no-time-to-train/)
[![arXiv](https://img.shields.io/badge/arXiv-2507.02798-b31b1b)](https://arxiv.org/abs/2507.02798)

**æœ€å…ˆç«¯ï¼ˆPapers with Codeï¼‰**
[**_SOTA 1-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-1-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/badge/State%20of%20the%20Art-Few--Shot%20Object%20Detection%20on%20MS--COCO%20(1--shot)-21CBCE?style=flat&logo=paperswithcode)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-1-shot?p=no-time-to-train-training-free-reference)

[**_SOTA 10-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-10-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/badge/State%20of%20the%20Art-Few--Shot%20Object%20Detection%20on%20MS--COCO%20(10--shot)-21CBCE?style=flat&logo=paperswithcode)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-10-shot?p=no-time-to-train-training-free-reference)

[**_SOTA 30-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-30-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/badge/State%20of%20the%20Art-Few--Shot%20Object%20Detection%20on%20MS--COCO%20(30--shot)-21CBCE?style=flat&logo=paperswithcode)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-30-shot?p=no-time-to-train-training-free-reference)

<!-- [**_SOTA 1-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-1-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/no-time-to-train-training-free-reference/few-shot-object-detection-on-ms-coco-1-shot)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-1-shot?p=no-time-to-train-training-free-reference)

[**_SOTA 10-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-10-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/no-time-to-train-training-free-reference/few-shot-object-detection-on-ms-coco-10-shot)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-10-shot?p=no-time-to-train-training-free-reference)

[**_SOTA 30-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-30-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/no-time-to-train-training-free-reference/few-shot-object-detection-on-ms-coco-30-shot)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-30-shot?p=no-time-to-train-training-free-reference) -->

</div>

---

> ğŸš¨ **æ›´æ–° (2025å¹´7æœˆ22æ—¥):** ã‚«ã‚¹ã‚¿ãƒ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æ‰‹é †ãŒè¿½åŠ ã•ã‚Œã¾ã—ãŸï¼
> 
> ğŸ”” **æ›´æ–° (2025å¹´7æœˆ16æ—¥):** ã‚³ãƒ¼ãƒ‰ãŒæ‰‹é †ä»˜ãã§æ›´æ–°ã•ã‚Œã¾ã—ãŸï¼

---

## ğŸ“‹ ç›®æ¬¡

- [ğŸ¯ ãƒã‚¤ãƒ©ã‚¤ãƒˆ](#-highlights)
- [ğŸ“œ ã‚¢ãƒ–ã‚¹ãƒˆãƒ©ã‚¯ãƒˆ](#-abstract)
- [ğŸ§  ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£](#-architecture)
- [ğŸ› ï¸ ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ‰‹é †](#ï¸-installation-instructions)
  - [1. ãƒªãƒã‚¸ãƒˆãƒªã®ã‚¯ãƒ­ãƒ¼ãƒ³](#1-clone-the-repository)
  - [2. condaç’°å¢ƒã®ä½œæˆ](#2-create-conda-environment)
  - [3. SAM2ã¨DinoV2ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«](#3-install-sam2-and-dinov2)
  - [4. ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰](#4-download-datasets)
  - [5. SAM2ã¨DinoV2ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰](#5-download-sam2-and-dinov2-checkpoints)
- [ğŸ“Š æ¨è«–ã‚³ãƒ¼ãƒ‰ï¼šFew-shot COCOã§30-shot SOTAçµæœã®å†ç¾](#-inference-code)
  - [0. å‚ç…§ã‚»ãƒƒãƒˆã®ä½œæˆ](#0-create-reference-set)
  - [1. ãƒ¡ãƒ¢ãƒªã«å‚ç…§ã‚’æ ¼ç´](#1-fill-memory-with-references)
  - [2. ãƒ¡ãƒ¢ãƒªãƒãƒ³ã‚¯ã®å¾Œå‡¦ç†](#2-post-process-memory-bank)
  - [3. ã‚¿ãƒ¼ã‚²ãƒƒãƒˆç”»åƒã§æ¨è«–](#3-inference-on-target-images)
  - [çµæœ](#results)

- [ğŸ” ã‚«ã‚¹ã‚¿ãƒ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ](#-custom-dataset)
  - [0. ã‚«ã‚¹ã‚¿ãƒ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æº–å‚™ â›µğŸ¦](#0-prepare-a-custom-dataset)
  - [0.1 ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã®ã¿åˆ©ç”¨å¯èƒ½ãªå ´åˆ](#01-if-only-bbox-annotations-are-available)
  - [0.2 COCOã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’pickleãƒ•ã‚¡ã‚¤ãƒ«ã«å¤‰æ›](#02-convert-coco-annotations-to-pickle-file)
  - [1. ãƒ¡ãƒ¢ãƒªã«å‚ç…§ã‚’æ ¼ç´](#1-fill-memory-with-references)
  - [2. ãƒ¡ãƒ¢ãƒªãƒãƒ³ã‚¯ã®å¾Œå‡¦ç†](#2-post-process-memory-bank)
- [ğŸ“š å¼•ç”¨](#-citation)


## ğŸ¯ ãƒã‚¤ãƒ©ã‚¤ãƒˆ
- ğŸ’¡ **å­¦ç¿’ä¸è¦**: ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚‚ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­è¨ˆã‚‚ä¸è¦â€•â€•å‚ç…§ç”»åƒã®ã¿ã€‚  
- ğŸ–¼ï¸ **å‚ç…§ãƒ™ãƒ¼ã‚¹**: å°‘æ•°ã®ä¾‹ã ã‘ã§æ–°è¦ç‰©ä½“ã‚’ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã€‚  
- ğŸ”¥ **SOTAæ€§èƒ½**: COCOã€PASCAL VOCã€Cross-Domain FSODã«ã¦å¾“æ¥ã®å­¦ç¿’ä¸è¦æ‰‹æ³•ã‚’ä¸Šå›ã‚‹ã€‚

**ãƒªãƒ³ã‚¯:**
- ğŸ§¾ [**arXivè«–æ–‡**](https://arxiv.org/abs/2507.02798)  
- ğŸŒ [**ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆWebã‚µã‚¤ãƒˆ**](https://miquel-espinosa.github.io/no-time-to-train/)  
- ğŸ“ˆ [**Papers with Code**](https://paperswithcode.com/paper/no-time-to-train-training-free-reference)

## ğŸ“œ ã‚¢ãƒ–ã‚¹ãƒˆãƒ©ã‚¯ãƒˆ

> The performance of image segmentation models has historically been constrained by the high cost of collecting large-scale annotated data. The Segment Anything Model (SAM) alleviates this original problem through a promptable, semantics-agnostic, segmentation paradigm and yet still requires manual visual-prompts or complex domain-dependent prompt-generation rules to process a new image. Towards reducing this new burden, our work investigates the task of object segmentation when provided with, alternatively, only a small set of reference images. Our key insight is to leverage strong semantic priors, as learned by foundation models, to identify corresponding regions between a reference and a target image. We find that correspondences enable automatic generation of instance-level segmentation masks for downstream tasks and instantiate our ideas via a multi-stage, training-free method incorporating (1) memory bank construction; (2) representation aggregation and (3) semantic-aware feature matching. Our experiments show significant improvements on segmentation metrics, leading to state-of-the-art performance on COCO FSOD (36.8% nAP), PASCAL VOC Few-Shot (71.2% nAP50) and outperforming existing training-free approaches on the Cross-Domain FSOD benchmark (22.4% nAP).

![cdfsod-results-final-comic-sans-min](https://github.com/user-attachments/assets/ab302c02-c080-4042-99fc-0e181ba8abb9)


## ğŸ§  Architecture

![training-free-architecture-comic-sans-min](https://github.com/user-attachments/assets/d84dd83a-505e-45a0-8ce3-98e1838017f9)


## ğŸ› ï¸ Installation instructions

### 1. Clone the repository

```bash
git clone https://github.com/miquel-espinosa/no-time-to-train.git
cd no-time-to-train
```
### 2. condaç’°å¢ƒã®ä½œæˆ

å¿…è¦ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’å«ã‚€condaç’°å¢ƒã‚’ä½œæˆã—ã¾ã™ã€‚

```bash
conda env create -f environment.yml
conda activate no-time-to-train
```
### 3. SAM2 ã¨ DinoV2 ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

SAM2 ã¨ DinoV2 ã‚’ã‚½ãƒ¼ã‚¹ã‹ã‚‰ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™ã€‚

```bash
pip install -e .
cd dinov2
pip install -e .
cd ..
```
### 4. ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰

COCOãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã€`data/coco` ã«é…ç½®ã—ã¦ãã ã•ã„ã€‚

### 5. SAM2ãŠã‚ˆã³DinoV2ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰

è«–æ–‡ã§ä½¿ç”¨ã•ã‚ŒãŸæ­£ç¢ºãªSAM2ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚
ï¼ˆãŸã ã—ã€SAM2.1ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã¯ã™ã§ã«åˆ©ç”¨å¯èƒ½ã§ã‚ã‚Šã€ã‚ˆã‚Šè‰¯ã„æ€§èƒ½ã‚’ç¤ºã™å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ï¼‰


```bash
mkdir -p checkpoints/dinov2
cd checkpoints
wget https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_large.pt
cd dinov2
wget https://dl.fbaipublicfiles.com/dinov2/dinov2_vitl14/dinov2_vitl14_pretrain.pth
cd ../..
```



## ğŸ“Š æ¨è«–ã‚³ãƒ¼ãƒ‰

âš ï¸ å…è²¬äº‹é …ï¼šã“ã‚Œã¯ç ”ç©¶ç”¨ã‚³ãƒ¼ãƒ‰ã§ã™ â€” å¤šå°‘ã®æ··ä¹±ã¯ã”å®¹èµ¦ãã ã•ã„ï¼

### Few-shot COCOã§30ã‚·ãƒ§ãƒƒãƒˆSOTAçµæœã®å†ç¾

æœ‰ç”¨ãªå¤‰æ•°ã‚’å®šç¾©ã—ã€çµæœç”¨ã®ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆã—ã¾ã™ï¼š


```bash
CONFIG=./no_time_to_train/new_exps/coco_fewshot_10shot_Sam2L.yaml
CLASS_SPLIT="few_shot_classes"
RESULTS_DIR=work_dirs/few_shot_results
SHOTS=30
SEED=33
GPUS=4

mkdir -p $RESULTS_DIR
FILENAME=few_shot_${SHOTS}shot_seed${SEED}.pkl
```
#### 0. å‚ç…§ã‚»ãƒƒãƒˆã®ä½œæˆ


```bash
python no_time_to_train/dataset/few_shot_sampling.py \
        --n-shot $SHOTS \
        --out-path ${RESULTS_DIR}/${FILENAME} \
        --seed $SEED \
        --dataset $CLASS_SPLIT
```
#### 1. å‚ç…§ã§ãƒ¡ãƒ¢ãƒªã‚’åŸ‹ã‚ã‚‹


```bash
python run_lightening.py test --config $CONFIG \
                              --model.test_mode fill_memory \
                              --out_path ${RESULTS_DIR}/memory.ckpt \
                              --model.init_args.model_cfg.memory_bank_cfg.length $SHOTS \
                              --model.init_args.dataset_cfgs.fill_memory.memory_pkl ${RESULTS_DIR}/${FILENAME} \
                              --model.init_args.dataset_cfgs.fill_memory.memory_length $SHOTS \
                              --model.init_args.dataset_cfgs.fill_memory.class_split $CLASS_SPLIT \
                              --trainer.logger.save_dir ${RESULTS_DIR}/ \
                              --trainer.devices $GPUS
```
#### 2. ãƒã‚¹ãƒˆãƒ—ãƒ­ã‚»ã‚¹ãƒ¡ãƒ¢ãƒªãƒãƒ³ã‚¯


```bash
python run_lightening.py test --config $CONFIG \
                              --model.test_mode postprocess_memory \
                              --model.init_args.model_cfg.memory_bank_cfg.length $SHOTS \
                              --ckpt_path ${RESULTS_DIR}/memory.ckpt \
                              --out_path ${RESULTS_DIR}/memory_postprocessed.ckpt \
                              --trainer.devices 1
```
#### 3. å¯¾è±¡ç”»åƒã«å¯¾ã™ã‚‹æ¨è«–


```bash
python run_lightening.py test --config $CONFIG  \
                              --ckpt_path ${RESULTS_DIR}/memory_postprocessed.ckpt \
                              --model.init_args.test_mode test \
                              --model.init_args.model_cfg.memory_bank_cfg.length $SHOTS \
                              --model.init_args.model_cfg.dataset_name $CLASS_SPLIT \
                              --model.init_args.dataset_cfgs.test.class_split $CLASS_SPLIT \
                              --trainer.logger.save_dir ${RESULTS_DIR}/ \
                              --trainer.devices $GPUS
```
æ¨è«–çµæœã‚’ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã§ï¼ˆè¨ˆç®—ã•ã‚Œã‚‹ã¨åŒæ™‚ã«ï¼‰è¡¨ç¤ºã—ãŸã„å ´åˆã¯ã€æ¬¡ã®å¼•æ•°ã‚’è¿½åŠ ã—ã¦ãã ã•ã„:

```bash
    --model.init_args.model_cfg.test.online_vis True
```
ã‚¹ã‚³ã‚¢é–¾å€¤ `score_thr` ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’èª¿æ•´ã™ã‚‹ã«ã¯ã€å¼•æ•°ã‚’è¿½åŠ ã—ã¾ã™ï¼ˆä¾‹ï¼šã‚¹ã‚³ã‚¢ãŒ `0.4` ã‚ˆã‚Šé«˜ã„ã™ã¹ã¦ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å¯è¦–åŒ–ã™ã‚‹å ´åˆï¼‰ã€‚
```bash
    --model.init_args.model_cfg.test.vis_thr 0.4
```
ç”»åƒã¯ `results_analysis/few_shot_classes/` ã«ä¿å­˜ã•ã‚Œã¾ã™ã€‚å·¦å´ã®ç”»åƒã¯æ­£è§£ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã€å³å´ã®ç”»åƒã¯æˆ‘ã€…ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¸è¦ã®æ‰‹æ³•ã§æ¤œå‡ºã•ã‚ŒãŸã‚»ã‚°ãƒ¡ãƒ³ãƒˆåŒ–ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚

ã“ã®ä¾‹ã§ã¯ `few_shot_classes` åˆ†å‰²ã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹ãŸã‚ã€ã“ã®åˆ†å‰²ã«å«ã¾ã‚Œã‚‹ã‚¯ãƒ©ã‚¹ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®ã¿ãŒã‚»ã‚°ãƒ¡ãƒ³ãƒˆåŒ–ã•ã‚Œã‚‹ã“ã¨ãŒæœŸå¾…ã•ã‚Œã¾ã™ï¼ˆCOCOã®ã™ã¹ã¦ã®ã‚¯ãƒ©ã‚¹ã§ã¯ã‚ã‚Šã¾ã›ã‚“ï¼‰ã€‚

#### çµæœ

ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚»ãƒƒãƒˆå†…ã®ã™ã¹ã¦ã®ç”»åƒã‚’å‡¦ç†ã—ãŸå¾Œã€ä»¥ä¸‹ã®ã‚‚ã®ãŒå¾—ã‚‰ã‚Œã‚‹ã¯ãšã§ã™ï¼š

```
BBOX RESULTS:
  Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.368

SEGM RESULTS:
  Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.342
```
---

## ğŸ” ã‚«ã‚¹ã‚¿ãƒ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ

æœ¬ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ã‚«ã‚¹ã‚¿ãƒ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§å®Ÿè¡Œã™ã‚‹æ‰‹é †ã‚’æä¾›ã—ã¾ã™ã€‚ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³å½¢å¼ã¯å¸¸ã«COCOãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§ã™ã€‚

> **TLDR;** *ã‚«ã‚¹ã‚¿ãƒ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ*ã§ãƒ•ãƒ«ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å®Ÿè¡Œã™ã‚‹æ–¹æ³•ã‚’ç›´æ¥ç¢ºèªã—ãŸã„å ´åˆã¯ã€`scripts/matching_cdfsod_pipeline.sh`ãŠã‚ˆã³CD-FSODãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ä¾‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆä¾‹ï¼š`scripts/dior_fish.sh`ï¼‰ã‚’ã”è¦§ãã ã•ã„ã€‚

### 0. ã‚«ã‚¹ã‚¿ãƒ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æº–å‚™ â›µğŸ¦

ã‚«ã‚¹ã‚¿ãƒ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§**ãƒœãƒ¼ãƒˆ**â›µã¨**é³¥**ğŸ¦ã‚’æ¤œå‡ºã—ãŸã„ã¨ä»®å®šã—ã¾ã™ã€‚æœ¬æ‰‹æ³•ã‚’åˆ©ç”¨ã™ã‚‹ã«ã¯ä»¥ä¸‹ãŒå¿…è¦ã§ã™ï¼š
- å„ã‚¯ãƒ©ã‚¹ã”ã¨ã«å°‘ãªãã¨ã‚‚1æšã®*ã‚¢ãƒãƒ†ãƒ¼ãƒˆæ¸ˆã¿*å‚ç…§ç”»åƒï¼ˆä¾‹ï¼šãƒœãƒ¼ãƒˆç”¨1æšã€é³¥ç”¨1æšï¼‰
- å¯¾è±¡ã‚¯ãƒ©ã‚¹ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’è¦‹ã¤ã‘ã‚‹ãŸã‚ã®è¤‡æ•°ã®ã‚¿ãƒ¼ã‚²ãƒƒãƒˆç”»åƒ

COCOç”»åƒã‚’ç”¨ã„ã¦ã‚«ã‚¹ã‚¿ãƒ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆã™ã‚‹ãƒˆã‚¤ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ç”¨æ„ã—ã¦ãŠã‚Šã€**1-shot**è¨­å®šã«å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚
```bash
mkdir -p data/my_custom_dataset
python scripts/make_custom_dataset.py
```
ã“ã‚Œã«ã‚ˆã‚Šã€ä»¥ä¸‹ã®ãƒ•ã‚©ãƒ«ãƒ€æ§‹é€ ã‚’æŒã¤ã‚«ã‚¹ã‚¿ãƒ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒä½œæˆã•ã‚Œã¾ã™ã€‚
```
data/my_custom_dataset/
    â”œâ”€â”€ annotations/
    â”‚   â”œâ”€â”€ custom_references.json
    â”‚   â”œâ”€â”€ custom_targets.json
    â”‚   â””â”€â”€ references_visualisations/
    â”‚       â”œâ”€â”€ bird_1.jpg
    â”‚       â””â”€â”€ boat_1.jpg
    â””â”€â”€ images/
        â”œâ”€â”€ 429819.jpg
        â”œâ”€â”€ 101435.jpg
        â””â”€â”€ (all target and reference images)
```
**å‚ç…§ç”»åƒã®å¯è¦–åŒ–ï¼ˆ1ã‚·ãƒ§ãƒƒãƒˆï¼‰ï¼š**

| BIRD ğŸ¦ ã®1ã‚·ãƒ§ãƒƒãƒˆå‚ç…§ç”»åƒ | BOAT â›µ ã®1ã‚·ãƒ§ãƒƒãƒˆå‚ç…§ç”»åƒ |
|:-----------------------------:|:------------------------------:|
| <img src="https://github.com/user-attachments/assets/e59e580d-a7db-42ac-b386-892af211fc85" alt="bird_1" width="500"/> | <img src="https://github.com/user-attachments/assets/f94ee025-ae37-4a45-9c3e-0cfe8f8cd2bc" alt="boat_1" width="500"/> |


### 0.1 ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã®ã¿ãŒåˆ©ç”¨å¯èƒ½ãªå ´åˆ

å‚ç…§ç”»åƒã«ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã—ã‹ãªã„å ´åˆã«ã‚‚å¯¾å¿œã§ãã‚‹ã‚ˆã†ã€SAM2ã‚’ç”¨ã„ã¦ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ãƒ¬ãƒ™ãƒ«ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒã‚¹ã‚¯ã‚’ç”Ÿæˆã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚‚æä¾›ã—ã¦ã„ã¾ã™ã€‚


```bash
# Download sam_h checkpoint. Feel free to use more recent checkpoints (note: code might need to be adapted)
wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth -O checkpoints/sam_vit_h_4b8939.pth
# Run automatic instance segmentation from ground truth bounding boxes.
python no_time_to_train/dataset/sam_bbox_to_segm_batch.py \
    --input_json data/my_custom_dataset/annotations/custom_references.json \
    --image_dir data/my_custom_dataset/images \
    --sam_checkpoint checkpoints/sam_vit_h_4b8939.pth \
    --model_type vit_h \
    --device cuda \
    --batch_size 8 \
    --visualize
```
**ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ãƒ¬ãƒ™ãƒ«ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒã‚¹ã‚¯ä»˜ãå‚ç…§ç”»åƒï¼ˆgtãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã‹ã‚‰SAM2ã§ç”Ÿæˆã€1-shotï¼‰ï¼š**

ç”Ÿæˆã•ã‚ŒãŸã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒã‚¹ã‚¯ã®å¯è¦–åŒ–ã¯ã€`data/my_custom_dataset/annotations/custom_references_with_SAM_segm/references_visualisations/` ã«ä¿å­˜ã•ã‚Œã¦ã„ã¾ã™ã€‚


| BIRD ğŸ¦ ã®1-shotå‚ç…§ç”»åƒï¼ˆSAMã§è‡ªå‹•ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåŒ–ï¼‰ | BOAT â›µ ã®1-shotå‚ç…§ç”»åƒï¼ˆSAMã§è‡ªå‹•ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåŒ–ï¼‰ |
|:---------------------------------:|:----------------------------------:|
| <img src="https://github.com/user-attachments/assets/65d38dc4-1454-43cd-9600-e8efc67b3a82" alt="bird_1_with_SAM_segm" width="500"/> | <img src="https://github.com/user-attachments/assets/43a558ad-50ca-4715-8285-9aa3268843c6" alt="boat_1_with_SAM_segm" width="500"/> |


### 0.2 cocoã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’pickleãƒ•ã‚¡ã‚¤ãƒ«ã«å¤‰æ›


```bash
python no_time_to_train/dataset/coco_to_pkl.py \
    data/my_custom_dataset/annotations/custom_references_with_segm.json \
    data/my_custom_dataset/annotations/custom_references_with_segm.pkl \
    1
```
### 1. å‚ç…§ã§ãƒ¡ãƒ¢ãƒªã‚’åŸ‹ã‚ã‚‹

æœ€åˆã«ã€ä¾¿åˆ©ãªå¤‰æ•°ã‚’å®šç¾©ã—ã€çµæœç”¨ã®ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆã—ã¾ã™ã€‚ãƒ©ãƒ™ãƒ«ã‚’æ­£ã—ãå¯è¦–åŒ–ã™ã‚‹ãŸã‚ã«ã¯ã€ã‚¯ãƒ©ã‚¹åã‚’jsonãƒ•ã‚¡ã‚¤ãƒ«ã«è¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹ã‚«ãƒ†ã‚´ãƒªIDé †ã«ä¸¦ã¹ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ä¾‹ï¼š`bird` ã®ã‚«ãƒ†ã‚´ãƒªIDã¯ `16`ã€`boat` ã®ã‚«ãƒ†ã‚´ãƒªIDã¯ `9` ã§ã™ã€‚ã—ãŸãŒã£ã¦ã€`CAT_NAMES=boat,bird` ã¨ãªã‚Šã¾ã™ã€‚


```bash
DATASET_NAME=my_custom_dataset
DATASET_PATH=data/my_custom_dataset
CAT_NAMES=boat,bird
CATEGORY_NUM=2
SHOT=1
YAML_PATH=no_time_to_train/pl_configs/matching_cdfsod_template.yaml
PATH_TO_SAVE_CKPTS=./tmp_ckpts/my_custom_dataset
mkdir -p $PATH_TO_SAVE_CKPTS
```
ã‚¹ãƒ†ãƒƒãƒ—1ã‚’å®Ÿè¡Œã—ã¾ã™ï¼š

```bash
python run_lightening.py test --config $YAML_PATH \
    --model.test_mode fill_memory \
    --out_path $PATH_TO_SAVE_CKPTS/$DATASET_NAME\_$SHOT\_refs_memory.pth \
    --model.init_args.dataset_cfgs.fill_memory.root $DATASET_PATH/images \
    --model.init_args.dataset_cfgs.fill_memory.json_file $DATASET_PATH/annotations/custom_references_with_segm.json \
    --model.init_args.dataset_cfgs.fill_memory.memory_pkl $DATASET_PATH/annotations/custom_references_with_segm.pkl \
    --model.init_args.dataset_cfgs.fill_memory.memory_length $SHOT \
    --model.init_args.dataset_cfgs.fill_memory.cat_names $CAT_NAMES \
    --model.init_args.model_cfg.dataset_name $DATASET_NAME \
    --model.init_args.model_cfg.memory_bank_cfg.length $SHOT \
    --model.init_args.model_cfg.memory_bank_cfg.category_num $CATEGORY_NUM \
    --trainer.devices 1
```
### 2. ãƒã‚¹ãƒˆãƒ—ãƒ­ã‚»ã‚¹ãƒ¡ãƒ¢ãƒªãƒãƒ³ã‚¯


```bash
python run_lightening.py test --config $YAML_PATH \
    --model.test_mode postprocess_memory \
    --ckpt_path $PATH_TO_SAVE_CKPTS/$DATASET_NAME\_$SHOT\_refs_memory.pth \
    --out_path $PATH_TO_SAVE_CKPTS/$DATASET_NAME\_$SHOT\_refs_memory_postprocessed.pth \
    --model.init_args.model_cfg.dataset_name $DATASET_NAME \
    --model.init_args.model_cfg.memory_bank_cfg.length $SHOT \
    --model.init_args.model_cfg.memory_bank_cfg.category_num $CATEGORY_NUM \
    --trainer.devices 1
```
### 3. ã‚¿ãƒ¼ã‚²ãƒƒãƒˆç”»åƒã§ã®æ¨è«–

`ONLINE_VIS` ã‚’ True ã«è¨­å®šã™ã‚‹ã¨ã€äºˆæ¸¬çµæœã¯ `results_analysis/my_custom_dataset/` ã«ä¿å­˜ã•ã‚Œã€è¨ˆç®—ã•ã‚Œã‚‹ã¨åŒæ™‚ã«è¡¨ç¤ºã•ã‚Œã¾ã™ã€‚ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å¯è¦–åŒ–ã‚’æœ‰åŠ¹ã«ã™ã‚‹ã¨å‡¦ç†é€Ÿåº¦ãŒå¤§å¹…ã«é…ããªã‚‹ã®ã§æ³¨æ„ã—ã¦ãã ã•ã„ã€‚

ã‚¹ã‚³ã‚¢é–¾å€¤ `VIS_THR` ã‚’å¤‰æ›´ã—ã¦ã€ã‚ˆã‚Šå¤šãã¾ãŸã¯å°‘ãªã„ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåŒ–ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’è¡¨ç¤ºã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚

```bash
ONLINE_VIS=True
VIS_THR=0.4
python run_lightening.py test --config $YAML_PATH \
    --model.test_mode test \
    --ckpt_path $PATH_TO_SAVE_CKPTS/$DATASET_NAME\_$SHOT\_refs_memory_postprocessed.pth \
    --model.init_args.model_cfg.dataset_name $DATASET_NAME \
    --model.init_args.model_cfg.memory_bank_cfg.length $SHOT \
    --model.init_args.model_cfg.memory_bank_cfg.category_num $CATEGORY_NUM \
    --model.init_args.model_cfg.test.imgs_path $DATASET_PATH/images \
    --model.init_args.model_cfg.test.online_vis $ONLINE_VIS \
    --model.init_args.model_cfg.test.vis_thr $VIS_THR \
    --model.init_args.dataset_cfgs.test.root $DATASET_PATH/images \
    --model.init_args.dataset_cfgs.test.json_file $DATASET_PATH/annotations/custom_targets.json \
    --model.init_args.dataset_cfgs.test.cat_names $CAT_NAMES \
    --trainer.devices 1
```
### çµæœ

ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™ï¼ˆä¸Šè¨˜ã®ã‚³ãƒãƒ³ãƒ‰ã¨å…¨ãåŒã˜ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ï¼‰ã¯æ¬¡ã®ã¨ãŠã‚Šã§ã™ã€‚


```
BBOX RESULTS:
  Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.478

SEGM RESULTS:
  Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.458
```
`results_analysis/my_custom_dataset/` ã«è¦–è¦šçš„ãªçµæœãŒä¿å­˜ã•ã‚Œã¾ã™ã€‚ãªãŠã€æœ¬æ‰‹æ³•ã¯å½é™°æ€§ã€ã™ãªã‚ã¡ç›®çš„ã‚¯ãƒ©ã‚¹ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ãŒå«ã¾ã‚Œã¦ã„ãªã„ç”»åƒã«ã‚‚å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚

*ç”»åƒã‚’ã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã¨æ‹¡å¤§è¡¨ç¤ºã•ã‚Œã¾ã™ â¬‡ï¸*

| ãƒœãƒ¼ãƒˆãŒã‚ã‚‹ã‚¿ãƒ¼ã‚²ãƒƒãƒˆç”»åƒ â›µï¼ˆå·¦ï¼šGTã€å³ï¼šäºˆæ¸¬ï¼‰ | é³¥ãŒã„ã‚‹ã‚¿ãƒ¼ã‚²ãƒƒãƒˆç”»åƒ ğŸ¦ï¼ˆå·¦ï¼šGTã€å³ï¼šäºˆæ¸¬ï¼‰ |
|:----------------------:|:----------------------:|
| ![000000459673](https://github.com/user-attachments/assets/678dc15a-dd3b-49d5-9287-6290da16aa6b) | ![000000407180](https://github.com/user-attachments/assets/fe306e48-af49-4d83-ac82-76fac6c456d1) |

| ãƒœãƒ¼ãƒˆã¨é³¥ãŒã‚ã‚‹ã‚¿ãƒ¼ã‚²ãƒƒãƒˆç”»åƒ â›µğŸ¦ï¼ˆå·¦ï¼šGTã€å³ï¼šäºˆæ¸¬ï¼‰ | ãƒœãƒ¼ãƒˆã‚„é³¥ãŒã„ãªã„ã‚¿ãƒ¼ã‚²ãƒƒãƒˆç”»åƒ ğŸš«ï¼ˆå·¦ï¼šGTã€å³ï¼šäºˆæ¸¬ï¼‰ |
|:---------------------------------:|:----------------------------------:|
| ![000000517410](https://github.com/user-attachments/assets/9849b227-7f43-43d7-81ea-58010a623ad5) | ![000000460598](https://github.com/user-attachments/assets/7587700c-e09d-4cf6-8590-3df129c2568e) |


## ğŸ“š å¼•ç”¨

æœ¬ç ”ç©¶ã‚’ä½¿ç”¨ã•ã‚Œã‚‹å ´åˆã¯ã€ä»¥ä¸‹ã®ã‚ˆã†ã«å¼•ç”¨ã—ã¦ãã ã•ã„:


```bibtex
@article{espinosa2025notimetotrain,
  title={No time to train! Training-Free Reference-Based Instance Segmentation},
  author={Miguel Espinosa and Chenhongyi Yang and Linus Ericsson and Steven McDonagh and Elliot J. Crowley},
  journal={arXiv preprint arXiv:2507.02798},
  year={2025},
  primaryclass={cs.CV}
}
```


---

Tranlated By [Open Ai Tx](https://github.com/OpenAiTx/OpenAiTx) | Last indexed: 2025-09-06

---