[
  {
    "Id": 1,
    "Content": "\n<div align=\"right\">\n  <details>\n    <summary >üåê Language</summary>\n    <div>\n      <div align=\"center\">\n        <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=en\">English</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=zh-CN\">ÁÆÄ‰Ωì‰∏≠Êñá</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=zh-TW\">ÁπÅÈ´î‰∏≠Êñá</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=ja\">Êó•Êú¨Ë™û</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=ko\">ÌïúÍµ≠Ïñ¥</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=hi\">‡§π‡§ø‡§®‡•ç‡§¶‡•Ä</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=th\">‡πÑ‡∏ó‡∏¢</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=fr\">Fran√ßais</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=de\">Deutsch</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=es\">Espa√±ol</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=it\">Italiano</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=ru\">–†—É—Å—Å–∫–∏–π</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=pt\">Portugu√™s</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=nl\">Nederlands</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=pl\">Polski</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=ar\">ÿßŸÑÿπÿ±ÿ®Ÿäÿ©</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=fa\">ŸÅÿßÿ±ÿ≥€å</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=tr\">T√ºrk√ße</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=vi\">Ti·∫øng Vi·ªát</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=id\">Bahasa Indonesia</a>\n      </div>\n    </div>\n  </details>\n</div>\n\n<div align=\"center\">\n\n# üöÄ No Time to Train!  \n### Training-Free Reference-Based Instance Segmentation  \n[![GitHub](https://img.shields.io/badge/%E2%80%8B-No%20Time%20To%20Train-black?logo=github)](https://github.com/miquel-espinosa/no-time-to-train)\n[![Website](https://img.shields.io/badge/üåê-Project%20Page-grey)](https://miquel-espinosa.github.io/no-time-to-train/)\n[![arXiv](https://img.shields.io/badge/arXiv-2507.02798-b31b1b)](https://arxiv.org/abs/2507.02798)\n\n**State-of-the-art (Papers with Code)**\n\n[**_SOTA 1-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-1-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/badge/State%20of%20the%20Art-Few--Shot%20Object%20Detection%20on%20MS--COCO%20(1--shot)-21CBCE?style=flat&logo=paperswithcode)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-1-shot?p=no-time-to-train-training-free-reference)\n\n[**_SOTA 10-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-10-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/badge/State%20of%20the%20Art-Few--Shot%20Object%20Detection%20on%20MS--COCO%20(10--shot)-21CBCE?style=flat&logo=paperswithcode)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-10-shot?p=no-time-to-train-training-free-reference)\n\n[**_SOTA 30-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-30-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/badge/State%20of%20the%20Art-Few--Shot%20Object%20Detection%20on%20MS--COCO%20(30--shot)-21CBCE?style=flat&logo=paperswithcode)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-30-shot?p=no-time-to-train-training-free-reference)\n\n<!-- [**_SOTA 1-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-1-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/no-time-to-train-training-free-reference/few-shot-object-detection-on-ms-coco-1-shot)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-1-shot?p=no-time-to-train-training-free-reference)\n\n[**_SOTA 10-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-10-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/no-time-to-train-training-free-reference/few-shot-object-detection-on-ms-coco-10-shot)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-10-shot?p=no-time-to-train-training-free-reference)\n\n[**_SOTA 30-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-30-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/no-time-to-train-training-free-reference/few-shot-object-detection-on-ms-coco-30-shot)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-30-shot?p=no-time-to-train-training-free-reference) -->\n\n</div>\n\n---\n\n> üö® **Update (22nd July 2025):** Instructions for custom datasets have been added!\n> \n> üîî **Update (16th July 2025):** Code has been updated with instructions!\n\n---\n\n## üìã Table of Contents\n\n- [üéØ Highlights](#-highlights)\n- [üìú Abstract](#-abstract)\n- [üß† Architecture](#-architecture)\n- [üõ†Ô∏è Installation instructions](#Ô∏è-installation-instructions)\n  - [1. Clone the repository](#1-clone-the-repository)\n  - [2. Create conda environment](#2-create-conda-environment)\n  - [3. Install SAM2 and DinoV2](#3-install-sam2-and-dinov2)\n  - [4. Download datasets](#4-download-datasets)\n  - [5. Download SAM2 and DinoV2 checkpoints](#5-download-sam2-and-dinov2-checkpoints)\n- [üìä Inference code: Reproduce 30-shot SOTA results in Few-shot COCO](#-inference-code)\n  - [0. Create reference set](#0-create-reference-set)\n  - [1. Fill memory with references](#1-fill-memory-with-references)\n  - [2. Post-process memory bank](#2-post-process-memory-bank)\n  - [3. Inference on target images](#3-inference-on-target-images)\n  - [Results](#results)\n- [üîç Custom dataset](#-custom-dataset)\n  - [0. Prepare a custom dataset ‚õµüê¶](#0-prepare-a-custom-dataset)\n  - [0.1 If only bbox annotations are available](#01-if-only-bbox-annotations-are-available)\n  - [0.2 Convert coco annotations to pickle file](#02-convert-coco-annotations-to-pickle-file)\n  - [1. Fill memory with references](#1-fill-memory-with-references)\n  - [2. Post-process memory bank](#2-post-process-memory-bank)\n- [üìö Citation](#-citation)\n\n\n## üéØ Highlights\n- üí° **Training-Free**: No fine-tuning, no prompt engineering‚Äîjust a reference image.  \n- üñºÔ∏è **Reference-Based**: Segment new objects using just a few examples.  \n- üî• **SOTA Performance**: Outperforms previous training-free approaches on COCO, PASCAL VOC, and Cross-Domain FSOD.\n\n**Links:**\n- üßæ [**arXiv Paper**](https://arxiv.org/abs/2507.02798)  \n- üåê [**Project Website**](https://miquel-espinosa.github.io/no-time-to-train/)  \n- üìà [**Papers with Code**](https://paperswithcode.com/paper/no-time-to-train-training-free-reference)\n\n## üìú Abstract",
    "ContentSha": "RYp0rCe8ggMemm0g+cHygIzVq4sWOYQx9Cu0GC4vsVY=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "\n<div align=\"right\">\n  <details>\n    <summary >üåê Bahasa</summary>\n    <div>\n      <div align=\"center\">\n        <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=en\">English</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=zh-CN\">ÁÆÄ‰Ωì‰∏≠Êñá</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=zh-TW\">ÁπÅÈ´î‰∏≠Êñá</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=ja\">Êó•Êú¨Ë™û</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=ko\">ÌïúÍµ≠Ïñ¥</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=hi\">‡§π‡§ø‡§®‡•ç‡§¶‡•Ä</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=th\">‡πÑ‡∏ó‡∏¢</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=fr\">Fran√ßais</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=de\">Deutsch</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=es\">Espa√±ol</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=it\">Italiano</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=ru\">–†—É—Å—Å–∫–∏–π</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=pt\">Portugu√™s</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=nl\">Nederlands</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=pl\">Polski</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=ar\">ÿßŸÑÿπÿ±ÿ®Ÿäÿ©</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=fa\">ŸÅÿßÿ±ÿ≥€å</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=tr\">T√ºrk√ße</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=vi\">Ti·∫øng Vi·ªát</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=id\">Bahasa Indonesia</a>\n      </div>\n    </div>\n  </details>\n</div>\n\n<div align=\"center\">\n\n# üöÄ Tidak Ada Waktu untuk Melatih!  \n### Segmentasi Instance Berbasis Referensi Tanpa Pelatihan  \n[![GitHub](https://img.shields.io/badge/%E2%80%8B-No%20Time%20To%20Train-black?logo=github)](https://github.com/miquel-espinosa/no-time-to-train)\n[![Website](https://img.shields.io/badge/üåê-Project%20Page-grey)](https://miquel-espinosa.github.io/no-time-to-train/)\n[![arXiv](https://img.shields.io/badge/arXiv-2507.02798-b31b1b)](https://arxiv.org/abs/2507.02798)\n\n**State-of-the-art (Papers with Code)**\n\n[**_SOTA 1-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-1-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/badge/State%20of%20the%20Art-Few--Shot%20Object%20Detection%20on%20MS--COCO%20(1--shot)-21CBCE?style=flat&logo=paperswithcode)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-1-shot?p=no-time-to-train-training-free-reference)\n\n[**_SOTA 10-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-10-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/badge/State%20of%20the%20Art-Few--Shot%20Object%20Detection%20on%20MS--COCO%20(10--shot)-21CBCE?style=flat&logo=paperswithcode)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-10-shot?p=no-time-to-train-training-free-reference)\n\n[**_SOTA 30-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-30-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/badge/State%20of%20the%20Art-Few--Shot%20Object%20Detection%20on%20MS--COCO%20(30--shot)-21CBCE?style=flat&logo=paperswithcode)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-30-shot?p=no-time-to-train-training-free-reference)\n\n<!-- [**_SOTA 1-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-1-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/no-time-to-train-training-free-reference/few-shot-object-detection-on-ms-coco-1-shot)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-1-shot?p=no-time-to-train-training-free-reference)\n\n[**_SOTA 10-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-10-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/no-time-to-train-training-free-reference/few-shot-object-detection-on-ms-coco-10-shot)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-10-shot?p=no-time-to-train-training-free-reference)\n\n[**_SOTA 30-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-30-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/no-time-to-train-training-free-reference/few-shot-object-detection-on-ms-coco-30-shot)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-30-shot?p=no-time-to-train-training-free-reference) -->\n\n</div>\n\n---\n\n> üö® **Update (22 Juli 2025):** Instruksi untuk dataset kustom telah ditambahkan!\n> \n> üîî **Update (16 Juli 2025):** Kode telah diperbarui beserta instruksinya!\n\n---\n\n## üìã Daftar Isi\n\n- [üéØ Sorotan](#-sorotan)\n- [üìú Abstrak](#-abstrak)\n- [üß† Arsitektur](#-arsitektur)\n- [üõ†Ô∏è Instruksi Instalasi](#Ô∏è-instruksi-instalasi)\n  - [1. Clone repositori](#1-clone-repositori)\n  - [2. Buat environment conda](#2-buat-environment-conda)\n  - [3. Instal SAM2 dan DinoV2](#3-instal-sam2-dan-dinov2)\n  - [4. Unduh dataset](#4-unduh-dataset)\n  - [5. Unduh checkpoint SAM2 dan DinoV2](#5-unduh-checkpoint-sam2-dan-dinov2)\n- [üìä Kode inferensi: Reproduksi hasil SOTA 30-shot pada Few-shot COCO](#-kode-inferensi)\n  - [0. Buat set referensi](#0-buat-set-referensi)\n  - [1. Isi memori dengan referensi](#1-isi-memori-dengan-referensi)\n  - [2. Pascaproses memory bank](#2-pascaproses-memory-bank)\n  - [3. Inferensi pada gambar target](#3-inferensi-pada-gambar-target)\n  - [Hasil](#hasil)\n- [üîç Dataset kustom](#-dataset-kustom)\n  - [0. Siapkan dataset kustom ‚õµüê¶](#0-siapkan-dataset-kustom)\n  - [0.1 Jika hanya tersedia anotasi bbox](#01-jika-hanya-tersedia-anotasi-bbox)\n  - [0.2 Konversi anotasi coco ke file pickle](#02-konversi-anotasi-coco-ke-file-pickle)\n  - [1. Isi memori dengan referensi](#1-isi-memori-dengan-referensi)\n  - [2. Pascaproses memory bank](#2-pascaproses-memory-bank)\n- [üìö Sitasi](#-sitasi)\n\n\n## üéØ Sorotan\n- üí° **Tanpa Pelatihan**: Tanpa fine-tuning, tanpa rekayasa prompt‚Äîhanya butuh gambar referensi.  \n- üñºÔ∏è **Berbasis Referensi**: Segmentasikan objek baru hanya dengan beberapa contoh.  \n- üî• **Performa SOTA**: Mengungguli pendekatan tanpa pelatihan sebelumnya pada COCO, PASCAL VOC, dan Cross-Domain FSOD.\n\n**Tautan:**\n- üßæ [**Makalah arXiv**](https://arxiv.org/abs/2507.02798)  \n- üåê [**Website Proyek**](https://miquel-espinosa.github.io/no-time-to-train/)  \n- üìà [**Papers with Code**](https://paperswithcode.com/paper/no-time-to-train-training-free-reference)\n\n## üìú Abstrak",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 2,
        "rowsha": "cWgam+tnnXudu7i74+ahMEGk/A9dQS+EwWLAIfi3dHk=",
        "originContent": "<div align=\"right\">",
        "translatedContent": "<div align=\"right\">"
      },
      {
        "row": 3,
        "rowsha": "orOcu5ARna/hb3RUkj6dBI8pHTM3WHeTvby17l5E0h0=",
        "originContent": "  <details>",
        "translatedContent": "  <details>"
      },
      {
        "row": 4,
        "rowsha": "TtgkLzblnvP0q9aAIVXt6s2LczXjy5k+QvHKcU0/5Ms=",
        "originContent": "    <summary >üåê Language</summary>",
        "translatedContent": "    <summary >üåê Bahasa</summary>"
      },
      {
        "row": 5,
        "rowsha": "fZtk4rPTAJEEslnbhSVkHEcPlsctYSzAV7CDPL3rJmA=",
        "originContent": "    <div>",
        "translatedContent": "    <div>"
      },
      {
        "row": 6,
        "rowsha": "9KQxOeJSigvTmGWO+mtnl8kZY9zQfueoy8sk4lYm09Q=",
        "originContent": "      <div align=\"center\">",
        "translatedContent": "      <div align=\"center\">"
      },
      {
        "row": 7,
        "rowsha": "G45/LutNWZI9vxtXslbbbHwCOULgzFXWYAhu/93l4zI=",
        "originContent": "        <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=en\">English</a>",
        "translatedContent": "        <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=en\">English</a>"
      },
      {
        "row": 8,
        "rowsha": "Ats18u3YZRckavncoTKGYRiwpbiHfSctTBbIhjCGos0=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=zh-CN\">ÁÆÄ‰Ωì‰∏≠Êñá</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=zh-CN\">ÁÆÄ‰Ωì‰∏≠Êñá</a>"
      },
      {
        "row": 9,
        "rowsha": "lEz2ylDdTMdB9rQtSXgGSpKBCBtWlYkWIREBeO0lors=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=zh-TW\">ÁπÅÈ´î‰∏≠Êñá</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=zh-TW\">ÁπÅÈ´î‰∏≠Êñá</a>"
      },
      {
        "row": 10,
        "rowsha": "97L3ibJEnPIvjf8+YiCmr3atMgUFb6w4O/wC2/BA6/8=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=ja\">Êó•Êú¨Ë™û</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=ja\">Êó•Êú¨Ë™û</a>"
      },
      {
        "row": 11,
        "rowsha": "3oFj7Mkpu+D6QswdcT3vKHKawPNXUF6RcbCVg2PWbsQ=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=ko\">ÌïúÍµ≠Ïñ¥</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=ko\">ÌïúÍµ≠Ïñ¥</a>"
      },
      {
        "row": 12,
        "rowsha": "ZF8CbRf3KWHXQPzg4G6ekXVvORqsWzEevfTrObmVBmE=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=hi\">‡§π‡§ø‡§®‡•ç‡§¶‡•Ä</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=hi\">‡§π‡§ø‡§®‡•ç‡§¶‡•Ä</a>"
      },
      {
        "row": 13,
        "rowsha": "ZtyN4+DuHy9qVSeUKbBY2nye7JCV1FH5IIAYJ8iuxVA=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=th\">‡πÑ‡∏ó‡∏¢</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=th\">‡πÑ‡∏ó‡∏¢</a>"
      },
      {
        "row": 14,
        "rowsha": "wtzRxSgQuRAkU/Q1AiRlvOKvp5J8Dgi8+8ZAkYRT1Mk=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=fr\">Fran√ßais</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=fr\">Fran√ßais</a>"
      },
      {
        "row": 15,
        "rowsha": "5ok7LiijP07K5Z8qLgSjMWA+zgKpfufQnFwisBo9DLA=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=de\">Deutsch</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=de\">Deutsch</a>"
      },
      {
        "row": 16,
        "rowsha": "HvcD3nQvNLh4xFZRvMx9b+Bc5ka6E8sJLqrMtv6u4G8=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=es\">Espa√±ol</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=es\">Espa√±ol</a>"
      },
      {
        "row": 17,
        "rowsha": "r9VPV8xQaIWBEvGEal9OvJLNSS4zTgMiMbGN26yYZvI=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=it\">Italiano</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=it\">Italiano</a>"
      },
      {
        "row": 18,
        "rowsha": "Xy5Fhh1idYriSI/ExdPGiHIMK0rm7aPt0ZcqU6mVMlU=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=ru\">–†—É—Å—Å–∫–∏–π</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=ru\">–†—É—Å—Å–∫–∏–π</a>"
      },
      {
        "row": 19,
        "rowsha": "dbSyNaa/57ty5bbGG7pZQhxzdFEK8F/TaNhnyeOGOR0=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=pt\">Portugu√™s</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=pt\">Portugu√™s</a>"
      },
      {
        "row": 20,
        "rowsha": "kjU5Io0pZZRzjb5adc0mC1Suop9TAc8ftGlC3R7JYoI=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=nl\">Nederlands</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=nl\">Nederlands</a>"
      },
      {
        "row": 21,
        "rowsha": "xowAjymdhYslq9cLyCu6eUUTJCiVR2V1KJZMTFRR5+o=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=pl\">Polski</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=pl\">Polski</a>"
      },
      {
        "row": 22,
        "rowsha": "41MPPnS6gKxjrGVAF9Fkmpeu0lfZ/zjCHi/HKf9BCW4=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=ar\">ÿßŸÑÿπÿ±ÿ®Ÿäÿ©</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=ar\">ÿßŸÑÿπÿ±ÿ®Ÿäÿ©</a>"
      },
      {
        "row": 23,
        "rowsha": "trPBM6f6uyK0oqDU92+2pGrjWXOlpBmlm34RAvqknvY=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=fa\">ŸÅÿßÿ±ÿ≥€å</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=fa\">ŸÅÿßÿ±ÿ≥€å</a>"
      },
      {
        "row": 24,
        "rowsha": "I4vaUyHHnPcJ/do6ED/Bs8dDKau8rbGs7Lu4MlcK8Ho=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=tr\">T√ºrk√ße</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=tr\">T√ºrk√ße</a>"
      },
      {
        "row": 25,
        "rowsha": "KuIxc2kpouXB+JvjrQsu7EjevEWN1zf7o+8wmwox9L0=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=vi\">Ti·∫øng Vi·ªát</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=vi\">Ti·∫øng Vi·ªát</a>"
      },
      {
        "row": 26,
        "rowsha": "YXMw4LVKVlCbi+Zhb3k7txrbP2uu14qlFi++jxrMsHM=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=id\">Bahasa Indonesia</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=id\">Bahasa Indonesia</a>"
      },
      {
        "row": 27,
        "rowsha": "0OM5wNEm0TO56MEBvQzL7AUZM7/3OpgIeqRf2zFre3Q=",
        "originContent": "      </div>",
        "translatedContent": "      </div>"
      },
      {
        "row": 28,
        "rowsha": "fcjTfY+fs8YnY5slBs1sZvWPAqEQR7tzaBDO54skkGQ=",
        "originContent": "    </div>",
        "translatedContent": "    </div>"
      },
      {
        "row": 29,
        "rowsha": "+fQNH2ldI7UM/rqRscP3hUSWAmw1HvQ2wEKDN8JagT0=",
        "originContent": "  </details>",
        "translatedContent": "  </details>"
      },
      {
        "row": 30,
        "rowsha": "qsMmUbEPVnxGG5tPJV1vsfpoWbU2jYvZpRr5IKshzyM=",
        "originContent": "</div>",
        "translatedContent": "</div>"
      },
      {
        "row": 31,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 32,
        "rowsha": "94MDjHJY1ZLwHNTLIEUIfk7TMc9cq1L/1FmwhqBTe/k=",
        "originContent": "<div align=\"center\">",
        "translatedContent": "<div align=\"center\">"
      },
      {
        "row": 33,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 34,
        "rowsha": "M2z5PpMcecoVKOuL1SHlc+Nemsj5RhARR5H/VCXUbU4=",
        "originContent": "# üöÄ No Time to Train!  ",
        "translatedContent": "# üöÄ Tidak Ada Waktu untuk Melatih!  "
      },
      {
        "row": 35,
        "rowsha": "sBABAz4Jw3ska9lsdsi3rPgLmZF2UtZveFVXqUbPW4o=",
        "originContent": "### Training-Free Reference-Based Instance Segmentation  ",
        "translatedContent": "### Segmentasi Instance Berbasis Referensi Tanpa Pelatihan  "
      },
      {
        "row": 36,
        "rowsha": "JtzwGnZRrNQ5I7E9S5GXrFkY4/D5xExLcZYAwT19D64=",
        "originContent": "[![GitHub](https://img.shields.io/badge/%E2%80%8B-No%20Time%20To%20Train-black?logo=github)](https://github.com/miquel-espinosa/no-time-to-train)",
        "translatedContent": "[![GitHub](https://img.shields.io/badge/%E2%80%8B-No%20Time%20To%20Train-black?logo=github)](https://github.com/miquel-espinosa/no-time-to-train)"
      },
      {
        "row": 37,
        "rowsha": "CRyX9LxzyIoLmrrOb7mTcL54XM1hKOGqkgq3VKhx5cE=",
        "originContent": "[![Website](https://img.shields.io/badge/üåê-Project%20Page-grey)](https://miquel-espinosa.github.io/no-time-to-train/)",
        "translatedContent": "[![Website](https://img.shields.io/badge/üåê-Project%20Page-grey)](https://miquel-espinosa.github.io/no-time-to-train/)"
      },
      {
        "row": 38,
        "rowsha": "dt6HOwBuvdMzY99NMmrvjF5F1UqOV/FCSs2Eonn3jFg=",
        "originContent": "[![arXiv](https://img.shields.io/badge/arXiv-2507.02798-b31b1b)](https://arxiv.org/abs/2507.02798)",
        "translatedContent": "[![arXiv](https://img.shields.io/badge/arXiv-2507.02798-b31b1b)](https://arxiv.org/abs/2507.02798)"
      },
      {
        "row": 39,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 40,
        "rowsha": "rSA9HSpS5rcIOZmSZRcPQKvvg2GUNxqsAdOWtJYdOHs=",
        "originContent": "**State-of-the-art (Papers with Code)**",
        "translatedContent": "**State-of-the-art (Papers with Code)**"
      },
      {
        "row": 41,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 42,
        "rowsha": "vX9Z1+qZyC7/kZ0bOC7vbDJManiCGbXqZk8AgQ84qM0=",
        "originContent": "[**_SOTA 1-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-1-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/badge/State%20of%20the%20Art-Few--Shot%20Object%20Detection%20on%20MS--COCO%20(1--shot)-21CBCE?style=flat&logo=paperswithcode)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-1-shot?p=no-time-to-train-training-free-reference)",
        "translatedContent": "[**_SOTA 1-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-1-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/badge/State%20of%20the%20Art-Few--Shot%20Object%20Detection%20on%20MS--COCO%20(1--shot)-21CBCE?style=flat&logo=paperswithcode)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-1-shot?p=no-time-to-train-training-free-reference)"
      },
      {
        "row": 43,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 44,
        "rowsha": "9mNYKE3Y0dXOTQkvb8trTyykMWIJMj3aYvs2wc7Dy/w=",
        "originContent": "[**_SOTA 10-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-10-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/badge/State%20of%20the%20Art-Few--Shot%20Object%20Detection%20on%20MS--COCO%20(10--shot)-21CBCE?style=flat&logo=paperswithcode)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-10-shot?p=no-time-to-train-training-free-reference)",
        "translatedContent": "[**_SOTA 10-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-10-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/badge/State%20of%20the%20Art-Few--Shot%20Object%20Detection%20on%20MS--COCO%20(10--shot)-21CBCE?style=flat&logo=paperswithcode)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-10-shot?p=no-time-to-train-training-free-reference)"
      },
      {
        "row": 45,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 46,
        "rowsha": "M73R//djgj0L2vtwCwYA8Jc2eOp2w4DNk1NVUZYGbTE=",
        "originContent": "[**_SOTA 30-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-30-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/badge/State%20of%20the%20Art-Few--Shot%20Object%20Detection%20on%20MS--COCO%20(30--shot)-21CBCE?style=flat&logo=paperswithcode)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-30-shot?p=no-time-to-train-training-free-reference)",
        "translatedContent": "[**_SOTA 30-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-30-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/badge/State%20of%20the%20Art-Few--Shot%20Object%20Detection%20on%20MS--COCO%20(30--shot)-21CBCE?style=flat&logo=paperswithcode)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-30-shot?p=no-time-to-train-training-free-reference)"
      },
      {
        "row": 47,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 48,
        "rowsha": "4VnWzjwLPfuR2EgQFIxOj01ti/2HIoGSaFN8NvfL/fU=",
        "originContent": "<!-- [**_SOTA 1-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-1-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/no-time-to-train-training-free-reference/few-shot-object-detection-on-ms-coco-1-shot)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-1-shot?p=no-time-to-train-training-free-reference)",
        "translatedContent": "<!-- [**_SOTA 1-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-1-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/no-time-to-train-training-free-reference/few-shot-object-detection-on-ms-coco-1-shot)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-1-shot?p=no-time-to-train-training-free-reference)"
      },
      {
        "row": 49,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 50,
        "rowsha": "5Vzq06fD98ehB9nIJb70JMck7pDlYhuPjdq4pjWemTg=",
        "originContent": "[**_SOTA 10-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-10-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/no-time-to-train-training-free-reference/few-shot-object-detection-on-ms-coco-10-shot)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-10-shot?p=no-time-to-train-training-free-reference)",
        "translatedContent": "[**_SOTA 10-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-10-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/no-time-to-train-training-free-reference/few-shot-object-detection-on-ms-coco-10-shot)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-10-shot?p=no-time-to-train-training-free-reference)"
      },
      {
        "row": 51,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 52,
        "rowsha": "Lp3ysorCxnFgKmvnuiyj8llAyxsgKM6TkSxqVFkAtzo=",
        "originContent": "[**_SOTA 30-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-30-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/no-time-to-train-training-free-reference/few-shot-object-detection-on-ms-coco-30-shot)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-30-shot?p=no-time-to-train-training-free-reference) -->",
        "translatedContent": "[**_SOTA 30-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-30-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/no-time-to-train-training-free-reference/few-shot-object-detection-on-ms-coco-30-shot)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-30-shot?p=no-time-to-train-training-free-reference) -->"
      },
      {
        "row": 53,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 54,
        "rowsha": "qsMmUbEPVnxGG5tPJV1vsfpoWbU2jYvZpRr5IKshzyM=",
        "originContent": "</div>",
        "translatedContent": "</div>"
      },
      {
        "row": 55,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 56,
        "rowsha": "yz+R1U7uMOU+NbK5mQX3Dxae1Un9eJCdPawt78ntjTs=",
        "originContent": "---",
        "translatedContent": "---"
      },
      {
        "row": 57,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 58,
        "rowsha": "B69jZWG+7Bcf3XwTlCrLDq7zJ6R0P5Lb3miM6RyrST8=",
        "originContent": "> üö® **Update (22nd July 2025):** Instructions for custom datasets have been added!",
        "translatedContent": "> üö® **Update (22 Juli 2025):** Instruksi untuk dataset kustom telah ditambahkan!"
      },
      {
        "row": 59,
        "rowsha": "7E+OPR98r724bpCLatg+QHrDaps++r2OJLVtgCKL5Ck=",
        "originContent": "> ",
        "translatedContent": "> "
      },
      {
        "row": 60,
        "rowsha": "NVfWm1HSMwF2EdXfgCXJYKpUZ1HZOJsRMEUiFhVdgqc=",
        "originContent": "> üîî **Update (16th July 2025):** Code has been updated with instructions!",
        "translatedContent": "> üîî **Update (16 Juli 2025):** Kode telah diperbarui beserta instruksinya!"
      },
      {
        "row": 61,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 62,
        "rowsha": "yz+R1U7uMOU+NbK5mQX3Dxae1Un9eJCdPawt78ntjTs=",
        "originContent": "---",
        "translatedContent": "---"
      },
      {
        "row": 63,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 64,
        "rowsha": "gI/1I87HHg3xh0//UJSFC6ZnF4rvkzKNqsRrROy4OT4=",
        "originContent": "## üìã Table of Contents",
        "translatedContent": "## üìã Daftar Isi"
      },
      {
        "row": 65,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 66,
        "rowsha": "nNQUAJIz1LHAKaPCqpOwlWw2V1U6+cxSwWn4SP47dYU=",
        "originContent": "- [üéØ Highlights](#-highlights)",
        "translatedContent": "- [üéØ Sorotan](#-sorotan)"
      },
      {
        "row": 67,
        "rowsha": "Yu2Tht6jyrgb81Dv2Lb3Od+nx0nyGk4T4cj16urKV2U=",
        "originContent": "- [üìú Abstract](#-abstract)",
        "translatedContent": "- [üìú Abstrak](#-abstrak)"
      },
      {
        "row": 68,
        "rowsha": "QlUWr+r6i1bCNXq6zWF9xq7AP6VlaFB+55fzw1uHGh4=",
        "originContent": "- [üß† Architecture](#-architecture)",
        "translatedContent": "- [üß† Arsitektur](#-arsitektur)"
      },
      {
        "row": 69,
        "rowsha": "LvvjM2oWVjYs2n37JdP4KxJEfjrmlXfMHEYRmg3enOQ=",
        "originContent": "- [üõ†Ô∏è Installation instructions](#Ô∏è-installation-instructions)",
        "translatedContent": "- [üõ†Ô∏è Instruksi Instalasi](#Ô∏è-instruksi-instalasi)"
      },
      {
        "row": 70,
        "rowsha": "/PgPyQxwaS0cIQHgVFkC3ij55sWJZfYd1yCTh2nzruo=",
        "originContent": "  - [1. Clone the repository](#1-clone-the-repository)",
        "translatedContent": "  - [1. Clone repositori](#1-clone-repositori)"
      },
      {
        "row": 71,
        "rowsha": "8sUHJDRIkb9dDdybJg2zcT82y2SDBjUvluSFGb9lVBM=",
        "originContent": "  - [2. Create conda environment](#2-create-conda-environment)",
        "translatedContent": "  - [2. Buat environment conda](#2-buat-environment-conda)"
      },
      {
        "row": 72,
        "rowsha": "UVdxTXFnRSDBzVF4T2aUxvPHopcFMYmHxQaW1H6OPgE=",
        "originContent": "  - [3. Install SAM2 and DinoV2](#3-install-sam2-and-dinov2)",
        "translatedContent": "  - [3. Instal SAM2 dan DinoV2](#3-instal-sam2-dan-dinov2)"
      },
      {
        "row": 73,
        "rowsha": "vmGLfIt0mS9Q/YAti3rKk4FenFiuiawcJga8eA1HvOo=",
        "originContent": "  - [4. Download datasets](#4-download-datasets)",
        "translatedContent": "  - [4. Unduh dataset](#4-unduh-dataset)"
      },
      {
        "row": 74,
        "rowsha": "JMFveg/CL8TprnWNKkURn6blL5NhMU16pmzjwIauENc=",
        "originContent": "  - [5. Download SAM2 and DinoV2 checkpoints](#5-download-sam2-and-dinov2-checkpoints)",
        "translatedContent": "  - [5. Unduh checkpoint SAM2 dan DinoV2](#5-unduh-checkpoint-sam2-dan-dinov2)"
      },
      {
        "row": 75,
        "rowsha": "4twIP/tovN+tEN+KOehWNX1x6ADAZktZhaU8S6q3qPk=",
        "originContent": "- [üìä Inference code: Reproduce 30-shot SOTA results in Few-shot COCO](#-inference-code)",
        "translatedContent": "- [üìä Kode inferensi: Reproduksi hasil SOTA 30-shot pada Few-shot COCO](#-kode-inferensi)"
      },
      {
        "row": 76,
        "rowsha": "XAaZ2BUnk0iPaGrcahhfTfiRzOiOmWVMhXy0yS1URIo=",
        "originContent": "  - [0. Create reference set](#0-create-reference-set)",
        "translatedContent": "  - [0. Buat set referensi](#0-buat-set-referensi)"
      },
      {
        "row": 77,
        "rowsha": "CtFWOMU1Fc9CVZLu2Rzmu0KND5cnswQEsU5Mp7Onhvc=",
        "originContent": "  - [1. Fill memory with references](#1-fill-memory-with-references)",
        "translatedContent": "  - [1. Isi memori dengan referensi](#1-isi-memori-dengan-referensi)"
      },
      {
        "row": 78,
        "rowsha": "EJbJqD4ueSk6fQ0G3e/0zkWNB+NbmAqL7F5GXdil5cM=",
        "originContent": "  - [2. Post-process memory bank](#2-post-process-memory-bank)",
        "translatedContent": "  - [2. Pascaproses memory bank](#2-pascaproses-memory-bank)"
      },
      {
        "row": 79,
        "rowsha": "1oE+QeEAJ0TNP+C2O/r0QRzWRsbxz8Blj9YRkbZZZus=",
        "originContent": "  - [3. Inference on target images](#3-inference-on-target-images)",
        "translatedContent": "  - [3. Inferensi pada gambar target](#3-inferensi-pada-gambar-target)"
      },
      {
        "row": 80,
        "rowsha": "0vQANuql7yEE1pWdHwSmSnQDu+2Y61IcAuCgVVNt9wU=",
        "originContent": "  - [Results](#results)",
        "translatedContent": "  - [Hasil](#hasil)"
      },
      {
        "row": 81,
        "rowsha": "5SOCYMb6Mc7UFPt7fW5/7Lk/oGmDIXGNMnIaAiyHGbA=",
        "originContent": "- [üîç Custom dataset](#-custom-dataset)",
        "translatedContent": "- [üîç Dataset kustom](#-dataset-kustom)"
      },
      {
        "row": 82,
        "rowsha": "GMbLjwNZu2OPam7WwwgFxNIlZaCAoQrvEKgT5bfr4wo=",
        "originContent": "  - [0. Prepare a custom dataset ‚õµüê¶](#0-prepare-a-custom-dataset)",
        "translatedContent": "  - [0. Siapkan dataset kustom ‚õµüê¶](#0-siapkan-dataset-kustom)"
      },
      {
        "row": 83,
        "rowsha": "pahrSq5eC+ZtBvhJBCOnwVsXCl3r6dbg5VVcHR60KgA=",
        "originContent": "  - [0.1 If only bbox annotations are available](#01-if-only-bbox-annotations-are-available)",
        "translatedContent": "  - [0.1 Jika hanya tersedia anotasi bbox](#01-jika-hanya-tersedia-anotasi-bbox)"
      },
      {
        "row": 84,
        "rowsha": "EhEJKG9MX3xsHHBuay+P9xPmW+ZFKMXemPkZ3zZftRE=",
        "originContent": "  - [0.2 Convert coco annotations to pickle file](#02-convert-coco-annotations-to-pickle-file)",
        "translatedContent": "  - [0.2 Konversi anotasi coco ke file pickle](#02-konversi-anotasi-coco-ke-file-pickle)"
      },
      {
        "row": 85,
        "rowsha": "CtFWOMU1Fc9CVZLu2Rzmu0KND5cnswQEsU5Mp7Onhvc=",
        "originContent": "  - [1. Fill memory with references](#1-fill-memory-with-references)",
        "translatedContent": "  - [1. Isi memori dengan referensi](#1-isi-memori-dengan-referensi)"
      },
      {
        "row": 86,
        "rowsha": "EJbJqD4ueSk6fQ0G3e/0zkWNB+NbmAqL7F5GXdil5cM=",
        "originContent": "  - [2. Post-process memory bank](#2-post-process-memory-bank)",
        "translatedContent": "  - [2. Pascaproses memory bank](#2-pascaproses-memory-bank)"
      },
      {
        "row": 87,
        "rowsha": "agiJTqQBkN7iJs7zNIHPQ5NaqAmNICzYGlCqSha4QuI=",
        "originContent": "- [üìö Citation](#-citation)",
        "translatedContent": "- [üìö Sitasi](#-sitasi)"
      },
      {
        "row": 88,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 89,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 90,
        "rowsha": "kIeGJFTQ5JJc/jXqjQ9PAg5wubcgfjTL2po5UNDrLQ8=",
        "originContent": "## üéØ Highlights",
        "translatedContent": "## üéØ Sorotan"
      },
      {
        "row": 91,
        "rowsha": "4c0+fbJNN24hIJySSKght3OZNjxykoTxkukVFgkNZok=",
        "originContent": "- üí° **Training-Free**: No fine-tuning, no prompt engineering‚Äîjust a reference image.  ",
        "translatedContent": "- üí° **Tanpa Pelatihan**: Tanpa fine-tuning, tanpa rekayasa prompt‚Äîhanya butuh gambar referensi.  "
      },
      {
        "row": 92,
        "rowsha": "177g7I1Hv/8E1qW/GKY8ESZKs1ERKa8lH2+eSJWPfys=",
        "originContent": "- üñºÔ∏è **Reference-Based**: Segment new objects using just a few examples.  ",
        "translatedContent": "- üñºÔ∏è **Berbasis Referensi**: Segmentasikan objek baru hanya dengan beberapa contoh.  "
      },
      {
        "row": 93,
        "rowsha": "hJVC6fdp5vmCdow9OaINDAoUeIQFo+H4J7X39/laLuQ=",
        "originContent": "- üî• **SOTA Performance**: Outperforms previous training-free approaches on COCO, PASCAL VOC, and Cross-Domain FSOD.",
        "translatedContent": "- üî• **Performa SOTA**: Mengungguli pendekatan tanpa pelatihan sebelumnya pada COCO, PASCAL VOC, dan Cross-Domain FSOD."
      },
      {
        "row": 94,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 95,
        "rowsha": "5t7uSO5Wec1VT7vt46wJD3xShwKEgg8Z6sc6sb/A3n4=",
        "originContent": "**Links:**",
        "translatedContent": "**Tautan:**"
      },
      {
        "row": 96,
        "rowsha": "mSZshukl7MsJrVvQ4IJvfrxptw7xbgh/UwGaEwRqCFk=",
        "originContent": "- üßæ [**arXiv Paper**](https://arxiv.org/abs/2507.02798)  ",
        "translatedContent": "- üßæ [**Makalah arXiv**](https://arxiv.org/abs/2507.02798)  "
      },
      {
        "row": 97,
        "rowsha": "aRS755BdZ7JdxnaQ39257Pg2fZoyNBuqId5PgA6rebk=",
        "originContent": "- üåê [**Project Website**](https://miquel-espinosa.github.io/no-time-to-train/)  ",
        "translatedContent": "- üåê [**Website Proyek**](https://miquel-espinosa.github.io/no-time-to-train/)  "
      },
      {
        "row": 98,
        "rowsha": "W0Ak9nAkjF7nVsfJUEtJvM6CVJHI9t7YMjCvBzmXZzo=",
        "originContent": "- üìà [**Papers with Code**](https://paperswithcode.com/paper/no-time-to-train-training-free-reference)",
        "translatedContent": "- üìà [**Papers with Code**](https://paperswithcode.com/paper/no-time-to-train-training-free-reference)"
      },
      {
        "row": 99,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 100,
        "rowsha": "AdIRiroevVLawnTYJDBh2L1x5u8N8rbImLDszk/n52Q=",
        "originContent": "## üìú Abstract",
        "translatedContent": "## üìú Abstrak"
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 2,
    "Content": "\n> The performance of image segmentation models has historically been constrained by the high cost of collecting large-scale annotated data. The Segment Anything Model (SAM) alleviates this original problem through a promptable, semantics-agnostic, segmentation paradigm and yet still requires manual visual-prompts or complex domain-dependent prompt-generation rules to process a new image. Towards reducing this new burden, our work investigates the task of object segmentation when provided with, alternatively, only a small set of reference images. Our key insight is to leverage strong semantic priors, as learned by foundation models, to identify corresponding regions between a reference and a target image. We find that correspondences enable automatic generation of instance-level segmentation masks for downstream tasks and instantiate our ideas via a multi-stage, training-free method incorporating (1) memory bank construction; (2) representation aggregation and (3) semantic-aware feature matching. Our experiments show significant improvements on segmentation metrics, leading to state-of-the-art performance on COCO FSOD (36.8% nAP), PASCAL VOC Few-Shot (71.2% nAP50) and outperforming existing training-free approaches on the Cross-Domain FSOD benchmark (22.4% nAP).\n\n![cdfsod-results-final-comic-sans-min](https://github.com/user-attachments/assets/ab302c02-c080-4042-99fc-0e181ba8abb9)\n\n\n## üß† Architecture\n\n![training-free-architecture-comic-sans-min](https://github.com/user-attachments/assets/d84dd83a-505e-45a0-8ce3-98e1838017f9)\n\n\n## üõ†Ô∏è Installation instructions\n\n### 1. Clone the repository\n",
    "ContentSha": "91gnhVueIAqK2vby/YaNefXztZdQYn3pNyfNxEwRFms=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "\n> The performance of image segmentation models has historically been constrained by the high cost of collecting large-scale annotated data. The Segment Anything Model (SAM) alleviates this original problem through a promptable, semantics-agnostic, segmentation paradigm and yet still requires manual visual-prompts or complex domain-dependent prompt-generation rules to process a new image. Towards reducing this new burden, our work investigates the task of object segmentation when provided with, alternatively, only a small set of reference images. Our key insight is to leverage strong semantic priors, as learned by foundation models, to identify corresponding regions between a reference and a target image. We find that correspondences enable automatic generation of instance-level segmentation masks for downstream tasks and instantiate our ideas via a multi-stage, training-free method incorporating (1) memory bank construction; (2) representation aggregation and (3) semantic-aware feature matching. Our experiments show significant improvements on segmentation metrics, leading to state-of-the-art performance on COCO FSOD (36.8% nAP), PASCAL VOC Few-Shot (71.2% nAP50) and outperforming existing training-free approaches on the Cross-Domain FSOD benchmark (22.4% nAP).\n\n![cdfsod-results-final-comic-sans-min](https://github.com/user-attachments/assets/ab302c02-c080-4042-99fc-0e181ba8abb9)\n\n\n## üß† Architecture\n\n![training-free-architecture-comic-sans-min](https://github.com/user-attachments/assets/d84dd83a-505e-45a0-8ce3-98e1838017f9)\n\n\n## üõ†Ô∏è Installation instructions\n\n### 1. Clone the repository\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 2,
        "rowsha": "f62KYkH46xSV0RKRpAlERSF/nhSETk2RE3WyAIz5gDw=",
        "originContent": "> The performance of image segmentation models has historically been constrained by the high cost of collecting large-scale annotated data. The Segment Anything Model (SAM) alleviates this original problem through a promptable, semantics-agnostic, segmentation paradigm and yet still requires manual visual-prompts or complex domain-dependent prompt-generation rules to process a new image. Towards reducing this new burden, our work investigates the task of object segmentation when provided with, alternatively, only a small set of reference images. Our key insight is to leverage strong semantic priors, as learned by foundation models, to identify corresponding regions between a reference and a target image. We find that correspondences enable automatic generation of instance-level segmentation masks for downstream tasks and instantiate our ideas via a multi-stage, training-free method incorporating (1) memory bank construction; (2) representation aggregation and (3) semantic-aware feature matching. Our experiments show significant improvements on segmentation metrics, leading to state-of-the-art performance on COCO FSOD (36.8% nAP), PASCAL VOC Few-Shot (71.2% nAP50) and outperforming existing training-free approaches on the Cross-Domain FSOD benchmark (22.4% nAP).",
        "translatedContent": "> The performance of image segmentation models has historically been constrained by the high cost of collecting large-scale annotated data. The Segment Anything Model (SAM) alleviates this original problem through a promptable, semantics-agnostic, segmentation paradigm and yet still requires manual visual-prompts or complex domain-dependent prompt-generation rules to process a new image. Towards reducing this new burden, our work investigates the task of object segmentation when provided with, alternatively, only a small set of reference images. Our key insight is to leverage strong semantic priors, as learned by foundation models, to identify corresponding regions between a reference and a target image. We find that correspondences enable automatic generation of instance-level segmentation masks for downstream tasks and instantiate our ideas via a multi-stage, training-free method incorporating (1) memory bank construction; (2) representation aggregation and (3) semantic-aware feature matching. Our experiments show significant improvements on segmentation metrics, leading to state-of-the-art performance on COCO FSOD (36.8% nAP), PASCAL VOC Few-Shot (71.2% nAP50) and outperforming existing training-free approaches on the Cross-Domain FSOD benchmark (22.4% nAP)."
      },
      {
        "row": 3,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 4,
        "rowsha": "2cFS6Ni4+vEPr5/fIkHNwVjmXSVHJRpd3EN6igllMqk=",
        "originContent": "![cdfsod-results-final-comic-sans-min](https://github.com/user-attachments/assets/ab302c02-c080-4042-99fc-0e181ba8abb9)",
        "translatedContent": "![cdfsod-results-final-comic-sans-min](https://github.com/user-attachments/assets/ab302c02-c080-4042-99fc-0e181ba8abb9)"
      },
      {
        "row": 5,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 6,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 7,
        "rowsha": "9ZwHLgVs/DMTWN3sszXIqi/Yn0AjwM/4BUudMPNrZrc=",
        "originContent": "## üß† Architecture",
        "translatedContent": "## üß† Architecture"
      },
      {
        "row": 8,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 9,
        "rowsha": "9yA6/g3QCBAgAR0tQeKBpaJwjEB0LHNGgYaTP8Odie8=",
        "originContent": "![training-free-architecture-comic-sans-min](https://github.com/user-attachments/assets/d84dd83a-505e-45a0-8ce3-98e1838017f9)",
        "translatedContent": "![training-free-architecture-comic-sans-min](https://github.com/user-attachments/assets/d84dd83a-505e-45a0-8ce3-98e1838017f9)"
      },
      {
        "row": 10,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 11,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 12,
        "rowsha": "waJ0INSC829ifiOOIlQMyceEvWq7ygQ1pzD67dJK+dU=",
        "originContent": "## üõ†Ô∏è Installation instructions",
        "translatedContent": "## üõ†Ô∏è Installation instructions"
      },
      {
        "row": 13,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 14,
        "rowsha": "+xj0fCZBnnk1GY2rxUGAtpalIeN4JdfjLYAPNPmqklw=",
        "originContent": "### 1. Clone the repository",
        "translatedContent": "### 1. Clone the repository"
      },
      {
        "row": 15,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 3,
    "Content": "```bash\ngit clone https://github.com/miquel-espinosa/no-time-to-train.git\ncd no-time-to-train\n```",
    "ContentSha": "FqsX96SwjKeMnD8rrDrd4pfjW32n5SRf0jXIvB4WHz4=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\ngit clone https://github.com/miquel-espinosa/no-time-to-train.git\ncd no-time-to-train\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 4,
    "Content": "\n### 2. Create conda environment\n\nWe will create a conda environment with the required packages.",
    "ContentSha": "xkwDa/DvfDApk69cNg5ORagN7Utfcos+yCxRpQNn6gk=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "### 2. Membuat lingkungan conda\n\nKita akan membuat lingkungan conda dengan paket-paket yang diperlukan.\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 5,
    "Content": "```bash\nconda env create -f environment.yml\nconda activate no-time-to-train\n```",
    "ContentSha": "W1AlselK7qAC1MpunsXhTPA8MG+kwjbpodKBkImFaio=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\nconda env create -f environment.yml\nconda activate no-time-to-train\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 6,
    "Content": "\n### 3. Install SAM2 and DinoV2\n\nWe will install SAM2 and DinoV2 from source.",
    "ContentSha": "qhWNaaTVSpemTiKekSRF2dWJYxX636VdhL+lPiso28M=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "### 3. Instal SAM2 dan DinoV2\n\nKita akan menginstal SAM2 dan DinoV2 dari sumbernya.\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 7,
    "Content": "```bash\npip install -e .\ncd dinov2\npip install -e .\ncd ..\n```",
    "ContentSha": "dMsjJwa9nz+HHMLijmYZdlLh6FmDBGmNlHxywBzbEg4=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\npip install -e .\ncd dinov2\npip install -e .\ncd ..\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 8,
    "Content": "\n### 4. Download datasets\n\nPlease download COCO dataset and place it in `data/coco`\n\n### 5. Download SAM2 and DinoV2 checkpoints\n\nWe will download the exact SAM2 checkpoints used in the paper.\n(Note, however, that SAM2.1 checkpoints are already available and might perform better.)\n",
    "ContentSha": "LTXcwC9KGMiPIiBLXtQVF6Wdi9d19gVIUBX6F+tGTqE=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "### 4. Unduh dataset\n\nSilakan unduh dataset COCO dan letakkan di `data/coco`\n\n### 5. Unduh checkpoint SAM2 dan DinoV2\n\nKami akan mengunduh checkpoint SAM2 yang persis digunakan dalam makalah.\n(Namun, perlu dicatat bahwa checkpoint SAM2.1 sudah tersedia dan mungkin memberikan performa yang lebih baik.)\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 9,
    "Content": "```bash\nmkdir -p checkpoints/dinov2\ncd checkpoints\nwget https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_large.pt\ncd dinov2\nwget https://dl.fbaipublicfiles.com/dinov2/dinov2_vitl14/dinov2_vitl14_pretrain.pth\ncd ../..\n```",
    "ContentSha": "Q/LddAGtfunblX1eLTx7t3Vs+C74LtCdgP/HQ3gIJgk=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\nmkdir -p checkpoints/dinov2\ncd checkpoints\nwget https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_large.pt\ncd dinov2\nwget https://dl.fbaipublicfiles.com/dinov2/dinov2_vitl14/dinov2_vitl14_pretrain.pth\ncd ../..\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 10,
    "Content": "\n\n## üìä Inference code\n\n‚ö†Ô∏è Disclaimer: This is research code ‚Äî expect a bit of chaos!\n\n### Reproducing 30-shot SOTA results in Few-shot COCO\n\nDefine useful variables and create a folder for results:\n",
    "ContentSha": "q8hVlrVr+ps2xB/JxM3tKtF/KxoLX4PepxohltYehb8=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "## üìä Kode Inferensi\n\n‚ö†Ô∏è Penafian: Ini adalah kode penelitian ‚Äî harap maklum jika ada sedikit kekacauan!\n\n### Mereproduksi hasil SOTA 30-shot pada Few-shot COCO\n\nDefinisikan variabel yang diperlukan dan buat folder untuk hasil:\n\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 11,
    "Content": "```bash\nCONFIG=./no_time_to_train/new_exps/coco_fewshot_10shot_Sam2L.yaml\nCLASS_SPLIT=\"few_shot_classes\"\nRESULTS_DIR=work_dirs/few_shot_results\nSHOTS=30\nSEED=33\nGPUS=4\n\nmkdir -p $RESULTS_DIR\nFILENAME=few_shot_${SHOTS}shot_seed${SEED}.pkl\n```",
    "ContentSha": "R03PMGcFnYnvttqgfztGnWdoyJeXMyxFUN7tyR4kpy8=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\nCONFIG=./no_time_to_train/new_exps/coco_fewshot_10shot_Sam2L.yaml\nCLASS_SPLIT=\"few_shot_classes\"\nRESULTS_DIR=work_dirs/few_shot_results\nSHOTS=30\nSEED=33\nGPUS=4\n\nmkdir -p $RESULTS_DIR\nFILENAME=few_shot_${SHOTS}shot_seed${SEED}.pkl\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 12,
    "Content": "\n#### 0. Create reference set\n",
    "ContentSha": "1XrtmJBqIS+6/RHkWmwwopPgE4d3ho+bdPLXEG612YQ=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "#### 0. Buat set referensi\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 13,
    "Content": "```bash\npython no_time_to_train/dataset/few_shot_sampling.py \\\n        --n-shot $SHOTS \\\n        --out-path ${RESULTS_DIR}/${FILENAME} \\\n        --seed $SEED \\\n        --dataset $CLASS_SPLIT\n```",
    "ContentSha": "XMsc+nj2n5gsZtjFdl6ErjVKLXgBoPIrungxtY9mDss=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\npython no_time_to_train/dataset/few_shot_sampling.py \\\n        --n-shot $SHOTS \\\n        --out-path ${RESULTS_DIR}/${FILENAME} \\\n        --seed $SEED \\\n        --dataset $CLASS_SPLIT\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 14,
    "Content": "\n#### 1. Fill memory with references\n",
    "ContentSha": "v8E00SBwAimb411iJf1DGyTZxexOPmC/xK0/B+XBH1g=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "#### 1. Isi memori dengan referensi\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 15,
    "Content": "```bash\npython run_lightening.py test --config $CONFIG \\\n                              --model.test_mode fill_memory \\\n                              --out_path ${RESULTS_DIR}/memory.ckpt \\\n                              --model.init_args.model_cfg.memory_bank_cfg.length $SHOTS \\\n                              --model.init_args.dataset_cfgs.fill_memory.memory_pkl ${RESULTS_DIR}/${FILENAME} \\\n                              --model.init_args.dataset_cfgs.fill_memory.memory_length $SHOTS \\\n                              --model.init_args.dataset_cfgs.fill_memory.class_split $CLASS_SPLIT \\\n                              --trainer.logger.save_dir ${RESULTS_DIR}/ \\\n                              --trainer.devices $GPUS\n```",
    "ContentSha": "1pVePuzaIdQCE/Nx0VoaWhFswuB5Jh1Z68Cw/2D8RkM=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\npython run_lightening.py test --config $CONFIG \\\n                              --model.test_mode fill_memory \\\n                              --out_path ${RESULTS_DIR}/memory.ckpt \\\n                              --model.init_args.model_cfg.memory_bank_cfg.length $SHOTS \\\n                              --model.init_args.dataset_cfgs.fill_memory.memory_pkl ${RESULTS_DIR}/${FILENAME} \\\n                              --model.init_args.dataset_cfgs.fill_memory.memory_length $SHOTS \\\n                              --model.init_args.dataset_cfgs.fill_memory.class_split $CLASS_SPLIT \\\n                              --trainer.logger.save_dir ${RESULTS_DIR}/ \\\n                              --trainer.devices $GPUS\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 16,
    "Content": "\n#### 2. Post-process memory bank\n",
    "ContentSha": "3A9quGczCnAQeUTcoJVGYLTQapI5nQ5aSj7AZIhGFJw=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "#### 2. Memori bank pasca-proses\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 17,
    "Content": "```bash\npython run_lightening.py test --config $CONFIG \\\n                              --model.test_mode postprocess_memory \\\n                              --model.init_args.model_cfg.memory_bank_cfg.length $SHOTS \\\n                              --ckpt_path ${RESULTS_DIR}/memory.ckpt \\\n                              --out_path ${RESULTS_DIR}/memory_postprocessed.ckpt \\\n                              --trainer.devices 1\n```",
    "ContentSha": "45qs8EyMtDUKs5A3rrQcJQXl6OIbI6s0rKOOnHmYURs=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\npython run_lightening.py test --config $CONFIG \\\n                              --model.test_mode postprocess_memory \\\n                              --model.init_args.model_cfg.memory_bank_cfg.length $SHOTS \\\n                              --ckpt_path ${RESULTS_DIR}/memory.ckpt \\\n                              --out_path ${RESULTS_DIR}/memory_postprocessed.ckpt \\\n                              --trainer.devices 1\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 18,
    "Content": "\n#### 3. Inference on target images\n",
    "ContentSha": "73CbGioqWaTULTrw0roBLoZCxgBgtmJVFDc7RHluH0g=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "#### 3. Inferensi pada gambar target\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 19,
    "Content": "```bash\npython run_lightening.py test --config $CONFIG  \\\n                              --ckpt_path ${RESULTS_DIR}/memory_postprocessed.ckpt \\\n                              --model.init_args.test_mode test \\\n                              --model.init_args.model_cfg.memory_bank_cfg.length $SHOTS \\\n                              --model.init_args.model_cfg.dataset_name $CLASS_SPLIT \\\n                              --model.init_args.dataset_cfgs.test.class_split $CLASS_SPLIT \\\n                              --trainer.logger.save_dir ${RESULTS_DIR}/ \\\n                              --trainer.devices $GPUS\n```",
    "ContentSha": "vbKXVEs47fJ5oF8vLkHVM2ofFMx1hKBBgQF9JAgp2Jo=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\npython run_lightening.py test --config $CONFIG  \\\n                              --ckpt_path ${RESULTS_DIR}/memory_postprocessed.ckpt \\\n                              --model.init_args.test_mode test \\\n                              --model.init_args.model_cfg.memory_bank_cfg.length $SHOTS \\\n                              --model.init_args.model_cfg.dataset_name $CLASS_SPLIT \\\n                              --model.init_args.dataset_cfgs.test.class_split $CLASS_SPLIT \\\n                              --trainer.logger.save_dir ${RESULTS_DIR}/ \\\n                              --trainer.devices $GPUS\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 20,
    "Content": "\nIf you'd like to see inference results online (as they are computed), uncomment lines 1746-1749 in `no_time_to_train/models/Sam2MatchingBaseline_noAMG.py` [here](https://github.com/miquel-espinosa/no-time-to-train/blob/main/no_time_to_train/models/Sam2MatchingBaseline_noAMG.py#L1746).\nAdjust the score threshold `score_thr` parameter as needed to see more or less segmented instances.\nImages will now be saved in `results_analysis/few_shot_classes/`. The image on the left shows the ground truth, the image on the right shows the segmented instances found by our training-free method.\n\nNote that in this example we are using the `few_shot_classes` split, thus, we should only expect to see segmented instances of the classes in this split (not all classes in COCO).\n\n#### Results\n\nAfter running all images in the validation set, you should obtain:\n",
    "ContentSha": "medzMxexFQJT2fGG5e8YEfmHZEa9eQ27lN3/GcxqnNU=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "Jika Anda ingin melihat hasil inferensi secara online (saat sedang dihitung), hapus komentar pada baris 1746-1749 di `no_time_to_train/models/Sam2MatchingBaseline_noAMG.py` [di sini](https://github.com/miquel-espinosa/no-time-to-train/blob/main/no_time_to_train/models/Sam2MatchingBaseline_noAMG.py#L1746).\nSesuaikan parameter ambang skor `score_thr` sesuai kebutuhan untuk melihat lebih banyak atau lebih sedikit instance yang disegmentasi.\nGambar sekarang akan disimpan di `results_analysis/few_shot_classes/`. Gambar di sebelah kiri menunjukkan ground truth, gambar di sebelah kanan menunjukkan instance yang disegmentasi yang ditemukan oleh metode tanpa pelatihan kami.\n\nPerhatikan bahwa pada contoh ini kita menggunakan split `few_shot_classes`, sehingga, kita hanya mengharapkan melihat instance yang disegmentasi dari kelas-kelas dalam split ini (bukan semua kelas di COCO).\n\n#### Hasil\n\nSetelah menjalankan semua gambar dalam set validasi, Anda seharusnya mendapatkan:\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 21,
    "Content": "```\nBBOX RESULTS:\n  Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.368\n\nSEGM RESULTS:\n  Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.342\n```",
    "ContentSha": "ch7itB3Sk8oLc3U+lNJGI3BV57wpOMkabTBsUiqzHDU=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```\nBBOX RESULTS:\n  Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.368\n\nSEGM RESULTS:\n  Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.342\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 22,
    "Content": "---\n\n## üîç Custom dataset\n\nWe provide the instructions for running our pipeline on a custom dataset. Annotation format are always in COCO format.\n\n> **TLDR;** To directly see how to run full pipeline on *custom datasets*, find `scripts/matching_cdfsod_pipeline.sh` together with example scripts of CD-FSOD datasets (e.g. `scripts/dior_fish.sh`)\n\n### 0. Prepare a custom dataset ‚õµüê¶\n\nLet's imagine we want to detect **boats**‚õµ and **birds**üê¶ in a custom dataset. To use our method we will need:\n- At least 1 *annotated* reference image for each class (i.e. 1 reference image for boat and 1 reference image for bird)\n- Multiple target images to find instances of our desired classes.\n\nWe have prepared a toy script to create a custom dataset with coco images, for a **1-shot** setting.",
    "ContentSha": "IPUeWphY2t966UmztjMo0ja/aOT1Wd0H0rkyNv8xt9Y=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "---\n\n## üîç Dataset kustom\n\nKami menyediakan instruksi untuk menjalankan pipeline kami pada dataset kustom. Format anotasi selalu menggunakan format COCO.\n\n> **TLDR;** Untuk langsung melihat cara menjalankan pipeline lengkap pada *dataset kustom*, temukan `scripts/matching_cdfsod_pipeline.sh` bersama dengan contoh skrip dataset CD-FSOD (misal `scripts/dior_fish.sh`)\n\n### 0. Siapkan dataset kustom ‚õµüê¶\n\nBayangkan kita ingin mendeteksi **perahu**‚õµ dan **burung**üê¶ dalam dataset kustom. Untuk menggunakan metode kami, kita akan membutuhkan:\n- Minimal 1 gambar referensi *yang sudah dianotasi* untuk setiap kelas (yaitu 1 gambar referensi untuk perahu dan 1 gambar referensi untuk burung)\n- Beberapa gambar target untuk menemukan instance dari kelas yang diinginkan.\n\nKami telah menyiapkan skrip sederhana untuk membuat dataset kustom dengan gambar coco, untuk skenario **1-shot**.",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 23,
    "Content": "```bash\npython scripts/make_custom_dataset.py\n```",
    "ContentSha": "Hjl+Pq3rFu2WuUdTIP37/i6uaUCEix81AF5Q9+tja9Y=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\npython scripts/make_custom_dataset.py\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 24,
    "Content": "This will create a custom dataset with the following folder structure:",
    "ContentSha": "9JGOKHf/Hqbdn+b2OqaUnKIYD8GGf7jwfM9mTbUtoP4=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "Ini akan membuat dataset khusus dengan struktur folder sebagai berikut:",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 25,
    "Content": "```\ndata/my_custom_dataset/\n    ‚îú‚îÄ‚îÄ annotations/\n    ‚îÇ   ‚îú‚îÄ‚îÄ custom_references.json\n    ‚îÇ   ‚îú‚îÄ‚îÄ custom_targets.json\n    ‚îÇ   ‚îî‚îÄ‚îÄ references_visualisations/\n    ‚îÇ       ‚îú‚îÄ‚îÄ bird_1.jpg\n    ‚îÇ       ‚îî‚îÄ‚îÄ boat_1.jpg\n    ‚îî‚îÄ‚îÄ images/\n        ‚îú‚îÄ‚îÄ 429819.jpg\n        ‚îú‚îÄ‚îÄ 101435.jpg\n        ‚îî‚îÄ‚îÄ (all target and reference images)\n```",
    "ContentSha": "Bj/IFZkQUfkoGUwynry3llvasPwDhX0B0JgBYl9vuQE=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```\ndata/my_custom_dataset/\n    ‚îú‚îÄ‚îÄ annotations/\n    ‚îÇ   ‚îú‚îÄ‚îÄ custom_references.json\n    ‚îÇ   ‚îú‚îÄ‚îÄ custom_targets.json\n    ‚îÇ   ‚îî‚îÄ‚îÄ references_visualisations/\n    ‚îÇ       ‚îú‚îÄ‚îÄ bird_1.jpg\n    ‚îÇ       ‚îî‚îÄ‚îÄ boat_1.jpg\n    ‚îî‚îÄ‚îÄ images/\n        ‚îú‚îÄ‚îÄ 429819.jpg\n        ‚îú‚îÄ‚îÄ 101435.jpg\n        ‚îî‚îÄ‚îÄ (all target and reference images)\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 26,
    "Content": "\n**Reference images visualisation (1-shot):**\n\n| 1-shot Reference Image for BIRD üê¶ | 1-shot Reference Image for BOAT ‚õµ |\n|:---------------------------------:|:----------------------------------:|\n| <img src=\"https://github.com/user-attachments/assets/e59e580d-a7db-42ac-b386-892af211fc85\" alt=\"bird_1\" width=\"500\"/> | <img src=\"https://github.com/user-attachments/assets/f94ee025-ae37-4a45-9c3e-0cfe8f8cd2bc\" alt=\"boat_1\" width=\"500\"/> |\n\n\n### 0.1 If only bbox annotations are available\n\nWe also provide a script to generate instance-level segmentation masks by using SAM2. This is useful if you only have bounding box annotations available for the reference images.\n",
    "ContentSha": "24nxqSCUluTBmTCEJTeg5Xoe4qe7qXxstVNWjA2/zVk=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "**Visualisasi gambar referensi (1-shot):**\n\n| Gambar Referensi 1-shot untuk BURUNG üê¶ | Gambar Referensi 1-shot untuk PERAHU ‚õµ |\n|:---------------------------------------:|:--------------------------------------:|\n| <img src=\"https://github.com/user-attachments/assets/e59e580d-a7db-42ac-b386-892af211fc85\" alt=\"bird_1\" width=\"500\"/> | <img src=\"https://github.com/user-attachments/assets/f94ee025-ae37-4a45-9c3e-0cfe8f8cd2bc\" alt=\"boat_1\" width=\"500\"/> |\n\n\n### 0.1 Jika hanya anotasi bbox yang tersedia\n\nKami juga menyediakan skrip untuk menghasilkan mask segmentasi tingkat instansi dengan menggunakan SAM2. Ini berguna jika Anda hanya memiliki anotasi bounding box untuk gambar referensi.\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 27,
    "Content": "```bash\n# Download sam_h checkpoint. Feel free to use more recent checkpoints (note: code might need to be adapted)\nwget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth -O checkpoints/sam_vit_h_4b8939.pth\n# Run automatic instance segmentation from ground truth bounding boxes.\npython no_time_to_train/dataset/sam_bbox_to_segm_batch.py \\\n    --input_json data/my_custom_dataset/annotations/custom_references.json \\\n    --image_dir data/my_custom_dataset/images \\\n    --sam_checkpoint checkpoints/sam_vit_h_4b8939.pth \\\n    --model_type vit_h \\\n    --device cuda \\\n    --batch_size 8 \\\n    --visualize\n```",
    "ContentSha": "MZFLWMxUY4Y3eseQiE2eVYRMs3mR83iZMQq1RJqVFCc=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\n# Download sam_h checkpoint. Feel free to use more recent checkpoints (note: code might need to be adapted)\nwget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth -O checkpoints/sam_vit_h_4b8939.pth\n# Run automatic instance segmentation from ground truth bounding boxes.\npython no_time_to_train/dataset/sam_bbox_to_segm_batch.py \\\n    --input_json data/my_custom_dataset/annotations/custom_references.json \\\n    --image_dir data/my_custom_dataset/images \\\n    --sam_checkpoint checkpoints/sam_vit_h_4b8939.pth \\\n    --model_type vit_h \\\n    --device cuda \\\n    --batch_size 8 \\\n    --visualize\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 28,
    "Content": "\n**Reference images with instance-level segmentation masks (generated by SAM2 from gt bounding boxes, 1-shot):**\n\nVisualisation of the generated segmentation masks are saved in `data/my_custom_dataset/annotations/custom_references_with_SAM_segm/references_visualisations/`.\n\n\n| 1-shot Reference Image for BIRD üê¶ (automatically segmented with SAM) | 1-shot Reference Image for BOAT ‚õµ (automatically segmented with SAM) |\n|:---------------------------------:|:----------------------------------:|\n| <img src=\"https://github.com/user-attachments/assets/65d38dc4-1454-43cd-9600-e8efc67b3a82\" alt=\"bird_1_with_SAM_segm\" width=\"500\"/> | <img src=\"https://github.com/user-attachments/assets/43a558ad-50ca-4715-8285-9aa3268843c6\" alt=\"boat_1_with_SAM_segm\" width=\"500\"/> |\n\n\n### 0.2 Convert coco annotations to pickle file\n",
    "ContentSha": "0a8ACnuaKmeocwoJUK+xvmctljcu8ZJdT00xJXlyJ5w=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "**Gambar referensi dengan masker segmentasi tingkat instansi (dihasilkan oleh SAM2 dari kotak pembatas gt, 1-shot):**\n\nVisualisasi dari masker segmentasi yang dihasilkan disimpan di `data/my_custom_dataset/annotations/custom_references_with_SAM_segm/references_visualisations/`.\n\n\n| Gambar Referensi 1-shot untuk BURUNG üê¶ (disegmentasi otomatis dengan SAM) | Gambar Referensi 1-shot untuk PERAHU ‚õµ (disegmentasi otomatis dengan SAM) |\n|:---------------------------------:|:----------------------------------:|\n| <img src=\"https://github.com/user-attachments/assets/65d38dc4-1454-43cd-9600-e8efc67b3a82\" alt=\"bird_1_with_SAM_segm\" width=\"500\"/> | <img src=\"https://github.com/user-attachments/assets/43a558ad-50ca-4715-8285-9aa3268843c6\" alt=\"boat_1_with_SAM_segm\" width=\"500\"/> |\n\n\n### 0.2 Konversi anotasi coco ke file pickle\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 29,
    "Content": "```bash\npython no_time_to_train/dataset/coco_to_pkl.py \\\n    data/my_custom_dataset/annotations/custom_references_with_segm.json \\\n    data/my_custom_dataset/annotations/custom_references_with_segm.pkl \\\n    1\n```",
    "ContentSha": "PSo9jaMX0pVKgHl0ecq9duQGpy1rMpXUU1iB4a8YzJM=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\npython no_time_to_train/dataset/coco_to_pkl.py \\\n    data/my_custom_dataset/annotations/custom_references_with_segm.json \\\n    data/my_custom_dataset/annotations/custom_references_with_segm.pkl \\\n    1\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 30,
    "Content": "\n### 1. Fill memory with references\n\nFirst, define useful variables and create a folder for results. For correct visualisation of labels, class names should be ordered by category id as appears in the json file. E.g. `bird` has category id `16`, `boat` has category id `9`. Thus, `CAT_NAMES=boat,bird`.\n",
    "ContentSha": "97iqG4pEnvNDE6ERpjfa2nL6RAtTIXJXwjJwqU/SNCg=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "### 1. Mengisi memori dengan referensi\n\nPertama, definisikan variabel yang diperlukan dan buat folder untuk hasil. Untuk visualisasi label yang benar, nama kelas harus diurutkan berdasarkan id kategori seperti yang muncul di file json. Misalnya, `bird` memiliki id kategori `16`, `boat` memiliki id kategori `9`. Jadi, `CAT_NAMES=boat,bird`.\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 31,
    "Content": "```bash\nDATASET_NAME=my_custom_dataset\nDATASET_PATH=data/my_custom_dataset\nCAT_NAMES=boat,bird\nCATEGORY_NUM=2\nSHOT=1\nYAML_PATH=no_time_to_train/pl_configs/matching_cdfsod_template.yaml\nPATH_TO_SAVE_CKPTS=./tmp_ckpts/my_custom_dataset\nmkdir -p $PATH_TO_SAVE_CKPTS\n```",
    "ContentSha": "mJIX4bJBaFbcwT8YfLR0V4w6qjU7MQEh3u6k2gtPrvw=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\nDATASET_NAME=my_custom_dataset\nDATASET_PATH=data/my_custom_dataset\nCAT_NAMES=boat,bird\nCATEGORY_NUM=2\nSHOT=1\nYAML_PATH=no_time_to_train/pl_configs/matching_cdfsod_template.yaml\nPATH_TO_SAVE_CKPTS=./tmp_ckpts/my_custom_dataset\nmkdir -p $PATH_TO_SAVE_CKPTS\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 32,
    "Content": "\nRun step 1:",
    "ContentSha": "PqClefvNhYLjlZsfjndNSKUJEy6R+goO4h/8KMDA1P0=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "Jalankan langkah 1:\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 33,
    "Content": "```bash\npython run_lightening.py test --config $YAML_PATH \\\n    --model.test_mode fill_memory \\\n    --out_path $PATH_TO_SAVE_CKPTS/$DATASET_NAME\\_$SHOT\\_refs_memory.pth \\\n    --model.init_args.dataset_cfgs.fill_memory.root $DATASET_PATH/images \\\n    --model.init_args.dataset_cfgs.fill_memory.json_file $DATASET_PATH/annotations/custom_references_with_segm.json \\\n    --model.init_args.dataset_cfgs.fill_memory.memory_pkl $DATASET_PATH/annotations/custom_references_with_segm.pkl \\\n    --model.init_args.dataset_cfgs.fill_memory.memory_length $SHOT \\\n    --model.init_args.dataset_cfgs.fill_memory.cat_names $CAT_NAMES \\\n    --model.init_args.model_cfg.dataset_name $DATASET_NAME \\\n    --model.init_args.model_cfg.memory_bank_cfg.length $SHOT \\\n    --model.init_args.model_cfg.memory_bank_cfg.category_num $CATEGORY_NUM \\\n    --trainer.devices 1\n```",
    "ContentSha": "wLZindeEKqrTUIIF55tL8lmaW4jWIZ2bdw6bj/1U9TU=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\npython run_lightening.py test --config $YAML_PATH \\\n    --model.test_mode fill_memory \\\n    --out_path $PATH_TO_SAVE_CKPTS/$DATASET_NAME\\_$SHOT\\_refs_memory.pth \\\n    --model.init_args.dataset_cfgs.fill_memory.root $DATASET_PATH/images \\\n    --model.init_args.dataset_cfgs.fill_memory.json_file $DATASET_PATH/annotations/custom_references_with_segm.json \\\n    --model.init_args.dataset_cfgs.fill_memory.memory_pkl $DATASET_PATH/annotations/custom_references_with_segm.pkl \\\n    --model.init_args.dataset_cfgs.fill_memory.memory_length $SHOT \\\n    --model.init_args.dataset_cfgs.fill_memory.cat_names $CAT_NAMES \\\n    --model.init_args.model_cfg.dataset_name $DATASET_NAME \\\n    --model.init_args.model_cfg.memory_bank_cfg.length $SHOT \\\n    --model.init_args.model_cfg.memory_bank_cfg.category_num $CATEGORY_NUM \\\n    --trainer.devices 1\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 34,
    "Content": "\n### 2. Post-process memory bank\n",
    "ContentSha": "39oOsuQIXM8TjT8ASLmZI0OpSbUSAT4d7YEHU7S2uqQ=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "### 2. Bank memori pasca-proses\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 35,
    "Content": "```bash\npython run_lightening.py test --config $YAML_PATH \\\n    --model.test_mode postprocess_memory \\\n    --ckpt_path $PATH_TO_SAVE_CKPTS/$DATASET_NAME\\_$SHOT\\_refs_memory.pth \\\n    --out_path $PATH_TO_SAVE_CKPTS/$DATASET_NAME\\_$SHOT\\_refs_memory_postprocessed.pth \\\n    --model.init_args.model_cfg.dataset_name $DATASET_NAME \\\n    --model.init_args.model_cfg.memory_bank_cfg.length $SHOT \\\n    --model.init_args.model_cfg.memory_bank_cfg.category_num $CATEGORY_NUM \\\n    --trainer.devices 1\n```",
    "ContentSha": "49JIaRecImNonhL7aGKB3JsAkgDw76Irci38QcuVb8k=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\npython run_lightening.py test --config $YAML_PATH \\\n    --model.test_mode postprocess_memory \\\n    --ckpt_path $PATH_TO_SAVE_CKPTS/$DATASET_NAME\\_$SHOT\\_refs_memory.pth \\\n    --out_path $PATH_TO_SAVE_CKPTS/$DATASET_NAME\\_$SHOT\\_refs_memory_postprocessed.pth \\\n    --model.init_args.model_cfg.dataset_name $DATASET_NAME \\\n    --model.init_args.model_cfg.memory_bank_cfg.length $SHOT \\\n    --model.init_args.model_cfg.memory_bank_cfg.category_num $CATEGORY_NUM \\\n    --trainer.devices 1\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 36,
    "Content": "\n### 3. Inference on target images\n\nIf `ONLINE_VIS` is set to True, prediction results will be saved in `results_analysis/my_custom_dataset/` and displayed as they are computed. NOTE that running with online visualisation is much slower.\n\nFeel free to change the score threshold `VIS_THR` to see more or less segmented instances.",
    "ContentSha": "iHMIprXo8OKpw9IBp/bgaLDyjCzJT/6l87G6FkpcZcY=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "### 3. Inferensi pada gambar target\n\nJika `ONLINE_VIS` disetel ke True, hasil prediksi akan disimpan di `results_analysis/my_custom_dataset/` dan ditampilkan saat diproses. PERHATIKAN bahwa menjalankan dengan visualisasi online jauh lebih lambat.\n\nSilakan ubah ambang skor `VIS_THR` untuk melihat lebih banyak atau lebih sedikit instance yang tersegmentasi.\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 37,
    "Content": "```bash\nONLINE_VIS=True\nVIS_THR=0.4\npython run_lightening.py test --config $YAML_PATH \\\n    --model.test_mode test \\\n    --ckpt_path $PATH_TO_SAVE_CKPTS/$DATASET_NAME\\_$SHOT\\_refs_memory_postprocessed.pth \\\n    --model.init_args.model_cfg.dataset_name $DATASET_NAME \\\n    --model.init_args.model_cfg.memory_bank_cfg.length $SHOT \\\n    --model.init_args.model_cfg.memory_bank_cfg.category_num $CATEGORY_NUM \\\n    --model.init_args.model_cfg.test.imgs_path $DATASET_PATH/images \\\n    --model.init_args.model_cfg.test.online_vis $ONLINE_VIS \\\n    --model.init_args.model_cfg.test.vis_thr $VIS_THR \\\n    --model.init_args.dataset_cfgs.test.root $DATASET_PATH/images \\\n    --model.init_args.dataset_cfgs.test.json_file $DATASET_PATH/annotations/custom_targets.json \\\n    --model.init_args.dataset_cfgs.test.cat_names $CAT_NAMES \\\n    --trainer.devices 1\n```",
    "ContentSha": "WwpzFHhc6G71aipZFN/unoGoH913SXlW3RG98ipcK1k=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\nONLINE_VIS=True\nVIS_THR=0.4\npython run_lightening.py test --config $YAML_PATH \\\n    --model.test_mode test \\\n    --ckpt_path $PATH_TO_SAVE_CKPTS/$DATASET_NAME\\_$SHOT\\_refs_memory_postprocessed.pth \\\n    --model.init_args.model_cfg.dataset_name $DATASET_NAME \\\n    --model.init_args.model_cfg.memory_bank_cfg.length $SHOT \\\n    --model.init_args.model_cfg.memory_bank_cfg.category_num $CATEGORY_NUM \\\n    --model.init_args.model_cfg.test.imgs_path $DATASET_PATH/images \\\n    --model.init_args.model_cfg.test.online_vis $ONLINE_VIS \\\n    --model.init_args.model_cfg.test.vis_thr $VIS_THR \\\n    --model.init_args.dataset_cfgs.test.root $DATASET_PATH/images \\\n    --model.init_args.dataset_cfgs.test.json_file $DATASET_PATH/annotations/custom_targets.json \\\n    --model.init_args.dataset_cfgs.test.cat_names $CAT_NAMES \\\n    --trainer.devices 1\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 38,
    "Content": "\n### Results\n\nPerformance metrics (with the exact same parameters as commands above) should be:\n",
    "ContentSha": "qUh629YPJLLYOXeHGSusGSWIYdfgfMGmHPttF+Zq0tU=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "### Hasil\n\nMetode pengukuran kinerja (dengan parameter yang sama persis seperti perintah di atas) seharusnya:\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 39,
    "Content": "```\nBBOX RESULTS:\n  Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.478\n\nSEGM RESULTS:\n  Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.458\n```",
    "ContentSha": "EqM8BsGgWhI+q5ZgXp4DOk8Wayw3iQnYToBVZntlyVI=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```\nBBOX RESULTS:\n  Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.478\n\nSEGM RESULTS:\n  Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.458\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 40,
    "Content": "\nVisual results are saved in `results_analysis/my_custom_dataset/`. Note that our method works for false negatives, that is, images that do not contain any instances of the desired classes.\n\n*Click images to enlarge ‚¨áÔ∏è*\n\n| Target image with boats ‚õµ (left GT, right predictions) | Target image with birds üê¶ (left GT, right predictions) |\n|:----------------------:|:----------------------:|\n| ![000000459673](https://github.com/user-attachments/assets/678dc15a-dd3b-49d5-9287-6290da16aa6b) | ![000000407180](https://github.com/user-attachments/assets/fe306e48-af49-4d83-ac82-76fac6c456d1) |\n\n| Target image with boats and birds ‚õµüê¶ (left GT, right predictions) | Target image without boats or birds üö´ (left GT, right predictions) |\n|:---------------------------------:|:----------------------------------:|\n| ![000000517410](https://github.com/user-attachments/assets/9849b227-7f43-43d7-81ea-58010a623ad5) | ![000000460598](https://github.com/user-attachments/assets/7587700c-e09d-4cf6-8590-3df129c2568e) |\n\n\n## üìö Citation\n\nIf you use this work, please cite us:\n",
    "ContentSha": "tEYR4ra1661R2TKfAxblzhr7EHrPwy5JI69dHQuD/mM=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "Hasil visual disimpan di `results_analysis/my_custom_dataset/`. Perlu dicatat bahwa metode kami bekerja untuk false negative, yaitu gambar yang tidak mengandung instance dari kelas yang diinginkan.\n\n*Klik gambar untuk memperbesar ‚¨áÔ∏è*\n\n| Gambar target dengan perahu ‚õµ (kiri GT, kanan prediksi) | Gambar target dengan burung üê¶ (kiri GT, kanan prediksi) |\n|:----------------------:|:----------------------:|\n| ![000000459673](https://github.com/user-attachments/assets/678dc15a-dd3b-49d5-9287-6290da16aa6b) | ![000000407180](https://github.com/user-attachments/assets/fe306e48-af49-4d83-ac82-76fac6c456d1) |\n\n| Gambar target dengan perahu dan burung ‚õµüê¶ (kiri GT, kanan prediksi) | Gambar target tanpa perahu atau burung üö´ (kiri GT, kanan prediksi) |\n|:---------------------------------:|:----------------------------------:|\n| ![000000517410](https://github.com/user-attachments/assets/9849b227-7f43-43d7-81ea-58010a623ad5) | ![000000460598](https://github.com/user-attachments/assets/7587700c-e09d-4cf6-8590-3df129c2568e) |\n\n\n## üìö Sitasi\n\nJika Anda menggunakan karya ini, mohon kutip kami:\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 41,
    "Content": "```bibtex\n@article{espinosa2025notimetotrain,\n  title={No time to train! Training-Free Reference-Based Instance Segmentation},\n  author={Miguel Espinosa and Chenhongyi Yang and Linus Ericsson and Steven McDonagh and Elliot J. Crowley},\n  journal={arXiv preprint arXiv:2507.02798},\n  year={2025},\n  primaryclass={cs.CV}\n}\n```",
    "ContentSha": "wkySuPRHWTRGorn0rwSBqyUnW5RNg9LVe0O7npcbKSs=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bibtex\n@article{espinosa2025notimetotrain,\n  title={No time to train! Training-Free Reference-Based Instance Segmentation},\n  author={Miguel Espinosa and Chenhongyi Yang and Linus Ericsson and Steven McDonagh and Elliot J. Crowley},\n  journal={arXiv preprint arXiv:2507.02798},\n  year={2025},\n  primaryclass={cs.CV}\n}\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 42,
    "Content": "",
    "ContentSha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  }
]