<div align="right">
  <details>
    <summary >ğŸŒ èªè¨€</summary>
    <div>
      <div align="center">
        <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=en">English</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=zh-CN">ç®€ä½“ä¸­æ–‡</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=zh-TW">ç¹é«”ä¸­æ–‡</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=ja">æ—¥æœ¬èª</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=ko">í•œêµ­ì–´</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=hi">à¤¹à¤¿à¤¨à¥à¤¦à¥€</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=th">à¹„à¸—à¸¢</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=fr">FranÃ§ais</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=de">Deutsch</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=es">EspaÃ±ol</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=it">Italiano</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=ru">Ğ ÑƒÑÑĞºĞ¸Ğ¹</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=pt">PortuguÃªs</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=nl">Nederlands</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=pl">Polski</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=ar">Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=fa">ÙØ§Ø±Ø³ÛŒ</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=tr">TÃ¼rkÃ§e</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=vi">Tiáº¿ng Viá»‡t</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=id">Bahasa Indonesia</a>
      </div>
    </div>
  </details>
</div>

<div align="center">

# ğŸš€ æ²’æœ‰æ™‚é–“è¨“ç·´ï¼
### ç„¡éœ€è¨“ç·´çš„åƒè€ƒå¼å¯¦ä¾‹åˆ†å‰²
[![GitHub](https://img.shields.io/badge/%E2%80%8B-No%20Time%20To%20Train-black?logo=github)](https://github.com/miquel-espinosa/no-time-to-train)
[![Website](https://img.shields.io/badge/ğŸŒ-Project%20Page-grey)](https://miquel-espinosa.github.io/no-time-to-train/)
[![arXiv](https://img.shields.io/badge/arXiv-2507.02798-b31b1b)](https://arxiv.org/abs/2507.02798)

**æœ€å…ˆé€²æŠ€è¡“ï¼ˆPapers with Codeï¼‰**

[**_SOTA 1-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-1-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/badge/State%20of%20the%20Art-Few--Shot%20Object%20Detection%20on%20MS--COCO%20(1--shot)-21CBCE?style=flat&logo=paperswithcode)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-1-shot?p=no-time-to-train-training-free-reference)

[**_SOTA 10-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-10-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/badge/State%20of%20the%20Art-Few--Shot%20Object%20Detection%20on%20MS--COCO%20(10--shot)-21CBCE?style=flat&logo=paperswithcode)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-10-shot?p=no-time-to-train-training-free-reference)

[**_SOTA 30-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-30-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/badge/State%20of%20the%20Art-Few--Shot%20Object%20Detection%20on%20MS--COCO%20(30--shot)-21CBCE?style=flat&logo=paperswithcode)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-30-shot?p=no-time-to-train-training-free-reference)

<!-- [**_SOTA 1-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-1-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/no-time-to-train-training-free-reference/few-shot-object-detection-on-ms-coco-1-shot)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-1-shot?p=no-time-to-train-training-free-reference)

[**_SOTA 10-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-10-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/no-time-to-train-training-free-reference/few-shot-object-detection-on-ms-coco-10-shot)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-10-shot?p=no-time-to-train-training-free-reference)

[**_SOTA 30-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-30-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/no-time-to-train-training-free-reference/few-shot-object-detection-on-ms-coco-30-shot)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-30-shot?p=no-time-to-train-training-free-reference) -->

</div>

---

> ğŸš¨ **æ›´æ–°ï¼ˆ2025å¹´7æœˆ22æ—¥ï¼‰ï¼š** å·²æ–°å¢è‡ªå®šç¾©è³‡æ–™é›†çš„ä½¿ç”¨èªªæ˜ï¼
> 
> ğŸ”” **æ›´æ–°ï¼ˆ2025å¹´7æœˆ16æ—¥ï¼‰ï¼š** ç¨‹å¼ç¢¼å·²æ›´æ–°ä¸¦é™„ä¸Šèªªæ˜ï¼

---

## ğŸ“‹ ç›®éŒ„

- [ğŸ¯ äº®é»](#-highlights)
- [ğŸ“œ æ‘˜è¦](#-abstract)
- [ğŸ§  æ¶æ§‹](#-architecture)
- [ğŸ› ï¸ å®‰è£èªªæ˜](#ï¸-installation-instructions)
  - [1. è¤‡è£½ç¨‹å¼åº«](#1-clone-the-repository)
  - [2. å»ºç«‹ conda ç’°å¢ƒ](#2-create-conda-environment)
  - [3. å®‰è£ SAM2 èˆ‡ DinoV2](#3-install-sam2-and-dinov2)
  - [4. ä¸‹è¼‰è³‡æ–™é›†](#4-download-datasets)
  - [5. ä¸‹è¼‰ SAM2 èˆ‡ DinoV2 æ¬Šé‡æª”](#5-download-sam2-and-dinov2-checkpoints)
- [ğŸ“Š æ¨è«–ç¨‹å¼ï¼šé‡ç¾ Few-shot COCO 30-shot SOTA çµæœ](#-inference-code)
  - [0. å»ºç«‹åƒè€ƒé›†](#0-create-reference-set)
  - [1. ä»¥åƒè€ƒè³‡æ–™å¡«å……è¨˜æ†¶é«”](#1-fill-memory-with-references)
  - [2. å¾Œè™•ç†è¨˜æ†¶é«”åº«](#2-post-process-memory-bank)
  - [3. ç›®æ¨™å½±åƒæ¨è«–](#3-inference-on-target-images)
  - [çµæœ](#results)
- [ğŸ” è‡ªå®šç¾©è³‡æ–™é›†](#-custom-dataset)
  - [0. æº–å‚™è‡ªå®šç¾©è³‡æ–™é›† â›µğŸ¦](#0-prepare-a-custom-dataset)
  - [0.1 åƒ…æœ‰ bbox æ¨™è¨»æ™‚](#01-if-only-bbox-annotations-are-available)
  - [0.2 å°‡ coco æ¨™è¨»è½‰ç‚º pickle æª”æ¡ˆ](#02-convert-coco-annotations-to-pickle-file)
  - [1. ä»¥åƒè€ƒè³‡æ–™å¡«å……è¨˜æ†¶é«”](#1-fill-memory-with-references)
  - [2. å¾Œè™•ç†è¨˜æ†¶é«”åº«](#2-post-process-memory-bank)
- [ğŸ“š åƒè€ƒæ–‡ç»](#-citation)


## ğŸ¯ äº®é»
- ğŸ’¡ **ç„¡éœ€è¨“ç·´**ï¼šç„¡éœ€å¾®èª¿ï¼Œç„¡éœ€æç¤ºå·¥ç¨‹â€”åªéœ€ä¸€å¼µåƒè€ƒåœ–ç‰‡ã€‚
- ğŸ–¼ï¸ **åƒè€ƒå¼æ–¹æ³•**ï¼šåƒ…ç”¨å¹¾å€‹ç¯„ä¾‹å³å¯åˆ†å‰²æ–°å°è±¡ã€‚
- ğŸ”¥ **æœ€å…ˆé€²è¡¨ç¾**ï¼šæ–¼ COCOã€PASCAL VOC åŠè·¨é ˜åŸŸ FSOD ä¸Šè¶…è¶Šæ—¢æœ‰ç„¡è¨“ç·´æ–¹æ³•ã€‚

**é€£çµï¼š**
- ğŸ§¾ [**arXiv è«–æ–‡**](https://arxiv.org/abs/2507.02798)  
- ğŸŒ [**å°ˆæ¡ˆç¶²ç«™**](https://miquel-espinosa.github.io/no-time-to-train/)  
- ğŸ“ˆ [**Papers with Code**](https://paperswithcode.com/paper/no-time-to-train-training-free-reference)

## ğŸ“œ æ‘˜è¦


> The performance of image segmentation models has historically been constrained by the high cost of collecting large-scale annotated data. The Segment Anything Model (SAM) alleviates this original problem through a promptable, semantics-agnostic, segmentation paradigm and yet still requires manual visual-prompts or complex domain-dependent prompt-generation rules to process a new image. Towards reducing this new burden, our work investigates the task of object segmentation when provided with, alternatively, only a small set of reference images. Our key insight is to leverage strong semantic priors, as learned by foundation models, to identify corresponding regions between a reference and a target image. We find that correspondences enable automatic generation of instance-level segmentation masks for downstream tasks and instantiate our ideas via a multi-stage, training-free method incorporating (1) memory bank construction; (2) representation aggregation and (3) semantic-aware feature matching. Our experiments show significant improvements on segmentation metrics, leading to state-of-the-art performance on COCO FSOD (36.8% nAP), PASCAL VOC Few-Shot (71.2% nAP50) and outperforming existing training-free approaches on the Cross-Domain FSOD benchmark (22.4% nAP).

![cdfsod-results-final-comic-sans-min](https://github.com/user-attachments/assets/ab302c02-c080-4042-99fc-0e181ba8abb9)


## ğŸ§  Architecture

![training-free-architecture-comic-sans-min](https://github.com/user-attachments/assets/d84dd83a-505e-45a0-8ce3-98e1838017f9)


## ğŸ› ï¸ Installation instructions

### 1. Clone the repository

```bash
git clone https://github.com/miquel-espinosa/no-time-to-train.git
cd no-time-to-train
```
### 2. å»ºç«‹ conda ç’°å¢ƒ

æˆ‘å€‘å°‡å»ºç«‹ä¸€å€‹åŒ…å«æ‰€éœ€å¥—ä»¶çš„ conda ç’°å¢ƒã€‚

```bash
conda env create -f environment.yml
conda activate no-time-to-train
```
### 3. å®‰è£ SAM2 å’Œ DinoV2

æˆ‘å€‘å°‡å¾åŸå§‹ç¢¼å®‰è£ SAM2 å’Œ DinoV2ã€‚

```bash
pip install -e .
cd dinov2
pip install -e .
cd ..
```
### 4. ä¸‹è¼‰æ•¸æ“šé›†

è«‹ä¸‹è¼‰ COCO æ•¸æ“šé›†ä¸¦å°‡å…¶æ”¾ç½®æ–¼ `data/coco`

### 5. ä¸‹è¼‰ SAM2 å’Œ DinoV2 æ¬Šé‡æª”

æˆ‘å€‘å°‡ä¸‹è¼‰è«–æ–‡ä¸­ä½¿ç”¨çš„ SAM2 æ¬Šé‡æª”ã€‚
ï¼ˆä½†è«‹æ³¨æ„ï¼ŒSAM2.1 æ¬Šé‡æª”å·²ç¶“å¯ç”¨ï¼Œä¸”å¯èƒ½æœ‰æ›´å¥½çš„è¡¨ç¾ã€‚ï¼‰


```bash
mkdir -p checkpoints/dinov2
cd checkpoints
wget https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_large.pt
cd dinov2
wget https://dl.fbaipublicfiles.com/dinov2/dinov2_vitl14/dinov2_vitl14_pretrain.pth
cd ../..
```
## ğŸ“Š æ¨è«–ç¨‹å¼ç¢¼

âš ï¸ å…è²¬è²æ˜ï¼šé€™æ˜¯ç ”ç©¶ç”¨ç¨‹å¼ç¢¼â€”â€”è«‹é æœŸæœƒæœ‰ä¸€äº›æ··äº‚ï¼

### åœ¨ Few-shot COCO ä¸­é‡ç¾ 30-shot SOTA çµæœ

å®šç¾©æœ‰ç”¨çš„è®Šæ•¸ä¸¦ç‚ºçµæœå»ºç«‹è³‡æ–™å¤¾ï¼š



```bash
CONFIG=./no_time_to_train/new_exps/coco_fewshot_10shot_Sam2L.yaml
CLASS_SPLIT="few_shot_classes"
RESULTS_DIR=work_dirs/few_shot_results
SHOTS=30
SEED=33
GPUS=4

mkdir -p $RESULTS_DIR
FILENAME=few_shot_${SHOTS}shot_seed${SEED}.pkl
```
#### 0. å»ºç«‹åƒè€ƒé›†


```bash
python no_time_to_train/dataset/few_shot_sampling.py \
        --n-shot $SHOTS \
        --out-path ${RESULTS_DIR}/${FILENAME} \
        --seed $SEED \
        --dataset $CLASS_SPLIT
```
#### 1. ç”¨åƒè€ƒå¡«å……è¨˜æ†¶é«”


```bash
python run_lightening.py test --config $CONFIG \
                              --model.test_mode fill_memory \
                              --out_path ${RESULTS_DIR}/memory.ckpt \
                              --model.init_args.model_cfg.memory_bank_cfg.length $SHOTS \
                              --model.init_args.dataset_cfgs.fill_memory.memory_pkl ${RESULTS_DIR}/${FILENAME} \
                              --model.init_args.dataset_cfgs.fill_memory.memory_length $SHOTS \
                              --model.init_args.dataset_cfgs.fill_memory.class_split $CLASS_SPLIT \
                              --trainer.logger.save_dir ${RESULTS_DIR}/ \
                              --trainer.devices $GPUS
```
#### 2. å¾Œè™•ç†è¨˜æ†¶é«”åº«


```bash
python run_lightening.py test --config $CONFIG \
                              --model.test_mode postprocess_memory \
                              --model.init_args.model_cfg.memory_bank_cfg.length $SHOTS \
                              --ckpt_path ${RESULTS_DIR}/memory.ckpt \
                              --out_path ${RESULTS_DIR}/memory_postprocessed.ckpt \
                              --trainer.devices 1
```
#### 3. åœ¨ç›®æ¨™å½±åƒä¸Šé€²è¡Œæ¨è«–


```bash
python run_lightening.py test --config $CONFIG  \
                              --ckpt_path ${RESULTS_DIR}/memory_postprocessed.ckpt \
                              --model.init_args.test_mode test \
                              --model.init_args.model_cfg.memory_bank_cfg.length $SHOTS \
                              --model.init_args.model_cfg.dataset_name $CLASS_SPLIT \
                              --model.init_args.dataset_cfgs.test.class_split $CLASS_SPLIT \
                              --trainer.logger.save_dir ${RESULTS_DIR}/ \
                              --trainer.devices $GPUS
```
å¦‚æœæ‚¨å¸Œæœ›å³æ™‚æŸ¥çœ‹æ¨è«–çµæœï¼ˆåœ¨è¨ˆç®—æ™‚ï¼‰ï¼Œè«‹å–æ¶ˆè¨»è§£ `no_time_to_train/models/Sam2MatchingBaseline_noAMG.py` ä¸­ç¬¬ 1746-1749 è¡Œ [é€™è£¡](https://github.com/miquel-espinosa/no-time-to-train/blob/main/no_time_to_train/models/Sam2MatchingBaseline_noAMG.py#L1746)ã€‚
æ ¹æ“šéœ€è¦èª¿æ•´åˆ†æ•¸é–€æª»åƒæ•¸ `score_thr`ï¼Œä»¥é¡¯ç¤ºæ›´å¤šæˆ–æ›´å°‘çš„åˆ†å‰²å¯¦ä¾‹ã€‚
å½±åƒå°‡æœƒå„²å­˜åœ¨ `results_analysis/few_shot_classes/`ã€‚å·¦å´çš„å½±åƒé¡¯ç¤ºçœŸå¯¦æ¨™è¨»ï¼Œå³å´çš„å½±åƒé¡¯ç¤ºæˆ‘å€‘ç„¡éœ€è¨“ç·´æ–¹æ³•æ‰€æ‰¾åˆ°çš„åˆ†å‰²å¯¦ä¾‹ã€‚

è«‹æ³¨æ„ï¼Œåœ¨æœ¬ç¯„ä¾‹ä¸­æˆ‘å€‘ä½¿ç”¨çš„æ˜¯ `few_shot_classes` åˆ†å‰²ï¼Œå› æ­¤ï¼Œæˆ‘å€‘åƒ…æ‡‰æœŸæœ›çœ‹åˆ°å±¬æ–¼æ­¤åˆ†å‰²ä¸­çš„é¡åˆ¥çš„åˆ†å‰²å¯¦ä¾‹ï¼ˆè€Œé COCO çš„æ‰€æœ‰é¡åˆ¥ï¼‰ã€‚

#### çµæœ

åœ¨å°é©—è­‰é›†ä¸­çš„æ‰€æœ‰å½±åƒåŸ·è¡Œå¾Œï¼Œæ‚¨æ‡‰è©²æœƒå¾—åˆ°ï¼š


```
BBOX RESULTS:
  Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.368

SEGM RESULTS:
  Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.342
```
---

## ğŸ” è‡ªè¨‚è³‡æ–™é›†

æˆ‘å€‘æä¾›äº†åœ¨è‡ªè¨‚è³‡æ–™é›†ä¸Šé‹è¡Œæˆ‘å€‘æµç¨‹çš„æ“ä½œèªªæ˜ã€‚è¨»é‡‹æ ¼å¼ä¸€å¾‹æ¡ç”¨ COCO æ ¼å¼ã€‚

> **ç¸½çµï¼›** è‹¥è¦ç›´æ¥æŸ¥çœ‹å¦‚ä½•åœ¨*è‡ªè¨‚è³‡æ–™é›†*ä¸Šé‹è¡Œå®Œæ•´æµç¨‹ï¼Œè«‹åƒè€ƒ `scripts/matching_cdfsod_pipeline.sh` ä»¥åŠ CD-FSOD è³‡æ–™é›†çš„ç¯„ä¾‹è…³æœ¬ï¼ˆä¾‹å¦‚ `scripts/dior_fish.sh`ï¼‰

### 0. æº–å‚™è‡ªè¨‚è³‡æ–™é›† â›µğŸ¦

å‡è¨­æˆ‘å€‘æƒ³åœ¨è‡ªè¨‚è³‡æ–™é›†ä¸­åµæ¸¬**èˆ¹éš»**â›µå’Œ**é³¥é¡**ğŸ¦ã€‚è¦ä½¿ç”¨æˆ‘å€‘çš„æ–¹æ³•ï¼Œæ‚¨éœ€è¦ï¼š
- æ¯å€‹é¡åˆ¥è‡³å°‘ 1 å¼µ*å·²è¨»é‡‹*çš„åƒè€ƒåœ–ç‰‡ï¼ˆå³ 1 å¼µèˆ¹çš„åƒè€ƒåœ–ç‰‡å’Œ 1 å¼µé³¥çš„åƒè€ƒåœ–ç‰‡ï¼‰
- å¤šå¼µç›®æ¨™åœ–ç‰‡ï¼Œç”¨ä»¥å°‹æ‰¾æˆ‘å€‘ç›®æ¨™é¡åˆ¥çš„å¯¦ä¾‹ã€‚

æˆ‘å€‘å·²æº–å‚™äº†ä¸€å€‹ç°¡æ˜“è…³æœ¬ï¼Œèƒ½å¤ ä»¥ coco åœ–ç‰‡å‰µå»ºè‡ªè¨‚è³‡æ–™é›†ï¼Œé©ç”¨æ–¼**1-shot**è¨­ç½®ã€‚
```bash
python scripts/make_custom_dataset.py
```
é€™å°‡æœƒå»ºç«‹ä¸€å€‹å…·æœ‰ä»¥ä¸‹è³‡æ–™å¤¾çµæ§‹çš„è‡ªè¨‚è³‡æ–™é›†ï¼š
```
data/my_custom_dataset/
    â”œâ”€â”€ annotations/
    â”‚   â”œâ”€â”€ custom_references.json
    â”‚   â”œâ”€â”€ custom_targets.json
    â”‚   â””â”€â”€ references_visualisations/
    â”‚       â”œâ”€â”€ bird_1.jpg
    â”‚       â””â”€â”€ boat_1.jpg
    â””â”€â”€ images/
        â”œâ”€â”€ 429819.jpg
        â”œâ”€â”€ 101435.jpg
        â””â”€â”€ (all target and reference images)
```
**åƒè€ƒåœ–ç‰‡è¦–è¦ºåŒ–ï¼ˆ1-shotï¼‰ï¼š**

| BIRD ğŸ¦ çš„ 1-shot åƒè€ƒåœ–ç‰‡ | BOAT â›µ çš„ 1-shot åƒè€ƒåœ–ç‰‡ |
|:---------------------------:|:----------------------------:|
| <img src="https://github.com/user-attachments/assets/e59e580d-a7db-42ac-b386-892af211fc85" alt="bird_1" width="500"/> | <img src="https://github.com/user-attachments/assets/f94ee025-ae37-4a45-9c3e-0cfe8f8cd2bc" alt="boat_1" width="500"/> |


### 0.1 åƒ…æœ‰ bbox æ¨™è¨»æ™‚

æˆ‘å€‘ä¹Ÿæä¾›ä¸€å€‹è…³æœ¬ï¼Œåˆ©ç”¨ SAM2 ç”Ÿæˆå¯¦ä¾‹ç´šåˆ†å‰²é®ç½©ã€‚é€™åœ¨åƒ…æœ‰åƒè€ƒåœ–ç‰‡çš„é‚Šç•Œæ¡†æ¨™è¨»æ™‚éå¸¸æœ‰ç”¨ã€‚


```bash
# Download sam_h checkpoint. Feel free to use more recent checkpoints (note: code might need to be adapted)
wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth -O checkpoints/sam_vit_h_4b8939.pth
# Run automatic instance segmentation from ground truth bounding boxes.
python no_time_to_train/dataset/sam_bbox_to_segm_batch.py \
    --input_json data/my_custom_dataset/annotations/custom_references.json \
    --image_dir data/my_custom_dataset/images \
    --sam_checkpoint checkpoints/sam_vit_h_4b8939.pth \
    --model_type vit_h \
    --device cuda \
    --batch_size 8 \
    --visualize
```
**å¸¶æœ‰å¯¦ä¾‹ç´šåˆ†å‰²é®ç½©çš„åƒè€ƒåœ–åƒï¼ˆç”± SAM2 æ ¹æ“š gt é‚Šç•Œæ¡†ç”Ÿæˆï¼Œ1-shotï¼‰ï¼š**

ç”¢ç”Ÿçš„åˆ†å‰²é®ç½©è¦–è¦ºåŒ–çµæœå·²å„²å­˜åœ¨ `data/my_custom_dataset/annotations/custom_references_with_SAM_segm/references_visualisations/`ã€‚

| BIRD ğŸ¦ çš„ 1-shot åƒè€ƒåœ–åƒï¼ˆä½¿ç”¨ SAM è‡ªå‹•åˆ†å‰²ï¼‰ | BOAT â›µ çš„ 1-shot åƒè€ƒåœ–åƒï¼ˆä½¿ç”¨ SAM è‡ªå‹•åˆ†å‰²ï¼‰ |
|:---------------------------------:|:----------------------------------:|
| <img src="https://github.com/user-attachments/assets/65d38dc4-1454-43cd-9600-e8efc67b3a82" alt="bird_1_with_SAM_segm" width="500"/> | <img src="https://github.com/user-attachments/assets/43a558ad-50ca-4715-8285-9aa3268843c6" alt="boat_1_with_SAM_segm" width="500"/> |

### 0.2 å°‡ coco æ¨™è¨»è½‰æ›ç‚º pickle æª”æ¡ˆ




```bash
python no_time_to_train/dataset/coco_to_pkl.py \
    data/my_custom_dataset/annotations/custom_references_with_segm.json \
    data/my_custom_dataset/annotations/custom_references_with_segm.pkl \
    1
```
### 1. ä»¥åƒè€ƒè³‡æ–™å¡«å……è¨˜æ†¶é«”

é¦–å…ˆï¼Œå®šç¾©æœ‰ç”¨çš„è®Šæ•¸ä¸¦å»ºç«‹ä¸€å€‹ç”¨æ–¼å„²å­˜çµæœçš„è³‡æ–™å¤¾ã€‚ç‚ºäº†æ­£ç¢ºé¡¯ç¤ºæ¨™ç±¤ï¼Œé¡åˆ¥åç¨±æ‡‰æŒ‰ç…§ json æª”æ¡ˆä¸­å‡ºç¾çš„é¡åˆ¥ id é †åºæ’åˆ—ã€‚ä¾‹å¦‚ï¼Œ`bird` çš„é¡åˆ¥ id ç‚º `16`ï¼Œ`boat` çš„é¡åˆ¥ id ç‚º `9`ã€‚å› æ­¤ï¼Œ`CAT_NAMES=boat,bird`ã€‚


```bash
DATASET_NAME=my_custom_dataset
DATASET_PATH=data/my_custom_dataset
CAT_NAMES=boat,bird
CATEGORY_NUM=2
SHOT=1
YAML_PATH=no_time_to_train/pl_configs/matching_cdfsod_template.yaml
PATH_TO_SAVE_CKPTS=./tmp_ckpts/my_custom_dataset
mkdir -p $PATH_TO_SAVE_CKPTS
```
åŸ·è¡Œæ­¥é©Ÿ 1ï¼š

```bash
python run_lightening.py test --config $YAML_PATH \
    --model.test_mode fill_memory \
    --out_path $PATH_TO_SAVE_CKPTS/$DATASET_NAME\_$SHOT\_refs_memory.pth \
    --model.init_args.dataset_cfgs.fill_memory.root $DATASET_PATH/images \
    --model.init_args.dataset_cfgs.fill_memory.json_file $DATASET_PATH/annotations/custom_references_with_segm.json \
    --model.init_args.dataset_cfgs.fill_memory.memory_pkl $DATASET_PATH/annotations/custom_references_with_segm.pkl \
    --model.init_args.dataset_cfgs.fill_memory.memory_length $SHOT \
    --model.init_args.dataset_cfgs.fill_memory.cat_names $CAT_NAMES \
    --model.init_args.model_cfg.dataset_name $DATASET_NAME \
    --model.init_args.model_cfg.memory_bank_cfg.length $SHOT \
    --model.init_args.model_cfg.memory_bank_cfg.category_num $CATEGORY_NUM \
    --trainer.devices 1
```
### 2. å¾Œè™•ç†è¨˜æ†¶é«”åº«


```bash
python run_lightening.py test --config $YAML_PATH \
    --model.test_mode postprocess_memory \
    --ckpt_path $PATH_TO_SAVE_CKPTS/$DATASET_NAME\_$SHOT\_refs_memory.pth \
    --out_path $PATH_TO_SAVE_CKPTS/$DATASET_NAME\_$SHOT\_refs_memory_postprocessed.pth \
    --model.init_args.model_cfg.dataset_name $DATASET_NAME \
    --model.init_args.model_cfg.memory_bank_cfg.length $SHOT \
    --model.init_args.model_cfg.memory_bank_cfg.category_num $CATEGORY_NUM \
    --trainer.devices 1
```
### 3. å°ç›®æ¨™åœ–åƒé€²è¡Œæ¨è«–

å¦‚æœå°‡ `ONLINE_VIS` è¨­ç‚º Trueï¼Œé æ¸¬çµæœå°‡æœƒå„²å­˜åœ¨ `results_analysis/my_custom_dataset/`ï¼Œä¸¦åœ¨è¨ˆç®—æ™‚å³æ™‚é¡¯ç¤ºã€‚è«‹æ³¨æ„ï¼Œå•Ÿç”¨ç·šä¸Šè¦–è¦ºåŒ–æœƒä½¿é‹è¡Œé€Ÿåº¦è®Šæ…¢è¨±å¤šã€‚

æ‚¨å¯ä»¥è‡ªç”±èª¿æ•´åˆ†æ•¸é–¾å€¼ `VIS_THR`ï¼Œä»¥æŸ¥çœ‹æ›´å¤šæˆ–æ›´å°‘çš„åˆ†å‰²å¯¦ä¾‹ã€‚

```bash
ONLINE_VIS=True
VIS_THR=0.4
python run_lightening.py test --config $YAML_PATH \
    --model.test_mode test \
    --ckpt_path $PATH_TO_SAVE_CKPTS/$DATASET_NAME\_$SHOT\_refs_memory_postprocessed.pth \
    --model.init_args.model_cfg.dataset_name $DATASET_NAME \
    --model.init_args.model_cfg.memory_bank_cfg.length $SHOT \
    --model.init_args.model_cfg.memory_bank_cfg.category_num $CATEGORY_NUM \
    --model.init_args.model_cfg.test.imgs_path $DATASET_PATH/images \
    --model.init_args.model_cfg.test.online_vis $ONLINE_VIS \
    --model.init_args.model_cfg.test.vis_thr $VIS_THR \
    --model.init_args.dataset_cfgs.test.root $DATASET_PATH/images \
    --model.init_args.dataset_cfgs.test.json_file $DATASET_PATH/annotations/custom_targets.json \
    --model.init_args.dataset_cfgs.test.cat_names $CAT_NAMES \
    --trainer.devices 1
```
### çµæœ

æ€§èƒ½æŒ‡æ¨™ï¼ˆä½¿ç”¨èˆ‡ä¸Šè¿°æŒ‡ä»¤å®Œå…¨ç›¸åŒçš„åƒæ•¸ï¼‰æ‡‰å¦‚ä¸‹æ‰€ç¤ºï¼š


```
BBOX RESULTS:
  Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.478

SEGM RESULTS:
  Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.458
```
è¦–è¦ºçµæœå·²å„²å­˜åœ¨ `results_analysis/my_custom_dataset/`ã€‚è«‹æ³¨æ„ï¼Œæˆ‘å€‘çš„æ–¹æ³•é©ç”¨æ–¼å½é™°æ€§ï¼Œä¹Ÿå°±æ˜¯é‚£äº›ä¸åŒ…å«ä»»ä½•ç›®æ¨™é¡åˆ¥å¯¦ä¾‹çš„å½±åƒã€‚

*é»æ“Šåœ–ç‰‡ä»¥æ”¾å¤§ â¬‡ï¸*

| å«æœ‰èˆ¹éš»çš„ç›®æ¨™å½±åƒ â›µï¼ˆå·¦ç‚ºGTï¼Œå³ç‚ºé æ¸¬ï¼‰ | å«æœ‰é³¥é¡çš„ç›®æ¨™å½±åƒ ğŸ¦ï¼ˆå·¦ç‚ºGTï¼Œå³ç‚ºé æ¸¬ï¼‰ |
|:----------------------:|:----------------------:|
| ![000000459673](https://github.com/user-attachments/assets/678dc15a-dd3b-49d5-9287-6290da16aa6b) | ![000000407180](https://github.com/user-attachments/assets/fe306e48-af49-4d83-ac82-76fac6c456d1) |

| å«æœ‰èˆ¹éš»èˆ‡é³¥é¡çš„ç›®æ¨™å½±åƒ â›µğŸ¦ï¼ˆå·¦ç‚ºGTï¼Œå³ç‚ºé æ¸¬ï¼‰ | ä¸å«èˆ¹éš»æˆ–é³¥é¡çš„ç›®æ¨™å½±åƒ ğŸš«ï¼ˆå·¦ç‚ºGTï¼Œå³ç‚ºé æ¸¬ï¼‰ |
|:---------------------------------:|:----------------------------------:|
| ![000000517410](https://github.com/user-attachments/assets/9849b227-7f43-43d7-81ea-58010a623ad5) | ![000000460598](https://github.com/user-attachments/assets/7587700c-e09d-4cf6-8590-3df129c2568e) |


## ğŸ“š å¼•ç”¨

å¦‚æœæ‚¨ä½¿ç”¨æœ¬ç ”ç©¶ï¼Œè«‹å¼•ç”¨æˆ‘å€‘ï¼š


```bibtex
@article{espinosa2025notimetotrain,
  title={No time to train! Training-Free Reference-Based Instance Segmentation},
  author={Miguel Espinosa and Chenhongyi Yang and Linus Ericsson and Steven McDonagh and Elliot J. Crowley},
  journal={arXiv preprint arXiv:2507.02798},
  year={2025},
  primaryclass={cs.CV}
}
```


---

Tranlated By [Open Ai Tx](https://github.com/OpenAiTx/OpenAiTx) | Last indexed: 2025-07-24

---