
<div align="right">
  <details>
    <summary >ğŸŒ ì–¸ì–´</summary>
    <div>
      <div align="center">
        <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=en">English</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=zh-CN">ç®€ä½“ä¸­æ–‡</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=zh-TW">ç¹é«”ä¸­æ–‡</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=ja">æ—¥æœ¬èª</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=ko">í•œêµ­ì–´</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=hi">à¤¹à¤¿à¤¨à¥à¤¦à¥€</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=th">à¹„à¸—à¸¢</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=fr">FranÃ§ais</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=de">Deutsch</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=es">EspaÃ±ol</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=it">Italiano</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=ru">Ğ ÑƒÑÑĞºĞ¸Ğ¹</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=pt">PortuguÃªs</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=nl">Nederlands</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=pl">Polski</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=ar">Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=fa">ÙØ§Ø±Ø³ÛŒ</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=tr">TÃ¼rkÃ§e</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=vi">Tiáº¿ng Viá»‡t</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=id">Bahasa Indonesia</a>
      </div>
    </div>
  </details>
</div>

<div align="center">

# ğŸš€ í›ˆë ¨í•  ì‹œê°„ì´ ì—†ë‹¤!  
### í›ˆë ¨ ì—†ì´ ì°¸ì¡° ê¸°ë°˜ ì¸ìŠ¤í„´ìŠ¤ ë¶„í•   
[![GitHub](https://img.shields.io/badge/%E2%80%8B-No%20Time%20To%20Train-black?logo=github)](https://github.com/miquel-espinosa/no-time-to-train)
[![Website](https://img.shields.io/badge/ğŸŒ-Project%20Page-grey)](https://miquel-espinosa.github.io/no-time-to-train/)
[![arXiv](https://img.shields.io/badge/arXiv-2507.02798-b31b1b)](https://arxiv.org/abs/2507.02798)

**ìµœì‹  ì—°êµ¬ (Papers with Code)**
[**_SOTA 1-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-1-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/badge/State%20of%20the%20Art-Few--Shot%20Object%20Detection%20on%20MS--COCO%20(1--shot)-21CBCE?style=flat&logo=paperswithcode)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-1-shot?p=no-time-to-train-training-free-reference)

[**_SOTA 10-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-10-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/badge/State%20of%20the%20Art-Few--Shot%20Object%20Detection%20on%20MS--COCO%20(10--shot)-21CBCE?style=flat&logo=paperswithcode)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-10-shot?p=no-time-to-train-training-free-reference)

[**_SOTA 30-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-30-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/badge/State%20of%20the%20Art-Few--Shot%20Object%20Detection%20on%20MS--COCO%20(30--shot)-21CBCE?style=flat&logo=paperswithcode)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-30-shot?p=no-time-to-train-training-free-reference)

<!-- [**_SOTA 1-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-1-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/no-time-to-train-training-free-reference/few-shot-object-detection-on-ms-coco-1-shot)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-1-shot?p=no-time-to-train-training-free-reference)

[**_SOTA 10-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-10-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/no-time-to-train-training-free-reference/few-shot-object-detection-on-ms-coco-10-shot)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-10-shot?p=no-time-to-train-training-free-reference)

[**_SOTA 30-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-30-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/no-time-to-train-training-free-reference/few-shot-object-detection-on-ms-coco-30-shot)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-30-shot?p=no-time-to-train-training-free-reference) -->

</div>

---

> ğŸš¨ **ì—…ë°ì´íŠ¸ (2025ë…„ 7ì›” 22ì¼):** ì‚¬ìš©ì ì§€ì • ë°ì´í„°ì…‹ì— ëŒ€í•œ ì§€ì¹¨ì´ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤!
> 
> ğŸ”” **ì—…ë°ì´íŠ¸ (2025ë…„ 7ì›” 16ì¼):** ì½”ë“œê°€ ì„¤ëª…ê³¼ í•¨ê»˜ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤!

---

## ğŸ“‹ ëª©ì°¨

- [ğŸ¯ í•˜ì´ë¼ì´íŠ¸](#-highlights)
- [ğŸ“œ ì´ˆë¡](#-abstract)
- [ğŸ§  ì•„í‚¤í…ì²˜](#-architecture)
- [ğŸ› ï¸ ì„¤ì¹˜ ë°©ë²•](#ï¸-installation-instructions)
  - [1. ì €ì¥ì†Œ í´ë¡ ](#1-clone-the-repository)
  - [2. conda í™˜ê²½ ìƒì„±](#2-create-conda-environment)
  - [3. SAM2 ë° DinoV2 ì„¤ì¹˜](#3-install-sam2-and-dinov2)
  - [4. ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ](#4-download-datasets)
  - [5. SAM2 ë° DinoV2 ì²´í¬í¬ì¸íŠ¸ ë‹¤ìš´ë¡œë“œ](#5-download-sam2-and-dinov2-checkpoints)
- [ğŸ“Š ì¶”ë¡  ì½”ë“œ: Few-shot COCOì—ì„œ 30-shot SOTA ê²°ê³¼ ì¬í˜„](#-inference-code)
  - [0. ì°¸ì¡° ì„¸íŠ¸ ìƒì„±](#0-create-reference-set)
  - [1. ì°¸ì¡°ë¡œ ë©”ëª¨ë¦¬ ì±„ìš°ê¸°](#1-fill-memory-with-references)
  - [2. ë©”ëª¨ë¦¬ ë±…í¬ í›„ì²˜ë¦¬](#2-post-process-memory-bank)
  - [3. ëŒ€ìƒ ì´ë¯¸ì§€ì—ì„œ ì¶”ë¡ ](#3-inference-on-target-images)
  - [ê²°ê³¼](#results)

- [ğŸ” ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹](#-custom-dataset)
  - [0. ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ ì¤€ë¹„ â›µğŸ¦](#0-prepare-a-custom-dataset)
  - [0.1 ë°”ìš´ë”© ë°•ìŠ¤ ì–´ë…¸í…Œì´ì…˜ë§Œ ìˆì„ ê²½ìš°](#01-if-only-bbox-annotations-are-available)
  - [0.2 coco ì–´ë…¸í…Œì´ì…˜ì„ pickle íŒŒì¼ë¡œ ë³€í™˜](#02-convert-coco-annotations-to-pickle-file)
  - [1. ì°¸ì¡°ë¡œ ë©”ëª¨ë¦¬ ì±„ìš°ê¸°](#1-fill-memory-with-references)
  - [2. ë©”ëª¨ë¦¬ ë±…í¬ í›„ì²˜ë¦¬](#2-post-process-memory-bank)
- [ğŸ“š ì¸ìš©](#-citation)


## ğŸ¯ í•˜ì´ë¼ì´íŠ¸
- ğŸ’¡ **í•™ìŠµ ë¶ˆí•„ìš”**: íŒŒì¸íŠœë‹ë„, í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ë„ ì—†ìŒâ€”ì°¸ì¡° ì´ë¯¸ì§€ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.  
- ğŸ–¼ï¸ **ì°¸ì¡° ê¸°ë°˜**: ì†Œìˆ˜ì˜ ì˜ˆì‹œë§Œìœ¼ë¡œ ìƒˆë¡œìš´ ê°ì²´ë¥¼ ë¶„í• í•©ë‹ˆë‹¤.  
- ğŸ”¥ **ìµœì²¨ë‹¨ ì„±ëŠ¥**: COCO, PASCAL VOC, Cross-Domain FSODì—ì„œ ê¸°ì¡´ í•™ìŠµ ë¶ˆí•„ìš” ë°©ë²•ë³´ë‹¤ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤.

**ë§í¬:**
- ğŸ§¾ [**arXiv ë…¼ë¬¸**](https://arxiv.org/abs/2507.02798)  
- ğŸŒ [**í”„ë¡œì íŠ¸ ì›¹ì‚¬ì´íŠ¸**](https://miquel-espinosa.github.io/no-time-to-train/)  
- ğŸ“ˆ [**Papers with Code**](https://paperswithcode.com/paper/no-time-to-train-training-free-reference)

## ğŸ“œ ì´ˆë¡

> The performance of image segmentation models has historically been constrained by the high cost of collecting large-scale annotated data. The Segment Anything Model (SAM) alleviates this original problem through a promptable, semantics-agnostic, segmentation paradigm and yet still requires manual visual-prompts or complex domain-dependent prompt-generation rules to process a new image. Towards reducing this new burden, our work investigates the task of object segmentation when provided with, alternatively, only a small set of reference images. Our key insight is to leverage strong semantic priors, as learned by foundation models, to identify corresponding regions between a reference and a target image. We find that correspondences enable automatic generation of instance-level segmentation masks for downstream tasks and instantiate our ideas via a multi-stage, training-free method incorporating (1) memory bank construction; (2) representation aggregation and (3) semantic-aware feature matching. Our experiments show significant improvements on segmentation metrics, leading to state-of-the-art performance on COCO FSOD (36.8% nAP), PASCAL VOC Few-Shot (71.2% nAP50) and outperforming existing training-free approaches on the Cross-Domain FSOD benchmark (22.4% nAP).

![cdfsod-results-final-comic-sans-min](https://github.com/user-attachments/assets/ab302c02-c080-4042-99fc-0e181ba8abb9)


## ğŸ§  Architecture

![training-free-architecture-comic-sans-min](https://github.com/user-attachments/assets/d84dd83a-505e-45a0-8ce3-98e1838017f9)


## ğŸ› ï¸ Installation instructions

### 1. Clone the repository

```bash
git clone https://github.com/miquel-espinosa/no-time-to-train.git
cd no-time-to-train
```
### 2. conda í™˜ê²½ ìƒì„±

í•„ìš”í•œ íŒ¨í‚¤ì§€ë¥¼ í¬í•¨í•œ conda í™˜ê²½ì„ ìƒì„±í•©ë‹ˆë‹¤.

```bash
conda env create -f environment.yml
conda activate no-time-to-train
```
### 3. SAM2 ë° DinoV2 ì„¤ì¹˜

ìš°ë¦¬ëŠ” SAM2ì™€ DinoV2ë¥¼ ì†ŒìŠ¤ì—ì„œ ì„¤ì¹˜í•  ê²ƒì…ë‹ˆë‹¤.

```bash
pip install -e .
cd dinov2
pip install -e .
cd ..
```
### 4. ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ

COCO ë°ì´í„°ì…‹ì„ ë‹¤ìš´ë¡œë“œí•˜ì—¬ `data/coco`ì— ì €ì¥í•˜ì„¸ìš”.

### 5. SAM2 ë° DinoV2 ì²´í¬í¬ì¸íŠ¸ ë‹¤ìš´ë¡œë“œ

ë…¼ë¬¸ì—ì„œ ì‚¬ìš©ëœ ì •í™•í•œ SAM2 ì²´í¬í¬ì¸íŠ¸ë¥¼ ë‹¤ìš´ë¡œë“œí•  ê²ƒì…ë‹ˆë‹¤.
(ë‹¨, SAM2.1 ì²´í¬í¬ì¸íŠ¸ëŠ” ì´ë¯¸ ì œê³µë˜ê³  ìˆìœ¼ë©° ë” ë‚˜ì€ ì„±ëŠ¥ì„ ë³´ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.)


```bash
mkdir -p checkpoints/dinov2
cd checkpoints
wget https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_large.pt
cd dinov2
wget https://dl.fbaipublicfiles.com/dinov2/dinov2_vitl14/dinov2_vitl14_pretrain.pth
cd ../..
```



## ğŸ“Š ì¶”ë¡  ì½”ë“œ

âš ï¸ ë©´ì±… ì¡°í•­: ì´ ì½”ë“œëŠ” ì—°êµ¬ìš©ì…ë‹ˆë‹¤ â€” ì•½ê°„ì˜ í˜¼ë€ì´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤!

### Few-shot COCOì—ì„œ 30-shot SOTA ê²°ê³¼ ì¬í˜„í•˜ê¸°

ìœ ìš©í•œ ë³€ìˆ˜ë¥¼ ì •ì˜í•˜ê³  ê²°ê³¼ë¥¼ ìœ„í•œ í´ë”ë¥¼ ë§Œë“­ë‹ˆë‹¤:


```bash
CONFIG=./no_time_to_train/new_exps/coco_fewshot_10shot_Sam2L.yaml
CLASS_SPLIT="few_shot_classes"
RESULTS_DIR=work_dirs/few_shot_results
SHOTS=30
SEED=33
GPUS=4

mkdir -p $RESULTS_DIR
FILENAME=few_shot_${SHOTS}shot_seed${SEED}.pkl
```
#### 0. ì°¸ì¡° ì„¸íŠ¸ ìƒì„±


```bash
python no_time_to_train/dataset/few_shot_sampling.py \
        --n-shot $SHOTS \
        --out-path ${RESULTS_DIR}/${FILENAME} \
        --seed $SEED \
        --dataset $CLASS_SPLIT
```
#### 1. ì°¸ì¡°ë¡œ ë©”ëª¨ë¦¬ ì±„ìš°ê¸°


```bash
python run_lightening.py test --config $CONFIG \
                              --model.test_mode fill_memory \
                              --out_path ${RESULTS_DIR}/memory.ckpt \
                              --model.init_args.model_cfg.memory_bank_cfg.length $SHOTS \
                              --model.init_args.dataset_cfgs.fill_memory.memory_pkl ${RESULTS_DIR}/${FILENAME} \
                              --model.init_args.dataset_cfgs.fill_memory.memory_length $SHOTS \
                              --model.init_args.dataset_cfgs.fill_memory.class_split $CLASS_SPLIT \
                              --trainer.logger.save_dir ${RESULTS_DIR}/ \
                              --trainer.devices $GPUS
```
#### 2. í›„ì²˜ë¦¬ ë©”ëª¨ë¦¬ ë±…í¬


```bash
python run_lightening.py test --config $CONFIG \
                              --model.test_mode postprocess_memory \
                              --model.init_args.model_cfg.memory_bank_cfg.length $SHOTS \
                              --ckpt_path ${RESULTS_DIR}/memory.ckpt \
                              --out_path ${RESULTS_DIR}/memory_postprocessed.ckpt \
                              --trainer.devices 1
```
#### 3. ëŒ€ìƒ ì´ë¯¸ì§€ì— ëŒ€í•œ ì¶”ë¡ 


```bash
python run_lightening.py test --config $CONFIG  \
                              --ckpt_path ${RESULTS_DIR}/memory_postprocessed.ckpt \
                              --model.init_args.test_mode test \
                              --model.init_args.model_cfg.memory_bank_cfg.length $SHOTS \
                              --model.init_args.model_cfg.dataset_name $CLASS_SPLIT \
                              --model.init_args.dataset_cfgs.test.class_split $CLASS_SPLIT \
                              --trainer.logger.save_dir ${RESULTS_DIR}/ \
                              --trainer.devices $GPUS
```
ì˜¨ë¼ì¸ì—ì„œ ì¶”ë¡  ê²°ê³¼ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ í™•ì¸í•˜ê³  ì‹¶ë‹¤ë©´ ë‹¤ìŒ ì¸ìë¥¼ ì¶”ê°€í•˜ì„¸ìš”:

```bash
    --model.init_args.model_cfg.test.online_vis True
```
`score_thr` ë§¤ê°œë³€ìˆ˜ì˜ ì ìˆ˜ ì„ê³„ê°’ì„ ì¡°ì •í•˜ë ¤ë©´ ì¸ìë¥¼ ì¶”ê°€í•˜ì„¸ìš” (ì˜ˆë¥¼ ë“¤ì–´, ì ìˆ˜ê°€ `0.4`ë³´ë‹¤ ë†’ì€ ëª¨ë“  ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì‹œê°í™”í•˜ë ¤ë©´):
```bash
    --model.init_args.model_cfg.test.vis_thr 0.4
```
ì´ë¯¸ì§€ëŠ” ì´ì œ `results_analysis/few_shot_classes/`ì— ì €ì¥ë©ë‹ˆë‹¤. ì™¼ìª½ ì´ë¯¸ì§€ëŠ” ì‹¤ì œ ì •ë‹µ(ground truth)ì„, ì˜¤ë¥¸ìª½ ì´ë¯¸ì§€ëŠ” í•™ìŠµ ì—†ì´ ìš°ë¦¬ ë°©ë²•ìœ¼ë¡œ ì°¾ì•„ë‚¸ ë¶„í•  ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.

ì´ ì˜ˆì œì—ì„œëŠ” `few_shot_classes` ë¶„í• ì„ ì‚¬ìš©í•˜ë¯€ë¡œ, í•´ë‹¹ ë¶„í• ì— í¬í•¨ëœ í´ë˜ìŠ¤ì˜ ë¶„í• ëœ ì¸ìŠ¤í„´ìŠ¤ë§Œ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤(COCOì˜ ëª¨ë“  í´ë˜ìŠ¤ê°€ ì•„ë‹˜).

#### ê²°ê³¼

ê²€ì¦ ì„¸íŠ¸ì˜ ëª¨ë“  ì´ë¯¸ì§€ë¥¼ ì‹¤í–‰í•œ í›„, ë‹¤ìŒê³¼ ê°™ì€ ê²°ê³¼ë¥¼ ì–»ê²Œ ë©ë‹ˆë‹¤:

```
BBOX RESULTS:
  Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.368

SEGM RESULTS:
  Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.342
```
---

## ğŸ” ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹

ìš°ë¦¬ëŠ” ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ì—ì„œ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•˜ëŠ” ë°©ë²•ì— ëŒ€í•œ ì§€ì¹¨ì„ ì œê³µí•©ë‹ˆë‹¤. ì–´ë…¸í…Œì´ì…˜ í¬ë§·ì€ í•­ìƒ COCO í¬ë§·ì…ë‹ˆë‹¤.

> **ìš”ì•½;** *ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹*ì—ì„œ ì „ì²´ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•˜ëŠ” ë°©ë²•ì„ ë°”ë¡œ í™•ì¸í•˜ë ¤ë©´, `scripts/matching_cdfsod_pipeline.sh`ì™€ í•¨ê»˜ CD-FSOD ë°ì´í„°ì…‹ì˜ ì˜ˆì‹œ ìŠ¤í¬ë¦½íŠ¸(ì˜ˆ: `scripts/dior_fish.sh`)ë¥¼ ì°¸ê³ í•˜ì„¸ìš”.

### 0. ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ ì¤€ë¹„í•˜ê¸° â›µğŸ¦

ì˜ˆë¥¼ ë“¤ì–´, ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ì—ì„œ **ë³´íŠ¸**â›µì™€ **ìƒˆ**ğŸ¦ë¥¼ íƒì§€í•˜ê³  ì‹¶ë‹¤ê³  ê°€ì •í•´ë´…ì‹œë‹¤. ìš°ë¦¬ì˜ ë°©ë²•ì„ ì‚¬ìš©í•˜ë ¤ë©´ ë‹¤ìŒì´ í•„ìš”í•©ë‹ˆë‹¤:
- ê° í´ë˜ìŠ¤ë§ˆë‹¤ ì ì–´ë„ 1ì¥ì˜ *ì–´ë…¸í…Œì´ì…˜ëœ* ê¸°ì¤€ ì´ë¯¸ì§€(ì˜ˆ: ë³´íŠ¸ 1ì¥, ìƒˆ 1ì¥)
- ì›í•˜ëŠ” í´ë˜ìŠ¤ë¥¼ ì°¾ê¸° ìœ„í•œ ì—¬ëŸ¬ ì¥ì˜ íƒ€ê¹ƒ ì´ë¯¸ì§€

ìš°ë¦¬ëŠ” coco ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•˜ì—¬ **1-shot** ì„¤ì •ì— ë§ëŠ” ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ì„ ë§Œë“œëŠ” í† ì´ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì¤€ë¹„í–ˆìŠµë‹ˆë‹¤.
```bash
mkdir -p data/my_custom_dataset
python scripts/make_custom_dataset.py
```
ì´ë ‡ê²Œ í•˜ë©´ ë‹¤ìŒê³¼ ê°™ì€ í´ë” êµ¬ì¡°ë¥¼ ê°€ì§„ ì‚¬ìš©ì ì§€ì • ë°ì´í„°ì…‹ì´ ìƒì„±ë©ë‹ˆë‹¤:
```
data/my_custom_dataset/
    â”œâ”€â”€ annotations/
    â”‚   â”œâ”€â”€ custom_references.json
    â”‚   â”œâ”€â”€ custom_targets.json
    â”‚   â””â”€â”€ references_visualisations/
    â”‚       â”œâ”€â”€ bird_1.jpg
    â”‚       â””â”€â”€ boat_1.jpg
    â””â”€â”€ images/
        â”œâ”€â”€ 429819.jpg
        â”œâ”€â”€ 101435.jpg
        â””â”€â”€ (all target and reference images)
```
**ì°¸ì¡° ì´ë¯¸ì§€ ì‹œê°í™” (1-shot):**

| BIRD ğŸ¦ì˜ 1-shot ì°¸ì¡° ì´ë¯¸ì§€ | BOAT â›µì˜ 1-shot ì°¸ì¡° ì´ë¯¸ì§€ |
|:-----------------------------:|:------------------------------:|
| <img src="https://github.com/user-attachments/assets/e59e580d-a7db-42ac-b386-892af211fc85" alt="bird_1" width="500"/> | <img src="https://github.com/user-attachments/assets/f94ee025-ae37-4a45-9c3e-0cfe8f8cd2bc" alt="boat_1" width="500"/> |


### 0.1 ë°”ìš´ë”© ë°•ìŠ¤ ì£¼ì„ë§Œ ìˆëŠ” ê²½ìš°

SAM2ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¸ìŠ¤í„´ìŠ¤ ìˆ˜ì¤€ì˜ ë¶„í•  ë§ˆìŠ¤í¬ë¥¼ ìƒì„±í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸ë„ ì œê³µí•©ë‹ˆë‹¤. ì´ëŠ” ì°¸ì¡° ì´ë¯¸ì§€ì— ëŒ€í•´ ë°”ìš´ë”© ë°•ìŠ¤ ì£¼ì„ë§Œ ìˆëŠ” ê²½ìš°ì— ìœ ìš©í•©ë‹ˆë‹¤.


```bash
# Download sam_h checkpoint. Feel free to use more recent checkpoints (note: code might need to be adapted)
wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth -O checkpoints/sam_vit_h_4b8939.pth
# Run automatic instance segmentation from ground truth bounding boxes.
python no_time_to_train/dataset/sam_bbox_to_segm_batch.py \
    --input_json data/my_custom_dataset/annotations/custom_references.json \
    --image_dir data/my_custom_dataset/images \
    --sam_checkpoint checkpoints/sam_vit_h_4b8939.pth \
    --model_type vit_h \
    --device cuda \
    --batch_size 8 \
    --visualize
```
**SAM2ë¡œ gt ë°”ìš´ë”© ë°•ìŠ¤ì—ì„œ ìƒì„±ëœ ì¸ìŠ¤í„´ìŠ¤ ìˆ˜ì¤€ ë¶„í•  ë§ˆìŠ¤í¬ê°€ í¬í•¨ëœ ì°¸ì¡° ì´ë¯¸ì§€(1-shot):**

ìƒì„±ëœ ë¶„í•  ë§ˆìŠ¤í¬ì˜ ì‹œê°í™” ê²°ê³¼ëŠ” `data/my_custom_dataset/annotations/custom_references_with_SAM_segm/references_visualisations/`ì— ì €ì¥ë©ë‹ˆë‹¤.

| BIRD ğŸ¦ì˜ 1-shot ì°¸ì¡° ì´ë¯¸ì§€ (SAMìœ¼ë¡œ ìë™ ë¶„í• ) | BOAT â›µì˜ 1-shot ì°¸ì¡° ì´ë¯¸ì§€ (SAMìœ¼ë¡œ ìë™ ë¶„í• ) |
|:---------------------------------:|:----------------------------------:|
| <img src="https://github.com/user-attachments/assets/65d38dc4-1454-43cd-9600-e8efc67b3a82" alt="bird_1_with_SAM_segm" width="500"/> | <img src="https://github.com/user-attachments/assets/43a558ad-50ca-4715-8285-9aa3268843c6" alt="boat_1_with_SAM_segm" width="500"/> |

### 0.2 coco ì–´ë…¸í…Œì´ì…˜ì„ í”¼í´ íŒŒì¼ë¡œ ë³€í™˜




```bash
python no_time_to_train/dataset/coco_to_pkl.py \
    data/my_custom_dataset/annotations/custom_references_with_segm.json \
    data/my_custom_dataset/annotations/custom_references_with_segm.pkl \
    1
```
### 1. ì°¸ì¡°ë¡œ ë©”ëª¨ë¦¬ ì±„ìš°ê¸°

ë¨¼ì €, ìœ ìš©í•œ ë³€ìˆ˜ë¥¼ ì •ì˜í•˜ê³  ê²°ê³¼ë¥¼ ìœ„í•œ í´ë”ë¥¼ ë§Œë“­ë‹ˆë‹¤. ë¼ë²¨ì˜ ì˜¬ë°”ë¥¸ ì‹œê°í™”ë¥¼ ìœ„í•´ í´ë˜ìŠ¤ ì´ë¦„ì€ json íŒŒì¼ì— ë‚˜íƒ€ë‚˜ëŠ” ì¹´í…Œê³ ë¦¬ id ìˆœì„œëŒ€ë¡œ ì •ë ¬ë˜ì–´ì•¼ í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, `bird`ì˜ ì¹´í…Œê³ ë¦¬ idëŠ” `16`, `boat`ì˜ ì¹´í…Œê³ ë¦¬ idëŠ” `9`ì…ë‹ˆë‹¤. ë”°ë¼ì„œ `CAT_NAMES=boat,bird`ê°€ ë©ë‹ˆë‹¤.


```bash
DATASET_NAME=my_custom_dataset
DATASET_PATH=data/my_custom_dataset
CAT_NAMES=boat,bird
CATEGORY_NUM=2
SHOT=1
YAML_PATH=no_time_to_train/pl_configs/matching_cdfsod_template.yaml
PATH_TO_SAVE_CKPTS=./tmp_ckpts/my_custom_dataset
mkdir -p $PATH_TO_SAVE_CKPTS
```
1ë‹¨ê³„ ì‹¤í–‰:

```bash
python run_lightening.py test --config $YAML_PATH \
    --model.test_mode fill_memory \
    --out_path $PATH_TO_SAVE_CKPTS/$DATASET_NAME\_$SHOT\_refs_memory.pth \
    --model.init_args.dataset_cfgs.fill_memory.root $DATASET_PATH/images \
    --model.init_args.dataset_cfgs.fill_memory.json_file $DATASET_PATH/annotations/custom_references_with_segm.json \
    --model.init_args.dataset_cfgs.fill_memory.memory_pkl $DATASET_PATH/annotations/custom_references_with_segm.pkl \
    --model.init_args.dataset_cfgs.fill_memory.memory_length $SHOT \
    --model.init_args.dataset_cfgs.fill_memory.cat_names $CAT_NAMES \
    --model.init_args.model_cfg.dataset_name $DATASET_NAME \
    --model.init_args.model_cfg.memory_bank_cfg.length $SHOT \
    --model.init_args.model_cfg.memory_bank_cfg.category_num $CATEGORY_NUM \
    --trainer.devices 1
```
### 2. í›„ì²˜ë¦¬ ë©”ëª¨ë¦¬ ë±…í¬


```bash
python run_lightening.py test --config $YAML_PATH \
    --model.test_mode postprocess_memory \
    --ckpt_path $PATH_TO_SAVE_CKPTS/$DATASET_NAME\_$SHOT\_refs_memory.pth \
    --out_path $PATH_TO_SAVE_CKPTS/$DATASET_NAME\_$SHOT\_refs_memory_postprocessed.pth \
    --model.init_args.model_cfg.dataset_name $DATASET_NAME \
    --model.init_args.model_cfg.memory_bank_cfg.length $SHOT \
    --model.init_args.model_cfg.memory_bank_cfg.category_num $CATEGORY_NUM \
    --trainer.devices 1
```
### 3. íƒ€ê²Ÿ ì´ë¯¸ì§€ì— ëŒ€í•œ ì¶”ë¡ 

`ONLINE_VIS`ê°€ Trueë¡œ ì„¤ì •ë˜ì–´ ìˆìœ¼ë©´, ì˜ˆì¸¡ ê²°ê³¼ê°€ `results_analysis/my_custom_dataset/`ì— ì €ì¥ë˜ê³  ê³„ì‚°ë˜ëŠ” ëŒ€ë¡œ í‘œì‹œë©ë‹ˆë‹¤. ì˜¨ë¼ì¸ ì‹œê°í™”ì™€ í•¨ê»˜ ì‹¤í–‰í•˜ë©´ ì†ë„ê°€ í›¨ì”¬ ëŠë ¤ì§„ë‹¤ëŠ” ì ì— ìœ ì˜í•˜ì„¸ìš”.

ë¶„í• ëœ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë” ë§ì´ ë˜ëŠ” ë” ì ê²Œ ë³´ê³  ì‹¶ë‹¤ë©´ ì ìˆ˜ ì„ê³„ê°’ `VIS_THR`ë¥¼ ììœ ë¡­ê²Œ ë³€ê²½í•˜ì„¸ìš”.

```bash
ONLINE_VIS=True
VIS_THR=0.4
python run_lightening.py test --config $YAML_PATH \
    --model.test_mode test \
    --ckpt_path $PATH_TO_SAVE_CKPTS/$DATASET_NAME\_$SHOT\_refs_memory_postprocessed.pth \
    --model.init_args.model_cfg.dataset_name $DATASET_NAME \
    --model.init_args.model_cfg.memory_bank_cfg.length $SHOT \
    --model.init_args.model_cfg.memory_bank_cfg.category_num $CATEGORY_NUM \
    --model.init_args.model_cfg.test.imgs_path $DATASET_PATH/images \
    --model.init_args.model_cfg.test.online_vis $ONLINE_VIS \
    --model.init_args.model_cfg.test.vis_thr $VIS_THR \
    --model.init_args.dataset_cfgs.test.root $DATASET_PATH/images \
    --model.init_args.dataset_cfgs.test.json_file $DATASET_PATH/annotations/custom_targets.json \
    --model.init_args.dataset_cfgs.test.cat_names $CAT_NAMES \
    --trainer.devices 1
```
### ê²°ê³¼

ì„±ëŠ¥ ì§€í‘œ(ìœ„ ëª…ë ¹ì–´ì™€ ì •í™•íˆ ë™ì¼í•œ ë§¤ê°œë³€ìˆ˜ ì‚¬ìš©)ëŠ” ë‹¤ìŒê³¼ ê°™ì•„ì•¼ í•©ë‹ˆë‹¤:


```
BBOX RESULTS:
  Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.478

SEGM RESULTS:
  Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.458
```
ì‹œê°ì  ê²°ê³¼ëŠ” `results_analysis/my_custom_dataset/`ì— ì €ì¥ë©ë‹ˆë‹¤. ë³¸ ë°©ë²•ì€ ì›í•˜ëŠ” í´ë˜ìŠ¤ì˜ ì¸ìŠ¤í„´ìŠ¤ê°€ ì—†ëŠ” ì´ë¯¸ì§€(ì¦‰, false negative)ì— ëŒ€í•´ì„œë„ ì‘ë™í•©ë‹ˆë‹¤.

*ì´ë¯¸ì§€ë¥¼ í´ë¦­í•˜ë©´ í™•ëŒ€ë©ë‹ˆë‹¤ â¬‡ï¸*

| ë³´íŠ¸ê°€ ìˆëŠ” ëŒ€ìƒ ì´ë¯¸ì§€ â›µ (ì™¼ìª½ GT, ì˜¤ë¥¸ìª½ ì˜ˆì¸¡) | ìƒˆê°€ ìˆëŠ” ëŒ€ìƒ ì´ë¯¸ì§€ ğŸ¦ (ì™¼ìª½ GT, ì˜¤ë¥¸ìª½ ì˜ˆì¸¡) |
|:----------------------:|:----------------------:|
| ![000000459673](https://github.com/user-attachments/assets/678dc15a-dd3b-49d5-9287-6290da16aa6b) | ![000000407180](https://github.com/user-attachments/assets/fe306e48-af49-4d83-ac82-76fac6c456d1) |

| ë³´íŠ¸ì™€ ìƒˆê°€ ëª¨ë‘ ìˆëŠ” ëŒ€ìƒ ì´ë¯¸ì§€ â›µğŸ¦ (ì™¼ìª½ GT, ì˜¤ë¥¸ìª½ ì˜ˆì¸¡) | ë³´íŠ¸ë‚˜ ìƒˆê°€ ì—†ëŠ” ëŒ€ìƒ ì´ë¯¸ì§€ ğŸš« (ì™¼ìª½ GT, ì˜¤ë¥¸ìª½ ì˜ˆì¸¡) |
|:---------------------------------:|:----------------------------------:|
| ![000000517410](https://github.com/user-attachments/assets/9849b227-7f43-43d7-81ea-58010a623ad5) | ![000000460598](https://github.com/user-attachments/assets/7587700c-e09d-4cf6-8590-3df129c2568e) |


## ğŸ“š ì¸ìš©

ì´ ì—°êµ¬ë¥¼ ì‚¬ìš©í•˜ì‹ ë‹¤ë©´, ì•„ë˜ì™€ ê°™ì´ ì¸ìš©í•´ ì£¼ì„¸ìš”:


```bibtex
@article{espinosa2025notimetotrain,
  title={No time to train! Training-Free Reference-Based Instance Segmentation},
  author={Miguel Espinosa and Chenhongyi Yang and Linus Ericsson and Steven McDonagh and Elliot J. Crowley},
  journal={arXiv preprint arXiv:2507.02798},
  year={2025},
  primaryclass={cs.CV}
}
```


---

Tranlated By [Open Ai Tx](https://github.com/OpenAiTx/OpenAiTx) | Last indexed: 2025-09-06

---