
<div align="right">
  <details>
    <summary >ğŸŒ NgÃ´n ngá»¯</summary>
    <div>
      <div align="center">
        <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=en">English</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=zh-CN">ç®€ä½“ä¸­æ–‡</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=zh-TW">ç¹é«”ä¸­æ–‡</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=ja">æ—¥æœ¬èª</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=ko">í•œêµ­ì–´</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=hi">à¤¹à¤¿à¤¨à¥à¤¦à¥€</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=th">à¹„à¸—à¸¢</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=fr">FranÃ§ais</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=de">Deutsch</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=es">EspaÃ±ol</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=it">Italiano</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=ru">Ğ ÑƒÑÑĞºĞ¸Ğ¹</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=pt">PortuguÃªs</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=nl">Nederlands</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=pl">Polski</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=ar">Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=fa">ÙØ§Ø±Ø³ÛŒ</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=tr">TÃ¼rkÃ§e</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=vi">Tiáº¿ng Viá»‡t</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=id">Bahasa Indonesia</a>
      </div>
    </div>
  </details>
</div>

<div align="center">

# ğŸš€ KhÃ´ng Thá»i Gian Äá»ƒ Huáº¥n Luyá»‡n!  
### PhÃ¢n Äoáº¡n Tham Chiáº¿u Theo Äá»‘i TÆ°á»£ng KhÃ´ng Cáº§n Huáº¥n Luyá»‡n  
[![GitHub](https://img.shields.io/badge/%E2%80%8B-KhÃ´ng%20Thá»i%20Gian%20Äá»ƒ%20Huáº¥n%20Luyá»‡n-black?logo=github)](https://github.com/miquel-espinosa/no-time-to-train)
[![Website](https://img.shields.io/badge/ğŸŒ-Trang%20Dá»±%20Ãn-grey)](https://miquel-espinosa.github.io/no-time-to-train/)
[![arXiv](https://img.shields.io/badge/arXiv-2507.02798-b31b1b)](https://arxiv.org/abs/2507.02798)

**Tráº¡ng thÃ¡i tiÃªn tiáº¿n nháº¥t (Papers with Code)**
[**_SOTA 1-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-1-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/badge/State%20of%20the%20Art-Few--Shot%20Object%20Detection%20on%20MS--COCO%20(1--shot)-21CBCE?style=flat&logo=paperswithcode)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-1-shot?p=no-time-to-train-training-free-reference)

[**_SOTA 10-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-10-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/badge/State%20of%20the%20Art-Few--Shot%20Object%20Detection%20on%20MS--COCO%20(10--shot)-21CBCE?style=flat&logo=paperswithcode)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-10-shot?p=no-time-to-train-training-free-reference)

[**_SOTA 30-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-30-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/badge/State%20of%20the%20Art-Few--Shot%20Object%20Detection%20on%20MS--COCO%20(30--shot)-21CBCE?style=flat&logo=paperswithcode)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-30-shot?p=no-time-to-train-training-free-reference)

<!-- [**_SOTA 1-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-1-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/no-time-to-train-training-free-reference/few-shot-object-detection-on-ms-coco-1-shot)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-1-shot?p=no-time-to-train-training-free-reference)

[**_SOTA 10-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-10-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/no-time-to-train-training-free-reference/few-shot-object-detection-on-ms-coco-10-shot)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-10-shot?p=no-time-to-train-training-free-reference)

[**_SOTA 30-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-30-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/no-time-to-train-training-free-reference/few-shot-object-detection-on-ms-coco-30-shot)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-30-shot?p=no-time-to-train-training-free-reference) -->

</div>

---

> ğŸš¨ **Cáº­p nháº­t (22 thÃ¡ng 7 nÄƒm 2025):** ÄÃ£ thÃªm hÆ°á»›ng dáº«n cho bá»™ dá»¯ liá»‡u tÃ¹y chá»‰nh!
> 
> ğŸ”” **Cáº­p nháº­t (16 thÃ¡ng 7 nÄƒm 2025):** MÃ£ nguá»“n Ä‘Ã£ Ä‘Æ°á»£c cáº­p nháº­t kÃ¨m hÆ°á»›ng dáº«n!

---

## ğŸ“‹ Má»¥c lá»¥c

- [ğŸ¯ Äiá»ƒm ná»•i báº­t](#-highlights)
- [ğŸ“œ TÃ³m táº¯t](#-abstract)
- [ğŸ§  Kiáº¿n trÃºc](#-architecture)
- [ğŸ› ï¸ HÆ°á»›ng dáº«n cÃ i Ä‘áº·t](#ï¸-installation-instructions)
  - [1. Sao chÃ©p kho lÆ°u trá»¯](#1-clone-the-repository)
  - [2. Táº¡o mÃ´i trÆ°á»ng conda](#2-create-conda-environment)
  - [3. CÃ i Ä‘áº·t SAM2 vÃ  DinoV2](#3-install-sam2-and-dinov2)
  - [4. Táº£i bá»™ dá»¯ liá»‡u](#4-download-datasets)
  - [5. Táº£i cÃ¡c checkpoint SAM2 vÃ  DinoV2](#5-download-sam2-and-dinov2-checkpoints)
- [ğŸ“Š MÃ£ suy luáº­n: TÃ¡i táº¡o káº¿t quáº£ SOTA 30-shot trÃªn Few-shot COCO](#-inference-code)
  - [0. Táº¡o bá»™ tham chiáº¿u](#0-create-reference-set)
  - [1. Náº¡p bá»™ nhá»› vá»›i cÃ¡c tham chiáº¿u](#1-fill-memory-with-references)
  - [2. Xá»­ lÃ½ háº­u ká»³ bá»™ nhá»›](#2-post-process-memory-bank)
  - [3. Suy luáº­n trÃªn áº£nh má»¥c tiÃªu](#3-inference-on-target-images)
  - [Káº¿t quáº£](#results)

- [ğŸ” Bá»™ dá»¯ liá»‡u tÃ¹y chá»‰nh](#-custom-dataset)
  - [0. Chuáº©n bá»‹ bá»™ dá»¯ liá»‡u tÃ¹y chá»‰nh â›µğŸ¦](#0-prepare-a-custom-dataset)
  - [0.1 Náº¿u chá»‰ cÃ³ chÃº thÃ­ch bbox](#01-if-only-bbox-annotations-are-available)
  - [0.2 Chuyá»ƒn Ä‘á»•i chÃº thÃ­ch coco sang file pickle](#02-convert-coco-annotations-to-pickle-file)
  - [1. Náº¡p bá»™ nhá»› vá»›i cÃ¡c tham chiáº¿u](#1-fill-memory-with-references)
  - [2. Xá»­ lÃ½ háº­u ká»³ ngÃ¢n hÃ ng bá»™ nhá»›](#2-post-process-memory-bank)
- [ğŸ“š TrÃ­ch dáº«n](#-citation)


## ğŸ¯ Äiá»ƒm ná»•i báº­t
- ğŸ’¡ **KhÃ´ng cáº§n huáº¥n luyá»‡n**: KhÃ´ng tinh chá»‰nh, khÃ´ng thiáº¿t káº¿ promptâ€”chá»‰ cáº§n má»™t áº£nh tham chiáº¿u.  
- ğŸ–¼ï¸ **Dá»±a trÃªn tham chiáº¿u**: PhÃ¢n Ä‘oáº¡n Ä‘á»‘i tÆ°á»£ng má»›i chá»‰ vá»›i má»™t vÃ i vÃ­ dá»¥.  
- ğŸ”¥ **Hiá»‡u nÄƒng SOTA**: VÆ°á»£t trá»™i cÃ¡c phÆ°Æ¡ng phÃ¡p khÃ´ng huáº¥n luyá»‡n trÆ°á»›c Ä‘Ã³ trÃªn COCO, PASCAL VOC, vÃ  Cross-Domain FSOD.

**LiÃªn káº¿t:**
- ğŸ§¾ [**BÃ i bÃ¡o arXiv**](https://arxiv.org/abs/2507.02798)  
- ğŸŒ [**Website dá»± Ã¡n**](https://miquel-espinosa.github.io/no-time-to-train/)  
- ğŸ“ˆ [**Papers with Code**](https://paperswithcode.com/paper/no-time-to-train-training-free-reference)

## ğŸ“œ TÃ³m táº¯t

> The performance of image segmentation models has historically been constrained by the high cost of collecting large-scale annotated data. The Segment Anything Model (SAM) alleviates this original problem through a promptable, semantics-agnostic, segmentation paradigm and yet still requires manual visual-prompts or complex domain-dependent prompt-generation rules to process a new image. Towards reducing this new burden, our work investigates the task of object segmentation when provided with, alternatively, only a small set of reference images. Our key insight is to leverage strong semantic priors, as learned by foundation models, to identify corresponding regions between a reference and a target image. We find that correspondences enable automatic generation of instance-level segmentation masks for downstream tasks and instantiate our ideas via a multi-stage, training-free method incorporating (1) memory bank construction; (2) representation aggregation and (3) semantic-aware feature matching. Our experiments show significant improvements on segmentation metrics, leading to state-of-the-art performance on COCO FSOD (36.8% nAP), PASCAL VOC Few-Shot (71.2% nAP50) and outperforming existing training-free approaches on the Cross-Domain FSOD benchmark (22.4% nAP).

![cdfsod-results-final-comic-sans-min](https://github.com/user-attachments/assets/ab302c02-c080-4042-99fc-0e181ba8abb9)


## ğŸ§  Architecture

![training-free-architecture-comic-sans-min](https://github.com/user-attachments/assets/d84dd83a-505e-45a0-8ce3-98e1838017f9)


## ğŸ› ï¸ Installation instructions

### 1. Clone the repository

```bash
git clone https://github.com/miquel-espinosa/no-time-to-train.git
cd no-time-to-train
```
### 2. Táº¡o mÃ´i trÆ°á»ng conda

ChÃºng ta sáº½ táº¡o má»™t mÃ´i trÆ°á»ng conda vá»›i cÃ¡c gÃ³i cáº§n thiáº¿t.

```bash
conda env create -f environment.yml
conda activate no-time-to-train
```
### 3. CÃ i Ä‘áº·t SAM2 vÃ  DinoV2

ChÃºng ta sáº½ cÃ i Ä‘áº·t SAM2 vÃ  DinoV2 tá»« mÃ£ nguá»“n.

```bash
pip install -e .
cd dinov2
pip install -e .
cd ..
```
### 4. Táº£i xuá»‘ng cÃ¡c bá»™ dá»¯ liá»‡u

Vui lÃ²ng táº£i xuá»‘ng bá»™ dá»¯ liá»‡u COCO vÃ  Ä‘áº·t nÃ³ vÃ o `data/coco`

### 5. Táº£i xuá»‘ng cÃ¡c checkpoint SAM2 vÃ  DinoV2

ChÃºng ta sáº½ táº£i xuá»‘ng cÃ¡c checkpoint SAM2 chÃ­nh xÃ¡c Ä‘Ã£ Ä‘Æ°á»£c sá»­ dá»¥ng trong bÃ i bÃ¡o.
(Tuy nhiÃªn, lÆ°u Ã½ ráº±ng cÃ¡c checkpoint SAM2.1 Ä‘Ã£ cÃ³ sáºµn vÃ  cÃ³ thá»ƒ hoáº¡t Ä‘á»™ng tá»‘t hÆ¡n.)


```bash
mkdir -p checkpoints/dinov2
cd checkpoints
wget https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_large.pt
cd dinov2
wget https://dl.fbaipublicfiles.com/dinov2/dinov2_vitl14/dinov2_vitl14_pretrain.pth
cd ../..
```
## ğŸ“Š MÃ£ suy luáº­n

âš ï¸ LÆ°u Ã½: ÄÃ¢y lÃ  mÃ£ nghiÃªn cá»©u â€” cÃ³ thá»ƒ sáº½ hÆ¡i lá»™n xá»™n!

### TÃ¡i táº¡o káº¿t quáº£ SOTA 30-shot trong Few-shot COCO

Äá»‹nh nghÄ©a cÃ¡c biáº¿n há»¯u Ã­ch vÃ  táº¡o má»™t thÆ° má»¥c cho káº¿t quáº£:



```bash
CONFIG=./no_time_to_train/new_exps/coco_fewshot_10shot_Sam2L.yaml
CLASS_SPLIT="few_shot_classes"
RESULTS_DIR=work_dirs/few_shot_results
SHOTS=30
SEED=33
GPUS=4

mkdir -p $RESULTS_DIR
FILENAME=few_shot_${SHOTS}shot_seed${SEED}.pkl
```
#### 0. Táº¡o bá»™ tham chiáº¿u


```bash
python no_time_to_train/dataset/few_shot_sampling.py \
        --n-shot $SHOTS \
        --out-path ${RESULTS_DIR}/${FILENAME} \
        --seed $SEED \
        --dataset $CLASS_SPLIT
```
#### 1. Láº¥p Ä‘áº§y bá»™ nhá»› báº±ng cÃ¡c tham chiáº¿u


```bash
python run_lightening.py test --config $CONFIG \
                              --model.test_mode fill_memory \
                              --out_path ${RESULTS_DIR}/memory.ckpt \
                              --model.init_args.model_cfg.memory_bank_cfg.length $SHOTS \
                              --model.init_args.dataset_cfgs.fill_memory.memory_pkl ${RESULTS_DIR}/${FILENAME} \
                              --model.init_args.dataset_cfgs.fill_memory.memory_length $SHOTS \
                              --model.init_args.dataset_cfgs.fill_memory.class_split $CLASS_SPLIT \
                              --trainer.logger.save_dir ${RESULTS_DIR}/ \
                              --trainer.devices $GPUS
```
#### 2. Xá»­ lÃ½ háº­u ká»³ bá»™ nhá»› ngÃ¢n hÃ ng


```bash
python run_lightening.py test --config $CONFIG \
                              --model.test_mode postprocess_memory \
                              --model.init_args.model_cfg.memory_bank_cfg.length $SHOTS \
                              --ckpt_path ${RESULTS_DIR}/memory.ckpt \
                              --out_path ${RESULTS_DIR}/memory_postprocessed.ckpt \
                              --trainer.devices 1
```
#### 3. Suy luáº­n trÃªn cÃ¡c hÃ¬nh áº£nh má»¥c tiÃªu


```bash
python run_lightening.py test --config $CONFIG  \
                              --ckpt_path ${RESULTS_DIR}/memory_postprocessed.ckpt \
                              --model.init_args.test_mode test \
                              --model.init_args.model_cfg.memory_bank_cfg.length $SHOTS \
                              --model.init_args.model_cfg.dataset_name $CLASS_SPLIT \
                              --model.init_args.dataset_cfgs.test.class_split $CLASS_SPLIT \
                              --trainer.logger.save_dir ${RESULTS_DIR}/ \
                              --trainer.devices $GPUS
```
Náº¿u báº¡n muá»‘n xem káº¿t quáº£ suy luáº­n trá»±c tuyáº¿n (ngay khi chÃºng Ä‘Æ°á»£c tÃ­nh toÃ¡n), hÃ£y thÃªm Ä‘á»‘i sá»‘:

```bash
    --model.init_args.model_cfg.test.online_vis True
```
Äá»ƒ Ä‘iá»u chá»‰nh tham sá»‘ ngÆ°á»¡ng Ä‘iá»ƒm sá»‘ `score_thr`, hÃ£y thÃªm Ä‘á»‘i sá»‘ (vÃ­ dá»¥, trá»±c quan hÃ³a táº¥t cáº£ cÃ¡c trÆ°á»ng há»£p cÃ³ Ä‘iá»ƒm sá»‘ cao hÆ¡n `0.4`):
```bash
    --model.init_args.model_cfg.test.vis_thr 0.4
```
CÃ¡c hÃ¬nh áº£nh bÃ¢y giá» sáº½ Ä‘Æ°á»£c lÆ°u trong `results_analysis/few_shot_classes/`. HÃ¬nh áº£nh bÃªn trÃ¡i hiá»ƒn thá»‹ dá»¯ liá»‡u thá»±c táº¿, hÃ¬nh áº£nh bÃªn pháº£i hiá»ƒn thá»‹ cÃ¡c vÃ¹ng phÃ¢n Ä‘oáº¡n do phÆ°Æ¡ng phÃ¡p khÃ´ng cáº§n huáº¥n luyá»‡n cá»§a chÃºng tÃ´i tÃ¬m Ä‘Æ°á»£c.

LÆ°u Ã½ ráº±ng trong vÃ­ dá»¥ nÃ y chÃºng tÃ´i Ä‘ang sá»­ dá»¥ng bá»™ chia `few_shot_classes`, do Ä‘Ã³, chÃºng ta chá»‰ nÃªn mong Ä‘á»£i tháº¥y cÃ¡c vÃ¹ng phÃ¢n Ä‘oáº¡n cá»§a cÃ¡c lá»›p trong bá»™ chia nÃ y (khÃ´ng pháº£i táº¥t cáº£ cÃ¡c lá»›p trong COCO).

#### Káº¿t quáº£

Sau khi cháº¡y táº¥t cáº£ cÃ¡c hÃ¬nh áº£nh trong táº­p kiá»ƒm Ä‘á»‹nh, báº¡n sáº½ thu Ä‘Æ°á»£c:

```
BBOX RESULTS:
  Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.368

SEGM RESULTS:
  Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.342
```
---

## ğŸ” Bá»™ dá»¯ liá»‡u tÃ¹y chá»‰nh

ChÃºng tÃ´i cung cáº¥p hÆ°á»›ng dáº«n Ä‘á»ƒ cháº¡y pipeline cá»§a mÃ¬nh trÃªn má»™t bá»™ dá»¯ liá»‡u tÃ¹y chá»‰nh. Äá»‹nh dáº¡ng chÃº thÃ­ch luÃ´n á»Ÿ Ä‘á»‹nh dáº¡ng COCO.

> **TLDR;** Äá»ƒ xem trá»±c tiáº¿p cÃ¡ch cháº¡y toÃ n bá»™ pipeline trÃªn *bá»™ dá»¯ liá»‡u tÃ¹y chá»‰nh*, hÃ£y xem `scripts/matching_cdfsod_pipeline.sh` cÃ¹ng vá»›i cÃ¡c script vÃ­ dá»¥ cá»§a bá»™ dá»¯ liá»‡u CD-FSOD (vÃ­ dá»¥: `scripts/dior_fish.sh`)

### 0. Chuáº©n bá»‹ bá»™ dá»¯ liá»‡u tÃ¹y chá»‰nh â›µğŸ¦

HÃ£y tÆ°á»Ÿng tÆ°á»£ng chÃºng ta muá»‘n phÃ¡t hiá»‡n **thuyá»n**â›µ vÃ  **chim**ğŸ¦ trong má»™t bá»™ dá»¯ liá»‡u tÃ¹y chá»‰nh. Äá»ƒ sá»­ dá»¥ng phÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i, báº¡n sáº½ cáº§n:
- Ãt nháº¥t 1 áº£nh tham chiáº¿u *Ä‘Æ°á»£c chÃº thÃ­ch* cho má»—i lá»›p (vÃ­ dá»¥: 1 áº£nh tham chiáº¿u cho thuyá»n vÃ  1 áº£nh tham chiáº¿u cho chim)
- Nhiá»u áº£nh má»¥c tiÃªu Ä‘á»ƒ tÃ¬m cÃ¡c Ä‘á»‘i tÆ°á»£ng cá»§a lá»›p mong muá»‘n.

ChÃºng tÃ´i Ä‘Ã£ chuáº©n bá»‹ má»™t script vÃ­ dá»¥ Ä‘á»ƒ táº¡o bá»™ dá»¯ liá»‡u tÃ¹y chá»‰nh vá»›i áº£nh coco, cho trÆ°á»ng há»£p **1-shot**.
```bash
mkdir -p data/my_custom_dataset
python scripts/make_custom_dataset.py
```
Äiá»u nÃ y sáº½ táº¡o ra má»™t bá»™ dá»¯ liá»‡u tÃ¹y chá»‰nh vá»›i cáº¥u trÃºc thÆ° má»¥c nhÆ° sau:
```
data/my_custom_dataset/
    â”œâ”€â”€ annotations/
    â”‚   â”œâ”€â”€ custom_references.json
    â”‚   â”œâ”€â”€ custom_targets.json
    â”‚   â””â”€â”€ references_visualisations/
    â”‚       â”œâ”€â”€ bird_1.jpg
    â”‚       â””â”€â”€ boat_1.jpg
    â””â”€â”€ images/
        â”œâ”€â”€ 429819.jpg
        â”œâ”€â”€ 101435.jpg
        â””â”€â”€ (all target and reference images)
```
**Trá»±c quan hÃ³a hÃ¬nh áº£nh tham chiáº¿u (1-shot):**

| HÃ¬nh áº£nh tham chiáº¿u 1-shot cho CHIM ğŸ¦ | HÃ¬nh áº£nh tham chiáº¿u 1-shot cho THUYá»€N â›µ |
|:--------------------------------------:|:---------------------------------------:|
| <img src="https://github.com/user-attachments/assets/e59e580d-a7db-42ac-b386-892af211fc85" alt="bird_1" width="500"/> | <img src="https://github.com/user-attachments/assets/f94ee025-ae37-4a45-9c3e-0cfe8f8cd2bc" alt="boat_1" width="500"/> |


### 0.1 Náº¿u chá»‰ cÃ³ chÃº thÃ­ch bbox

ChÃºng tÃ´i cÅ©ng cung cáº¥p má»™t script Ä‘á»ƒ táº¡o máº·t náº¡ phÃ¢n Ä‘oáº¡n cáº¥p Ä‘á»‘i tÆ°á»£ng báº±ng cÃ¡ch sá»­ dá»¥ng SAM2. Äiá»u nÃ y há»¯u Ã­ch náº¿u báº¡n chá»‰ cÃ³ cÃ¡c chÃº thÃ­ch bounding box cho hÃ¬nh áº£nh tham chiáº¿u.


```bash
# Download sam_h checkpoint. Feel free to use more recent checkpoints (note: code might need to be adapted)
wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth -O checkpoints/sam_vit_h_4b8939.pth
# Run automatic instance segmentation from ground truth bounding boxes.
python no_time_to_train/dataset/sam_bbox_to_segm_batch.py \
    --input_json data/my_custom_dataset/annotations/custom_references.json \
    --image_dir data/my_custom_dataset/images \
    --sam_checkpoint checkpoints/sam_vit_h_4b8939.pth \
    --model_type vit_h \
    --device cuda \
    --batch_size 8 \
    --visualize
```
**HÃ¬nh áº£nh tham chiáº¿u vá»›i máº·t náº¡ phÃ¢n Ä‘oáº¡n cáº¥p Ä‘á»™ Ä‘á»‘i tÆ°á»£ng (Ä‘Æ°á»£c táº¡o bá»Ÿi SAM2 tá»« cÃ¡c há»™p chá»©a gt, 1-shot):**

HÃ¬nh áº£nh trá»±c quan hÃ³a cá»§a cÃ¡c máº·t náº¡ phÃ¢n Ä‘oáº¡n Ä‘Ã£ Ä‘Æ°á»£c lÆ°u táº¡i `data/my_custom_dataset/annotations/custom_references_with_SAM_segm/references_visualisations/`.


| HÃ¬nh áº£nh tham chiáº¿u 1-shot cho CHIM ğŸ¦ (tá»± Ä‘á»™ng phÃ¢n Ä‘oáº¡n báº±ng SAM) | HÃ¬nh áº£nh tham chiáº¿u 1-shot cho THUYá»€N â›µ (tá»± Ä‘á»™ng phÃ¢n Ä‘oáº¡n báº±ng SAM) |
|:---------------------------------:|:----------------------------------:|
| <img src="https://github.com/user-attachments/assets/65d38dc4-1454-43cd-9600-e8efc67b3a82" alt="bird_1_with_SAM_segm" width="500"/> | <img src="https://github.com/user-attachments/assets/43a558ad-50ca-4715-8285-9aa3268843c6" alt="boat_1_with_SAM_segm" width="500"/> |


### 0.2 Chuyá»ƒn Ä‘á»•i chÃº thÃ­ch coco sang táº­p tin pickle


```bash
python no_time_to_train/dataset/coco_to_pkl.py \
    data/my_custom_dataset/annotations/custom_references_with_segm.json \
    data/my_custom_dataset/annotations/custom_references_with_segm.pkl \
    1
```
### 1. Äá»• Ä‘áº§y bá»™ nhá»› vá»›i cÃ¡c tham chiáº¿u

Äáº§u tiÃªn, Ä‘á»‹nh nghÄ©a cÃ¡c biáº¿n há»¯u Ã­ch vÃ  táº¡o má»™t thÆ° má»¥c Ä‘á»ƒ lÆ°u káº¿t quáº£. Äá»ƒ hiá»ƒn thá»‹ nhÃ£n Ä‘Ãºng cÃ¡ch, tÃªn cÃ¡c lá»›p pháº£i Ä‘Æ°á»£c sáº¯p xáº¿p theo id danh má»¥c nhÆ° trong tá»‡p json. VÃ­ dá»¥, `bird` cÃ³ id danh má»¥c lÃ  `16`, `boat` cÃ³ id danh má»¥c lÃ  `9`. Do Ä‘Ã³, `CAT_NAMES=boat,bird`.


```bash
DATASET_NAME=my_custom_dataset
DATASET_PATH=data/my_custom_dataset
CAT_NAMES=boat,bird
CATEGORY_NUM=2
SHOT=1
YAML_PATH=no_time_to_train/pl_configs/matching_cdfsod_template.yaml
PATH_TO_SAVE_CKPTS=./tmp_ckpts/my_custom_dataset
mkdir -p $PATH_TO_SAVE_CKPTS
```
Cháº¡y bÆ°á»›c 1:

```bash
python run_lightening.py test --config $YAML_PATH \
    --model.test_mode fill_memory \
    --out_path $PATH_TO_SAVE_CKPTS/$DATASET_NAME\_$SHOT\_refs_memory.pth \
    --model.init_args.dataset_cfgs.fill_memory.root $DATASET_PATH/images \
    --model.init_args.dataset_cfgs.fill_memory.json_file $DATASET_PATH/annotations/custom_references_with_segm.json \
    --model.init_args.dataset_cfgs.fill_memory.memory_pkl $DATASET_PATH/annotations/custom_references_with_segm.pkl \
    --model.init_args.dataset_cfgs.fill_memory.memory_length $SHOT \
    --model.init_args.dataset_cfgs.fill_memory.cat_names $CAT_NAMES \
    --model.init_args.model_cfg.dataset_name $DATASET_NAME \
    --model.init_args.model_cfg.memory_bank_cfg.length $SHOT \
    --model.init_args.model_cfg.memory_bank_cfg.category_num $CATEGORY_NUM \
    --trainer.devices 1
```
### 2. Xá»­ lÃ½ háº­u ká»³ bá»™ nhá»› ngÃ¢n hÃ ng


```bash
python run_lightening.py test --config $YAML_PATH \
    --model.test_mode postprocess_memory \
    --ckpt_path $PATH_TO_SAVE_CKPTS/$DATASET_NAME\_$SHOT\_refs_memory.pth \
    --out_path $PATH_TO_SAVE_CKPTS/$DATASET_NAME\_$SHOT\_refs_memory_postprocessed.pth \
    --model.init_args.model_cfg.dataset_name $DATASET_NAME \
    --model.init_args.model_cfg.memory_bank_cfg.length $SHOT \
    --model.init_args.model_cfg.memory_bank_cfg.category_num $CATEGORY_NUM \
    --trainer.devices 1
```
### 3. Suy luáº­n trÃªn cÃ¡c áº£nh má»¥c tiÃªu

Náº¿u `ONLINE_VIS` Ä‘Æ°á»£c Ä‘áº·t thÃ nh True, káº¿t quáº£ dá»± Ä‘oÃ¡n sáº½ Ä‘Æ°á»£c lÆ°u trong `results_analysis/my_custom_dataset/` vÃ  hiá»ƒn thá»‹ ngay khi Ä‘Æ°á»£c tÃ­nh toÃ¡n. LÆ¯U Ã ráº±ng cháº¡y vá»›i cháº¿ Ä‘á»™ trá»±c quan hÃ³a trá»±c tuyáº¿n sáº½ cháº­m hÆ¡n nhiá»u.

Báº¡n cÃ³ thá»ƒ thay Ä‘á»•i ngÆ°á»¡ng Ä‘iá»ƒm sá»‘ `VIS_THR` Ä‘á»ƒ xem nhiá»u hoáº·c Ã­t Ä‘á»‘i tÆ°á»£ng Ä‘Æ°á»£c phÃ¢n Ä‘oáº¡n hÆ¡n.

```bash
ONLINE_VIS=True
VIS_THR=0.4
python run_lightening.py test --config $YAML_PATH \
    --model.test_mode test \
    --ckpt_path $PATH_TO_SAVE_CKPTS/$DATASET_NAME\_$SHOT\_refs_memory_postprocessed.pth \
    --model.init_args.model_cfg.dataset_name $DATASET_NAME \
    --model.init_args.model_cfg.memory_bank_cfg.length $SHOT \
    --model.init_args.model_cfg.memory_bank_cfg.category_num $CATEGORY_NUM \
    --model.init_args.model_cfg.test.imgs_path $DATASET_PATH/images \
    --model.init_args.model_cfg.test.online_vis $ONLINE_VIS \
    --model.init_args.model_cfg.test.vis_thr $VIS_THR \
    --model.init_args.dataset_cfgs.test.root $DATASET_PATH/images \
    --model.init_args.dataset_cfgs.test.json_file $DATASET_PATH/annotations/custom_targets.json \
    --model.init_args.dataset_cfgs.test.cat_names $CAT_NAMES \
    --trainer.devices 1
```
### Káº¿t quáº£

CÃ¡c chá»‰ sá»‘ hiá»‡u suáº¥t (vá»›i Ä‘Ãºng cÃ¡c tham sá»‘ nhÆ° cÃ¡c lá»‡nh trÃªn) nÃªn lÃ :


```
BBOX RESULTS:
  Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.478

SEGM RESULTS:
  Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.458
```
Káº¿t quáº£ trá»±c quan Ä‘Æ°á»£c lÆ°u trong `results_analysis/my_custom_dataset/`. LÆ°u Ã½ ráº±ng phÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i hoáº¡t Ä‘á»™ng vá»›i cÃ¡c trÆ°á»ng há»£p Ã¢m tÃ­nh giáº£, tá»©c lÃ  cÃ¡c hÃ¬nh áº£nh khÃ´ng chá»©a báº¥t ká»³ Ä‘á»‘i tÆ°á»£ng nÃ o thuá»™c cÃ¡c lá»›p mong muá»‘n.

*Báº¥m vÃ o hÃ¬nh Ä‘á»ƒ phÃ³ng to â¬‡ï¸*

| áº¢nh má»¥c tiÃªu vá»›i thuyá»n â›µ (trÃ¡i GT, pháº£i dá»± Ä‘oÃ¡n) | áº¢nh má»¥c tiÃªu vá»›i chim ğŸ¦ (trÃ¡i GT, pháº£i dá»± Ä‘oÃ¡n) |
|:----------------------:|:----------------------:|
| ![000000459673](https://github.com/user-attachments/assets/678dc15a-dd3b-49d5-9287-6290da16aa6b) | ![000000407180](https://github.com/user-attachments/assets/fe306e48-af49-4d83-ac82-76fac6c456d1) |

| áº¢nh má»¥c tiÃªu vá»›i thuyá»n vÃ  chim â›µğŸ¦ (trÃ¡i GT, pháº£i dá»± Ä‘oÃ¡n) | áº¢nh má»¥c tiÃªu khÃ´ng cÃ³ thuyá»n hoáº·c chim ğŸš« (trÃ¡i GT, pháº£i dá»± Ä‘oÃ¡n) |
|:---------------------------------:|:----------------------------------:|
| ![000000517410](https://github.com/user-attachments/assets/9849b227-7f43-43d7-81ea-58010a623ad5) | ![000000460598](https://github.com/user-attachments/assets/7587700c-e09d-4cf6-8590-3df129c2568e) |


## ğŸ“š TrÃ­ch dáº«n

Náº¿u báº¡n sá»­ dá»¥ng cÃ´ng trÃ¬nh nÃ y, vui lÃ²ng trÃ­ch dáº«n chÃºng tÃ´i:


```bibtex
@article{espinosa2025notimetotrain,
  title={No time to train! Training-Free Reference-Based Instance Segmentation},
  author={Miguel Espinosa and Chenhongyi Yang and Linus Ericsson and Steven McDonagh and Elliot J. Crowley},
  journal={arXiv preprint arXiv:2507.02798},
  year={2025},
  primaryclass={cs.CV}
}
```


---

Tranlated By [Open Ai Tx](https://github.com/OpenAiTx/OpenAiTx) | Last indexed: 2025-09-06

---