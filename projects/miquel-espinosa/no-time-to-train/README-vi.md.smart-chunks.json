[
  {
    "Id": 1,
    "Content": "\n<div align=\"right\">\n  <details>\n    <summary >üåê Language</summary>\n    <div>\n      <div align=\"center\">\n        <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=en\">English</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=zh-CN\">ÁÆÄ‰Ωì‰∏≠Êñá</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=zh-TW\">ÁπÅÈ´î‰∏≠Êñá</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=ja\">Êó•Êú¨Ë™û</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=ko\">ÌïúÍµ≠Ïñ¥</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=hi\">‡§π‡§ø‡§®‡•ç‡§¶‡•Ä</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=th\">‡πÑ‡∏ó‡∏¢</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=fr\">Fran√ßais</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=de\">Deutsch</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=es\">Espa√±ol</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=it\">Italiano</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=ru\">–†—É—Å—Å–∫–∏–π</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=pt\">Portugu√™s</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=nl\">Nederlands</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=pl\">Polski</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=ar\">ÿßŸÑÿπÿ±ÿ®Ÿäÿ©</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=fa\">ŸÅÿßÿ±ÿ≥€å</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=tr\">T√ºrk√ße</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=vi\">Ti·∫øng Vi·ªát</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=id\">Bahasa Indonesia</a>\n      </div>\n    </div>\n  </details>\n</div>\n\n<div align=\"center\">\n\n# üöÄ No Time to Train!  \n### Training-Free Reference-Based Instance Segmentation  \n[![GitHub](https://img.shields.io/badge/%E2%80%8B-No%20Time%20To%20Train-black?logo=github)](https://github.com/miquel-espinosa/no-time-to-train)\n[![Website](https://img.shields.io/badge/üåê-Project%20Page-grey)](https://miquel-espinosa.github.io/no-time-to-train/)\n[![arXiv](https://img.shields.io/badge/arXiv-2507.02798-b31b1b)](https://arxiv.org/abs/2507.02798)\n\n**State-of-the-art (Papers with Code)**",
    "ContentSha": "lG1vuwmuqLt4d95/PBMz1H5HG0r+JfvC/FVnqNQvTnM=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "\n<div align=\"right\">\n  <details>\n    <summary >üåê Ng√¥n ng·ªØ</summary>\n    <div>\n      <div align=\"center\">\n        <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=en\">English</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=zh-CN\">ÁÆÄ‰Ωì‰∏≠Êñá</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=zh-TW\">ÁπÅÈ´î‰∏≠Êñá</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=ja\">Êó•Êú¨Ë™û</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=ko\">ÌïúÍµ≠Ïñ¥</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=hi\">‡§π‡§ø‡§®‡•ç‡§¶‡•Ä</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=th\">‡πÑ‡∏ó‡∏¢</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=fr\">Fran√ßais</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=de\">Deutsch</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=es\">Espa√±ol</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=it\">Italiano</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=ru\">–†—É—Å—Å–∫–∏–π</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=pt\">Portugu√™s</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=nl\">Nederlands</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=pl\">Polski</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=ar\">ÿßŸÑÿπÿ±ÿ®Ÿäÿ©</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=fa\">ŸÅÿßÿ±ÿ≥€å</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=tr\">T√ºrk√ße</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=vi\">Ti·∫øng Vi·ªát</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=id\">Bahasa Indonesia</a>\n      </div>\n    </div>\n  </details>\n</div>\n\n<div align=\"center\">\n\n# üöÄ Kh√¥ng Th·ªùi Gian ƒê·ªÉ Hu·∫•n Luy·ªán!  \n### Ph√¢n ƒêo·∫°n Tham Chi·∫øu Theo ƒê·ªëi T∆∞·ª£ng Kh√¥ng C·∫ßn Hu·∫•n Luy·ªán  \n[![GitHub](https://img.shields.io/badge/%E2%80%8B-Kh√¥ng%20Th·ªùi%20Gian%20ƒê·ªÉ%20Hu·∫•n%20Luy·ªán-black?logo=github)](https://github.com/miquel-espinosa/no-time-to-train)\n[![Website](https://img.shields.io/badge/üåê-Trang%20D·ª±%20√Ån-grey)](https://miquel-espinosa.github.io/no-time-to-train/)\n[![arXiv](https://img.shields.io/badge/arXiv-2507.02798-b31b1b)](https://arxiv.org/abs/2507.02798)\n\n**Tr·∫°ng th√°i ti√™n ti·∫øn nh·∫•t (Papers with Code)**",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 2,
    "Content": "\n[**_SOTA 1-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-1-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/badge/State%20of%20the%20Art-Few--Shot%20Object%20Detection%20on%20MS--COCO%20(1--shot)-21CBCE?style=flat&logo=paperswithcode)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-1-shot?p=no-time-to-train-training-free-reference)\n\n[**_SOTA 10-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-10-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/badge/State%20of%20the%20Art-Few--Shot%20Object%20Detection%20on%20MS--COCO%20(10--shot)-21CBCE?style=flat&logo=paperswithcode)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-10-shot?p=no-time-to-train-training-free-reference)\n\n[**_SOTA 30-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-30-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/badge/State%20of%20the%20Art-Few--Shot%20Object%20Detection%20on%20MS--COCO%20(30--shot)-21CBCE?style=flat&logo=paperswithcode)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-30-shot?p=no-time-to-train-training-free-reference)\n\n<!-- [**_SOTA 1-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-1-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/no-time-to-train-training-free-reference/few-shot-object-detection-on-ms-coco-1-shot)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-1-shot?p=no-time-to-train-training-free-reference)\n\n[**_SOTA 10-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-10-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/no-time-to-train-training-free-reference/few-shot-object-detection-on-ms-coco-10-shot)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-10-shot?p=no-time-to-train-training-free-reference)\n\n[**_SOTA 30-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-30-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/no-time-to-train-training-free-reference/few-shot-object-detection-on-ms-coco-30-shot)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-30-shot?p=no-time-to-train-training-free-reference) -->\n\n</div>\n\n---\n\n> üö® **Update (22nd July 2025):** Instructions for custom datasets have been added!\n> \n> üîî **Update (16th July 2025):** Code has been updated with instructions!\n\n---\n\n## üìã Table of Contents\n\n- [üéØ Highlights](#-highlights)\n- [üìú Abstract](#-abstract)\n- [üß† Architecture](#-architecture)\n- [üõ†Ô∏è Installation instructions](#Ô∏è-installation-instructions)\n  - [1. Clone the repository](#1-clone-the-repository)\n  - [2. Create conda environment](#2-create-conda-environment)\n  - [3. Install SAM2 and DinoV2](#3-install-sam2-and-dinov2)\n  - [4. Download datasets](#4-download-datasets)\n  - [5. Download SAM2 and DinoV2 checkpoints](#5-download-sam2-and-dinov2-checkpoints)\n- [üìä Inference code: Reproduce 30-shot SOTA results in Few-shot COCO](#-inference-code)\n  - [0. Create reference set](#0-create-reference-set)\n  - [1. Fill memory with references](#1-fill-memory-with-references)\n  - [2. Post-process memory bank](#2-post-process-memory-bank)\n  - [3. Inference on target images](#3-inference-on-target-images)\n  - [Results](#results)",
    "ContentSha": "+yQ5ol79RNsk2le3no6dLpgaMzuy0Nh4xdRCmVNp8FE=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "[**_SOTA 1-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-1-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/badge/State%20of%20the%20Art-Few--Shot%20Object%20Detection%20on%20MS--COCO%20(1--shot)-21CBCE?style=flat&logo=paperswithcode)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-1-shot?p=no-time-to-train-training-free-reference)\n\n[**_SOTA 10-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-10-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/badge/State%20of%20the%20Art-Few--Shot%20Object%20Detection%20on%20MS--COCO%20(10--shot)-21CBCE?style=flat&logo=paperswithcode)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-10-shot?p=no-time-to-train-training-free-reference)\n\n[**_SOTA 30-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-30-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/badge/State%20of%20the%20Art-Few--Shot%20Object%20Detection%20on%20MS--COCO%20(30--shot)-21CBCE?style=flat&logo=paperswithcode)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-30-shot?p=no-time-to-train-training-free-reference)\n\n<!-- [**_SOTA 1-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-1-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/no-time-to-train-training-free-reference/few-shot-object-detection-on-ms-coco-1-shot)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-1-shot?p=no-time-to-train-training-free-reference)\n\n[**_SOTA 10-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-10-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/no-time-to-train-training-free-reference/few-shot-object-detection-on-ms-coco-10-shot)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-10-shot?p=no-time-to-train-training-free-reference)\n\n[**_SOTA 30-shot_**](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-30-shot?p=no-time-to-train-training-free-reference) | [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/no-time-to-train-training-free-reference/few-shot-object-detection-on-ms-coco-30-shot)](https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-30-shot?p=no-time-to-train-training-free-reference) -->\n\n</div>\n\n---\n\n> üö® **C·∫≠p nh·∫≠t (22 th√°ng 7 nƒÉm 2025):** ƒê√£ th√™m h∆∞·ªõng d·∫´n cho b·ªô d·ªØ li·ªáu t√πy ch·ªânh!\n> \n> üîî **C·∫≠p nh·∫≠t (16 th√°ng 7 nƒÉm 2025):** M√£ ngu·ªìn ƒë√£ ƒë∆∞·ª£c c·∫≠p nh·∫≠t k√®m h∆∞·ªõng d·∫´n!\n\n---\n\n## üìã M·ª•c l·ª•c\n\n- [üéØ ƒêi·ªÉm n·ªïi b·∫≠t](#-highlights)\n- [üìú T√≥m t·∫Øt](#-abstract)\n- [üß† Ki·∫øn tr√∫c](#-architecture)\n- [üõ†Ô∏è H∆∞·ªõng d·∫´n c√†i ƒë·∫∑t](#Ô∏è-installation-instructions)\n  - [1. Sao ch√©p kho l∆∞u tr·ªØ](#1-clone-the-repository)\n  - [2. T·∫°o m√¥i tr∆∞·ªùng conda](#2-create-conda-environment)\n  - [3. C√†i ƒë·∫∑t SAM2 v√† DinoV2](#3-install-sam2-and-dinov2)\n  - [4. T·∫£i b·ªô d·ªØ li·ªáu](#4-download-datasets)\n  - [5. T·∫£i c√°c checkpoint SAM2 v√† DinoV2](#5-download-sam2-and-dinov2-checkpoints)\n- [üìä M√£ suy lu·∫≠n: T√°i t·∫°o k·∫øt qu·∫£ SOTA 30-shot tr√™n Few-shot COCO](#-inference-code)\n  - [0. T·∫°o b·ªô tham chi·∫øu](#0-create-reference-set)\n  - [1. N·∫°p b·ªô nh·ªõ v·ªõi c√°c tham chi·∫øu](#1-fill-memory-with-references)\n  - [2. X·ª≠ l√Ω h·∫≠u k·ª≥ b·ªô nh·ªõ](#2-post-process-memory-bank)\n  - [3. Suy lu·∫≠n tr√™n ·∫£nh m·ª•c ti√™u](#3-inference-on-target-images)\n  - [K·∫øt qu·∫£](#results)\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 3,
    "Content": "- [üîç Custom dataset](#-custom-dataset)\n  - [0. Prepare a custom dataset ‚õµüê¶](#0-prepare-a-custom-dataset)\n  - [0.1 If only bbox annotations are available](#01-if-only-bbox-annotations-are-available)\n  - [0.2 Convert coco annotations to pickle file](#02-convert-coco-annotations-to-pickle-file)\n  - [1. Fill memory with references](#1-fill-memory-with-references)\n  - [2. Post-process memory bank](#2-post-process-memory-bank)\n- [üìö Citation](#-citation)\n\n\n## üéØ Highlights\n- üí° **Training-Free**: No fine-tuning, no prompt engineering‚Äîjust a reference image.  \n- üñºÔ∏è **Reference-Based**: Segment new objects using just a few examples.  \n- üî• **SOTA Performance**: Outperforms previous training-free approaches on COCO, PASCAL VOC, and Cross-Domain FSOD.\n\n**Links:**\n- üßæ [**arXiv Paper**](https://arxiv.org/abs/2507.02798)  \n- üåê [**Project Website**](https://miquel-espinosa.github.io/no-time-to-train/)  \n- üìà [**Papers with Code**](https://paperswithcode.com/paper/no-time-to-train-training-free-reference)\n\n## üìú Abstract\n",
    "ContentSha": "HKE5vt8IwUJiOubYYPHCrRXZ3fqCpGqVFP3Xj5VV+p4=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "- [üîç B·ªô d·ªØ li·ªáu t√πy ch·ªânh](#-custom-dataset)\n  - [0. Chu·∫©n b·ªã b·ªô d·ªØ li·ªáu t√πy ch·ªânh ‚õµüê¶](#0-prepare-a-custom-dataset)\n  - [0.1 N·∫øu ch·ªâ c√≥ ch√∫ th√≠ch bbox](#01-if-only-bbox-annotations-are-available)\n  - [0.2 Chuy·ªÉn ƒë·ªïi ch√∫ th√≠ch coco sang file pickle](#02-convert-coco-annotations-to-pickle-file)\n  - [1. N·∫°p b·ªô nh·ªõ v·ªõi c√°c tham chi·∫øu](#1-fill-memory-with-references)\n  - [2. X·ª≠ l√Ω h·∫≠u k·ª≥ ng√¢n h√†ng b·ªô nh·ªõ](#2-post-process-memory-bank)\n- [üìö Tr√≠ch d·∫´n](#-citation)\n\n\n## üéØ ƒêi·ªÉm n·ªïi b·∫≠t\n- üí° **Kh√¥ng c·∫ßn hu·∫•n luy·ªán**: Kh√¥ng tinh ch·ªânh, kh√¥ng thi·∫øt k·∫ø prompt‚Äîch·ªâ c·∫ßn m·ªôt ·∫£nh tham chi·∫øu.  \n- üñºÔ∏è **D·ª±a tr√™n tham chi·∫øu**: Ph√¢n ƒëo·∫°n ƒë·ªëi t∆∞·ª£ng m·ªõi ch·ªâ v·ªõi m·ªôt v√†i v√≠ d·ª•.  \n- üî• **Hi·ªáu nƒÉng SOTA**: V∆∞·ª£t tr·ªôi c√°c ph∆∞∆°ng ph√°p kh√¥ng hu·∫•n luy·ªán tr∆∞·ªõc ƒë√≥ tr√™n COCO, PASCAL VOC, v√† Cross-Domain FSOD.\n\n**Li√™n k·∫øt:**\n- üßæ [**B√†i b√°o arXiv**](https://arxiv.org/abs/2507.02798)  \n- üåê [**Website d·ª± √°n**](https://miquel-espinosa.github.io/no-time-to-train/)  \n- üìà [**Papers with Code**](https://paperswithcode.com/paper/no-time-to-train-training-free-reference)\n\n## üìú T√≥m t·∫Øt\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 4,
    "Content": "> The performance of image segmentation models has historically been constrained by the high cost of collecting large-scale annotated data. The Segment Anything Model (SAM) alleviates this original problem through a promptable, semantics-agnostic, segmentation paradigm and yet still requires manual visual-prompts or complex domain-dependent prompt-generation rules to process a new image. Towards reducing this new burden, our work investigates the task of object segmentation when provided with, alternatively, only a small set of reference images. Our key insight is to leverage strong semantic priors, as learned by foundation models, to identify corresponding regions between a reference and a target image. We find that correspondences enable automatic generation of instance-level segmentation masks for downstream tasks and instantiate our ideas via a multi-stage, training-free method incorporating (1) memory bank construction; (2) representation aggregation and (3) semantic-aware feature matching. Our experiments show significant improvements on segmentation metrics, leading to state-of-the-art performance on COCO FSOD (36.8% nAP), PASCAL VOC Few-Shot (71.2% nAP50) and outperforming existing training-free approaches on the Cross-Domain FSOD benchmark (22.4% nAP).",
    "ContentSha": "f62KYkH46xSV0RKRpAlERSF/nhSETk2RE3WyAIz5gDw=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "> The performance of image segmentation models has historically been constrained by the high cost of collecting large-scale annotated data. The Segment Anything Model (SAM) alleviates this original problem through a promptable, semantics-agnostic, segmentation paradigm and yet still requires manual visual-prompts or complex domain-dependent prompt-generation rules to process a new image. Towards reducing this new burden, our work investigates the task of object segmentation when provided with, alternatively, only a small set of reference images. Our key insight is to leverage strong semantic priors, as learned by foundation models, to identify corresponding regions between a reference and a target image. We find that correspondences enable automatic generation of instance-level segmentation masks for downstream tasks and instantiate our ideas via a multi-stage, training-free method incorporating (1) memory bank construction; (2) representation aggregation and (3) semantic-aware feature matching. Our experiments show significant improvements on segmentation metrics, leading to state-of-the-art performance on COCO FSOD (36.8% nAP), PASCAL VOC Few-Shot (71.2% nAP50) and outperforming existing training-free approaches on the Cross-Domain FSOD benchmark (22.4% nAP).",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 5,
    "Content": "\n![cdfsod-results-final-comic-sans-min](https://github.com/user-attachments/assets/ab302c02-c080-4042-99fc-0e181ba8abb9)\n\n\n## üß† Architecture\n\n![training-free-architecture-comic-sans-min](https://github.com/user-attachments/assets/d84dd83a-505e-45a0-8ce3-98e1838017f9)\n\n\n## üõ†Ô∏è Installation instructions\n\n### 1. Clone the repository\n",
    "ContentSha": "V4xbbzEUhNFOhqp3BaqWeY1MaXeaFR8RD3QR6DHJiVo=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "\n![cdfsod-results-final-comic-sans-min](https://github.com/user-attachments/assets/ab302c02-c080-4042-99fc-0e181ba8abb9)\n\n\n## üß† Architecture\n\n![training-free-architecture-comic-sans-min](https://github.com/user-attachments/assets/d84dd83a-505e-45a0-8ce3-98e1838017f9)\n\n\n## üõ†Ô∏è Installation instructions\n\n### 1. Clone the repository\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 6,
    "Content": "```bash\ngit clone https://github.com/miquel-espinosa/no-time-to-train.git\ncd no-time-to-train\n```",
    "ContentSha": "FqsX96SwjKeMnD8rrDrd4pfjW32n5SRf0jXIvB4WHz4=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\ngit clone https://github.com/miquel-espinosa/no-time-to-train.git\ncd no-time-to-train\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 7,
    "Content": "\n### 2. Create conda environment\n\nWe will create a conda environment with the required packages.",
    "ContentSha": "xkwDa/DvfDApk69cNg5ORagN7Utfcos+yCxRpQNn6gk=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "### 2. T·∫°o m√¥i tr∆∞·ªùng conda\n\nCh√∫ng ta s·∫Ω t·∫°o m·ªôt m√¥i tr∆∞·ªùng conda v·ªõi c√°c g√≥i c·∫ßn thi·∫øt.\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 8,
    "Content": "```bash\nconda env create -f environment.yml\nconda activate no-time-to-train\n```",
    "ContentSha": "W1AlselK7qAC1MpunsXhTPA8MG+kwjbpodKBkImFaio=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\nconda env create -f environment.yml\nconda activate no-time-to-train\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 9,
    "Content": "\n### 3. Install SAM2 and DinoV2\n\nWe will install SAM2 and DinoV2 from source.",
    "ContentSha": "qhWNaaTVSpemTiKekSRF2dWJYxX636VdhL+lPiso28M=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "### 3. C√†i ƒë·∫∑t SAM2 v√† DinoV2\n\nCh√∫ng ta s·∫Ω c√†i ƒë·∫∑t SAM2 v√† DinoV2 t·ª´ m√£ ngu·ªìn.\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 10,
    "Content": "```bash\npip install -e .\ncd dinov2\npip install -e .\ncd ..\n```",
    "ContentSha": "dMsjJwa9nz+HHMLijmYZdlLh6FmDBGmNlHxywBzbEg4=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\npip install -e .\ncd dinov2\npip install -e .\ncd ..\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 11,
    "Content": "\n### 4. Download datasets\n\nPlease download COCO dataset and place it in `data/coco`\n\n### 5. Download SAM2 and DinoV2 checkpoints\n\nWe will download the exact SAM2 checkpoints used in the paper.\n(Note, however, that SAM2.1 checkpoints are already available and might perform better.)\n",
    "ContentSha": "LTXcwC9KGMiPIiBLXtQVF6Wdi9d19gVIUBX6F+tGTqE=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "### 4. T·∫£i xu·ªëng c√°c b·ªô d·ªØ li·ªáu\n\nVui l√≤ng t·∫£i xu·ªëng b·ªô d·ªØ li·ªáu COCO v√† ƒë·∫∑t n√≥ v√†o `data/coco`\n\n### 5. T·∫£i xu·ªëng c√°c checkpoint SAM2 v√† DinoV2\n\nCh√∫ng ta s·∫Ω t·∫£i xu·ªëng c√°c checkpoint SAM2 ch√≠nh x√°c ƒë√£ ƒë∆∞·ª£c s·ª≠ d·ª•ng trong b√†i b√°o.\n(Tuy nhi√™n, l∆∞u √Ω r·∫±ng c√°c checkpoint SAM2.1 ƒë√£ c√≥ s·∫µn v√† c√≥ th·ªÉ ho·∫°t ƒë·ªông t·ªët h∆°n.)\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 12,
    "Content": "```bash\nmkdir -p checkpoints/dinov2\ncd checkpoints\nwget https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_large.pt\ncd dinov2\nwget https://dl.fbaipublicfiles.com/dinov2/dinov2_vitl14/dinov2_vitl14_pretrain.pth\ncd ../..\n```",
    "ContentSha": "Q/LddAGtfunblX1eLTx7t3Vs+C74LtCdgP/HQ3gIJgk=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\nmkdir -p checkpoints/dinov2\ncd checkpoints\nwget https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_large.pt\ncd dinov2\nwget https://dl.fbaipublicfiles.com/dinov2/dinov2_vitl14/dinov2_vitl14_pretrain.pth\ncd ../..\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 13,
    "Content": "\n\n## üìä Inference code\n\n‚ö†Ô∏è Disclaimer: This is research code ‚Äî expect a bit of chaos!\n\n### Reproducing 30-shot SOTA results in Few-shot COCO\n\nDefine useful variables and create a folder for results:\n",
    "ContentSha": "q8hVlrVr+ps2xB/JxM3tKtF/KxoLX4PepxohltYehb8=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "## üìä M√£ suy lu·∫≠n\n\n‚ö†Ô∏è L∆∞u √Ω: ƒê√¢y l√† m√£ nghi√™n c·ª©u ‚Äî c√≥ th·ªÉ s·∫Ω h∆°i l·ªôn x·ªôn!\n\n### T√°i t·∫°o k·∫øt qu·∫£ SOTA 30-shot trong Few-shot COCO\n\nƒê·ªãnh nghƒ©a c√°c bi·∫øn h·ªØu √≠ch v√† t·∫°o m·ªôt th∆∞ m·ª•c cho k·∫øt qu·∫£:\n\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 14,
    "Content": "```bash\nCONFIG=./no_time_to_train/new_exps/coco_fewshot_10shot_Sam2L.yaml\nCLASS_SPLIT=\"few_shot_classes\"\nRESULTS_DIR=work_dirs/few_shot_results\nSHOTS=30\nSEED=33\nGPUS=4\n\nmkdir -p $RESULTS_DIR\nFILENAME=few_shot_${SHOTS}shot_seed${SEED}.pkl\n```",
    "ContentSha": "R03PMGcFnYnvttqgfztGnWdoyJeXMyxFUN7tyR4kpy8=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\nCONFIG=./no_time_to_train/new_exps/coco_fewshot_10shot_Sam2L.yaml\nCLASS_SPLIT=\"few_shot_classes\"\nRESULTS_DIR=work_dirs/few_shot_results\nSHOTS=30\nSEED=33\nGPUS=4\n\nmkdir -p $RESULTS_DIR\nFILENAME=few_shot_${SHOTS}shot_seed${SEED}.pkl\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 15,
    "Content": "\n#### 0. Create reference set\n",
    "ContentSha": "1XrtmJBqIS+6/RHkWmwwopPgE4d3ho+bdPLXEG612YQ=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "#### 0. T·∫°o b·ªô tham chi·∫øu\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 16,
    "Content": "```bash\npython no_time_to_train/dataset/few_shot_sampling.py \\\n        --n-shot $SHOTS \\\n        --out-path ${RESULTS_DIR}/${FILENAME} \\\n        --seed $SEED \\\n        --dataset $CLASS_SPLIT\n```",
    "ContentSha": "XMsc+nj2n5gsZtjFdl6ErjVKLXgBoPIrungxtY9mDss=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\npython no_time_to_train/dataset/few_shot_sampling.py \\\n        --n-shot $SHOTS \\\n        --out-path ${RESULTS_DIR}/${FILENAME} \\\n        --seed $SEED \\\n        --dataset $CLASS_SPLIT\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 17,
    "Content": "\n#### 1. Fill memory with references\n",
    "ContentSha": "v8E00SBwAimb411iJf1DGyTZxexOPmC/xK0/B+XBH1g=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "#### 1. L·∫•p ƒë·∫ßy b·ªô nh·ªõ b·∫±ng c√°c tham chi·∫øu\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 18,
    "Content": "```bash\npython run_lightening.py test --config $CONFIG \\\n                              --model.test_mode fill_memory \\\n                              --out_path ${RESULTS_DIR}/memory.ckpt \\\n                              --model.init_args.model_cfg.memory_bank_cfg.length $SHOTS \\\n                              --model.init_args.dataset_cfgs.fill_memory.memory_pkl ${RESULTS_DIR}/${FILENAME} \\\n                              --model.init_args.dataset_cfgs.fill_memory.memory_length $SHOTS \\\n                              --model.init_args.dataset_cfgs.fill_memory.class_split $CLASS_SPLIT \\\n                              --trainer.logger.save_dir ${RESULTS_DIR}/ \\\n                              --trainer.devices $GPUS\n```",
    "ContentSha": "1pVePuzaIdQCE/Nx0VoaWhFswuB5Jh1Z68Cw/2D8RkM=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\npython run_lightening.py test --config $CONFIG \\\n                              --model.test_mode fill_memory \\\n                              --out_path ${RESULTS_DIR}/memory.ckpt \\\n                              --model.init_args.model_cfg.memory_bank_cfg.length $SHOTS \\\n                              --model.init_args.dataset_cfgs.fill_memory.memory_pkl ${RESULTS_DIR}/${FILENAME} \\\n                              --model.init_args.dataset_cfgs.fill_memory.memory_length $SHOTS \\\n                              --model.init_args.dataset_cfgs.fill_memory.class_split $CLASS_SPLIT \\\n                              --trainer.logger.save_dir ${RESULTS_DIR}/ \\\n                              --trainer.devices $GPUS\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 19,
    "Content": "\n#### 2. Post-process memory bank\n",
    "ContentSha": "3A9quGczCnAQeUTcoJVGYLTQapI5nQ5aSj7AZIhGFJw=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "#### 2. X·ª≠ l√Ω h·∫≠u k·ª≥ b·ªô nh·ªõ ng√¢n h√†ng\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 20,
    "Content": "```bash\npython run_lightening.py test --config $CONFIG \\\n                              --model.test_mode postprocess_memory \\\n                              --model.init_args.model_cfg.memory_bank_cfg.length $SHOTS \\\n                              --ckpt_path ${RESULTS_DIR}/memory.ckpt \\\n                              --out_path ${RESULTS_DIR}/memory_postprocessed.ckpt \\\n                              --trainer.devices 1\n```",
    "ContentSha": "45qs8EyMtDUKs5A3rrQcJQXl6OIbI6s0rKOOnHmYURs=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\npython run_lightening.py test --config $CONFIG \\\n                              --model.test_mode postprocess_memory \\\n                              --model.init_args.model_cfg.memory_bank_cfg.length $SHOTS \\\n                              --ckpt_path ${RESULTS_DIR}/memory.ckpt \\\n                              --out_path ${RESULTS_DIR}/memory_postprocessed.ckpt \\\n                              --trainer.devices 1\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 21,
    "Content": "\n#### 3. Inference on target images\n",
    "ContentSha": "73CbGioqWaTULTrw0roBLoZCxgBgtmJVFDc7RHluH0g=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "#### 3. Suy lu·∫≠n tr√™n c√°c h√¨nh ·∫£nh m·ª•c ti√™u\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 22,
    "Content": "```bash\npython run_lightening.py test --config $CONFIG  \\\n                              --ckpt_path ${RESULTS_DIR}/memory_postprocessed.ckpt \\\n                              --model.init_args.test_mode test \\\n                              --model.init_args.model_cfg.memory_bank_cfg.length $SHOTS \\\n                              --model.init_args.model_cfg.dataset_name $CLASS_SPLIT \\\n                              --model.init_args.dataset_cfgs.test.class_split $CLASS_SPLIT \\\n                              --trainer.logger.save_dir ${RESULTS_DIR}/ \\\n                              --trainer.devices $GPUS\n```",
    "ContentSha": "vbKXVEs47fJ5oF8vLkHVM2ofFMx1hKBBgQF9JAgp2Jo=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\npython run_lightening.py test --config $CONFIG  \\\n                              --ckpt_path ${RESULTS_DIR}/memory_postprocessed.ckpt \\\n                              --model.init_args.test_mode test \\\n                              --model.init_args.model_cfg.memory_bank_cfg.length $SHOTS \\\n                              --model.init_args.model_cfg.dataset_name $CLASS_SPLIT \\\n                              --model.init_args.dataset_cfgs.test.class_split $CLASS_SPLIT \\\n                              --trainer.logger.save_dir ${RESULTS_DIR}/ \\\n                              --trainer.devices $GPUS\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 23,
    "Content": "\nIf you'd like to see inference results online (as they are computed), add the argument:",
    "ContentSha": "Dp4E3gH6hSg659jJwzXukrsk5Jl8KA5ymhMGoz6L/wc=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "N·∫øu b·∫°n mu·ªën xem k·∫øt qu·∫£ suy lu·∫≠n tr·ª±c tuy·∫øn (ngay khi ch√∫ng ƒë∆∞·ª£c t√≠nh to√°n), h√£y th√™m ƒë·ªëi s·ªë:\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 24,
    "Content": "```bash\n    --model.init_args.model_cfg.test.online_vis True\n```",
    "ContentSha": "mbu//ROEScsc0zLyvi3r1BPFxMrHWk/o7rqLvu03LTA=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\n    --model.init_args.model_cfg.test.online_vis True\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 25,
    "Content": "To adjust the score threshold `score_thr` parameter, add the argument (for example, visualising all instances with score higher than `0.4`):",
    "ContentSha": "qweycVV6vcVlQTeQ2dS1zGx5GmbYXYcZs6oNjQhUwNI=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "ƒê·ªÉ ƒëi·ªÅu ch·ªânh tham s·ªë ng∆∞·ª°ng ƒëi·ªÉm s·ªë `score_thr`, h√£y th√™m ƒë·ªëi s·ªë (v√≠ d·ª•, tr·ª±c quan h√≥a t·∫•t c·∫£ c√°c tr∆∞·ªùng h·ª£p c√≥ ƒëi·ªÉm s·ªë cao h∆°n `0.4`):",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 26,
    "Content": "```bash\n    --model.init_args.model_cfg.test.vis_thr 0.4\n```",
    "ContentSha": "af/rWDR0jwUHbKw+uPDz7J5oeScBvpa9U5qwCYxo0Pg=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\n    --model.init_args.model_cfg.test.vis_thr 0.4\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 27,
    "Content": "Images will now be saved in `results_analysis/few_shot_classes/`. The image on the left shows the ground truth, the image on the right shows the segmented instances found by our training-free method.\n\nNote that in this example we are using the `few_shot_classes` split, thus, we should only expect to see segmented instances of the classes in this split (not all classes in COCO).\n\n#### Results\n\nAfter running all images in the validation set, you should obtain:\n",
    "ContentSha": "UYiVB+AwL2aAWVmV805O2tsw2jw3cL3t1ysHKuWCd28=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "C√°c h√¨nh ·∫£nh b√¢y gi·ªù s·∫Ω ƒë∆∞·ª£c l∆∞u trong `results_analysis/few_shot_classes/`. H√¨nh ·∫£nh b√™n tr√°i hi·ªÉn th·ªã d·ªØ li·ªáu th·ª±c t·∫ø, h√¨nh ·∫£nh b√™n ph·∫£i hi·ªÉn th·ªã c√°c v√πng ph√¢n ƒëo·∫°n do ph∆∞∆°ng ph√°p kh√¥ng c·∫ßn hu·∫•n luy·ªán c·ªßa ch√∫ng t√¥i t√¨m ƒë∆∞·ª£c.\n\nL∆∞u √Ω r·∫±ng trong v√≠ d·ª• n√†y ch√∫ng t√¥i ƒëang s·ª≠ d·ª•ng b·ªô chia `few_shot_classes`, do ƒë√≥, ch√∫ng ta ch·ªâ n√™n mong ƒë·ª£i th·∫•y c√°c v√πng ph√¢n ƒëo·∫°n c·ªßa c√°c l·ªõp trong b·ªô chia n√†y (kh√¥ng ph·∫£i t·∫•t c·∫£ c√°c l·ªõp trong COCO).\n\n#### K·∫øt qu·∫£\n\nSau khi ch·∫°y t·∫•t c·∫£ c√°c h√¨nh ·∫£nh trong t·∫≠p ki·ªÉm ƒë·ªãnh, b·∫°n s·∫Ω thu ƒë∆∞·ª£c:\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 28,
    "Content": "```\nBBOX RESULTS:\n  Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.368\n\nSEGM RESULTS:\n  Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.342\n```",
    "ContentSha": "ch7itB3Sk8oLc3U+lNJGI3BV57wpOMkabTBsUiqzHDU=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```\nBBOX RESULTS:\n  Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.368\n\nSEGM RESULTS:\n  Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.342\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 29,
    "Content": "---\n\n## üîç Custom dataset\n\nWe provide the instructions for running our pipeline on a custom dataset. Annotation format are always in COCO format.\n\n> **TLDR;** To directly see how to run full pipeline on *custom datasets*, find `scripts/matching_cdfsod_pipeline.sh` together with example scripts of CD-FSOD datasets (e.g. `scripts/dior_fish.sh`)\n\n### 0. Prepare a custom dataset ‚õµüê¶\n\nLet's imagine we want to detect **boats**‚õµ and **birds**üê¶ in a custom dataset. To use our method we will need:\n- At least 1 *annotated* reference image for each class (i.e. 1 reference image for boat and 1 reference image for bird)\n- Multiple target images to find instances of our desired classes.\n\nWe have prepared a toy script to create a custom dataset with coco images, for a **1-shot** setting.",
    "ContentSha": "IPUeWphY2t966UmztjMo0ja/aOT1Wd0H0rkyNv8xt9Y=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "---\n\n## üîç B·ªô d·ªØ li·ªáu t√πy ch·ªânh\n\nCh√∫ng t√¥i cung c·∫•p h∆∞·ªõng d·∫´n ƒë·ªÉ ch·∫°y pipeline c·ªßa m√¨nh tr√™n m·ªôt b·ªô d·ªØ li·ªáu t√πy ch·ªânh. ƒê·ªãnh d·∫°ng ch√∫ th√≠ch lu√¥n ·ªü ƒë·ªãnh d·∫°ng COCO.\n\n> **TLDR;** ƒê·ªÉ xem tr·ª±c ti·∫øp c√°ch ch·∫°y to√†n b·ªô pipeline tr√™n *b·ªô d·ªØ li·ªáu t√πy ch·ªânh*, h√£y xem `scripts/matching_cdfsod_pipeline.sh` c√πng v·ªõi c√°c script v√≠ d·ª• c·ªßa b·ªô d·ªØ li·ªáu CD-FSOD (v√≠ d·ª•: `scripts/dior_fish.sh`)\n\n### 0. Chu·∫©n b·ªã b·ªô d·ªØ li·ªáu t√πy ch·ªânh ‚õµüê¶\n\nH√£y t∆∞·ªüng t∆∞·ª£ng ch√∫ng ta mu·ªën ph√°t hi·ªán **thuy·ªÅn**‚õµ v√† **chim**üê¶ trong m·ªôt b·ªô d·ªØ li·ªáu t√πy ch·ªânh. ƒê·ªÉ s·ª≠ d·ª•ng ph∆∞∆°ng ph√°p c·ªßa ch√∫ng t√¥i, b·∫°n s·∫Ω c·∫ßn:\n- √çt nh·∫•t 1 ·∫£nh tham chi·∫øu *ƒë∆∞·ª£c ch√∫ th√≠ch* cho m·ªói l·ªõp (v√≠ d·ª•: 1 ·∫£nh tham chi·∫øu cho thuy·ªÅn v√† 1 ·∫£nh tham chi·∫øu cho chim)\n- Nhi·ªÅu ·∫£nh m·ª•c ti√™u ƒë·ªÉ t√¨m c√°c ƒë·ªëi t∆∞·ª£ng c·ªßa l·ªõp mong mu·ªën.\n\nCh√∫ng t√¥i ƒë√£ chu·∫©n b·ªã m·ªôt script v√≠ d·ª• ƒë·ªÉ t·∫°o b·ªô d·ªØ li·ªáu t√πy ch·ªânh v·ªõi ·∫£nh coco, cho tr∆∞·ªùng h·ª£p **1-shot**.",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 30,
    "Content": "```bash\nmkdir -p data/my_custom_dataset\npython scripts/make_custom_dataset.py\n```",
    "ContentSha": "QqoeCMR6ke4ax/152QCJr8NiqoIlKNt5rN0t2zxaRtM=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\nmkdir -p data/my_custom_dataset\npython scripts/make_custom_dataset.py\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 31,
    "Content": "This will create a custom dataset with the following folder structure:",
    "ContentSha": "9JGOKHf/Hqbdn+b2OqaUnKIYD8GGf7jwfM9mTbUtoP4=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "ƒêi·ªÅu n√†y s·∫Ω t·∫°o ra m·ªôt b·ªô d·ªØ li·ªáu t√πy ch·ªânh v·ªõi c·∫•u tr√∫c th∆∞ m·ª•c nh∆∞ sau:",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 32,
    "Content": "```\ndata/my_custom_dataset/\n    ‚îú‚îÄ‚îÄ annotations/\n    ‚îÇ   ‚îú‚îÄ‚îÄ custom_references.json\n    ‚îÇ   ‚îú‚îÄ‚îÄ custom_targets.json\n    ‚îÇ   ‚îî‚îÄ‚îÄ references_visualisations/\n    ‚îÇ       ‚îú‚îÄ‚îÄ bird_1.jpg\n    ‚îÇ       ‚îî‚îÄ‚îÄ boat_1.jpg\n    ‚îî‚îÄ‚îÄ images/\n        ‚îú‚îÄ‚îÄ 429819.jpg\n        ‚îú‚îÄ‚îÄ 101435.jpg\n        ‚îî‚îÄ‚îÄ (all target and reference images)\n```",
    "ContentSha": "Bj/IFZkQUfkoGUwynry3llvasPwDhX0B0JgBYl9vuQE=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```\ndata/my_custom_dataset/\n    ‚îú‚îÄ‚îÄ annotations/\n    ‚îÇ   ‚îú‚îÄ‚îÄ custom_references.json\n    ‚îÇ   ‚îú‚îÄ‚îÄ custom_targets.json\n    ‚îÇ   ‚îî‚îÄ‚îÄ references_visualisations/\n    ‚îÇ       ‚îú‚îÄ‚îÄ bird_1.jpg\n    ‚îÇ       ‚îî‚îÄ‚îÄ boat_1.jpg\n    ‚îî‚îÄ‚îÄ images/\n        ‚îú‚îÄ‚îÄ 429819.jpg\n        ‚îú‚îÄ‚îÄ 101435.jpg\n        ‚îî‚îÄ‚îÄ (all target and reference images)\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 33,
    "Content": "\n**Reference images visualisation (1-shot):**\n\n| 1-shot Reference Image for BIRD üê¶ | 1-shot Reference Image for BOAT ‚õµ |\n|:---------------------------------:|:----------------------------------:|\n| <img src=\"https://github.com/user-attachments/assets/e59e580d-a7db-42ac-b386-892af211fc85\" alt=\"bird_1\" width=\"500\"/> | <img src=\"https://github.com/user-attachments/assets/f94ee025-ae37-4a45-9c3e-0cfe8f8cd2bc\" alt=\"boat_1\" width=\"500\"/> |\n\n\n### 0.1 If only bbox annotations are available\n\nWe also provide a script to generate instance-level segmentation masks by using SAM2. This is useful if you only have bounding box annotations available for the reference images.\n",
    "ContentSha": "24nxqSCUluTBmTCEJTeg5Xoe4qe7qXxstVNWjA2/zVk=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "**Tr·ª±c quan h√≥a h√¨nh ·∫£nh tham chi·∫øu (1-shot):**\n\n| H√¨nh ·∫£nh tham chi·∫øu 1-shot cho CHIM üê¶ | H√¨nh ·∫£nh tham chi·∫øu 1-shot cho THUY·ªÄN ‚õµ |\n|:--------------------------------------:|:---------------------------------------:|\n| <img src=\"https://github.com/user-attachments/assets/e59e580d-a7db-42ac-b386-892af211fc85\" alt=\"bird_1\" width=\"500\"/> | <img src=\"https://github.com/user-attachments/assets/f94ee025-ae37-4a45-9c3e-0cfe8f8cd2bc\" alt=\"boat_1\" width=\"500\"/> |\n\n\n### 0.1 N·∫øu ch·ªâ c√≥ ch√∫ th√≠ch bbox\n\nCh√∫ng t√¥i c≈©ng cung c·∫•p m·ªôt script ƒë·ªÉ t·∫°o m·∫∑t n·∫° ph√¢n ƒëo·∫°n c·∫•p ƒë·ªëi t∆∞·ª£ng b·∫±ng c√°ch s·ª≠ d·ª•ng SAM2. ƒêi·ªÅu n√†y h·ªØu √≠ch n·∫øu b·∫°n ch·ªâ c√≥ c√°c ch√∫ th√≠ch bounding box cho h√¨nh ·∫£nh tham chi·∫øu.\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 34,
    "Content": "```bash\n# Download sam_h checkpoint. Feel free to use more recent checkpoints (note: code might need to be adapted)\nwget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth -O checkpoints/sam_vit_h_4b8939.pth\n# Run automatic instance segmentation from ground truth bounding boxes.\npython no_time_to_train/dataset/sam_bbox_to_segm_batch.py \\\n    --input_json data/my_custom_dataset/annotations/custom_references.json \\\n    --image_dir data/my_custom_dataset/images \\\n    --sam_checkpoint checkpoints/sam_vit_h_4b8939.pth \\\n    --model_type vit_h \\\n    --device cuda \\\n    --batch_size 8 \\\n    --visualize\n```",
    "ContentSha": "MZFLWMxUY4Y3eseQiE2eVYRMs3mR83iZMQq1RJqVFCc=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\n# Download sam_h checkpoint. Feel free to use more recent checkpoints (note: code might need to be adapted)\nwget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth -O checkpoints/sam_vit_h_4b8939.pth\n# Run automatic instance segmentation from ground truth bounding boxes.\npython no_time_to_train/dataset/sam_bbox_to_segm_batch.py \\\n    --input_json data/my_custom_dataset/annotations/custom_references.json \\\n    --image_dir data/my_custom_dataset/images \\\n    --sam_checkpoint checkpoints/sam_vit_h_4b8939.pth \\\n    --model_type vit_h \\\n    --device cuda \\\n    --batch_size 8 \\\n    --visualize\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 35,
    "Content": "\n**Reference images with instance-level segmentation masks (generated by SAM2 from gt bounding boxes, 1-shot):**\n\nVisualisation of the generated segmentation masks are saved in `data/my_custom_dataset/annotations/custom_references_with_SAM_segm/references_visualisations/`.\n\n\n| 1-shot Reference Image for BIRD üê¶ (automatically segmented with SAM) | 1-shot Reference Image for BOAT ‚õµ (automatically segmented with SAM) |\n|:---------------------------------:|:----------------------------------:|\n| <img src=\"https://github.com/user-attachments/assets/65d38dc4-1454-43cd-9600-e8efc67b3a82\" alt=\"bird_1_with_SAM_segm\" width=\"500\"/> | <img src=\"https://github.com/user-attachments/assets/43a558ad-50ca-4715-8285-9aa3268843c6\" alt=\"boat_1_with_SAM_segm\" width=\"500\"/> |\n\n\n### 0.2 Convert coco annotations to pickle file\n",
    "ContentSha": "0a8ACnuaKmeocwoJUK+xvmctljcu8ZJdT00xJXlyJ5w=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "**H√¨nh ·∫£nh tham chi·∫øu v·ªõi m·∫∑t n·∫° ph√¢n ƒëo·∫°n c·∫•p ƒë·ªô ƒë·ªëi t∆∞·ª£ng (ƒë∆∞·ª£c t·∫°o b·ªüi SAM2 t·ª´ c√°c h·ªôp ch·ª©a gt, 1-shot):**\n\nH√¨nh ·∫£nh tr·ª±c quan h√≥a c·ªßa c√°c m·∫∑t n·∫° ph√¢n ƒëo·∫°n ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°i `data/my_custom_dataset/annotations/custom_references_with_SAM_segm/references_visualisations/`.\n\n\n| H√¨nh ·∫£nh tham chi·∫øu 1-shot cho CHIM üê¶ (t·ª± ƒë·ªông ph√¢n ƒëo·∫°n b·∫±ng SAM) | H√¨nh ·∫£nh tham chi·∫øu 1-shot cho THUY·ªÄN ‚õµ (t·ª± ƒë·ªông ph√¢n ƒëo·∫°n b·∫±ng SAM) |\n|:---------------------------------:|:----------------------------------:|\n| <img src=\"https://github.com/user-attachments/assets/65d38dc4-1454-43cd-9600-e8efc67b3a82\" alt=\"bird_1_with_SAM_segm\" width=\"500\"/> | <img src=\"https://github.com/user-attachments/assets/43a558ad-50ca-4715-8285-9aa3268843c6\" alt=\"boat_1_with_SAM_segm\" width=\"500\"/> |\n\n\n### 0.2 Chuy·ªÉn ƒë·ªïi ch√∫ th√≠ch coco sang t·∫≠p tin pickle\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 36,
    "Content": "```bash\npython no_time_to_train/dataset/coco_to_pkl.py \\\n    data/my_custom_dataset/annotations/custom_references_with_segm.json \\\n    data/my_custom_dataset/annotations/custom_references_with_segm.pkl \\\n    1\n```",
    "ContentSha": "PSo9jaMX0pVKgHl0ecq9duQGpy1rMpXUU1iB4a8YzJM=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\npython no_time_to_train/dataset/coco_to_pkl.py \\\n    data/my_custom_dataset/annotations/custom_references_with_segm.json \\\n    data/my_custom_dataset/annotations/custom_references_with_segm.pkl \\\n    1\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 37,
    "Content": "\n### 1. Fill memory with references\n\nFirst, define useful variables and create a folder for results. For correct visualisation of labels, class names should be ordered by category id as appears in the json file. E.g. `bird` has category id `16`, `boat` has category id `9`. Thus, `CAT_NAMES=boat,bird`.\n",
    "ContentSha": "97iqG4pEnvNDE6ERpjfa2nL6RAtTIXJXwjJwqU/SNCg=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "### 1. ƒê·ªï ƒë·∫ßy b·ªô nh·ªõ v·ªõi c√°c tham chi·∫øu\n\nƒê·∫ßu ti√™n, ƒë·ªãnh nghƒ©a c√°c bi·∫øn h·ªØu √≠ch v√† t·∫°o m·ªôt th∆∞ m·ª•c ƒë·ªÉ l∆∞u k·∫øt qu·∫£. ƒê·ªÉ hi·ªÉn th·ªã nh√£n ƒë√∫ng c√°ch, t√™n c√°c l·ªõp ph·∫£i ƒë∆∞·ª£c s·∫Øp x·∫øp theo id danh m·ª•c nh∆∞ trong t·ªáp json. V√≠ d·ª•, `bird` c√≥ id danh m·ª•c l√† `16`, `boat` c√≥ id danh m·ª•c l√† `9`. Do ƒë√≥, `CAT_NAMES=boat,bird`.\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 38,
    "Content": "```bash\nDATASET_NAME=my_custom_dataset\nDATASET_PATH=data/my_custom_dataset\nCAT_NAMES=boat,bird\nCATEGORY_NUM=2\nSHOT=1\nYAML_PATH=no_time_to_train/pl_configs/matching_cdfsod_template.yaml\nPATH_TO_SAVE_CKPTS=./tmp_ckpts/my_custom_dataset\nmkdir -p $PATH_TO_SAVE_CKPTS\n```",
    "ContentSha": "mJIX4bJBaFbcwT8YfLR0V4w6qjU7MQEh3u6k2gtPrvw=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\nDATASET_NAME=my_custom_dataset\nDATASET_PATH=data/my_custom_dataset\nCAT_NAMES=boat,bird\nCATEGORY_NUM=2\nSHOT=1\nYAML_PATH=no_time_to_train/pl_configs/matching_cdfsod_template.yaml\nPATH_TO_SAVE_CKPTS=./tmp_ckpts/my_custom_dataset\nmkdir -p $PATH_TO_SAVE_CKPTS\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 39,
    "Content": "\nRun step 1:",
    "ContentSha": "PqClefvNhYLjlZsfjndNSKUJEy6R+goO4h/8KMDA1P0=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "Ch·∫°y b∆∞·ªõc 1:\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 40,
    "Content": "```bash\npython run_lightening.py test --config $YAML_PATH \\\n    --model.test_mode fill_memory \\\n    --out_path $PATH_TO_SAVE_CKPTS/$DATASET_NAME\\_$SHOT\\_refs_memory.pth \\\n    --model.init_args.dataset_cfgs.fill_memory.root $DATASET_PATH/images \\\n    --model.init_args.dataset_cfgs.fill_memory.json_file $DATASET_PATH/annotations/custom_references_with_segm.json \\\n    --model.init_args.dataset_cfgs.fill_memory.memory_pkl $DATASET_PATH/annotations/custom_references_with_segm.pkl \\\n    --model.init_args.dataset_cfgs.fill_memory.memory_length $SHOT \\\n    --model.init_args.dataset_cfgs.fill_memory.cat_names $CAT_NAMES \\\n    --model.init_args.model_cfg.dataset_name $DATASET_NAME \\\n    --model.init_args.model_cfg.memory_bank_cfg.length $SHOT \\\n    --model.init_args.model_cfg.memory_bank_cfg.category_num $CATEGORY_NUM \\\n    --trainer.devices 1\n```",
    "ContentSha": "wLZindeEKqrTUIIF55tL8lmaW4jWIZ2bdw6bj/1U9TU=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\npython run_lightening.py test --config $YAML_PATH \\\n    --model.test_mode fill_memory \\\n    --out_path $PATH_TO_SAVE_CKPTS/$DATASET_NAME\\_$SHOT\\_refs_memory.pth \\\n    --model.init_args.dataset_cfgs.fill_memory.root $DATASET_PATH/images \\\n    --model.init_args.dataset_cfgs.fill_memory.json_file $DATASET_PATH/annotations/custom_references_with_segm.json \\\n    --model.init_args.dataset_cfgs.fill_memory.memory_pkl $DATASET_PATH/annotations/custom_references_with_segm.pkl \\\n    --model.init_args.dataset_cfgs.fill_memory.memory_length $SHOT \\\n    --model.init_args.dataset_cfgs.fill_memory.cat_names $CAT_NAMES \\\n    --model.init_args.model_cfg.dataset_name $DATASET_NAME \\\n    --model.init_args.model_cfg.memory_bank_cfg.length $SHOT \\\n    --model.init_args.model_cfg.memory_bank_cfg.category_num $CATEGORY_NUM \\\n    --trainer.devices 1\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 41,
    "Content": "\n### 2. Post-process memory bank\n",
    "ContentSha": "39oOsuQIXM8TjT8ASLmZI0OpSbUSAT4d7YEHU7S2uqQ=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "### 2. X·ª≠ l√Ω h·∫≠u k·ª≥ b·ªô nh·ªõ ng√¢n h√†ng\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 42,
    "Content": "```bash\npython run_lightening.py test --config $YAML_PATH \\\n    --model.test_mode postprocess_memory \\\n    --ckpt_path $PATH_TO_SAVE_CKPTS/$DATASET_NAME\\_$SHOT\\_refs_memory.pth \\\n    --out_path $PATH_TO_SAVE_CKPTS/$DATASET_NAME\\_$SHOT\\_refs_memory_postprocessed.pth \\\n    --model.init_args.model_cfg.dataset_name $DATASET_NAME \\\n    --model.init_args.model_cfg.memory_bank_cfg.length $SHOT \\\n    --model.init_args.model_cfg.memory_bank_cfg.category_num $CATEGORY_NUM \\\n    --trainer.devices 1\n```",
    "ContentSha": "49JIaRecImNonhL7aGKB3JsAkgDw76Irci38QcuVb8k=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\npython run_lightening.py test --config $YAML_PATH \\\n    --model.test_mode postprocess_memory \\\n    --ckpt_path $PATH_TO_SAVE_CKPTS/$DATASET_NAME\\_$SHOT\\_refs_memory.pth \\\n    --out_path $PATH_TO_SAVE_CKPTS/$DATASET_NAME\\_$SHOT\\_refs_memory_postprocessed.pth \\\n    --model.init_args.model_cfg.dataset_name $DATASET_NAME \\\n    --model.init_args.model_cfg.memory_bank_cfg.length $SHOT \\\n    --model.init_args.model_cfg.memory_bank_cfg.category_num $CATEGORY_NUM \\\n    --trainer.devices 1\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 43,
    "Content": "\n#### 2.1 Visualise post-processed memory bank\n",
    "ContentSha": "Pz+UrI1n9P9i9DChpNd/m3unfj17ZqVz3PnHMyK+5XU=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "\n#### 2.1 Tr·ª±c quan h√≥a b·ªô nh·ªõ ƒë√£ x·ª≠ l√Ω h·∫≠u k·ª≥\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 2,
        "rowsha": "zA9xPuN6grCmDtzemkhLkPyW7qI+l8F89v7W60063mQ=",
        "originContent": "#### 2.1 Visualise post-processed memory bank",
        "translatedContent": "#### 2.1 Tr·ª±c quan h√≥a b·ªô nh·ªõ ƒë√£ x·ª≠ l√Ω h·∫≠u k·ª≥"
      },
      {
        "row": 3,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 44,
    "Content": "```bash\npython run_lightening.py test --config $YAML_PATH \\\n    --model.test_mode vis_memory \\\n    --ckpt_path $PATH_TO_SAVE_CKPTS/$DATASET_NAME\\_$SHOT\\_refs_memory_postprocessed.pth \\\n    --model.init_args.dataset_cfgs.fill_memory.root $DATASET_PATH/images \\\n    --model.init_args.dataset_cfgs.fill_memory.json_file $DATASET_PATH/annotations/custom_references_with_segm.json \\\n    --model.init_args.dataset_cfgs.fill_memory.memory_pkl $DATASET_PATH/annotations/custom_references_with_segm.pkl \\\n    --model.init_args.dataset_cfgs.fill_memory.memory_length $SHOT \\\n    --model.init_args.dataset_cfgs.fill_memory.cat_names $CAT_NAMES \\\n    --model.init_args.model_cfg.dataset_name $DATASET_NAME \\\n    --model.init_args.model_cfg.memory_bank_cfg.length $SHOT \\\n    --model.init_args.model_cfg.memory_bank_cfg.category_num $CATEGORY_NUM \\\n    --trainer.devices 1\n```",
    "ContentSha": "2C9ilXiP+W/SLak7O3FNtKLBBgCCWOswHD8qb+mug1w=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\npython run_lightening.py test --config $YAML_PATH \\\n    --model.test_mode vis_memory \\\n    --ckpt_path $PATH_TO_SAVE_CKPTS/$DATASET_NAME\\_$SHOT\\_refs_memory_postprocessed.pth \\\n    --model.init_args.dataset_cfgs.fill_memory.root $DATASET_PATH/images \\\n    --model.init_args.dataset_cfgs.fill_memory.json_file $DATASET_PATH/annotations/custom_references_with_segm.json \\\n    --model.init_args.dataset_cfgs.fill_memory.memory_pkl $DATASET_PATH/annotations/custom_references_with_segm.pkl \\\n    --model.init_args.dataset_cfgs.fill_memory.memory_length $SHOT \\\n    --model.init_args.dataset_cfgs.fill_memory.cat_names $CAT_NAMES \\\n    --model.init_args.model_cfg.dataset_name $DATASET_NAME \\\n    --model.init_args.model_cfg.memory_bank_cfg.length $SHOT \\\n    --model.init_args.model_cfg.memory_bank_cfg.category_num $CATEGORY_NUM \\\n    --trainer.devices 1\n```",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "rTMjNc+qNIxb1xXDR5hEYiJw1fc4muBwuBsTXVIaIho=",
        "originContent": "```bash",
        "translatedContent": "```bash"
      },
      {
        "row": 2,
        "rowsha": "3ETYk+lXCmWw9FFEJ+wILd+zQZjjy0tb7XEaA2ooWes=",
        "originContent": "python run_lightening.py test --config $YAML_PATH \\",
        "translatedContent": "python run_lightening.py test --config $YAML_PATH \\"
      },
      {
        "row": 3,
        "rowsha": "sv7jXy1+zlYZ8hhMVNvjEq7J8BT4RkJJ2afn2CFyHyk=",
        "originContent": "    --model.test_mode vis_memory \\",
        "translatedContent": "    --model.test_mode vis_memory \\"
      },
      {
        "row": 4,
        "rowsha": "YaLMccWSufRiTsk+GoOYdBhkbklyP1j280Pi7lKtRsc=",
        "originContent": "    --ckpt_path $PATH_TO_SAVE_CKPTS/$DATASET_NAME\\_$SHOT\\_refs_memory_postprocessed.pth \\",
        "translatedContent": "    --ckpt_path $PATH_TO_SAVE_CKPTS/$DATASET_NAME\\_$SHOT\\_refs_memory_postprocessed.pth \\"
      },
      {
        "row": 5,
        "rowsha": "+BumbXTQ220P4SshjpoA32nDp/jwiCWbKFKYVi5RYXc=",
        "originContent": "    --model.init_args.dataset_cfgs.fill_memory.root $DATASET_PATH/images \\",
        "translatedContent": "    --model.init_args.dataset_cfgs.fill_memory.root $DATASET_PATH/images \\"
      },
      {
        "row": 6,
        "rowsha": "0QT7QmjYkqhfRshvsrRJCFd1cBt2OEEaPr2ax0WhEPA=",
        "originContent": "    --model.init_args.dataset_cfgs.fill_memory.json_file $DATASET_PATH/annotations/custom_references_with_segm.json \\",
        "translatedContent": "    --model.init_args.dataset_cfgs.fill_memory.json_file $DATASET_PATH/annotations/custom_references_with_segm.json \\"
      },
      {
        "row": 7,
        "rowsha": "SWrctgl0L7Kdk4nV2WBDVityuZNXBo7ZP3vjpFq3q+Y=",
        "originContent": "    --model.init_args.dataset_cfgs.fill_memory.memory_pkl $DATASET_PATH/annotations/custom_references_with_segm.pkl \\",
        "translatedContent": "    --model.init_args.dataset_cfgs.fill_memory.memory_pkl $DATASET_PATH/annotations/custom_references_with_segm.pkl \\"
      },
      {
        "row": 8,
        "rowsha": "ajwBbsJuNblaKhLCmbsz4NzIAKPocJiMx8opaUw7JHc=",
        "originContent": "    --model.init_args.dataset_cfgs.fill_memory.memory_length $SHOT \\",
        "translatedContent": "    --model.init_args.dataset_cfgs.fill_memory.memory_length $SHOT \\"
      },
      {
        "row": 9,
        "rowsha": "CMOv5nGBSogT0gO7wMGjvPW4XkomwTa82Tj0iD9Y3FQ=",
        "originContent": "    --model.init_args.dataset_cfgs.fill_memory.cat_names $CAT_NAMES \\",
        "translatedContent": "    --model.init_args.dataset_cfgs.fill_memory.cat_names $CAT_NAMES \\"
      },
      {
        "row": 10,
        "rowsha": "kjbTFgGn3Au3NL6CMgQDK2RpX6DraWPljNvBjaZwD/Q=",
        "originContent": "    --model.init_args.model_cfg.dataset_name $DATASET_NAME \\",
        "translatedContent": "    --model.init_args.model_cfg.dataset_name $DATASET_NAME \\"
      },
      {
        "row": 11,
        "rowsha": "I/do2Okczknn/9X/8y5Tan5Adh+bBdjM83mpNMTgU1Q=",
        "originContent": "    --model.init_args.model_cfg.memory_bank_cfg.length $SHOT \\",
        "translatedContent": "    --model.init_args.model_cfg.memory_bank_cfg.length $SHOT \\"
      },
      {
        "row": 12,
        "rowsha": "7Cn+uZ9khgahObEB4bul8QUBZse0UStnwto6jY94u64=",
        "originContent": "    --model.init_args.model_cfg.memory_bank_cfg.category_num $CATEGORY_NUM \\",
        "translatedContent": "    --model.init_args.model_cfg.memory_bank_cfg.category_num $CATEGORY_NUM \\"
      },
      {
        "row": 13,
        "rowsha": "MaGbj/BQoWys9ayvwnfa9LJa4GU85A541/zZC+Xlgzo=",
        "originContent": "    --trainer.devices 1",
        "translatedContent": "    --trainer.devices 1"
      },
      {
        "row": 14,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      }
    ],
    "IsCodeBlock": true
  },
  {
    "Id": 45,
    "Content": "PCA and K-means visualisations for the memory bank images are stored in `results_analysis/memory_vis/my_custom_dataset`.\n\n### 3. Inference on target images\n\nIf `ONLINE_VIS` is set to True, prediction results will be saved in `results_analysis/my_custom_dataset/` and displayed as they are computed. NOTE that running with online visualisation is much slower.\n\nFeel free to change the score threshold `VIS_THR` to see more or less segmented instances.",
    "ContentSha": "4E7c2MViriAoxOfwY+eeCB/D3hPi2EsbE37pTJqGFn8=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "C√°c h√¨nh ·∫£nh tr·ª±c quan h√≥a PCA v√† K-means cho b·ªô nh·ªõ ·∫£nh ƒë∆∞·ª£c l∆∞u t·∫°i `results_analysis/memory_vis/my_custom_dataset`.\n\n### 3. Suy lu·∫≠n tr√™n c√°c ·∫£nh m·ª•c ti√™u\n\nN·∫øu `ONLINE_VIS` ƒë∆∞·ª£c ƒë·∫∑t th√†nh True, k·∫øt qu·∫£ d·ª± ƒëo√°n s·∫Ω ƒë∆∞·ª£c l∆∞u t·∫°i `results_analysis/my_custom_dataset/` v√† hi·ªÉn th·ªã ngay khi ƒë∆∞·ª£c t√≠nh to√°n. L∆ØU √ù r·∫±ng vi·ªác ch·∫°y v·ªõi tr·ª±c quan h√≥a tr·ª±c tuy·∫øn s·∫Ω ch·∫≠m h∆°n nhi·ªÅu.\n\nB·∫°n c√≥ th·ªÉ thay ƒë·ªïi ng∆∞·ª°ng ƒëi·ªÉm s·ªë `VIS_THR` ƒë·ªÉ xem nhi·ªÅu ho·∫∑c √≠t c√°c ƒë·ªëi t∆∞·ª£ng ƒë√£ ƒë∆∞·ª£c ph√¢n ƒëo·∫°n h∆°n.",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "v06/j8pVoIsYKBBWpbMfxpIB8qMIcJbM2tdkKJl/cIE=",
        "originContent": "PCA and K-means visualisations for the memory bank images are stored in `results_analysis/memory_vis/my_custom_dataset`.",
        "translatedContent": "C√°c h√¨nh ·∫£nh tr·ª±c quan h√≥a PCA v√† K-means cho b·ªô nh·ªõ ·∫£nh ƒë∆∞·ª£c l∆∞u t·∫°i `results_analysis/memory_vis/my_custom_dataset`."
      },
      {
        "row": 2,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 3,
        "rowsha": "mgJPj3vIyTELe8bZmHn4RAZnA8e/rUDydk+y7d9nDPM=",
        "originContent": "### 3. Inference on target images",
        "translatedContent": "### 3. Suy lu·∫≠n tr√™n c√°c ·∫£nh m·ª•c ti√™u"
      },
      {
        "row": 4,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 5,
        "rowsha": "YM++GYWJ+d+mCXMS9tSUVlwWGrHkv3G/JLx27lurQ0U=",
        "originContent": "If `ONLINE_VIS` is set to True, prediction results will be saved in `results_analysis/my_custom_dataset/` and displayed as they are computed. NOTE that running with online visualisation is much slower.",
        "translatedContent": "N·∫øu `ONLINE_VIS` ƒë∆∞·ª£c ƒë·∫∑t th√†nh True, k·∫øt qu·∫£ d·ª± ƒëo√°n s·∫Ω ƒë∆∞·ª£c l∆∞u t·∫°i `results_analysis/my_custom_dataset/` v√† hi·ªÉn th·ªã ngay khi ƒë∆∞·ª£c t√≠nh to√°n. L∆ØU √ù r·∫±ng vi·ªác ch·∫°y v·ªõi tr·ª±c quan h√≥a tr·ª±c tuy·∫øn s·∫Ω ch·∫≠m h∆°n nhi·ªÅu."
      },
      {
        "row": 6,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 7,
        "rowsha": "XNhHBadyh3RCBpAmQ14NYnkh3kQ6nLbAWUU5I0lwtn8=",
        "originContent": "Feel free to change the score threshold `VIS_THR` to see more or less segmented instances.",
        "translatedContent": "B·∫°n c√≥ th·ªÉ thay ƒë·ªïi ng∆∞·ª°ng ƒëi·ªÉm s·ªë `VIS_THR` ƒë·ªÉ xem nhi·ªÅu ho·∫∑c √≠t c√°c ƒë·ªëi t∆∞·ª£ng ƒë√£ ƒë∆∞·ª£c ph√¢n ƒëo·∫°n h∆°n."
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 46,
    "Content": "```bash\nONLINE_VIS=True\nVIS_THR=0.4\npython run_lightening.py test --config $YAML_PATH \\\n    --model.test_mode test \\\n    --ckpt_path $PATH_TO_SAVE_CKPTS/$DATASET_NAME\\_$SHOT\\_refs_memory_postprocessed.pth \\\n    --model.init_args.model_cfg.dataset_name $DATASET_NAME \\\n    --model.init_args.model_cfg.memory_bank_cfg.length $SHOT \\\n    --model.init_args.model_cfg.memory_bank_cfg.category_num $CATEGORY_NUM \\\n    --model.init_args.model_cfg.test.imgs_path $DATASET_PATH/images \\\n    --model.init_args.model_cfg.test.online_vis $ONLINE_VIS \\\n    --model.init_args.model_cfg.test.vis_thr $VIS_THR \\\n    --model.init_args.dataset_cfgs.test.root $DATASET_PATH/images \\\n    --model.init_args.dataset_cfgs.test.json_file $DATASET_PATH/annotations/custom_targets.json \\\n    --model.init_args.dataset_cfgs.test.cat_names $CAT_NAMES \\\n    --trainer.devices 1\n```",
    "ContentSha": "WwpzFHhc6G71aipZFN/unoGoH913SXlW3RG98ipcK1k=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\nONLINE_VIS=True\nVIS_THR=0.4\npython run_lightening.py test --config $YAML_PATH \\\n    --model.test_mode test \\\n    --ckpt_path $PATH_TO_SAVE_CKPTS/$DATASET_NAME\\_$SHOT\\_refs_memory_postprocessed.pth \\\n    --model.init_args.model_cfg.dataset_name $DATASET_NAME \\\n    --model.init_args.model_cfg.memory_bank_cfg.length $SHOT \\\n    --model.init_args.model_cfg.memory_bank_cfg.category_num $CATEGORY_NUM \\\n    --model.init_args.model_cfg.test.imgs_path $DATASET_PATH/images \\\n    --model.init_args.model_cfg.test.online_vis $ONLINE_VIS \\\n    --model.init_args.model_cfg.test.vis_thr $VIS_THR \\\n    --model.init_args.dataset_cfgs.test.root $DATASET_PATH/images \\\n    --model.init_args.dataset_cfgs.test.json_file $DATASET_PATH/annotations/custom_targets.json \\\n    --model.init_args.dataset_cfgs.test.cat_names $CAT_NAMES \\\n    --trainer.devices 1\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 47,
    "Content": "\n### Results\n\nPerformance metrics (with the exact same parameters as commands above) should be:\n",
    "ContentSha": "qUh629YPJLLYOXeHGSusGSWIYdfgfMGmHPttF+Zq0tU=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "### K·∫øt qu·∫£\n\nC√°c ch·ªâ s·ªë hi·ªáu su·∫•t (v·ªõi ƒë√∫ng c√°c tham s·ªë nh∆∞ c√°c l·ªánh tr√™n) n√™n l√†:\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 48,
    "Content": "```\nBBOX RESULTS:\n  Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.478\n\nSEGM RESULTS:\n  Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.458\n```",
    "ContentSha": "EqM8BsGgWhI+q5ZgXp4DOk8Wayw3iQnYToBVZntlyVI=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```\nBBOX RESULTS:\n  Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.478\n\nSEGM RESULTS:\n  Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.458\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 49,
    "Content": "\nVisual results are saved in `results_analysis/my_custom_dataset/`. Note that our method works for false negatives, that is, images that do not contain any instances of the desired classes.\n\n*Click images to enlarge ‚¨áÔ∏è*\n\n| Target image with boats ‚õµ (left GT, right predictions) | Target image with birds üê¶ (left GT, right predictions) |\n|:----------------------:|:----------------------:|\n| ![000000459673](https://github.com/user-attachments/assets/678dc15a-dd3b-49d5-9287-6290da16aa6b) | ![000000407180](https://github.com/user-attachments/assets/fe306e48-af49-4d83-ac82-76fac6c456d1) |\n\n| Target image with boats and birds ‚õµüê¶ (left GT, right predictions) | Target image without boats or birds üö´ (left GT, right predictions) |\n|:---------------------------------:|:----------------------------------:|\n| ![000000517410](https://github.com/user-attachments/assets/9849b227-7f43-43d7-81ea-58010a623ad5) | ![000000460598](https://github.com/user-attachments/assets/7587700c-e09d-4cf6-8590-3df129c2568e) |\n\n\n## üìö Citation\n\nIf you use this work, please cite us:\n",
    "ContentSha": "tEYR4ra1661R2TKfAxblzhr7EHrPwy5JI69dHQuD/mM=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "K·∫øt qu·∫£ tr·ª±c quan ƒë∆∞·ª£c l∆∞u trong `results_analysis/my_custom_dataset/`. L∆∞u √Ω r·∫±ng ph∆∞∆°ng ph√°p c·ªßa ch√∫ng t√¥i ho·∫°t ƒë·ªông v·ªõi c√°c tr∆∞·ªùng h·ª£p √¢m t√≠nh gi·∫£, t·ª©c l√† c√°c h√¨nh ·∫£nh kh√¥ng ch·ª©a b·∫•t k·ª≥ ƒë·ªëi t∆∞·ª£ng n√†o thu·ªôc c√°c l·ªõp mong mu·ªën.\n\n*B·∫•m v√†o h√¨nh ƒë·ªÉ ph√≥ng to ‚¨áÔ∏è*\n\n| ·∫¢nh m·ª•c ti√™u v·ªõi thuy·ªÅn ‚õµ (tr√°i GT, ph·∫£i d·ª± ƒëo√°n) | ·∫¢nh m·ª•c ti√™u v·ªõi chim üê¶ (tr√°i GT, ph·∫£i d·ª± ƒëo√°n) |\n|:----------------------:|:----------------------:|\n| ![000000459673](https://github.com/user-attachments/assets/678dc15a-dd3b-49d5-9287-6290da16aa6b) | ![000000407180](https://github.com/user-attachments/assets/fe306e48-af49-4d83-ac82-76fac6c456d1) |\n\n| ·∫¢nh m·ª•c ti√™u v·ªõi thuy·ªÅn v√† chim ‚õµüê¶ (tr√°i GT, ph·∫£i d·ª± ƒëo√°n) | ·∫¢nh m·ª•c ti√™u kh√¥ng c√≥ thuy·ªÅn ho·∫∑c chim üö´ (tr√°i GT, ph·∫£i d·ª± ƒëo√°n) |\n|:---------------------------------:|:----------------------------------:|\n| ![000000517410](https://github.com/user-attachments/assets/9849b227-7f43-43d7-81ea-58010a623ad5) | ![000000460598](https://github.com/user-attachments/assets/7587700c-e09d-4cf6-8590-3df129c2568e) |\n\n\n## üìö Tr√≠ch d·∫´n\n\nN·∫øu b·∫°n s·ª≠ d·ª•ng c√¥ng tr√¨nh n√†y, vui l√≤ng tr√≠ch d·∫´n ch√∫ng t√¥i:\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 50,
    "Content": "```bibtex\n@article{espinosa2025notimetotrain,\n  title={No time to train! Training-Free Reference-Based Instance Segmentation},\n  author={Miguel Espinosa and Chenhongyi Yang and Linus Ericsson and Steven McDonagh and Elliot J. Crowley},\n  journal={arXiv preprint arXiv:2507.02798},\n  year={2025},\n  primaryclass={cs.CV}\n}\n```",
    "ContentSha": "wkySuPRHWTRGorn0rwSBqyUnW5RNg9LVe0O7npcbKSs=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bibtex\n@article{espinosa2025notimetotrain,\n  title={No time to train! Training-Free Reference-Based Instance Segmentation},\n  author={Miguel Espinosa and Chenhongyi Yang and Linus Ericsson and Steven McDonagh and Elliot J. Crowley},\n  journal={arXiv preprint arXiv:2507.02798},\n  year={2025},\n  primaryclass={cs.CV}\n}\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 51,
    "Content": "",
    "ContentSha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  }
]