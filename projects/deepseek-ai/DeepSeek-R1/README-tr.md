# DeepSeek-R1
<!-- markdownlint-disable first-line-h1 -->
<!-- markdownlint-disable html -->
<!-- markdownlint-disable no-duplicate-header -->

<div align="center">
  <img src="https://github.com/deepseek-ai/DeepSeek-V2/blob/main/figures/logo.svg?raw=true" width="60%" alt="DeepSeek-R1" />
</div>
<hr>
<div align="center" style="line-height: 1;">
  <a href="https://www.deepseek.com/" target="_blank"><img alt="Homepage"
    src="https://github.com/deepseek-ai/DeepSeek-V2/blob/main/figures/badge.svg?raw=true"/></a>
  <a href="https://chat.deepseek.com/" target="_blank"><img alt="Chat"
    src="https://img.shields.io/badge/ğŸ¤–%20Chat-DeepSeek%20R1-536af5?color=536af5&logoColor=white"/></a>
  <a href="https://huggingface.co/deepseek-ai" target="_blank"><img alt="Hugging Face"
    src="https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-DeepSeek%20AI-ffc107?color=ffc107&logoColor=white"/></a>
  <br>
  <a href="https://discord.gg/Tc7c45Zzu5" target="_blank"><img alt="Discord"
    src="https://img.shields.io/badge/Discord-DeepSeek%20AI-7289da?logo=discord&logoColor=white&color=7289da"/></a>
  <a href="https://github.com/deepseek-ai/DeepSeek-V2/blob/main/figures/qr.jpeg?raw=true" target="_blank"><img alt="WeChat"
    src="https://img.shields.io/badge/WeChat-DeepSeek%20AI-brightgreen?logo=wechat&logoColor=white"/></a>
  <a href="https://twitter.com/deepseek_ai" target="_blank"><img alt="Twitter Follow"
    src="https://img.shields.io/badge/Twitter-deepseek_ai-white?logo=x&logoColor=white"/></a>
  <br>
  <a href="https://github.com/deepseek-ai/DeepSeek-R1/blob/main/LICENSE"><img alt="License"
    src="https://img.shields.io/badge/License-MIT-f5de53?&color=f5de53"/></a>
  <br>
  <a href="https://github.com/deepseek-ai/DeepSeek-R1/blob/main/DeepSeek_R1.pdf"><b>Makale Linki</b>ğŸ‘ï¸</a>
</div>

## 1. GiriÅŸ

Ä°lk nesil akÄ±l yÃ¼rÃ¼tme modellerimiz DeepSeek-R1-Zero ve DeepSeek-R1'i tanÄ±tÄ±yoruz.
DeepSeek-R1-Zero, denetimli ince ayar (SFT) Ã¶n adÄ±m olmadan bÃ¼yÃ¼k Ã¶lÃ§ekli pekiÅŸtirmeli Ã¶ÄŸrenme (RL) ile eÄŸitilmiÅŸ bir model olup akÄ±l yÃ¼rÃ¼tmede dikkat Ã§ekici bir performans sergilemiÅŸtir.
RL ile, DeepSeek-R1-Zero doÄŸal olarak Ã§ok sayÄ±da gÃ¼Ã§lÃ¼ ve ilginÃ§ akÄ±l yÃ¼rÃ¼tme davranÄ±ÅŸlarÄ± sergilemiÅŸtir.
Ancak, DeepSeek-R1-Zero, bitmeyen tekrarlar, dÃ¼ÅŸÃ¼k okunabilirlik ve dil karÄ±ÅŸÄ±mÄ± gibi zorluklarla karÅŸÄ±laÅŸmaktadÄ±r. Bu sorunlarÄ± ele almak ve akÄ±l yÃ¼rÃ¼tme performansÄ±nÄ± daha da artÄ±rmak iÃ§in
RL Ã¶ncesinde cold-start verilerini iÃ§eren DeepSeek-R1'i sunuyoruz.
DeepSeek-R1, matematik, kod ve akÄ±l yÃ¼rÃ¼tme gÃ¶revlerinde OpenAI-o1 ile karÅŸÄ±laÅŸtÄ±rÄ±labilir bir performans elde etmektedir.
AraÅŸtÄ±rma topluluÄŸunu desteklemek amacÄ±yla DeepSeek-R1-Zero, DeepSeek-R1 ve DeepSeek-R1'den tÃ¼retilmiÅŸ, Llama ve Qwen tabanlÄ± altÄ± yoÄŸun modeli aÃ§Ä±k kaynak olarak paylaÅŸtÄ±k. DeepSeek-R1-Distill-Qwen-32B, Ã§eÅŸitli kÄ±yaslamalarda OpenAI-o1-mini'yi geride bÄ±rakarak yoÄŸun modeller iÃ§in yeni bir Ã¼st seviye sonuÃ§ elde etmiÅŸtir.

**NOT: DeepSeek-R1 serisi modelleri yerel olarak Ã§alÄ±ÅŸtÄ±rmadan Ã¶nce, lÃ¼tfen [KullanÄ±m Ã–nerileri](#usage-recommendations) bÃ¶lÃ¼mÃ¼nÃ¼ incelemenizi Ã¶nemle tavsiye ederiz.**

<p align="center">
  <img width="80%" src="figures/benchmark.jpg">
</p>

## 2. Model Ã–zeti

---

**Sonradan EÄŸitim: Temel Modelde BÃ¼yÃ¼k Ã–lÃ§ekli PekiÅŸtirmeli Ã–ÄŸrenme**

-  DoÄŸrudan temel modele denetimli ince ayar (SFT) Ã¶n adÄ±mÄ±na ihtiyaÃ§ duymadan pekiÅŸtirmeli Ã¶ÄŸrenme (RL) uyguluyoruz. Bu yaklaÅŸÄ±m, modelin karmaÅŸÄ±k problemleri Ã§Ã¶zmek iÃ§in dÃ¼ÅŸÃ¼nce zinciri (CoT) keÅŸfetmesine olanak tanÄ±r ve DeepSeek-R1-Zero'nun geliÅŸtirilmesiyle sonuÃ§lanÄ±r. DeepSeek-R1-Zero; Ã¶z-doÄŸrulama, yansÄ±tma ve uzun CoT'lar Ã¼retme gibi yetenekler sergiler ve araÅŸtÄ±rma topluluÄŸu iÃ§in Ã¶nemli bir dÃ¶nÃ¼m noktasÄ±dÄ±r. Ã–zellikle, LLM'lerin akÄ±l yÃ¼rÃ¼tme yeteneklerinin yalnÄ±zca RL ile, SFT'ye gerek kalmadan teÅŸvik edilebileceÄŸini doÄŸrulayan ilk aÃ§Ä±k araÅŸtÄ±rmadÄ±r. Bu atÄ±lÄ±m, bu alanda gelecekteki geliÅŸmelerin yolunu aÃ§maktadÄ±r.

-  DeepSeek-R1'i geliÅŸtirmek iÃ§in kullandÄ±ÄŸÄ±mÄ±z pipeline'Ä± tanÄ±tÄ±yoruz. Pipeline, daha iyi akÄ±l yÃ¼rÃ¼tme kalÄ±plarÄ±nÄ± keÅŸfetmek ve insan tercihlerine hizalanmak iÃ§in iki RL aÅŸamasÄ±nÄ± ve modelin akÄ±l yÃ¼rÃ¼tme ve akÄ±l yÃ¼rÃ¼tme dÄ±ÅŸÄ± yetenekleri iÃ§in baÅŸlangÄ±Ã§ olarak iki SFT aÅŸamasÄ±nÄ± iÃ§erir.
    Pipeline'Ä±n daha iyi modeller oluÅŸturma yoluyla sektÃ¶re fayda saÄŸlayacaÄŸÄ±na inanÄ±yoruz.

---

**DamÄ±tma: KÃ¼Ã§Ã¼k Modeller de GÃ¼Ã§lÃ¼ Olabilir**

-  Daha bÃ¼yÃ¼k modellerin akÄ±l yÃ¼rÃ¼tme kalÄ±plarÄ±nÄ±n kÃ¼Ã§Ã¼k modellere damÄ±tÄ±labileceÄŸini ve bunun, kÃ¼Ã§Ã¼k modellerde RL yoluyla keÅŸfedilen akÄ±l yÃ¼rÃ¼tme kalÄ±plarÄ±na gÃ¶re daha iyi performans saÄŸladÄ±ÄŸÄ±nÄ± gÃ¶steriyoruz. AÃ§Ä±k kaynaklÄ± DeepSeek-R1 ve API'si, araÅŸtÄ±rma topluluÄŸunun gelecekte daha iyi kÃ¼Ã§Ã¼k modeller damÄ±tmasÄ±na fayda saÄŸlayacaktÄ±r.
- DeepSeek-R1 tarafÄ±ndan Ã¼retilen akÄ±l yÃ¼rÃ¼tme verilerini kullanarak, araÅŸtÄ±rma topluluÄŸunda yaygÄ±n olarak kullanÄ±lan birkaÃ§ yoÄŸun modeli ince ayar yaptÄ±k. DeÄŸerlendirme sonuÃ§larÄ±, damÄ±tÄ±lmÄ±ÅŸ kÃ¼Ã§Ã¼k yoÄŸun modellerin kÄ±yaslamalarda olaÄŸanÃ¼stÃ¼ performans gÃ¶sterdiÄŸini ortaya koymaktadÄ±r. Qwen2.5 ve Llama3 serisi tabanlÄ± olarak 1.5B, 7B, 8B, 14B, 32B ve 70B kontrol noktalarÄ±nÄ± topluluÄŸa aÃ§Ä±k kaynak olarak sunuyoruz.

## 3. Model Ä°ndirmeleri

### DeepSeek-R1 Modelleri

<div align="center">

| **Model** | **#Toplam Parametre** | **#Aktif Parametre** | **BaÄŸlam UzunluÄŸu** | **Ä°ndir** |
| :------------: | :------------: | :------------: | :------------: | :------------: |
| DeepSeek-R1-Zero | 671B | 37B | 128K   | [ğŸ¤— HuggingFace](https://huggingface.co/deepseek-ai/DeepSeek-R1-Zero)   |
| DeepSeek-R1   | 671B | 37B |  128K   | [ğŸ¤— HuggingFace](https://huggingface.co/deepseek-ai/DeepSeek-R1)   |

</div>

DeepSeek-R1-Zero & DeepSeek-R1, DeepSeek-V3-Base tabanlÄ± olarak eÄŸitilmiÅŸtir.
Model mimarisiyle ilgili daha fazla bilgi iÃ§in lÃ¼tfen [DeepSeek-V3](https://github.com/deepseek-ai/DeepSeek-V3) deposuna bakÄ±nÄ±z.

### DeepSeek-R1-Distill Modelleri

<div align="center">

| **Model** | **Temel Model** | **Ä°ndir** |
| :------------: | :------------: | :------------: |
| DeepSeek-R1-Distill-Qwen-1.5B  | [Qwen2.5-Math-1.5B](https://huggingface.co/Qwen/Qwen2.5-Math-1.5B) | [ğŸ¤— HuggingFace](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B)   |
| DeepSeek-R1-Distill-Qwen-7B  | [Qwen2.5-Math-7B](https://huggingface.co/Qwen/Qwen2.5-Math-7B) | [ğŸ¤— HuggingFace](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B)   |
| DeepSeek-R1-Distill-Llama-8B  | [Llama-3.1-8B](https://huggingface.co/meta-llama/Llama-3.1-8B) | [ğŸ¤— HuggingFace](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-8B)   |
| DeepSeek-R1-Distill-Qwen-14B   | [Qwen2.5-14B](https://huggingface.co/Qwen/Qwen2.5-14B) | [ğŸ¤— HuggingFace](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-14B)   |
|DeepSeek-R1-Distill-Qwen-32B  | [Qwen2.5-32B](https://huggingface.co/Qwen/Qwen2.5-32B) | [ğŸ¤— HuggingFace](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-32B)   |
| DeepSeek-R1-Distill-Llama-70B  | [Llama-3.3-70B-Instruct](https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct) | [ğŸ¤— HuggingFace](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-70B)   |

</div>

DeepSeek-R1-Distill modelleri, DeepSeek-R1 tarafÄ±ndan Ã¼retilen Ã¶rnekler kullanÄ±larak aÃ§Ä±k kaynaklÄ± modeller Ã¼zerinden ince ayar yapÄ±lmÄ±ÅŸtÄ±r.
YapÄ±landÄ±rma dosyalarÄ±nÄ± ve tokenleÅŸtiricilerini hafifÃ§e deÄŸiÅŸtirdik. Bu modelleri Ã§alÄ±ÅŸtÄ±rmak iÃ§in lÃ¼tfen bizim ayarlarÄ±mÄ±zÄ± kullanÄ±n.

## 4. DeÄŸerlendirme SonuÃ§larÄ±

### DeepSeek-R1-DeÄŸerlendirme
 TÃ¼m modellerimiz iÃ§in maksimum Ã¼retim uzunluÄŸu 32.768 token olarak ayarlanmÄ±ÅŸtÄ±r. Ã–rnekleme gerektiren kÄ±yaslamalar iÃ§in sÄ±caklÄ±k $0.6$, top-p deÄŸeri $0.95$ olarak kullanÄ±lÄ±r ve pass@1'i tahmin etmek iÃ§in sorgu baÅŸÄ±na 64 yanÄ±t Ã¼retilir.
<div align="center">


| Kategori | KÄ±yaslama (Metrik) | Claude-3.5-Sonnet-1022 | GPT-4o 0513 | DeepSeek V3 | OpenAI o1-mini | OpenAI o1-1217 | DeepSeek R1 |
|----------|-------------------|----------------------|------------|--------------|----------------|------------|--------------|
| | Mimari | - | - | MoE | - | - | MoE |
| | # Aktif Parametre | - | - | 37B | - | - | 37B |
| | # Toplam Parametre | - | - | 671B | - | - | 671B |
| Ä°ngilizce | MMLU (Pass@1) | 88.3 | 87.2 | 88.5 | 85.2 | **91.8** | 90.8 |
| | MMLU-Redux (EM) | 88.9 | 88.0 | 89.1 | 86.7 | - | **92.9** |
| | MMLU-Pro (EM) | 78.0 | 72.6 | 75.9 | 80.3 | - | **84.0** |
| | DROP (3-shot F1) | 88.3 | 83.7 | 91.6 | 83.9 | 90.2 | **92.2** |
| | IF-Eval (Prompt Strict) | **86.5** | 84.3 | 86.1 | 84.8 | - | 83.3 |
| | GPQA-Diamond (Pass@1) | 65.0 | 49.9 | 59.1 | 60.0 | **75.7** | 71.5 |
| | SimpleQA (DoÄŸru) | 28.4 | 38.2 | 24.9 | 7.0 | **47.0** | 30.1 |
| | FRAMES (DoÄŸruluk) | 72.5 | 80.5 | 73.3 | 76.9 | - | **82.5** |
| | AlpacaEval2.0 (LC-kazanma oranÄ±) | 52.0 | 51.1 | 70.0 | 57.8 | - | **87.6** |
| | ArenaHard (GPT-4-1106) | 85.2 | 80.4 | 85.5 | 92.0 | - | **92.3** |
| Kod | LiveCodeBench (Pass@1-COT) | 33.8 | 34.2 | - | 53.8 | 63.4 | **65.9** |
| | Codeforces (YÃ¼zdelik Dilim) | 20.3 | 23.6 | 58.7 | 93.4 | **96.6** | 96.3 |
| | Codeforces (Puan) | 717 | 759 | 1134 | 1820 | **2061** | 2029 |
| | SWE DoÄŸrulandÄ± (Ã‡Ã¶zÃ¼ldÃ¼) | **50.8** | 38.8 | 42.0 | 41.6 | 48.9 | 49.2 |
| | Aider-Polyglot (DoÄŸruluk) | 45.3 | 16.0 | 49.6 | 32.9 | **61.7** | 53.3 |
| Matematik | AIME 2024 (Pass@1) | 16.0 | 9.3 | 39.2 | 63.6 | 79.2 | **79.8** |
| | MATH-500 (Pass@1) | 78.3 | 74.6 | 90.2 | 90.0 | 96.4 | **97.3** |
| | CNMO 2024 (Pass@1) | 13.1 | 10.8 | 43.2 | 67.6 | - | **78.8** |
| Ã‡ince | CLUEWSC (EM) | 85.4 | 87.9 | 90.9 | 89.9 | - | **92.8** |
| | C-Eval (EM) | 76.7 | 76.0 | 86.5 | 68.9 | - | **91.8** |
| | C-SimpleQA (DoÄŸru) | 55.4 | 58.7 | **68.0** | 40.3 | - | 63.7 |

</div>


### DamÄ±tÄ±lmÄ±ÅŸ Model DeÄŸerlendirmesi


<div align="center">

| Model                                    | AIME 2024 pass@1 | AIME 2024 cons@64 | MATH-500 pass@1 | GPQA Diamond pass@1 | LiveCodeBench pass@1 | CodeForces puan |
|------------------------------------------|------------------|-------------------|-----------------|----------------------|----------------------|-------------------|
| GPT-4o-0513                          | 9.3              | 13.4              | 74.6            | 49.9                 | 32.9                 | 759               |
| Claude-3.5-Sonnet-1022             | 16.0             | 26.7                 | 78.3            | 65.0                 | 38.9                 | 717               |
| o1-mini                              | 63.6             | 80.0              | 90.0            | 60.0                 | 53.8                 | **1820**          |
| QwQ-32B-Preview                              | 44.0             | 60.0                 | 90.6            | 54.5               | 41.9                 | 1316              |
| DeepSeek-R1-Distill-Qwen-1.5B       | 28.9             | 52.7              | 83.9            | 33.8                 | 16.9                 | 954               |
| DeepSeek-R1-Distill-Qwen-7B          | 55.5             | 83.3              | 92.8            | 49.1                 | 37.6                 | 1189              |
| DeepSeek-R1-Distill-Qwen-14B         | 69.7             | 80.0              | 93.9            | 59.1                 | 53.1                 | 1481              |
| DeepSeek-R1-Distill-Qwen-32B        | **72.6**         | 83.3              | 94.3            | 62.1                 | 57.2                 | 1691              |
| DeepSeek-R1-Distill-Llama-8B         | 50.4             | 80.0              | 89.1            | 49.0                 | 39.6                 | 1205              |
| DeepSeek-R1-Distill-Llama-70B        | 70.0             | **86.7**          | **94.5**        | **65.2**             | **57.5**             | 1633              |

</div>


## 5. Sohbet Sitesi & API Platformu
DeepSeek'in resmi web sitesinde DeepSeek-R1 ile sohbet edebilirsiniz: [chat.deepseek.com](https://chat.deepseek.com) ve "DeepThink" dÃ¼ÄŸmesini aÃ§abilirsiniz.

AyrÄ±ca DeepSeek Platformunda OpenAI-Uyumlu API sunuyoruz: [platform.deepseek.com](https://platform.deepseek.com/)

## 6. Yerel Olarak Ã‡alÄ±ÅŸtÄ±rma

### DeepSeek-R1 Modelleri

DeepSeek-R1'i yerel olarak Ã§alÄ±ÅŸtÄ±rma hakkÄ±nda daha fazla bilgi iÃ§in lÃ¼tfen [DeepSeek-V3](https://github.com/deepseek-ai/DeepSeek-V3) deposunu ziyaret edin.

**NOT: Hugging Face Transformers doÄŸrudan henÃ¼z desteklenmemektedir.**

### DeepSeek-R1-Distill Modelleri

DeepSeek-R1-Distill modelleri, Qwen veya Llama modellerinde olduÄŸu gibi kullanÄ±labilir.

Ã–rneÄŸin, [vLLM](https://github.com/vllm-project/vllm) ile bir servisi kolayca baÅŸlatabilirsiniz:

```shell
vllm serve deepseek-ai/DeepSeek-R1-Distill-Qwen-32B --tensor-parallel-size 2 --max-model-len 32768 --enforce-eager
```

AyrÄ±ca [SGLang](https://github.com/sgl-project/sglang) ile de kolayca bir servis baÅŸlatabilirsiniz.

```bash
python3 -m sglang.launch_server --model deepseek-ai/DeepSeek-R1-Distill-Qwen-32B --trust-remote-code --tp 2
```

### KullanÄ±m Ã–nerileri

**DeepSeek-R1 serisi modelleri, kÄ±yaslama dahil olmak Ã¼zere, beklenen performansa ulaÅŸmak iÃ§in aÅŸaÄŸÄ±daki yapÄ±landÄ±rmalara uymanÄ±zÄ± Ã¶neririz:**

1. Bitmeyen tekrarlarÄ± veya tutarsÄ±z Ã§Ä±ktÄ±larÄ± Ã¶nlemek iÃ§in sÄ±caklÄ±ÄŸÄ± 0.5-0.7 aralÄ±ÄŸÄ±nda ayarlayÄ±n (0.6 Ã¶nerilir).
2. **Sistem komutu eklemekten kaÃ§Ä±nÄ±n; tÃ¼m yÃ¶nergeler kullanÄ±cÄ± komutunda bulunmalÄ±dÄ±r.**
3. Matematiksel problemler iÃ§in, isteminize ÅŸu yÃ¶nergeyi eklemeniz tavsiye edilir: "LÃ¼tfen adÄ±m adÄ±m akÄ±l yÃ¼rÃ¼tÃ¼n ve nihai cevabÄ±nÄ±zÄ± \boxed{} iÃ§ine yazÄ±n."
4. Model performansÄ±nÄ± deÄŸerlendirirken, birden fazla test yapÄ±p sonuÃ§larÄ± ortalama almanÄ±z Ã¶nerilir.

Ek olarak, DeepSeek-R1 serisi modellerin bazÄ± sorgulara yanÄ±t verirken dÃ¼ÅŸÃ¼nce kalÄ±bÄ±nÄ± (yani "\<think\>\n\n\</think\>") atladÄ±ÄŸÄ±nÄ± gÃ¶zlemledik; bu, modelin performansÄ±nÄ± olumsuz etkileyebilir.
**Modelin kapsamlÄ± bir ÅŸekilde akÄ±l yÃ¼rÃ¼tmesini saÄŸlamak iÃ§in, her yanÄ±tÄ±n baÅŸÄ±nda modelin "\<think\>\n" ile baÅŸlamasÄ±nÄ± zorunlu kÄ±lmanÄ±zÄ± Ã¶neririz.**

### Resmi Komutlar
Resmi DeepSeek web/uygulamasÄ±nda sistem komutu kullanÄ±lmaz; daha iyi kullanÄ±cÄ± deneyimi iÃ§in dosya yÃ¼kleme ve web aramasÄ± iÃ§in iki Ã¶zel komut tasarlanmÄ±ÅŸtÄ±r. AyrÄ±ca, web/uygulamadaki sÄ±caklÄ±k deÄŸeri 0.6'dÄ±r.

Dosya yÃ¼kleme iÃ§in, {file_name}, {file_content} ve {question} argÃ¼manlarÄ±nÄ±n yer aldÄ±ÄŸÄ± ÅŸablonu takip edin.
```
file_template = \
"""[file name]: {file_name}
[file content begin]
{file_content}
[file content end]
{question}"""
```

Web Arama iÃ§in, {search_results}, {cur_date} ve {question} argÃ¼manlarÄ± kullanÄ±lÄ±r.

Ã‡ince sorgular iÃ§in ÅŸu komutu kullanÄ±yoruz:
```
search_answer_zh_template = \
'''# ä»¥ä¸‹å†…å®¹æ˜¯åŸºäºç”¨æˆ·å‘é€çš„æ¶ˆæ¯çš„æœç´¢ç»“æœ:
{search_results}
åœ¨æˆ‘ç»™ä½ çš„æœç´¢ç»“æœä¸­ï¼Œæ¯ä¸ªç»“æœéƒ½æ˜¯[webpage X begin]...[webpage X end]æ ¼å¼çš„ï¼ŒXä»£è¡¨æ¯ç¯‡æ–‡ç« çš„æ•°å­—ç´¢å¼•ã€‚è¯·åœ¨é€‚å½“çš„æƒ…å†µä¸‹åœ¨å¥å­æœ«å°¾å¼•ç”¨ä¸Šä¸‹æ–‡ã€‚è¯·æŒ‰ç…§å¼•ç”¨ç¼–å·[citation:X]çš„æ ¼å¼åœ¨ç­”æ¡ˆä¸­å¯¹åº”éƒ¨åˆ†å¼•ç”¨ä¸Šä¸‹æ–‡ã€‚å¦‚æœä¸€å¥è¯æºè‡ªå¤šä¸ªä¸Šä¸‹æ–‡ï¼Œè¯·åˆ—å‡ºæ‰€æœ‰ç›¸å…³çš„å¼•ç”¨ç¼–å·ï¼Œä¾‹å¦‚[citation:3][citation:5]ï¼Œåˆ‡è®°ä¸è¦å°†å¼•ç”¨é›†ä¸­åœ¨æœ€åè¿”å›å¼•ç”¨ç¼–å·ï¼Œè€Œæ˜¯åœ¨ç­”æ¡ˆå¯¹åº”éƒ¨åˆ†åˆ—å‡ºã€‚
åœ¨å›ç­”æ—¶ï¼Œè¯·æ³¨æ„ä»¥ä¸‹å‡ ç‚¹ï¼š
- ä»Šå¤©æ˜¯{cur_date}ã€‚
- å¹¶éæœç´¢ç»“æœçš„æ‰€æœ‰å†…å®¹éƒ½ä¸ç”¨æˆ·çš„é—®é¢˜å¯†åˆ‡ç›¸å…³ï¼Œä½ éœ€è¦ç»“åˆé—®é¢˜ï¼Œå¯¹æœç´¢ç»“æœè¿›è¡Œç”„åˆ«ã€ç­›é€‰ã€‚
- å¯¹äºåˆ—ä¸¾ç±»çš„é—®é¢˜ï¼ˆå¦‚åˆ—ä¸¾æ‰€æœ‰èˆªç­ä¿¡æ¯ï¼‰ï¼Œå°½é‡å°†ç­”æ¡ˆæ§åˆ¶åœ¨10ä¸ªè¦ç‚¹ä»¥å†…ï¼Œå¹¶å‘Šè¯‰ç”¨æˆ·å¯ä»¥æŸ¥çœ‹æœç´¢æ¥æºã€è·å¾—å®Œæ•´ä¿¡æ¯ã€‚ä¼˜å…ˆæä¾›ä¿¡æ¯å®Œæ•´ã€æœ€ç›¸å…³çš„åˆ—ä¸¾é¡¹ï¼›å¦‚éå¿…è¦ï¼Œä¸è¦ä¸»åŠ¨å‘Šè¯‰ç”¨æˆ·æœç´¢ç»“æœæœªæä¾›çš„å†…å®¹ã€‚
- å¯¹äºåˆ›ä½œç±»çš„é—®é¢˜ï¼ˆå¦‚å†™è®ºæ–‡ï¼‰ï¼Œè¯·åŠ¡å¿…åœ¨æ­£æ–‡çš„æ®µè½ä¸­å¼•ç”¨å¯¹åº”çš„å‚è€ƒç¼–å·ï¼Œä¾‹å¦‚[citation:3][citation:5]ï¼Œä¸èƒ½åªåœ¨æ–‡ç« æœ«å°¾å¼•ç”¨ã€‚ä½ éœ€è¦è§£è¯»å¹¶æ¦‚æ‹¬ç”¨æˆ·çš„é¢˜ç›®è¦æ±‚ï¼Œé€‰æ‹©åˆé€‚çš„æ ¼å¼ï¼Œå……åˆ†åˆ©ç”¨æœç´¢ç»“æœå¹¶æŠ½å–é‡è¦ä¿¡æ¯ï¼Œç”Ÿæˆç¬¦åˆç”¨æˆ·è¦æ±‚ã€æå…·æ€æƒ³æ·±åº¦ã€å¯Œæœ‰åˆ›é€ åŠ›ä¸ä¸“ä¸šæ€§çš„ç­”æ¡ˆã€‚ä½ çš„åˆ›ä½œç¯‡å¹…éœ€è¦å°½å¯èƒ½å»¶é•¿ï¼Œå¯¹äºæ¯ä¸€ä¸ªè¦ç‚¹çš„è®ºè¿°è¦æ¨æµ‹ç”¨æˆ·çš„æ„å›¾ï¼Œç»™å‡ºå°½å¯èƒ½å¤šè§’åº¦çš„å›ç­”è¦ç‚¹ï¼Œä¸”åŠ¡å¿…ä¿¡æ¯é‡å¤§ã€è®ºè¿°è¯¦å°½ã€‚
- å¦‚æœå›ç­”å¾ˆé•¿ï¼Œè¯·å°½é‡ç»“æ„åŒ–ã€åˆ†æ®µè½æ€»ç»“ã€‚å¦‚æœéœ€è¦åˆ†ç‚¹ä½œç­”ï¼Œå°½é‡æ§åˆ¶åœ¨5ä¸ªç‚¹ä»¥å†…ï¼Œå¹¶åˆå¹¶ç›¸å…³çš„å†…å®¹ã€‚
- å¯¹äºå®¢è§‚ç±»çš„é—®ç­”ï¼Œå¦‚æœé—®é¢˜çš„ç­”æ¡ˆéå¸¸ç®€çŸ­ï¼Œå¯ä»¥é€‚å½“è¡¥å……ä¸€åˆ°ä¸¤å¥ç›¸å…³ä¿¡æ¯ï¼Œä»¥ä¸°å¯Œå†…å®¹ã€‚
- ä½ éœ€è¦æ ¹æ®ç”¨æˆ·è¦æ±‚å’Œå›ç­”å†…å®¹é€‰æ‹©åˆé€‚ã€ç¾è§‚çš„å›ç­”æ ¼å¼ï¼Œç¡®ä¿å¯è¯»æ€§å¼ºã€‚
- ä½ çš„å›ç­”åº”è¯¥ç»¼åˆå¤šä¸ªç›¸å…³ç½‘é¡µæ¥å›ç­”ï¼Œä¸èƒ½é‡å¤å¼•ç”¨ä¸€ä¸ªç½‘é¡µã€‚
- é™¤éç”¨æˆ·è¦æ±‚ï¼Œå¦åˆ™ä½ å›ç­”çš„è¯­è¨€éœ€è¦å’Œç”¨æˆ·æé—®çš„è¯­è¨€ä¿æŒä¸€è‡´ã€‚

# ç”¨æˆ·æ¶ˆæ¯ä¸ºï¼š
{question}'''
```

Ä°ngilizce sorgular iÃ§in ÅŸu komutu kullanÄ±yoruz:
```
search_answer_en_template = \
'''# The following contents are the search results related to the user's message:
{search_results}
In the search results I provide to you, each result is formatted as [webpage X begin]...[webpage X end], where X represents the numerical index of each article. Please cite the context at the end of the relevant sentence when appropriate. Use the citation format [citation:X] in the corresponding part of your answer. If a sentence is derived from multiple contexts, list all relevant citation numbers, such as [citation:3][citation:5]. Be sure not to cluster all citations at the end; instead, include them in the corresponding parts of the answer.
When responding, please keep the following points in mind:
- Today is {cur_date}.
- Not all content in the search results is closely related to the user's question. You need to evaluate and filter the search results based on the question.
- For listing-type questions (e.g., listing all flight information), try to limit the answer to 10 key points and inform the user that they can refer to the search sources for complete information. Prioritize providing the most complete and relevant items in the list. Avoid mentioning content not provided in the search results unless necessary.
- For creative tasks (e.g., writing an essay), ensure that references are cited within the body of the text, such as [citation:3][citation:5], rather than only at the end of the text. You need to interpret and summarize the user's requirements, choose an appropriate format, fully utilize the search results, extract key information, and generate an answer that is insightful, creative, and professional. Extend the length of your response as much as possible, addressing each point in detail and from multiple perspectives, ensuring the content is rich and thorough.
- If the response is lengthy, structure it well and summarize it in paragraphs. If a point-by-point format is needed, try to limit it to 5 points and merge related content.
- For objective Q&A, if the answer is very brief, you may add one or two related sentences to enrich the content.
- Choose an appropriate and visually appealing format for your response based on the user's requirements and the content of the answer, ensuring strong readability.
- Your answer should synthesize information from multiple relevant webpages and avoid repeatedly citing the same webpage.
- Unless the user requests otherwise, your response should be in the same language as the user's question.

# The user's message is:
{question}'''
```

## 7. Lisans
Bu kod deposu ve model aÄŸÄ±rlÄ±klarÄ± [MIT LisansÄ±](https://github.com/deepseek-ai/DeepSeek-R1/blob/main/LICENSE) ile lisanslanmÄ±ÅŸtÄ±r.
DeepSeek-R1 serisi ticari kullanÄ±mÄ± destekler, herhangi bir deÄŸiÅŸiklik ve tÃ¼rev Ã§alÄ±ÅŸmaya, distilasyon dahil ancak bununla sÄ±nÄ±rlÄ± olmamak Ã¼zere, izin verir. LÃ¼tfen dikkat edin:
- DeepSeek-R1-Distill-Qwen-1.5B, DeepSeek-R1-Distill-Qwen-7B, DeepSeek-R1-Distill-Qwen-14B ve DeepSeek-R1-Distill-Qwen-32B, [Qwen-2.5 serisi](https://github.com/QwenLM/Qwen2.5) tabanlÄ±dÄ±r, baÅŸlangÄ±Ã§ta [Apache 2.0 LisansÄ±](https://huggingface.co/Qwen/Qwen2.5-1.5B/blob/main/LICENSE) ile lisanslanmÄ±ÅŸtÄ±r ve ÅŸimdi DeepSeek-R1 ile derlenmiÅŸ 800k Ã¶rnek ile ince ayar yapÄ±lmÄ±ÅŸtÄ±r.
- DeepSeek-R1-Distill-Llama-8B, Llama3.1-8B-Base tabanlÄ±dÄ±r ve baÅŸlangÄ±Ã§ta [Llama3.1 lisansÄ±](https://huggingface.co/meta-llama/Llama-3.1-8B/blob/main/LICENSE) ile lisanslanmÄ±ÅŸtÄ±r.
- DeepSeek-R1-Distill-Llama-70B, Llama3.3-70B-Instruct tabanlÄ±dÄ±r ve baÅŸlangÄ±Ã§ta [Llama3.3 lisansÄ±](https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct/blob/main/LICENSE) ile lisanslanmÄ±ÅŸtÄ±r.

## 8. AtÄ±f
```bibtex
@misc{deepseekai2025deepseekr1incentivizingreasoningcapability,
      title={DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning}, 
      author={DeepSeek-AI},
      year={2025},
      eprint={2501.12948},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2501.12948}, 
}
```

## 9. Ä°letiÅŸim
Herhangi bir sorunuz varsa, lÃ¼tfen bir issue aÃ§Ä±n veya bizimle [service@deepseek.com](mailto:service@deepseek.com) adresinden iletiÅŸime geÃ§in.

---

[Powered By OpenAiTx](https://github.com/OpenAiTx/OpenAiTx)

---