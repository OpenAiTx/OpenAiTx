# DeepSeek-R1
<!-- markdownlint-disable first-line-h1 -->
<!-- markdownlint-disable html -->
<!-- markdownlint-disable no-duplicate-header -->

<div align="center">
  <img src="https://github.com/deepseek-ai/DeepSeek-V2/blob/main/figures/logo.svg?raw=true" width="60%" alt="DeepSeek-R1" />
</div>
<hr>
<div align="center" style="line-height: 1;">
  <a href="https://www.deepseek.com/" target="_blank"><img alt="Homepage"
    src="https://github.com/deepseek-ai/DeepSeek-V2/blob/main/figures/badge.svg?raw=true"/></a>
  <a href="https://chat.deepseek.com/" target="_blank"><img alt="Chat"
    src="https://img.shields.io/badge/ğŸ¤–%20Chat-DeepSeek%20R1-536af5?color=536af5&logoColor=white"/></a>
  <a href="https://huggingface.co/deepseek-ai" target="_blank"><img alt="Hugging Face"
    src="https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-DeepSeek%20AI-ffc107?color=ffc107&logoColor=white"/></a>
  <br>
  <a href="https://discord.gg/Tc7c45Zzu5" target="_blank"><img alt="Discord"
    src="https://img.shields.io/badge/Discord-DeepSeek%20AI-7289da?logo=discord&logoColor=white&color=7289da"/></a>
  <a href="https://github.com/deepseek-ai/DeepSeek-V2/blob/main/figures/qr.jpeg?raw=true" target="_blank"><img alt="WeChat"
    src="https://img.shields.io/badge/WeChat-DeepSeek%20AI-brightgreen?logo=wechat&logoColor=white"/></a>
  <a href="https://twitter.com/deepseek_ai" target="_blank"><img alt="Twitter Follow"
    src="https://img.shields.io/badge/Twitter-deepseek_ai-white?logo=x&logoColor=white"/></a>
  <br>
  <a href="https://github.com/deepseek-ai/DeepSeek-R1/blob/main/LICENSE"><img alt="License"
    src="https://img.shields.io/badge/License-MIT-f5de53?&color=f5de53"/></a>
  <br>
  <a href="https://github.com/deepseek-ai/DeepSeek-R1/blob/main/DeepSeek_R1.pdf"><b>Paper Link</b>ğŸ‘ï¸</a>
</div>

## 1. Wprowadzenie

Przedstawiamy nasze modele pierwszej generacji do rozumowania: DeepSeek-R1-Zero oraz DeepSeek-R1.
DeepSeek-R1-Zero, model trenowany w oparciu o wielkoskalowe uczenie ze wzmocnieniem (RL) bez wstÄ™pnego nadzorowanego dostrajania (SFT), wykazaÅ‚ znakomitÄ… wydajnoÅ›Ä‡ w zadaniach wymagajÄ…cych rozumowania.
DziÄ™ki RL, DeepSeek-R1-Zero naturalnie przejawiaÅ‚ liczne potÄ™Å¼ne i interesujÄ…ce zachowania zwiÄ…zane z rozumowaniem.
JednakÅ¼e DeepSeek-R1-Zero napotykaÅ‚ wyzwania takie jak niekoÅ„czÄ…ce siÄ™ powtarzanie, niska czytelnoÅ›Ä‡ oraz mieszanie jÄ™zykÃ³w. Aby rozwiÄ…zaÄ‡ te problemy i dodatkowo zwiÄ™kszyÄ‡ wydajnoÅ›Ä‡ w rozumowaniu,
wprowadzamy DeepSeek-R1, ktÃ³ry uwzglÄ™dnia dane z zimnego startu przed RL.
DeepSeek-R1 osiÄ…ga wydajnoÅ›Ä‡ porÃ³wnywalnÄ… z OpenAI-o1 w zadaniach matematycznych, kodowania i rozumowania.
Aby wesprzeÄ‡ spoÅ‚ecznoÅ›Ä‡ naukowÄ…, otworzyliÅ›my kod DeepSeek-R1-Zero, DeepSeek-R1 oraz szeÅ›ciu gÄ™stych modeli destylowanych z DeepSeek-R1 na bazie Llama i Qwen. DeepSeek-R1-Distill-Qwen-32B przewyÅ¼sza OpenAI-o1-mini w rÃ³Å¼nych benchmarkach, osiÄ…gajÄ…c nowe rekordy dla gÄ™stych modeli.

**UWAGA: Przed uruchomieniem modeli z serii DeepSeek-R1 lokalnie, zalecamy zapoznanie siÄ™ z sekcjÄ… [Rekomendacje uÅ¼ytkowania](#usage-recommendations).**

<p align="center">
  <img width="80%" src="figures/benchmark.jpg">
</p>

## 2. Podsumowanie modelu

---

**Trenowanie poÅ›rednie: Wielkoskalowe uczenie ze wzmocnieniem na modelu bazowym**

-  BezpoÅ›rednio stosujemy uczenie ze wzmocnieniem (RL) na modelu bazowym bez polegania na nadzorowanym dostrajaniu (SFT) jako kroku wstÄ™pnego. Takie podejÅ›cie pozwala modelowi eksplorowaÄ‡ Å‚aÅ„cuchy rozumowania (CoT) do rozwiÄ…zywania zÅ‚oÅ¼onych problemÃ³w, co zaowocowaÅ‚o powstaniem DeepSeek-R1-Zero. DeepSeek-R1-Zero wykazuje umiejÄ™tnoÅ›ci takie jak autoweryfikacja, refleksja i generowanie dÅ‚ugich Å‚aÅ„cuchÃ³w rozumowania, co stanowi istotny kamieÅ„ milowy dla spoÅ‚ecznoÅ›ci badawczej. Co waÅ¼ne, jest to pierwsze otwarte badanie, ktÃ³re potwierdza, Å¼e zdolnoÅ›ci rozumowania LLM mogÄ… byÄ‡ motywowane wyÅ‚Ä…cznie przez RL, bez koniecznoÅ›ci stosowania SFT. To przeÅ‚omowe osiÄ…gniÄ™cie otwiera drogÄ™ do dalszego rozwoju w tej dziedzinie.

-   Wprowadzamy nasz pipeline do rozwoju DeepSeek-R1. Pipeline obejmuje dwa etapy RL majÄ…ce na celu odkrycie ulepszonych wzorcÃ³w rozumowania i dostosowanie do preferencji uÅ¼ytkownikÃ³w, a takÅ¼e dwa etapy SFT, ktÃ³re stanowiÄ… bazÄ™ do rozumowania i innych umiejÄ™tnoÅ›ci modelu.
    Wierzymy, Å¼e pipeline przyniesie korzyÅ›ci branÅ¼y poprzez tworzenie lepszych modeli.

---

**Destylacja: Mniejsze modele mogÄ… byÄ‡ rÃ³wnieÅ¼ potÄ™Å¼ne**

-  Pokazujemy, Å¼e wzorce rozumowania wiÄ™kszych modeli mogÄ… byÄ‡ destylowane do mniejszych modeli, co skutkuje lepszÄ… wydajnoÅ›ciÄ… niÅ¼ te odkryte przez RL na maÅ‚ych modelach. OtwartoÅºrÃ³dÅ‚owy DeepSeek-R1, jak rÃ³wnieÅ¼ jego API, umoÅ¼liwi spoÅ‚ecznoÅ›ci naukowej destylacjÄ™ jeszcze lepszych maÅ‚ych modeli w przyszÅ‚oÅ›ci.
- WykorzystujÄ…c dane rozumowania wygenerowane przez DeepSeek-R1, dostroiliÅ›my kilka gÄ™stych modeli szeroko stosowanych w spoÅ‚ecznoÅ›ci naukowej. Wyniki ewaluacji pokazujÄ…, Å¼e destylowane mniejsze modele gÄ™ste wypadajÄ… wyjÄ…tkowo dobrze na benchmarkach. UdostÄ™pniamy otwarte checkpointy 1.5B, 7B, 8B, 14B, 32B oraz 70B bazujÄ…ce na Qwen2.5 i Llama3 dla spoÅ‚ecznoÅ›ci.

## 3. Pobieranie modeli

### Modele DeepSeek-R1

<div align="center">

| **Model** | **#ÅÄ…czna liczba parametrÃ³w** | **#Aktywowane parametry** | **DÅ‚ugoÅ›Ä‡ kontekstu** | **Pobierz** |
| :------------: | :------------: | :------------: | :------------: | :------------: |
| DeepSeek-R1-Zero | 671B | 37B | 128K   | [ğŸ¤— HuggingFace](https://huggingface.co/deepseek-ai/DeepSeek-R1-Zero)   |
| DeepSeek-R1   | 671B | 37B |  128K   | [ğŸ¤— HuggingFace](https://huggingface.co/deepseek-ai/DeepSeek-R1)   |

</div>

DeepSeek-R1-Zero i DeepSeek-R1 sÄ… trenowane na bazie DeepSeek-V3-Base.
WiÄ™cej informacji o architekturze modelu znajduje siÄ™ w repozytorium [DeepSeek-V3](https://github.com/deepseek-ai/DeepSeek-V3).

### Modele DeepSeek-R1-Distill

<div align="center">

| **Model** | **Model bazowy** | **Pobierz** |
| :------------: | :------------: | :------------: |
| DeepSeek-R1-Distill-Qwen-1.5B  | [Qwen2.5-Math-1.5B](https://huggingface.co/Qwen/Qwen2.5-Math-1.5B) | [ğŸ¤— HuggingFace](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B)   |
| DeepSeek-R1-Distill-Qwen-7B  | [Qwen2.5-Math-7B](https://huggingface.co/Qwen/Qwen2.5-Math-7B) | [ğŸ¤— HuggingFace](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B)   |
| DeepSeek-R1-Distill-Llama-8B  | [Llama-3.1-8B](https://huggingface.co/meta-llama/Llama-3.1-8B) | [ğŸ¤— HuggingFace](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-8B)   |
| DeepSeek-R1-Distill-Qwen-14B   | [Qwen2.5-14B](https://huggingface.co/Qwen/Qwen2.5-14B) | [ğŸ¤— HuggingFace](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-14B)   |
|DeepSeek-R1-Distill-Qwen-32B  | [Qwen2.5-32B](https://huggingface.co/Qwen/Qwen2.5-32B) | [ğŸ¤— HuggingFace](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-32B)   |
| DeepSeek-R1-Distill-Llama-70B  | [Llama-3.3-70B-Instruct](https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct) | [ğŸ¤— HuggingFace](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-70B)   |

</div>

Modele DeepSeek-R1-Distill sÄ… dostrajane na bazie modeli otwartoÅºrÃ³dÅ‚owych, wykorzystujÄ…c prÃ³bki wygenerowane przez DeepSeek-R1.
Lekko zmieniamy ich konfiguracje oraz tokenizery. Prosimy uÅ¼ywaÄ‡ naszych ustawieÅ„ do uruchamiania tych modeli.

## 4. Wyniki ewaluacji

### DeepSeek-R1-Evaluation
 Dla wszystkich naszych modeli maksymalna dÅ‚ugoÅ›Ä‡ generowanego tekstu zostaÅ‚a ustawiona na 32 768 tokenÃ³w. Dla benchmarkÃ³w wymagajÄ…cych prÃ³bkowania stosujemy temperaturÄ™ $0.6$, wartoÅ›Ä‡ top-p $0.95$ oraz generujemy 64 odpowiedzi na zapytanie, by oszacowaÄ‡ pass@1.
<div align="center">


| Kategoria | Benchmark (Metryka) | Claude-3.5-Sonnet-1022 | GPT-4o 0513 | DeepSeek V3 | OpenAI o1-mini | OpenAI o1-1217 | DeepSeek R1 |
|----------|-------------------|----------------------|------------|--------------|----------------|------------|--------------|
| | Architektura | - | - | MoE | - | - | MoE |
| | # Aktywowane parametry | - | - | 37B | - | - | 37B |
| | # ÅÄ…czna liczba parametrÃ³w | - | - | 671B | - | - | 671B |
| Angielski | MMLU (Pass@1) | 88.3 | 87.2 | 88.5 | 85.2 | **91.8** | 90.8 |
| | MMLU-Redux (EM) | 88.9 | 88.0 | 89.1 | 86.7 | - | **92.9** |
| | MMLU-Pro (EM) | 78.0 | 72.6 | 75.9 | 80.3 | - | **84.0** |
| | DROP (3-shot F1) | 88.3 | 83.7 | 91.6 | 83.9 | 90.2 | **92.2** |
| | IF-Eval (Prompt Strict) | **86.5** | 84.3 | 86.1 | 84.8 | - | 83.3 |
| | GPQA-Diamond (Pass@1) | 65.0 | 49.9 | 59.1 | 60.0 | **75.7** | 71.5 |
| | SimpleQA (Correct) | 28.4 | 38.2 | 24.9 | 7.0 | **47.0** | 30.1 |
| | FRAMES (Acc.) | 72.5 | 80.5 | 73.3 | 76.9 | - | **82.5** |
| | AlpacaEval2.0 (LC-winrate) | 52.0 | 51.1 | 70.0 | 57.8 | - | **87.6** |
| | ArenaHard (GPT-4-1106) | 85.2 | 80.4 | 85.5 | 92.0 | - | **92.3** |
| Kod | LiveCodeBench (Pass@1-COT) | 33.8 | 34.2 | - | 53.8 | 63.4 | **65.9** |
| | Codeforces (Percentyl) | 20.3 | 23.6 | 58.7 | 93.4 | **96.6** | 96.3 |
| | Codeforces (Rating) | 717 | 759 | 1134 | 1820 | **2061** | 2029 |
| | SWE Verified (Resolved) | **50.8** | 38.8 | 42.0 | 41.6 | 48.9 | 49.2 |
| | Aider-Polyglot (Acc.) | 45.3 | 16.0 | 49.6 | 32.9 | **61.7** | 53.3 |
| Matematyka | AIME 2024 (Pass@1) | 16.0 | 9.3 | 39.2 | 63.6 | 79.2 | **79.8** |
| | MATH-500 (Pass@1) | 78.3 | 74.6 | 90.2 | 90.0 | 96.4 | **97.3** |
| | CNMO 2024 (Pass@1) | 13.1 | 10.8 | 43.2 | 67.6 | - | **78.8** |
| ChiÅ„ski | CLUEWSC (EM) | 85.4 | 87.9 | 90.9 | 89.9 | - | **92.8** |
| | C-Eval (EM) | 76.7 | 76.0 | 86.5 | 68.9 | - | **91.8** |
| | C-SimpleQA (Correct) | 55.4 | 58.7 | **68.0** | 40.3 | - | 63.7 |

</div>


### Ewaluacja modeli destylowanych

<div align="center">

| Model                                    | AIME 2024 pass@1 | AIME 2024 cons@64 | MATH-500 pass@1 | GPQA Diamond pass@1 | LiveCodeBench pass@1 | CodeForces rating |
|------------------------------------------|------------------|-------------------|-----------------|----------------------|----------------------|-------------------|
| GPT-4o-0513                          | 9.3              | 13.4              | 74.6            | 49.9                 | 32.9                 | 759               |
| Claude-3.5-Sonnet-1022             | 16.0             | 26.7                 | 78.3            | 65.0                 | 38.9                 | 717               |
| o1-mini                              | 63.6             | 80.0              | 90.0            | 60.0                 | 53.8                 | **1820**          |
| QwQ-32B-Preview                              | 44.0             | 60.0                 | 90.6            | 54.5               | 41.9                 | 1316              |
| DeepSeek-R1-Distill-Qwen-1.5B       | 28.9             | 52.7              | 83.9            | 33.8                 | 16.9                 | 954               |
| DeepSeek-R1-Distill-Qwen-7B          | 55.5             | 83.3              | 92.8            | 49.1                 | 37.6                 | 1189              |
| DeepSeek-R1-Distill-Qwen-14B         | 69.7             | 80.0              | 93.9            | 59.1                 | 53.1                 | 1481              |
| DeepSeek-R1-Distill-Qwen-32B        | **72.6**         | 83.3              | 94.3            | 62.1                 | 57.2                 | 1691              |
| DeepSeek-R1-Distill-Llama-8B         | 50.4             | 80.0              | 89.1            | 49.0                 | 39.6                 | 1205              |
| DeepSeek-R1-Distill-Llama-70B        | 70.0             | **86.7**          | **94.5**        | **65.2**             | **57.5**             | 1633              |

</div>


## 5. Strona czatu & Platforma API
MoÅ¼esz rozmawiaÄ‡ z DeepSeek-R1 na oficjalnej stronie DeepSeek: [chat.deepseek.com](https://chat.deepseek.com) i przeÅ‚Ä…czyÄ‡ przycisk "DeepThink".

Oferujemy takÅ¼e API kompatybilne z OpenAI na platformie DeepSeek: [platform.deepseek.com](https://platform.deepseek.com/)

## 6. Jak uruchomiÄ‡ lokalnie

### Modele DeepSeek-R1

Prosimy odwiedziÄ‡ repozytorium [DeepSeek-V3](https://github.com/deepseek-ai/DeepSeek-V3), aby uzyskaÄ‡ wiÄ™cej informacji o lokalnym uruchamianiu DeepSeek-R1.

**UWAGA: Transformers od Hugging Face nie sÄ… jeszcze bezpoÅ›rednio wspierane.**

### Modele DeepSeek-R1-Distill

Modele DeepSeek-R1-Distill moÅ¼na wykorzystywaÄ‡ w taki sam sposÃ³b jak modele Qwen lub Llama.

Na przykÅ‚ad, moÅ¼na Å‚atwo uruchomiÄ‡ usÅ‚ugÄ™ uÅ¼ywajÄ…c [vLLM](https://github.com/vllm-project/vllm):

```shell
vllm serve deepseek-ai/DeepSeek-R1-Distill-Qwen-32B --tensor-parallel-size 2 --max-model-len 32768 --enforce-eager
```

MoÅ¼esz takÅ¼e Å‚atwo uruchomiÄ‡ usÅ‚ugÄ™ uÅ¼ywajÄ…c [SGLang](https://github.com/sgl-project/sglang)

```bash
python3 -m sglang.launch_server --model deepseek-ai/DeepSeek-R1-Distill-Qwen-32B --trust-remote-code --tp 2
```

### Rekomendacje uÅ¼ytkowania

**Zalecamy stosowanie siÄ™ do poniÅ¼szych konfiguracji podczas korzystania z modeli z serii DeepSeek-R1, w tym podczas benchmarkÃ³w, aby osiÄ…gnÄ…Ä‡ oczekiwane wyniki:**

1. Ustaw temperaturÄ™ w zakresie 0.5-0.7 (zalecane 0.6), aby zapobiec niekoÅ„czÄ…cym siÄ™ powtÃ³rzeniom lub niespÃ³jnym wyjÅ›ciom.
2. **Unikaj dodawania promptu systemowego; wszystkie instrukcje powinny byÄ‡ zawarte w promptcie uÅ¼ytkownika.**
3. W przypadku zadaÅ„ matematycznych zaleca siÄ™ dodanie do promptu dyrektywy np.: "ProszÄ™ rozumowaÄ‡ krok po kroku i umieÅ›ciÄ‡ ostatecznÄ… odpowiedÅº w \boxed{}."
4. Podczas oceny wydajnoÅ›ci modelu zaleca siÄ™ przeprowadzenie kilku testÃ³w i uÅ›rednienie wynikÃ³w.

Dodatkowo zaobserwowaliÅ›my, Å¼e modele z serii DeepSeek-R1 majÄ… tendencjÄ™ do pomijania wzorca myÅ›lenia (tj. wypisywania "\<think\>\n\n\</think\>") przy odpowiadaniu na niektÃ³re zapytania, co moÅ¼e negatywnie wpÅ‚ywaÄ‡ na wydajnoÅ›Ä‡ modelu.
**Aby zapewniÄ‡, Å¼e model angaÅ¼uje siÄ™ w rozumowanie, zalecamy wymuszanie, aby model rozpoczynaÅ‚ swojÄ… odpowiedÅº od "\<think\>\n" na poczÄ…tku kaÅ¼dego wyjÅ›cia.**

### Oficjalne prompty
W oficjalnej stronie/aplikacji DeepSeek nie uÅ¼ywamy promptÃ³w systemowych, lecz projektujemy dwa konkretne prompty do uploadu plikÃ³w i wyszukiwania w sieci dla lepszych doÅ›wiadczeÅ„ uÅ¼ytkownika. Dodatkowo temperatura w web/aplikacji wynosi 0.6.

Dla uploadu pliku, prosimy korzystaÄ‡ ze wzoru promptu, gdzie {file_name}, {file_content} oraz {question} sÄ… argumentami.
```
file_template = \
"""[file name]: {file_name}
[file content begin]
{file_content}
[file content end]
{question}"""
```

Dla wyszukiwania w sieci, {search_results}, {cur_date} oraz {question} sÄ… argumentami.

Dla zapytaÅ„ po chiÅ„sku uÅ¼ywamy promptu:
```
search_answer_zh_template = \
'''# ä»¥ä¸‹å†…å®¹æ˜¯åŸºäºç”¨æˆ·å‘é€çš„æ¶ˆæ¯çš„æœç´¢ç»“æœ:
{search_results}
åœ¨æˆ‘ç»™ä½ çš„æœç´¢ç»“æœä¸­ï¼Œæ¯ä¸ªç»“æœéƒ½æ˜¯[webpage X begin]...[webpage X end]æ ¼å¼çš„ï¼ŒXä»£è¡¨æ¯ç¯‡æ–‡ç« çš„æ•°å­—ç´¢å¼•ã€‚è¯·åœ¨é€‚å½“çš„æƒ…å†µä¸‹åœ¨å¥å­æœ«å°¾å¼•ç”¨ä¸Šä¸‹æ–‡ã€‚è¯·æŒ‰ç…§å¼•ç”¨ç¼–å·[citation:X]çš„æ ¼å¼åœ¨ç­”æ¡ˆä¸­å¯¹åº”éƒ¨åˆ†å¼•ç”¨ä¸Šä¸‹æ–‡ã€‚å¦‚æœä¸€å¥è¯æºè‡ªå¤šä¸ªä¸Šä¸‹æ–‡ï¼Œè¯·åˆ—å‡ºæ‰€æœ‰ç›¸å…³çš„å¼•ç”¨ç¼–å·ï¼Œä¾‹å¦‚[citation:3][citation:5]ï¼Œåˆ‡è®°ä¸è¦å°†å¼•ç”¨é›†ä¸­åœ¨æœ€åè¿”å›å¼•ç”¨ç¼–å·ï¼Œè€Œæ˜¯åœ¨ç­”æ¡ˆå¯¹åº”éƒ¨åˆ†åˆ—å‡ºã€‚
åœ¨å›ç­”æ—¶ï¼Œè¯·æ³¨æ„ä»¥ä¸‹å‡ ç‚¹ï¼š
- ä»Šå¤©æ˜¯{cur_date}ã€‚
- å¹¶éæœç´¢ç»“æœçš„æ‰€æœ‰å†…å®¹éƒ½ä¸ç”¨æˆ·çš„é—®é¢˜å¯†åˆ‡ç›¸å…³ï¼Œä½ éœ€è¦ç»“åˆé—®é¢˜ï¼Œå¯¹æœç´¢ç»“æœè¿›è¡Œç”„åˆ«ã€ç­›é€‰ã€‚
- å¯¹äºåˆ—ä¸¾ç±»çš„é—®é¢˜ï¼ˆå¦‚åˆ—ä¸¾æ‰€æœ‰èˆªç­ä¿¡æ¯ï¼‰ï¼Œå°½é‡å°†ç­”æ¡ˆæ§åˆ¶åœ¨10ä¸ªè¦ç‚¹ä»¥å†…ï¼Œå¹¶å‘Šè¯‰ç”¨æˆ·å¯ä»¥æŸ¥çœ‹æœç´¢æ¥æºã€è·å¾—å®Œæ•´ä¿¡æ¯ã€‚ä¼˜å…ˆæä¾›ä¿¡æ¯å®Œæ•´ã€æœ€ç›¸å…³çš„åˆ—ä¸¾é¡¹ï¼›å¦‚éå¿…è¦ï¼Œä¸è¦ä¸»åŠ¨å‘Šè¯‰ç”¨æˆ·æœç´¢ç»“æœæœªæä¾›çš„å†…å®¹ã€‚
- å¯¹äºåˆ›ä½œç±»çš„é—®é¢˜ï¼ˆå¦‚å†™è®ºæ–‡ï¼‰ï¼Œè¯·åŠ¡å¿…åœ¨æ­£æ–‡çš„æ®µè½ä¸­å¼•ç”¨å¯¹åº”çš„å‚è€ƒç¼–å·ï¼Œä¾‹å¦‚[citation:3][citation:5]ï¼Œä¸èƒ½åªåœ¨æ–‡ç« æœ«å°¾å¼•ç”¨ã€‚ä½ éœ€è¦è§£è¯»å¹¶æ¦‚æ‹¬ç”¨æˆ·çš„é¢˜ç›®è¦æ±‚ï¼Œé€‰æ‹©åˆé€‚çš„æ ¼å¼ï¼Œå……åˆ†åˆ©ç”¨æœç´¢ç»“æœå¹¶æŠ½å–é‡è¦ä¿¡æ¯ï¼Œç”Ÿæˆç¬¦åˆç”¨æˆ·è¦æ±‚ã€æå…·æ€æƒ³æ·±åº¦ã€å¯Œæœ‰åˆ›é€ åŠ›ä¸ä¸“ä¸šæ€§çš„ç­”æ¡ˆã€‚ä½ çš„åˆ›ä½œç¯‡å¹…éœ€è¦å°½å¯èƒ½å»¶é•¿ï¼Œå¯¹äºæ¯ä¸€ä¸ªè¦ç‚¹çš„è®ºè¿°è¦æ¨æµ‹ç”¨æˆ·çš„æ„å›¾ï¼Œç»™å‡ºå°½å¯èƒ½å¤šè§’åº¦çš„å›ç­”è¦ç‚¹ï¼Œä¸”åŠ¡å¿…ä¿¡æ¯é‡å¤§ã€è®ºè¿°è¯¦å°½ã€‚
- å¦‚æœå›ç­”å¾ˆé•¿ï¼Œè¯·å°½é‡ç»“æ„åŒ–ã€åˆ†æ®µè½æ€»ç»“ã€‚å¦‚æœéœ€è¦åˆ†ç‚¹ä½œç­”ï¼Œå°½é‡æ§åˆ¶åœ¨5ä¸ªç‚¹ä»¥å†…ï¼Œå¹¶åˆå¹¶ç›¸å…³çš„å†…å®¹ã€‚
- å¯¹äºå®¢è§‚ç±»çš„é—®ç­”ï¼Œå¦‚æœé—®é¢˜çš„ç­”æ¡ˆéå¸¸ç®€çŸ­ï¼Œå¯ä»¥é€‚å½“è¡¥å……ä¸€åˆ°ä¸¤å¥ç›¸å…³ä¿¡æ¯ï¼Œä»¥ä¸°å¯Œå†…å®¹ã€‚
- ä½ éœ€è¦æ ¹æ®ç”¨æˆ·è¦æ±‚å’Œå›ç­”å†…å®¹é€‰æ‹©åˆé€‚ã€ç¾è§‚çš„å›ç­”æ ¼å¼ï¼Œç¡®ä¿å¯è¯»æ€§å¼ºã€‚
- ä½ çš„å›ç­”åº”è¯¥ç»¼åˆå¤šä¸ªç›¸å…³ç½‘é¡µæ¥å›ç­”ï¼Œä¸èƒ½é‡å¤å¼•ç”¨ä¸€ä¸ªç½‘é¡µã€‚
- é™¤éç”¨æˆ·è¦æ±‚ï¼Œå¦åˆ™ä½ å›ç­”çš„è¯­è¨€éœ€è¦å’Œç”¨æˆ·æé—®çš„è¯­è¨€ä¿æŒä¸€è‡´ã€‚

# ç”¨æˆ·æ¶ˆæ¯ä¸ºï¼š
{question}'''
```

Dla zapytaÅ„ po angielsku uÅ¼ywamy promptu:
```
search_answer_en_template = \
'''# The following contents are the search results related to the user's message:
{search_results}
In the search results I provide to you, each result is formatted as [webpage X begin]...[webpage X end], where X represents the numerical index of each article. Please cite the context at the end of the relevant sentence when appropriate. Use the citation format [citation:X] in the corresponding part of your answer. If a sentence is derived from multiple contexts, list all relevant citation numbers, such as [citation:3][citation:5]. Be sure not to cluster all citations at the end; instead, include them in the corresponding parts of the answer.
When responding, please keep the following points in mind:
- Today is {cur_date}.
- Not all content in the search results is closely related to the user's question. You need to evaluate and filter the search results based on the question.
- For listing-type questions (e.g., listing all flight information), try to limit the answer to 10 key points and inform the user that they can refer to the search sources for complete information. Prioritize providing the most complete and relevant items in the list. Avoid mentioning content not provided in the search results unless necessary.
- For creative tasks (e.g., writing an essay), ensure that references are cited within the body of the text, such as [citation:3][citation:5], rather than only at the end of the text. You need to interpret and summarize the user's requirements, choose an appropriate format, fully utilize the search results, extract key information, and generate an answer that is insightful, creative, and professional. Extend the length of your response as much as possible, addressing each point in detail and from multiple perspectives, ensuring the content is rich and thorough.
- If the response is lengthy, structure it well and summarize it in paragraphs. If a point-by-point format is needed, try to limit it to 5 points and merge related content.
- For objective Q&A, if the answer is very brief, you may add one or two related sentences to enrich the content.
- Choose an appropriate and visually appealing format for your response based on the user's requirements and the content of the answer, ensuring strong readability.
- Your answer should synthesize information from multiple relevant webpages and avoid repeatedly citing the same webpage.
- Unless the user requests otherwise, your response should be in the same language as the user's question.

# The user's message is:
{question}'''
```

## 7. Licencja
To repozytorium kodu i wagi modeli sÄ… licencjonowane na zasadach [Licencji MIT](https://github.com/deepseek-ai/DeepSeek-R1/blob/main/LICENSE).
Seria DeepSeek-R1 wspiera komercyjne wykorzystanie, pozwala na dowolne modyfikacje oraz prace pochodne, w tym, ale nie tylko, destylacjÄ™ do treningu innych LLM. Prosimy zauwaÅ¼yÄ‡:
- DeepSeek-R1-Distill-Qwen-1.5B, DeepSeek-R1-Distill-Qwen-7B, DeepSeek-R1-Distill-Qwen-14B i DeepSeek-R1-Distill-Qwen-32B sÄ… pochodnymi [serii Qwen-2.5](https://github.com/QwenLM/Qwen2.5), ktÃ³ra jest oryginalnie licencjonowana na zasadach [Licencji Apache 2.0](https://huggingface.co/Qwen/Qwen2.5-1.5B/blob/main/LICENSE) i obecnie dostrojona na 800k prÃ³bkach wyselekcjonowanych przez DeepSeek-R1.
- DeepSeek-R1-Distill-Llama-8B pochodzi z Llama3.1-8B-Base i jest oryginalnie licencjonowany na zasadach [licencji Llama3.1](https://huggingface.co/meta-llama/Llama-3.1-8B/blob/main/LICENSE).
- DeepSeek-R1-Distill-Llama-70B pochodzi z Llama3.3-70B-Instruct i jest oryginalnie licencjonowany na zasadach [licencji Llama3.3](https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct/blob/main/LICENSE).

## 8. Cytowanie
```bibtex
@misc{deepseekai2025deepseekr1incentivizingreasoningcapability,
      title={DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning}, 
      author={DeepSeek-AI},
      year={2025},
      eprint={2501.12948},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2501.12948}, 
}
```

## 9. Kontakt
JeÅ›li masz jakiekolwiek pytania, zgÅ‚oÅ› issue lub skontaktuj siÄ™ z nami pod adresem [service@deepseek.com](mailto:service@deepseek.com).

---

[Powered By OpenAiTx](https://github.com/OpenAiTx/OpenAiTx)

---