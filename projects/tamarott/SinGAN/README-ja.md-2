{
  "id": 2,
  "origin": "\n```\nboth the masked and unmasked output will be saved.\nHere as well, different injection scale will produce different editing effects. The coarsest injection scale equals 1. \n\n###  Paint to Image\n\nTo transfer a paint into a realistic image (See example in Fig. 11 in [our paper](https://arxiv.org/pdf/1905.01164.pdf)), please first train SinGAN model on the desired image (as described above), then save your paint under \"Input/Paint\", and run the command\n\n```\npython paint2image.py --input_name <training_image_file_name> --ref_name <paint_image_file_name> --paint_start_scale <scale to inject>\n\n```\nHere as well, different injection scale will produce different editing effects. The coarsest injection scale equals 1. \n\nAdvanced option: Specify quantization_flag to be True, to re-train *only* the injection level of the model, to get a on a color-quantized version of upsampled generated images from the previous scale. For some images, this might lead to more realistic results.\n\n### Super Resolution\nTo super resolve an image, please run:\n```\npython SR.py --input_name <LR_image_file_name>\n```\nThis will automatically train a SinGAN model correspond to 4x upsampling factor (if not exist already).\nFor different SR factors, please specify it using the parameter `--sr_factor` when calling the function.\nSinGAN's results on the BSD100 dataset can be download from the 'Downloads' folder.\n\n## Additional Data and Functions\n\n### Single Image Fréchet Inception Distance (SIFID score)\nTo calculate the SIFID between real images and their corresponding fake samples, please run:\n```\npython SIFID/sifid_score.py --path2real <real images path> --path2fake <fake images path> \n```  \nMake sure that each of the fake images file name is identical to its corresponding real image file name. Images should be saved in `.jpg` format.\n\n### Super Resolution Results\nSinGAN's SR results on the BSD100 dataset can be download from the 'Downloads' folder.\n\n### User Study\nThe data used for the user study can be found in the Downloads folder. \n\nreal folder: 50 real images, randomly picked from the [places database](http://places.csail.mit.edu/)\n\nfake_high_variance folder: random samples starting from n=N for each of the real images \n\nfake_mid_variance folder: random samples starting from n=N-1 for each of the real images \n\nFor additional details please see section 3.1 in our [paper](https://arxiv.org/pdf/1905.01164.pdf)\n",
  "origin_sha": "v2Hr70I0nZ4UNa7ZnNNQt5KYkmsFYj4x/0oM9zwQ87g=",
  "translate": "```\nマスクありおよびマスクなしの出力の両方が保存されます。\nここでも、異なるインジェクションスケールは異なる編集効果をもたらします。最も粗いインジェクションスケールは1です。\n\n###  Paint to Image\n\nペイントをリアルな画像に変換するには（[論文](https://arxiv.org/pdf/1905.01164.pdf)のFig. 11を参照）、まず希望する画像でSinGANモデルをトレーニングしてください（上記の説明参照）。その後、「Input/Paint」にペイント画像を保存し、以下のコマンドを実行します。\n\n```\npython paint2image.py --input_name <training_image_file_name> --ref_name <paint_image_file_name> --paint_start_scale <scale to inject>\n```\nここでも、異なるインジェクションスケールは異なる編集効果をもたらします。最も粗いインジェクションスケールは1です。\n\n高度なオプション: quantization_flagをTrueに指定すると、モデルのインジェクションレベル*のみ*を再学習し、前のスケールからアップサンプリングされた生成画像の色量子化バージョンを取得します。一部の画像では、これによりよりリアルな結果が得られる場合があります。\n\n### 超解像\n画像を超解像するには、次のコマンドを実行してください:\n```\npython SR.py --input_name <LR_image_file_name>\n```\nこれにより、SinGANモデルが自動的に4倍のアップサンプリングファクターに対応してトレーニングされます（まだ存在しない場合）。\n異なるSRファクターの場合、関数呼び出し時にパラメータ `--sr_factor` を指定してください。\nSinGANのBSD100データセットにおける結果は「Downloads」フォルダからダウンロードできます。\n\n## 追加データおよび機能\n\n### Single Image Fréchet Inception Distance（SIFIDスコア）\n実画像と対応する偽サンプル間のSIFIDを計算するには、次を実行してください:\n```\npython SIFID/sifid_score.py --path2real <real images path> --path2fake <fake images path> \n```  \n各偽画像ファイル名が対応する実画像ファイル名と同一であることを確認してください。画像は`.jpg`形式で保存してください。\n\n### 超解像結果\nSinGANのBSD100データセットにおけるSR結果は「Downloads」フォルダからダウンロードできます。\n\n### ユーザースタディ\nユーザースタディで使用されたデータはDownloadsフォルダにあります。\n\nrealフォルダ： [places database](http://places.csail.mit.edu/)からランダムに選ばれた50枚の実画像\n\nfake_high_varianceフォルダ： 各実画像についてn=Nから開始したランダムサンプル\n\nfake_mid_varianceフォルダ： 各実画像についてn=N-1から開始したランダムサンプル\n\n詳細については、[論文](https://arxiv.org/pdf/1905.01164.pdf)のセクション3.1を参照してください。\n```",
  "status": "ok"
}