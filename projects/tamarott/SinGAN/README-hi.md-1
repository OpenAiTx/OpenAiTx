{
  "id": 1,
  "origin": "# SinGAN\n\n[Project](https://tamarott.github.io/SinGAN.htm) | [Arxiv](https://arxiv.org/pdf/1905.01164.pdf) | [CVF](http://openaccess.thecvf.com/content_ICCV_2019/papers/Shaham_SinGAN_Learning_a_Generative_Model_From_a_Single_Natural_Image_ICCV_2019_paper.pdf) | [Supplementary materials](https://openaccess.thecvf.com/content_ICCV_2019/supplemental/Shaham_SinGAN_Learning_a_ICCV_2019_supplemental.pdf) | [Talk (ICCV`19)](https://youtu.be/mdAcPe74tZI?t=3191) \n### Official pytorch implementation of the paper: \"SinGAN: Learning a Generative Model from a Single Natural Image\"\n#### ICCV 2019 Best paper award (Marr prize)\n\n\n## Random samples from a *single* image\nWith SinGAN, you can train a generative model from a single natural image, and then generate random samples from the given image, for example:\n\n![](https://raw.githubusercontent.com/tamarott/SinGAN/master/imgs/teaser.PNG)\n\n\n## SinGAN's applications\nSinGAN can be also used for a line of image manipulation tasks, for example:\n ![](https://raw.githubusercontent.com/tamarott/SinGAN/master/imgs/manipulation.PNG)\nThis is done by injecting an image to the already trained model. See section 4 in our [paper](https://arxiv.org/pdf/1905.01164.pdf) for more details.\n\n\n### Citation\nIf you use this code for your research, please cite our paper:\n\n```\n@inproceedings{rottshaham2019singan,\n  title={SinGAN: Learning a Generative Model from a Single Natural Image},\n  author={Rott Shaham, Tamar and Dekel, Tali and Michaeli, Tomer},\n  booktitle={Computer Vision (ICCV), IEEE International Conference on},\n  year={2019}\n}\n```\n\n## Code\n\n### Install dependencies\n\n```\npython -m pip install -r requirements.txt\n```\n\nThis code was tested with python 3.6, torch 1.4\n\nPlease note: the code currently only supports torch 1.4 or earlier because of the optimization scheme.\n\nFor later torch versions, you may try this repository: https://github.com/kligvasser/SinGAN (results won't necessarily be identical to the official implementation).\n\n\n###  Train\nTo train SinGAN model on your own image, put the desired training image under Input/Images, and run\n\n```\npython main_train.py --input_name <input_file_name>\n```\n\nThis will also use the resulting trained model to generate random samples starting from the coarsest scale (n=0).\n\nTo run this code on a cpu machine, specify `--not_cuda` when calling `main_train.py`\n\n###  Random samples\nTo generate random samples from any starting generation scale, please first train SinGAN model on the desired image (as described above), then run \n\n```\npython random_samples.py --input_name <training_image_file_name> --mode random_samples --gen_start_scale <generation start scale number>\n```\n\npay attention: for using the full model, specify the generation start scale to be 0, to start the generation from the second scale, specify it to be 1, and so on. \n\n###  Random samples of arbitrary sizes\nTo generate random samples of arbitrary sizes, please first train SinGAN model on the desired image (as described above), then run \n\n```\npython random_samples.py --input_name <training_image_file_name> --mode random_samples_arbitrary_sizes --scale_h <horizontal scaling factor> --scale_v <vertical scaling factor>\n```\n\n###  Animation from a single image\n\nTo generate short animation from a single image, run\n\n```\npython animation.py --input_name <input_file_name> \n```\n\nThis will automatically start a new training phase with noise padding mode.\n\n###  Harmonization\n\nTo harmonize a pasted object into an image (See example in Fig. 13 in [our paper](https://arxiv.org/pdf/1905.01164.pdf)), please first train SinGAN model on the desired background image (as described above), then save the naively pasted reference image and it's binary mask under \"Input/Harmonization\" (see saved images for an example). Run the command\n\n```\npython harmonization.py --input_name <training_image_file_name> --ref_name <naively_pasted_reference_image_file_name> --harmonization_start_scale <scale to inject>\n\n```\n\nPlease note that different injection scale will produce different harmonization effects. The coarsest injection scale equals 1. \n\n###  Editing\n\nTo edit an image, (See example in Fig. 12 in [our paper](https://arxiv.org/pdf/1905.01164.pdf)), please first train SinGAN model on the desired non-edited image (as described above), then save the naive edit as a reference image under \"Input/Editing\" with a corresponding binary map (see saved images for an example). Run the command\n\n```\npython editing.py --input_name <training_image_file_name> --ref_name <edited_image_file_name> --editing_start_scale <scale to inject>",
  "origin_sha": "WBYBAX/rAWvXc6ASkSueAHHWs8nzqFsy7WJit8teMbQ=",
  "translate": "# SinGAN\n\n[प्रोजेक्ट](https://tamarott.github.io/SinGAN.htm) | [Arxiv](https://arxiv.org/pdf/1905.01164.pdf) | [CVF](http://openaccess.thecvf.com/content_ICCV_2019/papers/Shaham_SinGAN_Learning_a_Generative_Model_From_a_Single_Natural_Image_ICCV_2019_paper.pdf) | [पूरक सामग्री](https://openaccess.thecvf.com/content_ICCV_2019/supplemental/Shaham_SinGAN_Learning_a_ICCV_2019_supplemental.pdf) | [टॉक (ICCV`19)](https://youtu.be/mdAcPe74tZI?t=3191) \n### पेपर का आधिकारिक PyTorch इम्प्लीमेंटेशन: \"SinGAN: Learning a Generative Model from a Single Natural Image\"\n#### ICCV 2019 सर्वश्रेष्ठ पेपर पुरस्कार (Marr पुरस्कार)\n\n\n## *एक* इमेज से रैंडम सैंपल\nSinGAN के साथ, आप एक ही प्राकृतिक छवि से एक जनरेटिव मॉडल को प्रशिक्षित कर सकते हैं, और फिर दी गई छवि से रैंडम सैंपल जेनरेट कर सकते हैं, उदाहरण के लिए:\n\n![](https://raw.githubusercontent.com/tamarott/SinGAN/master/imgs/teaser.PNG)\n\n\n## SinGAN के अनुप्रयोग\nSinGAN का उपयोग छवि हेरफेर के विभिन्न कार्यों के लिए भी किया जा सकता है, उदाहरण के लिए:\n ![](https://raw.githubusercontent.com/tamarott/SinGAN/master/imgs/manipulation.PNG)\nयह पहले से प्रशिक्षित मॉडल में एक छवि इंजेक्ट करके किया जाता है। अधिक विवरण के लिए हमारे [पेपर](https://arxiv.org/pdf/1905.01164.pdf) के अनुभाग 4 को देखें।\n\n\n### उद्धरण\nयदि आप अपने शोध में इस कोड का उपयोग करते हैं, तो कृपया हमारे पेपर का उद्धरण दें:\n\n```\n@inproceedings{rottshaham2019singan,\n  title={SinGAN: Learning a Generative Model from a Single Natural Image},\n  author={Rott Shaham, Tamar and Dekel, Tali and Michaeli, Tomer},\n  booktitle={Computer Vision (ICCV), IEEE International Conference on},\n  year={2019}\n}\n```\n\n## कोड\n\n### डिपेंडेंसी इंस्टॉल करें\n\n```\npython -m pip install -r requirements.txt\n```\n\nइस कोड का परीक्षण python 3.6, torch 1.4 के साथ किया गया था।\n\nकृपया ध्यान दें: यह कोड वर्तमान में केवल torch 1.4 या इससे पहले के संस्करणों का समर्थन करता है, अनुकूलन योजना के कारण।\n\nबाद के torch वर्शन के लिए, आप इस रिपॉजिटरी को आज़मा सकते हैं: https://github.com/kligvasser/SinGAN (परिणाम जरूरी नहीं कि आधिकारिक इम्प्लीमेंटेशन के समान हों।)\n\n\n###  ट्रेनिंग\nSinGAN मॉडल को अपनी खुद की इमेज पर ट्रेन करने के लिए, वांछित ट्रेनिंग इमेज को Input/Images के अंतर्गत डालें, और चलाएँ\n\n```\npython main_train.py --input_name <input_file_name>\n```\n\nयह प्रशिक्षित मॉडल का उपयोग करते हुए सबसे मोटे स्केल (n=0) से रैंडम सैंपल भी जेनरेट करेगा।\n\nइस कोड को सीपीयू मशीन पर चलाने के लिए, `main_train.py` कॉल करते समय `--not_cuda` निर्दिष्ट करें।\n\n###  रैंडम सैंपल\nकिसी भी आरंभिक जनरेशन स्केल से रैंडम सैंपल जेनरेट करने के लिए, कृपया पहले वांछित छवि पर SinGAN मॉडल ट्रेन करें (जैसा ऊपर वर्णित है), फिर चलाएँ \n\n```\npython random_samples.py --input_name <training_image_file_name> --mode random_samples --gen_start_scale <generation start scale number>\n```\n\nध्यान दें: फुल मॉडल का उपयोग करने के लिए, जनरेशन स्टार्ट स्केल को 0 पर सेट करें, दूसरी स्केल से जनरेशन शुरू करने के लिए इसे 1 पर सेट करें, और इसी तरह आगे।\n\n###  मनचाहे आकार के रैंडम सैंपल\nमनचाहे आकार के रैंडम सैंपल जेनरेट करने के लिए, कृपया पहले वांछित छवि पर SinGAN मॉडल ट्रेन करें (जैसा ऊपर वर्णित है), फिर चलाएँ \n\n```\npython random_samples.py --input_name <training_image_file_name> --mode random_samples_arbitrary_sizes --scale_h <horizontal scaling factor> --scale_v <vertical scaling factor>\n```\n\n###  एकल छवि से एनीमेशन\n\nएकल छवि से शॉर्ट एनीमेशन जेनरेट करने के लिए, चलाएँ\n\n```\npython animation.py --input_name <input_file_name> \n```\n\nयह स्वचालित रूप से नॉइज़ पैडिंग मोड के साथ एक नई ट्रेनिंग फेज शुरू करेगा।\n\n###  हार्मोनाइजेशन\n\nकिसी छवि में पेस्ट किए गए ऑब्जेक्ट को हार्मोनाइज करने के लिए (उदाहरण के लिए Fig. 13 में देखें [हमारे पेपर](https://arxiv.org/pdf/1905.01164.pdf)), कृपया पहले वांछित बैकग्राउंड इमेज पर SinGAN मॉडल ट्रेन करें (जैसा ऊपर वर्णित है), फिर नॉन-हार्मोनाइज्ड रेफरेंस इमेज और उसकी बाइनरी मास्क को \"Input/Harmonization\" में सेव करें (उदाहरण के लिए सेव्ड इमेज देखें)। कमांड चलाएँ\n\n```\npython harmonization.py --input_name <training_image_file_name> --ref_name <naively_pasted_reference_image_file_name> --harmonization_start_scale <scale to inject>\n\n```\n\nकृपया ध्यान दें कि अलग-अलग इंजेक्शन स्केल अलग-अलग हार्मोनाइजेशन प्रभाव देंगे। सबसे मोटा इंजेक्शन स्केल 1 है।\n\n###  एडिटिंग\n\nकिसी छवि को संपादित करने के लिए (Fig. 12 में उदाहरण देखें [हमारे पेपर](https://arxiv.org/pdf/1905.01164.pdf)), कृपया पहले वांछित नॉन-एडिटेड इमेज पर SinGAN मॉडल ट्रेन करें (जैसा ऊपर वर्णित है), फिर \"Input/Editing\" में रेफरेंस इमेज के रूप में नाइव एडिट सेव करें और उसकी संबंधित बाइनरी मैप भी सेव करें (उदाहरण के लिए सेव्ड इमेज देखें)। कमांड चलाएँ\n\n```\npython editing.py --input_name <training_image_file_name> --ref_name <edited_image_file_name> --editing_start_scale <scale to inject>",
  "status": "ok"
}