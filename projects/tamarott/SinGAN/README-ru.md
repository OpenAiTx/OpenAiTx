# SinGAN

[Проект](https://tamarott.github.io/SinGAN.htm) | [Arxiv](https://arxiv.org/pdf/1905.01164.pdf) | [CVF](http://openaccess.thecvf.com/content_ICCV_2019/papers/Shaham_SinGAN_Learning_a_Generative_Model_From_a_Single_Natural_Image_ICCV_2019_paper.pdf) | [Дополнительные материалы](https://openaccess.thecvf.com/content_ICCV_2019/supplemental/Shaham_SinGAN_Learning_a_ICCV_2019_supplemental.pdf) | [Доклад (ICCV`19)](https://youtu.be/mdAcPe74tZI?t=3191) 
### Официальная реализация на pytorch статьи: "SinGAN: Learning a Generative Model from a Single Natural Image"
#### Лучшая статья ICCV 2019 (приз Марра)


## Случайные выборки из *одного* изображения
С помощью SinGAN вы можете обучить генеративную модель на одном натуральном изображении, а затем генерировать случайные выборки из данного изображения, например:

![](https://raw.githubusercontent.com/tamarott/SinGAN/master/imgs/teaser.PNG)


## Применения SinGAN
SinGAN также может использоваться для различных задач манипуляции изображениями, например:
 ![](https://raw.githubusercontent.com/tamarott/SinGAN/master/imgs/manipulation.PNG)
Это достигается путем внедрения изображения в уже обученную модель. Подробнее смотрите в разделе 4 нашей [статьи](https://arxiv.org/pdf/1905.01164.pdf).


### Цитирование
Если вы используете этот код в своих исследованиях, пожалуйста, цитируйте нашу статью:

```
@inproceedings{rottshaham2019singan,
  title={SinGAN: Learning a Generative Model from a Single Natural Image},
  author={Rott Shaham, Tamar and Dekel, Tali and Michaeli, Tomer},
  booktitle={Computer Vision (ICCV), IEEE International Conference on},
  year={2019}
}
```

## Код

### Установка зависимостей

```
python -m pip install -r requirements.txt
```

Этот код был протестирован с python 3.6, torch 1.4

Обратите внимание: на данный момент код поддерживает только torch 1.4 или более ранние версии из-за используемой схемы оптимизации.

Для более поздних версий torch вы можете попробовать этот репозиторий: https://github.com/kligvasser/SinGAN (результаты могут отличаться от официальной реализации).


###  Обучение
Чтобы обучить модель SinGAN на вашем изображении, поместите нужное изображение для обучения в папку Input/Images и запустите

```
python main_train.py --input_name <input_file_name>
```

Это также использует полученную обученную модель для генерации случайных выборок, начиная с самого грубого масштаба (n=0).

Чтобы запустить этот код на процессоре, укажите `--not_cuda` при запуске `main_train.py`

###  Случайные выборки
Чтобы сгенерировать случайные выборки с любого начального масштаба генерации, сначала обучите модель SinGAN на нужном изображении (как описано выше), затем запустите 

```
python random_samples.py --input_name <training_image_file_name> --mode random_samples --gen_start_scale <generation start scale number>
```

обратите внимание: чтобы использовать полную модель, укажите начальный масштаб генерации равным 0; чтобы начать генерацию со второго масштаба, укажите 1 и так далее. 

###  Случайные выборки произвольных размеров
Чтобы сгенерировать случайные выборки произвольных размеров, сначала обучите модель SinGAN на нужном изображении (как описано выше), затем запустите 

```
python random_samples.py --input_name <training_image_file_name> --mode random_samples_arbitrary_sizes --scale_h <horizontal scaling factor> --scale_v <vertical scaling factor>
```

###  Анимация из одного изображения

Чтобы сгенерировать короткую анимацию из одного изображения, выполните

```
python animation.py --input_name <input_file_name> 
```

Это автоматически запустит новый этап обучения в режиме заполнения шумом.

###  Гармонизация

Чтобы гармонично вставить объект в изображение (см. пример на рис. 13 в [нашей статье](https://arxiv.org/pdf/1905.01164.pdf)), сначала обучите модель SinGAN на нужном фоновом изображении (как описано выше), затем сохраните наивно вставленное референсное изображение и его бинарную маску в папку "Input/Harmonization" (см. сохранённые изображения для примера). Выполните команду

```
python harmonization.py --input_name <training_image_file_name> --ref_name <naively_pasted_reference_image_file_name> --harmonization_start_scale <scale to inject>

```

Обратите внимание, что разные масштабы внедрения дадут разные эффекты гармонизации. Самый грубый масштаб внедрения равен 1. 

###  Редактирование

Чтобы отредактировать изображение (см. пример на рис. 12 в [нашей статье](https://arxiv.org/pdf/1905.01164.pdf)), сначала обучите модель SinGAN на нужном неотредактированном изображении (как описано выше), затем сохраните наивное редактирование в виде референсного изображения в папке "Input/Editing" с соответствующей бинарной картой (см. сохранённые изображения для примера). Выполните команду

```
python editing.py --input_name <training_image_file_name> --ref_name <edited_image_file_name> --editing_start_scale <scale to inject>
```
как замаскированный, так и незамаскированный вывод будут сохранены.
Здесь также различный масштаб внедрения приведет к различным эффектам редактирования. Самый грубый масштаб внедрения равен 1.

###  Перевод рисунка в изображение

Чтобы преобразовать рисунок в реалистичное изображение (см. пример на рис. 11 в [нашей статье](https://arxiv.org/pdf/1905.01164.pdf)), сначала обучите модель SinGAN на нужном изображении (как описано выше), затем сохраните ваш рисунок в папку "Input/Paint" и выполните команду

```
python paint2image.py --input_name <имя_файла_обучающего_изображения> --ref_name <имя_файла_рисунка> --paint_start_scale <масштаб_внедрения>
```

Здесь также различный масштаб внедрения приведет к различным эффектам редактирования. Самый грубый масштаб внедрения равен 1.

Расширенная опция: укажите quantization_flag как True, чтобы переобучить *только* уровень внедрения модели, получая версию с квантованием цветов для увеличенных сгенерированных изображений с предыдущего масштаба. Для некоторых изображений это может привести к более реалистичным результатам.

### Суперразрешение
Для увеличения разрешения изображения выполните:
```
python SR.py --input_name <имя_файла_низкоразрешенного_изображения>
```
Это автоматически обучит модель SinGAN, соответствующую 4-кратному фактору увеличения (если таковой еще не существует).
Для других коэффициентов увеличения укажите их с помощью параметра `--sr_factor` при вызове функции.
Результаты SinGAN на наборе данных BSD100 можно скачать из папки 'Downloads'.

## Дополнительные данные и функции

### Фреше-Инцепшн расстояние для одного изображения (SIFID score)
Чтобы вычислить SIFID между реальными изображениями и соответствующими им поддельными образцами, выполните:
```
python SIFID/sifid_score.py --path2real <путь_к_реальным_изображениям> --path2fake <путь_к_поддельным_изображениям> 
```  
Убедитесь, что имя каждого файла с поддельным изображением совпадает с именем соответствующего реального изображения. Изображения должны быть сохранены в формате `.jpg`.

### Результаты суперразрешения
Результаты SR SinGAN на наборе данных BSD100 можно скачать из папки 'Downloads'.

### Пользовательское исследование
Данные, использованные для пользовательского исследования, можно найти в папке Downloads.

папка real: 50 реальных изображений, случайным образом выбранных из [базы данных places](http://places.csail.mit.edu/)

папка fake_high_variance: случайные образцы, начиная с n=N для каждого реального изображения 

папка fake_mid_variance: случайные образцы, начиная с n=N-1 для каждого реального изображения 

Для получения дополнительных сведений см. раздел 3.1 в нашей [статье](https://arxiv.org/pdf/1905.01164.pdf)
```

---

Tranlated By [Open Ai Tx](https://github.com/OpenAiTx/OpenAiTx) | Last indexed: 2025-06-29

---