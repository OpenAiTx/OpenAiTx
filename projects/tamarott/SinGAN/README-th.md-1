{
  "id": 1,
  "origin": "# SinGAN\n\n[Project](https://tamarott.github.io/SinGAN.htm) | [Arxiv](https://arxiv.org/pdf/1905.01164.pdf) | [CVF](http://openaccess.thecvf.com/content_ICCV_2019/papers/Shaham_SinGAN_Learning_a_Generative_Model_From_a_Single_Natural_Image_ICCV_2019_paper.pdf) | [Supplementary materials](https://openaccess.thecvf.com/content_ICCV_2019/supplemental/Shaham_SinGAN_Learning_a_ICCV_2019_supplemental.pdf) | [Talk (ICCV`19)](https://youtu.be/mdAcPe74tZI?t=3191) \n### Official pytorch implementation of the paper: \"SinGAN: Learning a Generative Model from a Single Natural Image\"\n#### ICCV 2019 Best paper award (Marr prize)\n\n\n## Random samples from a *single* image\nWith SinGAN, you can train a generative model from a single natural image, and then generate random samples from the given image, for example:\n\n![](https://raw.githubusercontent.com/tamarott/SinGAN/master/imgs/teaser.PNG)\n\n\n## SinGAN's applications\nSinGAN can be also used for a line of image manipulation tasks, for example:\n ![](https://raw.githubusercontent.com/tamarott/SinGAN/master/imgs/manipulation.PNG)\nThis is done by injecting an image to the already trained model. See section 4 in our [paper](https://arxiv.org/pdf/1905.01164.pdf) for more details.\n\n\n### Citation\nIf you use this code for your research, please cite our paper:\n\n```\n@inproceedings{rottshaham2019singan,\n  title={SinGAN: Learning a Generative Model from a Single Natural Image},\n  author={Rott Shaham, Tamar and Dekel, Tali and Michaeli, Tomer},\n  booktitle={Computer Vision (ICCV), IEEE International Conference on},\n  year={2019}\n}\n```\n\n## Code\n\n### Install dependencies\n\n```\npython -m pip install -r requirements.txt\n```\n\nThis code was tested with python 3.6, torch 1.4\n\nPlease note: the code currently only supports torch 1.4 or earlier because of the optimization scheme.\n\nFor later torch versions, you may try this repository: https://github.com/kligvasser/SinGAN (results won't necessarily be identical to the official implementation).\n\n\n###  Train\nTo train SinGAN model on your own image, put the desired training image under Input/Images, and run\n\n```\npython main_train.py --input_name <input_file_name>\n```\n\nThis will also use the resulting trained model to generate random samples starting from the coarsest scale (n=0).\n\nTo run this code on a cpu machine, specify `--not_cuda` when calling `main_train.py`\n\n###  Random samples\nTo generate random samples from any starting generation scale, please first train SinGAN model on the desired image (as described above), then run \n\n```\npython random_samples.py --input_name <training_image_file_name> --mode random_samples --gen_start_scale <generation start scale number>\n```\n\npay attention: for using the full model, specify the generation start scale to be 0, to start the generation from the second scale, specify it to be 1, and so on. \n\n###  Random samples of arbitrary sizes\nTo generate random samples of arbitrary sizes, please first train SinGAN model on the desired image (as described above), then run \n\n```\npython random_samples.py --input_name <training_image_file_name> --mode random_samples_arbitrary_sizes --scale_h <horizontal scaling factor> --scale_v <vertical scaling factor>\n```\n\n###  Animation from a single image\n\nTo generate short animation from a single image, run\n\n```\npython animation.py --input_name <input_file_name> \n```\n\nThis will automatically start a new training phase with noise padding mode.\n\n###  Harmonization\n\nTo harmonize a pasted object into an image (See example in Fig. 13 in [our paper](https://arxiv.org/pdf/1905.01164.pdf)), please first train SinGAN model on the desired background image (as described above), then save the naively pasted reference image and it's binary mask under \"Input/Harmonization\" (see saved images for an example). Run the command\n\n```\npython harmonization.py --input_name <training_image_file_name> --ref_name <naively_pasted_reference_image_file_name> --harmonization_start_scale <scale to inject>\n\n```\n\nPlease note that different injection scale will produce different harmonization effects. The coarsest injection scale equals 1. \n\n###  Editing\n\nTo edit an image, (See example in Fig. 12 in [our paper](https://arxiv.org/pdf/1905.01164.pdf)), please first train SinGAN model on the desired non-edited image (as described above), then save the naive edit as a reference image under \"Input/Editing\" with a corresponding binary map (see saved images for an example). Run the command\n\n```\npython editing.py --input_name <training_image_file_name> --ref_name <edited_image_file_name> --editing_start_scale <scale to inject>",
  "origin_sha": "WBYBAX/rAWvXc6ASkSueAHHWs8nzqFsy7WJit8teMbQ=",
  "translate": "# SinGAN\n\n[โครงการ](https://tamarott.github.io/SinGAN.htm) | [Arxiv](https://arxiv.org/pdf/1905.01164.pdf) | [CVF](http://openaccess.thecvf.com/content_ICCV_2019/papers/Shaham_SinGAN_Learning_a_Generative_Model_From_a_Single_Natural_Image_ICCV_2019_paper.pdf) | [เอกสารเสริม](https://openaccess.thecvf.com/content_ICCV_2019/supplemental/Shaham_SinGAN_Learning_a_ICCV_2019_supplemental.pdf) | [Talk (ICCV`19)](https://youtu.be/mdAcPe74tZI?t=3191) \n### โค้ดอย่างเป็นทางการของ pytorch สำหรับบทความ: \"SinGAN: Learning a Generative Model from a Single Natural Image\"\n#### รางวัลบทความยอดเยี่ยม ICCV 2019 (Marr prize)\n\n\n## ตัวอย่างสุ่มจาก *ภาพเดียว*\nด้วย SinGAN คุณสามารถฝึกโมเดลสร้างภาพจากภาพธรรมชาติภาพเดียว และสามารถสร้างตัวอย่างสุ่มจากภาพนั้น เช่น:\n\n![](https://raw.githubusercontent.com/tamarott/SinGAN/master/imgs/teaser.PNG)\n\n\n## การประยุกต์ใช้งานของ SinGAN\nSinGAN ยังสามารถนำไปใช้กับงานปรับแต่งภาพหลายประเภท เช่น:\n ![](https://raw.githubusercontent.com/tamarott/SinGAN/master/imgs/manipulation.PNG)\nโดยการแทรกภาพเข้าไปในโมเดลที่ผ่านการฝึกแล้ว ดูรายละเอียดเพิ่มเติมในหัวข้อที่ 4 ของ [บทความของเรา](https://arxiv.org/pdf/1905.01164.pdf)\n\n\n### การอ้างอิง\nหากคุณใช้โค้ดนี้ในงานวิจัย กรุณาอ้างอิงบทความของเรา:\n\n```\n@inproceedings{rottshaham2019singan,\n  title={SinGAN: Learning a Generative Model from a Single Natural Image},\n  author={Rott Shaham, Tamar and Dekel, Tali and Michaeli, Tomer},\n  booktitle={Computer Vision (ICCV), IEEE International Conference on},\n  year={2019}\n}\n```\n\n## โค้ด\n\n### ติดตั้ง dependencies\n\n```\npython -m pip install -r requirements.txt\n```\n\nโค้ดนี้ผ่านการทดสอบกับ python 3.6, torch 1.4\n\nโปรดทราบ: โค้ดนี้รองรับเฉพาะ torch 1.4 หรือเก่ากว่า เนื่องจากวิธีการปรับแต่งประสิทธิภาพ\n\nสำหรับ torch เวอร์ชันใหม่กว่า คุณสามารถลองใช้ repository นี้: https://github.com/kligvasser/SinGAN (ผลลัพธ์อาจไม่เหมือนกับ implementation อย่างเป็นทางการ)\n\n\n###  ฝึกโมเดล\nหากต้องการฝึกโมเดล SinGAN กับภาพของคุณเอง ให้วางภาพสำหรับฝึกไว้ในโฟลเดอร์ Input/Images แล้วรัน\n\n```\npython main_train.py --input_name <input_file_name>\n```\n\nการดำเนินการนี้จะใช้โมเดลที่ฝึกเสร็จแล้วเพื่อสร้างตัวอย่างสุ่มโดยเริ่มจากสเกลที่หยาบที่สุด (n=0)\n\nหากต้องการรันโค้ดนี้บนเครื่อง cpu ให้ระบุ `--not_cuda` ขณะเรียกใช้ `main_train.py`\n\n###  ตัวอย่างสุ่ม\nหากต้องการสร้างตัวอย่างสุ่มจากสเกลของการสร้างใดๆ กรุณาฝึกโมเดล SinGAN กับภาพที่ต้องการ (ตามที่อธิบายข้างต้น) แล้วรัน\n\n```\npython random_samples.py --input_name <training_image_file_name> --mode random_samples --gen_start_scale <generation start scale number>\n```\n\nโปรดสังเกต: หากต้องการใช้โมเดลเต็ม ให้ตั้งค่าสเกลเริ่มต้นเป็น 0 หากต้องการเริ่มสร้างจากสเกลที่สอง ให้ตั้งเป็น 1 และอื่นๆ \n\n###  ตัวอย่างสุ่มขนาดใดก็ได้\nหากต้องการสร้างตัวอย่างสุ่มที่มีขนาดตามต้องการ กรุณาฝึกโมเดล SinGAN กับภาพที่ต้องการ (ตามที่อธิบายข้างต้น) แล้วรัน\n\n```\npython random_samples.py --input_name <training_image_file_name> --mode random_samples_arbitrary_sizes --scale_h <horizontal scaling factor> --scale_v <vertical scaling factor>\n```\n\n###  สร้างแอนิเมชันจากภาพเดียว\n\nหากต้องการสร้างแอนิเมชันสั้นจากภาพเดียว ให้รัน\n\n```\npython animation.py --input_name <input_file_name> \n```\n\nระบบจะเริ่มการฝึกใหม่โดยใช้โหมด noise padding โดยอัตโนมัติ\n\n###  การปรับกลมกลืน (Harmonization)\n\nหากต้องการปรับกลมกลืนวัตถุที่วางแทรกลงในภาพ (ดูตัวอย่างในรูปที่ 13 ใน [บทความของเรา](https://arxiv.org/pdf/1905.01164.pdf)) กรุณาฝึกโมเดล SinGAN กับภาพพื้นหลังที่ต้องการ (ตามที่อธิบายข้างต้น) จากนั้นบันทึกภาพอ้างอิงที่วางวัตถุอย่างง่ายและ binary mask ไว้ใน \"Input/Harmonization\" (ดูตัวอย่างจากไฟล์ที่บันทึกไว้) รันคำสั่ง\n\n```\npython harmonization.py --input_name <training_image_file_name> --ref_name <naively_pasted_reference_image_file_name> --harmonization_start_scale <scale to inject>\n\n```\n\nโปรดทราบว่าสเกลการแทรกที่แตกต่างจะให้ผลลัพธ์การปรับกลมกลืนที่แตกต่างกัน สเกลการแทรกที่หยาบที่สุดคือ 1\n\n###  การแก้ไข (Editing)\n\nหากต้องการแก้ไขภาพ (ดูตัวอย่างในรูปที่ 12 ใน [บทความของเรา](https://arxiv.org/pdf/1905.01164.pdf)) กรุณาฝึกโมเดล SinGAN กับภาพที่ยังไม่ได้แก้ไข (ตามที่อธิบายข้างต้น) จากนั้นบันทึกภาพที่แก้ไขแบบง่ายเป็น reference ไว้ใน \"Input/Editing\" พร้อม binary map ที่เกี่ยวข้อง (ดูตัวอย่างจากไฟล์ที่บันทึกไว้) รันคำสั่ง\n\n```\npython editing.py --input_name <training_image_file_name> --ref_name <edited_image_file_name> --editing_start_scale <scale to inject>",
  "status": "ok"
}