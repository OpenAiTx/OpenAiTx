{
  "id": 1,
  "origin": "# SinGAN\n\n[Project](https://tamarott.github.io/SinGAN.htm) | [Arxiv](https://arxiv.org/pdf/1905.01164.pdf) | [CVF](http://openaccess.thecvf.com/content_ICCV_2019/papers/Shaham_SinGAN_Learning_a_Generative_Model_From_a_Single_Natural_Image_ICCV_2019_paper.pdf) | [Supplementary materials](https://openaccess.thecvf.com/content_ICCV_2019/supplemental/Shaham_SinGAN_Learning_a_ICCV_2019_supplemental.pdf) | [Talk (ICCV`19)](https://youtu.be/mdAcPe74tZI?t=3191) \n### Official pytorch implementation of the paper: \"SinGAN: Learning a Generative Model from a Single Natural Image\"\n#### ICCV 2019 Best paper award (Marr prize)\n\n\n## Random samples from a *single* image\nWith SinGAN, you can train a generative model from a single natural image, and then generate random samples from the given image, for example:\n\n![](https://raw.githubusercontent.com/tamarott/SinGAN/master/imgs/teaser.PNG)\n\n\n## SinGAN's applications\nSinGAN can be also used for a line of image manipulation tasks, for example:\n ![](https://raw.githubusercontent.com/tamarott/SinGAN/master/imgs/manipulation.PNG)\nThis is done by injecting an image to the already trained model. See section 4 in our [paper](https://arxiv.org/pdf/1905.01164.pdf) for more details.\n\n\n### Citation\nIf you use this code for your research, please cite our paper:\n\n```\n@inproceedings{rottshaham2019singan,\n  title={SinGAN: Learning a Generative Model from a Single Natural Image},\n  author={Rott Shaham, Tamar and Dekel, Tali and Michaeli, Tomer},\n  booktitle={Computer Vision (ICCV), IEEE International Conference on},\n  year={2019}\n}\n```\n\n## Code\n\n### Install dependencies\n\n```\npython -m pip install -r requirements.txt\n```\n\nThis code was tested with python 3.6, torch 1.4\n\nPlease note: the code currently only supports torch 1.4 or earlier because of the optimization scheme.\n\nFor later torch versions, you may try this repository: https://github.com/kligvasser/SinGAN (results won't necessarily be identical to the official implementation).\n\n\n###  Train\nTo train SinGAN model on your own image, put the desired training image under Input/Images, and run\n\n```\npython main_train.py --input_name <input_file_name>\n```\n\nThis will also use the resulting trained model to generate random samples starting from the coarsest scale (n=0).\n\nTo run this code on a cpu machine, specify `--not_cuda` when calling `main_train.py`\n\n###  Random samples\nTo generate random samples from any starting generation scale, please first train SinGAN model on the desired image (as described above), then run \n\n```\npython random_samples.py --input_name <training_image_file_name> --mode random_samples --gen_start_scale <generation start scale number>\n```\n\npay attention: for using the full model, specify the generation start scale to be 0, to start the generation from the second scale, specify it to be 1, and so on. \n\n###  Random samples of arbitrary sizes\nTo generate random samples of arbitrary sizes, please first train SinGAN model on the desired image (as described above), then run \n\n```\npython random_samples.py --input_name <training_image_file_name> --mode random_samples_arbitrary_sizes --scale_h <horizontal scaling factor> --scale_v <vertical scaling factor>\n```\n\n###  Animation from a single image\n\nTo generate short animation from a single image, run\n\n```\npython animation.py --input_name <input_file_name> \n```\n\nThis will automatically start a new training phase with noise padding mode.\n\n###  Harmonization\n\nTo harmonize a pasted object into an image (See example in Fig. 13 in [our paper](https://arxiv.org/pdf/1905.01164.pdf)), please first train SinGAN model on the desired background image (as described above), then save the naively pasted reference image and it's binary mask under \"Input/Harmonization\" (see saved images for an example). Run the command\n\n```\npython harmonization.py --input_name <training_image_file_name> --ref_name <naively_pasted_reference_image_file_name> --harmonization_start_scale <scale to inject>\n\n```\n\nPlease note that different injection scale will produce different harmonization effects. The coarsest injection scale equals 1. \n\n###  Editing\n\nTo edit an image, (See example in Fig. 12 in [our paper](https://arxiv.org/pdf/1905.01164.pdf)), please first train SinGAN model on the desired non-edited image (as described above), then save the naive edit as a reference image under \"Input/Editing\" with a corresponding binary map (see saved images for an example). Run the command\n\n```\npython editing.py --input_name <training_image_file_name> --ref_name <edited_image_file_name> --editing_start_scale <scale to inject>",
  "origin_sha": "WBYBAX/rAWvXc6ASkSueAHHWs8nzqFsy7WJit8teMbQ=",
  "translate": "# SinGAN\n\n[프로젝트](https://tamarott.github.io/SinGAN.htm) | [Arxiv](https://arxiv.org/pdf/1905.01164.pdf) | [CVF](http://openaccess.thecvf.com/content_ICCV_2019/papers/Shaham_SinGAN_Learning_a_Generative_Model_From_a_Single_Natural_Image_ICCV_2019_paper.pdf) | [보조 자료](https://openaccess.thecvf.com/content_ICCV_2019/supplemental/Shaham_SinGAN_Learning_a_ICCV_2019_supplemental.pdf) | [강연 (ICCV`19)](https://youtu.be/mdAcPe74tZI?t=3191) \n### 논문 공식 pytorch 구현: \"SinGAN: Learning a Generative Model from a Single Natural Image\"\n#### ICCV 2019 최우수 논문상 (Marr prize)\n\n\n## *단일* 이미지로부터의 랜덤 샘플\nSinGAN을 사용하면 단일 자연 이미지로부터 생성 모델을 학습할 수 있으며, 이후 주어진 이미지로부터 랜덤 샘플을 생성할 수 있습니다. 예를 들어:\n\n![](https://raw.githubusercontent.com/tamarott/SinGAN/master/imgs/teaser.PNG)\n\n\n## SinGAN의 응용\nSinGAN은 다양한 이미지 조작 작업에도 사용할 수 있습니다. 예를 들어:\n ![](https://raw.githubusercontent.com/tamarott/SinGAN/master/imgs/manipulation.PNG)\n이 작업은 이미 학습된 모델에 이미지를 주입하여 수행합니다. 자세한 내용은 [논문](https://arxiv.org/pdf/1905.01164.pdf) 4장을 참고하세요.\n\n\n### 인용\n이 코드를 연구에 사용하신다면 논문을 인용해 주세요:\n\n```\n@inproceedings{rottshaham2019singan,\n  title={SinGAN: Learning a Generative Model from a Single Natural Image},\n  author={Rott Shaham, Tamar and Dekel, Tali and Michaeli, Tomer},\n  booktitle={Computer Vision (ICCV), IEEE International Conference on},\n  year={2019}\n}\n```\n\n## 코드\n\n### 의존성 설치\n\n```\npython -m pip install -r requirements.txt\n```\n\n이 코드는 python 3.6, torch 1.4에서 테스트되었습니다.\n\n참고: 현재 코드는 최적화 방식으로 인해 torch 1.4 이하만 지원합니다.\n\n더 최신 버전의 torch를 사용하려면 다음 저장소를 시도해 볼 수 있습니다: https://github.com/kligvasser/SinGAN (결과는 공식 구현과 반드시 동일하지 않을 수 있습니다).\n\n\n###  학습\n사용자 이미지로 SinGAN 모델을 학습하려면, 원하는 학습 이미지를 Input/Images 폴더에 넣고 아래 명령어를 실행하세요.\n\n```\npython main_train.py --input_name <input_file_name>\n```\n\n이 명령은 결과로 생성된 학습된 모델을 사용해, 가장 거친 스케일(n=0)부터 랜덤 샘플도 생성합니다.\n\ncpu 환경에서 코드를 실행하려면 `main_train.py` 호출 시 `--not_cuda` 옵션을 지정하세요.\n\n###  랜덤 샘플\n원하는 시작 생성 스케일에서 랜덤 샘플을 생성하려면, 먼저 위에서 설명한 대로 SinGAN 모델을 원하는 이미지로 학습한 뒤, 아래 명령을 실행하세요.\n\n```\npython random_samples.py --input_name <training_image_file_name> --mode random_samples --gen_start_scale <generation start scale number>\n```\n\n주의: 전체 모델을 사용하려면 생성 시작 스케일을 0으로 지정하세요. 두 번째 스케일부터 시작하려면 1로 지정하면 됩니다.\n\n###  임의 크기의 랜덤 샘플\n임의의 크기로 랜덤 샘플을 생성하려면, 먼저 위에서 설명한 대로 SinGAN 모델을 원하는 이미지로 학습한 뒤, 아래 명령을 실행하세요.\n\n```\npython random_samples.py --input_name <training_image_file_name> --mode random_samples_arbitrary_sizes --scale_h <horizontal scaling factor> --scale_v <vertical scaling factor>\n```\n\n###  단일 이미지로 애니메이션 생성\n\n단일 이미지로 짧은 애니메이션을 생성하려면, 아래 명령을 실행하세요.\n\n```\npython animation.py --input_name <input_file_name> \n```\n\n이 명령은 자동으로 noise padding 모드로 새로운 학습 단계를 시작합니다.\n\n###  조화화(Harmonization)\n\n오브젝트를 이미지에 자연스럽게 합성하려면([논문](https://arxiv.org/pdf/1905.01164.pdf) Fig. 13 참고), 먼저 SinGAN 모델을 원하는 배경 이미지로 학습하고(위와 동일), 단순히 합성한 참조 이미지와 해당 바이너리 마스크를 \"Input/Harmonization\" 폴더에 저장하세요(예시는 저장된 이미지를 참고). 아래 명령어를 실행하세요.\n\n```\npython harmonization.py --input_name <training_image_file_name> --ref_name <naively_pasted_reference_image_file_name> --harmonization_start_scale <scale to inject>\n\n```\n\n주입 스케일에 따라 서로 다른 조화화 효과가 나옵니다. 가장 거친 주입 스케일은 1입니다.\n\n###  편집\n\n이미지를 편집하려면([논문](https://arxiv.org/pdf/1905.01164.pdf) Fig. 12 참고), 먼저 SinGAN 모델을 원하는 비편집 이미지로 학습하고(위와 동일), 간단히 편집한 이미지를 \"Input/Editing\"에 해당 바이너리 맵과 함께 참조 이미지로 저장하세요(예시는 저장된 이미지를 참고). 아래 명령어를 실행하세요.\n\n```\npython editing.py --input_name <training_image_file_name> --ref_name <edited_image_file_name> --editing_start_scale <scale to inject>",
  "status": "ok"
}