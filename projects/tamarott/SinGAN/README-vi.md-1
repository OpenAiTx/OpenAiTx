{
  "id": 1,
  "origin": "# SinGAN\n\n[Project](https://tamarott.github.io/SinGAN.htm) | [Arxiv](https://arxiv.org/pdf/1905.01164.pdf) | [CVF](http://openaccess.thecvf.com/content_ICCV_2019/papers/Shaham_SinGAN_Learning_a_Generative_Model_From_a_Single_Natural_Image_ICCV_2019_paper.pdf) | [Supplementary materials](https://openaccess.thecvf.com/content_ICCV_2019/supplemental/Shaham_SinGAN_Learning_a_ICCV_2019_supplemental.pdf) | [Talk (ICCV`19)](https://youtu.be/mdAcPe74tZI?t=3191) \n### Official pytorch implementation of the paper: \"SinGAN: Learning a Generative Model from a Single Natural Image\"\n#### ICCV 2019 Best paper award (Marr prize)\n\n\n## Random samples from a *single* image\nWith SinGAN, you can train a generative model from a single natural image, and then generate random samples from the given image, for example:\n\n![](https://raw.githubusercontent.com/tamarott/SinGAN/master/imgs/teaser.PNG)\n\n\n## SinGAN's applications\nSinGAN can be also used for a line of image manipulation tasks, for example:\n ![](https://raw.githubusercontent.com/tamarott/SinGAN/master/imgs/manipulation.PNG)\nThis is done by injecting an image to the already trained model. See section 4 in our [paper](https://arxiv.org/pdf/1905.01164.pdf) for more details.\n\n\n### Citation\nIf you use this code for your research, please cite our paper:\n\n```\n@inproceedings{rottshaham2019singan,\n  title={SinGAN: Learning a Generative Model from a Single Natural Image},\n  author={Rott Shaham, Tamar and Dekel, Tali and Michaeli, Tomer},\n  booktitle={Computer Vision (ICCV), IEEE International Conference on},\n  year={2019}\n}\n```\n\n## Code\n\n### Install dependencies\n\n```\npython -m pip install -r requirements.txt\n```\n\nThis code was tested with python 3.6, torch 1.4\n\nPlease note: the code currently only supports torch 1.4 or earlier because of the optimization scheme.\n\nFor later torch versions, you may try this repository: https://github.com/kligvasser/SinGAN (results won't necessarily be identical to the official implementation).\n\n\n###  Train\nTo train SinGAN model on your own image, put the desired training image under Input/Images, and run\n\n```\npython main_train.py --input_name <input_file_name>\n```\n\nThis will also use the resulting trained model to generate random samples starting from the coarsest scale (n=0).\n\nTo run this code on a cpu machine, specify `--not_cuda` when calling `main_train.py`\n\n###  Random samples\nTo generate random samples from any starting generation scale, please first train SinGAN model on the desired image (as described above), then run \n\n```\npython random_samples.py --input_name <training_image_file_name> --mode random_samples --gen_start_scale <generation start scale number>\n```\n\npay attention: for using the full model, specify the generation start scale to be 0, to start the generation from the second scale, specify it to be 1, and so on. \n\n###  Random samples of arbitrary sizes\nTo generate random samples of arbitrary sizes, please first train SinGAN model on the desired image (as described above), then run \n\n```\npython random_samples.py --input_name <training_image_file_name> --mode random_samples_arbitrary_sizes --scale_h <horizontal scaling factor> --scale_v <vertical scaling factor>\n```\n\n###  Animation from a single image\n\nTo generate short animation from a single image, run\n\n```\npython animation.py --input_name <input_file_name> \n```\n\nThis will automatically start a new training phase with noise padding mode.\n\n###  Harmonization\n\nTo harmonize a pasted object into an image (See example in Fig. 13 in [our paper](https://arxiv.org/pdf/1905.01164.pdf)), please first train SinGAN model on the desired background image (as described above), then save the naively pasted reference image and it's binary mask under \"Input/Harmonization\" (see saved images for an example). Run the command\n\n```\npython harmonization.py --input_name <training_image_file_name> --ref_name <naively_pasted_reference_image_file_name> --harmonization_start_scale <scale to inject>\n\n```\n\nPlease note that different injection scale will produce different harmonization effects. The coarsest injection scale equals 1. \n\n###  Editing\n\nTo edit an image, (See example in Fig. 12 in [our paper](https://arxiv.org/pdf/1905.01164.pdf)), please first train SinGAN model on the desired non-edited image (as described above), then save the naive edit as a reference image under \"Input/Editing\" with a corresponding binary map (see saved images for an example). Run the command\n\n```\npython editing.py --input_name <training_image_file_name> --ref_name <edited_image_file_name> --editing_start_scale <scale to inject>",
  "origin_sha": "WBYBAX/rAWvXc6ASkSueAHHWs8nzqFsy7WJit8teMbQ=",
  "translate": "# SinGAN\n\n[Project](https://tamarott.github.io/SinGAN.htm) | [Arxiv](https://arxiv.org/pdf/1905.01164.pdf) | [CVF](http://openaccess.thecvf.com/content_ICCV_2019/papers/Shaham_SinGAN_Learning_a_Generative_Model_From_a_Single_Natural_Image_ICCV_2019_paper.pdf) | [Supplementary materials](https://openaccess.thecvf.com/content_ICCV_2019/supplemental/Shaham_SinGAN_Learning_a_ICCV_2019_supplemental.pdf) | [Talk (ICCV`19)](https://youtu.be/mdAcPe74tZI?t=3191) \n### Cài đặt chính thức bằng pytorch của bài báo: \"SinGAN: Learning a Generative Model from a Single Natural Image\"\n#### Giải thưởng bài báo xuất sắc nhất ICCV 2019 (Marr prize)\n\n\n## Các mẫu ngẫu nhiên từ *một* ảnh duy nhất\nVới SinGAN, bạn có thể huấn luyện một mô hình sinh từ một ảnh tự nhiên duy nhất, và sau đó sinh ra các mẫu ngẫu nhiên từ ảnh đó, ví dụ:\n\n![](https://raw.githubusercontent.com/tamarott/SinGAN/master/imgs/teaser.PNG)\n\n\n## Ứng dụng của SinGAN\nSinGAN cũng có thể được sử dụng cho một loạt các tác vụ chỉnh sửa ảnh, ví dụ:\n ![](https://raw.githubusercontent.com/tamarott/SinGAN/master/imgs/manipulation.PNG)\nViệc này được thực hiện bằng cách đưa một ảnh vào mô hình đã được huấn luyện sẵn. Xem mục 4 trong [bài báo](https://arxiv.org/pdf/1905.01164.pdf) của chúng tôi để biết thêm chi tiết.\n\n\n### Trích dẫn\nNếu bạn sử dụng mã nguồn này cho nghiên cứu của mình, vui lòng trích dẫn bài báo của chúng tôi:\n\n```\n@inproceedings{rottshaham2019singan,\n  title={SinGAN: Learning a Generative Model from a Single Natural Image},\n  author={Rott Shaham, Tamar and Dekel, Tali and Michaeli, Tomer},\n  booktitle={Computer Vision (ICCV), IEEE International Conference on},\n  year={2019}\n}\n```\n\n## Mã nguồn\n\n### Cài đặt các thư viện phụ thuộc\n\n```\npython -m pip install -r requirements.txt\n```\n\nMã nguồn này đã được kiểm tra với python 3.6, torch 1.4\n\nLưu ý: mã nguồn hiện tại chỉ hỗ trợ torch 1.4 hoặc thấp hơn do sơ đồ tối ưu hóa.\n\nVới các phiên bản torch mới hơn, bạn có thể thử kho này: https://github.com/kligvasser/SinGAN (kết quả có thể sẽ không giống hoàn toàn với bản cài đặt chính thức).\n\n\n###  Huấn luyện\nĐể huấn luyện mô hình SinGAN trên ảnh của riêng bạn, hãy đặt ảnh huấn luyện mong muốn vào thư mục Input/Images, và chạy\n\n```\npython main_train.py --input_name <input_file_name>\n```\n\nLệnh này cũng sẽ sử dụng mô hình đã huấn luyện để sinh các mẫu ngẫu nhiên bắt đầu từ cấp độ thô nhất (n=0).\n\nĐể chạy mã này trên máy chỉ có cpu, hãy thêm tùy chọn `--not_cuda` khi gọi `main_train.py`\n\n###  Mẫu ngẫu nhiên\nĐể sinh các mẫu ngẫu nhiên từ bất kỳ cấp độ sinh nào, trước hết hãy huấn luyện mô hình SinGAN trên ảnh mong muốn (như hướng dẫn ở trên), sau đó chạy \n\n```\npython random_samples.py --input_name <training_image_file_name> --mode random_samples --gen_start_scale <generation start scale number>\n```\n\nlưu ý: để sử dụng toàn bộ mô hình, hãy đặt cấp độ bắt đầu sinh là 0; để bắt đầu sinh từ cấp độ thứ hai, hãy đặt là 1, v.v.\n\n###  Mẫu ngẫu nhiên với kích thước tuỳ ý\nĐể sinh các mẫu ngẫu nhiên với kích thước tuỳ ý, trước hết hãy huấn luyện mô hình SinGAN trên ảnh mong muốn (như hướng dẫn ở trên), sau đó chạy\n\n```\npython random_samples.py --input_name <training_image_file_name> --mode random_samples_arbitrary_sizes --scale_h <horizontal scaling factor> --scale_v <vertical scaling factor>\n```\n\n###  Tạo hoạt ảnh từ một ảnh duy nhất\n\nĐể sinh hoạt ảnh ngắn từ một ảnh duy nhất, chạy\n\n```\npython animation.py --input_name <input_file_name> \n```\n\nLệnh này sẽ tự động bắt đầu một pha huấn luyện mới với chế độ noise padding.\n\n###  Hài hoà hoá\n\nĐể hài hoà một đối tượng dán vào trong ảnh (Xem ví dụ trong Hình 13 ở [bài báo của chúng tôi](https://arxiv.org/pdf/1905.01164.pdf)), trước hết hãy huấn luyện mô hình SinGAN trên ảnh nền mong muốn (như hướng dẫn ở trên), sau đó lưu ảnh tham chiếu được dán thô và mặt nạ nhị phân của nó vào thư mục \"Input/Harmonization\" (xem ảnh mẫu đã lưu). Chạy lệnh\n\n```\npython harmonization.py --input_name <training_image_file_name> --ref_name <naively_pasted_reference_image_file_name> --harmonization_start_scale <scale to inject>\n\n```\n\nLưu ý rằng các cấp độ chèn khác nhau sẽ tạo ra hiệu ứng hài hoà khác nhau. Cấp độ chèn thô nhất là 1.\n\n###  Chỉnh sửa\n\nĐể chỉnh sửa một ảnh, (Xem ví dụ trong Hình 12 ở [bài báo của chúng tôi](https://arxiv.org/pdf/1905.01164.pdf)), trước hết hãy huấn luyện mô hình SinGAN trên ảnh gốc chưa chỉnh sửa mong muốn (như hướng dẫn ở trên), sau đó lưu bản chỉnh sửa thô làm ảnh tham chiếu vào thư mục \"Input/Editing\" cùng với bản đồ nhị phân tương ứng (xem ảnh mẫu đã lưu). Chạy lệnh\n\n```\npython editing.py --input_name <training_image_file_name> --ref_name <edited_image_file_name> --editing_start_scale <scale to inject>",
  "status": "ok"
}