{
  "fullName": "Fanqi-Lin/OneTwoVLA",
  "htmlUrl": "https://github.com/Fanqi-Lin/OneTwoVLA",
  "readmeUrl": "https://raw.githubusercontent.com/Fanqi-Lin/OneTwoVLA/main/README.md",
  "sha": "40a0d7b925061df3236191d892adb5a6384fd9f9",
  "siz": 3431,
  "stargazers_count": 153,
  "indexTime": "2025-07-25T04:15:13.1550086Z",
  "TokenUsage": [
    {
      "Language": "ko",
      "PromptTokens": 1671,
      "CompletionTokens": 1086,
      "TotalTokens": 2757
    },
    {
      "Language": "ja",
      "PromptTokens": 1671,
      "CompletionTokens": 1157,
      "TotalTokens": 2828
    },
    {
      "Language": "en",
      "PromptTokens": 1667,
      "CompletionTokens": 916,
      "TotalTokens": 2583
    },
    {
      "Language": "zh-CN",
      "PromptTokens": 1683,
      "CompletionTokens": 960,
      "TotalTokens": 2643
    }
  ],
  "status": 0,
  "updatetime": "0001-01-01T00:00:00",
  "GitHubApiData": {
    "id": 985132242,
    "node_id": "R_kgDOOrfs0g",
    "name": "OneTwoVLA",
    "full_name": "Fanqi-Lin/OneTwoVLA",
    "private": false,
    "html_url": "https://github.com/Fanqi-Lin/OneTwoVLA",
    "description": "Official implementation of \"OneTwoVLA: A Unified Vision-Language-Action Model with Adaptive Reasoning\"",
    "created_at": "2025-05-17T14:04:40+08:00",
    "updated_at": "2025-07-24T20:57:42+08:00",
    "pushed_at": "2025-05-30T14:00:03+08:00",
    "language": "Python",
    "stargazers_count": 153,
    "watchers_count": 153,
    "forks_count": 4,
    "size": 1411,
    "default_branch": "main"
  },
  "TranslatedDescriptions": {
    "zh-CN": "“OneTwoVLA：具有自适应推理能力的统一视觉-语言-动作模型”官方实现",
    "ja": "「OneTwoVLA: 適応的推論を備えた統一視覚・言語・行動モデル」の公式実装",
    "ko": "\"OneTwoVLA: 적응형 추론을 갖춘 통합 비전-언어-행동 모델\" 공식 구현체",
    "en": "Official implementation of \"OneTwoVLA: A Unified Vision-Language-Action Model with Adaptive Reasoning\""
  }
}