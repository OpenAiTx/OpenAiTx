<div align="center">
    
<h1><a href="https://ieeexplore.ieee.org/document/10591792">Change-Agentï¼šè¿ˆå‘äº¤äº’å¼ç»¼åˆé¥æ„Ÿå˜åŒ–è§£é‡Šä¸åˆ†æ</a></h1>

**[åˆ˜æ™¨é˜³](https://chen-yang-liu.github.io/), [é™ˆå…‹è¨€](https://kyanchen.github.io), [å¼ æµ©å¤©](https://scholar.google.com/citations?user=c7uR6NUAAAAJ), [é½å­é¹](https://scholar.google.com/citations?user=KhMtmBsAAAAJ), [é‚¹æ­£éœ](https://scholar.google.com.hk/citations?hl=en&user=DzwoyZsAAAAJ), ä»¥åŠ [çŸ³æŒ¯ä¼Ÿ*âœ‰](https://scholar.google.com.hk/citations?hl=en&user=kNhFWQIAAAAJ)**

<div align="center">
  <img src="https://raw.githubusercontent.com/Chen-Yang-Liu/Change-Agent/main/resource/Change_Agent.png" width="400"/>
</div>
</div>

## å¦‚æœä½ å¯¹æœ¬ä»“åº“æ„Ÿå…´è¶£ï¼Œè¯·ç»™æˆ‘ä»¬ä¸€ä¸ª :star: 

æœ¬æ–‡çš„å®˜æ–¹ PyTorch å®ç°ï¼šâ€œ**Change-Agentï¼šè¿ˆå‘äº¤äº’å¼ç»¼åˆé¥æ„Ÿå˜åŒ–è§£é‡Šä¸åˆ†æ**â€å‘è¡¨äº [[IEEE](https://ieeexplore.ieee.org/document/10591792)] ***(è¢« IEEE TGRS 2024 æ¥æ”¶)***

## ğŸ¥³æ–°é—»

- 2024-06ï¼šä»£ç  **å·²å‘å¸ƒ**ã€‚
- 2024-03ï¼šè®ºæ–‡ **å·²å‘å¸ƒ**ã€‚
- ğŸ”¥ æˆ‘ä»¬çš„ç»¼è¿°â€œ**é¥æ„Ÿæ—¶åºè§†è§‰-è¯­è¨€æ¨¡å‹ï¼šä¸€é¡¹ç»¼åˆè°ƒç ”**â€ï¼š[Arxiv](https://arxiv.org/abs/2412.02573) || [Github](https://github.com/Chen-Yang-Liu/Awesome-RS-Temporal-VLM)** ğŸ”¥ 

## ç›®å½•
- [LEVIR-MCI æ•°æ®é›†](#LEVIR-MCI-dataset)
- [å¤šå±‚æ¬¡å˜åŒ–è§£é‡Šæ¨¡å‹è®­ç»ƒ](#Training-of-the-multi-level-change-interpretation-model)
- [Change-Agent æ„å»º](#Construction-of-Change-Agent)
- [å¼•ç”¨](#Citation)

## LEVIR-MCI æ•°æ®é›† 
- ä¸‹è½½ LEVIR_MCI æ•°æ®é›†ï¼š[LEVIR-MCI](https://huggingface.co/datasets/lcybuaa/LEVIR-MCI/tree/main)ï¼ˆ**ç°å·²å¼€æ”¾ï¼**ï¼‰ã€‚
- æœ¬æ•°æ®é›†æ˜¯æˆ‘ä»¬å…ˆå‰å»ºç«‹çš„ [LEVIR-CC æ•°æ®é›†](https://github.com/Chen-Yang-Liu/RSICC) çš„æ‰©å±•ï¼ŒåŒ…å«åŒæ—¶ç›¸å½±åƒä»¥åŠå¤šæ ·çš„å˜åŒ–æ£€æµ‹æ©ç å’Œæè¿°æ€§å¥å­ã€‚å®ƒä¸ºæ¢ç´¢å˜åŒ–æ£€æµ‹ä¸å˜åŒ–æè¿°çš„å¤šä»»åŠ¡å­¦ä¹ æä¾›äº†å…³é”®æ•°æ®åŸºç¡€ã€‚
    <br>
    <div align="center">
      <img src="https://raw.githubusercontent.com/Chen-Yang-Liu/Change-Agent/main/resource/dataset.png" width="800"/>
    </div>
    <br>
## å¤šå±‚æ¬¡å˜åŒ–è§£é‡Šæ¨¡å‹è®­ç»ƒ
MCI æ¨¡å‹æ¦‚è§ˆï¼š
<br>
    <div align="center">
      <img src="https://raw.githubusercontent.com/Chen-Yang-Liu/Change-Agent/main/resource/MCI_model.png" width="800"/>
    </div>
<br>

### å‡†å¤‡å·¥ä½œ
    
- **ç¯å¢ƒå®‰è£…**ï¼š
    <details open>
    
    **æ­¥éª¤ 1**ï¼šåˆ›å»ºä¸€ä¸ªåä¸º `Multi_change_env` çš„è™šæ‹Ÿç¯å¢ƒå¹¶æ¿€æ´»å®ƒã€‚
    ```python
    conda create -n Multi_change_env python=3.9
    conda activate Multi_change_env
    ```
    
    **æ­¥éª¤ 2**ï¼šä¸‹è½½æˆ–å…‹éš†è¯¥ä»“åº“ã€‚
    ```python
    git clone https://github.com/Chen-Yang-Liu/Change-Agent.git
    cd ./Change-Agent/Multi_change
    ```
    
    **æ­¥éª¤3**ï¼šå®‰è£…ä¾èµ–é¡¹ã€‚
    ```python
    pip install -r requirements.txt
    ```
    </details>

- **ä¸‹è½½æ•°æ®é›†**ï¼š
  <details open>
      
  é“¾æ¥ï¼š[LEVIR-MCI](https://huggingface.co/datasets/lcybuaa/LEVIR-MCI/tree/main)ã€‚LEVIR-MCI çš„æ•°æ®ç»“æ„ç»„ç»‡å¦‚ä¸‹ï¼š

    ```
    â”œâ”€/DATA_PATH_ROOT/Levir-MCI-dataset/
            â”œâ”€LevirCCcaptions.json
            â”œâ”€images
                 â”œâ”€train
                 â”‚  â”œâ”€A
                 â”‚  â”œâ”€B
                 â”‚  â”œâ”€label
                 â”œâ”€val
                 â”‚  â”œâ”€A
                 â”‚  â”œâ”€B
                 â”‚  â”œâ”€label
                 â”œâ”€test
                 â”‚  â”œâ”€A
                 â”‚  â”œâ”€B
                 â”‚  â”œâ”€label
    ```
    å…¶ä¸­æ–‡ä»¶å¤¹``A``åŒ…å«å‰æœŸå›¾åƒï¼Œæ–‡ä»¶å¤¹``B``åŒ…å«åæœŸå›¾åƒï¼Œæ–‡ä»¶å¤¹``label``åŒ…å«å˜åŒ–æ£€æµ‹æ©ç ã€‚
    </details>

- **æå–LEVIR-MCIä¸­æ¯å¯¹å›¾åƒæè¿°çš„æ–‡æœ¬æ–‡ä»¶**ï¼š

    ```
    python preprocess_data.py
    ```
    ä¹‹åï¼Œæ‚¨å¯ä»¥åœ¨ `./data/LEVIR_MCI/` ä¸­æ‰¾åˆ°ä¸€äº›ç”Ÿæˆçš„æ–‡ä»¶ã€‚

### è®­ç»ƒ
ç¡®ä¿æ‚¨å·²å®Œæˆä¸Šè¿°æ•°æ®å‡†å¤‡ã€‚ç„¶åï¼ŒæŒ‰å¦‚ä¸‹æ–¹å¼å¼€å§‹è®­ç»ƒï¼š
```python
python train.py --train_goal 2 --data_folder /DATA_PATH_ROOT/Levir-MCI-dataset/images --savepath ./models_ckpt/
```

### è¯„ä¼°
```python
python test.py --data_folder /DATA_PATH_ROOT/Levir-MCI-dataset/images --checkpoint {checkpoint_PATH}
```
æˆ‘ä»¬å»ºè®®è®­ç»ƒæ¨¡å‹5æ¬¡ä»¥è·å¾—å¹³å‡åˆ†æ•°ã€‚

### æ¨ç†
è¿è¡Œæ¨ç†ä»¥å¼€å§‹ï¼Œæ–¹æ³•å¦‚ä¸‹ï¼š
```python
python predict.py --imgA_path {imgA_path} --imgB_path {imgA_path} --mask_save_path ./CDmask.png
```
ä½ å¯ä»¥ä¿®æ”¹ ``predict.py`` ä¸­ ``Change_Perception.define_args()`` çš„ ``--checkpoint`` å‚æ•°ã€‚ç„¶åä½ å¯ä»¥ä½¿ç”¨ä½ è‡ªå·±çš„æ¨¡å‹ï¼Œå½“ç„¶ï¼Œä½ ä¹Ÿå¯ä»¥ä¸‹è½½æˆ‘ä»¬çš„é¢„è®­ç»ƒæ¨¡å‹ ``MCI_model.pth``ï¼Œä¸‹è½½åœ°å€ï¼š[[Hugging face](https://huggingface.co/lcybuaa/Change-Agent/tree/main)]ã€‚ä¸‹è½½åï¼Œå°†å…¶æ”¾å…¥ `./models_ckpt/` æ–‡ä»¶å¤¹ä¸­ã€‚



## Change-Agent çš„æ„å»º
<br>
<div align="center">
      <img src="https://raw.githubusercontent.com/Chen-Yang-Liu/Change-Agent/main/resource/overview_agent.png" width="800"/>
</div>

- **Agent å®‰è£…**ï¼š
    ```python
    cd ./Change-Agent/lagent-main
    pip install -e .[all]
    ```
- **è¿è¡Œä»£ç†**ï¼š

    è¿›å…¥ ``Multi_change`` æ–‡ä»¶å¤¹ï¼š
    ```python
    cd ./Change-Agent/Multi_change
    ```
    ï¼ˆ1ï¼‰è¿è¡Œä»£ç†å®¢æˆ·ç«¯æ¼”ç¤ºï¼š
    ```bash
    # You need to install streamlit first
    # pip install streamlit
    python try_chat.py
    ```
        
    ï¼ˆ2ï¼‰è¿è¡Œä»£ç†ç½‘é¡µæ¼”ç¤ºï¼š
    ```bash
    # You need to install streamlit first
    # pip install streamlit
    streamlit run react_web_demo.py
    ```
    <br>
    <div align="center">
          <img src="https://raw.githubusercontent.com/Chen-Yang-Liu/Change-Agent/main/resource/web.png"/>
    </div>

## å¼•ç”¨
å¦‚æœæ‚¨åœ¨ç ”ç©¶ä¸­å‘ç°æœ¬æ–‡æœ‰ç”¨ï¼Œè¯·è€ƒè™‘å¼•ç”¨ï¼š
```
@ARTICLE{Liu_Change_Agent,
  author={Liu, Chenyang and Chen, Keyan and Zhang, Haotian and Qi, Zipeng and Zou, Zhengxia and Shi, Zhenwei},
  journal={IEEE Transactions on Geoscience and Remote Sensing}, 
  title={Change-Agent: Toward Interactive Comprehensive Remote Sensing Change Interpretation and Analysis}, 
  year={2024},
  volume={},
  number={},
  pages={1-1},
  keywords={Remote sensing;Feature extraction;Semantics;Transformers;Roads;Earth;Task analysis;Interactive Change-Agent;change captioning;change detection;multi-task learning;large language model},
  doi={10.1109/TGRS.2024.3425815}}

```

## è‡´è°¢
æ„Ÿè°¢ä»¥ä¸‹ä»“åº“ï¼š

[RSICCformer](https://github.com/Chen-Yang-Liu/RSICC); [Chg2Cap](https://github.com/ShizhenChang/Chg2Cap); [lagent](https://github.com/InternLM/lagent)

## è®¸å¯åè®®
æœ¬ä»“åº“éµå¾ª[MIT è®¸å¯è¯](https://github.com/Chen-Yang-Liu/Change-Agent/blob/main/LICENSE.txt)åˆ†å‘ã€‚ä»£ç ä»…é™äºå­¦æœ¯ç”¨é€”ã€‚

## è”ç³»æˆ‘ä»¬
å¦‚æœæ‚¨æœ‰ä»»ä½•å…¶ä»–é—®é¢˜â“ï¼Œè¯·åŠæ—¶è”ç³»æˆ‘ä»¬ ğŸ‘¬


---

Tranlated By [Open Ai Tx](https://github.com/OpenAiTx/OpenAiTx) | Last indexed: 2025-08-19

---