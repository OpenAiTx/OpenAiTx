<div align="center">
    
<h1><a href="https://ieeexplore.ieee.org/document/10591792">Change-Agent : Vers une interpr√©tation et une analyse interactives et compl√®tes des changements en t√©l√©d√©tection</a></h1>

**[Chenyang Liu](https://chen-yang-liu.github.io/), [Keyan Chen](https://kyanchen.github.io), [Haotian Zhang](https://scholar.google.com/citations?user=c7uR6NUAAAAJ), [Zipeng Qi](https://scholar.google.com/citations?user=KhMtmBsAAAAJ), [Zhengxia Zou](https://scholar.google.com.hk/citations?hl=en&user=DzwoyZsAAAAJ), et [Zhenwei Shi*‚úâ](https://scholar.google.com.hk/citations?hl=en&user=kNhFWQIAAAAJ)**

<div align="center">
  <img src="https://raw.githubusercontent.com/Chen-Yang-Liu/Change-Agent/main/resource/Change_Agent.png" width="400"/>
</div>
</div>

## Mettez-nous une :star: si ce d√©p√¥t vous int√©resse

Impl√©mentation officielle PyTorch de l‚Äôarticle : "**Change-Agent : Vers une interpr√©tation et une analyse interactives et compl√®tes des changements en t√©l√©d√©tection**" dans [[IEEE](https://ieeexplore.ieee.org/document/10591792)]  ***(Accept√© par IEEE TGRS 2024)***

## ü•≥Nouvelles

- 2024-06 : Le code est **disponible**.
- 2024-03 : L‚Äôarticle est **disponible**.
- üî• Notre enqu√™te "**Mod√®les vision-langage temporels en t√©l√©d√©tection : une enqu√™te compl√®te" : [Arxiv](https://arxiv.org/abs/2412.02573) || [Github](https://github.com/Chen-Yang-Liu/Awesome-RS-Temporal-VLM)** üî• 

## Table des mati√®res
- [Jeu de donn√©es LEVIR-MCI](#LEVIR-MCI-dataset)
- [Entra√Ænement du mod√®le MCI](#Training-of-the-multi-level-change-interpretation-model)
- [Construction de Change-Agent](#Construction-of-Change-Agent)
- [Citation](#Citation)

## Jeu de donn√©es LEVIR-MCI 
- T√©l√©chargez le jeu de donn√©es LEVIR_MCI : [LEVIR-MCI](https://huggingface.co/datasets/lcybuaa/LEVIR-MCI/tree/main) (**Disponible maintenant !**).
- Ce jeu de donn√©es est une extension de notre pr√©c√©dent [jeu LEVIR-CC](https://github.com/Chen-Yang-Liu/RSICC). Il contient des images bi-temporelles ainsi que des masques de d√©tection de changements divers et des phrases descriptives. Il fournit une base de donn√©es essentielle pour explorer l‚Äôapprentissage multit√¢che pour la d√©tection et la description des changements.
    <br>
    <div align="center">
      <img src="https://raw.githubusercontent.com/Chen-Yang-Liu/Change-Agent/main/resource/dataset.png" width="800"/>
    </div>
    <br>
## Entra√Ænement du mod√®le d‚Äôinterpr√©tation multi-niveaux des changements
Vue d‚Äôensemble du mod√®le MCI :
<br>
    <div align="center">
      <img src="https://raw.githubusercontent.com/Chen-Yang-Liu/Change-Agent/main/resource/MCI_model.png" width="800"/>
    </div>
<br>

### Pr√©paration
    
- **Installation de l'environnement** :
    <details open>
    
    **√âtape 1** : Cr√©ez un environnement virtuel nomm√© `Multi_change_env` et activez-le.
    ```python
    conda create -n Multi_change_env python=3.9
    conda activate Multi_change_env
    ```
    
    **√âtape 2** : T√©l√©chargez ou clonez le d√©p√¥t.
    ```python
    git clone https://github.com/Chen-Yang-Liu/Change-Agent.git
    cd ./Change-Agent/Multi_change
    ```
    
    **√âtape 3** : Installer les d√©pendances.
    ```python
    pip install -r requirements.txt
    ```
    </details>

- **T√©l√©charger le jeu de donn√©es** :
  <details open>
      
  Lien : [LEVIR-MCI](https://huggingface.co/datasets/lcybuaa/LEVIR-MCI/tree/main). La structure des donn√©es de LEVIR-MCI est organis√©e comme suit :

    ```
    ‚îú‚îÄ/DATA_PATH_ROOT/Levir-MCI-dataset/
            ‚îú‚îÄLevirCCcaptions.json
            ‚îú‚îÄimages
                 ‚îú‚îÄtrain
                 ‚îÇ  ‚îú‚îÄA
                 ‚îÇ  ‚îú‚îÄB
                 ‚îÇ  ‚îú‚îÄlabel
                 ‚îú‚îÄval
                 ‚îÇ  ‚îú‚îÄA
                 ‚îÇ  ‚îú‚îÄB
                 ‚îÇ  ‚îú‚îÄlabel
                 ‚îú‚îÄtest
                 ‚îÇ  ‚îú‚îÄA
                 ‚îÇ  ‚îú‚îÄB
                 ‚îÇ  ‚îú‚îÄlabel
    ```
    o√π le dossier ``A`` contient les images pr√©-phase, le dossier ``B`` contient les images post-phase, et le dossier ``label`` contient les masques de d√©tection de changement.
    </details>

- **Extraire les fichiers texte pour les descriptions de chaque paire d‚Äôimages dans LEVIR-MCI** :

    ```
    python preprocess_data.py
    ```
    Apr√®s cela, vous pouvez trouver certains fichiers g√©n√©r√©s dans `./data/LEVIR_MCI/`. 

### Entra√Ænement
Assurez-vous d'avoir effectu√© la pr√©paration des donn√©es ci-dessus. Ensuite, lancez l'entra√Ænement comme suit :
```python
python train.py --train_goal 2 --data_folder /DATA_PATH_ROOT/Levir-MCI-dataset/images --savepath ./models_ckpt/
```

### √âvaluer
```python
python test.py --data_folder /DATA_PATH_ROOT/Levir-MCI-dataset/images --checkpoint {checkpoint_PATH}
```
Nous recommandons d'entra√Æner le mod√®le 5 fois pour obtenir un score moyen.

### Inf√©rence
Lancez l'inf√©rence pour commencer comme suit :
```python
python predict.py --imgA_path {imgA_path} --imgB_path {imgA_path} --mask_save_path ./CDmask.png
```
Vous pouvez modifier ``--checkpoint`` de ``Change_Perception.define_args()`` dans ``predict.py``. Ensuite, vous pouvez utiliser votre propre mod√®le, bien s√ªr, vous pouvez √©galement t√©l√©charger notre mod√®le pr√©-entra√Æn√© ``MCI_model.pth`` ici : [[Hugging face](https://huggingface.co/lcybuaa/Change-Agent/tree/main)]. Apr√®s cela, placez-le dans `./models_ckpt/`.



## Construction de Change-Agent
<br>
<div align="center">
      <img src="https://raw.githubusercontent.com/Chen-Yang-Liu/Change-Agent/main/resource/overview_agent.png" width="800"/>
</div>

- **Installation de l'Agent** :
    ```python
    cd ./Change-Agent/lagent-main
    pip install -e .[all]
    ```
- **Ex√©cuter l'Agent** :

    se placer dans le dossier ``Multi_change`` :
    ```python
    cd ./Change-Agent/Multi_change
    ```
    (1) Ex√©cuter la d√©mo de l'Agent CLI :
    ```bash
    # You need to install streamlit first
    # pip install streamlit
    python try_chat.py
    ```
        
    (2) Ex√©cuter la d√©monstration Web de l'Agent :
    ```bash
    # You need to install streamlit first
    # pip install streamlit
    streamlit run react_web_demo.py
    ```
    <br>
    <div align="center">
          <img src="https://raw.githubusercontent.com/Chen-Yang-Liu/Change-Agent/main/resource/web.png"/>
    </div>

## Citation
Si vous trouvez cet article utile dans vos recherches, veuillez envisager de le citer :
```
@ARTICLE{Liu_Change_Agent,
  author={Liu, Chenyang and Chen, Keyan and Zhang, Haotian and Qi, Zipeng and Zou, Zhengxia and Shi, Zhenwei},
  journal={IEEE Transactions on Geoscience and Remote Sensing}, 
  title={Change-Agent: Toward Interactive Comprehensive Remote Sensing Change Interpretation and Analysis}, 
  year={2024},
  volume={},
  number={},
  pages={1-1},
  keywords={Remote sensing;Feature extraction;Semantics;Transformers;Roads;Earth;Task analysis;Interactive Change-Agent;change captioning;change detection;multi-task learning;large language model},
  doi={10.1109/TGRS.2024.3425815}}

```

## Remerciements
Merci aux d√©p√¥ts suivants :

[RSICCformer](https://github.com/Chen-Yang-Liu/RSICC); [Chg2Cap](https://github.com/ShizhenChang/Chg2Cap); [lagent](https://github.com/InternLM/lagent)

## Licence
Ce d√©p√¥t est distribu√© sous la [Licence MIT](https://github.com/Chen-Yang-Liu/Change-Agent/blob/main/LICENSE.txt). Le code peut √™tre utilis√© uniquement √† des fins acad√©miques.

## Contactez-nous
Si vous avez d'autres questions‚ùì, veuillez nous contacter rapidement üë¨


---

Tranlated By [Open Ai Tx](https://github.com/OpenAiTx/OpenAiTx) | Last indexed: 2025-08-19

---