<div align="center">
    
<h1><a href="https://ieeexplore.ieee.org/document/10591792">Change-Agent: Hacia una interpretaci√≥n y an√°lisis interactivo integral de cambios en teledetecci√≥n</a></h1>

**[Chenyang Liu](https://chen-yang-liu.github.io/), [Keyan Chen](https://kyanchen.github.io), [Haotian Zhang](https://scholar.google.com/citations?user=c7uR6NUAAAAJ), [Zipeng Qi](https://scholar.google.com/citations?user=KhMtmBsAAAAJ), [Zhengxia Zou](https://scholar.google.com.hk/citations?hl=en&user=DzwoyZsAAAAJ), y [Zhenwei Shi*‚úâ](https://scholar.google.com.hk/citations?hl=en&user=kNhFWQIAAAAJ)**

<div align="center">
  <img src="https://raw.githubusercontent.com/Chen-Yang-Liu/Change-Agent/main/resource/Change_Agent.png" width="400"/>
</div>
</div>

## Comp√°rtenos una :star: si te interesa este repositorio

Implementaci√≥n oficial en PyTorch del art√≠culo: "**Change-Agent: Hacia una interpretaci√≥n y an√°lisis interactivo integral de cambios en teledetecci√≥n**" en [[IEEE](https://ieeexplore.ieee.org/document/10591792)]  ***(Aceptado por IEEE TGRS 2024)***

## ü•≥Noticias

- 2024-06: El c√≥digo est√° **disponible**.
- 2024-03: El art√≠culo est√° **disponible**.
- üî• Nuestra encuesta "**Modelos de Visi√≥n-Lenguaje Temporales en Teledetecci√≥n: Una Revisi√≥n Integral": [Arxiv](https://arxiv.org/abs/2412.02573) || [Github](https://github.com/Chen-Yang-Liu/Awesome-RS-Temporal-VLM)** üî• 

## Tabla de Contenidos
- [Conjunto de datos LEVIR-MCI](#LEVIR-MCI-dataset)
- [Entrenamiento del modelo MCI](#Training-of-the-multi-level-change-interpretation-model)
- [Construcci√≥n de Change-Agent](#Construction-of-Change-Agent)
- [Citaci√≥n](#Citation)

## Conjunto de datos LEVIR-MCI 
- Descarga el conjunto de datos LEVIR_MCI: [LEVIR-MCI](https://huggingface.co/datasets/lcybuaa/LEVIR-MCI/tree/main) (**¬°Disponible Ahora!**).
- Este conjunto de datos es una extensi√≥n de nuestro previamente establecido [conjunto LEVIR-CC](https://github.com/Chen-Yang-Liu/RSICC). Contiene im√°genes bi-temporales as√≠ como diversas m√°scaras de detecci√≥n de cambio y oraciones descriptivas. Proporciona una base de datos crucial para explorar el aprendizaje multitarea para detecci√≥n de cambios y generaci√≥n de leyendas de cambio.
    <br>
    <div align="center">
      <img src="https://raw.githubusercontent.com/Chen-Yang-Liu/Change-Agent/main/resource/dataset.png" width="800"/>
    </div>
    <br>
## Entrenamiento del modelo de interpretaci√≥n de cambios a m√∫ltiples niveles
La visi√≥n general del modelo MCI:
<br>
    <div align="center">
      <img src="https://raw.githubusercontent.com/Chen-Yang-Liu/Change-Agent/main/resource/MCI_model.png" width="800"/>
    </div>
<br>

### Preparaci√≥n
    
- **Instalaci√≥n del entorno**:
    <details open>
    
    **Paso 1**: Cree un entorno virtual llamado `Multi_change_env` y act√≠velo.
    ```python
    conda create -n Multi_change_env python=3.9
    conda activate Multi_change_env
    ```
    
    **Paso 2**: Descargue o clone el repositorio.
    ```python
    git clone https://github.com/Chen-Yang-Liu/Change-Agent.git
    cd ./Change-Agent/Multi_change
    ```
    
    **Paso 3**: Instalar dependencias.
    ```python
    pip install -r requirements.txt
    ```
    </details>

- **Descargar conjunto de datos**:
  <details open>
      
  Enlace: [LEVIR-MCI](https://huggingface.co/datasets/lcybuaa/LEVIR-MCI/tree/main). La estructura de datos de LEVIR-MCI est√° organizada de la siguiente manera:

    ```
    ‚îú‚îÄ/DATA_PATH_ROOT/Levir-MCI-dataset/
            ‚îú‚îÄLevirCCcaptions.json
            ‚îú‚îÄimages
                 ‚îú‚îÄtrain
                 ‚îÇ  ‚îú‚îÄA
                 ‚îÇ  ‚îú‚îÄB
                 ‚îÇ  ‚îú‚îÄlabel
                 ‚îú‚îÄval
                 ‚îÇ  ‚îú‚îÄA
                 ‚îÇ  ‚îú‚îÄB
                 ‚îÇ  ‚îú‚îÄlabel
                 ‚îú‚îÄtest
                 ‚îÇ  ‚îú‚îÄA
                 ‚îÇ  ‚îú‚îÄB
                 ‚îÇ  ‚îú‚îÄlabel
    ```
    donde la carpeta ``A`` contiene im√°genes de la pre-fase, la carpeta ``B`` contiene im√°genes de la post-fase, y la carpeta ``label`` contiene las m√°scaras de detecci√≥n de cambios.
    </details>

- **Extraer archivos de texto con las descripciones de cada par de im√°genes en LEVIR-MCI**:

    ```
    python preprocess_data.py
    ```
    Despu√©s de eso, puedes encontrar algunos archivos generados en `./data/LEVIR_MCI/`. 

### Entrenamiento
Aseg√∫rate de haber realizado la preparaci√≥n de datos mencionada anteriormente. Luego, comienza el entrenamiento de la siguiente manera:
```python
python train.py --train_goal 2 --data_folder /DATA_PATH_ROOT/Levir-MCI-dataset/images --savepath ./models_ckpt/
```

### Evaluar
```python
python test.py --data_folder /DATA_PATH_ROOT/Levir-MCI-dataset/images --checkpoint {checkpoint_PATH}
```
Recomendamos entrenar el modelo 5 veces para obtener una puntuaci√≥n promedio.

### Inferencia
Ejecute la inferencia para comenzar de la siguiente manera:
```python
python predict.py --imgA_path {imgA_path} --imgB_path {imgA_path} --mask_save_path ./CDmask.png
```
Puedes modificar ``--checkpoint`` de ``Change_Perception.define_args()`` en ``predict.py``. Luego puedes usar tu propio modelo, por supuesto, tambi√©n puedes descargar nuestro modelo preentrenado ``MCI_model.pth`` aqu√≠: [[Hugging face](https://huggingface.co/lcybuaa/Change-Agent/tree/main)]. Despu√©s de eso, col√≥calo en `./models_ckpt/`.



## Construcci√≥n de Change-Agent
<br>
<div align="center">
      <img src="https://raw.githubusercontent.com/Chen-Yang-Liu/Change-Agent/main/resource/overview_agent.png" width="800"/>
</div>

- **Instalaci√≥n del Agente**:
    ```python
    cd ./Change-Agent/lagent-main
    pip install -e .[all]
    ```
- **Ejecutar Agente**:

    entrar en la carpeta ``Multi_change``:
    ```python
    cd ./Change-Agent/Multi_change
    ```
    (1) Ejecutar demostraci√≥n de Agent Cli:
    ```bash
    # You need to install streamlit first
    # pip install streamlit
    python try_chat.py
    ```
        
    (2) Ejecutar la demostraci√≥n web del agente:
    ```bash
    # You need to install streamlit first
    # pip install streamlit
    streamlit run react_web_demo.py
    ```
    <br>
    <div align="center">
          <img src="https://raw.githubusercontent.com/Chen-Yang-Liu/Change-Agent/main/resource/web.png"/>
    </div>

## Cita
Si encuentra este art√≠culo √∫til para su investigaci√≥n, por favor considere citar:
```
@ARTICLE{Liu_Change_Agent,
  author={Liu, Chenyang and Chen, Keyan and Zhang, Haotian and Qi, Zipeng and Zou, Zhengxia and Shi, Zhenwei},
  journal={IEEE Transactions on Geoscience and Remote Sensing}, 
  title={Change-Agent: Toward Interactive Comprehensive Remote Sensing Change Interpretation and Analysis}, 
  year={2024},
  volume={},
  number={},
  pages={1-1},
  keywords={Remote sensing;Feature extraction;Semantics;Transformers;Roads;Earth;Task analysis;Interactive Change-Agent;change captioning;change detection;multi-task learning;large language model},
  doi={10.1109/TGRS.2024.3425815}}

```
## Agradecimientos
Gracias a el siguiente repositorio:

[RSICCformer](https://github.com/Chen-Yang-Liu/RSICC); [Chg2Cap](https://github.com/ShizhenChang/Chg2Cap); [lagent](https://github.com/InternLM/lagent)

## Licencia
Este repositorio se distribuye bajo la [Licencia MIT](https://github.com/Chen-Yang-Liu/Change-Agent/blob/main/LICENSE.txt). El c√≥digo puede usarse solo con fines acad√©micos.

## Cont√°ctanos
Si tienes alguna otra pregunta‚ùì, por favor cont√°ctanos a tiempo üë¨



---

Tranlated By [Open Ai Tx](https://github.com/OpenAiTx/OpenAiTx) | Last indexed: 2025-08-19

---