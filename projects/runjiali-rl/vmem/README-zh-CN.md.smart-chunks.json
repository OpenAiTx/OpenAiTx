[
  {
    "Id": 1,
    "Content": "<div align=\"center\">\n<img src=\"https://raw.githubusercontent.com/runjiali-rl/vmem/main/assets/title_logo.png\" width=\"200\" alt=\"VMem Logo\"/>\n<h1>VMem: Consistent Interactive Video Scene Generation with Surfel-Indexed View Memory</h1>\n\n<p align=\"center\">ICCV 2025</p>\n\n\n<a href=\"https://v-mem.github.io/\"><img src=\"https://img.shields.io/badge/%F0%9F%8F%A0%20Project%20Page-gray.svg\"></a>\n<a href=\"http://arxiv.org/abs/2506.18903\"><img src=\"https://img.shields.io/badge/%F0%9F%93%84%20arXiv-2506.18903-B31B1B.svg\"></a>\n<a href=\"https://huggingface.co/liguang0115/vmem\"><img src=\"https://img.shields.io/badge/%F0%9F%A4%97%20Model_Card-Huggingface-orange\"></a>\n<a href=\"https://huggingface.co/spaces/liguang0115/vmem\"><img src=\"https://img.shields.io/badge/%F0%9F%9A%80%20Gradio%20Demo-Huggingface-orange\"></a>\n\n[Runjia Li](https://runjiali-rl.github.io/), [Philip Torr](https://www.robots.ox.ac.uk/~phst/), [Andrea Vedaldi](https://www.robots.ox.ac.uk/~vedaldi/), [Tomas Jakab](https://www.robots.ox.ac.uk/~tomj/)\n<br>\n<br>\n[University of Oxford](https://www.robots.ox.ac.uk/~vgg/)\n</div>\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/runjiali-rl/vmem/main/assets/demo_teaser.gif\" width=\"100%\" alt=\"Teaser\" style=\"border-radius:10px;\"/>\n</p>\n\n<!-- <p align=\"center\" border-radius=\"10px\">\n  <img src=\"https://raw.githubusercontent.com/runjiali-rl/vmem/main/assets/benchmark.png\" width=\"100%\" alt=\"teaser_page1\"/>\n</p> -->\n\n# Overview\n\n`VMem` is a plug-and-play memory mechanism of image-set models for consistent scene generation.\nExisting methods either rely on inpainting with explicit geometry estimation, which suffers from inaccuracies, or use limited context windows in video-based approaches, leading to poor long-term coherence. To overcome these issues, we introduce Surfel Memory of Views (VMem), which anchors past views to surface elements (surfels) they observed. This enables conditioning novel view generation on the most relevant past views rather than just the most recent ones, enhancing long-term scene consistency while reducing computational cost.\n\n\n# :wrench: Installation\n",
    "ContentSha": "DPdLqeh2MubQ7TQVe2B9bd7Zliw+EB9dV79ea5nWI8M=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "<div align=\"center\">\n<img src=\"https://raw.githubusercontent.com/runjiali-rl/vmem/main/assets/title_logo.png\" width=\"200\" alt=\"VMem Logo\"/>\n<h1>VMem：基于表面元素索引视图记忆的一致交互式视频场景生成</h1>\n\n<p align=\"center\">ICCV 2025</p>\n\n\n<a href=\"https://v-mem.github.io/\"><img src=\"https://img.shields.io/badge/%F0%9F%8F%A0%20Project%20Page-gray.svg\"></a>\n<a href=\"http://arxiv.org/abs/2506.18903\"><img src=\"https://img.shields.io/badge/%F0%9F%93%84%20arXiv-2506.18903-B31B1B.svg\"></a>\n<a href=\"https://huggingface.co/liguang0115/vmem\"><img src=\"https://img.shields.io/badge/%F0%9F%A4%97%20Model_Card-Huggingface-orange\"></a>\n<a href=\"https://huggingface.co/spaces/liguang0115/vmem\"><img src=\"https://img.shields.io/badge/%F0%9F%9A%80%20Gradio%20Demo-Huggingface-orange\"></a>\n\n[李润佳](https://runjiali-rl.github.io/), [Philip Torr](https://www.robots.ox.ac.uk/~phst/), [Andrea Vedaldi](https://www.robots.ox.ac.uk/~vedaldi/), [Tomas Jakab](https://www.robots.ox.ac.uk/~tomj/)\n<br>\n<br>\n[牛津大学](https://www.robots.ox.ac.uk/~vgg/)\n</div>\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/runjiali-rl/vmem/main/assets/demo_teaser.gif\" width=\"100%\" alt=\"Teaser\" style=\"border-radius:10px;\"/>\n</p>\n\n<!-- <p align=\"center\" border-radius=\"10px\">\n  <img src=\"https://raw.githubusercontent.com/runjiali-rl/vmem/main/assets/benchmark.png\" width=\"100%\" alt=\"teaser_page1\"/>\n</p> -->\n\n# 概述\n\n`VMem` 是一种可插拔的图像集模型记忆机制，用于一致的场景生成。\n现有方法要么依赖带有显式几何估计的图像修补，存在不准确问题；要么在基于视频的方法中使用有限的上下文窗口，导致长期一致性差。为克服这些问题，我们提出了视图表面元素记忆（VMem），将过去的视图锚定到它们观察到的表面元素（surfels）上。这使得新视图生成可以基于最相关的过去视图，而非仅仅是最近的视图，从而增强了长期场景一致性，同时降低了计算成本。\n\n\n# :wrench: 安装\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "94MDjHJY1ZLwHNTLIEUIfk7TMc9cq1L/1FmwhqBTe/k=",
        "originContent": "<div align=\"center\">",
        "translatedContent": "<div align=\"center\">"
      },
      {
        "row": 2,
        "rowsha": "HXGMi/BlHhF785AkPq6n/sdBZRQWAwbdzKAuOEmnfxc=",
        "originContent": "<img src=\"https://raw.githubusercontent.com/runjiali-rl/vmem/main/assets/title_logo.png\" width=\"200\" alt=\"VMem Logo\"/>",
        "translatedContent": "<img src=\"https://raw.githubusercontent.com/runjiali-rl/vmem/main/assets/title_logo.png\" width=\"200\" alt=\"VMem Logo\"/>"
      },
      {
        "row": 3,
        "rowsha": "Oh9WXFDCECzrhNuY8DDok4OhRihMqVwOCbAGAz7K+fA=",
        "originContent": "<h1>VMem: Consistent Interactive Video Scene Generation with Surfel-Indexed View Memory</h1>",
        "translatedContent": "<h1>VMem：基于表面元素索引视图记忆的一致交互式视频场景生成</h1>"
      },
      {
        "row": 4,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 5,
        "rowsha": "IXWkT6rBcrOFJYE9okPnTOLgEz4uGKEAWiWfVbaaKIg=",
        "originContent": "<p align=\"center\">ICCV 2025</p>",
        "translatedContent": "<p align=\"center\">ICCV 2025</p>"
      },
      {
        "row": 6,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 7,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 8,
        "rowsha": "12H8xP2ERMBSUma8Ep9/mh0W+yY0sUf9kdCj5yW5Tqg=",
        "originContent": "<a href=\"https://v-mem.github.io/\"><img src=\"https://img.shields.io/badge/%F0%9F%8F%A0%20Project%20Page-gray.svg\"></a>",
        "translatedContent": "<a href=\"https://v-mem.github.io/\"><img src=\"https://img.shields.io/badge/%F0%9F%8F%A0%20Project%20Page-gray.svg\"></a>"
      },
      {
        "row": 9,
        "rowsha": "iuL3AYwhx7kYbS+oKUQNxrgBiuQuduBvi+4mj9qC4es=",
        "originContent": "<a href=\"http://arxiv.org/abs/2506.18903\"><img src=\"https://img.shields.io/badge/%F0%9F%93%84%20arXiv-2506.18903-B31B1B.svg\"></a>",
        "translatedContent": "<a href=\"http://arxiv.org/abs/2506.18903\"><img src=\"https://img.shields.io/badge/%F0%9F%93%84%20arXiv-2506.18903-B31B1B.svg\"></a>"
      },
      {
        "row": 10,
        "rowsha": "9AaOSopZSzMN9eEnp+2Glvj6g4Pjp2qaJ4Ymp6UWnDg=",
        "originContent": "<a href=\"https://huggingface.co/liguang0115/vmem\"><img src=\"https://img.shields.io/badge/%F0%9F%A4%97%20Model_Card-Huggingface-orange\"></a>",
        "translatedContent": "<a href=\"https://huggingface.co/liguang0115/vmem\"><img src=\"https://img.shields.io/badge/%F0%9F%A4%97%20Model_Card-Huggingface-orange\"></a>"
      },
      {
        "row": 11,
        "rowsha": "A0bxHNjVrfeeKltpLK+LZaSzXBqTaOazSfm95/N9b0U=",
        "originContent": "<a href=\"https://huggingface.co/spaces/liguang0115/vmem\"><img src=\"https://img.shields.io/badge/%F0%9F%9A%80%20Gradio%20Demo-Huggingface-orange\"></a>",
        "translatedContent": "<a href=\"https://huggingface.co/spaces/liguang0115/vmem\"><img src=\"https://img.shields.io/badge/%F0%9F%9A%80%20Gradio%20Demo-Huggingface-orange\"></a>"
      },
      {
        "row": 12,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 13,
        "rowsha": "DdBsNt97Zo4Araion13v3IdA82RffKKWg+mdy2P8uFI=",
        "originContent": "[Runjia Li](https://runjiali-rl.github.io/), [Philip Torr](https://www.robots.ox.ac.uk/~phst/), [Andrea Vedaldi](https://www.robots.ox.ac.uk/~vedaldi/), [Tomas Jakab](https://www.robots.ox.ac.uk/~tomj/)",
        "translatedContent": "[李润佳](https://runjiali-rl.github.io/), [Philip Torr](https://www.robots.ox.ac.uk/~phst/), [Andrea Vedaldi](https://www.robots.ox.ac.uk/~vedaldi/), [Tomas Jakab](https://www.robots.ox.ac.uk/~tomj/)"
      },
      {
        "row": 14,
        "rowsha": "Za7xrbqGcqX+eTLZ+fDcNcJDWJP2URKsrGKNLcF6C88=",
        "originContent": "<br>",
        "translatedContent": "<br>"
      },
      {
        "row": 15,
        "rowsha": "Za7xrbqGcqX+eTLZ+fDcNcJDWJP2URKsrGKNLcF6C88=",
        "originContent": "<br>",
        "translatedContent": "<br>"
      },
      {
        "row": 16,
        "rowsha": "c8LWwduu9Cvp0hE86ux6OyVOMbypVAbyz1DWJZ1N4tE=",
        "originContent": "[University of Oxford](https://www.robots.ox.ac.uk/~vgg/)",
        "translatedContent": "[牛津大学](https://www.robots.ox.ac.uk/~vgg/)"
      },
      {
        "row": 17,
        "rowsha": "qsMmUbEPVnxGG5tPJV1vsfpoWbU2jYvZpRr5IKshzyM=",
        "originContent": "</div>",
        "translatedContent": "</div>"
      },
      {
        "row": 18,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 19,
        "rowsha": "+/a9XmPwQixGFroME/GMEOLpReZZV4ARosR9orAplJY=",
        "originContent": "<p align=\"center\">",
        "translatedContent": "<p align=\"center\">"
      },
      {
        "row": 20,
        "rowsha": "FwzIJyIYswPMfEnd3Heg332yCjCuTikk4a9YLts2Yk0=",
        "originContent": "  <img src=\"https://raw.githubusercontent.com/runjiali-rl/vmem/main/assets/demo_teaser.gif\" width=\"100%\" alt=\"Teaser\" style=\"border-radius:10px;\"/>",
        "translatedContent": "  <img src=\"https://raw.githubusercontent.com/runjiali-rl/vmem/main/assets/demo_teaser.gif\" width=\"100%\" alt=\"Teaser\" style=\"border-radius:10px;\"/>"
      },
      {
        "row": 21,
        "rowsha": "dSdvPNAZSmR86FDDSF6tkQUCVfI9qmACHOR5tThOetY=",
        "originContent": "</p>",
        "translatedContent": "</p>"
      },
      {
        "row": 22,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 23,
        "rowsha": "iCHSnG58DdUTrQ5+w4Y18uxD4/VHfAMo1CTptoujA44=",
        "originContent": "<!-- <p align=\"center\" border-radius=\"10px\">",
        "translatedContent": "<!-- <p align=\"center\" border-radius=\"10px\">"
      },
      {
        "row": 24,
        "rowsha": "+OoHYcat/fu97Dt9BHZja+BbyoJYt2JK6Dg8w39kJi4=",
        "originContent": "  <img src=\"https://raw.githubusercontent.com/runjiali-rl/vmem/main/assets/benchmark.png\" width=\"100%\" alt=\"teaser_page1\"/>",
        "translatedContent": "  <img src=\"https://raw.githubusercontent.com/runjiali-rl/vmem/main/assets/benchmark.png\" width=\"100%\" alt=\"teaser_page1\"/>"
      },
      {
        "row": 25,
        "rowsha": "bqXhAqBeGFOcy+yMM61cF0cF1HZoWS7rvEH5O6+MLgo=",
        "originContent": "</p> -->",
        "translatedContent": "</p> -->"
      },
      {
        "row": 26,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 27,
        "rowsha": "4ct9hhrs3178ur7dMe6XCFewLuyUDXLAhXSnsbO99YA=",
        "originContent": "# Overview",
        "translatedContent": "# 概述"
      },
      {
        "row": 28,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 29,
        "rowsha": "EyJ4wfSQAsxxidpu/6LBK2ny1jxsoNGK5KOuttS1YfM=",
        "originContent": "`VMem` is a plug-and-play memory mechanism of image-set models for consistent scene generation.",
        "translatedContent": "`VMem` 是一种可插拔的图像集模型记忆机制，用于一致的场景生成。"
      },
      {
        "row": 30,
        "rowsha": "tHu7HEwxMYJA8y2koQvb3nlM737c5g94T1eV6OAYUwM=",
        "originContent": "Existing methods either rely on inpainting with explicit geometry estimation, which suffers from inaccuracies, or use limited context windows in video-based approaches, leading to poor long-term coherence. To overcome these issues, we introduce Surfel Memory of Views (VMem), which anchors past views to surface elements (surfels) they observed. This enables conditioning novel view generation on the most relevant past views rather than just the most recent ones, enhancing long-term scene consistency while reducing computational cost.",
        "translatedContent": "现有方法要么依赖带有显式几何估计的图像修补，存在不准确问题；要么在基于视频的方法中使用有限的上下文窗口，导致长期一致性差。为克服这些问题，我们提出了视图表面元素记忆（VMem），将过去的视图锚定到它们观察到的表面元素（surfels）上。这使得新视图生成可以基于最相关的过去视图，而非仅仅是最近的视图，从而增强了长期场景一致性，同时降低了计算成本。"
      },
      {
        "row": 31,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 32,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 33,
        "rowsha": "L2KKcuhmRd4fOoDQBvx+2rI2fwKm/AWInWRH66e3f2M=",
        "originContent": "# :wrench: Installation",
        "translatedContent": "# :wrench: 安装"
      },
      {
        "row": 34,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 2,
    "Content": "```bash\nconda create -n vmem python=3.10\nconda activate vmem\npip install -r requirements.txt\n```",
    "ContentSha": "yOFM7iCaVWn8rwLyEoeKtmkPKk/6YHMkkFz4xKQblHc=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\nconda create -n vmem python=3.10\nconda activate vmem\npip install -r requirements.txt\n```",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "rTMjNc+qNIxb1xXDR5hEYiJw1fc4muBwuBsTXVIaIho=",
        "originContent": "```bash",
        "translatedContent": "```bash"
      },
      {
        "row": 2,
        "rowsha": "iUPTbDaxaofGuKiKLY0GRq4rmvzbN8GstklSkhNCTSQ=",
        "originContent": "conda create -n vmem python=3.10",
        "translatedContent": "conda create -n vmem python=3.10"
      },
      {
        "row": 3,
        "rowsha": "n1WJZUPh5CqLPg9vEgiqq++l15iVg6jiWWCQi4p/BWY=",
        "originContent": "conda activate vmem",
        "translatedContent": "conda activate vmem"
      },
      {
        "row": 4,
        "rowsha": "9jQ5Tmvmy0Rca8gZGuieLw3iHyIU3Ba5zS4ICtZgsdw=",
        "originContent": "pip install -r requirements.txt",
        "translatedContent": "pip install -r requirements.txt"
      },
      {
        "row": 5,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      }
    ],
    "IsCodeBlock": true
  },
  {
    "Id": 3,
    "Content": "\n\n# :rocket: Usage\n\nYou need to properly authenticate with Hugging Face to download our model weights. Once set up, our code will handle it automatically at your first run. You can authenticate by running\n",
    "ContentSha": "C5lB7GGxtaVbGVbjw75qAfl7npbv3oU3Ij2eKIX7Hho=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "<translate-content>\n\n# :rocket: 使用方法\n\n您需要正确认证 Hugging Face 以下载我们的模型权重。设置完成后，我们的代码将在您首次运行时自动处理。您可以通过运行进行认证\n</translate-content>",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "<translate-content>"
      },
      {
        "row": 2,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 3,
        "rowsha": "oD+UYKo3KLdZLcg1NFXuAiFGxirQczPKjK1R8h0kBKU=",
        "originContent": "# :rocket: Usage",
        "translatedContent": "# :rocket: 使用方法"
      },
      {
        "row": 4,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 5,
        "rowsha": "4Cnb/40Ezn1qUIogpAlKp88OsdDt0q7XwB4y0R4qfUc=",
        "originContent": "You need to properly authenticate with Hugging Face to download our model weights. Once set up, our code will handle it automatically at your first run. You can authenticate by running",
        "translatedContent": "您需要正确认证 Hugging Face 以下载我们的模型权重。设置完成后，我们的代码将在您首次运行时自动处理。您可以通过运行进行认证"
      },
      {
        "row": 6,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "</translate-content>"
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 4,
    "Content": "```bash\n# This will prompt you to enter your Hugging Face credentials.\nhuggingface-cli login\n```",
    "ContentSha": "gBgmsoghsldG6mWEbvEn1TVhipZe/yLMSS44CRxLSs0=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\n# This will prompt you to enter your Hugging Face credentials.\nhuggingface-cli login\n```",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "rTMjNc+qNIxb1xXDR5hEYiJw1fc4muBwuBsTXVIaIho=",
        "originContent": "```bash",
        "translatedContent": "```bash"
      },
      {
        "row": 2,
        "rowsha": "h2FWd/Ag+8MetQ1w0y0iclYT0wVhaF7kRj9uol/3HIk=",
        "originContent": "# This will prompt you to enter your Hugging Face credentials.",
        "translatedContent": "# This will prompt you to enter your Hugging Face credentials."
      },
      {
        "row": 3,
        "rowsha": "W0Xvph8W4mkGNv9wDyTW95OKeoUVMbNfTuCBFhP7qTI=",
        "originContent": "huggingface-cli login",
        "translatedContent": "huggingface-cli login"
      },
      {
        "row": 4,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      }
    ],
    "IsCodeBlock": true
  },
  {
    "Id": 5,
    "Content": "\nOnce authenticated, go to our model card [here](https://huggingface.co/liguang0115/vmem) and enter your information for access.\n\nWe provide a demo for you to interact with `VMem`. Simply run\n",
    "ContentSha": "5g2I4ViZe3yYUG3+vS788TwI2iIAbZywIsDf8WvMiEk=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "一旦验证通过，访问我们的模型卡[这里](https://huggingface.co/liguang0115/vmem)并输入您的访问信息。\n\n我们为您提供了一个与`VMem`交互的演示。只需运行\n\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "一旦验证通过，访问我们的模型卡[这里](https://huggingface.co/liguang0115/vmem)并输入您的访问信息。"
      },
      {
        "row": 2,
        "rowsha": "Xb6YoVP6k0gGPTIHKQA+nscILMcRBus23+qwAtkCP7c=",
        "originContent": "Once authenticated, go to our model card [here](https://huggingface.co/liguang0115/vmem) and enter your information for access.",
        "translatedContent": ""
      },
      {
        "row": 3,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "我们为您提供了一个与`VMem`交互的演示。只需运行"
      },
      {
        "row": 4,
        "rowsha": "CjkWYJLsvQe4wHF61QzJ2vCQin+/gFjbvCgkIKayEuo=",
        "originContent": "We provide a demo for you to interact with `VMem`. Simply run",
        "translatedContent": ""
      },
      {
        "row": 5,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 6,
    "Content": "```bash\npython app.py\n```",
    "ContentSha": "2nQFYMHYtsOO4+egbu20DhxqoaxfzoH8CneeM8qTEb0=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\npython app.py\n```",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "rTMjNc+qNIxb1xXDR5hEYiJw1fc4muBwuBsTXVIaIho=",
        "originContent": "```bash",
        "translatedContent": "```bash"
      },
      {
        "row": 2,
        "rowsha": "yTP73cr3O39gKLRUBLHoG37pGRVYjUGUDuod1taGRp8=",
        "originContent": "python app.py",
        "translatedContent": "python app.py"
      },
      {
        "row": 3,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      }
    ],
    "IsCodeBlock": true
  },
  {
    "Id": 7,
    "Content": "\n\n## :heart: Acknowledgement\nThis work is built on top of [CUT3R](https://github.com/CUT3R/CUT3R), [DUSt3R](https://github.com/naver/dust3r) and [Stable Virtual Camera](https://github.com/stability-ai/stable-virtual-camera). We thank them for their great works.\n\n\n\n\n\n# :books: Citing\n\nIf you find this repository useful, please consider giving a star :star: and citation.\n",
    "ContentSha": "HraNSDfNIxUyvZiMxhqtAG3mF02ZzqbnHUURxQu/Fzg=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "<translate-content>\n\n## :heart: 致谢\n本作品基于 [CUT3R](https://github.com/CUT3R/CUT3R)、[DUSt3R](https://github.com/naver/dust3r) 和 [Stable Virtual Camera](https://github.com/stability-ai/stable-virtual-camera) 开发。感谢他们的卓越贡献。\n\n\n\n\n\n# :books: 引用\n\n如果您觉得本仓库有用，请考虑点个星 :star: 并引用。\n</translate-content>",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "<translate-content>"
      },
      {
        "row": 2,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 3,
        "rowsha": "LmoVqWzcuWsqk67d8jb+aWXliPDfeHhCH2KGp1Ogth8=",
        "originContent": "## :heart: Acknowledgement",
        "translatedContent": "## :heart: 致谢"
      },
      {
        "row": 4,
        "rowsha": "plqXWgA/jm1Djbw2V0DDE7X4yX/OTCUcWSmpDBj1SuQ=",
        "originContent": "This work is built on top of [CUT3R](https://github.com/CUT3R/CUT3R), [DUSt3R](https://github.com/naver/dust3r) and [Stable Virtual Camera](https://github.com/stability-ai/stable-virtual-camera). We thank them for their great works.",
        "translatedContent": "本作品基于 [CUT3R](https://github.com/CUT3R/CUT3R)、[DUSt3R](https://github.com/naver/dust3r) 和 [Stable Virtual Camera](https://github.com/stability-ai/stable-virtual-camera) 开发。感谢他们的卓越贡献。"
      },
      {
        "row": 5,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 6,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 7,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 8,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 9,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 10,
        "rowsha": "aOLWq4SSnCjXEAuaKaueljmL5b5p5SD4QhOLxoM2N+Q=",
        "originContent": "# :books: Citing",
        "translatedContent": "# :books: 引用"
      },
      {
        "row": 11,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 12,
        "rowsha": "Ic0NUNdNRxBdpGU7VHESzEsn6sHjqA0RGH/1fE/5RUM=",
        "originContent": "If you find this repository useful, please consider giving a star :star: and citation.",
        "translatedContent": "如果您觉得本仓库有用，请考虑点个星 :star: 并引用。"
      },
      {
        "row": 13,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "</translate-content>"
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 8,
    "Content": "```\n@article{li2025vmem,\n  title={VMem: Consistent Interactive Video Scene Generation with Surfel-Indexed View Memory},\n  author={Li, Runjia and Torr, Philip and Vedaldi, Andrea and Jakab, Tomas},\n  journal={arXiv preprint arXiv:2506.18903},\n  year={2025}\n}\n```",
    "ContentSha": "9BIXjxPXKAEWuNGcaGAQzNzw+hFnLNHP4rouH1gW384=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```\n@article{li2025vmem,\n  title={VMem: Consistent Interactive Video Scene Generation with Surfel-Indexed View Memory},\n  author={Li, Runjia and Torr, Philip and Vedaldi, Andrea and Jakab, Tomas},\n  journal={arXiv preprint arXiv:2506.18903},\n  year={2025}\n}\n```",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      },
      {
        "row": 2,
        "rowsha": "9XqiMsGCnqSvk7rrteZBZQuM6MEUfuHIvsNNWuc2hOE=",
        "originContent": "@article{li2025vmem,",
        "translatedContent": "@article{li2025vmem,"
      },
      {
        "row": 3,
        "rowsha": "3C2/64hi97/wG002PgsjZw6hQRGlGImURj2XA+rF1c4=",
        "originContent": "  title={VMem: Consistent Interactive Video Scene Generation with Surfel-Indexed View Memory},",
        "translatedContent": "  title={VMem: Consistent Interactive Video Scene Generation with Surfel-Indexed View Memory},"
      },
      {
        "row": 4,
        "rowsha": "pLZ9bAizHEWU9iJ1bD10X1cSAKg1TYOxypr9hwMpFJM=",
        "originContent": "  author={Li, Runjia and Torr, Philip and Vedaldi, Andrea and Jakab, Tomas},",
        "translatedContent": "  author={Li, Runjia and Torr, Philip and Vedaldi, Andrea and Jakab, Tomas},"
      },
      {
        "row": 5,
        "rowsha": "6gN7J38G7mazvkw7cLNXpKGvxHtA1V2uKodvacPrUNQ=",
        "originContent": "  journal={arXiv preprint arXiv:2506.18903},",
        "translatedContent": "  journal={arXiv preprint arXiv:2506.18903},"
      },
      {
        "row": 6,
        "rowsha": "6oyqJVJ20XoZhlyGjaewQyTQsSBBtVAYmqUtTwjLbAg=",
        "originContent": "  year={2025}",
        "translatedContent": "  year={2025}"
      },
      {
        "row": 7,
        "rowsha": "0Qs2qnSlm89KiBhYN/ZYr682Ru/yuxbDko0OkzXpRdI=",
        "originContent": "}",
        "translatedContent": "}"
      },
      {
        "row": 8,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      }
    ],
    "IsCodeBlock": true
  },
  {
    "Id": 9,
    "Content": "",
    "ContentSha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  }
]