[
  {
    "Id": 1,
    "Content": "# End-to-end Trainable Deep Neural Network for Robotic Grasp Detection and Semantic Segmentation from RGB\n\n<p align=\"center\">\n<img src=\"https://raw.githubusercontent.com/stefan-ainetter/grasp_det_seg_cnn/main/Network.png\" width=\"100%\"/>\n<br>\n<a href=\"https://arxiv.org/abs/2107.05287\">arXiv</a>\n</p>\n\nThis repository contains the code for the ICRA21 paper \"End-to-end Trainable Deep Neural Network for Robotic Grasp Detection\nand Semantic Segmentation from RGB\". \nIt contains the code for training and testing our proposed method in combination with the OCID_grasp dataset. \n\nIf you use our method or dataset extension for your research, please cite:",
    "ContentSha": "SVcL4Yhz0nvluc9l267GviAm+saweS3ClVsW6jV+DdQ=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "# End-to-end Trainable Deep Neural Network for Robotic Grasp Detection and Semantic Segmentation from RGB\n\n<p align=\"center\">\n<img src=\"https://raw.githubusercontent.com/stefan-ainetter/grasp_det_seg_cnn/main/Network.png\" width=\"100%\"/>\n<br>\n<a href=\"https://arxiv.org/abs/2107.05287\">arXiv</a>\n</p>\n\nThis repository contains the code for the ICRA21 paper \"End-to-end Trainable Deep Neural Network for Robotic Grasp Detection\nand Semantic Segmentation from RGB\". \nIt contains the code for training and testing our proposed method in combination with the OCID_grasp dataset. \n\nIf you use our method or dataset extension for your research, please cite:",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "G6tLOUXN60voRKh47li5k1OEAr+74v2qWuhXZWybQZI=",
        "originContent": "# End-to-end Trainable Deep Neural Network for Robotic Grasp Detection and Semantic Segmentation from RGB",
        "translatedContent": "# End-to-end Trainable Deep Neural Network for Robotic Grasp Detection and Semantic Segmentation from RGB"
      },
      {
        "row": 2,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 3,
        "rowsha": "+/a9XmPwQixGFroME/GMEOLpReZZV4ARosR9orAplJY=",
        "originContent": "<p align=\"center\">",
        "translatedContent": "<p align=\"center\">"
      },
      {
        "row": 4,
        "rowsha": "pH8/wwzCP8rsHxoNAtQrJs1lkMEtd3A2b74TTe8WkTo=",
        "originContent": "<img src=\"https://raw.githubusercontent.com/stefan-ainetter/grasp_det_seg_cnn/main/Network.png\" width=\"100%\"/>",
        "translatedContent": "<img src=\"https://raw.githubusercontent.com/stefan-ainetter/grasp_det_seg_cnn/main/Network.png\" width=\"100%\"/>"
      },
      {
        "row": 5,
        "rowsha": "Za7xrbqGcqX+eTLZ+fDcNcJDWJP2URKsrGKNLcF6C88=",
        "originContent": "<br>",
        "translatedContent": "<br>"
      },
      {
        "row": 6,
        "rowsha": "CuvelhwGQWtDXJ9HTNReH1G5PZyqmjLHKUITZDpgiZU=",
        "originContent": "<a href=\"https://arxiv.org/abs/2107.05287\">arXiv</a>",
        "translatedContent": "<a href=\"https://arxiv.org/abs/2107.05287\">arXiv</a>"
      },
      {
        "row": 7,
        "rowsha": "dSdvPNAZSmR86FDDSF6tkQUCVfI9qmACHOR5tThOetY=",
        "originContent": "</p>",
        "translatedContent": "</p>"
      },
      {
        "row": 8,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 9,
        "rowsha": "fH/zrrkjtyY/2KffanHlIHCcfsouwE7HIkj3vPDPats=",
        "originContent": "This repository contains the code for the ICRA21 paper \"End-to-end Trainable Deep Neural Network for Robotic Grasp Detection",
        "translatedContent": "This repository contains the code for the ICRA21 paper \"End-to-end Trainable Deep Neural Network for Robotic Grasp Detection"
      },
      {
        "row": 10,
        "rowsha": "WbwkDIQ4KPQmQsaiPSaKkBRQww4Z6PbuOWqDNn+o8as=",
        "originContent": "and Semantic Segmentation from RGB\". ",
        "translatedContent": "and Semantic Segmentation from RGB\". "
      },
      {
        "row": 11,
        "rowsha": "wtLPiCjN/XO+eAeYXDG8Tcga1RGaW7GJ0sa43OfzB0c=",
        "originContent": "It contains the code for training and testing our proposed method in combination with the OCID_grasp dataset. ",
        "translatedContent": "It contains the code for training and testing our proposed method in combination with the OCID_grasp dataset. "
      },
      {
        "row": 12,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 13,
        "rowsha": "vFCeUREzbEaoLwryxEXs1Myw7Fntzv8Yeu1IgOC6yTU=",
        "originContent": "If you use our method or dataset extension for your research, please cite:",
        "translatedContent": "If you use our method or dataset extension for your research, please cite:"
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 2,
    "Content": "```bibtex\n@InProceedings{ainetter2021end,\n  title={End-to-end Trainable Deep Neural Network for Robotic Grasp Detection and Semantic Segmentation from RGB},\n  author={Ainetter, Stefan and Fraundorfer, Friedrich},\n  booktitle={IEEE International Conference on Robotics and Automation (ICRA)},\n  pages={13452--13458}\n  year={2021}\n}\n```",
    "ContentSha": "d3PI1UCnGvc/62HRxTI2RrZbEmHQLkGLWB/8pyqtPKM=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bibtex\n@InProceedings{ainetter2021end,\n  title={End-to-end Trainable Deep Neural Network for Robotic Grasp Detection and Semantic Segmentation from RGB},\n  author={Ainetter, Stefan and Fraundorfer, Friedrich},\n  booktitle={IEEE International Conference on Robotics and Automation (ICRA)},\n  pages={13452--13458}\n  year={2021}\n}\n```",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "o+TmyQ6wneV6/FQB6aUlRSjIGr2/YLJtnz5uxBgsScQ=",
        "originContent": "```bibtex",
        "translatedContent": "```bibtex"
      },
      {
        "row": 2,
        "rowsha": "h1kd4vKaSqjXa1Rhc7YGHRAdCDKI4AH6jjYEo9VdWQ0=",
        "originContent": "@InProceedings{ainetter2021end,",
        "translatedContent": "@InProceedings{ainetter2021end,"
      },
      {
        "row": 3,
        "rowsha": "JyhfHtsN2W5tsN9lYVOubkqpu/qhfSZTsDq3V1tNeYE=",
        "originContent": "  title={End-to-end Trainable Deep Neural Network for Robotic Grasp Detection and Semantic Segmentation from RGB},",
        "translatedContent": "  title={End-to-end Trainable Deep Neural Network for Robotic Grasp Detection and Semantic Segmentation from RGB},"
      },
      {
        "row": 4,
        "rowsha": "f9m2jImP5cv/fNjXVcxgzdWvt95drcIUc8RXzO8gA4I=",
        "originContent": "  author={Ainetter, Stefan and Fraundorfer, Friedrich},",
        "translatedContent": "  author={Ainetter, Stefan and Fraundorfer, Friedrich},"
      },
      {
        "row": 5,
        "rowsha": "ltjqa7zSoDG1Va/fAKC/BpOkmu96NjI1oNDOatNcXXI=",
        "originContent": "  booktitle={IEEE International Conference on Robotics and Automation (ICRA)},",
        "translatedContent": "  booktitle={IEEE International Conference on Robotics and Automation (ICRA)},"
      },
      {
        "row": 6,
        "rowsha": "MtbIAPrXLQzWAamxiTweFAsnQU1+aukDxXgHNCMMeP4=",
        "originContent": "  pages={13452--13458}",
        "translatedContent": "  pages={13452--13458}"
      },
      {
        "row": 7,
        "rowsha": "QRDXTY8rj/7Ra4fyR1kolwdti02Ai8YiXxcKkmvqL6A=",
        "originContent": "  year={2021}",
        "translatedContent": "  year={2021}"
      },
      {
        "row": 8,
        "rowsha": "0Qs2qnSlm89KiBhYN/ZYr682Ru/yuxbDko0OkzXpRdI=",
        "originContent": "}",
        "translatedContent": "}"
      },
      {
        "row": 9,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      }
    ],
    "IsCodeBlock": true
  },
  {
    "Id": 3,
    "Content": "\n## Requirements and setup\n\nMain system requirements:\n* CUDA 10.1\n* Linux with GCC 7 or 8\n* PyTorch v1.1.0\n\n**IMPORTANT NOTE**: These requirements are not necessarily stringent, e.g. it might be possible to compile with older\nversions of CUDA, or under Windows. However, we have only tested the code under the above settings and cannot provide support for other setups.\n\nTo install PyTorch, please refer to https://github.com/pytorch/pytorch#installation.\n\nTo install all other dependencies using pip:",
    "ContentSha": "UFXfdTH1VMMvXvoYFInoh3GsLHEfMCOpW692iLxdrhc=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "\n## Requirements and setup\n\nMain system requirements:\n* CUDA 10.1\n* Linux with GCC 7 or 8\n* PyTorch v1.1.0\n\n**IMPORTANT NOTE**: These requirements are not necessarily stringent, e.g. it might be possible to compile with older\nversions of CUDA, or under Windows. However, we have only tested the code under the above settings and cannot provide support for other setups.\n\nTo install PyTorch, please refer to https://github.com/pytorch/pytorch#installation.\n\nTo install all other dependencies using pip:",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 2,
        "rowsha": "1tGc+hUZn8nYqXxFVag9q+5fBxbE/pkH8+yiV3VL5rY=",
        "originContent": "## Requirements and setup",
        "translatedContent": "## Requirements and setup"
      },
      {
        "row": 3,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 4,
        "rowsha": "7r2ACHoGnPV8CntIHsGfA8OBYmpX4Nx+uiaU0z0iwwk=",
        "originContent": "Main system requirements:",
        "translatedContent": "Main system requirements:"
      },
      {
        "row": 5,
        "rowsha": "TZPw9SBiMuZiCyyd322q6bhrgV2zOJjUihpQGOzKE1w=",
        "originContent": "* CUDA 10.1",
        "translatedContent": "* CUDA 10.1"
      },
      {
        "row": 6,
        "rowsha": "fRGf0OTtlu/bPQRO743G7LDErwd4IdLVpc97C2DeoNg=",
        "originContent": "* Linux with GCC 7 or 8",
        "translatedContent": "* Linux with GCC 7 or 8"
      },
      {
        "row": 7,
        "rowsha": "HCjVgy9x+EgdYwuUlxmnizotny5QVOtTyGEedMCK11w=",
        "originContent": "* PyTorch v1.1.0",
        "translatedContent": "* PyTorch v1.1.0"
      },
      {
        "row": 8,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 9,
        "rowsha": "uycUK8znZrBag4mNqBCLgGvqfbw5e9V23wBsfNp2tyM=",
        "originContent": "**IMPORTANT NOTE**: These requirements are not necessarily stringent, e.g. it might be possible to compile with older",
        "translatedContent": "**IMPORTANT NOTE**: These requirements are not necessarily stringent, e.g. it might be possible to compile with older"
      },
      {
        "row": 10,
        "rowsha": "WwbbY+qo+iTmWP879j87O9aLNFuUXyCIKeYd12o1FDU=",
        "originContent": "versions of CUDA, or under Windows. However, we have only tested the code under the above settings and cannot provide support for other setups.",
        "translatedContent": "versions of CUDA, or under Windows. However, we have only tested the code under the above settings and cannot provide support for other setups."
      },
      {
        "row": 11,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 12,
        "rowsha": "2Eq/W2HxRllVzFi6pbPbn1BUKOHemqLKT9mjEf7nO5s=",
        "originContent": "To install PyTorch, please refer to https://github.com/pytorch/pytorch#installation.",
        "translatedContent": "To install PyTorch, please refer to https://github.com/pytorch/pytorch#installation."
      },
      {
        "row": 13,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 14,
        "rowsha": "l+i0lLCSEcqojMGwhreVo9q3Ad1wtnjQfsDlawqDvfc=",
        "originContent": "To install all other dependencies using pip:",
        "translatedContent": "To install all other dependencies using pip:"
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 4,
    "Content": "```bash\npip install -r requirements.txt\n```",
    "ContentSha": "TxMa9uJC0PmBOnm3/TRl4YDLNvSwCWaRNjyXpFhndHU=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\npip install -r requirements.txt\n```",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "rTMjNc+qNIxb1xXDR5hEYiJw1fc4muBwuBsTXVIaIho=",
        "originContent": "```bash",
        "translatedContent": "```bash"
      },
      {
        "row": 2,
        "rowsha": "9jQ5Tmvmy0Rca8gZGuieLw3iHyIU3Ba5zS4ICtZgsdw=",
        "originContent": "pip install -r requirements.txt",
        "translatedContent": "pip install -r requirements.txt"
      },
      {
        "row": 3,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      }
    ],
    "IsCodeBlock": true
  },
  {
    "Id": 5,
    "Content": "\n### Setup\n\nOur code is split into two main components: a library containing implementations for the various network modules,\nalgorithms and utilities, and a set of scripts to train / test the networks.\n\nThe library, called `grasp_det_seg`, can be installed with:",
    "ContentSha": "SHXHm6LwhsTa8/A96p/4S2FD72Xd+i/4idVqm7HWqh8=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "\n### Setup\n\nOur code is divided into two main components: a library containing implementations of various network modules,\nalgorithms, and utilities, and a set of scripts to train/test the networks.\n\nThe library, called `grasp_det_seg`, can be installed with:",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 2,
        "rowsha": "iJa409tTUC9P1gTULbIw6Kod+KAUdLl5kgZl7whoChE=",
        "originContent": "### Setup",
        "translatedContent": "### Setup"
      },
      {
        "row": 3,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 4,
        "rowsha": "l+Y9N09haW9XicaL32+pdyUSAZo2Pgqz1ockT35q8M4=",
        "originContent": "Our code is split into two main components: a library containing implementations for the various network modules,",
        "translatedContent": "Our code is divided into two main components: a library containing implementations of various network modules,"
      },
      {
        "row": 5,
        "rowsha": "7GRjc31hbX29IdxC23tIlk5Z/B1qlX+1gcXzAAlSNsI=",
        "originContent": "algorithms and utilities, and a set of scripts to train / test the networks.",
        "translatedContent": "algorithms, and utilities, and a set of scripts to train/test the networks."
      },
      {
        "row": 6,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 7,
        "rowsha": "/IuZZ8KRVzkty19LeVwo1LCv9/UO6cuF8GzGVwuNBnw=",
        "originContent": "The library, called `grasp_det_seg`, can be installed with:",
        "translatedContent": "The library, called `grasp_det_seg`, can be installed with:"
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 6,
    "Content": "```bash\ngit clone https://github.com/stefan-ainetter/grasp_det_seg_cnn.git\ncd grasp_det_seg_cnn\npython setup.py install\n```",
    "ContentSha": "Lgds7avU61M+o+IZAPV/m1Ps2MWZvfxeNyxV1Z0Krfw=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\ngit clone https://github.com/stefan-ainetter/grasp_det_seg_cnn.git\ncd grasp_det_seg_cnn\npython setup.py install\n```",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "rTMjNc+qNIxb1xXDR5hEYiJw1fc4muBwuBsTXVIaIho=",
        "originContent": "```bash",
        "translatedContent": "```bash"
      },
      {
        "row": 2,
        "rowsha": "2u6RRIHpvUX2y6/Uw/S92huMpcWyZqT2h1wwqktSjKU=",
        "originContent": "git clone https://github.com/stefan-ainetter/grasp_det_seg_cnn.git",
        "translatedContent": "git clone https://github.com/stefan-ainetter/grasp_det_seg_cnn.git"
      },
      {
        "row": 3,
        "rowsha": "tN9rJige5VjRAS/pNa+BKxlGZEm4j6cLqcnG9FYNvKk=",
        "originContent": "cd grasp_det_seg_cnn",
        "translatedContent": "cd grasp_det_seg_cnn"
      },
      {
        "row": 4,
        "rowsha": "ZTt6UdZddAnjGeKdUdXuKvZdYhrZ72IUjn6s+Z4omHk=",
        "originContent": "python setup.py install",
        "translatedContent": "python setup.py install"
      },
      {
        "row": 5,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      }
    ],
    "IsCodeBlock": true
  },
  {
    "Id": 7,
    "Content": "\n## Trained models\n\nThe model files provided are made available under the [CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/) license.\n\nA trained model for the OCID_grasp dataset can be downloaded [here](https://cloud.tugraz.at/index.php/s/NA7icqiJ5SeNSA6?dir=/Grasp_det_seg_cnn/OCID_pretrained). \nDownload and copy the downloaded weights into the `ckpt_files_OCID/pretrained` folder.\n\nFor re-training the network on OCID_grasp, you need to download weights pretrained on ImageNet \n[here](https://cloud.tugraz.at/index.php/s/NA7icqiJ5SeNSA6?dir=/Grasp_det_seg_cnn/ImageNet_weights) and copy them \ninto the `weights_pretrained` folder.\n\n### Training\n\nTraining involves three main steps: Preparing the dataset, creating a configuration file and running the training\nscript.\n\nTo prepare the dataset:\n1) Download the OCID_grasp dataset [here](https://cloud.tugraz.at/index.php/s/NA7icqiJ5SeNSA6?dir=/Grasp_det_seg_cnn/OCID_grasp).\nUnpack the downloaded `OCID_grasp.zip` file into the `DATA` folder.\n2) The configuration file is a simple text file in `ini` format.\nThe default value of each configuration parameter, as well as a short description of what it does, is available in\n[grasp_det_seg/config/defaults](grasp_det_seg/config/defaults).\n**Note** that these are just an indication of what a \"reasonable\" value for each parameter could be, and are not\nmeant as a way to reproduce any of the results from our paper.\n\n3) To launch the training:",
    "ContentSha": "UnxWxD0oRxePXcKwPwtt7yjvluEUUyEuxyrkoASNGw4=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "\n## Trained models\n\nThe model files provided are made available under the [CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/) license.\n\nA trained model for the OCID_grasp dataset can be downloaded [here](https://cloud.tugraz.at/index.php/s/NA7icqiJ5SeNSA6?dir=/Grasp_det_seg_cnn/OCID_pretrained). \nDownload and copy the downloaded weights into the `ckpt_files_OCID/pretrained` folder.\n\nFor re-training the network on OCID_grasp, you need to download weights pretrained on ImageNet \n[here](https://cloud.tugraz.at/index.php/s/NA7icqiJ5SeNSA6?dir=/Grasp_det_seg_cnn/ImageNet_weights) and copy them \ninto the `weights_pretrained` folder.\n\n### Training\n\nTraining involves three main steps: Preparing the dataset, creating a configuration file and running the training\nscript.\n\nTo prepare the dataset:\n1) Download the OCID_grasp dataset [here](https://cloud.tugraz.at/index.php/s/NA7icqiJ5SeNSA6?dir=/Grasp_det_seg_cnn/OCID_grasp).\nUnpack the downloaded `OCID_grasp.zip` file into the `DATA` folder.\n2) The configuration file is a simple text file in `ini` format.\nThe default value of each configuration parameter, as well as a short description of what it does, is available in\n[grasp_det_seg/config/defaults](grasp_det_seg/config/defaults).\n**Note** that these are just an indication of what a \"reasonable\" value for each parameter could be, and are not\nmeant as a way to reproduce any of the results from our paper.\n\n3) To launch the training:",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 2,
        "rowsha": "Gs54AtwofEk9CwPO7KHNzntI0Od7uMv4wOR82+zDc2c=",
        "originContent": "## Trained models",
        "translatedContent": "## Trained models"
      },
      {
        "row": 3,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 4,
        "rowsha": "0feZmXrFMgl0/yeAtYaoKgOnVFNoCosrkr/szAMAEHY=",
        "originContent": "The model files provided are made available under the [CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/) license.",
        "translatedContent": "The model files provided are made available under the [CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/) license."
      },
      {
        "row": 5,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 6,
        "rowsha": "UPmrEFiHa9kCLhmjsulrUFLiS10PnptZC4ExYAXabvE=",
        "originContent": "A trained model for the OCID_grasp dataset can be downloaded [here](https://cloud.tugraz.at/index.php/s/NA7icqiJ5SeNSA6?dir=/Grasp_det_seg_cnn/OCID_pretrained). ",
        "translatedContent": "A trained model for the OCID_grasp dataset can be downloaded [here](https://cloud.tugraz.at/index.php/s/NA7icqiJ5SeNSA6?dir=/Grasp_det_seg_cnn/OCID_pretrained). "
      },
      {
        "row": 7,
        "rowsha": "txKsBTjA5jCUWxL7pKby+9HNPLSDwGdSRkpru3FsVuc=",
        "originContent": "Download and copy the downloaded weights into the `ckpt_files_OCID/pretrained` folder.",
        "translatedContent": "Download and copy the downloaded weights into the `ckpt_files_OCID/pretrained` folder."
      },
      {
        "row": 8,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 9,
        "rowsha": "72kq0hyVh6nY/FQCr3kQzFkQEUD/0xlIJlxYVy0SyJk=",
        "originContent": "For re-training the network on OCID_grasp, you need to download weights pretrained on ImageNet ",
        "translatedContent": "For re-training the network on OCID_grasp, you need to download weights pretrained on ImageNet "
      },
      {
        "row": 10,
        "rowsha": "wZcoZ52PxtS1qHWwqDrpMRr4FJO+OSvr9VuYezjMPww=",
        "originContent": "[here](https://cloud.tugraz.at/index.php/s/NA7icqiJ5SeNSA6?dir=/Grasp_det_seg_cnn/ImageNet_weights) and copy them ",
        "translatedContent": "[here](https://cloud.tugraz.at/index.php/s/NA7icqiJ5SeNSA6?dir=/Grasp_det_seg_cnn/ImageNet_weights) and copy them "
      },
      {
        "row": 11,
        "rowsha": "9+SzBNdXOWg35LZ/WogXSVv18gnAI4SyOylfBUZHhTA=",
        "originContent": "into the `weights_pretrained` folder.",
        "translatedContent": "into the `weights_pretrained` folder."
      },
      {
        "row": 12,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 13,
        "rowsha": "cNKS2XI0q3UNj4+rlFmjA0lefbWomrdh7j5BPCDMKNw=",
        "originContent": "### Training",
        "translatedContent": "### Training"
      },
      {
        "row": 14,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 15,
        "rowsha": "eQCAQ6FcBRihX0kFBysSKKnUmSUlgrm5+sqlkkVs1Vc=",
        "originContent": "Training involves three main steps: Preparing the dataset, creating a configuration file and running the training",
        "translatedContent": "Training involves three main steps: Preparing the dataset, creating a configuration file and running the training"
      },
      {
        "row": 16,
        "rowsha": "HpkQECi3IwVSLmb3kLtCyOav8kaiFi57Bdg7xS6ONqQ=",
        "originContent": "script.",
        "translatedContent": "script."
      },
      {
        "row": 17,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 18,
        "rowsha": "tpVK+Jl785dtv9eRwIdSmlHVOAnppxQp7PdncX7qBic=",
        "originContent": "To prepare the dataset:",
        "translatedContent": "To prepare the dataset:"
      },
      {
        "row": 19,
        "rowsha": "u4KQCuZojCvF1PzYEeSJImsRUcCx/xZ6fP7BkUlkJQ0=",
        "originContent": "1) Download the OCID_grasp dataset [here](https://cloud.tugraz.at/index.php/s/NA7icqiJ5SeNSA6?dir=/Grasp_det_seg_cnn/OCID_grasp).",
        "translatedContent": "1) Download the OCID_grasp dataset [here](https://cloud.tugraz.at/index.php/s/NA7icqiJ5SeNSA6?dir=/Grasp_det_seg_cnn/OCID_grasp)."
      },
      {
        "row": 20,
        "rowsha": "ADwSTE0uOm0YiRN9G7wn4LGZJaKg9TpV0bI7v+0xWe8=",
        "originContent": "Unpack the downloaded `OCID_grasp.zip` file into the `DATA` folder.",
        "translatedContent": "Unpack the downloaded `OCID_grasp.zip` file into the `DATA` folder."
      },
      {
        "row": 21,
        "rowsha": "9khvzqP/nuqCIHxURD4M5/RMdgd6fGTbiRytAv/Vu4k=",
        "originContent": "2) The configuration file is a simple text file in `ini` format.",
        "translatedContent": "2) The configuration file is a simple text file in `ini` format."
      },
      {
        "row": 22,
        "rowsha": "zVg4u89O16LTTAWaWzcPeiciH7t/6b5iYPSINnJBr3A=",
        "originContent": "The default value of each configuration parameter, as well as a short description of what it does, is available in",
        "translatedContent": "The default value of each configuration parameter, as well as a short description of what it does, is available in"
      },
      {
        "row": 23,
        "rowsha": "++SaMnKd9NSnQbJPlemRnnlive33/vKwuVQkRZzsYK8=",
        "originContent": "[grasp_det_seg/config/defaults](grasp_det_seg/config/defaults).",
        "translatedContent": "[grasp_det_seg/config/defaults](grasp_det_seg/config/defaults)."
      },
      {
        "row": 24,
        "rowsha": "Y+Wsp7KYCUTP2c8BxrSpJCxfZUctQwLvbQmA/G3CaKs=",
        "originContent": "**Note** that these are just an indication of what a \"reasonable\" value for each parameter could be, and are not",
        "translatedContent": "**Note** that these are just an indication of what a \"reasonable\" value for each parameter could be, and are not"
      },
      {
        "row": 25,
        "rowsha": "bYp7c0oCKqoi3PSHm3X3KzVSkpXRLEvtnf0AYsEpobo=",
        "originContent": "meant as a way to reproduce any of the results from our paper.",
        "translatedContent": "meant as a way to reproduce any of the results from our paper."
      },
      {
        "row": 26,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 27,
        "rowsha": "Xd6eLHO6BJNziG5Vqan0sNlH5nHLKqxfm1C8YsPg3bs=",
        "originContent": "3) To launch the training:",
        "translatedContent": "3) To launch the training:"
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 8,
    "Content": "```bash\ncd scripts\npython3 -m torch.distributed.launch --nproc_per_node=1 train_det_seg_OCID.py \n--log_dir=LOGDIR CONFIG DATA_DIR\n```",
    "ContentSha": "16PG9/TtAudgTWZKznPTizPiNRRykijVxsruX/FmHSI=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\ncd scripts\npython3 -m torch.distributed.launch --nproc_per_node=1 train_det_seg_OCID.py \n--log_dir=LOGDIR CONFIG DATA_DIR\n```",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "rTMjNc+qNIxb1xXDR5hEYiJw1fc4muBwuBsTXVIaIho=",
        "originContent": "```bash",
        "translatedContent": "```bash"
      },
      {
        "row": 2,
        "rowsha": "osdQT8ZHo/O5eva3VI/7Opomtqcc3lffSxdAmcGTCF8=",
        "originContent": "cd scripts",
        "translatedContent": "cd scripts"
      },
      {
        "row": 3,
        "rowsha": "tEgUyhabRdKjjns4U427ynszGjjzBTQtIvQKDgT9h7s=",
        "originContent": "python3 -m torch.distributed.launch --nproc_per_node=1 train_det_seg_OCID.py ",
        "translatedContent": "python3 -m torch.distributed.launch --nproc_per_node=1 train_det_seg_OCID.py "
      },
      {
        "row": 4,
        "rowsha": "q4FS2Y0P/c08fKkLNy8SBnnjSEselS41NuDn9USn/DA=",
        "originContent": "--log_dir=LOGDIR CONFIG DATA_DIR",
        "translatedContent": "--log_dir=LOGDIR CONFIG DATA_DIR"
      },
      {
        "row": 5,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      }
    ],
    "IsCodeBlock": true
  },
  {
    "Id": 9,
    "Content": "Training logs, both in text and Tensorboard formats as well as the trained network parameters, will be written \nin `LOG_DIR` (e.g. `ckpt_files_OCID`).\nThe file `CONFIG` contains the network configuration e.g. `grasp_det_seg/config/defaults/det_seg_OCID.ini`, \nand `DATA_DIR` points to the previously downloaded OCID_grasp splits, e.g. `DATA/OCID_grasp/data_split`.\n\nNote that, for now, our code **must** be launched in \"distributed\" mode using PyTorch's `torch.distributed.launch`\nutility.\n\n### Running inference\n\nGiven a trained network, inference can be run on any set of images using\n[scripts/test_det_seg_OCID.py](https://raw.githubusercontent.com/stefan-ainetter/grasp_det_seg_cnn/main/scripts/test_det_seg_OCID.py):",
    "ContentSha": "aSovULCugM/xlZZAJNOk2TmLLBuOFAamaZZHCREkK8s=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "Training logs, both in text and Tensorboard formats as well as the trained network parameters, will be written \nin `LOG_DIR` (e.g. `ckpt_files_OCID`).\nThe file `CONFIG` contains the network configuration e.g. `grasp_det_seg/config/defaults/det_seg_OCID.ini`, \nand `DATA_DIR` points to the previously downloaded OCID_grasp splits, e.g. `DATA/OCID_grasp/data_split`.\n\nNote that, for now, our code **must** be launched in \"distributed\" mode using PyTorch's `torch.distributed.launch`\nutility.\n\n### Running inference\n\nGiven a trained network, inference can be run on any set of images using\n[scripts/test_det_seg_OCID.py](https://raw.githubusercontent.com/stefan-ainetter/grasp_det_seg_cnn/main/scripts/test_det_seg_OCID.py):",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "yy+xTAi6zMVy+2qRYEUPROQlK8ocDLRAkogfA6UcJjc=",
        "originContent": "Training logs, both in text and Tensorboard formats as well as the trained network parameters, will be written ",
        "translatedContent": "Training logs, both in text and Tensorboard formats as well as the trained network parameters, will be written "
      },
      {
        "row": 2,
        "rowsha": "BEx7AI+OB7Jj8OcICE3KLIXz3aKNkh1NsZmctqx2p/8=",
        "originContent": "in `LOG_DIR` (e.g. `ckpt_files_OCID`).",
        "translatedContent": "in `LOG_DIR` (e.g. `ckpt_files_OCID`)."
      },
      {
        "row": 3,
        "rowsha": "Bu7ySMKBqd150OhO7PFMh9uTYcj2accejh0G1a/++i4=",
        "originContent": "The file `CONFIG` contains the network configuration e.g. `grasp_det_seg/config/defaults/det_seg_OCID.ini`, ",
        "translatedContent": "The file `CONFIG` contains the network configuration e.g. `grasp_det_seg/config/defaults/det_seg_OCID.ini`, "
      },
      {
        "row": 4,
        "rowsha": "bBY1sqoGZi709tajOP28z7yiqnjbo8HzF1YtKFzA0Ao=",
        "originContent": "and `DATA_DIR` points to the previously downloaded OCID_grasp splits, e.g. `DATA/OCID_grasp/data_split`.",
        "translatedContent": "and `DATA_DIR` points to the previously downloaded OCID_grasp splits, e.g. `DATA/OCID_grasp/data_split`."
      },
      {
        "row": 5,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 6,
        "rowsha": "Jw/o3WswNmPBknyZfhLaopDNoPgILYdVgdRaWOh35ag=",
        "originContent": "Note that, for now, our code **must** be launched in \"distributed\" mode using PyTorch's `torch.distributed.launch`",
        "translatedContent": "Note that, for now, our code **must** be launched in \"distributed\" mode using PyTorch's `torch.distributed.launch`"
      },
      {
        "row": 7,
        "rowsha": "lKseaZ5op3JHQbfrM0Q6rX6I4fxKK16JL5kMEY6cpCc=",
        "originContent": "utility.",
        "translatedContent": "utility."
      },
      {
        "row": 8,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 9,
        "rowsha": "YHsJXu+tqYYP3JoETNjFeyieKrZ1zh5YeHPj3BxSra8=",
        "originContent": "### Running inference",
        "translatedContent": "### Running inference"
      },
      {
        "row": 10,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 11,
        "rowsha": "rhC37uBssuCbgoaCmctv8tg/4FTOS0lX8uKlqG5acJs=",
        "originContent": "Given a trained network, inference can be run on any set of images using",
        "translatedContent": "Given a trained network, inference can be run on any set of images using"
      },
      {
        "row": 12,
        "rowsha": "L0xtXB/FtI3LuT57l5g7k7p3m80i/bNsHt6AwqEUO/I=",
        "originContent": "[scripts/test_det_seg_OCID.py](https://raw.githubusercontent.com/stefan-ainetter/grasp_det_seg_cnn/main/scripts/test_det_seg_OCID.py):",
        "translatedContent": "[scripts/test_det_seg_OCID.py](https://raw.githubusercontent.com/stefan-ainetter/grasp_det_seg_cnn/main/scripts/test_det_seg_OCID.py):"
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 10,
    "Content": "```bash\ncd scripts\npython3 -m torch.distributed.launch --nproc_per_node=1 test_det_seg_OCID.py \n--log_dir=LOG_DIR CONFIG MODEL_PARAMS DATA_DIR OUTPUT_DIR\n\n```",
    "ContentSha": "rAAfgkUxfkYKGLFnUxyhhq/9OtPyM6Zb7inzaTXf6tg=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\ncd scripts\npython3 -m torch.distributed.launch --nproc_per_node=1 test_det_seg_OCID.py \n--log_dir=LOG_DIR CONFIG MODEL_PARAMS DATA_DIR OUTPUT_DIR\n\n```",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "rTMjNc+qNIxb1xXDR5hEYiJw1fc4muBwuBsTXVIaIho=",
        "originContent": "```bash",
        "translatedContent": "```bash"
      },
      {
        "row": 2,
        "rowsha": "osdQT8ZHo/O5eva3VI/7Opomtqcc3lffSxdAmcGTCF8=",
        "originContent": "cd scripts",
        "translatedContent": "cd scripts"
      },
      {
        "row": 3,
        "rowsha": "yGo/xltjzI9kCDic5lsbvmwZ103W6IopdoA++1FbXS0=",
        "originContent": "python3 -m torch.distributed.launch --nproc_per_node=1 test_det_seg_OCID.py ",
        "translatedContent": "python3 -m torch.distributed.launch --nproc_per_node=1 test_det_seg_OCID.py "
      },
      {
        "row": 4,
        "rowsha": "UlLXky6k0jdCYpJUQdMjSDyNW9NWFhRikAqvRBZ1Sq4=",
        "originContent": "--log_dir=LOG_DIR CONFIG MODEL_PARAMS DATA_DIR OUTPUT_DIR",
        "translatedContent": "--log_dir=LOG_DIR CONFIG MODEL_PARAMS DATA_DIR OUTPUT_DIR"
      },
      {
        "row": 5,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 6,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      }
    ],
    "IsCodeBlock": true
  },
  {
    "Id": 11,
    "Content": "Predictions will be written to `OUTPUT_DIR` e.g. the `output` folder. `MODEL_PARAMS` are pre-trained weights e.g. `ckpt_files_OCID/pretrained/model_last.pth.tar`, \n`DATA_DIR` points to the used dateset splits e.g. `DATA/OCID_grasp/data_split`.\n\n## OCID_grasp dataset\nThe OCID_grasp dataset can be downloaded [here](https://cloud.tugraz.at/index.php/s/NA7icqiJ5SeNSA6?dir=/Grasp_det_seg_cnn/OCID_grasp).\nOCID_grasp consists of 1763 selected RGB-D images of the OCID dataset, with over 11.4k segmented object masks and more than 75k hand-annotated \ngrasp candidates. Additionally, each object is classified into one of 31 object classes.\n## Related Work\nOCID_grasp is a dataset extension of the [OCID dataset](https://www.acin.tuwien.ac.at/en/vision-for-robotics/software-tools/object-clutter-indoor-dataset/).\nIf you decide to use OCID_grasp for your research, please also cite the OCID paper:",
    "ContentSha": "Q+rjaJD+yucVKHOa0N6DoyXk+1EPs6Hvapxo2Y2IJag=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "Predictions will be written to `OUTPUT_DIR` e.g. the `output` folder. `MODEL_PARAMS` are pre-trained weights e.g. `ckpt_files_OCID/pretrained/model_last.pth.tar`, \n`DATA_DIR` points to the used dateset splits e.g. `DATA/OCID_grasp/data_split`.\n\n## OCID_grasp dataset\nThe OCID_grasp dataset can be downloaded [here](https://cloud.tugraz.at/index.php/s/NA7icqiJ5SeNSA6?dir=/Grasp_det_seg_cnn/OCID_grasp).\nOCID_grasp consists of 1763 selected RGB-D images of the OCID dataset, with over 11.4k segmented object masks and more than 75k hand-annotated \ngrasp candidates. Additionally, each object is classified into one of 31 object classes.\n## Related Work\nOCID_grasp is a dataset extension of the [OCID dataset](https://www.acin.tuwien.ac.at/en/vision-for-robotics/software-tools/object-clutter-indoor-dataset/).\nIf you decide to use OCID_grasp for your research, please also cite the OCID paper:",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "LGfuta0BJtREwunwa0cA444cqws6wg2/1Zr9ase6uuE=",
        "originContent": "Predictions will be written to `OUTPUT_DIR` e.g. the `output` folder. `MODEL_PARAMS` are pre-trained weights e.g. `ckpt_files_OCID/pretrained/model_last.pth.tar`, ",
        "translatedContent": "Predictions will be written to `OUTPUT_DIR` e.g. the `output` folder. `MODEL_PARAMS` are pre-trained weights e.g. `ckpt_files_OCID/pretrained/model_last.pth.tar`, "
      },
      {
        "row": 2,
        "rowsha": "mg/tvYR/kVEYh6aDAm3zEGBiwMfFuhYCywAX+Bg4RiU=",
        "originContent": "`DATA_DIR` points to the used dateset splits e.g. `DATA/OCID_grasp/data_split`.",
        "translatedContent": "`DATA_DIR` points to the used dateset splits e.g. `DATA/OCID_grasp/data_split`."
      },
      {
        "row": 3,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 4,
        "rowsha": "qFhWQWGReCAAodXBX54hbnJArb6K84zlkpenVBoWvzM=",
        "originContent": "## OCID_grasp dataset",
        "translatedContent": "## OCID_grasp dataset"
      },
      {
        "row": 5,
        "rowsha": "omrqOod/6P5EpDL+v1RdkiqkgG8yUeCY5TABr3iIunI=",
        "originContent": "The OCID_grasp dataset can be downloaded [here](https://cloud.tugraz.at/index.php/s/NA7icqiJ5SeNSA6?dir=/Grasp_det_seg_cnn/OCID_grasp).",
        "translatedContent": "The OCID_grasp dataset can be downloaded [here](https://cloud.tugraz.at/index.php/s/NA7icqiJ5SeNSA6?dir=/Grasp_det_seg_cnn/OCID_grasp)."
      },
      {
        "row": 6,
        "rowsha": "dZds0w4Cjy/fLl4MXyAUKeztcwpYlkHktDB8Qr/SNZQ=",
        "originContent": "OCID_grasp consists of 1763 selected RGB-D images of the OCID dataset, with over 11.4k segmented object masks and more than 75k hand-annotated ",
        "translatedContent": "OCID_grasp consists of 1763 selected RGB-D images of the OCID dataset, with over 11.4k segmented object masks and more than 75k hand-annotated "
      },
      {
        "row": 7,
        "rowsha": "AtDjEF79S/csjw819FF1t1GRPg8orHiKdWGQ0NVoZgc=",
        "originContent": "grasp candidates. Additionally, each object is classified into one of 31 object classes.",
        "translatedContent": "grasp candidates. Additionally, each object is classified into one of 31 object classes."
      },
      {
        "row": 8,
        "rowsha": "gQgmB+mDPNzuAGWV+6k2andOSH0JX602DNs4sjSZtf0=",
        "originContent": "## Related Work",
        "translatedContent": "## Related Work"
      },
      {
        "row": 9,
        "rowsha": "IHIyhhl867B0xc05sUp+hppl2/MHh3NkI822d7LxUtU=",
        "originContent": "OCID_grasp is a dataset extension of the [OCID dataset](https://www.acin.tuwien.ac.at/en/vision-for-robotics/software-tools/object-clutter-indoor-dataset/).",
        "translatedContent": "OCID_grasp is a dataset extension of the [OCID dataset](https://www.acin.tuwien.ac.at/en/vision-for-robotics/software-tools/object-clutter-indoor-dataset/)."
      },
      {
        "row": 10,
        "rowsha": "m1vrFeWhPsndAQdN0iAZHyy+76xelV342JvJJFk6ti0=",
        "originContent": "If you decide to use OCID_grasp for your research, please also cite the OCID paper:",
        "translatedContent": "If you decide to use OCID_grasp for your research, please also cite the OCID paper:"
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 12,
    "Content": "```bibtex\n@inproceedings{suchi2019easylabel,\n  title={EasyLabel: a semi-automatic pixel-wise object annotation tool for creating robotic RGB-D datasets},\n  author={Suchi, Markus and Patten, Timothy and Fischinger, David and Vincze, Markus},\n  booktitle={2019 International Conference on Robotics and Automation (ICRA)},\n  pages={6678--6684},\n  year={2019},\n  organization={IEEE}\n}\n```",
    "ContentSha": "1iBZXMOeurJZBuKzq4DVpt7Ec/DDgZ5jEGeKmz+hJ/4=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bibtex\n@inproceedings{suchi2019easylabel,\n  title={EasyLabel: a semi-automatic pixel-wise object annotation tool for creating robotic RGB-D datasets},\n  author={Suchi, Markus and Patten, Timothy and Fischinger, David and Vincze, Markus},\n  booktitle={2019 International Conference on Robotics and Automation (ICRA)},\n  pages={6678--6684},\n  year={2019},\n  organization={IEEE}\n}\n```",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "o+TmyQ6wneV6/FQB6aUlRSjIGr2/YLJtnz5uxBgsScQ=",
        "originContent": "```bibtex",
        "translatedContent": "```bibtex"
      },
      {
        "row": 2,
        "rowsha": "am+7fzPMogX57+2No7Zx6g+m/KO6Kpe1VoZRwopV4Kg=",
        "originContent": "@inproceedings{suchi2019easylabel,",
        "translatedContent": "@inproceedings{suchi2019easylabel,"
      },
      {
        "row": 3,
        "rowsha": "3EiZpAxiykBZX3FWPLD330m67Bv96NRgDWCxZ4vuU/4=",
        "originContent": "  title={EasyLabel: a semi-automatic pixel-wise object annotation tool for creating robotic RGB-D datasets},",
        "translatedContent": "  title={EasyLabel: a semi-automatic pixel-wise object annotation tool for creating robotic RGB-D datasets},"
      },
      {
        "row": 4,
        "rowsha": "IxumqeikoFIe6Hndls9+IAJi13XUKKk9bmC7xaFxXm0=",
        "originContent": "  author={Suchi, Markus and Patten, Timothy and Fischinger, David and Vincze, Markus},",
        "translatedContent": "  author={Suchi, Markus and Patten, Timothy and Fischinger, David and Vincze, Markus},"
      },
      {
        "row": 5,
        "rowsha": "IInWFJKqnyVR2m4m2aHt68UI1DxIt9IREQltzcuUIpo=",
        "originContent": "  booktitle={2019 International Conference on Robotics and Automation (ICRA)},",
        "translatedContent": "  booktitle={2019 International Conference on Robotics and Automation (ICRA)},"
      },
      {
        "row": 6,
        "rowsha": "tlaHsVykO12Fo3/PGqoVi3f9pXdsUwtjsrTAFcryMU4=",
        "originContent": "  pages={6678--6684},",
        "translatedContent": "  pages={6678--6684},"
      },
      {
        "row": 7,
        "rowsha": "ocEOTULJTOsDZV6KHGnRSOuaoV0qhbBNO4DJ3ntJ94Q=",
        "originContent": "  year={2019},",
        "translatedContent": "  year={2019},"
      },
      {
        "row": 8,
        "rowsha": "9Hfv4nT468GMOcLLDRYiC872ATBuopr8BNVdeXRMKKo=",
        "originContent": "  organization={IEEE}",
        "translatedContent": "  organization={IEEE}"
      },
      {
        "row": 9,
        "rowsha": "0Qs2qnSlm89KiBhYN/ZYr682Ru/yuxbDko0OkzXpRdI=",
        "originContent": "}",
        "translatedContent": "}"
      },
      {
        "row": 10,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      }
    ],
    "IsCodeBlock": true
  },
  {
    "Id": 13,
    "Content": "Our framework is based on the architecture from [Seamless Scene Segmentation](https://github.com/mapillary/seamseg):",
    "ContentSha": "teEAAZH35j5EeglHUPss2l/VI0NSW5CguZHzPiIagvw=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "Our framework is based on the architecture from [Seamless Scene Segmentation](https://github.com/mapillary/seamseg):",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "teEAAZH35j5EeglHUPss2l/VI0NSW5CguZHzPiIagvw=",
        "originContent": "Our framework is based on the architecture from [Seamless Scene Segmentation](https://github.com/mapillary/seamseg):",
        "translatedContent": "Our framework is based on the architecture from [Seamless Scene Segmentation](https://github.com/mapillary/seamseg):"
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 14,
    "Content": "```bibtex\n@InProceedings{Porzi_2019_CVPR,\n  author = {Porzi, Lorenzo and Rota Bul\\`o, Samuel and Colovic, Aleksander and Kontschieder, Peter},\n  title = {Seamless Scene Segmentation},\n  booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},\n  month = {June},\n  year = {2019}\n}\n```",
    "ContentSha": "FK+vIm7hQ8n4L2GxlAPqIkSI6lVy6uIKui7hFqn4TDw=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bibtex\n@InProceedings{Porzi_2019_CVPR,\n  author = {Porzi, Lorenzo and Rota Bul\\`o, Samuel and Colovic, Aleksander and Kontschieder, Peter},\n  title = {Seamless Scene Segmentation},\n  booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},\n  month = {June},\n  year = {2019}\n}\n```",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "o+TmyQ6wneV6/FQB6aUlRSjIGr2/YLJtnz5uxBgsScQ=",
        "originContent": "```bibtex",
        "translatedContent": "```bibtex"
      },
      {
        "row": 2,
        "rowsha": "qXDOjNU0Ch+XRTRZ0ydjkWKK/3MJexKAClYsDFO56b0=",
        "originContent": "@InProceedings{Porzi_2019_CVPR,",
        "translatedContent": "@InProceedings{Porzi_2019_CVPR,"
      },
      {
        "row": 3,
        "rowsha": "FfFKa/UbaCH8vG4kEYTyqdUQYPgB8+MveMXV9ea9oN8=",
        "originContent": "  author = {Porzi, Lorenzo and Rota Bul\\`o, Samuel and Colovic, Aleksander and Kontschieder, Peter},",
        "translatedContent": "  author = {Porzi, Lorenzo and Rota Bul\\`o, Samuel and Colovic, Aleksander and Kontschieder, Peter},"
      },
      {
        "row": 4,
        "rowsha": "uGIEzIbt62asefZrx+otnREvHQmBHrAbyQ+caaPx6z8=",
        "originContent": "  title = {Seamless Scene Segmentation},",
        "translatedContent": "  title = {Seamless Scene Segmentation},"
      },
      {
        "row": 5,
        "rowsha": "OzLWvmPmU0HySxSvHnCvlw84cXG0JRG32Y2hANlllNc=",
        "originContent": "  booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},",
        "translatedContent": "  booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},"
      },
      {
        "row": 6,
        "rowsha": "U1Izw4geK+wX4RkAbLnK9NT0MBNGq5VLS9uL46bPZVs=",
        "originContent": "  month = {June},",
        "translatedContent": "  month = {June},"
      },
      {
        "row": 7,
        "rowsha": "NcyTFqu73UT68Hhp/KhgRz8xkWN2xeRhiy2hedxuQjc=",
        "originContent": "  year = {2019}",
        "translatedContent": "  year = {2019}"
      },
      {
        "row": 8,
        "rowsha": "0Qs2qnSlm89KiBhYN/ZYr682Ru/yuxbDko0OkzXpRdI=",
        "originContent": "}",
        "translatedContent": "}"
      },
      {
        "row": 9,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      }
    ],
    "IsCodeBlock": true
  },
  {
    "Id": 15,
    "Content": "---\n## About our latest Research\n### Our paper 'Depth-aware Object Segmentation and Grasp Detection for Robotic Picking Tasks' got accepted at BMVC21\nIn our latest work, we implemented a method for joint grasp detection and class-agnostic object instance segmentation,\nwhich was published at BMVC21. \nMore information can be found [here](https://arxiv.org/pdf/2111.11114).\n",
    "ContentSha": "YG+vtnTyYBCJ3dfscEwf9ciz2CjHp4vry9z6DASBwhU=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "---\n## About our latest Research\n### Our paper 'Depth-aware Object Segmentation and Grasp Detection for Robotic Picking Tasks' got accepted at BMVC21\nIn our latest work, we implemented a method for joint grasp detection and class-agnostic object instance segmentation,\nwhich was published at BMVC21. \nMore information can be found [here](https://arxiv.org/pdf/2111.11114).\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "yz+R1U7uMOU+NbK5mQX3Dxae1Un9eJCdPawt78ntjTs=",
        "originContent": "---",
        "translatedContent": "---"
      },
      {
        "row": 2,
        "rowsha": "kJZYblkECg2EIWGuT746GoZHpfK3HuKzWt/k5GEQrbc=",
        "originContent": "## About our latest Research",
        "translatedContent": "## About our latest Research"
      },
      {
        "row": 3,
        "rowsha": "96M3ewdojOSKPqTVkgan54N+NTpS/EW41y7Ac4TIDdY=",
        "originContent": "### Our paper 'Depth-aware Object Segmentation and Grasp Detection for Robotic Picking Tasks' got accepted at BMVC21",
        "translatedContent": "### Our paper 'Depth-aware Object Segmentation and Grasp Detection for Robotic Picking Tasks' got accepted at BMVC21"
      },
      {
        "row": 4,
        "rowsha": "p30lQqbpYb7jbznlL9TlbAztV2qbRHGsS9Teeat5SB8=",
        "originContent": "In our latest work, we implemented a method for joint grasp detection and class-agnostic object instance segmentation,",
        "translatedContent": "In our latest work, we implemented a method for joint grasp detection and class-agnostic object instance segmentation,"
      },
      {
        "row": 5,
        "rowsha": "EDlMAC1EObuIzJFQydpJqPXK/0vDMpZHE+tLrO4RXBc=",
        "originContent": "which was published at BMVC21. ",
        "translatedContent": "which was published at BMVC21. "
      },
      {
        "row": 6,
        "rowsha": "U97RtC1JlDrhwc0yd1F9F/THZbwTgS0QCDUrMANUgC4=",
        "originContent": "More information can be found [here](https://arxiv.org/pdf/2111.11114).",
        "translatedContent": "More information can be found [here](https://arxiv.org/pdf/2111.11114)."
      },
      {
        "row": 7,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  }
]