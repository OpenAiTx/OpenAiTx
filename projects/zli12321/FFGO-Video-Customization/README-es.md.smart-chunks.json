[
  {
    "Id": 1,
    "Content": "# FFGO: First Frame is the Place to Go For Video Content Custimization\n\n**Official repository for the,  \"First Frame is the Place to Go For Video Content Custimization\"**\n\n**English:**\n[[Website](http://firstframego.github.io)] | [[Paper](https://arxiv.org/abs/2511.15700)] | [[ðŸ”´ YouTube: Unofficial Community Showcase](https://www.youtube.com/watch?v=Dks3q5w7sdw)] | [[ðŸ”´ Real User Demo](https://github.com/kijai/ComfyUI-WanVideoWrapper/issues/1676)]\n\n**ä¸­æ–‡:**\n[[æ–°æ™ºå…ƒ](https://mp.weixin.qq.com/s/XQGmskJqqFdKx4vCc45tDA)] | [[bilibili](https://www.bilibili.com/video/BV1DQSzB9Eo7/)]\n\n\n![teaser.gif](https://raw.githubusercontent.com/zli12321/FFGO-Video-Customization/main/./asset/git.gif)\n\n\n\n### Coming soon\n- Adding our Official ComfyUI workflow support for using our trained LoRAs, with all parameters setup aligned with our inference code.\n- TODOs: Releasing LoRAs for smaller-size base models - Hunyuan 1.5 8B or Wan2.2 5B\n\n\n**ðŸ¤— Lora Adapters on Huggingface:**  \n- [FFGO-Lora-Adapter](https://huggingface.co/Video-Customization/FFGO-Lora-Adapter)\n\n\n#### Training Data Sample\n- **Please note that we currently provide only a subset of our 50 training videos to demonstrate the data format.**\n\n- Check the ```/Data/train/``` folder\n\n### Setup\n- Create Environment",
    "ContentSha": "qyhFHDi8AhpoDDeQT5dHjRPUpIXkolC2lRzGryzFETo=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "# FFGO: El Primer Cuadro es el Lugar para la PersonalizaciÃ³n de Contenido de Video\n\n**Repositorio oficial de, \"El Primer Cuadro es el Lugar para la PersonalizaciÃ³n de Contenido de Video\"**\n\n**InglÃ©s:**  \n[[Sitio web](http://firstframego.github.io)] | [[ArtÃ­culo](https://arxiv.org/abs/2511.15700)] | [[ðŸ”´ YouTube: ExhibiciÃ³n Comunitaria No Oficial](https://www.youtube.com/watch?v=Dks3q5w7sdw)] | [[ðŸ”´ DemostraciÃ³n de Usuario Real](https://github.com/kijai/ComfyUI-WanVideoWrapper/issues/1676)]\n\n**ä¸­æ–‡:**  \n[[æ–°æ™ºå…ƒ](https://mp.weixin.qq.com/s/XQGmskJqqFdKx4vCc45tDA)] | [[bilibili](https://www.bilibili.com/video/BV1DQSzB9Eo7/)]\n\n\n![teaser.gif](https://raw.githubusercontent.com/zli12321/FFGO-Video-Customization/main/./asset/git.gif)\n\n\n\n### PrÃ³ximamente  \n- AÃ±adiendo soporte oficial para el flujo de trabajo ComfyUI para usar nuestros LoRAs entrenados, con todos los parÃ¡metros configurados alineados con nuestro cÃ³digo de inferencia.  \n- Pendientes: Lanzamiento de LoRAs para modelos base de menor tamaÃ±o - Hunyuan 1.5 8B o Wan2.2 5B  \n\n\n**ðŸ¤— Adaptadores Lora en Huggingface:**  \n- [FFGO-Lora-Adapter](https://huggingface.co/Video-Customization/FFGO-Lora-Adapter)\n\n\n#### Muestra de Datos de Entrenamiento  \n- **Por favor, tenga en cuenta que actualmente solo proporcionamos un subconjunto de nuestros 50 videos de entrenamiento para demostrar el formato de los datos.**\n\n- Verifique la carpeta ```/Data/train/```  \n\n### ConfiguraciÃ³n  \n- Crear entorno",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "SwQTspyt216cwsEh0U6sl6Z4p8jxFf8rSNUdRVCs5pw=",
        "originContent": "# FFGO: First Frame is the Place to Go For Video Content Custimization",
        "translatedContent": "# FFGO: El Primer Cuadro es el Lugar para la PersonalizaciÃ³n de Contenido de Video"
      },
      {
        "row": 2,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 3,
        "rowsha": "dQFltMqU6zFlo71fKMMJ+wynKaLMH3qAoA0MXAZZtYs=",
        "originContent": "**Official repository for the,  \"First Frame is the Place to Go For Video Content Custimization\"**",
        "translatedContent": "**Repositorio oficial de, \"El Primer Cuadro es el Lugar para la PersonalizaciÃ³n de Contenido de Video\"**"
      },
      {
        "row": 4,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 5,
        "rowsha": "TbpuHyvWJ41MoKIXTV5X0XTqW7g7wfNsH8jxaFW+8fc=",
        "originContent": "**English:**",
        "translatedContent": "**InglÃ©s:**  "
      },
      {
        "row": 6,
        "rowsha": "glOBnc8gl5onRpqUmbNed3ITKHk4XP6iEJj/wAlx4G4=",
        "originContent": "[[Website](http://firstframego.github.io)] | [[Paper](https://arxiv.org/abs/2511.15700)] | [[ðŸ”´ YouTube: Unofficial Community Showcase](https://www.youtube.com/watch?v=Dks3q5w7sdw)] | [[ðŸ”´ Real User Demo](https://github.com/kijai/ComfyUI-WanVideoWrapper/issues/1676)]",
        "translatedContent": "[[Sitio web](http://firstframego.github.io)] | [[ArtÃ­culo](https://arxiv.org/abs/2511.15700)] | [[ðŸ”´ YouTube: ExhibiciÃ³n Comunitaria No Oficial](https://www.youtube.com/watch?v=Dks3q5w7sdw)] | [[ðŸ”´ DemostraciÃ³n de Usuario Real](https://github.com/kijai/ComfyUI-WanVideoWrapper/issues/1676)]"
      },
      {
        "row": 7,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 8,
        "rowsha": "cdjcLJpgeFDb/kyrTCXXVu7RkIPjzc42CXj1yhZXnp4=",
        "originContent": "**ä¸­æ–‡:**",
        "translatedContent": "**ä¸­æ–‡:**  "
      },
      {
        "row": 9,
        "rowsha": "bOHMoPNwwLcWWa1s/KRPDEHOoqNcA6S19kvPeAe1d9k=",
        "originContent": "[[æ–°æ™ºå…ƒ](https://mp.weixin.qq.com/s/XQGmskJqqFdKx4vCc45tDA)] | [[bilibili](https://www.bilibili.com/video/BV1DQSzB9Eo7/)]",
        "translatedContent": "[[æ–°æ™ºå…ƒ](https://mp.weixin.qq.com/s/XQGmskJqqFdKx4vCc45tDA)] | [[bilibili](https://www.bilibili.com/video/BV1DQSzB9Eo7/)]"
      },
      {
        "row": 10,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 11,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 12,
        "rowsha": "88GZRSEittFpQDJPd0+VTq4JNJeNxx1K1ouynWyUYOM=",
        "originContent": "![teaser.gif](https://raw.githubusercontent.com/zli12321/FFGO-Video-Customization/main/./asset/git.gif)",
        "translatedContent": "![teaser.gif](https://raw.githubusercontent.com/zli12321/FFGO-Video-Customization/main/./asset/git.gif)"
      },
      {
        "row": 13,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 14,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 15,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 16,
        "rowsha": "6KErDh3z4s2y4QVIJFFZQ7asdVbncqC2LxIplI/1qCM=",
        "originContent": "### Coming soon",
        "translatedContent": "### PrÃ³ximamente  "
      },
      {
        "row": 17,
        "rowsha": "biatG2duCcb78TAkw1oFgTQjZPZ0a5/vpPdE/mqJfCw=",
        "originContent": "- Adding our Official ComfyUI workflow support for using our trained LoRAs, with all parameters setup aligned with our inference code.",
        "translatedContent": "- AÃ±adiendo soporte oficial para el flujo de trabajo ComfyUI para usar nuestros LoRAs entrenados, con todos los parÃ¡metros configurados alineados con nuestro cÃ³digo de inferencia.  "
      },
      {
        "row": 18,
        "rowsha": "YeUTdoMSEA8iU+r8rTD2owlkAVexxv75lxCrb//JKPs=",
        "originContent": "- TODOs: Releasing LoRAs for smaller-size base models - Hunyuan 1.5 8B or Wan2.2 5B",
        "translatedContent": "- Pendientes: Lanzamiento de LoRAs para modelos base de menor tamaÃ±o - Hunyuan 1.5 8B o Wan2.2 5B  "
      },
      {
        "row": 19,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 20,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 21,
        "rowsha": "rrkT+6GW2mvdH3MB+uMvQ1DRGz+1wdT+NxjxgA8Fd9M=",
        "originContent": "**ðŸ¤— Lora Adapters on Huggingface:**  ",
        "translatedContent": "**ðŸ¤— Adaptadores Lora en Huggingface:**  "
      },
      {
        "row": 22,
        "rowsha": "bIuY6zIKIrlYHk8BDPWCAlmL2a8UJaDom1hn6YuXVCs=",
        "originContent": "- [FFGO-Lora-Adapter](https://huggingface.co/Video-Customization/FFGO-Lora-Adapter)",
        "translatedContent": "- [FFGO-Lora-Adapter](https://huggingface.co/Video-Customization/FFGO-Lora-Adapter)"
      },
      {
        "row": 23,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 24,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 25,
        "rowsha": "gDEjTva/4NgYsCxavyUBZEtH8HX3+Yda2Wg5UyY/lF0=",
        "originContent": "#### Training Data Sample",
        "translatedContent": "#### Muestra de Datos de Entrenamiento  "
      },
      {
        "row": 26,
        "rowsha": "4SG1V9u9jmz6EQS+w+JPwFT7hByEfyLk9L5RwR8nhZ8=",
        "originContent": "- **Please note that we currently provide only a subset of our 50 training videos to demonstrate the data format.**",
        "translatedContent": "- **Por favor, tenga en cuenta que actualmente solo proporcionamos un subconjunto de nuestros 50 videos de entrenamiento para demostrar el formato de los datos.**"
      },
      {
        "row": 27,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 28,
        "rowsha": "zuGLHimilCgVBauTRnIAM5fUpQ8LwPLPWxb3iJvLni4=",
        "originContent": "- Check the ```/Data/train/``` folder",
        "translatedContent": "- Verifique la carpeta ```/Data/train/```  "
      },
      {
        "row": 29,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 30,
        "rowsha": "iJa409tTUC9P1gTULbIw6Kod+KAUdLl5kgZl7whoChE=",
        "originContent": "### Setup",
        "translatedContent": "### ConfiguraciÃ³n  "
      },
      {
        "row": 31,
        "rowsha": "K42aDOFx5aHGU0brOtIMB9/V0fO9xRnrIF+BVRRTtpo=",
        "originContent": "- Create Environment",
        "translatedContent": "- Crear entorno"
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 2,
    "Content": "```\nconda create -n ffgo python=3.11\nconda activate ffgo\n```",
    "ContentSha": "qv7DyfX1v2piXL34LsaEyCyNFlx4BKm7aDQ6pkG9d7o=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```\nconda create -n ffgo python=3.11\nconda activate ffgo\n```",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      },
      {
        "row": 2,
        "rowsha": "y7EMkp5cQ45IbemY6FgvS78lzONCh1rCyOgV/doy5F8=",
        "originContent": "conda create -n ffgo python=3.11",
        "translatedContent": "conda create -n ffgo python=3.11"
      },
      {
        "row": 3,
        "rowsha": "2hHOiCjwPKSvyp3l36WLyq8k69KTbwbNdrUbmzhvvR8=",
        "originContent": "conda activate ffgo",
        "translatedContent": "conda activate ffgo"
      },
      {
        "row": 4,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      }
    ],
    "IsCodeBlock": true
  },
  {
    "Id": 3,
    "Content": "\n- Clone Repository and Setup",
    "ContentSha": "Aun5SvF3qPb0L3exWTe/h0yjAO7GvxyeM9vqGcNaJxs=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "- Clonar repositorio y configuraciÃ³n\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "- Clonar repositorio y configuraciÃ³n"
      },
      {
        "row": 2,
        "rowsha": "Z9yENE4INxdlrp/597py1kMx0bQ+JOAkUbPcsyDiJnQ=",
        "originContent": "- Clone Repository and Setup",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 4,
    "Content": "```\ngit clone https://github.com/zli12321/FFGO-Video-Customization.git\ncd FFGO-Video-Customization\nbash setup.sh\n```",
    "ContentSha": "MVms6rbeoDvo26EbMa5I5f5lkSpuEGL2NCJKh7A9tGc=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```\ngit clone https://github.com/zli12321/FFGO-Video-Customization.git\ncd FFGO-Video-Customization\nbash setup.sh\n```",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      },
      {
        "row": 2,
        "rowsha": "ADggVgFstIEsxR255DOUxLpX7m4viW4TPXQ2NnzRpKk=",
        "originContent": "git clone https://github.com/zli12321/FFGO-Video-Customization.git",
        "translatedContent": "git clone https://github.com/zli12321/FFGO-Video-Customization.git"
      },
      {
        "row": 3,
        "rowsha": "7BLToQXoDjbrCpw6sO0yQYnLntnIKMYDqmj0R8OZ5Tc=",
        "originContent": "cd FFGO-Video-Customization",
        "translatedContent": "cd FFGO-Video-Customization"
      },
      {
        "row": 4,
        "rowsha": "s8JIgfNQIrvDiZYy0YVZcBaC+qWOoDrzGNllIzwMt7Y=",
        "originContent": "bash setup.sh",
        "translatedContent": "bash setup.sh"
      },
      {
        "row": 5,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      }
    ],
    "IsCodeBlock": true
  },
  {
    "Id": 5,
    "Content": "\n\n### Test data\n- Test data is available in [Data](https://github.com/zli12321/FFGO-Video-Customization/tree/main/Data/combined_first_frames) folder. All test data involving personal portrait rights has been removed. [0-data.csv](https://github.com/zli12321/FFGO-Video-Customization/blob/main/Data/combined_first_frames/0-data.csv) has the input image path and the caption to generate the video.\n- Test data materials are available in [data_materials](https://github.com/zli12321/FFGO-Video-Customization/tree/main/Data/data_materials) folder. These are materials that can form the final input image for video generations.\n- Get your own test data: find any images online and segment out the elements as RGBA layer, then combine it with a background using our [combine script]().\n\n\n### Running Inference\n\n- **When running on your own data, make sure to append our learned transition phrase, \"ad23r2 the camera view suddenly changes. \", to your text prompt to ensure the model behaves correctly.**\n\n- **All video results in the paper are generated at 1280â€¯Ã—â€¯720 resolution with 81 frames, which requires an H200 GPU for inference unless memory-saving techniques are applied. For lower resource usage, 640â€¯Ã—â€¯480 resolution videos can be generated without H200. However outputs at this lower resolution can differ significantly in content from the 1280â€¯Ã—â€¯720 results as we shown in the paper.**\n\n- **We are using H200 (141GB RAM) to run inference. If you are using A100 or H100, the memory saving such as cpu offload features need to be turned on.**\n\n1. Download [Wan2.2-I2V-14B](https://huggingface.co/Wan-AI/Wan2.2-I2V-A14B) from huggingface or modelscope and download our Lora adapters. \n",
    "ContentSha": "Ve6Q71BUucLqUDWnsAp2oXqB13HAbznn0RQnU331xlw=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "\n\n### Test data\n- Test data is available in [Data](https://github.com/zli12321/FFGO-Video-Customization/tree/main/Data/combined_first_frames) folder. All test data involving personal portrait rights has been removed. [0-data.csv](https://github.com/zli12321/FFGO-Video-Customization/blob/main/Data/combined_first_frames/0-data.csv) has the input image path and the caption to generate the video.\n- Test data materials are available in [data_materials](https://github.com/zli12321/FFGO-Video-Customization/tree/main/Data/data_materials) folder. These are materials that can form the final input image for video generations.\n- Get your own test data: find any images online and segment out the elements as RGBA layer, then combine it with a background using our [combine script]().\n\n\n### Running Inference\n\n- **When running on your own data, make sure to append our learned transition phrase, \"ad23r2 the camera view suddenly changes. \", to your text prompt to ensure the model behaves correctly.**\n\n- **All video results in the paper are generated at 1280â€¯Ã—â€¯720 resolution with 81 frames, which requires an H200 GPU for inference unless memory-saving techniques are applied. For lower resource usage, 640â€¯Ã—â€¯480 resolution videos can be generated without H200. However outputs at this lower resolution can differ significantly in content from the 1280â€¯Ã—â€¯720 results as we shown in the paper.**\n\n- **We are using H200 (141GB RAM) to run inference. If you are using A100 or H100, the memory saving such as cpu offload features need to be turned on.**\n\n1. Download [Wan2.2-I2V-14B](https://huggingface.co/Wan-AI/Wan2.2-I2V-A14B) from huggingface or modelscope and download our Lora adapters. \n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 2,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 3,
        "rowsha": "GctLXqU+Z1V8/2mVlKX3ktRVDnhi9VjJz0jMNMa4G9Q=",
        "originContent": "### Test data",
        "translatedContent": "### Test data"
      },
      {
        "row": 4,
        "rowsha": "PvKertP0jgCQnGlXJ/REc0TIuJ06FisYelpL6118d6c=",
        "originContent": "- Test data is available in [Data](https://github.com/zli12321/FFGO-Video-Customization/tree/main/Data/combined_first_frames) folder. All test data involving personal portrait rights has been removed. [0-data.csv](https://github.com/zli12321/FFGO-Video-Customization/blob/main/Data/combined_first_frames/0-data.csv) has the input image path and the caption to generate the video.",
        "translatedContent": "- Test data is available in [Data](https://github.com/zli12321/FFGO-Video-Customization/tree/main/Data/combined_first_frames) folder. All test data involving personal portrait rights has been removed. [0-data.csv](https://github.com/zli12321/FFGO-Video-Customization/blob/main/Data/combined_first_frames/0-data.csv) has the input image path and the caption to generate the video."
      },
      {
        "row": 5,
        "rowsha": "Xg4RTjZ5vjTIyCmGvrOtPZ6rcXF8yje751pHbiRpGzg=",
        "originContent": "- Test data materials are available in [data_materials](https://github.com/zli12321/FFGO-Video-Customization/tree/main/Data/data_materials) folder. These are materials that can form the final input image for video generations.",
        "translatedContent": "- Test data materials are available in [data_materials](https://github.com/zli12321/FFGO-Video-Customization/tree/main/Data/data_materials) folder. These are materials that can form the final input image for video generations."
      },
      {
        "row": 6,
        "rowsha": "B3qp0cRceGkKkVuIn68za+mqQ2+zDvWQiMHhqULn9XA=",
        "originContent": "- Get your own test data: find any images online and segment out the elements as RGBA layer, then combine it with a background using our [combine script]().",
        "translatedContent": "- Get your own test data: find any images online and segment out the elements as RGBA layer, then combine it with a background using our [combine script]()."
      },
      {
        "row": 7,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 8,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 9,
        "rowsha": "UTF+/8nh5U7VL9FYw/joz3sBObQhO1EEJyO4S1xOH9M=",
        "originContent": "### Running Inference",
        "translatedContent": "### Running Inference"
      },
      {
        "row": 10,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 11,
        "rowsha": "sH50QPFp4F08KPEb3S3ISsNm1cM3agNivtTa/b1fgtU=",
        "originContent": "- **When running on your own data, make sure to append our learned transition phrase, \"ad23r2 the camera view suddenly changes. \", to your text prompt to ensure the model behaves correctly.**",
        "translatedContent": "- **When running on your own data, make sure to append our learned transition phrase, \"ad23r2 the camera view suddenly changes. \", to your text prompt to ensure the model behaves correctly.**"
      },
      {
        "row": 12,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 13,
        "rowsha": "k1/bRJg+JkfvCEhh47GZpBqggij96D2bqyoCn5n42Vo=",
        "originContent": "- **All video results in the paper are generated at 1280â€¯Ã—â€¯720 resolution with 81 frames, which requires an H200 GPU for inference unless memory-saving techniques are applied. For lower resource usage, 640â€¯Ã—â€¯480 resolution videos can be generated without H200. However outputs at this lower resolution can differ significantly in content from the 1280â€¯Ã—â€¯720 results as we shown in the paper.**",
        "translatedContent": "- **All video results in the paper are generated at 1280â€¯Ã—â€¯720 resolution with 81 frames, which requires an H200 GPU for inference unless memory-saving techniques are applied. For lower resource usage, 640â€¯Ã—â€¯480 resolution videos can be generated without H200. However outputs at this lower resolution can differ significantly in content from the 1280â€¯Ã—â€¯720 results as we shown in the paper.**"
      },
      {
        "row": 14,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 15,
        "rowsha": "9AImjqvxTpV87oX6tMJpAOb4KCaRVlvAd1nka0u0GRI=",
        "originContent": "- **We are using H200 (141GB RAM) to run inference. If you are using A100 or H100, the memory saving such as cpu offload features need to be turned on.**",
        "translatedContent": "- **We are using H200 (141GB RAM) to run inference. If you are using A100 or H100, the memory saving such as cpu offload features need to be turned on.**"
      },
      {
        "row": 16,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 17,
        "rowsha": "t10dv1jhCRJqjAQuKpinEnmPaobNHVn1fdIMIWYuq5I=",
        "originContent": "1. Download [Wan2.2-I2V-14B](https://huggingface.co/Wan-AI/Wan2.2-I2V-A14B) from huggingface or modelscope and download our Lora adapters. ",
        "translatedContent": "1. Download [Wan2.2-I2V-14B](https://huggingface.co/Wan-AI/Wan2.2-I2V-A14B) from huggingface or modelscope and download our Lora adapters. "
      },
      {
        "row": 18,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 6,
    "Content": "```bash\nbash download.sh\n```",
    "ContentSha": "uvlSK0z0EzRpbpgJSPP/W3GZOFWaNf75wbm995MePNQ=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\nbash download.sh\n```",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "rTMjNc+qNIxb1xXDR5hEYiJw1fc4muBwuBsTXVIaIho=",
        "originContent": "```bash",
        "translatedContent": "```bash"
      },
      {
        "row": 2,
        "rowsha": "B5iS8tt2B/R7HCMJBnJIog2Ml6KQ8v45WvgcNIR+/90=",
        "originContent": "bash download.sh",
        "translatedContent": "bash download.sh"
      },
      {
        "row": 3,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      }
    ],
    "IsCodeBlock": true
  },
  {
    "Id": 7,
    "Content": "\n\n2. Run fun demo video inference\n",
    "ContentSha": "P8c3fMK6YoPHRiMkocX1Cc1BgrgVkzX6pHLe5yFi/Ig=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "\n\n2. Run fun demo video inference\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 2,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 3,
        "rowsha": "2zvBEg17zdr+TwHRq/K59EpLySlo8oXOADm/TvP+l0I=",
        "originContent": "2. Run fun demo video inference",
        "translatedContent": "2. Run fun demo video inference"
      },
      {
        "row": 4,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 8,
    "Content": "```\nbash ./example_single_inference.sh\n```",
    "ContentSha": "KZPdjyZayvlC4VxZ1VAZlCxGzSKncJfVINCxbsyGqGs=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```\nbash ./example_single_inference.sh\n```",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      },
      {
        "row": 2,
        "rowsha": "xkFY9Qdr8kp9ttOLoofjAa8rQZnYrPgBs7kL0w5eGOQ=",
        "originContent": "bash ./example_single_inference.sh",
        "translatedContent": "bash ./example_single_inference.sh"
      },
      {
        "row": 3,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      }
    ],
    "IsCodeBlock": true
  },
  {
    "Id": 9,
    "Content": "\n3. Run continuous inference on our example test dataset",
    "ContentSha": "JL/De+i2L2eCIbwsezlcbNiCQvu/TFRBCzyjyhp3aHY=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "\n3. Ejecutar inferencia continua en nuestro conjunto de datos de prueba de ejemplo",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 2,
        "rowsha": "PH41fvjqn1wzbKWtKAkKHVJ/8/zsrVvf2avKrh7ZFDE=",
        "originContent": "3. Run continuous inference on our example test dataset",
        "translatedContent": "3. Ejecutar inferencia continua en nuestro conjunto de datos de prueba de ejemplo"
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 10,
    "Content": "```\nbash example_inference.sh\n```",
    "ContentSha": "eAcvG1sABSwPF/UHfycA/QmVvKovopIdfyw+oENphwk=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```\nbash example_inference.sh\n```",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      },
      {
        "row": 2,
        "rowsha": "zMEbGWpGG4eMWwFn8uMPzNB+/qbjKFIglA7/FrjpTRo=",
        "originContent": "bash example_inference.sh",
        "translatedContent": "bash example_inference.sh"
      },
      {
        "row": 3,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      }
    ],
    "IsCodeBlock": true
  },
  {
    "Id": 11,
    "Content": "\n<!-- \n4. Run 4 Step Lora speedup (Will cause quality degrade and inconsistency.)\n",
    "ContentSha": "WQIxw1flPT+4yNHIyZ3QUUTKjl86yI9hPspsVgPCou4=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "\n<!-- \n4. Run 4 Step Lora speedup (Will cause quality degrade and inconsistency.)\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 2,
        "rowsha": "RU0q/UtVDC+mNFGNMDxHOlylYF/5rsBe7vM7iP1MvNk=",
        "originContent": "<!-- ",
        "translatedContent": "<!-- "
      },
      {
        "row": 3,
        "rowsha": "lKP8FDnnxDD4W/qUwVKOJO6Kb8dEuVVGhQwIeeskMuY=",
        "originContent": "4. Run 4 Step Lora speedup (Will cause quality degrade and inconsistency.)",
        "translatedContent": "4. Run 4 Step Lora speedup (Will cause quality degrade and inconsistency.)"
      },
      {
        "row": 4,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 12,
    "Content": "```\nbash ./example_4_step_lora_inference.sh\n``` -->",
    "ContentSha": "IuxkB8fPoaClQSM343Fz6TVyHl1f/cg9L3lMGWm9sQ8=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```\nbash ./example_4_step_lora_inference.sh\n``` -->",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      },
      {
        "row": 2,
        "rowsha": "WQi0MVhOlfcnUPxOfAw9lIYY0aUcKG9f2YNeLHRXv3g=",
        "originContent": "bash ./example_4_step_lora_inference.sh",
        "translatedContent": "bash ./example_4_step_lora_inference.sh"
      },
      {
        "row": 3,
        "rowsha": "PtnQzsLc2URY6kfqmknZe9+0cSmzhAMT9pxhkNeeVQc=",
        "originContent": "``` -->",
        "translatedContent": "``` -->"
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 13,
    "Content": "\n\n### Citation",
    "ContentSha": "cvtMFjJVtioXrJj/5P/UXw3feaNT27oAqBtsqRImo6A=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "\n\n### CitaciÃ³n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 2,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 3,
        "rowsha": "3TJ4J3Mtr7864eEakXgFTcOl07FEMoJn02zh7whWa54=",
        "originContent": "### Citation",
        "translatedContent": "### CitaciÃ³n"
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 14,
    "Content": "```\n@article{chen2025first,\n  title={First Frame Is the Place to Go for Video Content Customization},\n  author={Chen, Jingxi and Li, Zongxia and Liu, Zhichao and Shi, Guangyao and Wu, Xiyang and Liu, Fuxiao and Fermuller, Cornelia and Feng, Brandon Y and Aloimonos, Yiannis},\n  journal={arXiv preprint arXiv:2511.15700},\n  year={2025}\n}\n```",
    "ContentSha": "7ZEyhdiDUJS8aYbFg3DTFVXT/oSps1wKCxJ7+TpW0OQ=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```\n@article{chen2025first,\n  title={First Frame Is the Place to Go for Video Content Customization},\n  author={Chen, Jingxi and Li, Zongxia and Liu, Zhichao and Shi, Guangyao and Wu, Xiyang and Liu, Fuxiao and Fermuller, Cornelia and Feng, Brandon Y and Aloimonos, Yiannis},\n  journal={arXiv preprint arXiv:2511.15700},\n  year={2025}\n}\n```",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      },
      {
        "row": 2,
        "rowsha": "MhpCWO0jcqcp5uj8G+nV6ubjwuVW9hk7Clb8dPWXK+U=",
        "originContent": "@article{chen2025first,",
        "translatedContent": "@article{chen2025first,"
      },
      {
        "row": 3,
        "rowsha": "9jGxf1Wl0epYoV3NiiIJf6RwRRpMHZpdzJ5WFpwao4Q=",
        "originContent": "  title={First Frame Is the Place to Go for Video Content Customization},",
        "translatedContent": "  title={First Frame Is the Place to Go for Video Content Customization},"
      },
      {
        "row": 4,
        "rowsha": "RsEmEoUCkaP0IFRmgrYUMlOjk2yENnVssEAKBupfc24=",
        "originContent": "  author={Chen, Jingxi and Li, Zongxia and Liu, Zhichao and Shi, Guangyao and Wu, Xiyang and Liu, Fuxiao and Fermuller, Cornelia and Feng, Brandon Y and Aloimonos, Yiannis},",
        "translatedContent": "  author={Chen, Jingxi and Li, Zongxia and Liu, Zhichao and Shi, Guangyao and Wu, Xiyang and Liu, Fuxiao and Fermuller, Cornelia and Feng, Brandon Y and Aloimonos, Yiannis},"
      },
      {
        "row": 5,
        "rowsha": "olUu2ppw23KxwLaBraRiWZuYATcPbUFomd9y1DMxymo=",
        "originContent": "  journal={arXiv preprint arXiv:2511.15700},",
        "translatedContent": "  journal={arXiv preprint arXiv:2511.15700},"
      },
      {
        "row": 6,
        "rowsha": "6oyqJVJ20XoZhlyGjaewQyTQsSBBtVAYmqUtTwjLbAg=",
        "originContent": "  year={2025}",
        "translatedContent": "  year={2025}"
      },
      {
        "row": 7,
        "rowsha": "0Qs2qnSlm89KiBhYN/ZYr682Ru/yuxbDko0OkzXpRdI=",
        "originContent": "}",
        "translatedContent": "}"
      },
      {
        "row": 8,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      }
    ],
    "IsCodeBlock": true
  }
]