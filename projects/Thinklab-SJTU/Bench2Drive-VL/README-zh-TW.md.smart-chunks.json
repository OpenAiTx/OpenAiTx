[
  {
    "Id": 1,
    "Content": "![B2DVL Header](https://raw.githubusercontent.com/Thinklab-SJTU/Bench2Drive-VL/main/./assets/Bench2Drive-VL.png)\n\n🚗 **Bench2Drive-VL** is a closed-loop full-stack benchmark for vision-language models (VLMs) in autonomous driving. In VQA part, our rule-based expert model DriveCommenter is used for generating VQAs' ground truth in CARLA simulator (or from static datasets like Bench2Drive). Original Bench2Drive metrics are used for planning benchmarking.\n\n<h2 align=\"center\">\n  <a href=\"https://thinklab-sjtu.github.io/Bench2Drive-VL/\"> Document</a> |\n  <a href=\"https://huggingface.co/datasets/Telkwevr/Bench2Drive-VL-base\"> Dataset</a>\n</h2>\n\n![B2DVL Structure](https://raw.githubusercontent.com/Thinklab-SJTU/Bench2Drive-VL/main/./assets/struct_new.png)\n\n📚 Docker support is on the way...\n\n![B2DVL Modules](https://raw.githubusercontent.com/Thinklab-SJTU/Bench2Drive-VL/main/./assets/modules_new.png)\n\n## How to use\n\n### Set up the environment\n\n1. Install CARLA:\n",
    "ContentSha": "sZWWXc32wRo7ygHm9pOPafxmpno7MxAuX9pb/gaz/XQ=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "![B2DVL Header](https://raw.githubusercontent.com/Thinklab-SJTU/Bench2Drive-VL/main/./assets/Bench2Drive-VL.png)\n\n🚗 **Bench2Drive-VL** 是一個針對自主駕駛中視覺語言模型（VLMs）的閉環全棧基準測試。在 VQA 部分，我們使用基於規則的專家模型 DriveCommenter 來生成 CARLA 模擬器中 VQA 的真實標籤（或來自像 Bench2Drive 這樣的靜態數據集）。規劃基準測試則使用原始 Bench2Drive 指標。\n\n<h2 align=\"center\">\n  <a href=\"https://thinklab-sjtu.github.io/Bench2Drive-VL/\"> 文件</a> |\n  <a href=\"https://huggingface.co/datasets/Telkwevr/Bench2Drive-VL-base\"> 數據集</a>\n</h2>\n\n![B2DVL Structure](https://raw.githubusercontent.com/Thinklab-SJTU/Bench2Drive-VL/main/./assets/struct_new.png)\n\n📚 Docker 支援即將推出...\n\n![B2DVL Modules](https://raw.githubusercontent.com/Thinklab-SJTU/Bench2Drive-VL/main/./assets/modules_new.png)\n\n## 使用方法\n\n### 環境設置\n\n1. 安裝 CARLA:\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 2,
    "Content": "    ```bash\n    mkdir carla\n    cd carla\n    wget https://carla-releases.s3.us-east-005.backblazeb2.com/Linux/CARLA_0.9.15.tar.gz\n    tar -xvf CARLA_0.9.15.tar.gz\n    cd Import && wget https://carla-releases.s3.us-east-005.backblazeb2.com/Linux/AdditionalMaps_0.9.15.tar.gz\n    cd .. && bash ImportAssets.sh\n    export CARLA_ROOT=YOUR_CARLA_PATH\n    echo \"$CARLA_ROOT/PythonAPI/carla/dist/carla-0.9.15-py3.7-linux-x86_64.egg\" >> YOUR_CONDA_PATH/envs/YOUR_CONDA_ENV_NAME/lib/python3.7/site-packages/carla.pth # python 3.8 also works well, please set YOUR_CONDA_PATH and YOUR_CONDA_ENV_NAME\n    ```",
    "ContentSha": "lntswi7b4GrUORtb/f9AbL1laKSO26+WHCYkOOjD9+4=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "    ```bash\n    mkdir carla\n    cd carla\n    wget https://carla-releases.s3.us-east-005.backblazeb2.com/Linux/CARLA_0.9.15.tar.gz\n    tar -xvf CARLA_0.9.15.tar.gz\n    cd Import && wget https://carla-releases.s3.us-east-005.backblazeb2.com/Linux/AdditionalMaps_0.9.15.tar.gz\n    cd .. && bash ImportAssets.sh\n    export CARLA_ROOT=YOUR_CARLA_PATH\n    echo \"$CARLA_ROOT/PythonAPI/carla/dist/carla-0.9.15-py3.7-linux-x86_64.egg\" >> YOUR_CONDA_PATH/envs/YOUR_CONDA_ENV_NAME/lib/python3.7/site-packages/carla.pth # python 3.8 also works well, please set YOUR_CONDA_PATH and YOUR_CONDA_ENV_NAME\n    ```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 3,
    "Content": "\n2. After installing CARLA, write an `env.sh`:\n",
    "ContentSha": "preY1tEmzN7BYUksbWjxzwRCrUFJJ08a2Kj7gJXfEag=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "2. 安裝 CARLA 後，撰寫一個 `env.sh`：\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 4,
    "Content": "   ```bash\n   export CARLA_ROOT=/path/to/your/carla\n\n   export CARLA_SERVER=${CARLA_ROOT}/CarlaUE4.sh\n   export PYTHONPATH=${CARLA_ROOT}/PythonAPI\n   export PYTHONPATH=$PYTHONPATH:${CARLA_ROOT}/PythonAPI/carla\n   export PYTHONPATH=$PYTHONPATH:$CARLA_ROOT/PythonAPI/carla/dist/carla-0.9.15-py3.7-linux-x86_64.egg\n\n   export WORK_DIR=/path/to/this/repo\n   export PYTHONPATH=$PYTHONPATH:${WORK_DIR}/scenario_runner\n   export PYTHONPATH=$PYTHONPATH:${WORK_DIR}/leaderboard\n   export PYTHONPATH=$PYTHONPATH:${WORK_DIR}/B2DVL_Adapter\n   export SCENARIO_RUNNER_ROOT=${WORK_DIR}/scenario_runner\n   export LEADERBOARD_ROOT=${WORK_DIR}/leaderboard\n\n   export VQA_GEN=1\n   export STRICT_MODE=1\n   # DriveCommenter drives back the ego vehicle after circumventing obstacles if STRICT_MODE > 0,\n   # must set to true if doing closed-loop eval.\n   ```",
    "ContentSha": "otYlO/ApR6znthPVFmDJ02+C4RQuBVNu9mS139Zt9po=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "   ```bash\n   export CARLA_ROOT=/path/to/your/carla\n\n   export CARLA_SERVER=${CARLA_ROOT}/CarlaUE4.sh\n   export PYTHONPATH=${CARLA_ROOT}/PythonAPI\n   export PYTHONPATH=$PYTHONPATH:${CARLA_ROOT}/PythonAPI/carla\n   export PYTHONPATH=$PYTHONPATH:$CARLA_ROOT/PythonAPI/carla/dist/carla-0.9.15-py3.7-linux-x86_64.egg\n\n   export WORK_DIR=/path/to/this/repo\n   export PYTHONPATH=$PYTHONPATH:${WORK_DIR}/scenario_runner\n   export PYTHONPATH=$PYTHONPATH:${WORK_DIR}/leaderboard\n   export PYTHONPATH=$PYTHONPATH:${WORK_DIR}/B2DVL_Adapter\n   export SCENARIO_RUNNER_ROOT=${WORK_DIR}/scenario_runner\n   export LEADERBOARD_ROOT=${WORK_DIR}/leaderboard\n\n   export VQA_GEN=1\n   export STRICT_MODE=1\n   # DriveCommenter drives back the ego vehicle after circumventing obstacles if STRICT_MODE > 0,\n   # must set to true if doing closed-loop eval.\n   ```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 5,
    "Content": "\n3. Make sure you have the correct environment variables:\n",
    "ContentSha": "fh8Ht87tDF6pBnSv+fEaSH7eEAoMWdR0Xrh0FCxWvzo=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "3. 確保您擁有正確的環境變數：\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 6,
    "Content": "   ```shell\n   source ./env.sh\n   ```",
    "ContentSha": "SU+Xw54HULVLps6Zggj79dmE6P9PjTJ0KpdtcmtTFM4=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "   ```shell\n   source ./env.sh\n   ```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 7,
    "Content": "\n### Closed-Loop Inference\n\n1. Write a vlm config file (examples can be found under `./vlm_config`):\n   \n   *This is a JSON file, so don't forget to delete all comments!*\n   \n   *Question id please refer to [document](https://raw.githubusercontent.com/Thinklab-SJTU/Bench2Drive-VL/main/./docs/qids.md).*\n\n   *Make sure you include question 50 because action module requires its answer.*\n",
    "ContentSha": "HRDNEYdq9IMnV3uuDpNbytTNCiumAM2xIhdBg+YOe6g=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "### 閉環推理\n\n1. 編寫 vlm 配置文件（範例可在 `./vlm_config` 中找到）：\n   \n   *這是一個 JSON 文件，請務必刪除所有註解！*\n   \n   *問題 ID 請參考 [文件](https://raw.githubusercontent.com/Thinklab-SJTU/Bench2Drive-VL/main/./docs/qids.md)。*\n\n   *請確保包含問題 50，因為動作模組需要其答案。*\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 8,
    "Content": "    ```java\n    {\n        \"TASK_CONFIGS\": {\n            \"FRAME_PER_SEC\": 10 // sensor saving frequency\n        },\n        \"INFERENCE_BASICS\": {\n            \"INPUT_WINDOW\": 1, // frame count of given image input\n            \"CONVERSATION_WINDOW\": 1, // not used anymore, to be removed\n            \"USE_ALL_CAMERAS\": false, // true if use all cameras as input\n            \"USE_BEV\": false, // true if use bev as input\n            \"NO_HISTORY_MODE\": false // do not inherit context of previous VQAs\n        },\n        \"CHAIN\": { // for inference\n            \"NODE\": [19, 15, 7, 24, 13, 47, 8, 43, 50],\n            \"EDGE\": { // \"pred\": succ\n                \"19\": [24, 13, 8],\n                \"15\": [7, 8],\n                \"7\": [8],\n                \"24\": [13, 47],\n                \"13\": [47, 8, 43],\n                \"47\": [8],\n                \"8\": [43],\n                \"43\": [50],\n                \"50\": []\n            },\n            \"INHERIT\": { // inherit context from last frame\n                \"19\": [43, 7],\n                \"15\": [7]\n            },\n            \"USE_GT\": [24] // questions which use ground truth as answer\n        },\n        \"CONTROL_RATE\": 2.0, // intervene freq of vlm\n        \"MODEL_NAME\": \"api\", // model name\n        \"MODEL_PATH\": \"../model_zoo/your_model\", // model path\n        \"GPU_ID\": 0, // the gpu model runs on\n        \"PORT\": 7023, // web port\n        \"IN_CARLA\": true,\n        \"USE_BASE64\": true, // if false, local path is used for transmitting images\n        \"NO_PERC_INFO\": false // do not pass extra perception info to vlm via prompt\n    }\n    ```",
    "ContentSha": "+7/+jzWgutLUPHwNsJFluDKDC8gLzDlBHgN0nwn9xTs=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "    ```java\n    {\n        \"TASK_CONFIGS\": {\n            \"FRAME_PER_SEC\": 10 // sensor saving frequency\n        },\n        \"INFERENCE_BASICS\": {\n            \"INPUT_WINDOW\": 1, // frame count of given image input\n            \"CONVERSATION_WINDOW\": 1, // not used anymore, to be removed\n            \"USE_ALL_CAMERAS\": false, // true if use all cameras as input\n            \"USE_BEV\": false, // true if use bev as input\n            \"NO_HISTORY_MODE\": false // do not inherit context of previous VQAs\n        },\n        \"CHAIN\": { // for inference\n            \"NODE\": [19, 15, 7, 24, 13, 47, 8, 43, 50],\n            \"EDGE\": { // \"pred\": succ\n                \"19\": [24, 13, 8],\n                \"15\": [7, 8],\n                \"7\": [8],\n                \"24\": [13, 47],\n                \"13\": [47, 8, 43],\n                \"47\": [8],\n                \"8\": [43],\n                \"43\": [50],\n                \"50\": []\n            },\n            \"INHERIT\": { // inherit context from last frame\n                \"19\": [43, 7],\n                \"15\": [7]\n            },\n            \"USE_GT\": [24] // questions which use ground truth as answer\n        },\n        \"CONTROL_RATE\": 2.0, // intervene freq of vlm\n        \"MODEL_NAME\": \"api\", // model name\n        \"MODEL_PATH\": \"../model_zoo/your_model\", // model path\n        \"GPU_ID\": 0, // the gpu model runs on\n        \"PORT\": 7023, // web port\n        \"IN_CARLA\": true,\n        \"USE_BASE64\": true, // if false, local path is used for transmitting images\n        \"NO_PERC_INFO\": false // do not pass extra perception info to vlm via prompt\n    }\n    ```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 9,
    "Content": "\n2. Write start up script:\n   \n    *If you want a quickstart, you can set MINIMAL=1 to run Bench2Drive-VL without VLM.*\n",
    "ContentSha": "ZznsG46hRUZm2JKjGBa+Y0pZSNK1TV9FEZw1gNqEQ4k=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "2. 撰寫啟動腳本：\n   \n    *如果您想快速啟動，可以設置 MINIMAL=1 以在沒有 VLM 的情況下運行 Bench2Drive-VL。*\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 10,
    "Content": "    ```bash\n    #!/bin/bash\n    BASE_PORT=20082 # CARLA port\n    BASE_TM_PORT=50000\n    BASE_ROUTES=./leaderboard/data/bench2drive220\n    TEAM_AGENT=leaderboard/team_code/data_agent.py\n    BASE_CHECKPOINT_ENDPOINT=./my_checkpoint\n    SAVE_PATH=./eval_v1/\n    GPU_RANK=0 # the gpu carla runs on\n    VLM_CONFIG=/path/to/your_vlm_config.json\n    PORT=$BASE_PORT\n    TM_PORT=$BASE_TM_PORT\n    ROUTES=\"${BASE_ROUTES}.xml\"\n    CHECKPOINT_ENDPOINT=\"${BASE_CHECKPOINT_ENDPOINT}.json\"\n    export MINIMAL=0 # if MINIMAL > 0, DriveCommenter takes control of the ego vehicle,\n    # and vlm server is not needed\n    bash leaderboard/scripts/run_evaluation.sh $PORT $TM_PORT 1 $ROUTES $TEAM_AGENT \".\" $CHECKPOINT_ENDPOINT $SAVE_PATH \"null\" $GPU_RANK $VLM_CONFIG\n    ```",
    "ContentSha": "Hh7OWTMbeIm2IIhp/LgyV1QJoecRRZeUhothj6gXzyM=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "    ```bash\n    #!/bin/bash\n    BASE_PORT=20082 # CARLA port\n    BASE_TM_PORT=50000\n    BASE_ROUTES=./leaderboard/data/bench2drive220\n    TEAM_AGENT=leaderboard/team_code/data_agent.py\n    BASE_CHECKPOINT_ENDPOINT=./my_checkpoint\n    SAVE_PATH=./eval_v1/\n    GPU_RANK=0 # the gpu carla runs on\n    VLM_CONFIG=/path/to/your_vlm_config.json\n    PORT=$BASE_PORT\n    TM_PORT=$BASE_TM_PORT\n    ROUTES=\"${BASE_ROUTES}.xml\"\n    CHECKPOINT_ENDPOINT=\"${BASE_CHECKPOINT_ENDPOINT}.json\"\n    export MINIMAL=0 # if MINIMAL > 0, DriveCommenter takes control of the ego vehicle,\n    # and vlm server is not needed\n    bash leaderboard/scripts/run_evaluation.sh $PORT $TM_PORT 1 $ROUTES $TEAM_AGENT \".\" $CHECKPOINT_ENDPOINT $SAVE_PATH \"null\" $GPU_RANK $VLM_CONFIG\n    ```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 11,
    "Content": "\n3. Start VLM Server (not needed if `MINIMAL`)\n",
    "ContentSha": "F9trEMGMH5mZDZamx9CkCzAVGyHBsCX1aPbNeFrEwHI=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "3. 啟動 VLM 伺服器（如果是 `MINIMAL` 則不需要）\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 12,
    "Content": "    ```shell\n    python ./B2DVL_Adapter/web_interact_app.py --config /path/to/your/vlm_config.json\n    ```",
    "ContentSha": "sVl5FxswCdqDwC+NOqVs3OdvP4xsjQ/92Nb3Bwe9wK8=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "    ```shell\n    python ./B2DVL_Adapter/web_interact_app.py --config /path/to/your/vlm_config.json\n    ```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 13,
    "Content": "\n4. Start Main module\n",
    "ContentSha": "bwnBqb0hoXMWxWrggCkciZdgkZXjCJh0L9ZaX7CrBUs=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "4. 啟動主模組\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 14,
    "Content": "    ```shell\n    bash ./startup.sh\n    ```",
    "ContentSha": "OyfRV5o9BAdYC88FKPQnUu7Rbe3V1uxIRGROXAmTSQo=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "    ```shell\n    bash ./startup.sh\n    ```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 15,
    "Content": "\n### Generate VQAs from static dataset using DriveCommenter\n\n1. Write a startup script under `./B2DVL-Adapter`\n",
    "ContentSha": "83Hsi06TPyDp0g6Gf7a4kmkm633SPSJJvpQeN+VNBT0=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "### 使用 DriveCommenter 從靜態數據集生成 VQA\n\n1. 在 `./B2DVL-Adapter` 下撰寫啟動腳本\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 16,
    "Content": "    ```bash\n    #!/bin/bash\n    export SUBSET=0 # generate from a subset of given dataset\n    export STRICT_MODE=1\n    # DriveCommenter drives back the ego vehicle after circumventing obstacles if STRICT_MODE > 0\n    export SUBSET_PATH=./subset_0.txt # subset file\n    export PROCESSED_PATH=./processed_paths_0.txt # checkpoint file\n    export CACHE_PATH=./.worker_0_cache\n    # DriveCommenter supports dataset in .tar.gz\n    # it will unzip some of the dataset temporarily in cache dir\n    python ./drive_commenter_main.py --data-directory=/path/to/Bench2Drive/dataset --output-graph-directory=./outgraph     --path-maps=${CARLA_ROOT}/CarlaUE4/Content/Carla/Maps     --worker-count=1\n    # We do not recommend using multiple worker here since multi-thread in python is not very good.\n    # You can run multiple DriveCommenter at the same time with different subset and checkpoint files to do the same.\n    ```",
    "ContentSha": "IA3ThUNS8fnxwG4mg0tbTylcE5Ln8TifUHS1AczaM98=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "    ```bash\n    #!/bin/bash\n    export SUBSET=0 # generate from a subset of given dataset\n    export STRICT_MODE=1\n    # DriveCommenter drives back the ego vehicle after circumventing obstacles if STRICT_MODE > 0\n    export SUBSET_PATH=./subset_0.txt # subset file\n    export PROCESSED_PATH=./processed_paths_0.txt # checkpoint file\n    export CACHE_PATH=./.worker_0_cache\n    # DriveCommenter supports dataset in .tar.gz\n    # it will unzip some of the dataset temporarily in cache dir\n    python ./drive_commenter_main.py --data-directory=/path/to/Bench2Drive/dataset --output-graph-directory=./outgraph     --path-maps=${CARLA_ROOT}/CarlaUE4/Content/Carla/Maps     --worker-count=1\n    # We do not recommend using multiple worker here since multi-thread in python is not very good.\n    # You can run multiple DriveCommenter at the same time with different subset and checkpoint files to do the same.\n    ```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 17,
    "Content": "\n2. Run it.\n",
    "ContentSha": "FJZ7LBdjDkDeV+4bIdLNyFwABNzOdT2iALEpST5ZWyU=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "",
    "Status": "error",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 18,
    "Content": "    ```shell\n    cd ./B2DVL-Adapter\n    bash ./your_startup_script.sh\n    ```",
    "ContentSha": "I56EVdL95mA77Tv1WMNN+jFS/zg5aps7aRzfqqHU5zE=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "    ```shell\n    cd ./B2DVL-Adapter\n    bash ./your_startup_script.sh\n    ```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 19,
    "Content": "\n### Open-Loop Inference\n\n1. Write a config file.\n",
    "ContentSha": "642Vk68gNoiB8VGufWMnuWv2nlZLmi4sBgiSPb/hL/4=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "### 開環推理\n\n1. 撰寫設定檔。\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 20,
    "Content": "    ```java\n    {\n        \"TASK_CONFIGS\": {\n            \"INFER_SUBSET\": false, // inference a subset of given dataset\n            \"USE_CHECKPOINT\": true, // record the process of inference\n            \"SUBSET_FILE\": \"./infer_configs/subset.txt\", // subset file, leave blank if not used\n            \"CHECKPOINT_FILE\": \"./infer_configs/finished_scenarios.txt\", // checkpoint file, leave blank if not used\n            \"ENTRY_EXIT_FILE\": \"./infer_configs/entry_exits.json\", // the file which specifies entry and exit point of certain scenario, \n            // you can create a file with \"{}\" as content if do not specify\n            \"FRAME_PER_SEC\": 10 // sensor frame\n        },\n        \"INFERENCE_BASICS\": {\n            \"INPUT_WINDOW\": 1,\n            \"CONVERSATION_WINDOW\": 2,\n            \"USE_ALL_CAMERAS\": true,\n            \"NO_HISTORY_MODE\": false,\n            \"APPEND_QUESTION\": true,\n            \"APPENDIX_FILE\": \"./infer_configs/append_questions.json\" // not used now, to be removed\n        },\n        \"CHAIN\": {\n            \"NODE\": [43, 50],\n            \"EDGE\": {\n                \"43\": [50],\n                \"50\": []\n            },\n            \"INHERIT\": {\n                \"19\": [43, 7],\n                \"15\": [7]\n            },\n            \"USE_GT\": []\n        }\n    }\n    ```",
    "ContentSha": "j/xZUEp0ZNlNG20j1LEXtb79A7WyjDgWPepkcuRpW/M=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "    ```java\n    {\n        \"TASK_CONFIGS\": {\n            \"INFER_SUBSET\": false, // inference a subset of given dataset\n            \"USE_CHECKPOINT\": true, // record the process of inference\n            \"SUBSET_FILE\": \"./infer_configs/subset.txt\", // subset file, leave blank if not used\n            \"CHECKPOINT_FILE\": \"./infer_configs/finished_scenarios.txt\", // checkpoint file, leave blank if not used\n            \"ENTRY_EXIT_FILE\": \"./infer_configs/entry_exits.json\", // the file which specifies entry and exit point of certain scenario, \n            // you can create a file with \"{}\" as content if do not specify\n            \"FRAME_PER_SEC\": 10 // sensor frame\n        },\n        \"INFERENCE_BASICS\": {\n            \"INPUT_WINDOW\": 1,\n            \"CONVERSATION_WINDOW\": 2,\n            \"USE_ALL_CAMERAS\": true,\n            \"NO_HISTORY_MODE\": false,\n            \"APPEND_QUESTION\": true,\n            \"APPENDIX_FILE\": \"./infer_configs/append_questions.json\" // not used now, to be removed\n        },\n        \"CHAIN\": {\n            \"NODE\": [43, 50],\n            \"EDGE\": {\n                \"43\": [50],\n                \"50\": []\n            },\n            \"INHERIT\": {\n                \"19\": [43, 7],\n                \"15\": [7]\n            },\n            \"USE_GT\": []\n        }\n    }\n    ```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 21,
    "Content": "\n2. Start up inference script:\n",
    "ContentSha": "+3pLIwo6LRPgukbsRfC3qQ3fMyzFQbtItEFpHQolUdw=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "2. 啟動推理腳本：\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 22,
    "Content": "    ```shell\n    cd ./B2DVL_Adapter\n    python inference.py --model Qwen2.5VL --model_path /path/to/Qwen2.5VL-3B-Instruct --config_dir /path/to/your_infer_config.json --image_dir /path/to/Bench2Drive/dataset --vqa_dir /path/to/vqa/dataset --num_workers 4 --out_dir ./infer_outputs\n    ```",
    "ContentSha": "9wUV1Q7741RCN/PkQymnb7rrPUiga1P9HquDT1qwBUA=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "    ```shell\n    cd ./B2DVL_Adapter\n    python inference.py --model Qwen2.5VL --model_path /path/to/Qwen2.5VL-3B-Instruct --config_dir /path/to/your_infer_config.json --image_dir /path/to/Bench2Drive/dataset --vqa_dir /path/to/vqa/dataset --num_workers 4 --out_dir ./infer_outputs\n    ```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 23,
    "Content": "\n### Evaluation\n\n1. To use your llm api for evaluation, create a `mytoken.py` under `./B2DVL-Adapter`. Take deepseek as an example:\n",
    "ContentSha": "1/kgFA2sMMF8VdtONOQ8Wk2fN+/1nS5U12KNCBcEr1I=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "### 評估\n\n1. 若要使用您的 llm api 進行評估，請在 `./B2DVL-Adapter` 下建立一個 `mytoken.py`。以 deepseek 為例：\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 24,
    "Content": "    ```python\n    DEEPSEEK_TOKEN = [\n        \"your-token-1\", # you can set multiple tokens, and they will be used in a round-robin way\n        \"your-token-2\"...\n    ]\n    DEEPSEEK_URL = \"https://api.deepseek.com/v1\"\n    ```",
    "ContentSha": "HYgpL+TSqg6Un3pfNByMbjnQIFvOSr0VzuTc3AZsi+o=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "    ```python\n    DEEPSEEK_TOKEN = [\n        \"your-token-1\", # you can set multiple tokens, and they will be used in a round-robin way\n        \"your-token-2\"...\n    ]\n    DEEPSEEK_URL = \"https://api.deepseek.com/v1\"\n    ```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 25,
    "Content": "\n    Then our script will call this api using `openai` templates.\n\n\n\n2. Write a config file:\n",
    "ContentSha": "BmkTtvsov7Wm4V89omlPyik+k85/OPw/J22yQDN+tQg=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "    然後我們的腳本將使用 `openai` 範本調用此 API。\n\n\n\n2. 撰寫一個配置文件：\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 26,
    "Content": "    ```java\n    {\n        \"EVAL_SUBSET\": true, // eval a subset of given infer result folder\n        \"USE_CHECKPOINT\": false, // use a file to record evaluation process\n        \"SUBSET_FILE\": \"./eval_configs/subset.txt\", // subset file\n        \"CHECKPOINT_FILE\": \"./eval_configs/finished_scenarios.txt\", // checkpoint file\n        \"INFERENCE_RESULT_DIR\": \"./infer_results\", // path to inference results\n        // when doing closed-loop inference, this dir is ./output/infer_results/model_name+input_mode\n        \"B2D_DIR\": \"/path/to/Bench2Drive/dataset\", // evaluation script uses annotations in b2d,\n        // when doing closed-loop inference, this dir is ./eval_v1(SAVE_PATH you specified)/model_name+input_mode\n        \"ORIGINAL_VQA_DIR\": \"../Carla_Chain_QA/carla_vqa_gen/vqa_dataset/outgraph\",\n        // when doing closed-loop inference, this dir is ./output/vqagen/model_name+input_mode\n        \"FRAME_PER_SEC\": 10, // sensor fps\n        \"LOOK_FUTURE\": false // not used now, to be removed\n    }\n    ```",
    "ContentSha": "iMBseHvYUuIdfpxyFPHtp+8xQpl//WbdT/vKTyQZk3A=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "    ```java\n    {\n        \"EVAL_SUBSET\": true, // eval a subset of given infer result folder\n        \"USE_CHECKPOINT\": false, // use a file to record evaluation process\n        \"SUBSET_FILE\": \"./eval_configs/subset.txt\", // subset file\n        \"CHECKPOINT_FILE\": \"./eval_configs/finished_scenarios.txt\", // checkpoint file\n        \"INFERENCE_RESULT_DIR\": \"./infer_results\", // path to inference results\n        // when doing closed-loop inference, this dir is ./output/infer_results/model_name+input_mode\n        \"B2D_DIR\": \"/path/to/Bench2Drive/dataset\", // evaluation script uses annotations in b2d,\n        // when doing closed-loop inference, this dir is ./eval_v1(SAVE_PATH you specified)/model_name+input_mode\n        \"ORIGINAL_VQA_DIR\": \"../Carla_Chain_QA/carla_vqa_gen/vqa_dataset/outgraph\",\n        // when doing closed-loop inference, this dir is ./output/vqagen/model_name+input_mode\n        \"FRAME_PER_SEC\": 10, // sensor fps\n        \"LOOK_FUTURE\": false // not used now, to be removed\n    }\n    ```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 27,
    "Content": "\n2. Run evaluation script:\n",
    "ContentSha": "T1POERZX5SypMBgWoMDRguFUJHkVnCL5lqTrySCO32c=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "2. 執行評估腳本：\n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 28,
    "Content": "    ```shell\n    python eval.py --config_dir ./path/to/eval_config.json --num_workers 4 --out_dir ./eval_outputs\n    ```",
    "ContentSha": "GOO++pasmwmBY5OSSHnasXShTxmnmZ+gySgDkmgQhMk=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "    ```shell\n    python eval.py --config_dir ./path/to/eval_config.json --num_workers 4 --out_dir ./eval_outputs\n    ```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 29,
    "Content": "\n## License\nAll assets and code are under the CC-BY-NC-ND unless specified otherwise.",
    "ContentSha": "987ni+TRN5ZJhYrE4/xZJbh9IL2fYM5BhfoK7BEgbdc=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "## 授權條款\n所有資產和程式碼均依CC-BY-NC-ND授權，除非另有說明。\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  }
]