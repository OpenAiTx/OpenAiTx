<div align="right">
  <details>
    <summary >ğŸŒ Idioma</summary>
    <div>
      <div align="center">
        <a href="https://openaitx.github.io/view.html?user=itshyao&project=proxyless-llm-websearch&lang=en">English</a>
        | <a href="https://openaitx.github.io/view.html?user=itshyao&project=proxyless-llm-websearch&lang=zh-CN">ç®€ä½“ä¸­æ–‡</a>
        | <a href="https://openaitx.github.io/view.html?user=itshyao&project=proxyless-llm-websearch&lang=zh-TW">ç¹é«”ä¸­æ–‡</a>
        | <a href="https://openaitx.github.io/view.html?user=itshyao&project=proxyless-llm-websearch&lang=ja">æ—¥æœ¬èª</a>
        | <a href="https://openaitx.github.io/view.html?user=itshyao&project=proxyless-llm-websearch&lang=ko">í•œêµ­ì–´</a>
        | <a href="https://openaitx.github.io/view.html?user=itshyao&project=proxyless-llm-websearch&lang=hi">à¤¹à¤¿à¤¨à¥à¤¦à¥€</a>
        | <a href="https://openaitx.github.io/view.html?user=itshyao&project=proxyless-llm-websearch&lang=th">à¹„à¸—à¸¢</a>
        | <a href="https://openaitx.github.io/view.html?user=itshyao&project=proxyless-llm-websearch&lang=fr">FranÃ§ais</a>
        | <a href="https://openaitx.github.io/view.html?user=itshyao&project=proxyless-llm-websearch&lang=de">Deutsch</a>
        | <a href="https://openaitx.github.io/view.html?user=itshyao&project=proxyless-llm-websearch&lang=es">EspaÃ±ol</a>
        | <a href="https://openaitx.github.io/view.html?user=itshyao&project=proxyless-llm-websearch&lang=it">Italiano</a>
        | <a href="https://openaitx.github.io/view.html?user=itshyao&project=proxyless-llm-websearch&lang=ru">Ğ ÑƒÑÑĞºĞ¸Ğ¹</a>
        | <a href="https://openaitx.github.io/view.html?user=itshyao&project=proxyless-llm-websearch&lang=pt">PortuguÃªs</a>
        | <a href="https://openaitx.github.io/view.html?user=itshyao&project=proxyless-llm-websearch&lang=nl">Nederlands</a>
        | <a href="https://openaitx.github.io/view.html?user=itshyao&project=proxyless-llm-websearch&lang=pl">Polski</a>
        | <a href="https://openaitx.github.io/view.html?user=itshyao&project=proxyless-llm-websearch&lang=ar">Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©</a>
        | <a href="https://openaitx.github.io/view.html?user=itshyao&project=proxyless-llm-websearch&lang=fa">ÙØ§Ø±Ø³ÛŒ</a>
        | <a href="https://openaitx.github.io/view.html?user=itshyao&project=proxyless-llm-websearch&lang=tr">TÃ¼rkÃ§e</a>
        | <a href="https://openaitx.github.io/view.html?user=itshyao&project=proxyless-llm-websearch&lang=vi">Tiáº¿ng Viá»‡t</a>
        | <a href="https://openaitx.github.io/view.html?user=itshyao&project=proxyless-llm-websearch&lang=id">Bahasa Indonesia</a>
      </div>
    </div>
  </details>
</div>

# ğŸ§  Motor de bÃºsqueda web LLM sin proxy

Una herramienta de recuperaciÃ³n web LLM multibuscador sin necesidad de proxy, compatible con el anÃ¡lisis de contenido de URL y rastreo web, combinando **LangGraph** y **LangGraph-MCP** para lograr una cadena de agentes modular. DiseÃ±ada para escenarios de acceso a conocimiento externo por modelos de lenguaje grande, soporta obtenciÃ³n y anÃ¡lisis de pÃ¡ginas web con **Playwright + Crawl4AI**, asÃ­ como concurrencia asÃ­ncrona, segmentaciÃ³n de contenido y reordenamiento filtrado.

## ğŸš€ Registro de actualizaciones

- ğŸ”¥ 2025-09-05: Soporte para **langgraph-mcp**
- ğŸ”¥ 2025-09-03: Nuevo despliegue con Docker, reordenador inteligente integrado, soporte para segmentadores y reordenadores de texto personalizados

## âœ¨ Vista rÃ¡pida de caracterÃ­sticas

- ğŸŒ **Sin necesidad de proxy**: ConfiguraciÃ³n de navegador nacional mediante Playwright, permite realizar bÃºsquedas en la web sin requerir proxy.
- ğŸ” **Soporte para mÃºltiples motores de bÃºsqueda**: Compatible con Bing, Quark, Baidu, Sogou y otros motores principales, aumentando la diversidad de fuentes de informaciÃ³n.
- ğŸ¤– **Reconocimiento de intenciÃ³n**: El sistema puede determinar automÃ¡ticamente si debe realizar una bÃºsqueda web o analizar una URL segÃºn el contenido ingresado por el usuario.
- ğŸ”„ **DescomposiciÃ³n de consultas**: SegÃºn la intenciÃ³n de bÃºsqueda del usuario, divide automÃ¡ticamente la consulta en varias subtareas y las ejecuta secuencialmente, mejorando la relevancia y eficiencia de la bÃºsqueda.
- âš™ï¸ **Arquitectura de agentes inteligentes**: Basada en **LangGraph**, encapsula **ã€Œweb_searchã€** y **ã€Œlink_parserã€**.
- ğŸƒâ€â™‚ï¸ **Procesamiento de tareas concurrentes asÃ­ncronas**: Admite procesamiento asÃ­ncrono y concurrente de tareas, permitiendo manejar eficientemente mÃºltiples bÃºsquedas.
- ğŸ“ **OptimizaciÃ³n del procesamiento de contenido**:

  - âœ‚ï¸ **SegmentaciÃ³n de contenido**: Divide el contenido extenso de las pÃ¡ginas web en secciones.

  - ğŸ”„ **Reordenamiento de contenido**: Reordena inteligentemente para aumentar la relevancia de la informaciÃ³n.

  - ğŸš« **Filtrado de contenido**: Elimina automÃ¡ticamente contenido irrelevante o duplicado.
- ğŸŒ **Soporte multiplataforma**:
  - ğŸ³ **Soporta despliegue en Docker**: Inicio con un solo clic, construcciÃ³n rÃ¡pida de servicios backend.

  - ğŸ–¥ï¸ Proporciona interfaz backend con FastAPI, integrable en cualquier sistema.

  - ğŸŒ Ofrece Gradio Web UI, permitiendo rÃ¡pida implementaciÃ³n como aplicaciÃ³n visual.

  - ğŸ§©[ **Soporte para extensiones de navegador**](https://github.com/itshyao/proxyless-llm-websearch/tree/main/extension): Compatible con Edge, proporciona extensiÃ³n inteligente para anÃ¡lisis de URL, permite iniciar solicitudes de anÃ¡lisis y extracciÃ³n de contenido directamente desde el navegador.


![workflow](https://raw.githubusercontent.com/itshyao/proxyless-llm-websearch/main/img/workflow.png)

![framework](https://raw.githubusercontent.com/itshyao/proxyless-llm-websearch/main/img/framework.png)

## âš¡ Comienzo rÃ¡pido

### Clonar el repositorio

```bash
git clone https://github.com/itshyao/proxyless-llm-websearch.git
cd proxyless-llm-websearch
```

### Instalar dependencias

```
pip install -r requirements.txt
python -m playwright install
```

### ConfiguraciÃ³n de variables de entorno

```
# ç™¾ç‚¼llm
OPENAI_BASE_URL=https://dashscope.aliyuncs.com/compatible-mode/v1
OPENAI_API_KEY=sk-xxx
MODEL_NAME=qwen-plus-latest

# ç™¾ç‚¼embedding
EMBEDDING_BASE_URL=https://dashscope.aliyuncs.com/compatible-mode/v1
EMBEDDING_API_KEY=sk-xxx
EMBEDDING_MODEL_NAME=text-embedding-v4

# ç™¾ç‚¼reranker
RERANK_BASE_URL=https://dashscope.aliyuncs.com/compatible-mode/v1
RERANK_API_KEY=sk-xxx
RERANK_MODEL=gte-rerank-v2
```

### Langgraph-Agent

#### DEMO

```shell
python agent/demo.py
```

#### SERVICIO API

```shell
python agent/api_serve.py
```

```python
import requests

url = "http://localhost:8800/search"

data = {
  "question": "å¹¿å·ä»Šæ—¥å¤©æ°”",
  "engine": "bing",
  "split": {
    "chunk_size": 512,
    "chunk_overlap": 128
  },
  "rerank": {
    "top_k": 5
  }
}

try:
    response = requests.post(
        url,
        json=data
    )

    if response.status_code == 200:
        print("âœ… è¯·æ±‚æˆåŠŸï¼")
        print("å“åº”å†…å®¹ï¼š", response.json())
    else:
        print(f"âŒ è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç ï¼š{response.status_code}")
        print("é”™è¯¯ä¿¡æ¯ï¼š", response.text)

except requests.exceptions.RequestException as e:
    print(f"âš ï¸ è¯·æ±‚å¼‚å¸¸ï¼š{str(e)}")
```

#### Gradio

```
python agent/gradio_demo.py
```

![gradio](https://raw.githubusercontent.com/itshyao/proxyless-llm-websearch/main/img/gradio1.png)

![gradio](https://raw.githubusercontent.com/itshyao/proxyless-llm-websearch/main/img/gradio2.png)

#### docker

```
docker-compose -f docker-compose-ag.yml up -d --build
```

### Langgrph-MCP

#### Iniciar el servicio MCP

```
python mcp/websearch.py
```

#### DEMOSTRACIÃ“N

```
python mcp/demo.py
```

#### SERVICIO API

```
python mcp/api_serve.py
```

```
import requests

url = "http://localhost:8800/search"

data = {
  "question": "å¹¿å·ä»Šæ—¥å¤©æ°”"
}

try:
    response = requests.post(
        url,
        json=data
    )

    if response.status_code == 200:
        print("âœ… è¯·æ±‚æˆåŠŸï¼")
        print("å“åº”å†…å®¹ï¼š", response.json())
    else:
        print(f"âŒ è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç ï¼š{response.status_code}")
        print("é”™è¯¯ä¿¡æ¯ï¼š", response.text)

except requests.exceptions.RequestException as e:
    print(f"âš ï¸ è¯·æ±‚å¼‚å¸¸ï¼š{str(e)}")
```

#### docker

```
docker-compose -f docker-compose-mcp.yml up -d --build
```

### MÃ³dulos personalizados

#### SegmentaciÃ³n personalizada

```
from typing import Optional, List

class YourSplitter:
    def __init__(self, text: str, chunk_size: int = 512, chunk_overlap: int = 128):
        self.text = text
        self.chunk_size = chunk_size
        self.chunk_overlap = chunk_overlap

    def split_text(self, text: Optional[str] = None) -> List:
        # TODO: implement splitting logic
        return ["your chunk"]
```

#### ReordenaciÃ³n personalizada

```
from typing import List, Union, Tuple

class YourReranker:
    async def get_reranked_documents(
        self,
        query: Union[str, List[str]],
        documents: List[str],
    ) -> Union[
        Tuple[List[str]],
        Tuple[List[int]],
    ]:
        return ["your chunk"], ["chunk index"]
```

## ğŸ” ComparaciÃ³n con pruebas de bÃºsqueda en lÃ­nea

Comparamos el proyecto con algunas API en lÃ­nea populares y evaluamos su desempeÃ±o en problemas complejos.

### ğŸ”¥ Conjunto de datos

- El conjunto de datos proviene de [WebWalkerQA](https://huggingface.co/datasets/callanwu/WebWalkerQA) publicado por Alibaba, contiene 680 preguntas de alta dificultad y abarca educaciÃ³n, conferencias acadÃ©micas, juegos y otros campos.
- El conjunto de datos incluye preguntas en chino e inglÃ©s.

### ğŸ§‘â€ğŸ« Resultados comparativos

| Motor de bÃºsqueda/Sistema | âœ… Correcto | âŒ Incorrecto | âš ï¸ Parcialmente correcto |
| ------------------------ | ---------- | ------------ | ----------------------- |
| **Volcano Ark**          | 5.00%      | 72.21%       | 22.79%                  |
| **Bailian**              | 9.85%      | 62.79%       | 27.35%                  |
| **Nuestro**              | 19.85%     | 47.94%       | 32.06%                  |
## ğŸ™ Agradecimientos

Algunas funciones de este proyecto se benefician del apoyo e inspiraciÃ³n de los siguientes proyectos de cÃ³digo abierto, por lo que expresamos nuestro agradecimiento:

- ğŸ§  [LangGraph](https://github.com/langchain-ai/langgraph): Utilizado para construir el marco de agentes modulares, facilita el desarrollo rÃ¡pido de sistemas de agentes complejos.
- ğŸ•· [Crawl4AI](https://github.com/unclecode/crawl4ai): Potente herramienta de anÃ¡lisis de contenido web, ayuda en la extracciÃ³n eficiente de datos y el scraping de pÃ¡ginas.
- ğŸŒ [Playwright](https://github.com/microsoft/playwright): Herramienta moderna de automatizaciÃ³n de navegadores, soporta scraping y pruebas automatizadas en varios navegadores.
- ğŸ”Œ [Langchain MCP Adapters](https://github.com/langchain-ai/langchain-mcp-adapters): Utilizado para la construcciÃ³n de MCP de procesamiento multichain.



---

Tranlated By [Open Ai Tx](https://github.com/OpenAiTx/OpenAiTx) | Last indexed: 2025-09-08

---