<div align="right">
  <details>
    <summary >ğŸŒ Langue</summary>
    <div>
      <div align="center">
        <a href="https://openaitx.github.io/view.html?user=itshyao&project=proxyless-llm-websearch&lang=en">English</a>
        | <a href="https://openaitx.github.io/view.html?user=itshyao&project=proxyless-llm-websearch&lang=zh-CN">ç®€ä½“ä¸­æ–‡</a>
        | <a href="https://openaitx.github.io/view.html?user=itshyao&project=proxyless-llm-websearch&lang=zh-TW">ç¹é«”ä¸­æ–‡</a>
        | <a href="https://openaitx.github.io/view.html?user=itshyao&project=proxyless-llm-websearch&lang=ja">æ—¥æœ¬èª</a>
        | <a href="https://openaitx.github.io/view.html?user=itshyao&project=proxyless-llm-websearch&lang=ko">í•œêµ­ì–´</a>
        | <a href="https://openaitx.github.io/view.html?user=itshyao&project=proxyless-llm-websearch&lang=hi">à¤¹à¤¿à¤¨à¥à¤¦à¥€</a>
        | <a href="https://openaitx.github.io/view.html?user=itshyao&project=proxyless-llm-websearch&lang=th">à¹„à¸—à¸¢</a>
        | <a href="https://openaitx.github.io/view.html?user=itshyao&project=proxyless-llm-websearch&lang=fr">FranÃ§ais</a>
        | <a href="https://openaitx.github.io/view.html?user=itshyao&project=proxyless-llm-websearch&lang=de">Deutsch</a>
        | <a href="https://openaitx.github.io/view.html?user=itshyao&project=proxyless-llm-websearch&lang=es">EspaÃ±ol</a>
        | <a href="https://openaitx.github.io/view.html?user=itshyao&project=proxyless-llm-websearch&lang=it">Italiano</a>
        | <a href="https://openaitx.github.io/view.html?user=itshyao&project=proxyless-llm-websearch&lang=ru">Ğ ÑƒÑÑĞºĞ¸Ğ¹</a>
        | <a href="https://openaitx.github.io/view.html?user=itshyao&project=proxyless-llm-websearch&lang=pt">PortuguÃªs</a>
        | <a href="https://openaitx.github.io/view.html?user=itshyao&project=proxyless-llm-websearch&lang=nl">Nederlands</a>
        | <a href="https://openaitx.github.io/view.html?user=itshyao&project=proxyless-llm-websearch&lang=pl">Polski</a>
        | <a href="https://openaitx.github.io/view.html?user=itshyao&project=proxyless-llm-websearch&lang=ar">Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©</a>
        | <a href="https://openaitx.github.io/view.html?user=itshyao&project=proxyless-llm-websearch&lang=fa">ÙØ§Ø±Ø³ÛŒ</a>
        | <a href="https://openaitx.github.io/view.html?user=itshyao&project=proxyless-llm-websearch&lang=tr">TÃ¼rkÃ§e</a>
        | <a href="https://openaitx.github.io/view.html?user=itshyao&project=proxyless-llm-websearch&lang=vi">Tiáº¿ng Viá»‡t</a>
        | <a href="https://openaitx.github.io/view.html?user=itshyao&project=proxyless-llm-websearch&lang=id">Bahasa Indonesia</a>
      </div>
    </div>
  </details>
</div>
# ğŸ§  Moteur de recherche LLM sans proxy

Un outil de rÃ©cupÃ©ration sur le web multi-moteur LLM sans proxy, prenant en charge lâ€™analyse de contenu dâ€™URL et le crawling de pages web, combinant **LangGraph** et **LangGraph-MCP** pour rÃ©aliser une chaÃ®ne d'agents modulaire. ConÃ§u pour lâ€™appel de connaissances externes par les grands modÃ¨les de langage, il prend en charge lâ€™acquisition et lâ€™analyse de pages web via **Playwright + Crawl4AI**, avec gestion de la concurrence asynchrone, dÃ©coupage et rÃ©organisation des contenus.

## ğŸš€ Journal des mises Ã  jour

- ğŸ”¥ 2025-09-05 : Support de **langgraph-mcp**
- ğŸ”¥ 2025-09-03 : Ajout du dÃ©ploiement Docker, reranker intÃ©grÃ©, support des dÃ©coupeurs et rerankers personnalisÃ©s

## âœ¨ AperÃ§u des fonctionnalitÃ©s

- ğŸŒ **Aucun proxy requis** : prise en charge des navigateurs chinois via la configuration Playwright, permettant la recherche en ligne sans proxy.
- ğŸ” **Prise en charge de plusieurs moteurs de recherche** : prise en charge de Bing, Quark, Baidu, Sogou et autres moteurs principaux, pour une diversitÃ© accrue des sources d'information.
- ğŸ¤– **Reconnaissance d'intention** : le systÃ¨me peut dÃ©terminer automatiquement, selon la saisie de l'utilisateur, s'il doit effectuer une recherche web ou analyser une URL.
- ğŸ”„ **DÃ©composition des requÃªtes** : en fonction de l'intention de recherche, la requÃªte est automatiquement divisÃ©e en plusieurs sous-tÃ¢ches qui sont exÃ©cutÃ©es successivement pour amÃ©liorer la pertinence et l'efficacitÃ© de la recherche.
- âš™ï¸ **Architecture intelligente** : encapsulation des modules **Â« web_search Â»** et **Â« link_parser Â»** basÃ©s sur **LangGraph**.
- ğŸƒâ€â™‚ï¸ **Traitement asynchrone et concurrent des tÃ¢ches** : prise en charge du traitement asynchrone et concurrent des tÃ¢ches, permettant de gÃ©rer efficacement plusieurs recherches.
- ğŸ“ **Optimisation du traitement du contenu** :

  - âœ‚ï¸ **DÃ©coupage du contenu** : division du contenu long des pages web en segments.

  - ğŸ”„ **RÃ©ordonnancement du contenu** : rÃ©organisation intelligente pour une meilleure pertinence de l'information.

  - ğŸš« **Filtrage du contenu** : suppression automatique des contenus non pertinents ou doublons.
- ğŸŒ **Prise en charge multiplateforme** :
  - ğŸ³ **DÃ©ploiement Docker pris en charge** : dÃ©marrage en un clic, construction rapide du service backend.

  - ğŸ–¥ï¸ Interface backend FastAPI fournie, intÃ©grable Ã  tout systÃ¨me.

  - ğŸŒ Interface Web Gradio fournie, permettant un dÃ©ploiement rapide en application visuelle.

  - ğŸ§©[ **Prise en charge des extensions navigateur**](https://github.com/itshyao/proxyless-llm-websearch/tree/main/extension) : prise en charge Edge, extension intelligente dâ€™analyse dâ€™URL, permettant lâ€™analyse et lâ€™extraction directe du contenu dans le navigateur.


![workflow](https://raw.githubusercontent.com/itshyao/proxyless-llm-websearch/main/img/workflow.png)

![framework](https://raw.githubusercontent.com/itshyao/proxyless-llm-websearch/main/img/framework.png)

## âš¡ DÃ©marrage rapide

### Cloner le dÃ©pÃ´t

```bash
git clone https://github.com/itshyao/proxyless-llm-websearch.git
cd proxyless-llm-websearch
```

### Installation des dÃ©pendances

```
pip install -r requirements.txt
python -m playwright install
```

### Configuration des variables d'environnement

```
# ç™¾ç‚¼llm
OPENAI_BASE_URL=https://dashscope.aliyuncs.com/compatible-mode/v1
OPENAI_API_KEY=sk-xxx
MODEL_NAME=qwen-plus-latest

# ç™¾ç‚¼embedding
EMBEDDING_BASE_URL=https://dashscope.aliyuncs.com/compatible-mode/v1
EMBEDDING_API_KEY=sk-xxx
EMBEDDING_MODEL_NAME=text-embedding-v4

# ç™¾ç‚¼reranker
RERANK_BASE_URL=https://dashscope.aliyuncs.com/compatible-mode/v1
RERANK_API_KEY=sk-xxx
RERANK_MODEL=gte-rerank-v2
```

### Langgraph-Agent

#### DÃ‰MONSTRATION

```shell
python agent/demo.py
```

#### SERVEUR API

```shell
python agent/api_serve.py
```

```python
import requests

url = "http://localhost:8800/search"

data = {
  "question": "å¹¿å·ä»Šæ—¥å¤©æ°”",
  "engine": "bing",
  "split": {
    "chunk_size": 512,
    "chunk_overlap": 128
  },
  "rerank": {
    "top_k": 5
  }
}

try:
    response = requests.post(
        url,
        json=data
    )

    if response.status_code == 200:
        print("âœ… è¯·æ±‚æˆåŠŸï¼")
        print("å“åº”å†…å®¹ï¼š", response.json())
    else:
        print(f"âŒ è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç ï¼š{response.status_code}")
        print("é”™è¯¯ä¿¡æ¯ï¼š", response.text)

except requests.exceptions.RequestException as e:
    print(f"âš ï¸ è¯·æ±‚å¼‚å¸¸ï¼š{str(e)}")
```

#### Gradio

```
python agent/gradio_demo.py
```

![gradio](https://raw.githubusercontent.com/itshyao/proxyless-llm-websearch/main/img/gradio1.png)

![gradio](https://raw.githubusercontent.com/itshyao/proxyless-llm-websearch/main/img/gradio2.png)

#### docker

```
docker-compose -f docker-compose-ag.yml up -d --build
```

### Langgrph-MCP

#### DÃ©marrer le service MCP

```
python mcp/websearch.py
```

#### DÃ‰MO

```
python mcp/demo.py
```

#### SERVEUR D'API

```
python mcp/api_serve.py
```

```
import requests

url = "http://localhost:8800/search"

data = {
  "question": "å¹¿å·ä»Šæ—¥å¤©æ°”"
}

try:
    response = requests.post(
        url,
        json=data
    )

    if response.status_code == 200:
        print("âœ… è¯·æ±‚æˆåŠŸï¼")
        print("å“åº”å†…å®¹ï¼š", response.json())
    else:
        print(f"âŒ è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç ï¼š{response.status_code}")
        print("é”™è¯¯ä¿¡æ¯ï¼š", response.text)

except requests.exceptions.RequestException as e:
    print(f"âš ï¸ è¯·æ±‚å¼‚å¸¸ï¼š{str(e)}")
```

#### docker

```
docker-compose -f docker-compose-mcp.yml up -d --build
```

### Module personnalisÃ©

#### Partitionnement personnalisÃ©

```
from typing import Optional, List

class YourSplitter:
    def __init__(self, text: str, chunk_size: int = 512, chunk_overlap: int = 128):
        self.text = text
        self.chunk_size = chunk_size
        self.chunk_overlap = chunk_overlap

    def split_text(self, text: Optional[str] = None) -> List:
        # TODO: implement splitting logic
        return ["your chunk"]
```

#### RÃ©organisation personnalisÃ©e

```
from typing import List, Union, Tuple

class YourReranker:
    async def get_reranked_documents(
        self,
        query: Union[str, List[str]],
        documents: List[str],
    ) -> Union[
        Tuple[List[str]],
        Tuple[List[int]],
    ]:
        return ["your chunk"], ["chunk index"]
```

## ğŸ” Comparaison avec les tests de recherche en ligne

Nous avons comparÃ© le projet avec plusieurs API en ligne principales, en Ã©valuant leurs performances sur des questions complexes.

### ğŸ”¥ Jeu de donnÃ©es

- Le jeu de donnÃ©es provient de [WebWalkerQA](https://huggingface.co/datasets/callanwu/WebWalkerQA) publiÃ© par Alibaba, comprenant 680 questions de haute difficultÃ© couvrant l'Ã©ducation, les confÃ©rences acadÃ©miques, les jeux et d'autres domaines.
- Le jeu de donnÃ©es inclut des questions en chinois et en anglais.

### ğŸ§‘â€ğŸ« RÃ©sultats comparatifs

| Moteur de recherche/SystÃ¨me | âœ… Correct | âŒ Incorrect | âš ï¸ Partiellement correct |
| -------------------------- | ----------| ------------| ------------------------|
| **Volcano Ark**            | 5,00 %    | 72,21 %     | 22,79 %                 |
| **Bailian**                | 9,85 %    | 62,79 %     | 27,35 %                 |
| **Notre**                  | 19,85 %   | 47,94 %     | 32,06 %                 |
## ğŸ™ Remerciements

Certaines fonctionnalitÃ©s de ce projet bÃ©nÃ©ficient du soutien et de l'inspiration des projets open source suivants, que nous tenons Ã  remercier :

- ğŸ§  [LangGraph](https://github.com/langchain-ai/langgraph) : utilisÃ© pour construire un cadre de chaÃ®ne d'agents modulaire, facilitant la crÃ©ation rapide de systÃ¨mes d'agents complexes.
- ğŸ•· [Crawl4AI](https://github.com/unclecode/crawl4ai) : puissant outil d'analyse de contenu web, facilitant le crawling efficace et l'extraction de donnÃ©es.
- ğŸŒ [Playwright](https://github.com/microsoft/playwright) : outil moderne d'automatisation de navigateur, supportant le crawling web et les tests automatisÃ©s multi-navigateurs.
- ğŸ”Œ [Langchain MCP Adapters](https://github.com/langchain-ai/langchain-mcp-adapters) : utilisÃ© pour la construction de MCP multi-chaÃ®nes.


---

Tranlated By [Open Ai Tx](https://github.com/OpenAiTx/OpenAiTx) | Last indexed: 2025-09-05

---