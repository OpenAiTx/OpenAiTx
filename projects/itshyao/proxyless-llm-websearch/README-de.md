<div align="right">
  <details>
    <summary >ğŸŒ Sprache</summary>
    <div>
      <div align="center">
        <a href="https://openaitx.github.io/view.html?user=itshyao&project=proxyless-llm-websearch&lang=en">English</a>
        | <a href="https://openaitx.github.io/view.html?user=itshyao&project=proxyless-llm-websearch&lang=zh-CN">ç®€ä½“ä¸­æ–‡</a>
        | <a href="https://openaitx.github.io/view.html?user=itshyao&project=proxyless-llm-websearch&lang=zh-TW">ç¹é«”ä¸­æ–‡</a>
        | <a href="https://openaitx.github.io/view.html?user=itshyao&project=proxyless-llm-websearch&lang=ja">æ—¥æœ¬èª</a>
        | <a href="https://openaitx.github.io/view.html?user=itshyao&project=proxyless-llm-websearch&lang=ko">í•œêµ­ì–´</a>
        | <a href="https://openaitx.github.io/view.html?user=itshyao&project=proxyless-llm-websearch&lang=hi">à¤¹à¤¿à¤¨à¥à¤¦à¥€</a>
        | <a href="https://openaitx.github.io/view.html?user=itshyao&project=proxyless-llm-websearch&lang=th">à¹„à¸—à¸¢</a>
        | <a href="https://openaitx.github.io/view.html?user=itshyao&project=proxyless-llm-websearch&lang=fr">FranÃ§ais</a>
        | <a href="https://openaitx.github.io/view.html?user=itshyao&project=proxyless-llm-websearch&lang=de">Deutsch</a>
        | <a href="https://openaitx.github.io/view.html?user=itshyao&project=proxyless-llm-websearch&lang=es">EspaÃ±ol</a>
        | <a href="https://openaitx.github.io/view.html?user=itshyao&project=proxyless-llm-websearch&lang=it">Italiano</a>
        | <a href="https://openaitx.github.io/view.html?user=itshyao&project=proxyless-llm-websearch&lang=ru">Ğ ÑƒÑÑĞºĞ¸Ğ¹</a>
        | <a href="https://openaitx.github.io/view.html?user=itshyao&project=proxyless-llm-websearch&lang=pt">PortuguÃªs</a>
        | <a href="https://openaitx.github.io/view.html?user=itshyao&project=proxyless-llm-websearch&lang=nl">Nederlands</a>
        | <a href="https://openaitx.github.io/view.html?user=itshyao&project=proxyless-llm-websearch&lang=pl">Polski</a>
        | <a href="https://openaitx.github.io/view.html?user=itshyao&project=proxyless-llm-websearch&lang=ar">Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©</a>
        | <a href="https://openaitx.github.io/view.html?user=itshyao&project=proxyless-llm-websearch&lang=fa">ÙØ§Ø±Ø³ÛŒ</a>
        | <a href="https://openaitx.github.io/view.html?user=itshyao&project=proxyless-llm-websearch&lang=tr">TÃ¼rkÃ§e</a>
        | <a href="https://openaitx.github.io/view.html?user=itshyao&project=proxyless-llm-websearch&lang=vi">Tiáº¿ng Viá»‡t</a>
        | <a href="https://openaitx.github.io/view.html?user=itshyao&project=proxyless-llm-websearch&lang=id">Bahasa Indonesia</a>
      </div>
    </div>
  </details>
</div>
# ğŸ§  Proxyless LLM Web-Suchmaschine

Ein Proxy-freies Multi-Suchmaschinen-LLM-Web-Retrieval-Tool, das die Analyse von URL-Inhalten und Web-Crawling unterstÃ¼tzt und mit **LangGraph** und **LangGraph-MCP** modulare Agenten-Ketten realisiert. Speziell fÃ¼r externe Wissensabruf-Szenarien von groÃŸen Sprachmodellen konzipiert, unterstÃ¼tzt **Playwright + Crawl4AI** zur Web-Erfassung und -Analyse sowie asynchrone ParallelitÃ¤t, Inhaltsslicing und Re-Ranking-Filterung.

## ğŸš€ Changelog

- ğŸ”¥ 2025-09-05: UnterstÃ¼tzung fÃ¼r **langgraph-mcp**
- ğŸ”¥ 2025-09-03: Neue Docker-Bereitstellung, integrierter intelligenter Re-Ranker, UnterstÃ¼tzung fÃ¼r benutzerdefinierte Text-Splitter und Re-Ranker

## âœ¨ FunktionsÃ¼bersicht

- ğŸŒ **Kein Proxy erforderlich**: Durch die Playwright-Konfiguration wird die UnterstÃ¼tzung fÃ¼r inlÃ¤ndische Browser ermÃ¶glicht, sodass Netzsuchen auch ohne Proxy durchgefÃ¼hrt werden kÃ¶nnen.
- ğŸ” **UnterstÃ¼tzung mehrerer Suchmaschinen**: UnterstÃ¼tzt Bing, Quark, Baidu, Sogou und andere fÃ¼hrende Suchmaschinen, wodurch die Vielfalt der Informationsquellen erhÃ¶ht wird.
- ğŸ¤– **Intent-Erkennung**: Das System kann anhand der Benutzereingabe automatisch entscheiden, ob eine Websuche oder die Analyse einer URL durchgefÃ¼hrt werden soll.
- ğŸ”„ **Abfragezerlegung**: Basierend auf der Suchabsicht des Nutzers werden Anfragen automatisch in mehrere Teilaufgaben zerlegt und nacheinander ausgefÃ¼hrt, um die Relevanz und Effizienz der Suche zu steigern.
- âš™ï¸ **Agentenarchitektur**: Basierend auf **LangGraph** sind die Agenten**â€web_searchâ€œ** und **â€link_parserâ€œ** gekapselt.
- ğŸƒâ€â™‚ï¸ **Asynchrone und parallele Aufgabenverarbeitung**: UnterstÃ¼tzt die asynchrone und parallele Bearbeitung von Aufgaben und kann mehrere SuchauftrÃ¤ge effizient verarbeiten.
- ğŸ“ **Optimierung der Inhaltsverarbeitung**:

  - âœ‚ï¸ **Inhalts-Slicing**: Lange Webseiteninhalte werden abschnittsweise aufgeteilt.

  - ğŸ”„ **Neuordnung der Inhalte**: Intelligente Umstrukturierung zur Steigerung der Informationsrelevanz.

  - ğŸš« **Inhaltsfilterung**: Automatisches Entfernen irrelevanter oder doppelter Inhalte.
- ğŸŒ **Multi-Plattform-UnterstÃ¼tzung**:
  - ğŸ³ **Docker-Deployment-UnterstÃ¼tzung**: Ein-Klick-Start fÃ¼r den schnellen Aufbau von Backend-Diensten.

  - ğŸ–¥ï¸ FastAPI-Backend-API wird bereitgestellt und kann in beliebige Systeme integriert werden.

  - ğŸŒ Gradio Web UI wird bereitgestellt und kann schnell als Visualisierungsanwendung bereitgestellt werden.

  - ğŸ§©[ **UnterstÃ¼tzung fÃ¼r Browser-Plugins**](https://github.com/itshyao/proxyless-llm-websearch/tree/main/extension): UnterstÃ¼tzt Edge, bietet ein intelligentes URL-Parsing-Plugin, mit dem Webseitenanalyse und Inhaltsextraktion direkt im Browser angefordert werden kÃ¶nnen.


![workflow](https://raw.githubusercontent.com/itshyao/proxyless-llm-websearch/main/img/workflow.png)

![framework](https://raw.githubusercontent.com/itshyao/proxyless-llm-websearch/main/img/framework.png)

## âš¡ Schnellstart

### Repository klonen

```bash
git clone https://github.com/itshyao/proxyless-llm-websearch.git
cd proxyless-llm-websearch
```

### AbhÃ¤ngigkeiten installieren

```
pip install -r requirements.txt
python -m playwright install
```

### Umgebungsvariablenkonfiguration

```
# ç™¾ç‚¼llm
OPENAI_BASE_URL=https://dashscope.aliyuncs.com/compatible-mode/v1
OPENAI_API_KEY=sk-xxx
MODEL_NAME=qwen-plus-latest

# ç™¾ç‚¼embedding
EMBEDDING_BASE_URL=https://dashscope.aliyuncs.com/compatible-mode/v1
EMBEDDING_API_KEY=sk-xxx
EMBEDDING_MODEL_NAME=text-embedding-v4

# ç™¾ç‚¼reranker
RERANK_BASE_URL=https://dashscope.aliyuncs.com/compatible-mode/v1
RERANK_API_KEY=sk-xxx
RERANK_MODEL=gte-rerank-v2
```

### Langgraph-Agent

#### DEMO

```shell
python agent/demo.py
```

#### API-BEREITSTELLUNG

```shell
python agent/api_serve.py
```

```python
import requests

url = "http://localhost:8800/search"

data = {
  "question": "å¹¿å·ä»Šæ—¥å¤©æ°”",
  "engine": "bing",
  "split": {
    "chunk_size": 512,
    "chunk_overlap": 128
  },
  "rerank": {
    "top_k": 5
  }
}

try:
    response = requests.post(
        url,
        json=data
    )

    if response.status_code == 200:
        print("âœ… è¯·æ±‚æˆåŠŸï¼")
        print("å“åº”å†…å®¹ï¼š", response.json())
    else:
        print(f"âŒ è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç ï¼š{response.status_code}")
        print("é”™è¯¯ä¿¡æ¯ï¼š", response.text)

except requests.exceptions.RequestException as e:
    print(f"âš ï¸ è¯·æ±‚å¼‚å¸¸ï¼š{str(e)}")
```

#### Gradio

```
python agent/gradio_demo.py
```

![gradio](https://raw.githubusercontent.com/itshyao/proxyless-llm-websearch/main/img/gradio1.png)

![gradio](https://raw.githubusercontent.com/itshyao/proxyless-llm-websearch/main/img/gradio2.png)

#### docker

```
docker-compose -f docker-compose-ag.yml up -d --build
```

### Langgrph-MCP

#### Starten des MCP-Dienstes

```
python mcp/websearch.py
```

#### DEMO

```
python mcp/demo.py
```

#### API-SERVER

```
python mcp/api_serve.py
```

```
import requests

url = "http://localhost:8800/search"

data = {
  "question": "å¹¿å·ä»Šæ—¥å¤©æ°”"
}

try:
    response = requests.post(
        url,
        json=data
    )

    if response.status_code == 200:
        print("âœ… è¯·æ±‚æˆåŠŸï¼")
        print("å“åº”å†…å®¹ï¼š", response.json())
    else:
        print(f"âŒ è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç ï¼š{response.status_code}")
        print("é”™è¯¯ä¿¡æ¯ï¼š", response.text)

except requests.exceptions.RequestException as e:
    print(f"âš ï¸ è¯·æ±‚å¼‚å¸¸ï¼š{str(e)}")
```

#### Docker

```
docker-compose -f docker-compose-mcp.yml up -d --build
```

### Benutzerdefinierte Module

#### Benutzerdefinierte Blockierung

```
from typing import Optional, List

class YourSplitter:
    def __init__(self, text: str, chunk_size: int = 512, chunk_overlap: int = 128):
        self.text = text
        self.chunk_size = chunk_size
        self.chunk_overlap = chunk_overlap

    def split_text(self, text: Optional[str] = None) -> List:
        # TODO: implement splitting logic
        return ["your chunk"]
```

#### Benutzerdefinierte Neuordnung

```
from typing import List, Union, Tuple

class YourReranker:
    async def get_reranked_documents(
        self,
        query: Union[str, List[str]],
        documents: List[str],
    ) -> Union[
        Tuple[List[str]],
        Tuple[List[int]],
    ]:
        return ["your chunk"], ["chunk index"]
```

## ğŸ” Vergleich mit Online-Netzwerksuche-Tests

Wir haben das Projekt mit einigen fÃ¼hrenden Online-APIs verglichen und seine Leistung bei komplexen Fragestellungen bewertet.

### ğŸ”¥ Datensatz

- Der Datensatz stammt von Ali und ist unter [WebWalkerQA](https://huggingface.co/datasets/callanwu/WebWalkerQA) verÃ¶ffentlicht. Er enthÃ¤lt 680 anspruchsvolle Fragen aus Bereichen wie Bildung, wissenschaftliche Konferenzen, Spiele und mehr.
- Der Datensatz umfasst Fragen in Chinesisch und Englisch.

### ğŸ§‘â€ğŸ« Vergleichsergebnisse

| Suchmaschine/System | âœ… Korrekt | âŒ Falsch | âš ï¸ Teilweise Korrekt |
| ------------------- | ----------| ---------| --------------------|
| **Volcano Ark**     | 5,00%     | 72,21%   | 22,79%              |
| **Bailian**         | 9,85%     | 62,79%   | 27,35%              |
| **Unser**           | 19,85%    | 47,94%   | 32,06%              |
## ğŸ™ Danksagung

Einige Funktionen dieses Projekts profitieren von der UnterstÃ¼tzung und Inspiration folgender Open-Source-Projekte. Wir danken herzlich:

- ğŸ§  [LangGraph](https://github.com/langchain-ai/langgraph): Zum Aufbau modularer Agenten-Frameworks, die den schnellen Aufbau komplexer Agentensysteme ermÃ¶glichen.
- ğŸ•· [Crawl4AI](https://github.com/unclecode/crawl4ai): Leistungsstarkes Webinhalts-Parsing-Tool fÃ¼r effizientes Web-Crawling und Datenauszug.
- ğŸŒ [Playwright](https://github.com/microsoft/playwright): Modernes Browser-Automatisierungstool fÃ¼r plattformÃ¼bergreifendes Web-Crawling und Testautomatisierung.
- ğŸ”Œ [Langchain MCP Adapters](https://github.com/langchain-ai/langchain-mcp-adapters): FÃ¼r die Erstellung von Multi-Chain-Prozessen mit MCP.


---

Tranlated By [Open Ai Tx](https://github.com/OpenAiTx/OpenAiTx) | Last indexed: 2025-09-05

---