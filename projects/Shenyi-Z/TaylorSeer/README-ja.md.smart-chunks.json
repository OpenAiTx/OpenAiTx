[
  {
    "Id": 1,
    "Content": "<div align=center>\n  \n# [ICCV 2025] *TaylorSeer*: From Reusing to Forecasting: Accelerating Diffusion Models with *TaylorSeers*\n\n<p>\n<a href='https://arxiv.org/abs/2503.06923'><img src='https://img.shields.io/badge/Paper-arXiv-red'></a>\n<a href='https://taylorseer.github.io/TaylorSeer/'><img src='https://img.shields.io/badge/Project-Page-blue'></a>\n</p>\n\n</div>\n\n## ğŸ”¥ News\n\n* `2025/06/26` ğŸ’¥ğŸ’¥ TaylorSeer is honored to be accepted by ICCV 2025!\n\n* `2025/05/03` ğŸš€ğŸš€ TaylorSeer for HiDream is released.\n\n* `2025/03/30` ğŸš€ğŸš€ TaylorSeer for Wan2.1 is released.\n\n* `2025/03/30` ğŸš€ğŸš€ The Diffusers inference scripts for TaylorSeers and the xDiT scripts applicable for multi-GPU parallel inference have been officially released.\n\n* `2025/03/10` ğŸš€ğŸš€ Our latest work \"From Reusing to Forecasting: Accelerating Diffusion Models with TaylorSeers\" is released! Codes are available at [TaylorSeer](https://github.com/Shenyi-Z/TaylorSeer)! TaylorSeer supports lossless compression at a rate of 4.99x on FLUX.1-dev (with a latency speedup of 3.53x) and high-quality acceleration at a compression rate of 5.00x on HunyuanVideo (with a latency speedup of 4.65x)! We hope *TaylorSeer* can move the paradigm of feature caching methods from reusing to forecasting.For more details, please refer to our latest research paper.\n* `2025/02/19` ğŸš€ğŸš€ ToCa solution for **FLUX** has been officially released after adjustments, now achieving up to **3.14Ã— lossless acceleration** (in FLOPs)!\n* `2025/01/22` ğŸ’¥ğŸ’¥ ToCa is honored to be accepted by ICLR 2025!\n* `2024/12/29` ğŸš€ğŸš€ We release our work [DuCa](https://arxiv.org/abs/2412.18911) about accelerating diffusion transformers for FREE, which achieves nearly lossless acceleration of **2.50Ã—** on [OpenSora](https://github.com/hpcaitech/Open-Sora)! ğŸ‰ **DuCa also overcomes the limitation of ToCa by fully supporting FlashAttention, enabling broader compatibility and efficiency improvements.**\n* `2024/12/24` ğŸ¤—ğŸ¤— We release an open-sourse repo \"[Awesome-Token-Reduction-for-Model-Compression](https://github.com/xuyang-liu16/Awesome-Token-Reduction-for-Model-Compression)\", which collects recent awesome token reduction papers! Feel free to contribute your suggestions!\n* `2024/12/10` ğŸ’¥ğŸ’¥ Our team's recent work, **SiTo** (https://github.com/EvelynZhang-epiclab/SiTo), has been accepted to **AAAI 2025**. It accelerates diffusion models through adaptive **Token Pruning**.\n* `2024/07/15` ğŸ¤—ğŸ¤— We release an open-sourse repo \"[Awesome-Generation-Acceleration](https://github.com/xuyang-liu16/Awesome-Generation-Acceleration)\", which collects recent awesome generation accleration papers! Feel free to contribute your suggestions!\n\n<details>\n  <summary><strong>Abstract</strong></summary>\n\n  Diffusion Transformers (DiT) have revolutionized high-fidelity image and video synthesis, yet their computational demands remain prohibitive for real-time applications. To solve this problem, feature caching has been proposed to accelerate diffusion models by caching the features in the previous timesteps and then reusing them in the following timesteps. However, at timesteps with significant intervals, the feature similarity in diffusion models decreases substantially, leading to a pronounced increase in errors introduced by feature caching, significantly harming the generation quality. To solve this problem, we propose TaylorSeer, which firstly shows that features of diffusion models at future timesteps can be predicted based on their values at previous timesteps. Based on the fact that features change slowly and continuously across timesteps, TaylorSeer employs a differential method to approximate the higher-order derivatives of features and predict features in future timesteps with Taylor series expansion. Extensive experiments demonstrate its significant effectiveness in both image and video synthesis, especially in high acceleration ratios. For instance, it achieves an almost lossless acceleration of 4.99 $\\times$ on FLUX and 5.00 $\\times$ on HunyuanVideo without additional training. On DiT, it achieves $3.41$ lower FID compared with previous SOTA at $4.53$ $\\times$ acceleration.\n\n</details>\n\n## ğŸ§© Community Contributions\n\nThanks to all the open-source contributors for their strong support! Weâ€™d love to hear from you!\n\n* ComfyUI-TaylorSeer-philipy1219 (FP8 Inference on FLUX, more video models coming): [ComfyUI-TaylorSeer-philipy1219](https://github.com/philipy1219/ComfyUI-TaylorSeer) by [philipy1219](https://github.com/philipy1219).\n\n## ğŸ›  Installation\n",
    "ContentSha": "37uFfQBn0Cp076D5K4hJQxTj573ffMx7qA31hLCBg/4=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "<div align=center>\n  \n# [ICCV 2025] *TaylorSeer*: å†åˆ©ç”¨ã‹ã‚‰äºˆæ¸¬ã¸ï¼š*TaylorSeers*ã«ã‚ˆã‚‹æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã®é«˜é€ŸåŒ–\n\n<p>\n<a href='https://arxiv.org/abs/2503.06923'><img src='https://img.shields.io/badge/Paper-arXiv-red'></a>\n<a href='https://taylorseer.github.io/TaylorSeer/'><img src='https://img.shields.io/badge/Project-Page-blue'></a>\n</p>\n\n</div>\n\n## ğŸ”¥ ãƒ‹ãƒ¥ãƒ¼ã‚¹\n\n* `2025/06/26` ğŸ’¥ğŸ’¥ TaylorSeerãŒICCV 2025ã«æ¡æŠã•ã‚Œã¾ã—ãŸï¼\n\n* `2025/05/03` ğŸš€ğŸš€ HiDreamå‘ã‘TaylorSeerã‚’ãƒªãƒªãƒ¼ã‚¹ã—ã¾ã—ãŸã€‚\n\n* `2025/03/30` ğŸš€ğŸš€ Wan2.1å‘ã‘TaylorSeerã‚’ãƒªãƒªãƒ¼ã‚¹ã—ã¾ã—ãŸã€‚\n\n* `2025/03/30` ğŸš€ğŸš€ TaylorSeersç”¨ã®Diffusersæ¨è«–ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¨ãƒãƒ«ãƒGPUä¸¦åˆ—æ¨è«–ã«å¯¾å¿œã—ãŸxDiTã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’æ­£å¼ã«å…¬é–‹ã—ã¾ã—ãŸã€‚\n\n* `2025/03/10` ğŸš€ğŸš€ æœ€æ–°ç ”ç©¶ã€Œå†åˆ©ç”¨ã‹ã‚‰äºˆæ¸¬ã¸ï¼šTaylorSeersã«ã‚ˆã‚‹æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã®é«˜é€ŸåŒ–ã€ã‚’å…¬é–‹ã—ã¾ã—ãŸï¼ã‚³ãƒ¼ãƒ‰ã¯[TaylorSeer](https://github.com/Shenyi-Z/TaylorSeer)ã§å…¥æ‰‹å¯èƒ½ã§ã™ï¼TaylorSeerã¯FLUX.1-devã§4.99å€ã®ç„¡æå¤±åœ§ç¸®ï¼ˆãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã¯3.53å€é«˜é€ŸåŒ–ï¼‰ã¨HunyuanVideoã§5.00å€ã®é«˜å“è³ªåŠ é€Ÿï¼ˆãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã¯4.65å€é«˜é€ŸåŒ–ï¼‰ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¾ã™ï¼*TaylorSeer*ãŒç‰¹å¾´ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ‰‹æ³•ã®ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã‚’å†åˆ©ç”¨ã‹ã‚‰äºˆæ¸¬ã¸ã¨å‰é€²ã•ã›ã‚‹ã“ã¨ã‚’æœŸå¾…ã—ã¦ã„ã¾ã™ã€‚è©³ç´°ã¯æœ€æ–°è«–æ–‡ã‚’ã”å‚ç…§ãã ã•ã„ã€‚\n* `2025/02/19` ğŸš€ğŸš€ **FLUX**å‘ã‘ToCaã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã‚’èª¿æ•´å¾Œã«æ­£å¼å…¬é–‹ã—ã€æœ€å¤§**3.14Ã—ã®ç„¡æå¤±åŠ é€Ÿ**ï¼ˆFLOPsãƒ™ãƒ¼ã‚¹ï¼‰ã‚’é”æˆã—ã¾ã—ãŸï¼\n* `2025/01/22` ğŸ’¥ğŸ’¥ ToCaãŒICLR 2025ã«æ¡æŠã•ã‚Œã¾ã—ãŸï¼\n* `2024/12/29` ğŸš€ğŸš€ æ‹¡æ•£ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼é«˜é€ŸåŒ–æ‰‹æ³•[DuCa](https://arxiv.org/abs/2412.18911)ã‚’ç„¡å„Ÿå…¬é–‹ã—ã€[OpenSora](https://github.com/hpcaitech/Open-Sora)ä¸Šã§ã»ã¼ç„¡æå¤±ã®2.50å€åŠ é€Ÿã‚’é”æˆã—ã¾ã—ãŸï¼ğŸ‰ **DuCaã¯ToCaã®åˆ¶é™ã‚’å…‹æœã—ã€FlashAttentionã‚’å®Œå…¨ã‚µãƒãƒ¼ãƒˆã™ã‚‹ã“ã¨ã§äº’æ›æ€§ã¨åŠ¹ç‡æ€§ã‚’å‘ä¸Šã•ã›ã¦ã„ã¾ã™ã€‚**\n* `2024/12/24` ğŸ¤—ğŸ¤— æœ€è¿‘ã®å„ªã‚ŒãŸãƒˆãƒ¼ã‚¯ãƒ³å‰Šæ¸›è«–æ–‡ã‚’åé›†ã—ãŸã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒªãƒã‚¸ãƒˆãƒªã€Œ[Awesome-Token-Reduction-for-Model-Compression](https://github.com/xuyang-liu16/Awesome-Token-Reduction-for-Model-Compression)ã€ã‚’å…¬é–‹ã—ã¾ã—ãŸï¼ã”æ„è¦‹ãƒ»ã”ææ¡ˆã‚’æ­“è¿ã—ã¾ã™ï¼\n* `2024/12/10` ğŸ’¥ğŸ’¥ ãƒãƒ¼ãƒ ã®æœ€æ–°ç ”ç©¶ **SiTo** (https://github.com/EvelynZhang-epiclab/SiTo) ãŒ **AAAI 2025** ã«æ¡æŠã•ã‚Œã¾ã—ãŸã€‚é©å¿œçš„ãª**ãƒˆãƒ¼ã‚¯ãƒ³ãƒ—ãƒ«ãƒ¼ãƒ‹ãƒ³ã‚°**ã§æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã‚’é«˜é€ŸåŒ–ã—ã¾ã™ã€‚\n* `2024/07/15` ğŸ¤—ğŸ¤— æœ€è¿‘ã®å„ªã‚ŒãŸç”ŸæˆåŠ é€Ÿè«–æ–‡ã‚’åé›†ã—ãŸã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒªãƒã‚¸ãƒˆãƒªã€Œ[Awesome-Generation-Acceleration](https://github.com/xuyang-liu16/Awesome-Generation-Acceleration)ã€ã‚’å…¬é–‹ã—ã¾ã—ãŸï¼ã”æ„è¦‹ãƒ»ã”ææ¡ˆã‚’æ­“è¿ã—ã¾ã™ï¼\n\n<details>\n  <summary><strong>æ¦‚è¦</strong></summary>\n\n  æ‹¡æ•£ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ï¼ˆDiTï¼‰ã¯é«˜å“è³ªãªç”»åƒãƒ»å‹•ç”»åˆæˆã«é©å‘½ã‚’ã‚‚ãŸã‚‰ã—ã¾ã—ãŸãŒã€ãã®è¨ˆç®—ã‚³ã‚¹ãƒˆã¯ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç”¨é€”ã«ã¯ä¾ç„¶ã¨ã—ã¦é«˜ã™ãã¾ã™ã€‚ã“ã®å•é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã€ç‰¹å¾´ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒææ¡ˆã•ã‚Œã€å‰ã®ã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—ã®ç‰¹å¾´ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—æ¬¡ã®ã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—ã§å†åˆ©ç”¨ã™ã‚‹ã“ã¨ã§æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã‚’é«˜é€ŸåŒ–ã—ã¦ã„ã¾ã™ã€‚ã—ã‹ã—ã€é–“éš”ã®å¤§ããªã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—ã§ã¯æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã®ç‰¹å¾´é¡ä¼¼åº¦ãŒå¤§å¹…ã«ä½ä¸‹ã—ã€ç‰¹å¾´ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ã‚ˆã‚‹èª¤å·®ãŒå¢—å¤§ã—ç”Ÿæˆå“è³ªã‚’è‘—ã—ãæãªã„ã¾ã™ã€‚ã“ã®å•é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã€TaylorSeerã‚’ææ¡ˆã—ã¾ã™ã€‚ã“ã‚Œã¯ã¾ãšæ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã®å°†æ¥ã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—ã®ç‰¹å¾´ãŒå‰ã®ã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—ã®å€¤ã‹ã‚‰äºˆæ¸¬å¯èƒ½ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã™ã€‚ç‰¹å¾´ãŒã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—é–“ã§ã‚†ã£ãã‚Šã‹ã¤é€£ç¶šçš„ã«å¤‰åŒ–ã™ã‚‹äº‹å®Ÿã«åŸºã¥ãã€TaylorSeerã¯å¾®åˆ†æ³•ã‚’ç”¨ã„ã¦ç‰¹å¾´ã®é«˜æ¬¡å°é–¢æ•°ã‚’è¿‘ä¼¼ã—ã€Taylorç´šæ•°å±•é–‹ã§å°†æ¥ã®ç‰¹å¾´ã‚’äºˆæ¸¬ã—ã¾ã™ã€‚åºƒç¯„ãªå®Ÿé¨“ã«ã‚ˆã‚Šç”»åƒãƒ»å‹•ç”»åˆæˆã§ç‰¹ã«é«˜åŠ é€Ÿç‡ã§ã®æœ‰åŠ¹æ€§ãŒç¤ºã•ã‚Œã¦ã„ã¾ã™ã€‚ä¾‹ãˆã°ã€è¿½åŠ å­¦ç¿’ãªã—ã§FLUXä¸Šã§ã»ã¼ç„¡æå¤±ã®4.99å€åŠ é€Ÿã€HunyuanVideoä¸Šã§5.00å€åŠ é€Ÿã‚’é”æˆã—ã¾ã™ã€‚DiTã§ã¯ã€å¾“æ¥ã®SOTAã‚ˆã‚Š$3.41$ä½ã„FIDã‚’$4.53$å€åŠ é€Ÿã§å®Ÿç¾ã—ã¾ã™ã€‚\n\n</details>\n\n## ğŸ§© ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£è²¢çŒ®\n\nå¼·åŠ›ãªã‚µãƒãƒ¼ãƒˆã‚’ã„ãŸã ã„ãŸã™ã¹ã¦ã®ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹è²¢çŒ®è€…ã«æ„Ÿè¬ã—ã¾ã™ï¼ã”æ„è¦‹ã‚‚ãŠå¾…ã¡ã—ã¦ã„ã¾ã™ï¼\n\n* ComfyUI-TaylorSeer-philipy1219ï¼ˆFLUXã§ã®FP8æ¨è«–ã€ä»Šå¾Œå‹•ç”»ãƒ¢ãƒ‡ãƒ«ã‚‚å¯¾å¿œäºˆå®šï¼‰ï¼š[ComfyUI-TaylorSeer-philipy1219](https://github.com/philipy1219/ComfyUI-TaylorSeer) by [philipy1219](https://github.com/philipy1219)ã€‚\n\n## ğŸ›  ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "fagPb+qexaXZ3eHptDc4ivZK9kTnn6hX3OIFMxv7aKA=",
        "originContent": "<div align=center>",
        "translatedContent": "<div align=center>"
      },
      {
        "row": 2,
        "rowsha": "bBefIeb2K2KQVdirQPRU7QLki2hWORNHO4V9NjjiOyg=",
        "originContent": "  ",
        "translatedContent": "  "
      },
      {
        "row": 3,
        "rowsha": "MOtTqT65KO6UuOPpgVNTUNy7DBii0E9VU9QXzmbDlRo=",
        "originContent": "# [ICCV 2025] *TaylorSeer*: From Reusing to Forecasting: Accelerating Diffusion Models with *TaylorSeers*",
        "translatedContent": "# [ICCV 2025] *TaylorSeer*: å†åˆ©ç”¨ã‹ã‚‰äºˆæ¸¬ã¸ï¼š*TaylorSeers*ã«ã‚ˆã‚‹æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã®é«˜é€ŸåŒ–"
      },
      {
        "row": 4,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 5,
        "rowsha": "M/J5lGcXcoeikmB4ChB6yY6mPdYWX2f8wNdHZ9CoIJA=",
        "originContent": "<p>",
        "translatedContent": "<p>"
      },
      {
        "row": 6,
        "rowsha": "mz6OHfHOKolNYRAUj7PcksyTTRde9MDQh/L+SZDoFfo=",
        "originContent": "<a href='https://arxiv.org/abs/2503.06923'><img src='https://img.shields.io/badge/Paper-arXiv-red'></a>",
        "translatedContent": "<a href='https://arxiv.org/abs/2503.06923'><img src='https://img.shields.io/badge/Paper-arXiv-red'></a>"
      },
      {
        "row": 7,
        "rowsha": "s05rwhJ5NOYGsjO9U5kI5HYTz2AEGGz9Fbptc/Pug9c=",
        "originContent": "<a href='https://taylorseer.github.io/TaylorSeer/'><img src='https://img.shields.io/badge/Project-Page-blue'></a>",
        "translatedContent": "<a href='https://taylorseer.github.io/TaylorSeer/'><img src='https://img.shields.io/badge/Project-Page-blue'></a>"
      },
      {
        "row": 8,
        "rowsha": "dSdvPNAZSmR86FDDSF6tkQUCVfI9qmACHOR5tThOetY=",
        "originContent": "</p>",
        "translatedContent": "</p>"
      },
      {
        "row": 9,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 10,
        "rowsha": "qsMmUbEPVnxGG5tPJV1vsfpoWbU2jYvZpRr5IKshzyM=",
        "originContent": "</div>",
        "translatedContent": "</div>"
      },
      {
        "row": 11,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 12,
        "rowsha": "D7bG/VBJXSi2hpB980ek7pr4pjcctcRkfLZHbhVcyVg=",
        "originContent": "## ğŸ”¥ News",
        "translatedContent": "## ğŸ”¥ ãƒ‹ãƒ¥ãƒ¼ã‚¹"
      },
      {
        "row": 13,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 14,
        "rowsha": "4+OZ9EqFu/vmVQzOQg6e3fSByT5AG7kgw0p/8ZZtXvg=",
        "originContent": "* `2025/06/26` ğŸ’¥ğŸ’¥ TaylorSeer is honored to be accepted by ICCV 2025!",
        "translatedContent": "* `2025/06/26` ğŸ’¥ğŸ’¥ TaylorSeerãŒICCV 2025ã«æ¡æŠã•ã‚Œã¾ã—ãŸï¼"
      },
      {
        "row": 15,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 16,
        "rowsha": "nWHnk9X5bw0hFy3WJgq/jX5Go8T0fpLu1GZwDSTAXQ4=",
        "originContent": "* `2025/05/03` ğŸš€ğŸš€ TaylorSeer for HiDream is released.",
        "translatedContent": "* `2025/05/03` ğŸš€ğŸš€ HiDreamå‘ã‘TaylorSeerã‚’ãƒªãƒªãƒ¼ã‚¹ã—ã¾ã—ãŸã€‚"
      },
      {
        "row": 17,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 18,
        "rowsha": "nkoB/ObNg2vVPOSBVJEmU88VVwnAhcgFXCZqkw1bSY0=",
        "originContent": "* `2025/03/30` ğŸš€ğŸš€ TaylorSeer for Wan2.1 is released.",
        "translatedContent": "* `2025/03/30` ğŸš€ğŸš€ Wan2.1å‘ã‘TaylorSeerã‚’ãƒªãƒªãƒ¼ã‚¹ã—ã¾ã—ãŸã€‚"
      },
      {
        "row": 19,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 20,
        "rowsha": "3NpXU50QD+KRAHj2dNcg+rCjixMNdTA/nGF1u6E0oe0=",
        "originContent": "* `2025/03/30` ğŸš€ğŸš€ The Diffusers inference scripts for TaylorSeers and the xDiT scripts applicable for multi-GPU parallel inference have been officially released.",
        "translatedContent": "* `2025/03/30` ğŸš€ğŸš€ TaylorSeersç”¨ã®Diffusersæ¨è«–ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¨ãƒãƒ«ãƒGPUä¸¦åˆ—æ¨è«–ã«å¯¾å¿œã—ãŸxDiTã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’æ­£å¼ã«å…¬é–‹ã—ã¾ã—ãŸã€‚"
      },
      {
        "row": 21,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 22,
        "rowsha": "9NG8DDgu4GTSLg6UyU6J2MUqXFt01vZBE1vkyAWpvuo=",
        "originContent": "* `2025/03/10` ğŸš€ğŸš€ Our latest work \"From Reusing to Forecasting: Accelerating Diffusion Models with TaylorSeers\" is released! Codes are available at [TaylorSeer](https://github.com/Shenyi-Z/TaylorSeer)! TaylorSeer supports lossless compression at a rate of 4.99x on FLUX.1-dev (with a latency speedup of 3.53x) and high-quality acceleration at a compression rate of 5.00x on HunyuanVideo (with a latency speedup of 4.65x)! We hope *TaylorSeer* can move the paradigm of feature caching methods from reusing to forecasting.For more details, please refer to our latest research paper.",
        "translatedContent": "* `2025/03/10` ğŸš€ğŸš€ æœ€æ–°ç ”ç©¶ã€Œå†åˆ©ç”¨ã‹ã‚‰äºˆæ¸¬ã¸ï¼šTaylorSeersã«ã‚ˆã‚‹æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã®é«˜é€ŸåŒ–ã€ã‚’å…¬é–‹ã—ã¾ã—ãŸï¼ã‚³ãƒ¼ãƒ‰ã¯[TaylorSeer](https://github.com/Shenyi-Z/TaylorSeer)ã§å…¥æ‰‹å¯èƒ½ã§ã™ï¼TaylorSeerã¯FLUX.1-devã§4.99å€ã®ç„¡æå¤±åœ§ç¸®ï¼ˆãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã¯3.53å€é«˜é€ŸåŒ–ï¼‰ã¨HunyuanVideoã§5.00å€ã®é«˜å“è³ªåŠ é€Ÿï¼ˆãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã¯4.65å€é«˜é€ŸåŒ–ï¼‰ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¾ã™ï¼*TaylorSeer*ãŒç‰¹å¾´ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ‰‹æ³•ã®ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã‚’å†åˆ©ç”¨ã‹ã‚‰äºˆæ¸¬ã¸ã¨å‰é€²ã•ã›ã‚‹ã“ã¨ã‚’æœŸå¾…ã—ã¦ã„ã¾ã™ã€‚è©³ç´°ã¯æœ€æ–°è«–æ–‡ã‚’ã”å‚ç…§ãã ã•ã„ã€‚"
      },
      {
        "row": 23,
        "rowsha": "HP4JYN9AqV5x9xftKuxud6Lmj5FbX6yZVjvsYTmL3X4=",
        "originContent": "* `2025/02/19` ğŸš€ğŸš€ ToCa solution for **FLUX** has been officially released after adjustments, now achieving up to **3.14Ã— lossless acceleration** (in FLOPs)!",
        "translatedContent": "* `2025/02/19` ğŸš€ğŸš€ **FLUX**å‘ã‘ToCaã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã‚’èª¿æ•´å¾Œã«æ­£å¼å…¬é–‹ã—ã€æœ€å¤§**3.14Ã—ã®ç„¡æå¤±åŠ é€Ÿ**ï¼ˆFLOPsãƒ™ãƒ¼ã‚¹ï¼‰ã‚’é”æˆã—ã¾ã—ãŸï¼"
      },
      {
        "row": 24,
        "rowsha": "OUJy4nRS5cJZhTQ/bIHSb7tR3CPpzmEdfy9FQsPvkKY=",
        "originContent": "* `2025/01/22` ğŸ’¥ğŸ’¥ ToCa is honored to be accepted by ICLR 2025!",
        "translatedContent": "* `2025/01/22` ğŸ’¥ğŸ’¥ ToCaãŒICLR 2025ã«æ¡æŠã•ã‚Œã¾ã—ãŸï¼"
      },
      {
        "row": 25,
        "rowsha": "JP7Uqbgmmu3w73rzXhFcbs+DuZhRhuwWmv0rp0Z8zBQ=",
        "originContent": "* `2024/12/29` ğŸš€ğŸš€ We release our work [DuCa](https://arxiv.org/abs/2412.18911) about accelerating diffusion transformers for FREE, which achieves nearly lossless acceleration of **2.50Ã—** on [OpenSora](https://github.com/hpcaitech/Open-Sora)! ğŸ‰ **DuCa also overcomes the limitation of ToCa by fully supporting FlashAttention, enabling broader compatibility and efficiency improvements.**",
        "translatedContent": "* `2024/12/29` ğŸš€ğŸš€ æ‹¡æ•£ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼é«˜é€ŸåŒ–æ‰‹æ³•[DuCa](https://arxiv.org/abs/2412.18911)ã‚’ç„¡å„Ÿå…¬é–‹ã—ã€[OpenSora](https://github.com/hpcaitech/Open-Sora)ä¸Šã§ã»ã¼ç„¡æå¤±ã®2.50å€åŠ é€Ÿã‚’é”æˆã—ã¾ã—ãŸï¼ğŸ‰ **DuCaã¯ToCaã®åˆ¶é™ã‚’å…‹æœã—ã€FlashAttentionã‚’å®Œå…¨ã‚µãƒãƒ¼ãƒˆã™ã‚‹ã“ã¨ã§äº’æ›æ€§ã¨åŠ¹ç‡æ€§ã‚’å‘ä¸Šã•ã›ã¦ã„ã¾ã™ã€‚**"
      },
      {
        "row": 26,
        "rowsha": "76EiBVgv/EgSTVYsjHggBTygkeo1yu7OIgVRvPD3Ixs=",
        "originContent": "* `2024/12/24` ğŸ¤—ğŸ¤— We release an open-sourse repo \"[Awesome-Token-Reduction-for-Model-Compression](https://github.com/xuyang-liu16/Awesome-Token-Reduction-for-Model-Compression)\", which collects recent awesome token reduction papers! Feel free to contribute your suggestions!",
        "translatedContent": "* `2024/12/24` ğŸ¤—ğŸ¤— æœ€è¿‘ã®å„ªã‚ŒãŸãƒˆãƒ¼ã‚¯ãƒ³å‰Šæ¸›è«–æ–‡ã‚’åé›†ã—ãŸã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒªãƒã‚¸ãƒˆãƒªã€Œ[Awesome-Token-Reduction-for-Model-Compression](https://github.com/xuyang-liu16/Awesome-Token-Reduction-for-Model-Compression)ã€ã‚’å…¬é–‹ã—ã¾ã—ãŸï¼ã”æ„è¦‹ãƒ»ã”ææ¡ˆã‚’æ­“è¿ã—ã¾ã™ï¼"
      },
      {
        "row": 27,
        "rowsha": "/8zh2xS0BXOpvQxdWqtvtS7GCz9dpRDj/KNLKaArh/s=",
        "originContent": "* `2024/12/10` ğŸ’¥ğŸ’¥ Our team's recent work, **SiTo** (https://github.com/EvelynZhang-epiclab/SiTo), has been accepted to **AAAI 2025**. It accelerates diffusion models through adaptive **Token Pruning**.",
        "translatedContent": "* `2024/12/10` ğŸ’¥ğŸ’¥ ãƒãƒ¼ãƒ ã®æœ€æ–°ç ”ç©¶ **SiTo** (https://github.com/EvelynZhang-epiclab/SiTo) ãŒ **AAAI 2025** ã«æ¡æŠã•ã‚Œã¾ã—ãŸã€‚é©å¿œçš„ãª**ãƒˆãƒ¼ã‚¯ãƒ³ãƒ—ãƒ«ãƒ¼ãƒ‹ãƒ³ã‚°**ã§æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã‚’é«˜é€ŸåŒ–ã—ã¾ã™ã€‚"
      },
      {
        "row": 28,
        "rowsha": "O7eC1AedMiPQpbcvrbKc4glnjZa6qtgwQDRRhUGn+1w=",
        "originContent": "* `2024/07/15` ğŸ¤—ğŸ¤— We release an open-sourse repo \"[Awesome-Generation-Acceleration](https://github.com/xuyang-liu16/Awesome-Generation-Acceleration)\", which collects recent awesome generation accleration papers! Feel free to contribute your suggestions!",
        "translatedContent": "* `2024/07/15` ğŸ¤—ğŸ¤— æœ€è¿‘ã®å„ªã‚ŒãŸç”ŸæˆåŠ é€Ÿè«–æ–‡ã‚’åé›†ã—ãŸã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒªãƒã‚¸ãƒˆãƒªã€Œ[Awesome-Generation-Acceleration](https://github.com/xuyang-liu16/Awesome-Generation-Acceleration)ã€ã‚’å…¬é–‹ã—ã¾ã—ãŸï¼ã”æ„è¦‹ãƒ»ã”ææ¡ˆã‚’æ­“è¿ã—ã¾ã™ï¼"
      },
      {
        "row": 29,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 30,
        "rowsha": "U8eO5ZMev1PH3G030/YyNbNyaS1S4k9n5Of/5MkmvMU=",
        "originContent": "<details>",
        "translatedContent": "<details>"
      },
      {
        "row": 31,
        "rowsha": "qLx6Z+0MU0Auz7F41A3Jc4dR+cSkzESO1JVS8/SKcDc=",
        "originContent": "  <summary><strong>Abstract</strong></summary>",
        "translatedContent": "  <summary><strong>æ¦‚è¦</strong></summary>"
      },
      {
        "row": 32,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 33,
        "rowsha": "YIqf7kN0c/54TcKx6d15MTu4MoUYVK2v7TZvknoQpw4=",
        "originContent": "  Diffusion Transformers (DiT) have revolutionized high-fidelity image and video synthesis, yet their computational demands remain prohibitive for real-time applications. To solve this problem, feature caching has been proposed to accelerate diffusion models by caching the features in the previous timesteps and then reusing them in the following timesteps. However, at timesteps with significant intervals, the feature similarity in diffusion models decreases substantially, leading to a pronounced increase in errors introduced by feature caching, significantly harming the generation quality. To solve this problem, we propose TaylorSeer, which firstly shows that features of diffusion models at future timesteps can be predicted based on their values at previous timesteps. Based on the fact that features change slowly and continuously across timesteps, TaylorSeer employs a differential method to approximate the higher-order derivatives of features and predict features in future timesteps with Taylor series expansion. Extensive experiments demonstrate its significant effectiveness in both image and video synthesis, especially in high acceleration ratios. For instance, it achieves an almost lossless acceleration of 4.99 $\\times$ on FLUX and 5.00 $\\times$ on HunyuanVideo without additional training. On DiT, it achieves $3.41$ lower FID compared with previous SOTA at $4.53$ $\\times$ acceleration.",
        "translatedContent": "  æ‹¡æ•£ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ï¼ˆDiTï¼‰ã¯é«˜å“è³ªãªç”»åƒãƒ»å‹•ç”»åˆæˆã«é©å‘½ã‚’ã‚‚ãŸã‚‰ã—ã¾ã—ãŸãŒã€ãã®è¨ˆç®—ã‚³ã‚¹ãƒˆã¯ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç”¨é€”ã«ã¯ä¾ç„¶ã¨ã—ã¦é«˜ã™ãã¾ã™ã€‚ã“ã®å•é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã€ç‰¹å¾´ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒææ¡ˆã•ã‚Œã€å‰ã®ã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—ã®ç‰¹å¾´ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—æ¬¡ã®ã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—ã§å†åˆ©ç”¨ã™ã‚‹ã“ã¨ã§æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã‚’é«˜é€ŸåŒ–ã—ã¦ã„ã¾ã™ã€‚ã—ã‹ã—ã€é–“éš”ã®å¤§ããªã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—ã§ã¯æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã®ç‰¹å¾´é¡ä¼¼åº¦ãŒå¤§å¹…ã«ä½ä¸‹ã—ã€ç‰¹å¾´ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ã‚ˆã‚‹èª¤å·®ãŒå¢—å¤§ã—ç”Ÿæˆå“è³ªã‚’è‘—ã—ãæãªã„ã¾ã™ã€‚ã“ã®å•é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã€TaylorSeerã‚’ææ¡ˆã—ã¾ã™ã€‚ã“ã‚Œã¯ã¾ãšæ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã®å°†æ¥ã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—ã®ç‰¹å¾´ãŒå‰ã®ã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—ã®å€¤ã‹ã‚‰äºˆæ¸¬å¯èƒ½ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã™ã€‚ç‰¹å¾´ãŒã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—é–“ã§ã‚†ã£ãã‚Šã‹ã¤é€£ç¶šçš„ã«å¤‰åŒ–ã™ã‚‹äº‹å®Ÿã«åŸºã¥ãã€TaylorSeerã¯å¾®åˆ†æ³•ã‚’ç”¨ã„ã¦ç‰¹å¾´ã®é«˜æ¬¡å°é–¢æ•°ã‚’è¿‘ä¼¼ã—ã€Taylorç´šæ•°å±•é–‹ã§å°†æ¥ã®ç‰¹å¾´ã‚’äºˆæ¸¬ã—ã¾ã™ã€‚åºƒç¯„ãªå®Ÿé¨“ã«ã‚ˆã‚Šç”»åƒãƒ»å‹•ç”»åˆæˆã§ç‰¹ã«é«˜åŠ é€Ÿç‡ã§ã®æœ‰åŠ¹æ€§ãŒç¤ºã•ã‚Œã¦ã„ã¾ã™ã€‚ä¾‹ãˆã°ã€è¿½åŠ å­¦ç¿’ãªã—ã§FLUXä¸Šã§ã»ã¼ç„¡æå¤±ã®4.99å€åŠ é€Ÿã€HunyuanVideoä¸Šã§5.00å€åŠ é€Ÿã‚’é”æˆã—ã¾ã™ã€‚DiTã§ã¯ã€å¾“æ¥ã®SOTAã‚ˆã‚Š$3.41$ä½ã„FIDã‚’$4.53$å€åŠ é€Ÿã§å®Ÿç¾ã—ã¾ã™ã€‚"
      },
      {
        "row": 34,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 35,
        "rowsha": "iKxEwaqPw8IiEEWQ6czEzAvKi1nrFO/wqlPbG+tChcM=",
        "originContent": "</details>",
        "translatedContent": "</details>"
      },
      {
        "row": 36,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 37,
        "rowsha": "vVMKG86X38wpzVR64MO4O04P+r93zrGe0ew8fB75VJE=",
        "originContent": "## ğŸ§© Community Contributions",
        "translatedContent": "## ğŸ§© ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£è²¢çŒ®"
      },
      {
        "row": 38,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 39,
        "rowsha": "NhqQVhWscK75IALoDKNa+hzMcIiPuhqHLJjuDbSctMA=",
        "originContent": "Thanks to all the open-source contributors for their strong support! Weâ€™d love to hear from you!",
        "translatedContent": "å¼·åŠ›ãªã‚µãƒãƒ¼ãƒˆã‚’ã„ãŸã ã„ãŸã™ã¹ã¦ã®ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹è²¢çŒ®è€…ã«æ„Ÿè¬ã—ã¾ã™ï¼ã”æ„è¦‹ã‚‚ãŠå¾…ã¡ã—ã¦ã„ã¾ã™ï¼"
      },
      {
        "row": 40,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 41,
        "rowsha": "woBL8XbSNmvsJez4Ev755tcLFMQBHiYdzCnwQ4Dm+lo=",
        "originContent": "* ComfyUI-TaylorSeer-philipy1219 (FP8 Inference on FLUX, more video models coming): [ComfyUI-TaylorSeer-philipy1219](https://github.com/philipy1219/ComfyUI-TaylorSeer) by [philipy1219](https://github.com/philipy1219).",
        "translatedContent": "* ComfyUI-TaylorSeer-philipy1219ï¼ˆFLUXã§ã®FP8æ¨è«–ã€ä»Šå¾Œå‹•ç”»ãƒ¢ãƒ‡ãƒ«ã‚‚å¯¾å¿œäºˆå®šï¼‰ï¼š[ComfyUI-TaylorSeer-philipy1219](https://github.com/philipy1219/ComfyUI-TaylorSeer) by [philipy1219](https://github.com/philipy1219)ã€‚"
      },
      {
        "row": 42,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 43,
        "rowsha": "Uib95QyFy+G2xAAPKyoC5mR8MEqKhXKN6jTjMNlQ47w=",
        "originContent": "## ğŸ›  Installation",
        "translatedContent": "## ğŸ›  ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«"
      },
      {
        "row": 44,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 2,
    "Content": "``` cmd\ngit clone https://github.com/Shenyi-Z/TaylorSeer.git\n```",
    "ContentSha": "tuWrp9bDtQRlcwPecUQOIggRbo+xLp0FrvKAqYyhPhI=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "``` cmd\ngit clone https://github.com/Shenyi-Z/TaylorSeer.git\n```",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "m+Ye/ZAlgvAp+ebS8N9WTXZep69SFbfwiK0O7Et0+Ro=",
        "originContent": "``` cmd",
        "translatedContent": "``` cmd"
      },
      {
        "row": 2,
        "rowsha": "cS+FAoCjHksjXqzHsY5NCYms9p+hgMbt55zlSipAEdM=",
        "originContent": "git clone https://github.com/Shenyi-Z/TaylorSeer.git",
        "translatedContent": "git clone https://github.com/Shenyi-Z/TaylorSeer.git"
      },
      {
        "row": 3,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      }
    ],
    "IsCodeBlock": true
  },
  {
    "Id": 3,
    "Content": "\n\n## TaylorSeer-FLUX\n\nTaylorSeer achieved a lossless computational compression of 4.99 $\\times$ and a Latency Speedup of 3.53 $\\times$ on FLUX.1-dev, as measured by [ImageReward](https://github.com/THUDM/ImageReward) for comprehensive quality. To run TaylorSeer-FLUX, see [TaylorSeer-FLUX](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-FLUX.md).\n\nBesides, We have provided examples of inference scripts for the **diffusers version**, as well as multi-GPU parallel **xDiT inference scripts**. You can also conduct tests based on them, located at [TaylorSeers-Diffusers](./TaylorSeers-Diffusers ) and [TaylorSeers-xDiT](./TaylorSeers-xDiT) respectively.\n\n## TaylorSeer-HunyuanVideo\n\nTaylorSeer achieved a computational compression of 5.00 $\\times$ and a remarkable Latency Speedup of 4.65 $\\times$ on HunyuanVideo, as comprehensively measured by the [VBench](https://github.com/Vchitect/VBench) metric. Compared to previous methods, it demonstrated significant improvements in both acceleration efficiency and quality. To run TaylorSeer-HunyuanVideo, see [TaylorSeer-HunyuanVideo](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-HunyuanVideo.md).\n\nIn addition, our scripts also support multi-GPU parallel acceleration implemented by HunyuanVideo using xDiT. In this case, the acceleration effect brought by the cache and the acceleration effect of multi-GPU parallelism are independent of each other and multiply, achieving extremely high acceleration effects.\n\n## TayorSeer-DiT\n\nTaylorSeer achieved a lossless computational compression of 2.77 $\\times$ on the base model DiT, as comprehensively evaluated by metrics such as FID. Its performance across various acceleration ratios significantly surpassed previous methods. For instance, in an extreme scenario with a 4.53 $\\times$ compression ratio, TaylorSeer's FID only increased by 0.33 from the non-accelerated baseline of 2.32, reaching 2.65, while ToCa and DuCa exhibited FID scores above 6.0 under the same conditions. To run TaylorSeer-DiT,see [TaylorSeer-DiT](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-DiT.md).\n\n## TaylorSeer-Wan2.1\n\nWe implemented the TaylorSeer acceleration method on Wan2.1, with support for multi-GPU parallel inference. The installation and inference commands for TaylorSeer-Wan2.1 are fully compatible with those of Wan2.1. To run TaylorSeer-Wan2.1, see [TaylorSeer-Wan2.1](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-Wan2.1.md).\n\n## TaylorSeer-HiDream\n\nThe recently open-sourced image generation model **HiDream**, despite its impressive output quality, faces increasing demands for acceleration due to its longer inference time. We applied **TaylorSeer** to accelerate HiDreamâ€™s inference, achieving a **72% reduction in runtime**. For more details, see [TaylorSeer-HiDream](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-HiDream.md).\n\n## ğŸ‘ Acknowledgements\n\n- Thanks to [DiT](https://github.com/facebookresearch/DiT) for their great work and codebase upon which we build TaylorSeer-DiT.\n- Thanks to [FLUX](https://github.com/black-forest-labs/flux) for their great work and codebase upon which we build TaylorSeer-FLUX.\n- Thanks to [HiDream](https://github.com/HiDream-ai/HiDream-I1) for their great work and codebase upon which we build TaylorSeer-HiDream.\n- Thanks to [HunyuanVideo](https://github.com/Tencent/HunyuanVideo) for their great work and codebase upon which we build TaylorSeer-HunyuanVideo.\n- Thanks to [Wan2.1](https://github.com/Wan-Video/Wan2.1) for their great work and codebase upon which we build TaylorSeer-Wan2.1.\n- Thanks to [ImageReward](https://github.com/THUDM/ImageReward) for Text-to-Image quality evaluation.\n- Thanks to [VBench](https://github.com/Vchitect/VBench) for Text-to-Video quality evaluation.\n\n\n## ğŸ“Œ Citation\n",
    "ContentSha": "j4spOn6j9j6K+1441QrOXQV28NxAb0gvoZxPRt2rZOk=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "## TaylorSeer-FLUX\n\nTaylorSeerã¯FLUX.1-devã«ãŠã„ã¦ã€[ImageReward](https://github.com/THUDM/ImageReward)ã«ã‚ˆã‚‹ç·åˆå“è³ªè©•ä¾¡ã§ã€æå¤±ãªã—ã®è¨ˆç®—åœ§ç¸®ç‡4.99å€ã¨ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã‚¹ãƒ”ãƒ¼ãƒ‰ã‚¢ãƒƒãƒ—3.53å€ã‚’é”æˆã—ã¾ã—ãŸã€‚TaylorSeer-FLUXã®å®Ÿè¡Œæ–¹æ³•ã«ã¤ã„ã¦ã¯ã€[TaylorSeer-FLUX](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-FLUX.md)ã‚’ã”è¦§ãã ã•ã„ã€‚\n\nã¾ãŸã€**diffusersç‰ˆ**ã®æ¨è«–ã‚¹ã‚¯ãƒªãƒ—ãƒˆä¾‹ã‚„ã€ãƒãƒ«ãƒGPUä¸¦åˆ—å¯¾å¿œã®**xDiTæ¨è«–ã‚¹ã‚¯ãƒªãƒ—ãƒˆ**ã‚‚æä¾›ã—ã¦ã„ã¾ã™ã€‚ã“ã‚Œã‚‰ã«åŸºã¥ããƒ†ã‚¹ãƒˆã¯ã€ãã‚Œãã‚Œ[TaylorSeers-Diffusers](./TaylorSeers-Diffusers)ãŠã‚ˆã³[TaylorSeers-xDiT](./TaylorSeers-xDiT)ã§å¯èƒ½ã§ã™ã€‚\n\n## TaylorSeer-HunyuanVideo\n\nTaylorSeerã¯HunyuanVideoã«ãŠã„ã¦ã€[VBench](https://github.com/Vchitect/VBench)ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã§ç·åˆè©•ä¾¡ã•ã‚Œã€è¨ˆç®—åœ§ç¸®ç‡5.00å€ã€å„ªã‚ŒãŸãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã‚¹ãƒ”ãƒ¼ãƒ‰ã‚¢ãƒƒãƒ—4.65å€ã‚’é”æˆã—ã¾ã—ãŸã€‚å¾“æ¥æ‰‹æ³•ã¨æ¯”è¼ƒã—ã€åŠ é€ŸåŠ¹ç‡ã¨å“è³ªã®ä¸¡é¢ã§å¤§å¹…ãªæ”¹å–„ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚TaylorSeer-HunyuanVideoã®å®Ÿè¡Œæ–¹æ³•ã«ã¤ã„ã¦ã¯ã€[TaylorSeer-HunyuanVideo](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-HunyuanVideo.md)ã‚’ã”è¦§ãã ã•ã„ã€‚\n\nã•ã‚‰ã«ã€å½“è©²ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯xDiTã‚’ç”¨ã„ãŸHunyuanVideoã®ãƒãƒ«ãƒGPUä¸¦åˆ—åŠ é€Ÿã‚‚ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™ã€‚ã“ã®å ´åˆã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ã‚ˆã‚‹åŠ é€ŸåŠ¹æœã¨ãƒãƒ«ãƒGPUä¸¦åˆ—ã«ã‚ˆã‚‹åŠ é€ŸåŠ¹æœã¯ç‹¬ç«‹ã‹ã¤ä¹—ç®—çš„ã«ä½œç”¨ã—ã€æ¥µã‚ã¦é«˜ã„åŠ é€ŸåŠ¹æœã‚’é”æˆã—ã¾ã™ã€‚\n\n## TayorSeer-DiT\n\nTaylorSeerã¯ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«DiTã«ãŠã„ã¦ã€FIDãªã©ã®æŒ‡æ¨™ã§ç·åˆè©•ä¾¡ã•ã‚Œã€æå¤±ãªã—ã®è¨ˆç®—åœ§ç¸®ç‡2.77å€ã‚’é”æˆã—ã¾ã—ãŸã€‚æ§˜ã€…ãªåŠ é€Ÿæ¯”ã«ãŠã‘ã‚‹æ€§èƒ½ã¯å¾“æ¥æ‰‹æ³•ã‚’å¤§ããä¸Šå›ã‚Šã¾ã™ã€‚ä¾‹ãˆã°ã€4.53å€ã®æ¥µç«¯ãªåœ§ç¸®æ¯”ã§ã¯ã€TaylorSeerã®FIDã¯éåŠ é€Ÿãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã®2.32ã‹ã‚‰ã‚ãšã‹0.33å¢—ã®2.65ã§ã‚ã‚‹ã®ã«å¯¾ã—ã€ToCaã‚„DuCaã¯åŒæ¡ä»¶ä¸‹ã§6.0ä»¥ä¸Šã®FIDã‚’ç¤ºã—ã¾ã—ãŸã€‚TaylorSeer-DiTã®å®Ÿè¡Œæ–¹æ³•ã«ã¤ã„ã¦ã¯ã€[TaylorSeer-DiT](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-DiT.md)ã‚’ã”è¦§ãã ã•ã„ã€‚\n\n## TaylorSeer-Wan2.1\n\nWan2.1ä¸Šã§TaylorSeeråŠ é€Ÿæ‰‹æ³•ã‚’å®Ÿè£…ã—ã€ãƒãƒ«ãƒGPUä¸¦åˆ—æ¨è«–ã«å¯¾å¿œã—ã¾ã—ãŸã€‚TaylorSeer-Wan2.1ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãŠã‚ˆã³æ¨è«–ã‚³ãƒãƒ³ãƒ‰ã¯Wan2.1ã¨å®Œå…¨äº’æ›ã§ã™ã€‚TaylorSeer-Wan2.1ã®å®Ÿè¡Œæ–¹æ³•ã«ã¤ã„ã¦ã¯ã€[TaylorSeer-Wan2.1](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-Wan2.1.md)ã‚’ã”è¦§ãã ã•ã„ã€‚\n\n## TaylorSeer-HiDream\n\næœ€è¿‘ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹åŒ–ã•ã‚ŒãŸç”»åƒç”Ÿæˆãƒ¢ãƒ‡ãƒ«**HiDream**ã¯ã€ãã®é«˜å“è³ªãªå‡ºåŠ›ã«ã‚‚é–¢ã‚ã‚‰ãšæ¨è«–æ™‚é–“ãŒé•·ãã€åŠ é€Ÿã®ãƒ‹ãƒ¼ã‚ºãŒé«˜ã¾ã£ã¦ã„ã¾ã™ã€‚ãã“ã§**TaylorSeer**ã‚’é©ç”¨ã—ã€HiDreamã®æ¨è«–ã‚’**72ï¼…ã®ãƒ©ãƒ³ã‚¿ã‚¤ãƒ å‰Šæ¸›**ã§åŠ é€Ÿã—ã¾ã—ãŸã€‚è©³ç´°ã¯[TaylorSeer-HiDream](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-HiDream.md)ã‚’ã”è¦§ãã ã•ã„ã€‚\n\n## ğŸ‘ è¬è¾\n\n- TaylorSeer-DiTã®æ§‹ç¯‰ã«ã‚ãŸã‚Šç´ æ™´ã‚‰ã—ã„æˆæœã¨ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã‚’æä¾›ã—ã¦ãã ã•ã£ãŸ[DiT](https://github.com/facebookresearch/DiT)ã«æ„Ÿè¬ã—ã¾ã™ã€‚\n- TaylorSeer-FLUXã®æ§‹ç¯‰ã«ã‚ãŸã‚Šç´ æ™´ã‚‰ã—ã„æˆæœã¨ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã‚’æä¾›ã—ã¦ãã ã•ã£ãŸ[FLUX](https://github.com/black-forest-labs/flux)ã«æ„Ÿè¬ã—ã¾ã™ã€‚\n- TaylorSeer-HiDreamã®æ§‹ç¯‰ã«ã‚ãŸã‚Šç´ æ™´ã‚‰ã—ã„æˆæœã¨ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã‚’æä¾›ã—ã¦ãã ã•ã£ãŸ[HiDream](https://github.com/HiDream-ai/HiDream-I1)ã«æ„Ÿè¬ã—ã¾ã™ã€‚\n- TaylorSeer-HunyuanVideoã®æ§‹ç¯‰ã«ã‚ãŸã‚Šç´ æ™´ã‚‰ã—ã„æˆæœã¨ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã‚’æä¾›ã—ã¦ãã ã•ã£ãŸ[HunyuanVideo](https://github.com/Tencent/HunyuanVideo)ã«æ„Ÿè¬ã—ã¾ã™ã€‚\n- TaylorSeer-Wan2.1ã®æ§‹ç¯‰ã«ã‚ãŸã‚Šç´ æ™´ã‚‰ã—ã„æˆæœã¨ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã‚’æä¾›ã—ã¦ãã ã•ã£ãŸ[Wan2.1](https://github.com/Wan-Video/Wan2.1)ã«æ„Ÿè¬ã—ã¾ã™ã€‚\n- ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ç”»åƒã¸ã®å“è³ªè©•ä¾¡ã«[ImageReward](https://github.com/THUDM/ImageReward)ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚\n- ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰å‹•ç”»ã¸ã®å“è³ªè©•ä¾¡ã«[VBench](https://github.com/Vchitect/VBench)ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚\n\n## ğŸ“Œ å¼•ç”¨æƒ…å ±\n\n\n\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "## TaylorSeer-FLUX"
      },
      {
        "row": 2,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 3,
        "rowsha": "L2TzcgjTuvv3I11CQ/GvH9lYRpj+s4SJYD9K/E2y5xU=",
        "originContent": "## TaylorSeer-FLUX",
        "translatedContent": "TaylorSeerã¯FLUX.1-devã«ãŠã„ã¦ã€[ImageReward](https://github.com/THUDM/ImageReward)ã«ã‚ˆã‚‹ç·åˆå“è³ªè©•ä¾¡ã§ã€æå¤±ãªã—ã®è¨ˆç®—åœ§ç¸®ç‡4.99å€ã¨ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã‚¹ãƒ”ãƒ¼ãƒ‰ã‚¢ãƒƒãƒ—3.53å€ã‚’é”æˆã—ã¾ã—ãŸã€‚TaylorSeer-FLUXã®å®Ÿè¡Œæ–¹æ³•ã«ã¤ã„ã¦ã¯ã€[TaylorSeer-FLUX](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-FLUX.md)ã‚’ã”è¦§ãã ã•ã„ã€‚"
      },
      {
        "row": 4,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 5,
        "rowsha": "chkx6Gc6ouZXsRcw0q01pp6iUgffxNIeRz+rDYu9/8g=",
        "originContent": "TaylorSeer achieved a lossless computational compression of 4.99 $\\times$ and a Latency Speedup of 3.53 $\\times$ on FLUX.1-dev, as measured by [ImageReward](https://github.com/THUDM/ImageReward) for comprehensive quality. To run TaylorSeer-FLUX, see [TaylorSeer-FLUX](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-FLUX.md).",
        "translatedContent": "ã¾ãŸã€**diffusersç‰ˆ**ã®æ¨è«–ã‚¹ã‚¯ãƒªãƒ—ãƒˆä¾‹ã‚„ã€ãƒãƒ«ãƒGPUä¸¦åˆ—å¯¾å¿œã®**xDiTæ¨è«–ã‚¹ã‚¯ãƒªãƒ—ãƒˆ**ã‚‚æä¾›ã—ã¦ã„ã¾ã™ã€‚ã“ã‚Œã‚‰ã«åŸºã¥ããƒ†ã‚¹ãƒˆã¯ã€ãã‚Œãã‚Œ[TaylorSeers-Diffusers](./TaylorSeers-Diffusers)ãŠã‚ˆã³[TaylorSeers-xDiT](./TaylorSeers-xDiT)ã§å¯èƒ½ã§ã™ã€‚"
      },
      {
        "row": 6,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 7,
        "rowsha": "A6kLZqPZQw64dlrFOjpMypZsNMO14xJmlmpv3pw8ezs=",
        "originContent": "Besides, We have provided examples of inference scripts for the **diffusers version**, as well as multi-GPU parallel **xDiT inference scripts**. You can also conduct tests based on them, located at [TaylorSeers-Diffusers](./TaylorSeers-Diffusers ) and [TaylorSeers-xDiT](./TaylorSeers-xDiT) respectively.",
        "translatedContent": "## TaylorSeer-HunyuanVideo"
      },
      {
        "row": 8,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 9,
        "rowsha": "TvDelfZTkkxA47gKZAdSw/WDfVwOxAFEDF0XiTfHVe4=",
        "originContent": "## TaylorSeer-HunyuanVideo",
        "translatedContent": "TaylorSeerã¯HunyuanVideoã«ãŠã„ã¦ã€[VBench](https://github.com/Vchitect/VBench)ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã§ç·åˆè©•ä¾¡ã•ã‚Œã€è¨ˆç®—åœ§ç¸®ç‡5.00å€ã€å„ªã‚ŒãŸãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã‚¹ãƒ”ãƒ¼ãƒ‰ã‚¢ãƒƒãƒ—4.65å€ã‚’é”æˆã—ã¾ã—ãŸã€‚å¾“æ¥æ‰‹æ³•ã¨æ¯”è¼ƒã—ã€åŠ é€ŸåŠ¹ç‡ã¨å“è³ªã®ä¸¡é¢ã§å¤§å¹…ãªæ”¹å–„ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚TaylorSeer-HunyuanVideoã®å®Ÿè¡Œæ–¹æ³•ã«ã¤ã„ã¦ã¯ã€[TaylorSeer-HunyuanVideo](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-HunyuanVideo.md)ã‚’ã”è¦§ãã ã•ã„ã€‚"
      },
      {
        "row": 10,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 11,
        "rowsha": "dvznffegIKSG4P+ItV8gb99Z1QttpWlLRDzlqMddPoI=",
        "originContent": "TaylorSeer achieved a computational compression of 5.00 $\\times$ and a remarkable Latency Speedup of 4.65 $\\times$ on HunyuanVideo, as comprehensively measured by the [VBench](https://github.com/Vchitect/VBench) metric. Compared to previous methods, it demonstrated significant improvements in both acceleration efficiency and quality. To run TaylorSeer-HunyuanVideo, see [TaylorSeer-HunyuanVideo](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-HunyuanVideo.md).",
        "translatedContent": "ã•ã‚‰ã«ã€å½“è©²ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯xDiTã‚’ç”¨ã„ãŸHunyuanVideoã®ãƒãƒ«ãƒGPUä¸¦åˆ—åŠ é€Ÿã‚‚ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™ã€‚ã“ã®å ´åˆã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ã‚ˆã‚‹åŠ é€ŸåŠ¹æœã¨ãƒãƒ«ãƒGPUä¸¦åˆ—ã«ã‚ˆã‚‹åŠ é€ŸåŠ¹æœã¯ç‹¬ç«‹ã‹ã¤ä¹—ç®—çš„ã«ä½œç”¨ã—ã€æ¥µã‚ã¦é«˜ã„åŠ é€ŸåŠ¹æœã‚’é”æˆã—ã¾ã™ã€‚"
      },
      {
        "row": 12,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 13,
        "rowsha": "Z3A/KHyeuxpEPv1W3z2nEo0Q6/Tl7PgTbK61vPvql+4=",
        "originContent": "In addition, our scripts also support multi-GPU parallel acceleration implemented by HunyuanVideo using xDiT. In this case, the acceleration effect brought by the cache and the acceleration effect of multi-GPU parallelism are independent of each other and multiply, achieving extremely high acceleration effects.",
        "translatedContent": "## TayorSeer-DiT"
      },
      {
        "row": 14,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 15,
        "rowsha": "7Y5OqYcgEa7ffvscRZL+2h7W//4Wv8MkKo/KciYC+Is=",
        "originContent": "## TayorSeer-DiT",
        "translatedContent": "TaylorSeerã¯ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«DiTã«ãŠã„ã¦ã€FIDãªã©ã®æŒ‡æ¨™ã§ç·åˆè©•ä¾¡ã•ã‚Œã€æå¤±ãªã—ã®è¨ˆç®—åœ§ç¸®ç‡2.77å€ã‚’é”æˆã—ã¾ã—ãŸã€‚æ§˜ã€…ãªåŠ é€Ÿæ¯”ã«ãŠã‘ã‚‹æ€§èƒ½ã¯å¾“æ¥æ‰‹æ³•ã‚’å¤§ããä¸Šå›ã‚Šã¾ã™ã€‚ä¾‹ãˆã°ã€4.53å€ã®æ¥µç«¯ãªåœ§ç¸®æ¯”ã§ã¯ã€TaylorSeerã®FIDã¯éåŠ é€Ÿãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã®2.32ã‹ã‚‰ã‚ãšã‹0.33å¢—ã®2.65ã§ã‚ã‚‹ã®ã«å¯¾ã—ã€ToCaã‚„DuCaã¯åŒæ¡ä»¶ä¸‹ã§6.0ä»¥ä¸Šã®FIDã‚’ç¤ºã—ã¾ã—ãŸã€‚TaylorSeer-DiTã®å®Ÿè¡Œæ–¹æ³•ã«ã¤ã„ã¦ã¯ã€[TaylorSeer-DiT](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-DiT.md)ã‚’ã”è¦§ãã ã•ã„ã€‚"
      },
      {
        "row": 16,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 17,
        "rowsha": "jKbN9crC/lW32o3a4odXocjXPpUX4BRy6Px6c5/OADI=",
        "originContent": "TaylorSeer achieved a lossless computational compression of 2.77 $\\times$ on the base model DiT, as comprehensively evaluated by metrics such as FID. Its performance across various acceleration ratios significantly surpassed previous methods. For instance, in an extreme scenario with a 4.53 $\\times$ compression ratio, TaylorSeer's FID only increased by 0.33 from the non-accelerated baseline of 2.32, reaching 2.65, while ToCa and DuCa exhibited FID scores above 6.0 under the same conditions. To run TaylorSeer-DiT,see [TaylorSeer-DiT](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-DiT.md).",
        "translatedContent": "## TaylorSeer-Wan2.1"
      },
      {
        "row": 18,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 19,
        "rowsha": "5DYFJIi4H43keQh/zs8HrC/0OvovNgdNRAgI1iPeXz4=",
        "originContent": "## TaylorSeer-Wan2.1",
        "translatedContent": "Wan2.1ä¸Šã§TaylorSeeråŠ é€Ÿæ‰‹æ³•ã‚’å®Ÿè£…ã—ã€ãƒãƒ«ãƒGPUä¸¦åˆ—æ¨è«–ã«å¯¾å¿œã—ã¾ã—ãŸã€‚TaylorSeer-Wan2.1ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãŠã‚ˆã³æ¨è«–ã‚³ãƒãƒ³ãƒ‰ã¯Wan2.1ã¨å®Œå…¨äº’æ›ã§ã™ã€‚TaylorSeer-Wan2.1ã®å®Ÿè¡Œæ–¹æ³•ã«ã¤ã„ã¦ã¯ã€[TaylorSeer-Wan2.1](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-Wan2.1.md)ã‚’ã”è¦§ãã ã•ã„ã€‚"
      },
      {
        "row": 20,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 21,
        "rowsha": "yw71nREC8h91wgq8ShsYXooL5pNuIYSukhKjsfMdofI=",
        "originContent": "We implemented the TaylorSeer acceleration method on Wan2.1, with support for multi-GPU parallel inference. The installation and inference commands for TaylorSeer-Wan2.1 are fully compatible with those of Wan2.1. To run TaylorSeer-Wan2.1, see [TaylorSeer-Wan2.1](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-Wan2.1.md).",
        "translatedContent": "## TaylorSeer-HiDream"
      },
      {
        "row": 22,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 23,
        "rowsha": "S9sampwK6RNX9MCgwJoggioDY+17FhuB/kPyHb5UgxQ=",
        "originContent": "## TaylorSeer-HiDream",
        "translatedContent": "æœ€è¿‘ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹åŒ–ã•ã‚ŒãŸç”»åƒç”Ÿæˆãƒ¢ãƒ‡ãƒ«**HiDream**ã¯ã€ãã®é«˜å“è³ªãªå‡ºåŠ›ã«ã‚‚é–¢ã‚ã‚‰ãšæ¨è«–æ™‚é–“ãŒé•·ãã€åŠ é€Ÿã®ãƒ‹ãƒ¼ã‚ºãŒé«˜ã¾ã£ã¦ã„ã¾ã™ã€‚ãã“ã§**TaylorSeer**ã‚’é©ç”¨ã—ã€HiDreamã®æ¨è«–ã‚’**72ï¼…ã®ãƒ©ãƒ³ã‚¿ã‚¤ãƒ å‰Šæ¸›**ã§åŠ é€Ÿã—ã¾ã—ãŸã€‚è©³ç´°ã¯[TaylorSeer-HiDream](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-HiDream.md)ã‚’ã”è¦§ãã ã•ã„ã€‚"
      },
      {
        "row": 24,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 25,
        "rowsha": "NQ+OZmBUlgODN0R1c2zfq7AZz9G4P4M99o3RBv7xXRk=",
        "originContent": "The recently open-sourced image generation model **HiDream**, despite its impressive output quality, faces increasing demands for acceleration due to its longer inference time. We applied **TaylorSeer** to accelerate HiDreamâ€™s inference, achieving a **72% reduction in runtime**. For more details, see [TaylorSeer-HiDream](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-HiDream.md).",
        "translatedContent": "## ğŸ‘ è¬è¾"
      },
      {
        "row": 26,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 27,
        "rowsha": "u0Hxe1TnAcDLUJOZsTSfCbn/hsIWD27vYpN/fqVX6NY=",
        "originContent": "## ğŸ‘ Acknowledgements",
        "translatedContent": "- TaylorSeer-DiTã®æ§‹ç¯‰ã«ã‚ãŸã‚Šç´ æ™´ã‚‰ã—ã„æˆæœã¨ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã‚’æä¾›ã—ã¦ãã ã•ã£ãŸ[DiT](https://github.com/facebookresearch/DiT)ã«æ„Ÿè¬ã—ã¾ã™ã€‚"
      },
      {
        "row": 28,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "- TaylorSeer-FLUXã®æ§‹ç¯‰ã«ã‚ãŸã‚Šç´ æ™´ã‚‰ã—ã„æˆæœã¨ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã‚’æä¾›ã—ã¦ãã ã•ã£ãŸ[FLUX](https://github.com/black-forest-labs/flux)ã«æ„Ÿè¬ã—ã¾ã™ã€‚"
      },
      {
        "row": 29,
        "rowsha": "CMyznQjDV0UsyA0kRFrsBu46YX9RCtwQPWaz6kDw57w=",
        "originContent": "- Thanks to [DiT](https://github.com/facebookresearch/DiT) for their great work and codebase upon which we build TaylorSeer-DiT.",
        "translatedContent": "- TaylorSeer-HiDreamã®æ§‹ç¯‰ã«ã‚ãŸã‚Šç´ æ™´ã‚‰ã—ã„æˆæœã¨ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã‚’æä¾›ã—ã¦ãã ã•ã£ãŸ[HiDream](https://github.com/HiDream-ai/HiDream-I1)ã«æ„Ÿè¬ã—ã¾ã™ã€‚"
      },
      {
        "row": 30,
        "rowsha": "g/lnC2dBLYng5nlpIMvvux4+WxpFGTfff9SbzUWHVBQ=",
        "originContent": "- Thanks to [FLUX](https://github.com/black-forest-labs/flux) for their great work and codebase upon which we build TaylorSeer-FLUX.",
        "translatedContent": "- TaylorSeer-HunyuanVideoã®æ§‹ç¯‰ã«ã‚ãŸã‚Šç´ æ™´ã‚‰ã—ã„æˆæœã¨ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã‚’æä¾›ã—ã¦ãã ã•ã£ãŸ[HunyuanVideo](https://github.com/Tencent/HunyuanVideo)ã«æ„Ÿè¬ã—ã¾ã™ã€‚"
      },
      {
        "row": 31,
        "rowsha": "yuga1q5FZmOSqw1xc0FAfu7Lu5HXOyeKTvtX/Iw2da0=",
        "originContent": "- Thanks to [HiDream](https://github.com/HiDream-ai/HiDream-I1) for their great work and codebase upon which we build TaylorSeer-HiDream.",
        "translatedContent": "- TaylorSeer-Wan2.1ã®æ§‹ç¯‰ã«ã‚ãŸã‚Šç´ æ™´ã‚‰ã—ã„æˆæœã¨ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã‚’æä¾›ã—ã¦ãã ã•ã£ãŸ[Wan2.1](https://github.com/Wan-Video/Wan2.1)ã«æ„Ÿè¬ã—ã¾ã™ã€‚"
      },
      {
        "row": 32,
        "rowsha": "FVkMzLsD/lLWDhQC+24S3sV+KYWrlNI6VWt9cXL8Wi4=",
        "originContent": "- Thanks to [HunyuanVideo](https://github.com/Tencent/HunyuanVideo) for their great work and codebase upon which we build TaylorSeer-HunyuanVideo.",
        "translatedContent": "- ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ç”»åƒã¸ã®å“è³ªè©•ä¾¡ã«[ImageReward](https://github.com/THUDM/ImageReward)ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚"
      },
      {
        "row": 33,
        "rowsha": "Eyj54ONx3tEFKlo9ycLBA5oO5Nl/y1cGnSKuJJlbEoY=",
        "originContent": "- Thanks to [Wan2.1](https://github.com/Wan-Video/Wan2.1) for their great work and codebase upon which we build TaylorSeer-Wan2.1.",
        "translatedContent": "- ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰å‹•ç”»ã¸ã®å“è³ªè©•ä¾¡ã«[VBench](https://github.com/Vchitect/VBench)ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚"
      },
      {
        "row": 34,
        "rowsha": "GjsWMErOgzFsSLuXdW1YI/Y3mLGiO0y5QoT5y8zAKqQ=",
        "originContent": "- Thanks to [ImageReward](https://github.com/THUDM/ImageReward) for Text-to-Image quality evaluation.",
        "translatedContent": ""
      },
      {
        "row": 35,
        "rowsha": "KlJSWNedKVvQL9mxodUIC4dZ1eBs/4O9za9u2hnJQp8=",
        "originContent": "- Thanks to [VBench](https://github.com/Vchitect/VBench) for Text-to-Video quality evaluation.",
        "translatedContent": "## ğŸ“Œ å¼•ç”¨æƒ…å ±"
      },
      {
        "row": 36,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 37,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 38,
        "rowsha": "A4soJLbZDJ5jsV21yB+YcMlje6BkPWiyME67jma7Kxo=",
        "originContent": "## ğŸ“Œ Citation",
        "translatedContent": ""
      },
      {
        "row": 39,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 4,
    "Content": "```bibtex\n@article{TaylorSeer2025,\n  title={From Reusing to Forecasting: Accelerating Diffusion Models with TaylorSeers},\n  author={Liu, Jiacheng and Zou, Chang and Lyu, Yuanhuiyi and Chen, Junjie and Zhang, Linfeng},\n  journal={arXiv preprint arXiv:2503.06923},\n  year={2025}\n}\n```",
    "ContentSha": "fen2LVp21p8N9q/eae7nT9vcoFlYE3VN97IgBC75x9g=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bibtex\n@article{TaylorSeer2025,\n  title={From Reusing to Forecasting: Accelerating Diffusion Models with TaylorSeers},\n  author={Liu, Jiacheng and Zou, Chang and Lyu, Yuanhuiyi and Chen, Junjie and Zhang, Linfeng},\n  journal={arXiv preprint arXiv:2503.06923},\n  year={2025}\n}\n```",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "o+TmyQ6wneV6/FQB6aUlRSjIGr2/YLJtnz5uxBgsScQ=",
        "originContent": "```bibtex",
        "translatedContent": "```bibtex"
      },
      {
        "row": 2,
        "rowsha": "/ty4Z1XAwebEXbgzwWSaIIwNKg9g4LtzTihn1TP3w/o=",
        "originContent": "@article{TaylorSeer2025,",
        "translatedContent": "@article{TaylorSeer2025,"
      },
      {
        "row": 3,
        "rowsha": "o+GEpfSsb6+HkPZus7oKYmeYIa0sYGPChFIDFE7bKJY=",
        "originContent": "  title={From Reusing to Forecasting: Accelerating Diffusion Models with TaylorSeers},",
        "translatedContent": "  title={From Reusing to Forecasting: Accelerating Diffusion Models with TaylorSeers},"
      },
      {
        "row": 4,
        "rowsha": "9Nti1MS5YJh1jS6YOETdLSqimPafh+aTqXwIUL0aqvY=",
        "originContent": "  author={Liu, Jiacheng and Zou, Chang and Lyu, Yuanhuiyi and Chen, Junjie and Zhang, Linfeng},",
        "translatedContent": "  author={Liu, Jiacheng and Zou, Chang and Lyu, Yuanhuiyi and Chen, Junjie and Zhang, Linfeng},"
      },
      {
        "row": 5,
        "rowsha": "g/zic5erjOtHBZRc431Y3hZJDd8qGKo8zBOAc1c/nmA=",
        "originContent": "  journal={arXiv preprint arXiv:2503.06923},",
        "translatedContent": "  journal={arXiv preprint arXiv:2503.06923},"
      },
      {
        "row": 6,
        "rowsha": "6oyqJVJ20XoZhlyGjaewQyTQsSBBtVAYmqUtTwjLbAg=",
        "originContent": "  year={2025}",
        "translatedContent": "  year={2025}"
      },
      {
        "row": 7,
        "rowsha": "0Qs2qnSlm89KiBhYN/ZYr682Ru/yuxbDko0OkzXpRdI=",
        "originContent": "}",
        "translatedContent": "}"
      },
      {
        "row": 8,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      }
    ],
    "IsCodeBlock": true
  },
  {
    "Id": 5,
    "Content": "\n## :e-mail: Contact\n\nIf you have any questions, please email [`shenyizou@outlook.com`](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/mailto:shenyizou@outlook.com).\n\n",
    "ContentSha": "71xBxPlelSoIdJqUiI+RvDt6idhGFPOYbo/OlJNyPAU=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "\n## :e-mail: ãŠå•ã„åˆã‚ã›\n\nã”è³ªå•ãŒã‚ã‚‹å ´åˆã¯ã€[`shenyizou@outlook.com`](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/mailto:shenyizou@outlook.com)ã¾ã§ãƒ¡ãƒ¼ãƒ«ã§ãŠå•ã„åˆã‚ã›ãã ã•ã„ã€‚\n\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 2,
        "rowsha": "K5bAg1EjOpNN4wve36Z6v3sJb4XtaMFL5UG4PpfakXM=",
        "originContent": "## :e-mail: Contact",
        "translatedContent": "## :e-mail: ãŠå•ã„åˆã‚ã›"
      },
      {
        "row": 3,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 4,
        "rowsha": "+O5l7O4UKOwm22BlC1HWUnYRp176sGuJ1pgHlKEIMY4=",
        "originContent": "If you have any questions, please email [`shenyizou@outlook.com`](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/mailto:shenyizou@outlook.com).",
        "translatedContent": "ã”è³ªå•ãŒã‚ã‚‹å ´åˆã¯ã€[`shenyizou@outlook.com`](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/mailto:shenyizou@outlook.com)ã¾ã§ãƒ¡ãƒ¼ãƒ«ã§ãŠå•ã„åˆã‚ã›ãã ã•ã„ã€‚"
      },
      {
        "row": 5,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 6,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  }
]