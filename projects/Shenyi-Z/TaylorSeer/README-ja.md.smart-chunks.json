[
  {
    "Id": 1,
    "Content": "<div align=center>\n  \n# [ICCV 2025] *TaylorSeer*: From Reusing to Forecasting: Accelerating Diffusion Models with *TaylorSeers*\n\n<p>\n<a href='https://arxiv.org/abs/2503.06923'><img src='https://img.shields.io/badge/Paper-arXiv-red'></a>\n<a href='https://taylorseer.github.io/TaylorSeer/'><img src='https://img.shields.io/badge/Project-Page-blue'></a>\n</p>\n\n</div>\n\n## 🔥 News\n\n* `2025/06/26` 💥💥 TaylorSeer is honored to be accepted by ICCV 2025!\n\n* `2025/05/03` 🚀🚀 TaylorSeer for HiDream is released.\n\n* `2025/03/30` 🚀🚀 TaylorSeer for Wan2.1 is released.\n\n* `2025/03/30` 🚀🚀 The Diffusers inference scripts for TaylorSeers and the xDiT scripts applicable for multi-GPU parallel inference have been officially released.\n\n* `2025/03/10` 🚀🚀 Our latest work \"From Reusing to Forecasting: Accelerating Diffusion Models with TaylorSeers\" is released! Codes are available at [TaylorSeer](https://github.com/Shenyi-Z/TaylorSeer)! TaylorSeer supports lossless compression at a rate of 4.99x on FLUX.1-dev (with a latency speedup of 3.53x) and high-quality acceleration at a compression rate of 5.00x on HunyuanVideo (with a latency speedup of 4.65x)! We hope *TaylorSeer* can move the paradigm of feature caching methods from reusing to forecasting.For more details, please refer to our latest research paper.\n* `2025/02/19` 🚀🚀 ToCa solution for **FLUX** has been officially released after adjustments, now achieving up to **3.14× lossless acceleration** (in FLOPs)!\n* `2025/01/22` 💥💥 ToCa is honored to be accepted by ICLR 2025!\n* `2024/12/29` 🚀🚀 We release our work [DuCa](https://arxiv.org/abs/2412.18911) about accelerating diffusion transformers for FREE, which achieves nearly lossless acceleration of **2.50×** on [OpenSora](https://github.com/hpcaitech/Open-Sora)! 🎉 **DuCa also overcomes the limitation of ToCa by fully supporting FlashAttention, enabling broader compatibility and efficiency improvements.**\n* `2024/12/24` 🤗🤗 We release an open-sourse repo \"[Awesome-Token-Reduction-for-Model-Compression](https://github.com/xuyang-liu16/Awesome-Token-Reduction-for-Model-Compression)\", which collects recent awesome token reduction papers! Feel free to contribute your suggestions!\n* `2024/12/10` 💥💥 Our team's recent work, **SiTo** (https://github.com/EvelynZhang-epiclab/SiTo), has been accepted to **AAAI 2025**. It accelerates diffusion models through adaptive **Token Pruning**.\n* `2024/07/15` 🤗🤗 We release an open-sourse repo \"[Awesome-Generation-Acceleration](https://github.com/xuyang-liu16/Awesome-Generation-Acceleration)\", which collects recent awesome generation accleration papers! Feel free to contribute your suggestions!\n\n<details>\n  <summary><strong>Abstract</strong></summary>\n\n  Diffusion Transformers (DiT) have revolutionized high-fidelity image and video synthesis, yet their computational demands remain prohibitive for real-time applications. To solve this problem, feature caching has been proposed to accelerate diffusion models by caching the features in the previous timesteps and then reusing them in the following timesteps. However, at timesteps with significant intervals, the feature similarity in diffusion models decreases substantially, leading to a pronounced increase in errors introduced by feature caching, significantly harming the generation quality. To solve this problem, we propose TaylorSeer, which firstly shows that features of diffusion models at future timesteps can be predicted based on their values at previous timesteps. Based on the fact that features change slowly and continuously across timesteps, TaylorSeer employs a differential method to approximate the higher-order derivatives of features and predict features in future timesteps with Taylor series expansion. Extensive experiments demonstrate its significant effectiveness in both image and video synthesis, especially in high acceleration ratios. For instance, it achieves an almost lossless acceleration of 4.99 $\\times$ on FLUX and 5.00 $\\times$ on HunyuanVideo without additional training. On DiT, it achieves $3.41$ lower FID compared with previous SOTA at $4.53$ $\\times$ acceleration.\n\n</details>\n\n## 🧩 Community Contributions\n\nThanks to all the open-source contributors for their strong support! We’d love to hear from you!\n\n* ComfyUI-TaylorSeer-philipy1219 (FP8 Inference on FLUX, more video models coming): [ComfyUI-TaylorSeer-philipy1219](https://github.com/philipy1219/ComfyUI-TaylorSeer) by [philipy1219](https://github.com/philipy1219).\n\n## 🛠 Installation\n",
    "ContentSha": "37uFfQBn0Cp076D5K4hJQxTj573ffMx7qA31hLCBg/4=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "<div align=center>\n  \n# [ICCV 2025] *TaylorSeer*: 再利用から予測へ：*TaylorSeers*による拡散モデルの高速化\n\n<p>\n<a href='https://arxiv.org/abs/2503.06923'><img src='https://img.shields.io/badge/Paper-arXiv-red'></a>\n<a href='https://taylorseer.github.io/TaylorSeer/'><img src='https://img.shields.io/badge/Project-Page-blue'></a>\n</p>\n\n</div>\n\n## 🔥 ニュース\n\n* `2025/06/26` 💥💥 TaylorSeerがICCV 2025に採択されました！\n\n* `2025/05/03` 🚀🚀 HiDream向けTaylorSeerをリリースしました。\n\n* `2025/03/30` 🚀🚀 Wan2.1向けTaylorSeerをリリースしました。\n\n* `2025/03/30` 🚀🚀 TaylorSeers用のDiffusers推論スクリプトとマルチGPU並列推論に対応したxDiTスクリプトを正式に公開しました。\n\n* `2025/03/10` 🚀🚀 最新研究「再利用から予測へ：TaylorSeersによる拡散モデルの高速化」を公開しました！コードは[TaylorSeer](https://github.com/Shenyi-Z/TaylorSeer)で入手可能です！TaylorSeerはFLUX.1-devで4.99倍の無損失圧縮（レイテンシは3.53倍高速化）とHunyuanVideoで5.00倍の高品質加速（レイテンシは4.65倍高速化）をサポートします！*TaylorSeer*が特徴キャッシュ手法のパラダイムを再利用から予測へと前進させることを期待しています。詳細は最新論文をご参照ください。\n* `2025/02/19` 🚀🚀 **FLUX**向けToCaソリューションを調整後に正式公開し、最大**3.14×の無損失加速**（FLOPsベース）を達成しました！\n* `2025/01/22` 💥💥 ToCaがICLR 2025に採択されました！\n* `2024/12/29` 🚀🚀 拡散トランスフォーマー高速化手法[DuCa](https://arxiv.org/abs/2412.18911)を無償公開し、[OpenSora](https://github.com/hpcaitech/Open-Sora)上でほぼ無損失の2.50倍加速を達成しました！🎉 **DuCaはToCaの制限を克服し、FlashAttentionを完全サポートすることで互換性と効率性を向上させています。**\n* `2024/12/24` 🤗🤗 最近の優れたトークン削減論文を収集したオープンソースリポジトリ「[Awesome-Token-Reduction-for-Model-Compression](https://github.com/xuyang-liu16/Awesome-Token-Reduction-for-Model-Compression)」を公開しました！ご意見・ご提案を歓迎します！\n* `2024/12/10` 💥💥 チームの最新研究 **SiTo** (https://github.com/EvelynZhang-epiclab/SiTo) が **AAAI 2025** に採択されました。適応的な**トークンプルーニング**で拡散モデルを高速化します。\n* `2024/07/15` 🤗🤗 最近の優れた生成加速論文を収集したオープンソースリポジトリ「[Awesome-Generation-Acceleration](https://github.com/xuyang-liu16/Awesome-Generation-Acceleration)」を公開しました！ご意見・ご提案を歓迎します！\n\n<details>\n  <summary><strong>概要</strong></summary>\n\n  拡散トランスフォーマー（DiT）は高品質な画像・動画合成に革命をもたらしましたが、その計算コストはリアルタイム用途には依然として高すぎます。この問題を解決するため、特徴キャッシュが提案され、前のタイムステップの特徴をキャッシュし次のタイムステップで再利用することで拡散モデルを高速化しています。しかし、間隔の大きなタイムステップでは拡散モデルの特徴類似度が大幅に低下し、特徴キャッシュによる誤差が増大し生成品質を著しく損ないます。この問題を解決するため、TaylorSeerを提案します。これはまず拡散モデルの将来タイムステップの特徴が前のタイムステップの値から予測可能であることを示します。特徴がタイムステップ間でゆっくりかつ連続的に変化する事実に基づき、TaylorSeerは微分法を用いて特徴の高次導関数を近似し、Taylor級数展開で将来の特徴を予測します。広範な実験により画像・動画合成で特に高加速率での有効性が示されています。例えば、追加学習なしでFLUX上でほぼ無損失の4.99倍加速、HunyuanVideo上で5.00倍加速を達成します。DiTでは、従来のSOTAより$3.41$低いFIDを$4.53$倍加速で実現します。\n\n</details>\n\n## 🧩 コミュニティ貢献\n\n強力なサポートをいただいたすべてのオープンソース貢献者に感謝します！ご意見もお待ちしています！\n\n* ComfyUI-TaylorSeer-philipy1219（FLUXでのFP8推論、今後動画モデルも対応予定）：[ComfyUI-TaylorSeer-philipy1219](https://github.com/philipy1219/ComfyUI-TaylorSeer) by [philipy1219](https://github.com/philipy1219)。\n\n## 🛠 インストール\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "fagPb+qexaXZ3eHptDc4ivZK9kTnn6hX3OIFMxv7aKA=",
        "originContent": "<div align=center>",
        "translatedContent": "<div align=center>"
      },
      {
        "row": 2,
        "rowsha": "bBefIeb2K2KQVdirQPRU7QLki2hWORNHO4V9NjjiOyg=",
        "originContent": "  ",
        "translatedContent": "  "
      },
      {
        "row": 3,
        "rowsha": "MOtTqT65KO6UuOPpgVNTUNy7DBii0E9VU9QXzmbDlRo=",
        "originContent": "# [ICCV 2025] *TaylorSeer*: From Reusing to Forecasting: Accelerating Diffusion Models with *TaylorSeers*",
        "translatedContent": "# [ICCV 2025] *TaylorSeer*: 再利用から予測へ：*TaylorSeers*による拡散モデルの高速化"
      },
      {
        "row": 4,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 5,
        "rowsha": "M/J5lGcXcoeikmB4ChB6yY6mPdYWX2f8wNdHZ9CoIJA=",
        "originContent": "<p>",
        "translatedContent": "<p>"
      },
      {
        "row": 6,
        "rowsha": "mz6OHfHOKolNYRAUj7PcksyTTRde9MDQh/L+SZDoFfo=",
        "originContent": "<a href='https://arxiv.org/abs/2503.06923'><img src='https://img.shields.io/badge/Paper-arXiv-red'></a>",
        "translatedContent": "<a href='https://arxiv.org/abs/2503.06923'><img src='https://img.shields.io/badge/Paper-arXiv-red'></a>"
      },
      {
        "row": 7,
        "rowsha": "s05rwhJ5NOYGsjO9U5kI5HYTz2AEGGz9Fbptc/Pug9c=",
        "originContent": "<a href='https://taylorseer.github.io/TaylorSeer/'><img src='https://img.shields.io/badge/Project-Page-blue'></a>",
        "translatedContent": "<a href='https://taylorseer.github.io/TaylorSeer/'><img src='https://img.shields.io/badge/Project-Page-blue'></a>"
      },
      {
        "row": 8,
        "rowsha": "dSdvPNAZSmR86FDDSF6tkQUCVfI9qmACHOR5tThOetY=",
        "originContent": "</p>",
        "translatedContent": "</p>"
      },
      {
        "row": 9,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 10,
        "rowsha": "qsMmUbEPVnxGG5tPJV1vsfpoWbU2jYvZpRr5IKshzyM=",
        "originContent": "</div>",
        "translatedContent": "</div>"
      },
      {
        "row": 11,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 12,
        "rowsha": "D7bG/VBJXSi2hpB980ek7pr4pjcctcRkfLZHbhVcyVg=",
        "originContent": "## 🔥 News",
        "translatedContent": "## 🔥 ニュース"
      },
      {
        "row": 13,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 14,
        "rowsha": "4+OZ9EqFu/vmVQzOQg6e3fSByT5AG7kgw0p/8ZZtXvg=",
        "originContent": "* `2025/06/26` 💥💥 TaylorSeer is honored to be accepted by ICCV 2025!",
        "translatedContent": "* `2025/06/26` 💥💥 TaylorSeerがICCV 2025に採択されました！"
      },
      {
        "row": 15,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 16,
        "rowsha": "nWHnk9X5bw0hFy3WJgq/jX5Go8T0fpLu1GZwDSTAXQ4=",
        "originContent": "* `2025/05/03` 🚀🚀 TaylorSeer for HiDream is released.",
        "translatedContent": "* `2025/05/03` 🚀🚀 HiDream向けTaylorSeerをリリースしました。"
      },
      {
        "row": 17,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 18,
        "rowsha": "nkoB/ObNg2vVPOSBVJEmU88VVwnAhcgFXCZqkw1bSY0=",
        "originContent": "* `2025/03/30` 🚀🚀 TaylorSeer for Wan2.1 is released.",
        "translatedContent": "* `2025/03/30` 🚀🚀 Wan2.1向けTaylorSeerをリリースしました。"
      },
      {
        "row": 19,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 20,
        "rowsha": "3NpXU50QD+KRAHj2dNcg+rCjixMNdTA/nGF1u6E0oe0=",
        "originContent": "* `2025/03/30` 🚀🚀 The Diffusers inference scripts for TaylorSeers and the xDiT scripts applicable for multi-GPU parallel inference have been officially released.",
        "translatedContent": "* `2025/03/30` 🚀🚀 TaylorSeers用のDiffusers推論スクリプトとマルチGPU並列推論に対応したxDiTスクリプトを正式に公開しました。"
      },
      {
        "row": 21,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 22,
        "rowsha": "9NG8DDgu4GTSLg6UyU6J2MUqXFt01vZBE1vkyAWpvuo=",
        "originContent": "* `2025/03/10` 🚀🚀 Our latest work \"From Reusing to Forecasting: Accelerating Diffusion Models with TaylorSeers\" is released! Codes are available at [TaylorSeer](https://github.com/Shenyi-Z/TaylorSeer)! TaylorSeer supports lossless compression at a rate of 4.99x on FLUX.1-dev (with a latency speedup of 3.53x) and high-quality acceleration at a compression rate of 5.00x on HunyuanVideo (with a latency speedup of 4.65x)! We hope *TaylorSeer* can move the paradigm of feature caching methods from reusing to forecasting.For more details, please refer to our latest research paper.",
        "translatedContent": "* `2025/03/10` 🚀🚀 最新研究「再利用から予測へ：TaylorSeersによる拡散モデルの高速化」を公開しました！コードは[TaylorSeer](https://github.com/Shenyi-Z/TaylorSeer)で入手可能です！TaylorSeerはFLUX.1-devで4.99倍の無損失圧縮（レイテンシは3.53倍高速化）とHunyuanVideoで5.00倍の高品質加速（レイテンシは4.65倍高速化）をサポートします！*TaylorSeer*が特徴キャッシュ手法のパラダイムを再利用から予測へと前進させることを期待しています。詳細は最新論文をご参照ください。"
      },
      {
        "row": 23,
        "rowsha": "HP4JYN9AqV5x9xftKuxud6Lmj5FbX6yZVjvsYTmL3X4=",
        "originContent": "* `2025/02/19` 🚀🚀 ToCa solution for **FLUX** has been officially released after adjustments, now achieving up to **3.14× lossless acceleration** (in FLOPs)!",
        "translatedContent": "* `2025/02/19` 🚀🚀 **FLUX**向けToCaソリューションを調整後に正式公開し、最大**3.14×の無損失加速**（FLOPsベース）を達成しました！"
      },
      {
        "row": 24,
        "rowsha": "OUJy4nRS5cJZhTQ/bIHSb7tR3CPpzmEdfy9FQsPvkKY=",
        "originContent": "* `2025/01/22` 💥💥 ToCa is honored to be accepted by ICLR 2025!",
        "translatedContent": "* `2025/01/22` 💥💥 ToCaがICLR 2025に採択されました！"
      },
      {
        "row": 25,
        "rowsha": "JP7Uqbgmmu3w73rzXhFcbs+DuZhRhuwWmv0rp0Z8zBQ=",
        "originContent": "* `2024/12/29` 🚀🚀 We release our work [DuCa](https://arxiv.org/abs/2412.18911) about accelerating diffusion transformers for FREE, which achieves nearly lossless acceleration of **2.50×** on [OpenSora](https://github.com/hpcaitech/Open-Sora)! 🎉 **DuCa also overcomes the limitation of ToCa by fully supporting FlashAttention, enabling broader compatibility and efficiency improvements.**",
        "translatedContent": "* `2024/12/29` 🚀🚀 拡散トランスフォーマー高速化手法[DuCa](https://arxiv.org/abs/2412.18911)を無償公開し、[OpenSora](https://github.com/hpcaitech/Open-Sora)上でほぼ無損失の2.50倍加速を達成しました！🎉 **DuCaはToCaの制限を克服し、FlashAttentionを完全サポートすることで互換性と効率性を向上させています。**"
      },
      {
        "row": 26,
        "rowsha": "76EiBVgv/EgSTVYsjHggBTygkeo1yu7OIgVRvPD3Ixs=",
        "originContent": "* `2024/12/24` 🤗🤗 We release an open-sourse repo \"[Awesome-Token-Reduction-for-Model-Compression](https://github.com/xuyang-liu16/Awesome-Token-Reduction-for-Model-Compression)\", which collects recent awesome token reduction papers! Feel free to contribute your suggestions!",
        "translatedContent": "* `2024/12/24` 🤗🤗 最近の優れたトークン削減論文を収集したオープンソースリポジトリ「[Awesome-Token-Reduction-for-Model-Compression](https://github.com/xuyang-liu16/Awesome-Token-Reduction-for-Model-Compression)」を公開しました！ご意見・ご提案を歓迎します！"
      },
      {
        "row": 27,
        "rowsha": "/8zh2xS0BXOpvQxdWqtvtS7GCz9dpRDj/KNLKaArh/s=",
        "originContent": "* `2024/12/10` 💥💥 Our team's recent work, **SiTo** (https://github.com/EvelynZhang-epiclab/SiTo), has been accepted to **AAAI 2025**. It accelerates diffusion models through adaptive **Token Pruning**.",
        "translatedContent": "* `2024/12/10` 💥💥 チームの最新研究 **SiTo** (https://github.com/EvelynZhang-epiclab/SiTo) が **AAAI 2025** に採択されました。適応的な**トークンプルーニング**で拡散モデルを高速化します。"
      },
      {
        "row": 28,
        "rowsha": "O7eC1AedMiPQpbcvrbKc4glnjZa6qtgwQDRRhUGn+1w=",
        "originContent": "* `2024/07/15` 🤗🤗 We release an open-sourse repo \"[Awesome-Generation-Acceleration](https://github.com/xuyang-liu16/Awesome-Generation-Acceleration)\", which collects recent awesome generation accleration papers! Feel free to contribute your suggestions!",
        "translatedContent": "* `2024/07/15` 🤗🤗 最近の優れた生成加速論文を収集したオープンソースリポジトリ「[Awesome-Generation-Acceleration](https://github.com/xuyang-liu16/Awesome-Generation-Acceleration)」を公開しました！ご意見・ご提案を歓迎します！"
      },
      {
        "row": 29,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 30,
        "rowsha": "U8eO5ZMev1PH3G030/YyNbNyaS1S4k9n5Of/5MkmvMU=",
        "originContent": "<details>",
        "translatedContent": "<details>"
      },
      {
        "row": 31,
        "rowsha": "qLx6Z+0MU0Auz7F41A3Jc4dR+cSkzESO1JVS8/SKcDc=",
        "originContent": "  <summary><strong>Abstract</strong></summary>",
        "translatedContent": "  <summary><strong>概要</strong></summary>"
      },
      {
        "row": 32,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 33,
        "rowsha": "YIqf7kN0c/54TcKx6d15MTu4MoUYVK2v7TZvknoQpw4=",
        "originContent": "  Diffusion Transformers (DiT) have revolutionized high-fidelity image and video synthesis, yet their computational demands remain prohibitive for real-time applications. To solve this problem, feature caching has been proposed to accelerate diffusion models by caching the features in the previous timesteps and then reusing them in the following timesteps. However, at timesteps with significant intervals, the feature similarity in diffusion models decreases substantially, leading to a pronounced increase in errors introduced by feature caching, significantly harming the generation quality. To solve this problem, we propose TaylorSeer, which firstly shows that features of diffusion models at future timesteps can be predicted based on their values at previous timesteps. Based on the fact that features change slowly and continuously across timesteps, TaylorSeer employs a differential method to approximate the higher-order derivatives of features and predict features in future timesteps with Taylor series expansion. Extensive experiments demonstrate its significant effectiveness in both image and video synthesis, especially in high acceleration ratios. For instance, it achieves an almost lossless acceleration of 4.99 $\\times$ on FLUX and 5.00 $\\times$ on HunyuanVideo without additional training. On DiT, it achieves $3.41$ lower FID compared with previous SOTA at $4.53$ $\\times$ acceleration.",
        "translatedContent": "  拡散トランスフォーマー（DiT）は高品質な画像・動画合成に革命をもたらしましたが、その計算コストはリアルタイム用途には依然として高すぎます。この問題を解決するため、特徴キャッシュが提案され、前のタイムステップの特徴をキャッシュし次のタイムステップで再利用することで拡散モデルを高速化しています。しかし、間隔の大きなタイムステップでは拡散モデルの特徴類似度が大幅に低下し、特徴キャッシュによる誤差が増大し生成品質を著しく損ないます。この問題を解決するため、TaylorSeerを提案します。これはまず拡散モデルの将来タイムステップの特徴が前のタイムステップの値から予測可能であることを示します。特徴がタイムステップ間でゆっくりかつ連続的に変化する事実に基づき、TaylorSeerは微分法を用いて特徴の高次導関数を近似し、Taylor級数展開で将来の特徴を予測します。広範な実験により画像・動画合成で特に高加速率での有効性が示されています。例えば、追加学習なしでFLUX上でほぼ無損失の4.99倍加速、HunyuanVideo上で5.00倍加速を達成します。DiTでは、従来のSOTAより$3.41$低いFIDを$4.53$倍加速で実現します。"
      },
      {
        "row": 34,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 35,
        "rowsha": "iKxEwaqPw8IiEEWQ6czEzAvKi1nrFO/wqlPbG+tChcM=",
        "originContent": "</details>",
        "translatedContent": "</details>"
      },
      {
        "row": 36,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 37,
        "rowsha": "vVMKG86X38wpzVR64MO4O04P+r93zrGe0ew8fB75VJE=",
        "originContent": "## 🧩 Community Contributions",
        "translatedContent": "## 🧩 コミュニティ貢献"
      },
      {
        "row": 38,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 39,
        "rowsha": "NhqQVhWscK75IALoDKNa+hzMcIiPuhqHLJjuDbSctMA=",
        "originContent": "Thanks to all the open-source contributors for their strong support! We’d love to hear from you!",
        "translatedContent": "強力なサポートをいただいたすべてのオープンソース貢献者に感謝します！ご意見もお待ちしています！"
      },
      {
        "row": 40,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 41,
        "rowsha": "woBL8XbSNmvsJez4Ev755tcLFMQBHiYdzCnwQ4Dm+lo=",
        "originContent": "* ComfyUI-TaylorSeer-philipy1219 (FP8 Inference on FLUX, more video models coming): [ComfyUI-TaylorSeer-philipy1219](https://github.com/philipy1219/ComfyUI-TaylorSeer) by [philipy1219](https://github.com/philipy1219).",
        "translatedContent": "* ComfyUI-TaylorSeer-philipy1219（FLUXでのFP8推論、今後動画モデルも対応予定）：[ComfyUI-TaylorSeer-philipy1219](https://github.com/philipy1219/ComfyUI-TaylorSeer) by [philipy1219](https://github.com/philipy1219)。"
      },
      {
        "row": 42,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 43,
        "rowsha": "Uib95QyFy+G2xAAPKyoC5mR8MEqKhXKN6jTjMNlQ47w=",
        "originContent": "## 🛠 Installation",
        "translatedContent": "## 🛠 インストール"
      },
      {
        "row": 44,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 2,
    "Content": "``` cmd\ngit clone https://github.com/Shenyi-Z/TaylorSeer.git\n```",
    "ContentSha": "tuWrp9bDtQRlcwPecUQOIggRbo+xLp0FrvKAqYyhPhI=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "``` cmd\ngit clone https://github.com/Shenyi-Z/TaylorSeer.git\n```",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "m+Ye/ZAlgvAp+ebS8N9WTXZep69SFbfwiK0O7Et0+Ro=",
        "originContent": "``` cmd",
        "translatedContent": "``` cmd"
      },
      {
        "row": 2,
        "rowsha": "cS+FAoCjHksjXqzHsY5NCYms9p+hgMbt55zlSipAEdM=",
        "originContent": "git clone https://github.com/Shenyi-Z/TaylorSeer.git",
        "translatedContent": "git clone https://github.com/Shenyi-Z/TaylorSeer.git"
      },
      {
        "row": 3,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      }
    ],
    "IsCodeBlock": true
  },
  {
    "Id": 3,
    "Content": "\n\n## TaylorSeer-FLUX\n\nTaylorSeer achieved a lossless computational compression of 4.99 $\\times$ and a Latency Speedup of 3.53 $\\times$ on FLUX.1-dev, as measured by [ImageReward](https://github.com/THUDM/ImageReward) for comprehensive quality. To run TaylorSeer-FLUX, see [TaylorSeer-FLUX](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-FLUX.md).\n\nBesides, We have provided examples of inference scripts for the **diffusers version**, as well as multi-GPU parallel **xDiT inference scripts**. You can also conduct tests based on them, located at [TaylorSeers-Diffusers](./TaylorSeers-Diffusers ) and [TaylorSeers-xDiT](./TaylorSeers-xDiT) respectively.\n\n## TaylorSeer-HunyuanVideo\n\nTaylorSeer achieved a computational compression of 5.00 $\\times$ and a remarkable Latency Speedup of 4.65 $\\times$ on HunyuanVideo, as comprehensively measured by the [VBench](https://github.com/Vchitect/VBench) metric. Compared to previous methods, it demonstrated significant improvements in both acceleration efficiency and quality. To run TaylorSeer-HunyuanVideo, see [TaylorSeer-HunyuanVideo](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-HunyuanVideo.md).\n\nIn addition, our scripts also support multi-GPU parallel acceleration implemented by HunyuanVideo using xDiT. In this case, the acceleration effect brought by the cache and the acceleration effect of multi-GPU parallelism are independent of each other and multiply, achieving extremely high acceleration effects.\n\n## TayorSeer-DiT\n\nTaylorSeer achieved a lossless computational compression of 2.77 $\\times$ on the base model DiT, as comprehensively evaluated by metrics such as FID. Its performance across various acceleration ratios significantly surpassed previous methods. For instance, in an extreme scenario with a 4.53 $\\times$ compression ratio, TaylorSeer's FID only increased by 0.33 from the non-accelerated baseline of 2.32, reaching 2.65, while ToCa and DuCa exhibited FID scores above 6.0 under the same conditions. To run TaylorSeer-DiT,see [TaylorSeer-DiT](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-DiT.md).\n\n## TaylorSeer-Wan2.1\n\nWe implemented the TaylorSeer acceleration method on Wan2.1, with support for multi-GPU parallel inference. The installation and inference commands for TaylorSeer-Wan2.1 are fully compatible with those of Wan2.1. To run TaylorSeer-Wan2.1, see [TaylorSeer-Wan2.1](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-Wan2.1.md).\n\n## TaylorSeer-HiDream\n\nThe recently open-sourced image generation model **HiDream**, despite its impressive output quality, faces increasing demands for acceleration due to its longer inference time. We applied **TaylorSeer** to accelerate HiDream’s inference, achieving a **72% reduction in runtime**. For more details, see [TaylorSeer-HiDream](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-HiDream.md).\n\n## 👍 Acknowledgements\n\n- Thanks to [DiT](https://github.com/facebookresearch/DiT) for their great work and codebase upon which we build TaylorSeer-DiT.\n- Thanks to [FLUX](https://github.com/black-forest-labs/flux) for their great work and codebase upon which we build TaylorSeer-FLUX.\n- Thanks to [HiDream](https://github.com/HiDream-ai/HiDream-I1) for their great work and codebase upon which we build TaylorSeer-HiDream.\n- Thanks to [HunyuanVideo](https://github.com/Tencent/HunyuanVideo) for their great work and codebase upon which we build TaylorSeer-HunyuanVideo.\n- Thanks to [Wan2.1](https://github.com/Wan-Video/Wan2.1) for their great work and codebase upon which we build TaylorSeer-Wan2.1.\n- Thanks to [ImageReward](https://github.com/THUDM/ImageReward) for Text-to-Image quality evaluation.\n- Thanks to [VBench](https://github.com/Vchitect/VBench) for Text-to-Video quality evaluation.\n\n\n## 📌 Citation\n",
    "ContentSha": "j4spOn6j9j6K+1441QrOXQV28NxAb0gvoZxPRt2rZOk=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "## TaylorSeer-FLUX\n\nTaylorSeerはFLUX.1-devにおいて、[ImageReward](https://github.com/THUDM/ImageReward)による総合品質評価で、損失なしの計算圧縮率4.99倍とレイテンシスピードアップ3.53倍を達成しました。TaylorSeer-FLUXの実行方法については、[TaylorSeer-FLUX](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-FLUX.md)をご覧ください。\n\nまた、**diffusers版**の推論スクリプト例や、マルチGPU並列対応の**xDiT推論スクリプト**も提供しています。これらに基づくテストは、それぞれ[TaylorSeers-Diffusers](./TaylorSeers-Diffusers)および[TaylorSeers-xDiT](./TaylorSeers-xDiT)で可能です。\n\n## TaylorSeer-HunyuanVideo\n\nTaylorSeerはHunyuanVideoにおいて、[VBench](https://github.com/Vchitect/VBench)メトリクスで総合評価され、計算圧縮率5.00倍、優れたレイテンシスピードアップ4.65倍を達成しました。従来手法と比較し、加速効率と品質の両面で大幅な改善を示しています。TaylorSeer-HunyuanVideoの実行方法については、[TaylorSeer-HunyuanVideo](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-HunyuanVideo.md)をご覧ください。\n\nさらに、当該スクリプトはxDiTを用いたHunyuanVideoのマルチGPU並列加速もサポートしています。この場合、キャッシュによる加速効果とマルチGPU並列による加速効果は独立かつ乗算的に作用し、極めて高い加速効果を達成します。\n\n## TayorSeer-DiT\n\nTaylorSeerはベースモデルDiTにおいて、FIDなどの指標で総合評価され、損失なしの計算圧縮率2.77倍を達成しました。様々な加速比における性能は従来手法を大きく上回ります。例えば、4.53倍の極端な圧縮比では、TaylorSeerのFIDは非加速ベースラインの2.32からわずか0.33増の2.65であるのに対し、ToCaやDuCaは同条件下で6.0以上のFIDを示しました。TaylorSeer-DiTの実行方法については、[TaylorSeer-DiT](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-DiT.md)をご覧ください。\n\n## TaylorSeer-Wan2.1\n\nWan2.1上でTaylorSeer加速手法を実装し、マルチGPU並列推論に対応しました。TaylorSeer-Wan2.1のインストールおよび推論コマンドはWan2.1と完全互換です。TaylorSeer-Wan2.1の実行方法については、[TaylorSeer-Wan2.1](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-Wan2.1.md)をご覧ください。\n\n## TaylorSeer-HiDream\n\n最近オープンソース化された画像生成モデル**HiDream**は、その高品質な出力にも関わらず推論時間が長く、加速のニーズが高まっています。そこで**TaylorSeer**を適用し、HiDreamの推論を**72％のランタイム削減**で加速しました。詳細は[TaylorSeer-HiDream](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-HiDream.md)をご覧ください。\n\n## 👍 謝辞\n\n- TaylorSeer-DiTの構築にあたり素晴らしい成果とコードベースを提供してくださった[DiT](https://github.com/facebookresearch/DiT)に感謝します。\n- TaylorSeer-FLUXの構築にあたり素晴らしい成果とコードベースを提供してくださった[FLUX](https://github.com/black-forest-labs/flux)に感謝します。\n- TaylorSeer-HiDreamの構築にあたり素晴らしい成果とコードベースを提供してくださった[HiDream](https://github.com/HiDream-ai/HiDream-I1)に感謝します。\n- TaylorSeer-HunyuanVideoの構築にあたり素晴らしい成果とコードベースを提供してくださった[HunyuanVideo](https://github.com/Tencent/HunyuanVideo)に感謝します。\n- TaylorSeer-Wan2.1の構築にあたり素晴らしい成果とコードベースを提供してくださった[Wan2.1](https://github.com/Wan-Video/Wan2.1)に感謝します。\n- テキストから画像への品質評価に[ImageReward](https://github.com/THUDM/ImageReward)を使用しています。\n- テキストから動画への品質評価に[VBench](https://github.com/Vchitect/VBench)を使用しています。\n\n## 📌 引用情報\n\n\n\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "## TaylorSeer-FLUX"
      },
      {
        "row": 2,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 3,
        "rowsha": "L2TzcgjTuvv3I11CQ/GvH9lYRpj+s4SJYD9K/E2y5xU=",
        "originContent": "## TaylorSeer-FLUX",
        "translatedContent": "TaylorSeerはFLUX.1-devにおいて、[ImageReward](https://github.com/THUDM/ImageReward)による総合品質評価で、損失なしの計算圧縮率4.99倍とレイテンシスピードアップ3.53倍を達成しました。TaylorSeer-FLUXの実行方法については、[TaylorSeer-FLUX](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-FLUX.md)をご覧ください。"
      },
      {
        "row": 4,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 5,
        "rowsha": "chkx6Gc6ouZXsRcw0q01pp6iUgffxNIeRz+rDYu9/8g=",
        "originContent": "TaylorSeer achieved a lossless computational compression of 4.99 $\\times$ and a Latency Speedup of 3.53 $\\times$ on FLUX.1-dev, as measured by [ImageReward](https://github.com/THUDM/ImageReward) for comprehensive quality. To run TaylorSeer-FLUX, see [TaylorSeer-FLUX](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-FLUX.md).",
        "translatedContent": "また、**diffusers版**の推論スクリプト例や、マルチGPU並列対応の**xDiT推論スクリプト**も提供しています。これらに基づくテストは、それぞれ[TaylorSeers-Diffusers](./TaylorSeers-Diffusers)および[TaylorSeers-xDiT](./TaylorSeers-xDiT)で可能です。"
      },
      {
        "row": 6,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 7,
        "rowsha": "A6kLZqPZQw64dlrFOjpMypZsNMO14xJmlmpv3pw8ezs=",
        "originContent": "Besides, We have provided examples of inference scripts for the **diffusers version**, as well as multi-GPU parallel **xDiT inference scripts**. You can also conduct tests based on them, located at [TaylorSeers-Diffusers](./TaylorSeers-Diffusers ) and [TaylorSeers-xDiT](./TaylorSeers-xDiT) respectively.",
        "translatedContent": "## TaylorSeer-HunyuanVideo"
      },
      {
        "row": 8,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 9,
        "rowsha": "TvDelfZTkkxA47gKZAdSw/WDfVwOxAFEDF0XiTfHVe4=",
        "originContent": "## TaylorSeer-HunyuanVideo",
        "translatedContent": "TaylorSeerはHunyuanVideoにおいて、[VBench](https://github.com/Vchitect/VBench)メトリクスで総合評価され、計算圧縮率5.00倍、優れたレイテンシスピードアップ4.65倍を達成しました。従来手法と比較し、加速効率と品質の両面で大幅な改善を示しています。TaylorSeer-HunyuanVideoの実行方法については、[TaylorSeer-HunyuanVideo](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-HunyuanVideo.md)をご覧ください。"
      },
      {
        "row": 10,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 11,
        "rowsha": "dvznffegIKSG4P+ItV8gb99Z1QttpWlLRDzlqMddPoI=",
        "originContent": "TaylorSeer achieved a computational compression of 5.00 $\\times$ and a remarkable Latency Speedup of 4.65 $\\times$ on HunyuanVideo, as comprehensively measured by the [VBench](https://github.com/Vchitect/VBench) metric. Compared to previous methods, it demonstrated significant improvements in both acceleration efficiency and quality. To run TaylorSeer-HunyuanVideo, see [TaylorSeer-HunyuanVideo](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-HunyuanVideo.md).",
        "translatedContent": "さらに、当該スクリプトはxDiTを用いたHunyuanVideoのマルチGPU並列加速もサポートしています。この場合、キャッシュによる加速効果とマルチGPU並列による加速効果は独立かつ乗算的に作用し、極めて高い加速効果を達成します。"
      },
      {
        "row": 12,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 13,
        "rowsha": "Z3A/KHyeuxpEPv1W3z2nEo0Q6/Tl7PgTbK61vPvql+4=",
        "originContent": "In addition, our scripts also support multi-GPU parallel acceleration implemented by HunyuanVideo using xDiT. In this case, the acceleration effect brought by the cache and the acceleration effect of multi-GPU parallelism are independent of each other and multiply, achieving extremely high acceleration effects.",
        "translatedContent": "## TayorSeer-DiT"
      },
      {
        "row": 14,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 15,
        "rowsha": "7Y5OqYcgEa7ffvscRZL+2h7W//4Wv8MkKo/KciYC+Is=",
        "originContent": "## TayorSeer-DiT",
        "translatedContent": "TaylorSeerはベースモデルDiTにおいて、FIDなどの指標で総合評価され、損失なしの計算圧縮率2.77倍を達成しました。様々な加速比における性能は従来手法を大きく上回ります。例えば、4.53倍の極端な圧縮比では、TaylorSeerのFIDは非加速ベースラインの2.32からわずか0.33増の2.65であるのに対し、ToCaやDuCaは同条件下で6.0以上のFIDを示しました。TaylorSeer-DiTの実行方法については、[TaylorSeer-DiT](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-DiT.md)をご覧ください。"
      },
      {
        "row": 16,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 17,
        "rowsha": "jKbN9crC/lW32o3a4odXocjXPpUX4BRy6Px6c5/OADI=",
        "originContent": "TaylorSeer achieved a lossless computational compression of 2.77 $\\times$ on the base model DiT, as comprehensively evaluated by metrics such as FID. Its performance across various acceleration ratios significantly surpassed previous methods. For instance, in an extreme scenario with a 4.53 $\\times$ compression ratio, TaylorSeer's FID only increased by 0.33 from the non-accelerated baseline of 2.32, reaching 2.65, while ToCa and DuCa exhibited FID scores above 6.0 under the same conditions. To run TaylorSeer-DiT,see [TaylorSeer-DiT](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-DiT.md).",
        "translatedContent": "## TaylorSeer-Wan2.1"
      },
      {
        "row": 18,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 19,
        "rowsha": "5DYFJIi4H43keQh/zs8HrC/0OvovNgdNRAgI1iPeXz4=",
        "originContent": "## TaylorSeer-Wan2.1",
        "translatedContent": "Wan2.1上でTaylorSeer加速手法を実装し、マルチGPU並列推論に対応しました。TaylorSeer-Wan2.1のインストールおよび推論コマンドはWan2.1と完全互換です。TaylorSeer-Wan2.1の実行方法については、[TaylorSeer-Wan2.1](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-Wan2.1.md)をご覧ください。"
      },
      {
        "row": 20,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 21,
        "rowsha": "yw71nREC8h91wgq8ShsYXooL5pNuIYSukhKjsfMdofI=",
        "originContent": "We implemented the TaylorSeer acceleration method on Wan2.1, with support for multi-GPU parallel inference. The installation and inference commands for TaylorSeer-Wan2.1 are fully compatible with those of Wan2.1. To run TaylorSeer-Wan2.1, see [TaylorSeer-Wan2.1](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-Wan2.1.md).",
        "translatedContent": "## TaylorSeer-HiDream"
      },
      {
        "row": 22,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 23,
        "rowsha": "S9sampwK6RNX9MCgwJoggioDY+17FhuB/kPyHb5UgxQ=",
        "originContent": "## TaylorSeer-HiDream",
        "translatedContent": "最近オープンソース化された画像生成モデル**HiDream**は、その高品質な出力にも関わらず推論時間が長く、加速のニーズが高まっています。そこで**TaylorSeer**を適用し、HiDreamの推論を**72％のランタイム削減**で加速しました。詳細は[TaylorSeer-HiDream](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-HiDream.md)をご覧ください。"
      },
      {
        "row": 24,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 25,
        "rowsha": "NQ+OZmBUlgODN0R1c2zfq7AZz9G4P4M99o3RBv7xXRk=",
        "originContent": "The recently open-sourced image generation model **HiDream**, despite its impressive output quality, faces increasing demands for acceleration due to its longer inference time. We applied **TaylorSeer** to accelerate HiDream’s inference, achieving a **72% reduction in runtime**. For more details, see [TaylorSeer-HiDream](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-HiDream.md).",
        "translatedContent": "## 👍 謝辞"
      },
      {
        "row": 26,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 27,
        "rowsha": "u0Hxe1TnAcDLUJOZsTSfCbn/hsIWD27vYpN/fqVX6NY=",
        "originContent": "## 👍 Acknowledgements",
        "translatedContent": "- TaylorSeer-DiTの構築にあたり素晴らしい成果とコードベースを提供してくださった[DiT](https://github.com/facebookresearch/DiT)に感謝します。"
      },
      {
        "row": 28,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "- TaylorSeer-FLUXの構築にあたり素晴らしい成果とコードベースを提供してくださった[FLUX](https://github.com/black-forest-labs/flux)に感謝します。"
      },
      {
        "row": 29,
        "rowsha": "CMyznQjDV0UsyA0kRFrsBu46YX9RCtwQPWaz6kDw57w=",
        "originContent": "- Thanks to [DiT](https://github.com/facebookresearch/DiT) for their great work and codebase upon which we build TaylorSeer-DiT.",
        "translatedContent": "- TaylorSeer-HiDreamの構築にあたり素晴らしい成果とコードベースを提供してくださった[HiDream](https://github.com/HiDream-ai/HiDream-I1)に感謝します。"
      },
      {
        "row": 30,
        "rowsha": "g/lnC2dBLYng5nlpIMvvux4+WxpFGTfff9SbzUWHVBQ=",
        "originContent": "- Thanks to [FLUX](https://github.com/black-forest-labs/flux) for their great work and codebase upon which we build TaylorSeer-FLUX.",
        "translatedContent": "- TaylorSeer-HunyuanVideoの構築にあたり素晴らしい成果とコードベースを提供してくださった[HunyuanVideo](https://github.com/Tencent/HunyuanVideo)に感謝します。"
      },
      {
        "row": 31,
        "rowsha": "yuga1q5FZmOSqw1xc0FAfu7Lu5HXOyeKTvtX/Iw2da0=",
        "originContent": "- Thanks to [HiDream](https://github.com/HiDream-ai/HiDream-I1) for their great work and codebase upon which we build TaylorSeer-HiDream.",
        "translatedContent": "- TaylorSeer-Wan2.1の構築にあたり素晴らしい成果とコードベースを提供してくださった[Wan2.1](https://github.com/Wan-Video/Wan2.1)に感謝します。"
      },
      {
        "row": 32,
        "rowsha": "FVkMzLsD/lLWDhQC+24S3sV+KYWrlNI6VWt9cXL8Wi4=",
        "originContent": "- Thanks to [HunyuanVideo](https://github.com/Tencent/HunyuanVideo) for their great work and codebase upon which we build TaylorSeer-HunyuanVideo.",
        "translatedContent": "- テキストから画像への品質評価に[ImageReward](https://github.com/THUDM/ImageReward)を使用しています。"
      },
      {
        "row": 33,
        "rowsha": "Eyj54ONx3tEFKlo9ycLBA5oO5Nl/y1cGnSKuJJlbEoY=",
        "originContent": "- Thanks to [Wan2.1](https://github.com/Wan-Video/Wan2.1) for their great work and codebase upon which we build TaylorSeer-Wan2.1.",
        "translatedContent": "- テキストから動画への品質評価に[VBench](https://github.com/Vchitect/VBench)を使用しています。"
      },
      {
        "row": 34,
        "rowsha": "GjsWMErOgzFsSLuXdW1YI/Y3mLGiO0y5QoT5y8zAKqQ=",
        "originContent": "- Thanks to [ImageReward](https://github.com/THUDM/ImageReward) for Text-to-Image quality evaluation.",
        "translatedContent": ""
      },
      {
        "row": 35,
        "rowsha": "KlJSWNedKVvQL9mxodUIC4dZ1eBs/4O9za9u2hnJQp8=",
        "originContent": "- Thanks to [VBench](https://github.com/Vchitect/VBench) for Text-to-Video quality evaluation.",
        "translatedContent": "## 📌 引用情報"
      },
      {
        "row": 36,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 37,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 38,
        "rowsha": "A4soJLbZDJ5jsV21yB+YcMlje6BkPWiyME67jma7Kxo=",
        "originContent": "## 📌 Citation",
        "translatedContent": ""
      },
      {
        "row": 39,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 4,
    "Content": "```bibtex\n@article{TaylorSeer2025,\n  title={From Reusing to Forecasting: Accelerating Diffusion Models with TaylorSeers},\n  author={Liu, Jiacheng and Zou, Chang and Lyu, Yuanhuiyi and Chen, Junjie and Zhang, Linfeng},\n  journal={arXiv preprint arXiv:2503.06923},\n  year={2025}\n}\n```",
    "ContentSha": "fen2LVp21p8N9q/eae7nT9vcoFlYE3VN97IgBC75x9g=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bibtex\n@article{TaylorSeer2025,\n  title={From Reusing to Forecasting: Accelerating Diffusion Models with TaylorSeers},\n  author={Liu, Jiacheng and Zou, Chang and Lyu, Yuanhuiyi and Chen, Junjie and Zhang, Linfeng},\n  journal={arXiv preprint arXiv:2503.06923},\n  year={2025}\n}\n```",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "o+TmyQ6wneV6/FQB6aUlRSjIGr2/YLJtnz5uxBgsScQ=",
        "originContent": "```bibtex",
        "translatedContent": "```bibtex"
      },
      {
        "row": 2,
        "rowsha": "/ty4Z1XAwebEXbgzwWSaIIwNKg9g4LtzTihn1TP3w/o=",
        "originContent": "@article{TaylorSeer2025,",
        "translatedContent": "@article{TaylorSeer2025,"
      },
      {
        "row": 3,
        "rowsha": "o+GEpfSsb6+HkPZus7oKYmeYIa0sYGPChFIDFE7bKJY=",
        "originContent": "  title={From Reusing to Forecasting: Accelerating Diffusion Models with TaylorSeers},",
        "translatedContent": "  title={From Reusing to Forecasting: Accelerating Diffusion Models with TaylorSeers},"
      },
      {
        "row": 4,
        "rowsha": "9Nti1MS5YJh1jS6YOETdLSqimPafh+aTqXwIUL0aqvY=",
        "originContent": "  author={Liu, Jiacheng and Zou, Chang and Lyu, Yuanhuiyi and Chen, Junjie and Zhang, Linfeng},",
        "translatedContent": "  author={Liu, Jiacheng and Zou, Chang and Lyu, Yuanhuiyi and Chen, Junjie and Zhang, Linfeng},"
      },
      {
        "row": 5,
        "rowsha": "g/zic5erjOtHBZRc431Y3hZJDd8qGKo8zBOAc1c/nmA=",
        "originContent": "  journal={arXiv preprint arXiv:2503.06923},",
        "translatedContent": "  journal={arXiv preprint arXiv:2503.06923},"
      },
      {
        "row": 6,
        "rowsha": "6oyqJVJ20XoZhlyGjaewQyTQsSBBtVAYmqUtTwjLbAg=",
        "originContent": "  year={2025}",
        "translatedContent": "  year={2025}"
      },
      {
        "row": 7,
        "rowsha": "0Qs2qnSlm89KiBhYN/ZYr682Ru/yuxbDko0OkzXpRdI=",
        "originContent": "}",
        "translatedContent": "}"
      },
      {
        "row": 8,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      }
    ],
    "IsCodeBlock": true
  },
  {
    "Id": 5,
    "Content": "\n## :e-mail: Contact\n\nIf you have any questions, please email [`shenyizou@outlook.com`](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/mailto:shenyizou@outlook.com).\n\n",
    "ContentSha": "71xBxPlelSoIdJqUiI+RvDt6idhGFPOYbo/OlJNyPAU=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "\n## :e-mail: お問い合わせ\n\nご質問がある場合は、[`shenyizou@outlook.com`](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/mailto:shenyizou@outlook.com)までメールでお問い合わせください。\n\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 2,
        "rowsha": "K5bAg1EjOpNN4wve36Z6v3sJb4XtaMFL5UG4PpfakXM=",
        "originContent": "## :e-mail: Contact",
        "translatedContent": "## :e-mail: お問い合わせ"
      },
      {
        "row": 3,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 4,
        "rowsha": "+O5l7O4UKOwm22BlC1HWUnYRp176sGuJ1pgHlKEIMY4=",
        "originContent": "If you have any questions, please email [`shenyizou@outlook.com`](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/mailto:shenyizou@outlook.com).",
        "translatedContent": "ご質問がある場合は、[`shenyizou@outlook.com`](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/mailto:shenyizou@outlook.com)までメールでお問い合わせください。"
      },
      {
        "row": 5,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 6,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  }
]