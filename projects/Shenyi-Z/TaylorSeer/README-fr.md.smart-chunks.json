[
  {
    "Id": 1,
    "Content": "<div align=center>\n  \n# [ICCV 2025] *TaylorSeer*: From Reusing to Forecasting: Accelerating Diffusion Models with *TaylorSeers*\n\n<p>\n<a href='https://arxiv.org/abs/2503.06923'><img src='https://img.shields.io/badge/Paper-arXiv-red'></a>\n<a href='https://taylorseer.github.io/TaylorSeer/'><img src='https://img.shields.io/badge/Project-Page-blue'></a>\n</p>\n\n</div>\n\n## üî• News\n\n* `2025/06/26` üí•üí• TaylorSeer is honored to be accepted by ICCV 2025!\n\n* `2025/05/03` üöÄüöÄ TaylorSeer for HiDream is released.\n\n* `2025/03/30` üöÄüöÄ TaylorSeer for Wan2.1 is released.\n\n* `2025/03/30` üöÄüöÄ The Diffusers inference scripts for TaylorSeers and the xDiT scripts applicable for multi-GPU parallel inference have been officially released.\n\n* `2025/03/10` üöÄüöÄ Our latest work \"From Reusing to Forecasting: Accelerating Diffusion Models with TaylorSeers\" is released! Codes are available at [TaylorSeer](https://github.com/Shenyi-Z/TaylorSeer)! TaylorSeer supports lossless compression at a rate of 4.99x on FLUX.1-dev (with a latency speedup of 3.53x) and high-quality acceleration at a compression rate of 5.00x on HunyuanVideo (with a latency speedup of 4.65x)! We hope *TaylorSeer* can move the paradigm of feature caching methods from reusing to forecasting.For more details, please refer to our latest research paper.\n* `2025/02/19` üöÄüöÄ ToCa solution for **FLUX** has been officially released after adjustments, now achieving up to **3.14√ó lossless acceleration** (in FLOPs)!\n* `2025/01/22` üí•üí• ToCa is honored to be accepted by ICLR 2025!\n* `2024/12/29` üöÄüöÄ We release our work [DuCa](https://arxiv.org/abs/2412.18911) about accelerating diffusion transformers for FREE, which achieves nearly lossless acceleration of **2.50√ó** on [OpenSora](https://github.com/hpcaitech/Open-Sora)! üéâ **DuCa also overcomes the limitation of ToCa by fully supporting FlashAttention, enabling broader compatibility and efficiency improvements.**\n* `2024/12/24` ü§óü§ó We release an open-sourse repo \"[Awesome-Token-Reduction-for-Model-Compression](https://github.com/xuyang-liu16/Awesome-Token-Reduction-for-Model-Compression)\", which collects recent awesome token reduction papers! Feel free to contribute your suggestions!\n* `2024/12/10` üí•üí• Our team's recent work, **SiTo** (https://github.com/EvelynZhang-epiclab/SiTo), has been accepted to **AAAI 2025**. It accelerates diffusion models through adaptive **Token Pruning**.\n* `2024/07/15` ü§óü§ó We release an open-sourse repo \"[Awesome-Generation-Acceleration](https://github.com/xuyang-liu16/Awesome-Generation-Acceleration)\", which collects recent awesome generation accleration papers! Feel free to contribute your suggestions!\n\n<details>\n  <summary><strong>Abstract</strong></summary>\n\n  Diffusion Transformers (DiT) have revolutionized high-fidelity image and video synthesis, yet their computational demands remain prohibitive for real-time applications. To solve this problem, feature caching has been proposed to accelerate diffusion models by caching the features in the previous timesteps and then reusing them in the following timesteps. However, at timesteps with significant intervals, the feature similarity in diffusion models decreases substantially, leading to a pronounced increase in errors introduced by feature caching, significantly harming the generation quality. To solve this problem, we propose TaylorSeer, which firstly shows that features of diffusion models at future timesteps can be predicted based on their values at previous timesteps. Based on the fact that features change slowly and continuously across timesteps, TaylorSeer employs a differential method to approximate the higher-order derivatives of features and predict features in future timesteps with Taylor series expansion. Extensive experiments demonstrate its significant effectiveness in both image and video synthesis, especially in high acceleration ratios. For instance, it achieves an almost lossless acceleration of 4.99 $\\times$ on FLUX and 5.00 $\\times$ on HunyuanVideo without additional training. On DiT, it achieves $3.41$ lower FID compared with previous SOTA at $4.53$ $\\times$ acceleration.\n\n</details>\n\n## üß© Community Contributions\n\nThanks to all the open-source contributors for their strong support! We‚Äôd love to hear from you!\n\n* ComfyUI-TaylorSeer-philipy1219 (FP8 Inference on FLUX, more video models coming): [ComfyUI-TaylorSeer-philipy1219](https://github.com/philipy1219/ComfyUI-TaylorSeer) by [philipy1219](https://github.com/philipy1219).\n\n## üõ† Installation\n",
    "ContentSha": "37uFfQBn0Cp076D5K4hJQxTj573ffMx7qA31hLCBg/4=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "<div align=center>\n  \n# [ICCV 2025] *TaylorSeer* : De la r√©utilisation √† la pr√©vision : Acc√©l√©rer les mod√®les de diffusion avec *TaylorSeers*\n\n<p>\n<a href='https://arxiv.org/abs/2503.06923'><img src='https://img.shields.io/badge/Paper-arXiv-red'></a>\n<a href='https://taylorseer.github.io/TaylorSeer/'><img src='https://img.shields.io/badge/Project-Page-blue'></a>\n</p>\n\n</div>\n\n## üî• Actualit√©s\n\n* `2025/06/26` üí•üí• TaylorSeer a l'honneur d'√™tre accept√© par ICCV 2025 !\n\n* `2025/05/03` üöÄüöÄ TaylorSeer pour HiDream est publi√©.\n\n* `2025/03/30` üöÄüöÄ TaylorSeer pour Wan2.1 est publi√©.\n\n* `2025/03/30` üöÄüöÄ Les scripts d'inf√©rence Diffusers pour TaylorSeers et les scripts xDiT applicables √† l'inf√©rence parall√®le multi-GPU ont √©t√© officiellement publi√©s.\n\n* `2025/03/10` üöÄüöÄ Notre dernier travail \"De la r√©utilisation √† la pr√©vision : Acc√©l√©rer les mod√®les de diffusion avec TaylorSeers\" est publi√© ! Les codes sont disponibles sur [TaylorSeer](https://github.com/Shenyi-Z/TaylorSeer) ! TaylorSeer supporte une compression sans perte √† un taux de 4,99x sur FLUX.1-dev (avec une acc√©l√©ration de latence de 3,53x) et une acc√©l√©ration de haute qualit√© √† un taux de compression de 5,00x sur HunyuanVideo (avec une acc√©l√©ration de latence de 4,65x) ! Nous esp√©rons que *TaylorSeer* pourra faire √©voluer le paradigme des m√©thodes de mise en cache des caract√©ristiques de la r√©utilisation √† la pr√©vision. Pour plus de d√©tails, veuillez vous r√©f√©rer √† notre dernier article de recherche.\n* `2025/02/19` üöÄüöÄ La solution ToCa pour **FLUX** a √©t√© officiellement publi√©e apr√®s ajustements, atteignant d√©sormais jusqu'√† **3,14√ó d'acc√©l√©ration sans perte** (en FLOPs) !\n* `2025/01/22` üí•üí• ToCa a l'honneur d'√™tre accept√© par ICLR 2025 !\n* `2024/12/29` üöÄüöÄ Nous publions gratuitement notre travail [DuCa](https://arxiv.org/abs/2412.18911) sur l'acc√©l√©ration des transformateurs de diffusion, qui atteint une acc√©l√©ration quasi sans perte de **2,50√ó** sur [OpenSora](https://github.com/hpcaitech/Open-Sora) ! üéâ **DuCa surmonte √©galement la limitation de ToCa en supportant pleinement FlashAttention, permettant une compatibilit√© et des am√©liorations d'efficacit√© plus larges.**\n* `2024/12/24` ü§óü§ó Nous publions un d√©p√¥t open-source \"[Awesome-Token-Reduction-for-Model-Compression](https://github.com/xuyang-liu16/Awesome-Token-Reduction-for-Model-Compression)\", qui rassemble les r√©cents excellents articles sur la r√©duction de tokens ! N'h√©sitez pas √† contribuer avec vos suggestions !\n* `2024/12/10` üí•üí• Le travail r√©cent de notre √©quipe, **SiTo** (https://github.com/EvelynZhang-epiclab/SiTo), a √©t√© accept√© √† **AAAI 2025**. Il acc√©l√®re les mod√®les de diffusion gr√¢ce √† la **pruning adaptative des tokens**.\n* `2024/07/15` ü§óü§ó Nous publions un d√©p√¥t open-source \"[Awesome-Generation-Acceleration](https://github.com/xuyang-liu16/Awesome-Generation-Acceleration)\", qui rassemble les r√©cents excellents articles sur l'acc√©l√©ration de g√©n√©ration ! N'h√©sitez pas √† contribuer avec vos suggestions !\n\n<details>\n  <summary><strong>R√©sum√©</strong></summary>\n\n  Les Diffusion Transformers (DiT) ont r√©volutionn√© la synth√®se d'images et de vid√©os √† haute fid√©lit√©, mais leurs exigences computationnelles restent prohibitives pour les applications en temps r√©el. Pour r√©soudre ce probl√®me, la mise en cache des caract√©ristiques a √©t√© propos√©e pour acc√©l√©rer les mod√®les de diffusion en mettant en cache les caract√©ristiques des pas de temps pr√©c√©dents puis en les r√©utilisant aux pas de temps suivants. Cependant, aux pas de temps avec des intervalles importants, la similarit√© des caract√©ristiques dans les mod√®les de diffusion diminue consid√©rablement, entra√Ænant une augmentation marqu√©e des erreurs introduites par la mise en cache des caract√©ristiques, ce qui nuit fortement √† la qualit√© de g√©n√©ration. Pour r√©soudre ce probl√®me, nous proposons TaylorSeer, qui montre d'abord que les caract√©ristiques des mod√®les de diffusion aux pas de temps futurs peuvent √™tre pr√©dites √† partir de leurs valeurs aux pas de temps pr√©c√©dents. Bas√© sur le fait que les caract√©ristiques changent lentement et continuellement au fil des pas de temps, TaylorSeer emploie une m√©thode diff√©rentielle pour approximer les d√©riv√©es d'ordre sup√©rieur des caract√©ristiques et pr√©dire les caract√©ristiques aux pas de temps futurs avec une expansion en s√©rie de Taylor. Des exp√©riences approfondies d√©montrent son efficacit√© significative tant en synth√®se d'images que de vid√©os, particuli√®rement pour des taux d'acc√©l√©ration √©lev√©s. Par exemple, il atteint une acc√©l√©ration quasi sans perte de 4,99 $\\times$ sur FLUX et 5,00 $\\times$ sur HunyuanVideo sans entra√Ænement suppl√©mentaire. Sur DiT, il obtient un FID inf√©rieur de $3,41$ compar√© au pr√©c√©dent √©tat de l'art √† une acc√©l√©ration de $4,53$ $\\times$.\n\n</details>\n\n## üß© Contributions de la communaut√©\n\nMerci √† tous les contributeurs open-source pour leur fort soutien ! Nous serions ravis d‚Äôavoir de vos nouvelles !\n\n* ComfyUI-TaylorSeer-philipy1219 (inf√©rence FP8 sur FLUX, plus de mod√®les vid√©o √† venir) : [ComfyUI-TaylorSeer-philipy1219](https://github.com/philipy1219/ComfyUI-TaylorSeer) par [philipy1219](https://github.com/philipy1219).\n\n## üõ† Installation\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "fagPb+qexaXZ3eHptDc4ivZK9kTnn6hX3OIFMxv7aKA=",
        "originContent": "<div align=center>",
        "translatedContent": "<div align=center>"
      },
      {
        "row": 2,
        "rowsha": "bBefIeb2K2KQVdirQPRU7QLki2hWORNHO4V9NjjiOyg=",
        "originContent": "  ",
        "translatedContent": "  "
      },
      {
        "row": 3,
        "rowsha": "MOtTqT65KO6UuOPpgVNTUNy7DBii0E9VU9QXzmbDlRo=",
        "originContent": "# [ICCV 2025] *TaylorSeer*: From Reusing to Forecasting: Accelerating Diffusion Models with *TaylorSeers*",
        "translatedContent": "# [ICCV 2025] *TaylorSeer* : De la r√©utilisation √† la pr√©vision : Acc√©l√©rer les mod√®les de diffusion avec *TaylorSeers*"
      },
      {
        "row": 4,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 5,
        "rowsha": "M/J5lGcXcoeikmB4ChB6yY6mPdYWX2f8wNdHZ9CoIJA=",
        "originContent": "<p>",
        "translatedContent": "<p>"
      },
      {
        "row": 6,
        "rowsha": "mz6OHfHOKolNYRAUj7PcksyTTRde9MDQh/L+SZDoFfo=",
        "originContent": "<a href='https://arxiv.org/abs/2503.06923'><img src='https://img.shields.io/badge/Paper-arXiv-red'></a>",
        "translatedContent": "<a href='https://arxiv.org/abs/2503.06923'><img src='https://img.shields.io/badge/Paper-arXiv-red'></a>"
      },
      {
        "row": 7,
        "rowsha": "s05rwhJ5NOYGsjO9U5kI5HYTz2AEGGz9Fbptc/Pug9c=",
        "originContent": "<a href='https://taylorseer.github.io/TaylorSeer/'><img src='https://img.shields.io/badge/Project-Page-blue'></a>",
        "translatedContent": "<a href='https://taylorseer.github.io/TaylorSeer/'><img src='https://img.shields.io/badge/Project-Page-blue'></a>"
      },
      {
        "row": 8,
        "rowsha": "dSdvPNAZSmR86FDDSF6tkQUCVfI9qmACHOR5tThOetY=",
        "originContent": "</p>",
        "translatedContent": "</p>"
      },
      {
        "row": 9,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 10,
        "rowsha": "qsMmUbEPVnxGG5tPJV1vsfpoWbU2jYvZpRr5IKshzyM=",
        "originContent": "</div>",
        "translatedContent": "</div>"
      },
      {
        "row": 11,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 12,
        "rowsha": "D7bG/VBJXSi2hpB980ek7pr4pjcctcRkfLZHbhVcyVg=",
        "originContent": "## üî• News",
        "translatedContent": "## üî• Actualit√©s"
      },
      {
        "row": 13,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 14,
        "rowsha": "4+OZ9EqFu/vmVQzOQg6e3fSByT5AG7kgw0p/8ZZtXvg=",
        "originContent": "* `2025/06/26` üí•üí• TaylorSeer is honored to be accepted by ICCV 2025!",
        "translatedContent": "* `2025/06/26` üí•üí• TaylorSeer a l'honneur d'√™tre accept√© par ICCV 2025 !"
      },
      {
        "row": 15,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 16,
        "rowsha": "nWHnk9X5bw0hFy3WJgq/jX5Go8T0fpLu1GZwDSTAXQ4=",
        "originContent": "* `2025/05/03` üöÄüöÄ TaylorSeer for HiDream is released.",
        "translatedContent": "* `2025/05/03` üöÄüöÄ TaylorSeer pour HiDream est publi√©."
      },
      {
        "row": 17,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 18,
        "rowsha": "nkoB/ObNg2vVPOSBVJEmU88VVwnAhcgFXCZqkw1bSY0=",
        "originContent": "* `2025/03/30` üöÄüöÄ TaylorSeer for Wan2.1 is released.",
        "translatedContent": "* `2025/03/30` üöÄüöÄ TaylorSeer pour Wan2.1 est publi√©."
      },
      {
        "row": 19,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 20,
        "rowsha": "3NpXU50QD+KRAHj2dNcg+rCjixMNdTA/nGF1u6E0oe0=",
        "originContent": "* `2025/03/30` üöÄüöÄ The Diffusers inference scripts for TaylorSeers and the xDiT scripts applicable for multi-GPU parallel inference have been officially released.",
        "translatedContent": "* `2025/03/30` üöÄüöÄ Les scripts d'inf√©rence Diffusers pour TaylorSeers et les scripts xDiT applicables √† l'inf√©rence parall√®le multi-GPU ont √©t√© officiellement publi√©s."
      },
      {
        "row": 21,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 22,
        "rowsha": "9NG8DDgu4GTSLg6UyU6J2MUqXFt01vZBE1vkyAWpvuo=",
        "originContent": "* `2025/03/10` üöÄüöÄ Our latest work \"From Reusing to Forecasting: Accelerating Diffusion Models with TaylorSeers\" is released! Codes are available at [TaylorSeer](https://github.com/Shenyi-Z/TaylorSeer)! TaylorSeer supports lossless compression at a rate of 4.99x on FLUX.1-dev (with a latency speedup of 3.53x) and high-quality acceleration at a compression rate of 5.00x on HunyuanVideo (with a latency speedup of 4.65x)! We hope *TaylorSeer* can move the paradigm of feature caching methods from reusing to forecasting.For more details, please refer to our latest research paper.",
        "translatedContent": "* `2025/03/10` üöÄüöÄ Notre dernier travail \"De la r√©utilisation √† la pr√©vision : Acc√©l√©rer les mod√®les de diffusion avec TaylorSeers\" est publi√© ! Les codes sont disponibles sur [TaylorSeer](https://github.com/Shenyi-Z/TaylorSeer) ! TaylorSeer supporte une compression sans perte √† un taux de 4,99x sur FLUX.1-dev (avec une acc√©l√©ration de latence de 3,53x) et une acc√©l√©ration de haute qualit√© √† un taux de compression de 5,00x sur HunyuanVideo (avec une acc√©l√©ration de latence de 4,65x) ! Nous esp√©rons que *TaylorSeer* pourra faire √©voluer le paradigme des m√©thodes de mise en cache des caract√©ristiques de la r√©utilisation √† la pr√©vision. Pour plus de d√©tails, veuillez vous r√©f√©rer √† notre dernier article de recherche."
      },
      {
        "row": 23,
        "rowsha": "HP4JYN9AqV5x9xftKuxud6Lmj5FbX6yZVjvsYTmL3X4=",
        "originContent": "* `2025/02/19` üöÄüöÄ ToCa solution for **FLUX** has been officially released after adjustments, now achieving up to **3.14√ó lossless acceleration** (in FLOPs)!",
        "translatedContent": "* `2025/02/19` üöÄüöÄ La solution ToCa pour **FLUX** a √©t√© officiellement publi√©e apr√®s ajustements, atteignant d√©sormais jusqu'√† **3,14√ó d'acc√©l√©ration sans perte** (en FLOPs) !"
      },
      {
        "row": 24,
        "rowsha": "OUJy4nRS5cJZhTQ/bIHSb7tR3CPpzmEdfy9FQsPvkKY=",
        "originContent": "* `2025/01/22` üí•üí• ToCa is honored to be accepted by ICLR 2025!",
        "translatedContent": "* `2025/01/22` üí•üí• ToCa a l'honneur d'√™tre accept√© par ICLR 2025 !"
      },
      {
        "row": 25,
        "rowsha": "JP7Uqbgmmu3w73rzXhFcbs+DuZhRhuwWmv0rp0Z8zBQ=",
        "originContent": "* `2024/12/29` üöÄüöÄ We release our work [DuCa](https://arxiv.org/abs/2412.18911) about accelerating diffusion transformers for FREE, which achieves nearly lossless acceleration of **2.50√ó** on [OpenSora](https://github.com/hpcaitech/Open-Sora)! üéâ **DuCa also overcomes the limitation of ToCa by fully supporting FlashAttention, enabling broader compatibility and efficiency improvements.**",
        "translatedContent": "* `2024/12/29` üöÄüöÄ Nous publions gratuitement notre travail [DuCa](https://arxiv.org/abs/2412.18911) sur l'acc√©l√©ration des transformateurs de diffusion, qui atteint une acc√©l√©ration quasi sans perte de **2,50√ó** sur [OpenSora](https://github.com/hpcaitech/Open-Sora) ! üéâ **DuCa surmonte √©galement la limitation de ToCa en supportant pleinement FlashAttention, permettant une compatibilit√© et des am√©liorations d'efficacit√© plus larges.**"
      },
      {
        "row": 26,
        "rowsha": "76EiBVgv/EgSTVYsjHggBTygkeo1yu7OIgVRvPD3Ixs=",
        "originContent": "* `2024/12/24` ü§óü§ó We release an open-sourse repo \"[Awesome-Token-Reduction-for-Model-Compression](https://github.com/xuyang-liu16/Awesome-Token-Reduction-for-Model-Compression)\", which collects recent awesome token reduction papers! Feel free to contribute your suggestions!",
        "translatedContent": "* `2024/12/24` ü§óü§ó Nous publions un d√©p√¥t open-source \"[Awesome-Token-Reduction-for-Model-Compression](https://github.com/xuyang-liu16/Awesome-Token-Reduction-for-Model-Compression)\", qui rassemble les r√©cents excellents articles sur la r√©duction de tokens ! N'h√©sitez pas √† contribuer avec vos suggestions !"
      },
      {
        "row": 27,
        "rowsha": "/8zh2xS0BXOpvQxdWqtvtS7GCz9dpRDj/KNLKaArh/s=",
        "originContent": "* `2024/12/10` üí•üí• Our team's recent work, **SiTo** (https://github.com/EvelynZhang-epiclab/SiTo), has been accepted to **AAAI 2025**. It accelerates diffusion models through adaptive **Token Pruning**.",
        "translatedContent": "* `2024/12/10` üí•üí• Le travail r√©cent de notre √©quipe, **SiTo** (https://github.com/EvelynZhang-epiclab/SiTo), a √©t√© accept√© √† **AAAI 2025**. Il acc√©l√®re les mod√®les de diffusion gr√¢ce √† la **pruning adaptative des tokens**."
      },
      {
        "row": 28,
        "rowsha": "O7eC1AedMiPQpbcvrbKc4glnjZa6qtgwQDRRhUGn+1w=",
        "originContent": "* `2024/07/15` ü§óü§ó We release an open-sourse repo \"[Awesome-Generation-Acceleration](https://github.com/xuyang-liu16/Awesome-Generation-Acceleration)\", which collects recent awesome generation accleration papers! Feel free to contribute your suggestions!",
        "translatedContent": "* `2024/07/15` ü§óü§ó Nous publions un d√©p√¥t open-source \"[Awesome-Generation-Acceleration](https://github.com/xuyang-liu16/Awesome-Generation-Acceleration)\", qui rassemble les r√©cents excellents articles sur l'acc√©l√©ration de g√©n√©ration ! N'h√©sitez pas √† contribuer avec vos suggestions !"
      },
      {
        "row": 29,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 30,
        "rowsha": "U8eO5ZMev1PH3G030/YyNbNyaS1S4k9n5Of/5MkmvMU=",
        "originContent": "<details>",
        "translatedContent": "<details>"
      },
      {
        "row": 31,
        "rowsha": "qLx6Z+0MU0Auz7F41A3Jc4dR+cSkzESO1JVS8/SKcDc=",
        "originContent": "  <summary><strong>Abstract</strong></summary>",
        "translatedContent": "  <summary><strong>R√©sum√©</strong></summary>"
      },
      {
        "row": 32,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 33,
        "rowsha": "YIqf7kN0c/54TcKx6d15MTu4MoUYVK2v7TZvknoQpw4=",
        "originContent": "  Diffusion Transformers (DiT) have revolutionized high-fidelity image and video synthesis, yet their computational demands remain prohibitive for real-time applications. To solve this problem, feature caching has been proposed to accelerate diffusion models by caching the features in the previous timesteps and then reusing them in the following timesteps. However, at timesteps with significant intervals, the feature similarity in diffusion models decreases substantially, leading to a pronounced increase in errors introduced by feature caching, significantly harming the generation quality. To solve this problem, we propose TaylorSeer, which firstly shows that features of diffusion models at future timesteps can be predicted based on their values at previous timesteps. Based on the fact that features change slowly and continuously across timesteps, TaylorSeer employs a differential method to approximate the higher-order derivatives of features and predict features in future timesteps with Taylor series expansion. Extensive experiments demonstrate its significant effectiveness in both image and video synthesis, especially in high acceleration ratios. For instance, it achieves an almost lossless acceleration of 4.99 $\\times$ on FLUX and 5.00 $\\times$ on HunyuanVideo without additional training. On DiT, it achieves $3.41$ lower FID compared with previous SOTA at $4.53$ $\\times$ acceleration.",
        "translatedContent": "  Les Diffusion Transformers (DiT) ont r√©volutionn√© la synth√®se d'images et de vid√©os √† haute fid√©lit√©, mais leurs exigences computationnelles restent prohibitives pour les applications en temps r√©el. Pour r√©soudre ce probl√®me, la mise en cache des caract√©ristiques a √©t√© propos√©e pour acc√©l√©rer les mod√®les de diffusion en mettant en cache les caract√©ristiques des pas de temps pr√©c√©dents puis en les r√©utilisant aux pas de temps suivants. Cependant, aux pas de temps avec des intervalles importants, la similarit√© des caract√©ristiques dans les mod√®les de diffusion diminue consid√©rablement, entra√Ænant une augmentation marqu√©e des erreurs introduites par la mise en cache des caract√©ristiques, ce qui nuit fortement √† la qualit√© de g√©n√©ration. Pour r√©soudre ce probl√®me, nous proposons TaylorSeer, qui montre d'abord que les caract√©ristiques des mod√®les de diffusion aux pas de temps futurs peuvent √™tre pr√©dites √† partir de leurs valeurs aux pas de temps pr√©c√©dents. Bas√© sur le fait que les caract√©ristiques changent lentement et continuellement au fil des pas de temps, TaylorSeer emploie une m√©thode diff√©rentielle pour approximer les d√©riv√©es d'ordre sup√©rieur des caract√©ristiques et pr√©dire les caract√©ristiques aux pas de temps futurs avec une expansion en s√©rie de Taylor. Des exp√©riences approfondies d√©montrent son efficacit√© significative tant en synth√®se d'images que de vid√©os, particuli√®rement pour des taux d'acc√©l√©ration √©lev√©s. Par exemple, il atteint une acc√©l√©ration quasi sans perte de 4,99 $\\times$ sur FLUX et 5,00 $\\times$ sur HunyuanVideo sans entra√Ænement suppl√©mentaire. Sur DiT, il obtient un FID inf√©rieur de $3,41$ compar√© au pr√©c√©dent √©tat de l'art √† une acc√©l√©ration de $4,53$ $\\times$."
      },
      {
        "row": 34,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 35,
        "rowsha": "iKxEwaqPw8IiEEWQ6czEzAvKi1nrFO/wqlPbG+tChcM=",
        "originContent": "</details>",
        "translatedContent": "</details>"
      },
      {
        "row": 36,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 37,
        "rowsha": "vVMKG86X38wpzVR64MO4O04P+r93zrGe0ew8fB75VJE=",
        "originContent": "## üß© Community Contributions",
        "translatedContent": "## üß© Contributions de la communaut√©"
      },
      {
        "row": 38,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 39,
        "rowsha": "NhqQVhWscK75IALoDKNa+hzMcIiPuhqHLJjuDbSctMA=",
        "originContent": "Thanks to all the open-source contributors for their strong support! We‚Äôd love to hear from you!",
        "translatedContent": "Merci √† tous les contributeurs open-source pour leur fort soutien ! Nous serions ravis d‚Äôavoir de vos nouvelles !"
      },
      {
        "row": 40,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 41,
        "rowsha": "woBL8XbSNmvsJez4Ev755tcLFMQBHiYdzCnwQ4Dm+lo=",
        "originContent": "* ComfyUI-TaylorSeer-philipy1219 (FP8 Inference on FLUX, more video models coming): [ComfyUI-TaylorSeer-philipy1219](https://github.com/philipy1219/ComfyUI-TaylorSeer) by [philipy1219](https://github.com/philipy1219).",
        "translatedContent": "* ComfyUI-TaylorSeer-philipy1219 (inf√©rence FP8 sur FLUX, plus de mod√®les vid√©o √† venir) : [ComfyUI-TaylorSeer-philipy1219](https://github.com/philipy1219/ComfyUI-TaylorSeer) par [philipy1219](https://github.com/philipy1219)."
      },
      {
        "row": 42,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 43,
        "rowsha": "Uib95QyFy+G2xAAPKyoC5mR8MEqKhXKN6jTjMNlQ47w=",
        "originContent": "## üõ† Installation",
        "translatedContent": "## üõ† Installation"
      },
      {
        "row": 44,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 2,
    "Content": "``` cmd\ngit clone https://github.com/Shenyi-Z/TaylorSeer.git\n```",
    "ContentSha": "tuWrp9bDtQRlcwPecUQOIggRbo+xLp0FrvKAqYyhPhI=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "``` cmd\ngit clone https://github.com/Shenyi-Z/TaylorSeer.git\n```",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "m+Ye/ZAlgvAp+ebS8N9WTXZep69SFbfwiK0O7Et0+Ro=",
        "originContent": "``` cmd",
        "translatedContent": "``` cmd"
      },
      {
        "row": 2,
        "rowsha": "cS+FAoCjHksjXqzHsY5NCYms9p+hgMbt55zlSipAEdM=",
        "originContent": "git clone https://github.com/Shenyi-Z/TaylorSeer.git",
        "translatedContent": "git clone https://github.com/Shenyi-Z/TaylorSeer.git"
      },
      {
        "row": 3,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      }
    ],
    "IsCodeBlock": true
  },
  {
    "Id": 3,
    "Content": "\n\n## TaylorSeer-FLUX\n\nTaylorSeer achieved a lossless computational compression of 4.99 $\\times$ and a Latency Speedup of 3.53 $\\times$ on FLUX.1-dev, as measured by [ImageReward](https://github.com/THUDM/ImageReward) for comprehensive quality. To run TaylorSeer-FLUX, see [TaylorSeer-FLUX](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-FLUX.md).\n\nBesides, We have provided examples of inference scripts for the **diffusers version**, as well as multi-GPU parallel **xDiT inference scripts**. You can also conduct tests based on them, located at [TaylorSeers-Diffusers](./TaylorSeers-Diffusers ) and [TaylorSeers-xDiT](./TaylorSeers-xDiT) respectively.\n\n## TaylorSeer-HunyuanVideo\n\nTaylorSeer achieved a computational compression of 5.00 $\\times$ and a remarkable Latency Speedup of 4.65 $\\times$ on HunyuanVideo, as comprehensively measured by the [VBench](https://github.com/Vchitect/VBench) metric. Compared to previous methods, it demonstrated significant improvements in both acceleration efficiency and quality. To run TaylorSeer-HunyuanVideo, see [TaylorSeer-HunyuanVideo](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-HunyuanVideo.md).\n\nIn addition, our scripts also support multi-GPU parallel acceleration implemented by HunyuanVideo using xDiT. In this case, the acceleration effect brought by the cache and the acceleration effect of multi-GPU parallelism are independent of each other and multiply, achieving extremely high acceleration effects.\n\n## TayorSeer-DiT\n\nTaylorSeer achieved a lossless computational compression of 2.77 $\\times$ on the base model DiT, as comprehensively evaluated by metrics such as FID. Its performance across various acceleration ratios significantly surpassed previous methods. For instance, in an extreme scenario with a 4.53 $\\times$ compression ratio, TaylorSeer's FID only increased by 0.33 from the non-accelerated baseline of 2.32, reaching 2.65, while ToCa and DuCa exhibited FID scores above 6.0 under the same conditions. To run TaylorSeer-DiT,see [TaylorSeer-DiT](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-DiT.md).\n\n## TaylorSeer-Wan2.1\n\nWe implemented the TaylorSeer acceleration method on Wan2.1, with support for multi-GPU parallel inference. The installation and inference commands for TaylorSeer-Wan2.1 are fully compatible with those of Wan2.1. To run TaylorSeer-Wan2.1, see [TaylorSeer-Wan2.1](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-Wan2.1.md).\n\n## TaylorSeer-HiDream\n\nThe recently open-sourced image generation model **HiDream**, despite its impressive output quality, faces increasing demands for acceleration due to its longer inference time. We applied **TaylorSeer** to accelerate HiDream‚Äôs inference, achieving a **72% reduction in runtime**. For more details, see [TaylorSeer-HiDream](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-HiDream.md).\n\n## üëç Acknowledgements\n\n- Thanks to [DiT](https://github.com/facebookresearch/DiT) for their great work and codebase upon which we build TaylorSeer-DiT.\n- Thanks to [FLUX](https://github.com/black-forest-labs/flux) for their great work and codebase upon which we build TaylorSeer-FLUX.\n- Thanks to [HiDream](https://github.com/HiDream-ai/HiDream-I1) for their great work and codebase upon which we build TaylorSeer-HiDream.\n- Thanks to [HunyuanVideo](https://github.com/Tencent/HunyuanVideo) for their great work and codebase upon which we build TaylorSeer-HunyuanVideo.\n- Thanks to [Wan2.1](https://github.com/Wan-Video/Wan2.1) for their great work and codebase upon which we build TaylorSeer-Wan2.1.\n- Thanks to [ImageReward](https://github.com/THUDM/ImageReward) for Text-to-Image quality evaluation.\n- Thanks to [VBench](https://github.com/Vchitect/VBench) for Text-to-Video quality evaluation.\n\n\n## üìå Citation\n",
    "ContentSha": "j4spOn6j9j6K+1441QrOXQV28NxAb0gvoZxPRt2rZOk=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "\n## TaylorSeer-FLUX\n\nTaylorSeer a r√©alis√© une compression computationnelle sans perte de 4,99 $\\times$ et une acc√©l√©ration de latence de 3,53 $\\times$ sur FLUX.1-dev, mesur√©es par [ImageReward](https://github.com/THUDM/ImageReward) pour une qualit√© globale. Pour ex√©cuter TaylorSeer-FLUX, voir [TaylorSeer-FLUX](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-FLUX.md).\n\nDe plus, nous avons fourni des exemples de scripts d'inf√©rence pour la **version diffusers**, ainsi que des scripts d'inf√©rence **xDiT** en parall√®le multi-GPU. Vous pouvez √©galement r√©aliser des tests bas√©s sur ceux-ci, situ√©s respectivement √† [TaylorSeers-Diffusers](./TaylorSeers-Diffusers ) et [TaylorSeers-xDiT](./TaylorSeers-xDiT).\n\n## TaylorSeer-HunyuanVideo\n\nTaylorSeer a atteint une compression computationnelle de 5,00 $\\times$ et une remarquable acc√©l√©ration de latence de 4,65 $\\times$ sur HunyuanVideo, mesur√©es de mani√®re exhaustive par la m√©trique [VBench](https://github.com/Vchitect/VBench). Par rapport aux m√©thodes pr√©c√©dentes, il a d√©montr√© des am√©liorations significatives tant en efficacit√© d'acc√©l√©ration qu'en qualit√©. Pour ex√©cuter TaylorSeer-HunyuanVideo, voir [TaylorSeer-HunyuanVideo](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-HunyuanVideo.md).\n\nDe plus, nos scripts prennent √©galement en charge l'acc√©l√©ration parall√®le multi-GPU mise en ≈ìuvre par HunyuanVideo utilisant xDiT. Dans ce cas, l'effet d'acc√©l√©ration apport√© par le cache et celui du parall√©lisme multi-GPU sont ind√©pendants l'un de l'autre et se multiplient, atteignant des effets d'acc√©l√©ration extr√™mement √©lev√©s.\n\n## TayorSeer-DiT\n\nTaylorSeer a r√©alis√© une compression computationnelle sans perte de 2,77 $\\times$ sur le mod√®le de base DiT, √©valu√©e de mani√®re exhaustive par des m√©triques telles que le FID. Ses performances √† divers ratios d'acc√©l√©ration ont largement surpass√© les m√©thodes pr√©c√©dentes. Par exemple, dans un sc√©nario extr√™me avec un ratio de compression de 4,53 $\\times$, le FID de TaylorSeer n'a augment√© que de 0,33 par rapport √† la r√©f√©rence non acc√©l√©r√©e de 2,32, atteignant 2,65, tandis que ToCa et DuCa affichaient des scores FID sup√©rieurs √† 6,0 dans les m√™mes conditions. Pour ex√©cuter TaylorSeer-DiT, voir [TaylorSeer-DiT](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-DiT.md).\n\n## TaylorSeer-Wan2.1\n\nNous avons impl√©ment√© la m√©thode d'acc√©l√©ration TaylorSeer sur Wan2.1, avec prise en charge de l'inf√©rence parall√®le multi-GPU. Les commandes d'installation et d'inf√©rence pour TaylorSeer-Wan2.1 sont enti√®rement compatibles avec celles de Wan2.1. Pour ex√©cuter TaylorSeer-Wan2.1, voir [TaylorSeer-Wan2.1](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-Wan2.1.md).\n\n## TaylorSeer-HiDream\n\nLe mod√®le de g√©n√©ration d'images r√©cemment open source **HiDream**, malgr√© sa qualit√© de sortie impressionnante, fait face √† des demandes croissantes d'acc√©l√©ration en raison de son temps d'inf√©rence plus long. Nous avons appliqu√© **TaylorSeer** pour acc√©l√©rer l'inf√©rence de HiDream, r√©alisant une **r√©duction de 72 % du temps d'ex√©cution**. Pour plus de d√©tails, voir [TaylorSeer-HiDream](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-HiDream.md).\n\n## üëç Remerciements\n\n- Merci √† [DiT](https://github.com/facebookresearch/DiT) pour leur excellent travail et leur base de code sur laquelle nous avons construit TaylorSeer-DiT.\n- Merci √† [FLUX](https://github.com/black-forest-labs/flux) pour leur excellent travail et leur base de code sur laquelle nous avons construit TaylorSeer-FLUX.\n- Merci √† [HiDream](https://github.com/HiDream-ai/HiDream-I1) pour leur excellent travail et leur base de code sur laquelle nous avons construit TaylorSeer-HiDream.\n- Merci √† [HunyuanVideo](https://github.com/Tencent/HunyuanVideo) pour leur excellent travail et leur base de code sur laquelle nous avons construit TaylorSeer-HunyuanVideo.\n- Merci √† [Wan2.1](https://github.com/Wan-Video/Wan2.1) pour leur excellent travail et leur base de code sur laquelle nous avons construit TaylorSeer-Wan2.1.\n- Merci √† [ImageReward](https://github.com/THUDM/ImageReward) pour l'√©valuation de la qualit√© texte-image.\n- Merci √† [VBench](https://github.com/Vchitect/VBench) pour l'√©valuation de la qualit√© texte-vid√©o.\n\n\n## üìå Citation\n\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 2,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "## TaylorSeer-FLUX"
      },
      {
        "row": 3,
        "rowsha": "L2TzcgjTuvv3I11CQ/GvH9lYRpj+s4SJYD9K/E2y5xU=",
        "originContent": "## TaylorSeer-FLUX",
        "translatedContent": ""
      },
      {
        "row": 4,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "TaylorSeer a r√©alis√© une compression computationnelle sans perte de 4,99 $\\times$ et une acc√©l√©ration de latence de 3,53 $\\times$ sur FLUX.1-dev, mesur√©es par [ImageReward](https://github.com/THUDM/ImageReward) pour une qualit√© globale. Pour ex√©cuter TaylorSeer-FLUX, voir [TaylorSeer-FLUX](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-FLUX.md)."
      },
      {
        "row": 5,
        "rowsha": "chkx6Gc6ouZXsRcw0q01pp6iUgffxNIeRz+rDYu9/8g=",
        "originContent": "TaylorSeer achieved a lossless computational compression of 4.99 $\\times$ and a Latency Speedup of 3.53 $\\times$ on FLUX.1-dev, as measured by [ImageReward](https://github.com/THUDM/ImageReward) for comprehensive quality. To run TaylorSeer-FLUX, see [TaylorSeer-FLUX](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-FLUX.md).",
        "translatedContent": ""
      },
      {
        "row": 6,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "De plus, nous avons fourni des exemples de scripts d'inf√©rence pour la **version diffusers**, ainsi que des scripts d'inf√©rence **xDiT** en parall√®le multi-GPU. Vous pouvez √©galement r√©aliser des tests bas√©s sur ceux-ci, situ√©s respectivement √† [TaylorSeers-Diffusers](./TaylorSeers-Diffusers ) et [TaylorSeers-xDiT](./TaylorSeers-xDiT)."
      },
      {
        "row": 7,
        "rowsha": "A6kLZqPZQw64dlrFOjpMypZsNMO14xJmlmpv3pw8ezs=",
        "originContent": "Besides, We have provided examples of inference scripts for the **diffusers version**, as well as multi-GPU parallel **xDiT inference scripts**. You can also conduct tests based on them, located at [TaylorSeers-Diffusers](./TaylorSeers-Diffusers ) and [TaylorSeers-xDiT](./TaylorSeers-xDiT) respectively.",
        "translatedContent": ""
      },
      {
        "row": 8,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "## TaylorSeer-HunyuanVideo"
      },
      {
        "row": 9,
        "rowsha": "TvDelfZTkkxA47gKZAdSw/WDfVwOxAFEDF0XiTfHVe4=",
        "originContent": "## TaylorSeer-HunyuanVideo",
        "translatedContent": ""
      },
      {
        "row": 10,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "TaylorSeer a atteint une compression computationnelle de 5,00 $\\times$ et une remarquable acc√©l√©ration de latence de 4,65 $\\times$ sur HunyuanVideo, mesur√©es de mani√®re exhaustive par la m√©trique [VBench](https://github.com/Vchitect/VBench). Par rapport aux m√©thodes pr√©c√©dentes, il a d√©montr√© des am√©liorations significatives tant en efficacit√© d'acc√©l√©ration qu'en qualit√©. Pour ex√©cuter TaylorSeer-HunyuanVideo, voir [TaylorSeer-HunyuanVideo](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-HunyuanVideo.md)."
      },
      {
        "row": 11,
        "rowsha": "dvznffegIKSG4P+ItV8gb99Z1QttpWlLRDzlqMddPoI=",
        "originContent": "TaylorSeer achieved a computational compression of 5.00 $\\times$ and a remarkable Latency Speedup of 4.65 $\\times$ on HunyuanVideo, as comprehensively measured by the [VBench](https://github.com/Vchitect/VBench) metric. Compared to previous methods, it demonstrated significant improvements in both acceleration efficiency and quality. To run TaylorSeer-HunyuanVideo, see [TaylorSeer-HunyuanVideo](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-HunyuanVideo.md).",
        "translatedContent": ""
      },
      {
        "row": 12,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "De plus, nos scripts prennent √©galement en charge l'acc√©l√©ration parall√®le multi-GPU mise en ≈ìuvre par HunyuanVideo utilisant xDiT. Dans ce cas, l'effet d'acc√©l√©ration apport√© par le cache et celui du parall√©lisme multi-GPU sont ind√©pendants l'un de l'autre et se multiplient, atteignant des effets d'acc√©l√©ration extr√™mement √©lev√©s."
      },
      {
        "row": 13,
        "rowsha": "Z3A/KHyeuxpEPv1W3z2nEo0Q6/Tl7PgTbK61vPvql+4=",
        "originContent": "In addition, our scripts also support multi-GPU parallel acceleration implemented by HunyuanVideo using xDiT. In this case, the acceleration effect brought by the cache and the acceleration effect of multi-GPU parallelism are independent of each other and multiply, achieving extremely high acceleration effects.",
        "translatedContent": ""
      },
      {
        "row": 14,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "## TayorSeer-DiT"
      },
      {
        "row": 15,
        "rowsha": "7Y5OqYcgEa7ffvscRZL+2h7W//4Wv8MkKo/KciYC+Is=",
        "originContent": "## TayorSeer-DiT",
        "translatedContent": ""
      },
      {
        "row": 16,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "TaylorSeer a r√©alis√© une compression computationnelle sans perte de 2,77 $\\times$ sur le mod√®le de base DiT, √©valu√©e de mani√®re exhaustive par des m√©triques telles que le FID. Ses performances √† divers ratios d'acc√©l√©ration ont largement surpass√© les m√©thodes pr√©c√©dentes. Par exemple, dans un sc√©nario extr√™me avec un ratio de compression de 4,53 $\\times$, le FID de TaylorSeer n'a augment√© que de 0,33 par rapport √† la r√©f√©rence non acc√©l√©r√©e de 2,32, atteignant 2,65, tandis que ToCa et DuCa affichaient des scores FID sup√©rieurs √† 6,0 dans les m√™mes conditions. Pour ex√©cuter TaylorSeer-DiT, voir [TaylorSeer-DiT](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-DiT.md)."
      },
      {
        "row": 17,
        "rowsha": "jKbN9crC/lW32o3a4odXocjXPpUX4BRy6Px6c5/OADI=",
        "originContent": "TaylorSeer achieved a lossless computational compression of 2.77 $\\times$ on the base model DiT, as comprehensively evaluated by metrics such as FID. Its performance across various acceleration ratios significantly surpassed previous methods. For instance, in an extreme scenario with a 4.53 $\\times$ compression ratio, TaylorSeer's FID only increased by 0.33 from the non-accelerated baseline of 2.32, reaching 2.65, while ToCa and DuCa exhibited FID scores above 6.0 under the same conditions. To run TaylorSeer-DiT,see [TaylorSeer-DiT](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-DiT.md).",
        "translatedContent": ""
      },
      {
        "row": 18,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "## TaylorSeer-Wan2.1"
      },
      {
        "row": 19,
        "rowsha": "5DYFJIi4H43keQh/zs8HrC/0OvovNgdNRAgI1iPeXz4=",
        "originContent": "## TaylorSeer-Wan2.1",
        "translatedContent": ""
      },
      {
        "row": 20,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "Nous avons impl√©ment√© la m√©thode d'acc√©l√©ration TaylorSeer sur Wan2.1, avec prise en charge de l'inf√©rence parall√®le multi-GPU. Les commandes d'installation et d'inf√©rence pour TaylorSeer-Wan2.1 sont enti√®rement compatibles avec celles de Wan2.1. Pour ex√©cuter TaylorSeer-Wan2.1, voir [TaylorSeer-Wan2.1](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-Wan2.1.md)."
      },
      {
        "row": 21,
        "rowsha": "yw71nREC8h91wgq8ShsYXooL5pNuIYSukhKjsfMdofI=",
        "originContent": "We implemented the TaylorSeer acceleration method on Wan2.1, with support for multi-GPU parallel inference. The installation and inference commands for TaylorSeer-Wan2.1 are fully compatible with those of Wan2.1. To run TaylorSeer-Wan2.1, see [TaylorSeer-Wan2.1](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-Wan2.1.md).",
        "translatedContent": ""
      },
      {
        "row": 22,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "## TaylorSeer-HiDream"
      },
      {
        "row": 23,
        "rowsha": "S9sampwK6RNX9MCgwJoggioDY+17FhuB/kPyHb5UgxQ=",
        "originContent": "## TaylorSeer-HiDream",
        "translatedContent": ""
      },
      {
        "row": 24,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "Le mod√®le de g√©n√©ration d'images r√©cemment open source **HiDream**, malgr√© sa qualit√© de sortie impressionnante, fait face √† des demandes croissantes d'acc√©l√©ration en raison de son temps d'inf√©rence plus long. Nous avons appliqu√© **TaylorSeer** pour acc√©l√©rer l'inf√©rence de HiDream, r√©alisant une **r√©duction de 72 % du temps d'ex√©cution**. Pour plus de d√©tails, voir [TaylorSeer-HiDream](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-HiDream.md)."
      },
      {
        "row": 25,
        "rowsha": "NQ+OZmBUlgODN0R1c2zfq7AZz9G4P4M99o3RBv7xXRk=",
        "originContent": "The recently open-sourced image generation model **HiDream**, despite its impressive output quality, faces increasing demands for acceleration due to its longer inference time. We applied **TaylorSeer** to accelerate HiDream‚Äôs inference, achieving a **72% reduction in runtime**. For more details, see [TaylorSeer-HiDream](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-HiDream.md).",
        "translatedContent": ""
      },
      {
        "row": 26,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "## üëç Remerciements"
      },
      {
        "row": 27,
        "rowsha": "u0Hxe1TnAcDLUJOZsTSfCbn/hsIWD27vYpN/fqVX6NY=",
        "originContent": "## üëç Acknowledgements",
        "translatedContent": ""
      },
      {
        "row": 28,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "- Merci √† [DiT](https://github.com/facebookresearch/DiT) pour leur excellent travail et leur base de code sur laquelle nous avons construit TaylorSeer-DiT."
      },
      {
        "row": 29,
        "rowsha": "CMyznQjDV0UsyA0kRFrsBu46YX9RCtwQPWaz6kDw57w=",
        "originContent": "- Thanks to [DiT](https://github.com/facebookresearch/DiT) for their great work and codebase upon which we build TaylorSeer-DiT.",
        "translatedContent": "- Merci √† [FLUX](https://github.com/black-forest-labs/flux) pour leur excellent travail et leur base de code sur laquelle nous avons construit TaylorSeer-FLUX."
      },
      {
        "row": 30,
        "rowsha": "g/lnC2dBLYng5nlpIMvvux4+WxpFGTfff9SbzUWHVBQ=",
        "originContent": "- Thanks to [FLUX](https://github.com/black-forest-labs/flux) for their great work and codebase upon which we build TaylorSeer-FLUX.",
        "translatedContent": "- Merci √† [HiDream](https://github.com/HiDream-ai/HiDream-I1) pour leur excellent travail et leur base de code sur laquelle nous avons construit TaylorSeer-HiDream."
      },
      {
        "row": 31,
        "rowsha": "yuga1q5FZmOSqw1xc0FAfu7Lu5HXOyeKTvtX/Iw2da0=",
        "originContent": "- Thanks to [HiDream](https://github.com/HiDream-ai/HiDream-I1) for their great work and codebase upon which we build TaylorSeer-HiDream.",
        "translatedContent": "- Merci √† [HunyuanVideo](https://github.com/Tencent/HunyuanVideo) pour leur excellent travail et leur base de code sur laquelle nous avons construit TaylorSeer-HunyuanVideo."
      },
      {
        "row": 32,
        "rowsha": "FVkMzLsD/lLWDhQC+24S3sV+KYWrlNI6VWt9cXL8Wi4=",
        "originContent": "- Thanks to [HunyuanVideo](https://github.com/Tencent/HunyuanVideo) for their great work and codebase upon which we build TaylorSeer-HunyuanVideo.",
        "translatedContent": "- Merci √† [Wan2.1](https://github.com/Wan-Video/Wan2.1) pour leur excellent travail et leur base de code sur laquelle nous avons construit TaylorSeer-Wan2.1."
      },
      {
        "row": 33,
        "rowsha": "Eyj54ONx3tEFKlo9ycLBA5oO5Nl/y1cGnSKuJJlbEoY=",
        "originContent": "- Thanks to [Wan2.1](https://github.com/Wan-Video/Wan2.1) for their great work and codebase upon which we build TaylorSeer-Wan2.1.",
        "translatedContent": "- Merci √† [ImageReward](https://github.com/THUDM/ImageReward) pour l'√©valuation de la qualit√© texte-image."
      },
      {
        "row": 34,
        "rowsha": "GjsWMErOgzFsSLuXdW1YI/Y3mLGiO0y5QoT5y8zAKqQ=",
        "originContent": "- Thanks to [ImageReward](https://github.com/THUDM/ImageReward) for Text-to-Image quality evaluation.",
        "translatedContent": "- Merci √† [VBench](https://github.com/Vchitect/VBench) pour l'√©valuation de la qualit√© texte-vid√©o."
      },
      {
        "row": 35,
        "rowsha": "KlJSWNedKVvQL9mxodUIC4dZ1eBs/4O9za9u2hnJQp8=",
        "originContent": "- Thanks to [VBench](https://github.com/Vchitect/VBench) for Text-to-Video quality evaluation.",
        "translatedContent": ""
      },
      {
        "row": 36,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 37,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "## üìå Citation"
      },
      {
        "row": 38,
        "rowsha": "A4soJLbZDJ5jsV21yB+YcMlje6BkPWiyME67jma7Kxo=",
        "originContent": "## üìå Citation",
        "translatedContent": ""
      },
      {
        "row": 39,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 4,
    "Content": "```bibtex\n@article{TaylorSeer2025,\n  title={From Reusing to Forecasting: Accelerating Diffusion Models with TaylorSeers},\n  author={Liu, Jiacheng and Zou, Chang and Lyu, Yuanhuiyi and Chen, Junjie and Zhang, Linfeng},\n  journal={arXiv preprint arXiv:2503.06923},\n  year={2025}\n}\n```",
    "ContentSha": "fen2LVp21p8N9q/eae7nT9vcoFlYE3VN97IgBC75x9g=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bibtex\n@article{TaylorSeer2025,\n  title={From Reusing to Forecasting: Accelerating Diffusion Models with TaylorSeers},\n  author={Liu, Jiacheng and Zou, Chang and Lyu, Yuanhuiyi and Chen, Junjie and Zhang, Linfeng},\n  journal={arXiv preprint arXiv:2503.06923},\n  year={2025}\n}\n```",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "o+TmyQ6wneV6/FQB6aUlRSjIGr2/YLJtnz5uxBgsScQ=",
        "originContent": "```bibtex",
        "translatedContent": "```bibtex"
      },
      {
        "row": 2,
        "rowsha": "/ty4Z1XAwebEXbgzwWSaIIwNKg9g4LtzTihn1TP3w/o=",
        "originContent": "@article{TaylorSeer2025,",
        "translatedContent": "@article{TaylorSeer2025,"
      },
      {
        "row": 3,
        "rowsha": "o+GEpfSsb6+HkPZus7oKYmeYIa0sYGPChFIDFE7bKJY=",
        "originContent": "  title={From Reusing to Forecasting: Accelerating Diffusion Models with TaylorSeers},",
        "translatedContent": "  title={From Reusing to Forecasting: Accelerating Diffusion Models with TaylorSeers},"
      },
      {
        "row": 4,
        "rowsha": "9Nti1MS5YJh1jS6YOETdLSqimPafh+aTqXwIUL0aqvY=",
        "originContent": "  author={Liu, Jiacheng and Zou, Chang and Lyu, Yuanhuiyi and Chen, Junjie and Zhang, Linfeng},",
        "translatedContent": "  author={Liu, Jiacheng and Zou, Chang and Lyu, Yuanhuiyi and Chen, Junjie and Zhang, Linfeng},"
      },
      {
        "row": 5,
        "rowsha": "g/zic5erjOtHBZRc431Y3hZJDd8qGKo8zBOAc1c/nmA=",
        "originContent": "  journal={arXiv preprint arXiv:2503.06923},",
        "translatedContent": "  journal={arXiv preprint arXiv:2503.06923},"
      },
      {
        "row": 6,
        "rowsha": "6oyqJVJ20XoZhlyGjaewQyTQsSBBtVAYmqUtTwjLbAg=",
        "originContent": "  year={2025}",
        "translatedContent": "  year={2025}"
      },
      {
        "row": 7,
        "rowsha": "0Qs2qnSlm89KiBhYN/ZYr682Ru/yuxbDko0OkzXpRdI=",
        "originContent": "}",
        "translatedContent": "}"
      },
      {
        "row": 8,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      }
    ],
    "IsCodeBlock": true
  },
  {
    "Id": 5,
    "Content": "\n## :e-mail: Contact\n\nIf you have any questions, please email [`shenyizou@outlook.com`](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/mailto:shenyizou@outlook.com).\n\n",
    "ContentSha": "71xBxPlelSoIdJqUiI+RvDt6idhGFPOYbo/OlJNyPAU=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "\n## :e-mail: Contact\n\nSi vous avez des questions, veuillez envoyer un courriel √† [`shenyizou@outlook.com`](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/mailto:shenyizou@outlook.com).\n\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 2,
        "rowsha": "K5bAg1EjOpNN4wve36Z6v3sJb4XtaMFL5UG4PpfakXM=",
        "originContent": "## :e-mail: Contact",
        "translatedContent": "## :e-mail: Contact"
      },
      {
        "row": 3,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 4,
        "rowsha": "+O5l7O4UKOwm22BlC1HWUnYRp176sGuJ1pgHlKEIMY4=",
        "originContent": "If you have any questions, please email [`shenyizou@outlook.com`](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/mailto:shenyizou@outlook.com).",
        "translatedContent": "Si vous avez des questions, veuillez envoyer un courriel √† [`shenyizou@outlook.com`](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/mailto:shenyizou@outlook.com)."
      },
      {
        "row": 5,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 6,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  }
]