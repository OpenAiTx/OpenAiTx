[
  {
    "Id": 1,
    "Content": "<div align=center>\n  \n# [ICCV 2025] *TaylorSeer*: From Reusing to Forecasting: Accelerating Diffusion Models with *TaylorSeers*\n\n<p>\n<a href='https://arxiv.org/abs/2503.06923'><img src='https://img.shields.io/badge/Paper-arXiv-red'></a>\n<a href='https://taylorseer.github.io/TaylorSeer/'><img src='https://img.shields.io/badge/Project-Page-blue'></a>\n</p>\n\n</div>\n\n## 🔥 News\n\n* `2025/06/26` 💥💥 TaylorSeer is honored to be accepted by ICCV 2025!\n\n* `2025/05/03` 🚀🚀 TaylorSeer for HiDream is released.\n\n* `2025/03/30` 🚀🚀 TaylorSeer for Wan2.1 is released.\n\n* `2025/03/30` 🚀🚀 The Diffusers inference scripts for TaylorSeers and the xDiT scripts applicable for multi-GPU parallel inference have been officially released.\n\n* `2025/03/10` 🚀🚀 Our latest work \"From Reusing to Forecasting: Accelerating Diffusion Models with TaylorSeers\" is released! Codes are available at [TaylorSeer](https://github.com/Shenyi-Z/TaylorSeer)! TaylorSeer supports lossless compression at a rate of 4.99x on FLUX.1-dev (with a latency speedup of 3.53x) and high-quality acceleration at a compression rate of 5.00x on HunyuanVideo (with a latency speedup of 4.65x)! We hope *TaylorSeer* can move the paradigm of feature caching methods from reusing to forecasting.For more details, please refer to our latest research paper.\n* `2025/02/19` 🚀🚀 ToCa solution for **FLUX** has been officially released after adjustments, now achieving up to **3.14× lossless acceleration** (in FLOPs)!\n* `2025/01/22` 💥💥 ToCa is honored to be accepted by ICLR 2025!\n* `2024/12/29` 🚀🚀 We release our work [DuCa](https://arxiv.org/abs/2412.18911) about accelerating diffusion transformers for FREE, which achieves nearly lossless acceleration of **2.50×** on [OpenSora](https://github.com/hpcaitech/Open-Sora)! 🎉 **DuCa also overcomes the limitation of ToCa by fully supporting FlashAttention, enabling broader compatibility and efficiency improvements.**\n* `2024/12/24` 🤗🤗 We release an open-sourse repo \"[Awesome-Token-Reduction-for-Model-Compression](https://github.com/xuyang-liu16/Awesome-Token-Reduction-for-Model-Compression)\", which collects recent awesome token reduction papers! Feel free to contribute your suggestions!\n* `2024/12/10` 💥💥 Our team's recent work, **SiTo** (https://github.com/EvelynZhang-epiclab/SiTo), has been accepted to **AAAI 2025**. It accelerates diffusion models through adaptive **Token Pruning**.\n* `2024/07/15` 🤗🤗 We release an open-sourse repo \"[Awesome-Generation-Acceleration](https://github.com/xuyang-liu16/Awesome-Generation-Acceleration)\", which collects recent awesome generation accleration papers! Feel free to contribute your suggestions!\n\n<details>\n  <summary><strong>Abstract</strong></summary>\n\n  Diffusion Transformers (DiT) have revolutionized high-fidelity image and video synthesis, yet their computational demands remain prohibitive for real-time applications. To solve this problem, feature caching has been proposed to accelerate diffusion models by caching the features in the previous timesteps and then reusing them in the following timesteps. However, at timesteps with significant intervals, the feature similarity in diffusion models decreases substantially, leading to a pronounced increase in errors introduced by feature caching, significantly harming the generation quality. To solve this problem, we propose TaylorSeer, which firstly shows that features of diffusion models at future timesteps can be predicted based on their values at previous timesteps. Based on the fact that features change slowly and continuously across timesteps, TaylorSeer employs a differential method to approximate the higher-order derivatives of features and predict features in future timesteps with Taylor series expansion. Extensive experiments demonstrate its significant effectiveness in both image and video synthesis, especially in high acceleration ratios. For instance, it achieves an almost lossless acceleration of 4.99 $\\times$ on FLUX and 5.00 $\\times$ on HunyuanVideo without additional training. On DiT, it achieves $3.41$ lower FID compared with previous SOTA at $4.53$ $\\times$ acceleration.\n\n</details>\n\n## 🧩 Community Contributions\n\nThanks to all the open-source contributors for their strong support! We’d love to hear from you!\n\n* ComfyUI-TaylorSeer-philipy1219 (FP8 Inference on FLUX, more video models coming): [ComfyUI-TaylorSeer-philipy1219](https://github.com/philipy1219/ComfyUI-TaylorSeer) by [philipy1219](https://github.com/philipy1219).\n\n## 🛠 Installation\n",
    "ContentSha": "37uFfQBn0Cp076D5K4hJQxTj573ffMx7qA31hLCBg/4=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "<div align=center>\n  \n# [ICCV 2025] *TaylorSeer*: De Reutilizar a Predecir: Acelerando Modelos de Difusión con *TaylorSeers*\n\n<p>\n<a href='https://arxiv.org/abs/2503.06923'><img src='https://img.shields.io/badge/Paper-arXiv-red'></a>\n<a href='https://taylorseer.github.io/TaylorSeer/'><img src='https://img.shields.io/badge/Project-Page-blue'></a>\n</p>\n\n</div>\n\n## 🔥 Noticias\n\n* `2025/06/26` 💥💥 ¡TaylorSeer tiene el honor de ser aceptado en ICCV 2025!\n\n* `2025/05/03` 🚀🚀 Se lanza TaylorSeer para HiDream.\n\n* `2025/03/30` 🚀🚀 Se lanza TaylorSeer para Wan2.1.\n\n* `2025/03/30` 🚀🚀 Los scripts de inferencia Diffusers para TaylorSeers y los scripts xDiT aplicables para inferencia paralela multi-GPU han sido lanzados oficialmente.\n\n* `2025/03/10` 🚀🚀 ¡Nuestro trabajo más reciente \"De Reutilizar a Predecir: Acelerando Modelos de Difusión con TaylorSeers\" ha sido publicado! Los códigos están disponibles en [TaylorSeer](https://github.com/Shenyi-Z/TaylorSeer)! TaylorSeer soporta compresión sin pérdidas a una tasa de 4.99x en FLUX.1-dev (con una aceleración en latencia de 3.53x) y aceleración de alta calidad a una tasa de compresión de 5.00x en HunyuanVideo (con una aceleración en latencia de 4.65x)! Esperamos que *TaylorSeer* pueda mover el paradigma de los métodos de caché de características de reutilización a predicción. Para más detalles, por favor consulte nuestro artículo de investigación más reciente.\n* `2025/02/19` 🚀🚀 La solución ToCa para **FLUX** ha sido oficialmente lanzada tras ajustes, logrando ahora hasta **3.14× aceleración sin pérdidas** (en FLOPs)!\n* `2025/01/22` 💥💥 ¡ToCa tiene el honor de ser aceptado en ICLR 2025!\n* `2024/12/29` 🚀🚀 Publicamos nuestro trabajo [DuCa](https://arxiv.org/abs/2412.18911) sobre la aceleración de transformadores de difusión GRATIS, que logra una aceleración casi sin pérdidas de **2.50×** en [OpenSora](https://github.com/hpcaitech/Open-Sora)! 🎉 **DuCa también supera la limitación de ToCa al soportar completamente FlashAttention, permitiendo una mayor compatibilidad y mejoras de eficiencia.**\n* `2024/12/24` 🤗🤗 Publicamos un repositorio de código abierto \"[Awesome-Token-Reduction-for-Model-Compression](https://github.com/xuyang-liu16/Awesome-Token-Reduction-for-Model-Compression)\", que recopila recientes trabajos sobresalientes sobre reducción de tokens! ¡No dudes en contribuir con tus sugerencias!\n* `2024/12/10` 💥💥 El trabajo reciente de nuestro equipo, **SiTo** (https://github.com/EvelynZhang-epiclab/SiTo), ha sido aceptado en **AAAI 2025**. Acelera modelos de difusión mediante **Poda Adaptativa de Tokens**.\n* `2024/07/15` 🤗🤗 Publicamos un repositorio de código abierto \"[Awesome-Generation-Acceleration](https://github.com/xuyang-liu16/Awesome-Generation-Acceleration)\", que recopila recientes trabajos sobresalientes sobre aceleración de generación! ¡No dudes en contribuir con tus sugerencias!\n\n<details>\n  <summary><strong>Resumen</strong></summary>\n\n  Los Transformadores de Difusión (DiT) han revolucionado la síntesis de imágenes y videos de alta fidelidad, pero sus demandas computacionales siguen siendo prohibitivas para aplicaciones en tiempo real. Para resolver este problema, se ha propuesto el caché de características para acelerar modelos de difusión almacenando las características en pasos de tiempo anteriores y reutilizándolas en los siguientes. Sin embargo, en pasos de tiempo con intervalos significativos, la similitud de características en modelos de difusión disminuye sustancialmente, lo que conduce a un aumento pronunciado en los errores introducidos por el caché de características, dañando significativamente la calidad de la generación. Para solucionar este problema, proponemos TaylorSeer, que primero demuestra que las características de los modelos de difusión en pasos de tiempo futuros pueden predecirse basándose en sus valores en pasos de tiempo anteriores. Basado en el hecho de que las características cambian lenta y continuamente a través de los pasos de tiempo, TaylorSeer emplea un método diferencial para aproximar las derivadas de orden superior de las características y predecir las características en pasos de tiempo futuros con la expansión en series de Taylor. Experimentos extensos demuestran su efectividad significativa tanto en síntesis de imágenes como de video, especialmente en altas tasas de aceleración. Por ejemplo, logra una aceleración casi sin pérdidas de 4.99 $\\times$ en FLUX y 5.00 $\\times$ en HunyuanVideo sin entrenamiento adicional. En DiT, logra un FID $3.41$ menor en comparación con el estado del arte previo con una aceleración de $4.53$ $\\times$.\n\n</details>\n\n## 🧩 Contribuciones de la Comunidad\n\n¡Gracias a todos los colaboradores de código abierto por su fuerte apoyo! ¡Nos encantaría saber de ti!\n\n* ComfyUI-TaylorSeer-philipy1219 (Inferencia FP8 en FLUX, más modelos de video próximamente): [ComfyUI-TaylorSeer-philipy1219](https://github.com/philipy1219/ComfyUI-TaylorSeer) por [philipy1219](https://github.com/philipy1219).\n\n## 🛠 Instalación\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "fagPb+qexaXZ3eHptDc4ivZK9kTnn6hX3OIFMxv7aKA=",
        "originContent": "<div align=center>",
        "translatedContent": "<div align=center>"
      },
      {
        "row": 2,
        "rowsha": "bBefIeb2K2KQVdirQPRU7QLki2hWORNHO4V9NjjiOyg=",
        "originContent": "  ",
        "translatedContent": "  "
      },
      {
        "row": 3,
        "rowsha": "MOtTqT65KO6UuOPpgVNTUNy7DBii0E9VU9QXzmbDlRo=",
        "originContent": "# [ICCV 2025] *TaylorSeer*: From Reusing to Forecasting: Accelerating Diffusion Models with *TaylorSeers*",
        "translatedContent": "# [ICCV 2025] *TaylorSeer*: De Reutilizar a Predecir: Acelerando Modelos de Difusión con *TaylorSeers*"
      },
      {
        "row": 4,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 5,
        "rowsha": "M/J5lGcXcoeikmB4ChB6yY6mPdYWX2f8wNdHZ9CoIJA=",
        "originContent": "<p>",
        "translatedContent": "<p>"
      },
      {
        "row": 6,
        "rowsha": "mz6OHfHOKolNYRAUj7PcksyTTRde9MDQh/L+SZDoFfo=",
        "originContent": "<a href='https://arxiv.org/abs/2503.06923'><img src='https://img.shields.io/badge/Paper-arXiv-red'></a>",
        "translatedContent": "<a href='https://arxiv.org/abs/2503.06923'><img src='https://img.shields.io/badge/Paper-arXiv-red'></a>"
      },
      {
        "row": 7,
        "rowsha": "s05rwhJ5NOYGsjO9U5kI5HYTz2AEGGz9Fbptc/Pug9c=",
        "originContent": "<a href='https://taylorseer.github.io/TaylorSeer/'><img src='https://img.shields.io/badge/Project-Page-blue'></a>",
        "translatedContent": "<a href='https://taylorseer.github.io/TaylorSeer/'><img src='https://img.shields.io/badge/Project-Page-blue'></a>"
      },
      {
        "row": 8,
        "rowsha": "dSdvPNAZSmR86FDDSF6tkQUCVfI9qmACHOR5tThOetY=",
        "originContent": "</p>",
        "translatedContent": "</p>"
      },
      {
        "row": 9,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 10,
        "rowsha": "qsMmUbEPVnxGG5tPJV1vsfpoWbU2jYvZpRr5IKshzyM=",
        "originContent": "</div>",
        "translatedContent": "</div>"
      },
      {
        "row": 11,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 12,
        "rowsha": "D7bG/VBJXSi2hpB980ek7pr4pjcctcRkfLZHbhVcyVg=",
        "originContent": "## 🔥 News",
        "translatedContent": "## 🔥 Noticias"
      },
      {
        "row": 13,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 14,
        "rowsha": "4+OZ9EqFu/vmVQzOQg6e3fSByT5AG7kgw0p/8ZZtXvg=",
        "originContent": "* `2025/06/26` 💥💥 TaylorSeer is honored to be accepted by ICCV 2025!",
        "translatedContent": "* `2025/06/26` 💥💥 ¡TaylorSeer tiene el honor de ser aceptado en ICCV 2025!"
      },
      {
        "row": 15,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 16,
        "rowsha": "nWHnk9X5bw0hFy3WJgq/jX5Go8T0fpLu1GZwDSTAXQ4=",
        "originContent": "* `2025/05/03` 🚀🚀 TaylorSeer for HiDream is released.",
        "translatedContent": "* `2025/05/03` 🚀🚀 Se lanza TaylorSeer para HiDream."
      },
      {
        "row": 17,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 18,
        "rowsha": "nkoB/ObNg2vVPOSBVJEmU88VVwnAhcgFXCZqkw1bSY0=",
        "originContent": "* `2025/03/30` 🚀🚀 TaylorSeer for Wan2.1 is released.",
        "translatedContent": "* `2025/03/30` 🚀🚀 Se lanza TaylorSeer para Wan2.1."
      },
      {
        "row": 19,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 20,
        "rowsha": "3NpXU50QD+KRAHj2dNcg+rCjixMNdTA/nGF1u6E0oe0=",
        "originContent": "* `2025/03/30` 🚀🚀 The Diffusers inference scripts for TaylorSeers and the xDiT scripts applicable for multi-GPU parallel inference have been officially released.",
        "translatedContent": "* `2025/03/30` 🚀🚀 Los scripts de inferencia Diffusers para TaylorSeers y los scripts xDiT aplicables para inferencia paralela multi-GPU han sido lanzados oficialmente."
      },
      {
        "row": 21,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 22,
        "rowsha": "9NG8DDgu4GTSLg6UyU6J2MUqXFt01vZBE1vkyAWpvuo=",
        "originContent": "* `2025/03/10` 🚀🚀 Our latest work \"From Reusing to Forecasting: Accelerating Diffusion Models with TaylorSeers\" is released! Codes are available at [TaylorSeer](https://github.com/Shenyi-Z/TaylorSeer)! TaylorSeer supports lossless compression at a rate of 4.99x on FLUX.1-dev (with a latency speedup of 3.53x) and high-quality acceleration at a compression rate of 5.00x on HunyuanVideo (with a latency speedup of 4.65x)! We hope *TaylorSeer* can move the paradigm of feature caching methods from reusing to forecasting.For more details, please refer to our latest research paper.",
        "translatedContent": "* `2025/03/10` 🚀🚀 ¡Nuestro trabajo más reciente \"De Reutilizar a Predecir: Acelerando Modelos de Difusión con TaylorSeers\" ha sido publicado! Los códigos están disponibles en [TaylorSeer](https://github.com/Shenyi-Z/TaylorSeer)! TaylorSeer soporta compresión sin pérdidas a una tasa de 4.99x en FLUX.1-dev (con una aceleración en latencia de 3.53x) y aceleración de alta calidad a una tasa de compresión de 5.00x en HunyuanVideo (con una aceleración en latencia de 4.65x)! Esperamos que *TaylorSeer* pueda mover el paradigma de los métodos de caché de características de reutilización a predicción. Para más detalles, por favor consulte nuestro artículo de investigación más reciente."
      },
      {
        "row": 23,
        "rowsha": "HP4JYN9AqV5x9xftKuxud6Lmj5FbX6yZVjvsYTmL3X4=",
        "originContent": "* `2025/02/19` 🚀🚀 ToCa solution for **FLUX** has been officially released after adjustments, now achieving up to **3.14× lossless acceleration** (in FLOPs)!",
        "translatedContent": "* `2025/02/19` 🚀🚀 La solución ToCa para **FLUX** ha sido oficialmente lanzada tras ajustes, logrando ahora hasta **3.14× aceleración sin pérdidas** (en FLOPs)!"
      },
      {
        "row": 24,
        "rowsha": "OUJy4nRS5cJZhTQ/bIHSb7tR3CPpzmEdfy9FQsPvkKY=",
        "originContent": "* `2025/01/22` 💥💥 ToCa is honored to be accepted by ICLR 2025!",
        "translatedContent": "* `2025/01/22` 💥💥 ¡ToCa tiene el honor de ser aceptado en ICLR 2025!"
      },
      {
        "row": 25,
        "rowsha": "JP7Uqbgmmu3w73rzXhFcbs+DuZhRhuwWmv0rp0Z8zBQ=",
        "originContent": "* `2024/12/29` 🚀🚀 We release our work [DuCa](https://arxiv.org/abs/2412.18911) about accelerating diffusion transformers for FREE, which achieves nearly lossless acceleration of **2.50×** on [OpenSora](https://github.com/hpcaitech/Open-Sora)! 🎉 **DuCa also overcomes the limitation of ToCa by fully supporting FlashAttention, enabling broader compatibility and efficiency improvements.**",
        "translatedContent": "* `2024/12/29` 🚀🚀 Publicamos nuestro trabajo [DuCa](https://arxiv.org/abs/2412.18911) sobre la aceleración de transformadores de difusión GRATIS, que logra una aceleración casi sin pérdidas de **2.50×** en [OpenSora](https://github.com/hpcaitech/Open-Sora)! 🎉 **DuCa también supera la limitación de ToCa al soportar completamente FlashAttention, permitiendo una mayor compatibilidad y mejoras de eficiencia.**"
      },
      {
        "row": 26,
        "rowsha": "76EiBVgv/EgSTVYsjHggBTygkeo1yu7OIgVRvPD3Ixs=",
        "originContent": "* `2024/12/24` 🤗🤗 We release an open-sourse repo \"[Awesome-Token-Reduction-for-Model-Compression](https://github.com/xuyang-liu16/Awesome-Token-Reduction-for-Model-Compression)\", which collects recent awesome token reduction papers! Feel free to contribute your suggestions!",
        "translatedContent": "* `2024/12/24` 🤗🤗 Publicamos un repositorio de código abierto \"[Awesome-Token-Reduction-for-Model-Compression](https://github.com/xuyang-liu16/Awesome-Token-Reduction-for-Model-Compression)\", que recopila recientes trabajos sobresalientes sobre reducción de tokens! ¡No dudes en contribuir con tus sugerencias!"
      },
      {
        "row": 27,
        "rowsha": "/8zh2xS0BXOpvQxdWqtvtS7GCz9dpRDj/KNLKaArh/s=",
        "originContent": "* `2024/12/10` 💥💥 Our team's recent work, **SiTo** (https://github.com/EvelynZhang-epiclab/SiTo), has been accepted to **AAAI 2025**. It accelerates diffusion models through adaptive **Token Pruning**.",
        "translatedContent": "* `2024/12/10` 💥💥 El trabajo reciente de nuestro equipo, **SiTo** (https://github.com/EvelynZhang-epiclab/SiTo), ha sido aceptado en **AAAI 2025**. Acelera modelos de difusión mediante **Poda Adaptativa de Tokens**."
      },
      {
        "row": 28,
        "rowsha": "O7eC1AedMiPQpbcvrbKc4glnjZa6qtgwQDRRhUGn+1w=",
        "originContent": "* `2024/07/15` 🤗🤗 We release an open-sourse repo \"[Awesome-Generation-Acceleration](https://github.com/xuyang-liu16/Awesome-Generation-Acceleration)\", which collects recent awesome generation accleration papers! Feel free to contribute your suggestions!",
        "translatedContent": "* `2024/07/15` 🤗🤗 Publicamos un repositorio de código abierto \"[Awesome-Generation-Acceleration](https://github.com/xuyang-liu16/Awesome-Generation-Acceleration)\", que recopila recientes trabajos sobresalientes sobre aceleración de generación! ¡No dudes en contribuir con tus sugerencias!"
      },
      {
        "row": 29,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 30,
        "rowsha": "U8eO5ZMev1PH3G030/YyNbNyaS1S4k9n5Of/5MkmvMU=",
        "originContent": "<details>",
        "translatedContent": "<details>"
      },
      {
        "row": 31,
        "rowsha": "qLx6Z+0MU0Auz7F41A3Jc4dR+cSkzESO1JVS8/SKcDc=",
        "originContent": "  <summary><strong>Abstract</strong></summary>",
        "translatedContent": "  <summary><strong>Resumen</strong></summary>"
      },
      {
        "row": 32,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 33,
        "rowsha": "YIqf7kN0c/54TcKx6d15MTu4MoUYVK2v7TZvknoQpw4=",
        "originContent": "  Diffusion Transformers (DiT) have revolutionized high-fidelity image and video synthesis, yet their computational demands remain prohibitive for real-time applications. To solve this problem, feature caching has been proposed to accelerate diffusion models by caching the features in the previous timesteps and then reusing them in the following timesteps. However, at timesteps with significant intervals, the feature similarity in diffusion models decreases substantially, leading to a pronounced increase in errors introduced by feature caching, significantly harming the generation quality. To solve this problem, we propose TaylorSeer, which firstly shows that features of diffusion models at future timesteps can be predicted based on their values at previous timesteps. Based on the fact that features change slowly and continuously across timesteps, TaylorSeer employs a differential method to approximate the higher-order derivatives of features and predict features in future timesteps with Taylor series expansion. Extensive experiments demonstrate its significant effectiveness in both image and video synthesis, especially in high acceleration ratios. For instance, it achieves an almost lossless acceleration of 4.99 $\\times$ on FLUX and 5.00 $\\times$ on HunyuanVideo without additional training. On DiT, it achieves $3.41$ lower FID compared with previous SOTA at $4.53$ $\\times$ acceleration.",
        "translatedContent": "  Los Transformadores de Difusión (DiT) han revolucionado la síntesis de imágenes y videos de alta fidelidad, pero sus demandas computacionales siguen siendo prohibitivas para aplicaciones en tiempo real. Para resolver este problema, se ha propuesto el caché de características para acelerar modelos de difusión almacenando las características en pasos de tiempo anteriores y reutilizándolas en los siguientes. Sin embargo, en pasos de tiempo con intervalos significativos, la similitud de características en modelos de difusión disminuye sustancialmente, lo que conduce a un aumento pronunciado en los errores introducidos por el caché de características, dañando significativamente la calidad de la generación. Para solucionar este problema, proponemos TaylorSeer, que primero demuestra que las características de los modelos de difusión en pasos de tiempo futuros pueden predecirse basándose en sus valores en pasos de tiempo anteriores. Basado en el hecho de que las características cambian lenta y continuamente a través de los pasos de tiempo, TaylorSeer emplea un método diferencial para aproximar las derivadas de orden superior de las características y predecir las características en pasos de tiempo futuros con la expansión en series de Taylor. Experimentos extensos demuestran su efectividad significativa tanto en síntesis de imágenes como de video, especialmente en altas tasas de aceleración. Por ejemplo, logra una aceleración casi sin pérdidas de 4.99 $\\times$ en FLUX y 5.00 $\\times$ en HunyuanVideo sin entrenamiento adicional. En DiT, logra un FID $3.41$ menor en comparación con el estado del arte previo con una aceleración de $4.53$ $\\times$."
      },
      {
        "row": 34,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 35,
        "rowsha": "iKxEwaqPw8IiEEWQ6czEzAvKi1nrFO/wqlPbG+tChcM=",
        "originContent": "</details>",
        "translatedContent": "</details>"
      },
      {
        "row": 36,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 37,
        "rowsha": "vVMKG86X38wpzVR64MO4O04P+r93zrGe0ew8fB75VJE=",
        "originContent": "## 🧩 Community Contributions",
        "translatedContent": "## 🧩 Contribuciones de la Comunidad"
      },
      {
        "row": 38,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 39,
        "rowsha": "NhqQVhWscK75IALoDKNa+hzMcIiPuhqHLJjuDbSctMA=",
        "originContent": "Thanks to all the open-source contributors for their strong support! We’d love to hear from you!",
        "translatedContent": "¡Gracias a todos los colaboradores de código abierto por su fuerte apoyo! ¡Nos encantaría saber de ti!"
      },
      {
        "row": 40,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 41,
        "rowsha": "woBL8XbSNmvsJez4Ev755tcLFMQBHiYdzCnwQ4Dm+lo=",
        "originContent": "* ComfyUI-TaylorSeer-philipy1219 (FP8 Inference on FLUX, more video models coming): [ComfyUI-TaylorSeer-philipy1219](https://github.com/philipy1219/ComfyUI-TaylorSeer) by [philipy1219](https://github.com/philipy1219).",
        "translatedContent": "* ComfyUI-TaylorSeer-philipy1219 (Inferencia FP8 en FLUX, más modelos de video próximamente): [ComfyUI-TaylorSeer-philipy1219](https://github.com/philipy1219/ComfyUI-TaylorSeer) por [philipy1219](https://github.com/philipy1219)."
      },
      {
        "row": 42,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 43,
        "rowsha": "Uib95QyFy+G2xAAPKyoC5mR8MEqKhXKN6jTjMNlQ47w=",
        "originContent": "## 🛠 Installation",
        "translatedContent": "## 🛠 Instalación"
      },
      {
        "row": 44,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 2,
    "Content": "``` cmd\ngit clone https://github.com/Shenyi-Z/TaylorSeer.git\n```",
    "ContentSha": "tuWrp9bDtQRlcwPecUQOIggRbo+xLp0FrvKAqYyhPhI=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "``` cmd\ngit clone https://github.com/Shenyi-Z/TaylorSeer.git\n```",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "m+Ye/ZAlgvAp+ebS8N9WTXZep69SFbfwiK0O7Et0+Ro=",
        "originContent": "``` cmd",
        "translatedContent": "``` cmd"
      },
      {
        "row": 2,
        "rowsha": "cS+FAoCjHksjXqzHsY5NCYms9p+hgMbt55zlSipAEdM=",
        "originContent": "git clone https://github.com/Shenyi-Z/TaylorSeer.git",
        "translatedContent": "git clone https://github.com/Shenyi-Z/TaylorSeer.git"
      },
      {
        "row": 3,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      }
    ],
    "IsCodeBlock": true
  },
  {
    "Id": 3,
    "Content": "\n\n## TaylorSeer-FLUX\n\nTaylorSeer achieved a lossless computational compression of 4.99 $\\times$ and a Latency Speedup of 3.53 $\\times$ on FLUX.1-dev, as measured by [ImageReward](https://github.com/THUDM/ImageReward) for comprehensive quality. To run TaylorSeer-FLUX, see [TaylorSeer-FLUX](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-FLUX.md).\n\nBesides, We have provided examples of inference scripts for the **diffusers version**, as well as multi-GPU parallel **xDiT inference scripts**. You can also conduct tests based on them, located at [TaylorSeers-Diffusers](./TaylorSeers-Diffusers ) and [TaylorSeers-xDiT](./TaylorSeers-xDiT) respectively.\n\n## TaylorSeer-HunyuanVideo\n\nTaylorSeer achieved a computational compression of 5.00 $\\times$ and a remarkable Latency Speedup of 4.65 $\\times$ on HunyuanVideo, as comprehensively measured by the [VBench](https://github.com/Vchitect/VBench) metric. Compared to previous methods, it demonstrated significant improvements in both acceleration efficiency and quality. To run TaylorSeer-HunyuanVideo, see [TaylorSeer-HunyuanVideo](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-HunyuanVideo.md).\n\nIn addition, our scripts also support multi-GPU parallel acceleration implemented by HunyuanVideo using xDiT. In this case, the acceleration effect brought by the cache and the acceleration effect of multi-GPU parallelism are independent of each other and multiply, achieving extremely high acceleration effects.\n\n## TayorSeer-DiT\n\nTaylorSeer achieved a lossless computational compression of 2.77 $\\times$ on the base model DiT, as comprehensively evaluated by metrics such as FID. Its performance across various acceleration ratios significantly surpassed previous methods. For instance, in an extreme scenario with a 4.53 $\\times$ compression ratio, TaylorSeer's FID only increased by 0.33 from the non-accelerated baseline of 2.32, reaching 2.65, while ToCa and DuCa exhibited FID scores above 6.0 under the same conditions. To run TaylorSeer-DiT,see [TaylorSeer-DiT](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-DiT.md).\n\n## TaylorSeer-Wan2.1\n\nWe implemented the TaylorSeer acceleration method on Wan2.1, with support for multi-GPU parallel inference. The installation and inference commands for TaylorSeer-Wan2.1 are fully compatible with those of Wan2.1. To run TaylorSeer-Wan2.1, see [TaylorSeer-Wan2.1](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-Wan2.1.md).\n\n## TaylorSeer-HiDream\n\nThe recently open-sourced image generation model **HiDream**, despite its impressive output quality, faces increasing demands for acceleration due to its longer inference time. We applied **TaylorSeer** to accelerate HiDream’s inference, achieving a **72% reduction in runtime**. For more details, see [TaylorSeer-HiDream](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-HiDream.md).\n\n## 👍 Acknowledgements\n\n- Thanks to [DiT](https://github.com/facebookresearch/DiT) for their great work and codebase upon which we build TaylorSeer-DiT.\n- Thanks to [FLUX](https://github.com/black-forest-labs/flux) for their great work and codebase upon which we build TaylorSeer-FLUX.\n- Thanks to [HiDream](https://github.com/HiDream-ai/HiDream-I1) for their great work and codebase upon which we build TaylorSeer-HiDream.\n- Thanks to [HunyuanVideo](https://github.com/Tencent/HunyuanVideo) for their great work and codebase upon which we build TaylorSeer-HunyuanVideo.\n- Thanks to [Wan2.1](https://github.com/Wan-Video/Wan2.1) for their great work and codebase upon which we build TaylorSeer-Wan2.1.\n- Thanks to [ImageReward](https://github.com/THUDM/ImageReward) for Text-to-Image quality evaluation.\n- Thanks to [VBench](https://github.com/Vchitect/VBench) for Text-to-Video quality evaluation.\n\n\n## 📌 Citation\n",
    "ContentSha": "j4spOn6j9j6K+1441QrOXQV28NxAb0gvoZxPRt2rZOk=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "\n## TaylorSeer-FLUX\n\nTaylorSeer logró una compresión computacional sin pérdidas de 4.99 $\\times$ y una aceleración de latencia de 3.53 $\\times$ en FLUX.1-dev, medida por [ImageReward](https://github.com/THUDM/ImageReward) para calidad integral. Para ejecutar TaylorSeer-FLUX, consulte [TaylorSeer-FLUX](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-FLUX.md).\n\nAdemás, hemos proporcionado ejemplos de scripts de inferencia para la **versión diffusers**, así como scripts de inferencia paralela multi-GPU **xDiT**. También puede realizar pruebas basadas en ellos, ubicados en [TaylorSeers-Diffusers](./TaylorSeers-Diffusers ) y [TaylorSeers-xDiT](./TaylorSeers-xDiT) respectivamente.\n\n## TaylorSeer-HunyuanVideo\n\nTaylorSeer logró una compresión computacional de 5.00 $\\times$ y una notable aceleración de latencia de 4.65 $\\times$ en HunyuanVideo, medida integralmente por la métrica [VBench](https://github.com/Vchitect/VBench). En comparación con métodos anteriores, demostró mejoras significativas tanto en eficiencia de aceleración como en calidad. Para ejecutar TaylorSeer-HunyuanVideo, consulte [TaylorSeer-HunyuanVideo](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-HunyuanVideo.md).\n\nAdemás, nuestros scripts también soportan aceleración paralela multi-GPU implementada por HunyuanVideo usando xDiT. En este caso, el efecto de aceleración aportado por la caché y el efecto de aceleración del paralelismo multi-GPU son independientes entre sí y se multiplican, logrando efectos de aceleración extremadamente altos.\n\n## TayorSeer-DiT\n\nTaylorSeer logró una compresión computacional sin pérdidas de 2.77 $\\times$ en el modelo base DiT, evaluado integralmente por métricas como FID. Su rendimiento en varios ratios de aceleración superó significativamente a métodos anteriores. Por ejemplo, en un escenario extremo con una relación de compresión de 4.53 $\\times$, el FID de TaylorSeer solo aumentó 0.33 respecto a la línea base sin acelerar de 2.32, alcanzando 2.65, mientras que ToCa y DuCa exhibieron puntuaciones FID superiores a 6.0 bajo las mismas condiciones. Para ejecutar TaylorSeer-DiT, consulte [TaylorSeer-DiT](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-DiT.md).\n\n## TaylorSeer-Wan2.1\n\nImplementamos el método de aceleración TaylorSeer en Wan2.1, con soporte para inferencia paralela multi-GPU. Los comandos de instalación e inferencia para TaylorSeer-Wan2.1 son totalmente compatibles con los de Wan2.1. Para ejecutar TaylorSeer-Wan2.1, consulte [TaylorSeer-Wan2.1](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-Wan2.1.md).\n\n## TaylorSeer-HiDream\n\nEl modelo de generación de imágenes recientemente abierto **HiDream**, a pesar de su impresionante calidad de salida, enfrenta demandas crecientes de aceleración debido a su mayor tiempo de inferencia. Aplicamos **TaylorSeer** para acelerar la inferencia de HiDream, logrando una **reducción del 72% en el tiempo de ejecución**. Para más detalles, consulte [TaylorSeer-HiDream](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-HiDream.md).\n\n## 👍 Agradecimientos\n\n- Gracias a [DiT](https://github.com/facebookresearch/DiT) por su gran trabajo y base de código sobre la cual construimos TaylorSeer-DiT.\n- Gracias a [FLUX](https://github.com/black-forest-labs/flux) por su gran trabajo y base de código sobre la cual construimos TaylorSeer-FLUX.\n- Gracias a [HiDream](https://github.com/HiDream-ai/HiDream-I1) por su gran trabajo y base de código sobre la cual construimos TaylorSeer-HiDream.\n- Gracias a [HunyuanVideo](https://github.com/Tencent/HunyuanVideo) por su gran trabajo y base de código sobre la cual construimos TaylorSeer-HunyuanVideo.\n- Gracias a [Wan2.1](https://github.com/Wan-Video/Wan2.1) por su gran trabajo y base de código sobre la cual construimos TaylorSeer-Wan2.1.\n- Gracias a [ImageReward](https://github.com/THUDM/ImageReward) por la evaluación de calidad Texto-a-Imagen.\n- Gracias a [VBench](https://github.com/Vchitect/VBench) por la evaluación de calidad Texto-a-Video.\n\n\n## 📌 Citación\n\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 2,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "## TaylorSeer-FLUX"
      },
      {
        "row": 3,
        "rowsha": "L2TzcgjTuvv3I11CQ/GvH9lYRpj+s4SJYD9K/E2y5xU=",
        "originContent": "## TaylorSeer-FLUX",
        "translatedContent": ""
      },
      {
        "row": 4,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "TaylorSeer logró una compresión computacional sin pérdidas de 4.99 $\\times$ y una aceleración de latencia de 3.53 $\\times$ en FLUX.1-dev, medida por [ImageReward](https://github.com/THUDM/ImageReward) para calidad integral. Para ejecutar TaylorSeer-FLUX, consulte [TaylorSeer-FLUX](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-FLUX.md)."
      },
      {
        "row": 5,
        "rowsha": "chkx6Gc6ouZXsRcw0q01pp6iUgffxNIeRz+rDYu9/8g=",
        "originContent": "TaylorSeer achieved a lossless computational compression of 4.99 $\\times$ and a Latency Speedup of 3.53 $\\times$ on FLUX.1-dev, as measured by [ImageReward](https://github.com/THUDM/ImageReward) for comprehensive quality. To run TaylorSeer-FLUX, see [TaylorSeer-FLUX](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-FLUX.md).",
        "translatedContent": ""
      },
      {
        "row": 6,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "Además, hemos proporcionado ejemplos de scripts de inferencia para la **versión diffusers**, así como scripts de inferencia paralela multi-GPU **xDiT**. También puede realizar pruebas basadas en ellos, ubicados en [TaylorSeers-Diffusers](./TaylorSeers-Diffusers ) y [TaylorSeers-xDiT](./TaylorSeers-xDiT) respectivamente."
      },
      {
        "row": 7,
        "rowsha": "A6kLZqPZQw64dlrFOjpMypZsNMO14xJmlmpv3pw8ezs=",
        "originContent": "Besides, We have provided examples of inference scripts for the **diffusers version**, as well as multi-GPU parallel **xDiT inference scripts**. You can also conduct tests based on them, located at [TaylorSeers-Diffusers](./TaylorSeers-Diffusers ) and [TaylorSeers-xDiT](./TaylorSeers-xDiT) respectively.",
        "translatedContent": ""
      },
      {
        "row": 8,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "## TaylorSeer-HunyuanVideo"
      },
      {
        "row": 9,
        "rowsha": "TvDelfZTkkxA47gKZAdSw/WDfVwOxAFEDF0XiTfHVe4=",
        "originContent": "## TaylorSeer-HunyuanVideo",
        "translatedContent": ""
      },
      {
        "row": 10,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "TaylorSeer logró una compresión computacional de 5.00 $\\times$ y una notable aceleración de latencia de 4.65 $\\times$ en HunyuanVideo, medida integralmente por la métrica [VBench](https://github.com/Vchitect/VBench). En comparación con métodos anteriores, demostró mejoras significativas tanto en eficiencia de aceleración como en calidad. Para ejecutar TaylorSeer-HunyuanVideo, consulte [TaylorSeer-HunyuanVideo](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-HunyuanVideo.md)."
      },
      {
        "row": 11,
        "rowsha": "dvznffegIKSG4P+ItV8gb99Z1QttpWlLRDzlqMddPoI=",
        "originContent": "TaylorSeer achieved a computational compression of 5.00 $\\times$ and a remarkable Latency Speedup of 4.65 $\\times$ on HunyuanVideo, as comprehensively measured by the [VBench](https://github.com/Vchitect/VBench) metric. Compared to previous methods, it demonstrated significant improvements in both acceleration efficiency and quality. To run TaylorSeer-HunyuanVideo, see [TaylorSeer-HunyuanVideo](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-HunyuanVideo.md).",
        "translatedContent": ""
      },
      {
        "row": 12,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "Además, nuestros scripts también soportan aceleración paralela multi-GPU implementada por HunyuanVideo usando xDiT. En este caso, el efecto de aceleración aportado por la caché y el efecto de aceleración del paralelismo multi-GPU son independientes entre sí y se multiplican, logrando efectos de aceleración extremadamente altos."
      },
      {
        "row": 13,
        "rowsha": "Z3A/KHyeuxpEPv1W3z2nEo0Q6/Tl7PgTbK61vPvql+4=",
        "originContent": "In addition, our scripts also support multi-GPU parallel acceleration implemented by HunyuanVideo using xDiT. In this case, the acceleration effect brought by the cache and the acceleration effect of multi-GPU parallelism are independent of each other and multiply, achieving extremely high acceleration effects.",
        "translatedContent": ""
      },
      {
        "row": 14,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "## TayorSeer-DiT"
      },
      {
        "row": 15,
        "rowsha": "7Y5OqYcgEa7ffvscRZL+2h7W//4Wv8MkKo/KciYC+Is=",
        "originContent": "## TayorSeer-DiT",
        "translatedContent": ""
      },
      {
        "row": 16,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "TaylorSeer logró una compresión computacional sin pérdidas de 2.77 $\\times$ en el modelo base DiT, evaluado integralmente por métricas como FID. Su rendimiento en varios ratios de aceleración superó significativamente a métodos anteriores. Por ejemplo, en un escenario extremo con una relación de compresión de 4.53 $\\times$, el FID de TaylorSeer solo aumentó 0.33 respecto a la línea base sin acelerar de 2.32, alcanzando 2.65, mientras que ToCa y DuCa exhibieron puntuaciones FID superiores a 6.0 bajo las mismas condiciones. Para ejecutar TaylorSeer-DiT, consulte [TaylorSeer-DiT](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-DiT.md)."
      },
      {
        "row": 17,
        "rowsha": "jKbN9crC/lW32o3a4odXocjXPpUX4BRy6Px6c5/OADI=",
        "originContent": "TaylorSeer achieved a lossless computational compression of 2.77 $\\times$ on the base model DiT, as comprehensively evaluated by metrics such as FID. Its performance across various acceleration ratios significantly surpassed previous methods. For instance, in an extreme scenario with a 4.53 $\\times$ compression ratio, TaylorSeer's FID only increased by 0.33 from the non-accelerated baseline of 2.32, reaching 2.65, while ToCa and DuCa exhibited FID scores above 6.0 under the same conditions. To run TaylorSeer-DiT,see [TaylorSeer-DiT](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-DiT.md).",
        "translatedContent": ""
      },
      {
        "row": 18,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "## TaylorSeer-Wan2.1"
      },
      {
        "row": 19,
        "rowsha": "5DYFJIi4H43keQh/zs8HrC/0OvovNgdNRAgI1iPeXz4=",
        "originContent": "## TaylorSeer-Wan2.1",
        "translatedContent": ""
      },
      {
        "row": 20,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "Implementamos el método de aceleración TaylorSeer en Wan2.1, con soporte para inferencia paralela multi-GPU. Los comandos de instalación e inferencia para TaylorSeer-Wan2.1 son totalmente compatibles con los de Wan2.1. Para ejecutar TaylorSeer-Wan2.1, consulte [TaylorSeer-Wan2.1](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-Wan2.1.md)."
      },
      {
        "row": 21,
        "rowsha": "yw71nREC8h91wgq8ShsYXooL5pNuIYSukhKjsfMdofI=",
        "originContent": "We implemented the TaylorSeer acceleration method on Wan2.1, with support for multi-GPU parallel inference. The installation and inference commands for TaylorSeer-Wan2.1 are fully compatible with those of Wan2.1. To run TaylorSeer-Wan2.1, see [TaylorSeer-Wan2.1](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-Wan2.1.md).",
        "translatedContent": ""
      },
      {
        "row": 22,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "## TaylorSeer-HiDream"
      },
      {
        "row": 23,
        "rowsha": "S9sampwK6RNX9MCgwJoggioDY+17FhuB/kPyHb5UgxQ=",
        "originContent": "## TaylorSeer-HiDream",
        "translatedContent": ""
      },
      {
        "row": 24,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "El modelo de generación de imágenes recientemente abierto **HiDream**, a pesar de su impresionante calidad de salida, enfrenta demandas crecientes de aceleración debido a su mayor tiempo de inferencia. Aplicamos **TaylorSeer** para acelerar la inferencia de HiDream, logrando una **reducción del 72% en el tiempo de ejecución**. Para más detalles, consulte [TaylorSeer-HiDream](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-HiDream.md)."
      },
      {
        "row": 25,
        "rowsha": "NQ+OZmBUlgODN0R1c2zfq7AZz9G4P4M99o3RBv7xXRk=",
        "originContent": "The recently open-sourced image generation model **HiDream**, despite its impressive output quality, faces increasing demands for acceleration due to its longer inference time. We applied **TaylorSeer** to accelerate HiDream’s inference, achieving a **72% reduction in runtime**. For more details, see [TaylorSeer-HiDream](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-HiDream.md).",
        "translatedContent": ""
      },
      {
        "row": 26,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "## 👍 Agradecimientos"
      },
      {
        "row": 27,
        "rowsha": "u0Hxe1TnAcDLUJOZsTSfCbn/hsIWD27vYpN/fqVX6NY=",
        "originContent": "## 👍 Acknowledgements",
        "translatedContent": ""
      },
      {
        "row": 28,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "- Gracias a [DiT](https://github.com/facebookresearch/DiT) por su gran trabajo y base de código sobre la cual construimos TaylorSeer-DiT."
      },
      {
        "row": 29,
        "rowsha": "CMyznQjDV0UsyA0kRFrsBu46YX9RCtwQPWaz6kDw57w=",
        "originContent": "- Thanks to [DiT](https://github.com/facebookresearch/DiT) for their great work and codebase upon which we build TaylorSeer-DiT.",
        "translatedContent": "- Gracias a [FLUX](https://github.com/black-forest-labs/flux) por su gran trabajo y base de código sobre la cual construimos TaylorSeer-FLUX."
      },
      {
        "row": 30,
        "rowsha": "g/lnC2dBLYng5nlpIMvvux4+WxpFGTfff9SbzUWHVBQ=",
        "originContent": "- Thanks to [FLUX](https://github.com/black-forest-labs/flux) for their great work and codebase upon which we build TaylorSeer-FLUX.",
        "translatedContent": "- Gracias a [HiDream](https://github.com/HiDream-ai/HiDream-I1) por su gran trabajo y base de código sobre la cual construimos TaylorSeer-HiDream."
      },
      {
        "row": 31,
        "rowsha": "yuga1q5FZmOSqw1xc0FAfu7Lu5HXOyeKTvtX/Iw2da0=",
        "originContent": "- Thanks to [HiDream](https://github.com/HiDream-ai/HiDream-I1) for their great work and codebase upon which we build TaylorSeer-HiDream.",
        "translatedContent": "- Gracias a [HunyuanVideo](https://github.com/Tencent/HunyuanVideo) por su gran trabajo y base de código sobre la cual construimos TaylorSeer-HunyuanVideo."
      },
      {
        "row": 32,
        "rowsha": "FVkMzLsD/lLWDhQC+24S3sV+KYWrlNI6VWt9cXL8Wi4=",
        "originContent": "- Thanks to [HunyuanVideo](https://github.com/Tencent/HunyuanVideo) for their great work and codebase upon which we build TaylorSeer-HunyuanVideo.",
        "translatedContent": "- Gracias a [Wan2.1](https://github.com/Wan-Video/Wan2.1) por su gran trabajo y base de código sobre la cual construimos TaylorSeer-Wan2.1."
      },
      {
        "row": 33,
        "rowsha": "Eyj54ONx3tEFKlo9ycLBA5oO5Nl/y1cGnSKuJJlbEoY=",
        "originContent": "- Thanks to [Wan2.1](https://github.com/Wan-Video/Wan2.1) for their great work and codebase upon which we build TaylorSeer-Wan2.1.",
        "translatedContent": "- Gracias a [ImageReward](https://github.com/THUDM/ImageReward) por la evaluación de calidad Texto-a-Imagen."
      },
      {
        "row": 34,
        "rowsha": "GjsWMErOgzFsSLuXdW1YI/Y3mLGiO0y5QoT5y8zAKqQ=",
        "originContent": "- Thanks to [ImageReward](https://github.com/THUDM/ImageReward) for Text-to-Image quality evaluation.",
        "translatedContent": "- Gracias a [VBench](https://github.com/Vchitect/VBench) por la evaluación de calidad Texto-a-Video."
      },
      {
        "row": 35,
        "rowsha": "KlJSWNedKVvQL9mxodUIC4dZ1eBs/4O9za9u2hnJQp8=",
        "originContent": "- Thanks to [VBench](https://github.com/Vchitect/VBench) for Text-to-Video quality evaluation.",
        "translatedContent": ""
      },
      {
        "row": 36,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 37,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "## 📌 Citación"
      },
      {
        "row": 38,
        "rowsha": "A4soJLbZDJ5jsV21yB+YcMlje6BkPWiyME67jma7Kxo=",
        "originContent": "## 📌 Citation",
        "translatedContent": ""
      },
      {
        "row": 39,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 4,
    "Content": "```bibtex\n@article{TaylorSeer2025,\n  title={From Reusing to Forecasting: Accelerating Diffusion Models with TaylorSeers},\n  author={Liu, Jiacheng and Zou, Chang and Lyu, Yuanhuiyi and Chen, Junjie and Zhang, Linfeng},\n  journal={arXiv preprint arXiv:2503.06923},\n  year={2025}\n}\n```",
    "ContentSha": "fen2LVp21p8N9q/eae7nT9vcoFlYE3VN97IgBC75x9g=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bibtex\n@article{TaylorSeer2025,\n  title={From Reusing to Forecasting: Accelerating Diffusion Models with TaylorSeers},\n  author={Liu, Jiacheng and Zou, Chang and Lyu, Yuanhuiyi and Chen, Junjie and Zhang, Linfeng},\n  journal={arXiv preprint arXiv:2503.06923},\n  year={2025}\n}\n```",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "o+TmyQ6wneV6/FQB6aUlRSjIGr2/YLJtnz5uxBgsScQ=",
        "originContent": "```bibtex",
        "translatedContent": "```bibtex"
      },
      {
        "row": 2,
        "rowsha": "/ty4Z1XAwebEXbgzwWSaIIwNKg9g4LtzTihn1TP3w/o=",
        "originContent": "@article{TaylorSeer2025,",
        "translatedContent": "@article{TaylorSeer2025,"
      },
      {
        "row": 3,
        "rowsha": "o+GEpfSsb6+HkPZus7oKYmeYIa0sYGPChFIDFE7bKJY=",
        "originContent": "  title={From Reusing to Forecasting: Accelerating Diffusion Models with TaylorSeers},",
        "translatedContent": "  title={From Reusing to Forecasting: Accelerating Diffusion Models with TaylorSeers},"
      },
      {
        "row": 4,
        "rowsha": "9Nti1MS5YJh1jS6YOETdLSqimPafh+aTqXwIUL0aqvY=",
        "originContent": "  author={Liu, Jiacheng and Zou, Chang and Lyu, Yuanhuiyi and Chen, Junjie and Zhang, Linfeng},",
        "translatedContent": "  author={Liu, Jiacheng and Zou, Chang and Lyu, Yuanhuiyi and Chen, Junjie and Zhang, Linfeng},"
      },
      {
        "row": 5,
        "rowsha": "g/zic5erjOtHBZRc431Y3hZJDd8qGKo8zBOAc1c/nmA=",
        "originContent": "  journal={arXiv preprint arXiv:2503.06923},",
        "translatedContent": "  journal={arXiv preprint arXiv:2503.06923},"
      },
      {
        "row": 6,
        "rowsha": "6oyqJVJ20XoZhlyGjaewQyTQsSBBtVAYmqUtTwjLbAg=",
        "originContent": "  year={2025}",
        "translatedContent": "  year={2025}"
      },
      {
        "row": 7,
        "rowsha": "0Qs2qnSlm89KiBhYN/ZYr682Ru/yuxbDko0OkzXpRdI=",
        "originContent": "}",
        "translatedContent": "}"
      },
      {
        "row": 8,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      }
    ],
    "IsCodeBlock": true
  },
  {
    "Id": 5,
    "Content": "\n## :e-mail: Contact\n\nIf you have any questions, please email [`shenyizou@outlook.com`](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/mailto:shenyizou@outlook.com).\n\n",
    "ContentSha": "71xBxPlelSoIdJqUiI+RvDt6idhGFPOYbo/OlJNyPAU=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "\n## :e-mail: Contacto\n\nSi tiene alguna pregunta, por favor envíe un correo electrónico a [`shenyizou@outlook.com`](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/mailto:shenyizou@outlook.com).\n\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 2,
        "rowsha": "K5bAg1EjOpNN4wve36Z6v3sJb4XtaMFL5UG4PpfakXM=",
        "originContent": "## :e-mail: Contact",
        "translatedContent": "## :e-mail: Contacto"
      },
      {
        "row": 3,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 4,
        "rowsha": "+O5l7O4UKOwm22BlC1HWUnYRp176sGuJ1pgHlKEIMY4=",
        "originContent": "If you have any questions, please email [`shenyizou@outlook.com`](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/mailto:shenyizou@outlook.com).",
        "translatedContent": "Si tiene alguna pregunta, por favor envíe un correo electrónico a [`shenyizou@outlook.com`](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/mailto:shenyizou@outlook.com)."
      },
      {
        "row": 5,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 6,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  }
]