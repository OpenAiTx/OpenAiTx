[
  {
    "row": 1,
    "rowsha": "fagPb+qexaXZ3eHptDc4ivZK9kTnn6hX3OIFMxv7aKA=",
    "originContent": "<div align=center>",
    "translatedContent": "<div align=center>"
  },
  {
    "row": 2,
    "rowsha": "bBefIeb2K2KQVdirQPRU7QLki2hWORNHO4V9NjjiOyg=",
    "originContent": "  ",
    "translatedContent": "  "
  },
  {
    "row": 3,
    "rowsha": "MOtTqT65KO6UuOPpgVNTUNy7DBii0E9VU9QXzmbDlRo=",
    "originContent": "# [ICCV 2025] *TaylorSeer*: From Reusing to Forecasting: Accelerating Diffusion Models with *TaylorSeers*",
    "translatedContent": "# [ICCV 2025] *TaylorSeer*: 재사용에서 예측으로: *TaylorSeers*로 확산 모델 가속화"
  },
  {
    "row": 4,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 5,
    "rowsha": "M/J5lGcXcoeikmB4ChB6yY6mPdYWX2f8wNdHZ9CoIJA=",
    "originContent": "<p>",
    "translatedContent": "<p>"
  },
  {
    "row": 6,
    "rowsha": "mz6OHfHOKolNYRAUj7PcksyTTRde9MDQh/L+SZDoFfo=",
    "originContent": "<a href='https://arxiv.org/abs/2503.06923'><img src='https://img.shields.io/badge/Paper-arXiv-red'></a>",
    "translatedContent": "<a href='https://arxiv.org/abs/2503.06923'><img src='https://img.shields.io/badge/Paper-arXiv-red'></a>"
  },
  {
    "row": 7,
    "rowsha": "s05rwhJ5NOYGsjO9U5kI5HYTz2AEGGz9Fbptc/Pug9c=",
    "originContent": "<a href='https://taylorseer.github.io/TaylorSeer/'><img src='https://img.shields.io/badge/Project-Page-blue'></a>",
    "translatedContent": "<a href='https://taylorseer.github.io/TaylorSeer/'><img src='https://img.shields.io/badge/Project-Page-blue'></a>"
  },
  {
    "row": 8,
    "rowsha": "dSdvPNAZSmR86FDDSF6tkQUCVfI9qmACHOR5tThOetY=",
    "originContent": "</p>",
    "translatedContent": "</p>"
  },
  {
    "row": 9,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 10,
    "rowsha": "qsMmUbEPVnxGG5tPJV1vsfpoWbU2jYvZpRr5IKshzyM=",
    "originContent": "</div>",
    "translatedContent": "</div>"
  },
  {
    "row": 11,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 12,
    "rowsha": "D7bG/VBJXSi2hpB980ek7pr4pjcctcRkfLZHbhVcyVg=",
    "originContent": "## 🔥 News",
    "translatedContent": "## 🔥 뉴스"
  },
  {
    "row": 13,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 14,
    "rowsha": "4+OZ9EqFu/vmVQzOQg6e3fSByT5AG7kgw0p/8ZZtXvg=",
    "originContent": "* `2025/06/26` 💥💥 TaylorSeer is honored to be accepted by ICCV 2025!",
    "translatedContent": "* `2025/06/26` 💥💥 TaylorSeer가 ICCV 2025에 채택되어 영광입니다!"
  },
  {
    "row": 15,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 16,
    "rowsha": "nWHnk9X5bw0hFy3WJgq/jX5Go8T0fpLu1GZwDSTAXQ4=",
    "originContent": "* `2025/05/03` 🚀🚀 TaylorSeer for HiDream is released.",
    "translatedContent": "* `2025/05/03` 🚀🚀 HiDream용 TaylorSeer가 출시되었습니다."
  },
  {
    "row": 17,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 18,
    "rowsha": "nkoB/ObNg2vVPOSBVJEmU88VVwnAhcgFXCZqkw1bSY0=",
    "originContent": "* `2025/03/30` 🚀🚀 TaylorSeer for Wan2.1 is released.",
    "translatedContent": "* `2025/03/30` 🚀🚀 Wan2.1용 TaylorSeer가 출시되었습니다."
  },
  {
    "row": 19,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 20,
    "rowsha": "3NpXU50QD+KRAHj2dNcg+rCjixMNdTA/nGF1u6E0oe0=",
    "originContent": "* `2025/03/30` 🚀🚀 The Diffusers inference scripts for TaylorSeers and the xDiT scripts applicable for multi-GPU parallel inference have been officially released.",
    "translatedContent": "* `2025/03/30` 🚀🚀 TaylorSeers용 Diffusers 추론 스크립트와 멀티 GPU 병렬 추론에 적용 가능한 xDiT 스크립트가 공식 출시되었습니다."
  },
  {
    "row": 21,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 22,
    "rowsha": "9NG8DDgu4GTSLg6UyU6J2MUqXFt01vZBE1vkyAWpvuo=",
    "originContent": "* `2025/03/10` 🚀🚀 Our latest work \"From Reusing to Forecasting: Accelerating Diffusion Models with TaylorSeers\" is released! Codes are available at [TaylorSeer](https://github.com/Shenyi-Z/TaylorSeer)! TaylorSeer supports lossless compression at a rate of 4.99x on FLUX.1-dev (with a latency speedup of 3.53x) and high-quality acceleration at a compression rate of 5.00x on HunyuanVideo (with a latency speedup of 4.65x)! We hope *TaylorSeer* can move the paradigm of feature caching methods from reusing to forecasting.For more details, please refer to our latest research paper.",
    "translatedContent": "* `2025/03/10` 🚀🚀 최신 연구 \"재사용에서 예측으로: TaylorSeers로 확산 모델 가속화\"가 발표되었습니다! 코드는 [TaylorSeer](https://github.com/Shenyi-Z/TaylorSeer)에서 확인 가능합니다! TaylorSeer는 FLUX.1-dev에서 4.99배 무손실 압축(지연 시간 3.53배 가속)과 HunyuanVideo에서 5.00배 압축률의 고품질 가속(지연 시간 4.65배 가속)을 지원합니다! *TaylorSeer*가 기능 캐싱 방법의 패러다임을 재사용에서 예측으로 전환할 수 있길 기대합니다. 자세한 내용은 최신 연구 논문을 참고해주세요."
  },
  {
    "row": 23,
    "rowsha": "HP4JYN9AqV5x9xftKuxud6Lmj5FbX6yZVjvsYTmL3X4=",
    "originContent": "* `2025/02/19` 🚀🚀 ToCa solution for **FLUX** has been officially released after adjustments, now achieving up to **3.14× lossless acceleration** (in FLOPs)!",
    "translatedContent": "* `2025/02/19` 🚀🚀 **FLUX**용 ToCa 솔루션이 조정 후 공식 출시되어 최대 **3.14× 무손실 가속**(FLOPs 기준)을 달성했습니다!"
  },
  {
    "row": 24,
    "rowsha": "OUJy4nRS5cJZhTQ/bIHSb7tR3CPpzmEdfy9FQsPvkKY=",
    "originContent": "* `2025/01/22` 💥💥 ToCa is honored to be accepted by ICLR 2025!",
    "translatedContent": "* `2025/01/22` 💥💥 ToCa가 ICLR 2025에 채택되어 영광입니다!"
  },
  {
    "row": 25,
    "rowsha": "JP7Uqbgmmu3w73rzXhFcbs+DuZhRhuwWmv0rp0Z8zBQ=",
    "originContent": "* `2024/12/29` 🚀🚀 We release our work [DuCa](https://arxiv.org/abs/2412.18911) about accelerating diffusion transformers for FREE, which achieves nearly lossless acceleration of **2.50×** on [OpenSora](https://github.com/hpcaitech/Open-Sora)! 🎉 **DuCa also overcomes the limitation of ToCa by fully supporting FlashAttention, enabling broader compatibility and efficiency improvements.**",
    "translatedContent": "* `2024/12/29` 🚀🚀 확산 변환기 가속을 위한 연구 [DuCa](https://arxiv.org/abs/2412.18911)를 무료로 공개했습니다. OpenSora에서 거의 무손실 가속 **2.50×**를 달성했습니다! 🎉 **DuCa는 FlashAttention을 완전히 지원하여 ToCa의 한계를 극복하고 호환성과 효율성을 넓혔습니다.**"
  },
  {
    "row": 26,
    "rowsha": "76EiBVgv/EgSTVYsjHggBTygkeo1yu7OIgVRvPD3Ixs=",
    "originContent": "* `2024/12/24` 🤗🤗 We release an open-sourse repo \"[Awesome-Token-Reduction-for-Model-Compression](https://github.com/xuyang-liu16/Awesome-Token-Reduction-for-Model-Compression)\", which collects recent awesome token reduction papers! Feel free to contribute your suggestions!",
    "translatedContent": "* `2024/12/24` 🤗🤗 최신 우수 토큰 축소 논문들을 모은 오픈소스 \"[Awesome-Token-Reduction-for-Model-Compression](https://github.com/xuyang-liu16/Awesome-Token-Reduction-for-Model-Compression)\" 저장소를 공개했습니다! 여러분의 제안도 환영합니다!"
  },
  {
    "row": 27,
    "rowsha": "/8zh2xS0BXOpvQxdWqtvtS7GCz9dpRDj/KNLKaArh/s=",
    "originContent": "* `2024/12/10` 💥💥 Our team's recent work, **SiTo** (https://github.com/EvelynZhang-epiclab/SiTo), has been accepted to **AAAI 2025**. It accelerates diffusion models through adaptive **Token Pruning**.",
    "translatedContent": "* `2024/12/10` 💥💥 우리 팀의 최신 연구 **SiTo** (https://github.com/EvelynZhang-epiclab/SiTo)가 **AAAI 2025**에 채택되었습니다. 적응형 **토큰 프루닝**을 통해 확산 모델을 가속합니다."
  },
  {
    "row": 28,
    "rowsha": "O7eC1AedMiPQpbcvrbKc4glnjZa6qtgwQDRRhUGn+1w=",
    "originContent": "* `2024/07/15` 🤗🤗 We release an open-sourse repo \"[Awesome-Generation-Acceleration](https://github.com/xuyang-liu16/Awesome-Generation-Acceleration)\", which collects recent awesome generation accleration papers! Feel free to contribute your suggestions!",
    "translatedContent": "* `2024/07/15` 🤗🤗 최신 우수 생성 가속 논문들을 모은 오픈소스 \"[Awesome-Generation-Acceleration](https://github.com/xuyang-liu16/Awesome-Generation-Acceleration)\" 저장소를 공개했습니다! 여러분의 제안도 환영합니다!"
  },
  {
    "row": 29,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 30,
    "rowsha": "U8eO5ZMev1PH3G030/YyNbNyaS1S4k9n5Of/5MkmvMU=",
    "originContent": "<details>",
    "translatedContent": "<details>"
  },
  {
    "row": 31,
    "rowsha": "qLx6Z+0MU0Auz7F41A3Jc4dR+cSkzESO1JVS8/SKcDc=",
    "originContent": "  <summary><strong>Abstract</strong></summary>",
    "translatedContent": "  <summary><strong>초록</strong></summary>"
  },
  {
    "row": 32,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 33,
    "rowsha": "YIqf7kN0c/54TcKx6d15MTu4MoUYVK2v7TZvknoQpw4=",
    "originContent": "  Diffusion Transformers (DiT) have revolutionized high-fidelity image and video synthesis, yet their computational demands remain prohibitive for real-time applications. To solve this problem, feature caching has been proposed to accelerate diffusion models by caching the features in the previous timesteps and then reusing them in the following timesteps. However, at timesteps with significant intervals, the feature similarity in diffusion models decreases substantially, leading to a pronounced increase in errors introduced by feature caching, significantly harming the generation quality. To solve this problem, we propose TaylorSeer, which firstly shows that features of diffusion models at future timesteps can be predicted based on their values at previous timesteps. Based on the fact that features change slowly and continuously across timesteps, TaylorSeer employs a differential method to approximate the higher-order derivatives of features and predict features in future timesteps with Taylor series expansion. Extensive experiments demonstrate its significant effectiveness in both image and video synthesis, especially in high acceleration ratios. For instance, it achieves an almost lossless acceleration of 4.99 $\\times$ on FLUX and 5.00 $\\times$ on HunyuanVideo without additional training. On DiT, it achieves $3.41$ lower FID compared with previous SOTA at $4.53$ $\\times$ acceleration.",
    "translatedContent": "  확산 변환기(DiT)는 고화질 이미지 및 비디오 합성을 혁신했지만, 실시간 적용에는 계산 비용이 매우 높습니다. 이를 해결하기 위해, 이전 타임스텝의 특징을 캐싱하고 이후 타임스텝에서 재사용하는 특징 캐싱 방법이 제안되었습니다. 그러나 간격이 큰 타임스텝에서는 확산 모델 내 특징 유사도가 크게 감소하여, 특징 캐싱으로 인한 오차가 크게 증가하고 생성 품질이 심각하게 저하됩니다. 이를 해결하기 위해, 우리는 미래 타임스텝의 확산 모델 특징을 이전 타임스텝 값 기반으로 예측할 수 있음을 보여주는 TaylorSeer를 제안합니다. 특징이 타임스텝 간 천천히 연속적으로 변화한다는 사실에 기반해, TaylorSeer는 미분 방법을 사용해 특징의 고차 도함수를 근사하고 Taylor 급수 전개로 미래 타임스텝의 특징을 예측합니다. 광범위한 실험에서 이미지 및 비디오 합성에서 특히 높은 가속 비율에서 뛰어난 효과를 입증했습니다. 예를 들어, 추가 훈련 없이 FLUX에서 4.99배 거의 무손실 가속, HunyuanVideo에서 5.00배 가속을 달성했습니다. DiT에서는 이전 SOTA 대비 4.53배 가속 시 $3.41$ 낮은 FID를 기록했습니다."
  },
  {
    "row": 34,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 35,
    "rowsha": "iKxEwaqPw8IiEEWQ6czEzAvKi1nrFO/wqlPbG+tChcM=",
    "originContent": "</details>",
    "translatedContent": "</details>"
  },
  {
    "row": 36,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 37,
    "rowsha": "vVMKG86X38wpzVR64MO4O04P+r93zrGe0ew8fB75VJE=",
    "originContent": "## 🧩 Community Contributions",
    "translatedContent": "## 🧩 커뮤니티 기여"
  },
  {
    "row": 38,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 39,
    "rowsha": "NhqQVhWscK75IALoDKNa+hzMcIiPuhqHLJjuDbSctMA=",
    "originContent": "Thanks to all the open-source contributors for their strong support! We’d love to hear from you!",
    "translatedContent": "강력한 지원을 해주신 모든 오픈소스 기여자분들께 감사드립니다! 여러분의 의견을 기다립니다!"
  },
  {
    "row": 40,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 41,
    "rowsha": "woBL8XbSNmvsJez4Ev755tcLFMQBHiYdzCnwQ4Dm+lo=",
    "originContent": "* ComfyUI-TaylorSeer-philipy1219 (FP8 Inference on FLUX, more video models coming): [ComfyUI-TaylorSeer-philipy1219](https://github.com/philipy1219/ComfyUI-TaylorSeer) by [philipy1219](https://github.com/philipy1219).",
    "translatedContent": "* ComfyUI-TaylorSeer-philipy1219 (FLUX에서 FP8 추론, 더 많은 비디오 모델 예정): [ComfyUI-TaylorSeer-philipy1219](https://github.com/philipy1219/ComfyUI-TaylorSeer) by [philipy1219](https://github.com/philipy1219)."
  },
  {
    "row": 42,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 43,
    "rowsha": "Uib95QyFy+G2xAAPKyoC5mR8MEqKhXKN6jTjMNlQ47w=",
    "originContent": "## 🛠 Installation",
    "translatedContent": "## 🛠 설치"
  },
  {
    "row": 44,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 45,
    "rowsha": "m+Ye/ZAlgvAp+ebS8N9WTXZep69SFbfwiK0O7Et0+Ro=",
    "originContent": "``` cmd",
    "translatedContent": "``` cmd"
  },
  {
    "row": 46,
    "rowsha": "cS+FAoCjHksjXqzHsY5NCYms9p+hgMbt55zlSipAEdM=",
    "originContent": "git clone https://github.com/Shenyi-Z/TaylorSeer.git",
    "translatedContent": "git clone https://github.com/Shenyi-Z/TaylorSeer.git"
  },
  {
    "row": 47,
    "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
    "originContent": "```",
    "translatedContent": "```"
  },
  {
    "row": 48,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "## TaylorSeer-FLUX"
  },
  {
    "row": 49,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 50,
    "rowsha": "L2TzcgjTuvv3I11CQ/GvH9lYRpj+s4SJYD9K/E2y5xU=",
    "originContent": "## TaylorSeer-FLUX",
    "translatedContent": "TaylorSeer는 FLUX.1-dev에서 4.99배의 무손실 연산 압축과 3.53배의 지연 시간 속도 향상을 달성했으며, 이는 종합 품질 평가를 위한 [ImageReward](https://github.com/THUDM/ImageReward)에 의해 측정되었습니다. TaylorSeer-FLUX 실행 방법은 [TaylorSeer-FLUX](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-FLUX.md)를 참조하세요."
  },
  {
    "row": 51,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 52,
    "rowsha": "chkx6Gc6ouZXsRcw0q01pp6iUgffxNIeRz+rDYu9/8g=",
    "originContent": "TaylorSeer achieved a lossless computational compression of 4.99 $\\times$ and a Latency Speedup of 3.53 $\\times$ on FLUX.1-dev, as measured by [ImageReward](https://github.com/THUDM/ImageReward) for comprehensive quality. To run TaylorSeer-FLUX, see [TaylorSeer-FLUX](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-FLUX.md).",
    "translatedContent": "또한, **diffusers 버전**에 대한 추론 스크립트 예제와 다중 GPU 병렬 **xDiT 추론 스크립트**도 제공하고 있습니다. 각각 [TaylorSeers-Diffusers](./TaylorSeers-Diffusers)와 [TaylorSeers-xDiT](./TaylorSeers-xDiT)에서 기반으로 테스트를 진행할 수 있습니다."
  },
  {
    "row": 53,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 54,
    "rowsha": "A6kLZqPZQw64dlrFOjpMypZsNMO14xJmlmpv3pw8ezs=",
    "originContent": "Besides, We have provided examples of inference scripts for the **diffusers version**, as well as multi-GPU parallel **xDiT inference scripts**. You can also conduct tests based on them, located at [TaylorSeers-Diffusers](./TaylorSeers-Diffusers ) and [TaylorSeers-xDiT](./TaylorSeers-xDiT) respectively.",
    "translatedContent": "## TaylorSeer-HunyuanVideo"
  },
  {
    "row": 55,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 56,
    "rowsha": "TvDelfZTkkxA47gKZAdSw/WDfVwOxAFEDF0XiTfHVe4=",
    "originContent": "## TaylorSeer-HunyuanVideo",
    "translatedContent": "TaylorSeer는 HunyuanVideo에서 5.00배의 연산 압축과 4.65배의 놀라운 지연 시간 속도 향상을 달성했으며, 이는 [VBench](https://github.com/Vchitect/VBench) 지표로 종합 평가되었습니다. 기존 방법들과 비교하여 가속 효율과 품질 모두에서 크게 향상된 결과를 보여주었습니다. TaylorSeer-HunyuanVideo 실행 방법은 [TaylorSeer-HunyuanVideo](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-HunyuanVideo.md)를 참조하세요."
  },
  {
    "row": 57,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 58,
    "rowsha": "dvznffegIKSG4P+ItV8gb99Z1QttpWlLRDzlqMddPoI=",
    "originContent": "TaylorSeer achieved a computational compression of 5.00 $\\times$ and a remarkable Latency Speedup of 4.65 $\\times$ on HunyuanVideo, as comprehensively measured by the [VBench](https://github.com/Vchitect/VBench) metric. Compared to previous methods, it demonstrated significant improvements in both acceleration efficiency and quality. To run TaylorSeer-HunyuanVideo, see [TaylorSeer-HunyuanVideo](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-HunyuanVideo.md).",
    "translatedContent": "추가로, 당사의 스크립트는 HunyuanVideo가 xDiT를 이용해 구현한 다중 GPU 병렬 가속도 지원합니다. 이 경우, 캐시로 인한 가속 효과와 다중 GPU 병렬 가속 효과는 서로 독립적이며 곱해져 매우 높은 가속 효과를 달성합니다."
  },
  {
    "row": 59,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 60,
    "rowsha": "Z3A/KHyeuxpEPv1W3z2nEo0Q6/Tl7PgTbK61vPvql+4=",
    "originContent": "In addition, our scripts also support multi-GPU parallel acceleration implemented by HunyuanVideo using xDiT. In this case, the acceleration effect brought by the cache and the acceleration effect of multi-GPU parallelism are independent of each other and multiply, achieving extremely high acceleration effects.",
    "translatedContent": "## TayorSeer-DiT"
  },
  {
    "row": 61,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 62,
    "rowsha": "7Y5OqYcgEa7ffvscRZL+2h7W//4Wv8MkKo/KciYC+Is=",
    "originContent": "## TayorSeer-DiT",
    "translatedContent": "TaylorSeer는 기본 모델 DiT에서 2.77배의 무손실 연산 압축을 달성했으며, FID 등 다양한 지표로 종합 평가되었습니다. 여러 가속 비율에서의 성능이 기존 방법들을 크게 능가했습니다. 예를 들어, 4.53배 압축이라는 극한 상황에서 TaylorSeer의 FID는 비가속 기준 2.32에서 0.33만 증가한 2.65를 기록한 반면, ToCa와 DuCa는 동일 조건에서 FID가 6.0 이상을 기록했습니다. TaylorSeer-DiT 실행 방법은 [TaylorSeer-DiT](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-DiT.md)를 참조하세요."
  },
  {
    "row": 63,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 64,
    "rowsha": "jKbN9crC/lW32o3a4odXocjXPpUX4BRy6Px6c5/OADI=",
    "originContent": "TaylorSeer achieved a lossless computational compression of 2.77 $\\times$ on the base model DiT, as comprehensively evaluated by metrics such as FID. Its performance across various acceleration ratios significantly surpassed previous methods. For instance, in an extreme scenario with a 4.53 $\\times$ compression ratio, TaylorSeer's FID only increased by 0.33 from the non-accelerated baseline of 2.32, reaching 2.65, while ToCa and DuCa exhibited FID scores above 6.0 under the same conditions. To run TaylorSeer-DiT,see [TaylorSeer-DiT](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-DiT.md).",
    "translatedContent": "## TaylorSeer-Wan2.1"
  },
  {
    "row": 65,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 66,
    "rowsha": "5DYFJIi4H43keQh/zs8HrC/0OvovNgdNRAgI1iPeXz4=",
    "originContent": "## TaylorSeer-Wan2.1",
    "translatedContent": "TaylorSeer 가속 방법을 Wan2.1에 구현했으며, 다중 GPU 병렬 추론을 지원합니다. TaylorSeer-Wan2.1의 설치 및 추론 명령어는 Wan2.1과 완전히 호환됩니다. TaylorSeer-Wan2.1 실행 방법은 [TaylorSeer-Wan2.1](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-Wan2.1.md)를 참조하세요."
  },
  {
    "row": 67,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 68,
    "rowsha": "yw71nREC8h91wgq8ShsYXooL5pNuIYSukhKjsfMdofI=",
    "originContent": "We implemented the TaylorSeer acceleration method on Wan2.1, with support for multi-GPU parallel inference. The installation and inference commands for TaylorSeer-Wan2.1 are fully compatible with those of Wan2.1. To run TaylorSeer-Wan2.1, see [TaylorSeer-Wan2.1](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-Wan2.1.md).",
    "translatedContent": "## TaylorSeer-HiDream"
  },
  {
    "row": 69,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 70,
    "rowsha": "S9sampwK6RNX9MCgwJoggioDY+17FhuB/kPyHb5UgxQ=",
    "originContent": "## TaylorSeer-HiDream",
    "translatedContent": "최근 오픈소스된 이미지 생성 모델 **HiDream**은 뛰어난 출력 품질에도 불구하고 긴 추론 시간으로 인해 가속 요구가 증가하고 있습니다. 우리는 **TaylorSeer**를 적용해 HiDream 추론을 가속화하여 **72%의 실행 시간 감소**를 달성했습니다. 자세한 내용은 [TaylorSeer-HiDream](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-HiDream.md)를 참조하세요."
  },
  {
    "row": 71,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 72,
    "rowsha": "NQ+OZmBUlgODN0R1c2zfq7AZz9G4P4M99o3RBv7xXRk=",
    "originContent": "The recently open-sourced image generation model **HiDream**, despite its impressive output quality, faces increasing demands for acceleration due to its longer inference time. We applied **TaylorSeer** to accelerate HiDream’s inference, achieving a **72% reduction in runtime**. For more details, see [TaylorSeer-HiDream](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-HiDream.md).",
    "translatedContent": "## 👍 감사의 글"
  },
  {
    "row": 73,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 74,
    "rowsha": "u0Hxe1TnAcDLUJOZsTSfCbn/hsIWD27vYpN/fqVX6NY=",
    "originContent": "## 👍 Acknowledgements",
    "translatedContent": "- TaylorSeer-DiT를 구축하는 데 기반이 된 훌륭한 작업과 코드베이스를 제공한 [DiT](https://github.com/facebookresearch/DiT) 팀에 감사드립니다."
  },
  {
    "row": 75,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "- TaylorSeer-FLUX를 구축하는 데 기반이 된 훌륭한 작업과 코드베이스를 제공한 [FLUX](https://github.com/black-forest-labs/flux) 팀에 감사드립니다."
  },
  {
    "row": 76,
    "rowsha": "CMyznQjDV0UsyA0kRFrsBu46YX9RCtwQPWaz6kDw57w=",
    "originContent": "- Thanks to [DiT](https://github.com/facebookresearch/DiT) for their great work and codebase upon which we build TaylorSeer-DiT.",
    "translatedContent": "- TaylorSeer-HiDream를 구축하는 데 기반이 된 훌륭한 작업과 코드베이스를 제공한 [HiDream](https://github.com/HiDream-ai/HiDream-I1) 팀에 감사드립니다."
  },
  {
    "row": 77,
    "rowsha": "g/lnC2dBLYng5nlpIMvvux4+WxpFGTfff9SbzUWHVBQ=",
    "originContent": "- Thanks to [FLUX](https://github.com/black-forest-labs/flux) for their great work and codebase upon which we build TaylorSeer-FLUX.",
    "translatedContent": "- TaylorSeer-HunyuanVideo를 구축하는 데 기반이 된 훌륭한 작업과 코드베이스를 제공한 [HunyuanVideo](https://github.com/Tencent/HunyuanVideo) 팀에 감사드립니다."
  },
  {
    "row": 78,
    "rowsha": "yuga1q5FZmOSqw1xc0FAfu7Lu5HXOyeKTvtX/Iw2da0=",
    "originContent": "- Thanks to [HiDream](https://github.com/HiDream-ai/HiDream-I1) for their great work and codebase upon which we build TaylorSeer-HiDream.",
    "translatedContent": "- TaylorSeer-Wan2.1을 구축하는 데 기반이 된 훌륭한 작업과 코드베이스를 제공한 [Wan2.1](https://github.com/Wan-Video/Wan2.1) 팀에 감사드립니다."
  },
  {
    "row": 79,
    "rowsha": "FVkMzLsD/lLWDhQC+24S3sV+KYWrlNI6VWt9cXL8Wi4=",
    "originContent": "- Thanks to [HunyuanVideo](https://github.com/Tencent/HunyuanVideo) for their great work and codebase upon which we build TaylorSeer-HunyuanVideo.",
    "translatedContent": "- 텍스트-투-이미지 품질 평가를 위한 [ImageReward](https://github.com/THUDM/ImageReward)에 감사드립니다."
  },
  {
    "row": 80,
    "rowsha": "Eyj54ONx3tEFKlo9ycLBA5oO5Nl/y1cGnSKuJJlbEoY=",
    "originContent": "- Thanks to [Wan2.1](https://github.com/Wan-Video/Wan2.1) for their great work and codebase upon which we build TaylorSeer-Wan2.1.",
    "translatedContent": "- 텍스트-투-비디오 품질 평가를 위한 [VBench](https://github.com/Vchitect/VBench)에 감사드립니다."
  },
  {
    "row": 81,
    "rowsha": "GjsWMErOgzFsSLuXdW1YI/Y3mLGiO0y5QoT5y8zAKqQ=",
    "originContent": "- Thanks to [ImageReward](https://github.com/THUDM/ImageReward) for Text-to-Image quality evaluation.",
    "translatedContent": ""
  },
  {
    "row": 82,
    "rowsha": "KlJSWNedKVvQL9mxodUIC4dZ1eBs/4O9za9u2hnJQp8=",
    "originContent": "- Thanks to [VBench](https://github.com/Vchitect/VBench) for Text-to-Video quality evaluation.",
    "translatedContent": ""
  },
  {
    "row": 83,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "## 📌 인용문헌"
  },
  {
    "row": 84,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 85,
    "rowsha": "A4soJLbZDJ5jsV21yB+YcMlje6BkPWiyME67jma7Kxo=",
    "originContent": "## 📌 Citation",
    "translatedContent": ""
  },
  {
    "row": 86,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 87,
    "rowsha": "o+TmyQ6wneV6/FQB6aUlRSjIGr2/YLJtnz5uxBgsScQ=",
    "originContent": "```bibtex",
    "translatedContent": "```bibtex"
  },
  {
    "row": 88,
    "rowsha": "/ty4Z1XAwebEXbgzwWSaIIwNKg9g4LtzTihn1TP3w/o=",
    "originContent": "@article{TaylorSeer2025,",
    "translatedContent": "@article{TaylorSeer2025,"
  },
  {
    "row": 89,
    "rowsha": "o+GEpfSsb6+HkPZus7oKYmeYIa0sYGPChFIDFE7bKJY=",
    "originContent": "  title={From Reusing to Forecasting: Accelerating Diffusion Models with TaylorSeers},",
    "translatedContent": "  title={From Reusing to Forecasting: Accelerating Diffusion Models with TaylorSeers},"
  },
  {
    "row": 90,
    "rowsha": "9Nti1MS5YJh1jS6YOETdLSqimPafh+aTqXwIUL0aqvY=",
    "originContent": "  author={Liu, Jiacheng and Zou, Chang and Lyu, Yuanhuiyi and Chen, Junjie and Zhang, Linfeng},",
    "translatedContent": "  author={Liu, Jiacheng and Zou, Chang and Lyu, Yuanhuiyi and Chen, Junjie and Zhang, Linfeng},"
  },
  {
    "row": 91,
    "rowsha": "g/zic5erjOtHBZRc431Y3hZJDd8qGKo8zBOAc1c/nmA=",
    "originContent": "  journal={arXiv preprint arXiv:2503.06923},",
    "translatedContent": "  journal={arXiv preprint arXiv:2503.06923},"
  },
  {
    "row": 92,
    "rowsha": "6oyqJVJ20XoZhlyGjaewQyTQsSBBtVAYmqUtTwjLbAg=",
    "originContent": "  year={2025}",
    "translatedContent": "  year={2025}"
  },
  {
    "row": 93,
    "rowsha": "0Qs2qnSlm89KiBhYN/ZYr682Ru/yuxbDko0OkzXpRdI=",
    "originContent": "}",
    "translatedContent": "}"
  },
  {
    "row": 94,
    "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
    "originContent": "```",
    "translatedContent": "```"
  },
  {
    "row": 95,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 96,
    "rowsha": "K5bAg1EjOpNN4wve36Z6v3sJb4XtaMFL5UG4PpfakXM=",
    "originContent": "## :e-mail: Contact",
    "translatedContent": "## :e-mail: 연락처"
  },
  {
    "row": 97,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 98,
    "rowsha": "+O5l7O4UKOwm22BlC1HWUnYRp176sGuJ1pgHlKEIMY4=",
    "originContent": "If you have any questions, please email [`shenyizou@outlook.com`](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/mailto:shenyizou@outlook.com).",
    "translatedContent": "질문이 있으시면, [`shenyizou@outlook.com`](https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/mailto:shenyizou@outlook.com)으로 이메일을 보내주세요."
  },
  {
    "row": 99,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 100,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  }
]