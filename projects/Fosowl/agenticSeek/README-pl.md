# AgenticSeek: Prywatna, lokalna alternatywa dla Manus

<p align="center">
<img align="center" src="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/media/agentic_seek_logo.png" width="300" height="300" alt="Agentic Seek Logo">
<p>

  English | [ä¸­æ–‡](https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_CHS.md) | [ç¹é«”ä¸­æ–‡](https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_CHT.md) | [FranÃ§ais](https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_FR.md) | [æ—¥æœ¬èª](https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_JP.md) | [PortuguÃªs (Brasil)](https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_PTBR.md) | [EspaÃ±ol](https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_ES.md)

*W peÅ‚ni **lokalna alternatywa dla Manus AI** â€“ ten asystent AI z obsÅ‚ugÄ… gÅ‚osu autonomicznie przeglÄ…da internet, pisze kod i planuje zadania, zachowujÄ…c wszystkie dane na Twoim urzÄ…dzeniu. Dostosowany do lokalnych modeli rozumowania, dziaÅ‚a caÅ‚kowicie na Twoim sprzÄ™cie, zapewniajÄ…c peÅ‚nÄ… prywatnoÅ›Ä‡ i brak zaleÅ¼noÅ›ci od chmury.*

[![OdwiedÅº AgenticSeek](https://img.shields.io/static/v1?label=Website&message=AgenticSeek&color=blue&style=flat-square)](https://fosowl.github.io/agenticSeek.html) ![License](https://img.shields.io/badge/license-GPL--3.0-green) [![Discord](https://img.shields.io/badge/Discord-Join%20Us-7289DA?logo=discord&logoColor=white)](https://discord.gg/8hGDaME3TC) [![Twitter](https://img.shields.io/twitter/url/https/twitter.com/fosowl.svg?style=social&label=Update%20%40Fosowl)](https://x.com/Martin993886460) [![GitHub stars](https://img.shields.io/github/stars/Fosowl/agenticSeek?style=social)](https://github.com/Fosowl/agenticSeek/stargazers)

### Dlaczego AgenticSeek?

* ğŸ”’ W peÅ‚ni lokalny i prywatny â€“ Wszystko dziaÅ‚a na Twoim komputerze â€” bez chmury, bez udostÄ™pniania danych. Twoje pliki, rozmowy i wyszukiwania pozostajÄ… prywatne.

* ğŸŒ Inteligentne przeglÄ…danie sieci â€“ AgenticSeek moÅ¼e samodzielnie przeglÄ…daÄ‡ internet â€” wyszukiwaÄ‡, czytaÄ‡, wyodrÄ™bniaÄ‡ informacje, wypeÅ‚niaÄ‡ formularze â€” wszystko bez uÅ¼ycia rÄ…k.

* ğŸ’» Autonomiczny asystent kodowania â€“ Potrzebujesz kodu? MoÅ¼e pisaÄ‡, debugowaÄ‡ i uruchamiaÄ‡ programy w Pythonie, C, Go, Javie i innych â€” wszystko bez nadzoru.

* ğŸ§  Inteligentny wybÃ³r agenta â€“ Zadajesz pytanie, a on sam wybiera najlepszego agenta do zadania. Jak zespÃ³Å‚ ekspertÃ³w gotowych do pomocy.

* ğŸ“‹ Planuje i realizuje zÅ‚oÅ¼one zadania â€“ Od planowania podrÃ³Å¼y po skomplikowane projekty â€” potrafi rozbiÄ‡ duÅ¼e zadania na kroki i wykonaÄ‡ je, korzystajÄ…c z wielu agentÃ³w AI.

* ğŸ™ï¸ ObsÅ‚uga gÅ‚osu â€“ Czysty, szybki, futurystyczny gÅ‚os oraz zamiana mowy na tekst pozwala rozmawiaÄ‡ z nim jak z wÅ‚asnym AI z filmu science fiction. (W trakcie opracowania)

### **Demo**

> *Czy moÅ¼esz wyszukaÄ‡ projekt agenticSeek, dowiedzieÄ‡ siÄ™, jakie sÄ… wymagane umiejÄ™tnoÅ›ci, nastÄ™pnie otworzyÄ‡ CV_candidates.zip i powiedzieÄ‡ mi, ktÃ³re najlepiej pasujÄ… do projektu*

https://github.com/user-attachments/assets/b8ca60e9-7b3b-4533-840e-08f9ac426316

ZastrzeÅ¼enie: To demo, w tym wszystkie pojawiajÄ…ce siÄ™ pliki (np.: CV_candidates.zip), sÄ… caÅ‚kowicie fikcyjne. Nie jesteÅ›my korporacjÄ…, szukamy wspÃ³Å‚twÃ³rcÃ³w open-source, a nie kandydatÃ³w.

> ğŸ› âš ï¸ï¸ **Aktywnie rozwijane**

> ğŸ™ Ten projekt powstaÅ‚ jako poboczny i nie posiada Å¼adnej mapy drogowej ani finansowania. RozrÃ³sÅ‚ siÄ™ znacznie bardziej, niÅ¼ siÄ™ spodziewaÅ‚em, koÅ„czÄ…c na GitHub Trending. Wszelkie wkÅ‚ady, opinie i cierpliwoÅ›Ä‡ sÄ… bardzo cenione.

## Wymagania wstÄ™pne

Przed rozpoczÄ™ciem upewnij siÄ™, Å¼e masz zainstalowane nastÄ™pujÄ…ce oprogramowanie:

*   **Git:** Do klonowania repozytorium. [Pobierz Git](https://git-scm.com/downloads)
*   **Python 3.10.x:** Zdecydowanie zalecamy uÅ¼ycie wersji Python 3.10.x. UÅ¼ywanie innych wersji moÅ¼e prowadziÄ‡ do bÅ‚Ä™dÃ³w zaleÅ¼noÅ›ci. [Pobierz Python 3.10](https://www.python.org/downloads/release/python-3100/) (wybierz wersjÄ™ 3.10.x).
*   **Docker Engine i Docker Compose:** Do uruchamiania usÅ‚ug takich jak SearxNG.
    *   Zainstaluj Docker Desktop (zawiera Docker Compose V2): [Windows](https://docs.docker.com/desktop/install/windows-install/) | [Mac](https://docs.docker.com/desktop/install/mac-install/) | [Linux](https://docs.docker.com/desktop/install/linux-install/)
    *   Alternatywnie, zainstaluj Docker Engine i Docker Compose oddzielnie na Linuksie: [Docker Engine](https://docs.docker.com/engine/install/) | [Docker Compose](https://docs.docker.com/compose/install/) (upewnij siÄ™, Å¼e instalujesz Compose V2, np. `sudo apt-get install docker-compose-plugin`).

### 1. **Sklonuj repozytorium i skonfiguruj**

```sh
git clone https://github.com/Fosowl/agenticSeek.git
cd agenticSeek
mv .env.example .env
```

### 2. ZmieÅ„ zawartoÅ›Ä‡ pliku .env

```sh
SEARXNG_BASE_URL="http://127.0.0.1:8080"
REDIS_BASE_URL="redis://redis:6379/0"
WORK_DIR="/Users/mlg/Documents/workspace_for_ai"
OLLAMA_PORT="11434"
LM_STUDIO_PORT="1234"
CUSTOM_ADDITIONAL_LLM_PORT="11435"
OPENAI_API_KEY='optional'
DEEPSEEK_API_KEY='optional'
OPENROUTER_API_KEY='optional'
TOGETHER_API_KEY='optional'
GOOGLE_API_KEY='optional'
ANTHROPIC_API_KEY='optional'
```

Zaktualizuj plik `.env` wÅ‚asnymi wartoÅ›ciami, jeÅ›li to konieczne:

- **SEARXNG_BASE_URL**: Pozostaw bez zmian
- **REDIS_BASE_URL**: Pozostaw bez zmian
- **WORK_DIR**: ÅšcieÅ¼ka do Twojego katalogu roboczego na komputerze lokalnym. AgenticSeek bÄ™dzie mÃ³gÅ‚ czytaÄ‡ i pracowaÄ‡ na tych plikach.
- **OLLAMA_PORT**: Numer portu dla usÅ‚ugi Ollama.
- **LM_STUDIO_PORT**: Numer portu dla LM Studio.
- **CUSTOM_ADDITIONAL_LLM_PORT**: Port dla dodatkowej, wÅ‚asnej usÅ‚ugi LLM.

**Klucze API sÄ… caÅ‚kowicie opcjonalne dla uÅ¼ytkownikÃ³w, ktÃ³rzy zdecydujÄ… siÄ™ uruchamiaÄ‡ LLM lokalnie. Jest to gÅ‚Ã³wny cel tego projektu. Pozostaw puste, jeÅ›li masz wystarczajÄ…co wydajny sprzÄ™t**

### 3. **Uruchom Docker**

Upewnij siÄ™, Å¼e Docker jest zainstalowany i dziaÅ‚a na Twoim systemie. MoÅ¼esz uruchomiÄ‡ Dockera nastÄ™pujÄ…cymi poleceniami:

- **Na Linux/macOS:**  
    OtwÃ³rz terminal i wpisz:
    ```sh
    sudo systemctl start docker
    ```
    Lub uruchom Docker Desktop z menu aplikacji, jeÅ›li jest zainstalowany.

- **Na Windows:**  
    Uruchom Docker Desktop z menu Start.

MoÅ¼esz sprawdziÄ‡, czy Docker dziaÅ‚a, wykonujÄ…c:
```sh
docker info
```
JeÅ›li zobaczysz informacje o instalacji Dockera, wszystko dziaÅ‚a poprawnie.

Zobacz tabelÄ™ [Dostawcy lokalni](#list-of-local-providers) poniÅ¼ej podsumowanie.

NastÄ™pny krok: [Uruchom AgenticSeek lokalnie](#start-services-and-run)

*Zobacz sekcjÄ™ [RozwiÄ…zywanie problemÃ³w](#troubleshooting), jeÅ›li masz problemy.*
*JeÅ›li TwÃ³j sprzÄ™t nie pozwala na lokalne uruchomienie LLM, zobacz [Konfiguracja z API](#setup-to-run-with-an-api).*
*SzczegÃ³Å‚owe wyjaÅ›nienia pliku `config.ini` w sekcji [Konfiguracja](#config).*

---

## Konfiguracja do lokalnego uruchamiania LLM

**Wymagania sprzÄ™towe:**

Aby uruchamiaÄ‡ LLM lokalnie, potrzebujesz odpowiedniego sprzÄ™tu. Minimalnie wymagana jest karta GPU zdolna do obsÅ‚ugi Magistral, Qwen lub Deepseek 14B. SzczegÃ³Å‚owe zalecenia dotyczÄ…ce modeli/wydajnoÅ›ci znajdziesz w FAQ.

**Uruchom lokalnego dostawcÄ™**  

Uruchom swojego lokalnego dostawcÄ™, np. ollama:

```sh
ollama serve
```

PoniÅ¼ej znajdziesz listÄ™ obsÅ‚ugiwanych lokalnych dostawcÃ³w.

**Zaktualizuj config.ini**

ZmieÅ„ plik config.ini, ustawiajÄ…c provider_name na obsÅ‚ugiwanego dostawcÄ™ oraz provider_model na model LLM obsÅ‚ugiwany przez dostawcÄ™. Zalecamy modele rozumowania takie jak *Magistral* lub *Deepseek*.

SzczegÃ³Å‚y sprzÄ™towe znajdziesz w **FAQ** na koÅ„cu README.

```sh
[MAIN]
is_local = True # Czy uruchamiasz lokalnie lub zdalnie.
provider_name = ollama # lub lm-studio, openai, itd.
provider_model = deepseek-r1:14b # wybierz model odpowiedni do swojego sprzÄ™tu
provider_server_address = 127.0.0.1:11434
agent_name = Jarvis # nazwa Twojej AI
recover_last_session = True # czy odzyskiwaÄ‡ ostatniÄ… sesjÄ™
save_session = True # czy zapamiÄ™tywaÄ‡ bieÅ¼Ä…cÄ… sesjÄ™
speak = False # zamiana tekstu na mowÄ™
listen = False # zamiana mowy na tekst, tylko CLI, eksperymentalne
jarvis_personality = False # czy uÅ¼ywaÄ‡ bardziej "Jarvisowej" osobowoÅ›ci (eksperymentalne)
languages = en zh # Lista jÄ™zykÃ³w, zamiana tekstu na mowÄ™ domyÅ›lnie w pierwszym jÄ™zyku z listy
[BROWSER]
headless_browser = True # pozostaw bez zmian, chyba Å¼e uÅ¼ywasz CLI na hoÅ›cie
stealth_mode = True # UÅ¼yj selenium nie do wykrycia, by zmniejszyÄ‡ wykrywanie przeglÄ…darki
```

**Uwaga**:

- Plik `config.ini` nie obsÅ‚uguje komentarzy.
Nie kopiuj i nie wklejaj przykÅ‚adowej konfiguracji bezpoÅ›rednio, poniewaÅ¼ komentarze spowodujÄ… bÅ‚Ä™dy. Zamiast tego rÄ™cznie zmodyfikuj plik `config.ini`, wpisujÄ…c wybrane ustawienia bez komentarzy.

- *NIE* ustawiaj provider_name na `openai`, jeÅ›li korzystasz z LM-studio do lokalnych LLM. Ustaw na `lm-studio`.

- NiektÃ³rzy dostawcy (np. lm-studio) wymagajÄ… dodania `http://` przed adresem IP. PrzykÅ‚ad: `http://127.0.0.1:1234`

**Lista lokalnych dostawcÃ³w**

| Dostawca     | Lokalny? | Opis                                                                 |
|--------------|----------|----------------------------------------------------------------------|
| ollama       | Tak      | Uruchamiaj LLM lokalnie z Å‚atwoÅ›ciÄ… uÅ¼ywajÄ…c ollama jako dostawcy     |
| lm-studio    | Tak      | Lokalny LLM przez LM studio (ustaw `provider_name` na `lm-studio`)    |
| openai       | Tak      | UÅ¼yj kompatybilnego API openai (np. serwer llama.cpp)                 |

NastÄ™pny krok: [Uruchom usÅ‚ugi i AgenticSeek](#Start-services-and-Run)

*Zobacz sekcjÄ™ [RozwiÄ…zywanie problemÃ³w](#troubleshooting), jeÅ›li masz problemy.*
*JeÅ›li TwÃ³j sprzÄ™t nie pozwala na lokalne uruchomienie LLM, zobacz [Konfiguracja z API](#setup-to-run-with-an-api).*
*SzczegÃ³Å‚owe wyjaÅ›nienia pliku `config.ini` w sekcji [Konfiguracja](#config).*

## Konfiguracja do uruchamiania przez API

To ustawienie wykorzystuje zewnÄ™trznych, chmurowych dostawcÃ³w LLM. Potrzebujesz klucza API wybranego serwisu.

**1. Wybierz dostawcÄ™ API i uzyskaj klucz:**

Zobacz [ListÄ™ dostawcÃ³w API](#list-of-api-providers) poniÅ¼ej. OdwiedÅº ich strony, zarejestruj siÄ™ i pobierz klucz API.

**2. Ustaw swÃ³j klucz API jako zmiennÄ… Å›rodowiskowÄ…:**


*   **Linux/macOS:**
    OtwÃ³rz terminal i uÅ¼yj polecenia `export`. Najlepiej dodaÄ‡ to do pliku profilu swojej powÅ‚oki (np. `~/.bashrc`, `~/.zshrc`), aby byÅ‚o trwaÅ‚e.
    ```sh
    export PROVIDER_API_KEY="tutaj_twÃ³j_klucz_api"
    # ZamieÅ„ PROVIDER_API_KEY na konkretnÄ… zmiennÄ…, np. OPENAI_API_KEY, GOOGLE_API_KEY
    ```
    PrzykÅ‚ad dla TogetherAI:
    ```sh
    export TOGETHER_API_KEY="xxxxxxxxxxxxxxxxxxxxxx"
    ```
*   **Windows:**
*   **Wiersz poleceÅ„ (Tymczasowo dla bieÅ¼Ä…cej sesji):**
    ```cmd
    set PROVIDER_API_KEY=twoj_klucz_api_tutaj
    ```
*   **PowerShell (Tymczasowo dla bieÅ¼Ä…cej sesji):**
    ```powershell
    $env:PROVIDER_API_KEY="twoj_klucz_api_tutaj"
    ```
*   **Na staÅ‚e:** Wyszukaj "zmienne Å›rodowiskowe" w pasku wyszukiwania Windows, kliknij "Edytuj zmienne Å›rodowiskowe systemu", a nastÄ™pnie kliknij przycisk "Zmienne Å›rodowiskowe...". Dodaj nowÄ… zmiennÄ… uÅ¼ytkownika z odpowiedniÄ… nazwÄ… (np. `OPENAI_API_KEY`) i Twoim kluczem jako wartoÅ›ciÄ….

*(Zobacz FAQ: [Jak ustawiÄ‡ klucze API?](#how-do-i-set-api-keys) po wiÄ™cej szczegÃ³Å‚Ã³w).*


**3. Zaktualizuj `config.ini`:**
```ini
[MAIN]
is_local = False
provider_name = openai # Lub google, deepseek, togetherAI, huggingface
provider_model = gpt-3.5-turbo # Lub gemini-1.5-flash, deepseek-chat, mistralai/Mixtral-8x7B-Instruct-v0.1 itd.
provider_server_address = # Zazwyczaj ignorowane lub moÅ¼na pozostawiÄ‡ puste, gdy is_local = False dla wiÄ™kszoÅ›ci API
# ... inne ustawienia ...
```
*Uwaga:* Upewnij siÄ™, Å¼e w wartoÅ›ciach `config.ini` nie ma spacji na koÅ„cu linii.

**Lista dostawcÃ³w API**

| Dostawca      | `provider_name` | Lokalny? | Opis                                              | Link do klucza API (przykÅ‚ady)              |
|---------------|-----------------|----------|---------------------------------------------------|---------------------------------------------|
| OpenAI        | `openai`        | Nie      | UÅ¼yj modeli ChatGPT przez API OpenAI.             | [platform.openai.com/signup](https://platform.openai.com/signup) |
| Google Gemini | `google`        | Nie      | UÅ¼yj modeli Google Gemini przez Google AI Studio. | [aistudio.google.com/keys](https://aistudio.google.com/keys) |
| Deepseek      | `deepseek`      | Nie      | UÅ¼yj modeli Deepseek przez ich API.               | [platform.deepseek.com](https://platform.deepseek.com) |
| Hugging Face  | `huggingface`   | Nie      | UÅ¼yj modeli z Hugging Face Inference API.         | [huggingface.co/settings/tokens](https://huggingface.co/settings/tokens) |
| TogetherAI    | `togetherAI`    | Nie      | UÅ¼yj rÃ³Å¼nych modeli open-source przez TogetherAI. | [api.together.ai/settings/api-keys](https://api.together.ai/settings/api-keys) |

*Uwaga:*
*   Odradzamy uÅ¼ywanie `gpt-4o` lub innych modeli OpenAI do zÅ‚oÅ¼onego przeglÄ…dania internetu i planowania zadaÅ„, poniewaÅ¼ aktualne optymalizacje promptÃ³w sÄ… skierowane pod modele takie jak Deepseek.
*   Zadania zwiÄ…zane z kodowaniem/bash mogÄ… napotkaÄ‡ problemy z Gemini, gdyÅ¼ moÅ¼e nie przestrzegaÄ‡ Å›ciÅ›le formatowania promptÃ³w zoptymalizowanych pod Deepseek.
*   `provider_server_address` w pliku `config.ini` jest zazwyczaj nieuÅ¼ywane, gdy `is_local = False`, poniewaÅ¼ adres API jest zwykle zapisany na staÅ‚e w odpowiedniej bibliotece dostawcy.

NastÄ™pny krok: [Uruchom usÅ‚ugi i AgenticSeek](#Start-services-and-Run)

*Zobacz sekcjÄ™ **Znane problemy** jeÅ›li napotkasz problemy*

*Zobacz sekcjÄ™ **Config** po szczegÃ³Å‚owe wyjaÅ›nienie pliku konfiguracyjnego.*

---

## Uruchom usÅ‚ugi i AgenticSeek

DomyÅ›lnie AgenticSeek uruchamiany jest w caÅ‚oÅ›ci w dockerze.

Uruchom wymagane usÅ‚ugi. Rozpocznie to wszystkie usÅ‚ugi z pliku docker-compose.yml, w tym:
    - searxng
    - redis (wymagany przez searxng)
    - frontend
    - backend (jeÅ›li uÅ¼ywasz `full`)

```sh
./start_services.sh full # MacOS
start ./start_services.cmd full # Windows
```

**Uwaga:** Ten krok pobierze i zaÅ‚aduje wszystkie obrazy Dockera, co moÅ¼e zajÄ…Ä‡ do 30 minut. Po uruchomieniu usÅ‚ug poczekaj, aÅ¼ usÅ‚uga backend bÄ™dzie w peÅ‚ni uruchomiona (powinieneÅ› zobaczyÄ‡ **backend: "GET /health HTTP/1.1" 200 OK** w logu), zanim wyÅ›lesz jakiekolwiek wiadomoÅ›ci. UsÅ‚ugi backend mogÄ… potrzebowaÄ‡ do 5 minut na pierwsze uruchomienie.

PrzejdÅº do `http://localhost:3000/` i powinieneÅ› zobaczyÄ‡ interfejs webowy.

*RozwiÄ…zywanie problemÃ³w z uruchomieniem usÅ‚ug:* JeÅ›li te skrypty siÄ™ nie powiodÄ…, upewnij siÄ™, Å¼e Docker Engine jest uruchomiony oraz Docker Compose (V2, `docker compose`) jest poprawnie zainstalowany. SprawdÅº komunikaty o bÅ‚Ä™dach w terminalu. Zobacz [FAQ: Pomoc! WystÄ…piÅ‚ bÅ‚Ä…d podczas uruchamiania AgenticSeek lub jego skryptÃ³w.](#faq-troubleshooting)

**Opcjonalnie:** Uruchom na hoÅ›cie (tryb CLI):

Aby uruchomiÄ‡ w interfejsie CLI musisz zainstalowaÄ‡ pakiet na hoÅ›cie:

```sh
./install.sh
./install.bat # windows
```

Uruchom usÅ‚ugi:

```sh
./start_services.sh # MacOS
start ./start_services.cmd # Windows
```

UÅ¼yj CLI: `python3 cli.py`


---

## UÅ¼ytkowanie

Upewnij siÄ™, Å¼e usÅ‚ugi sÄ… uruchomione poprzez `./start_services.sh full` i przejdÅº do `localhost:3000` aby uzyskaÄ‡ dostÄ™p do interfejsu webowego.

MoÅ¼esz takÅ¼e uÅ¼yÄ‡ funkcji rozpoznawania mowy ustawiajÄ…c `listen = True` w konfiguracji. Tylko w trybie CLI.

Aby zakoÅ„czyÄ‡, po prostu powiedz/napisz `goodbye`.

Oto przykÅ‚ady uÅ¼ycia:

> *StwÃ³rz grÄ™ w wÄ™Å¼a w pythonie!*

> *Wyszukaj w internecie najlepsze kawiarnie w Rennes, Francja, i zapisz listÄ™ trzech z ich adresami w pliku rennes_cafes.txt.*

> *Napisz program w Go obliczajÄ…cy silniÄ™ liczby, zapisz go jako factorial.go w swoim katalogu roboczym*

> *Wyszukaj w folderze summer_pictures wszystkie pliki JPG, zmieÅ„ ich nazwy na dzisiejszÄ… datÄ™ i zapisz listÄ™ zmienionych plikÃ³w w photos_list.txt*

> *Wyszukaj online popularne filmy sci-fi z 2024 i wybierz trzy do obejrzenia dziÅ› wieczorem. Zapisz listÄ™ w movie_night.txt.*

> *Wyszukaj w internecie najnowsze artykuÅ‚y o AI z 2025, wybierz trzy, i napisz skrypt w Pythonie, ktÃ³ry pobierze ich tytuÅ‚y i podsumowania. Zapisz skrypt jako news_scraper.py, a podsumowania w ai_news.txt w /home/projects*

> *W piÄ…tek wyszukaj w internecie darmowe API do notowaÅ„ gieÅ‚dowych, zarejestruj siÄ™ jako supersuper7434567@gmail.com, potem napisz skrypt w Pythonie pobierajÄ…cy dzienne ceny Tesli i zapisz wyniki w stock_prices.csv*

*ZwrÃ³Ä‡ uwagÄ™, Å¼e moÅ¼liwoÅ›ci wypeÅ‚niania formularzy sÄ… nadal eksperymentalne i mogÄ… nie dziaÅ‚aÄ‡ poprawnie.*



Po wpisaniu zapytania AgenticSeek przydzieli najlepszego agenta do zadania.

PoniewaÅ¼ to wczesny prototyp, system routingu agentÃ³w moÅ¼e nie zawsze przydzieliÄ‡ wÅ‚aÅ›ciwego agenta na podstawie zapytania.

Dlatego powinieneÅ› byÄ‡ bardzo precyzyjny w tym, czego oczekujesz i jak AI ma postÄ™powaÄ‡ â€” np. jeÅ›li chcesz, by wyszukaÅ‚ informacje w internecie, nie pisz:

`Czy znasz jakieÅ› dobre kraje na podrÃ³Å¼ solo?`

Zamiast tego, zapytaj:

`Wyszukaj w internecie i dowiedz siÄ™, ktÃ³re kraje sÄ… najlepsze do podrÃ³Å¼owania solo`

---

## **Konfiguracja uruchomienia LLM na wÅ‚asnym serwerze**

JeÅ›li masz wydajny komputer lub serwer, z ktÃ³rego moÅ¼esz korzystaÄ‡, ale chcesz uÅ¼ywaÄ‡ go z laptopa, masz moÅ¼liwoÅ›Ä‡ uruchomienia LLM na zdalnym serwerze za pomocÄ… naszego wÅ‚asnego serwera llm.

Na swoim "serwerze", ktÃ³ry bÄ™dzie uruchamiaÅ‚ model AI, pobierz adres IP

```sh
ip a | grep "inet " | grep -v 127.0.0.1 | awk '{print $2}' | cut -d/ -f1 # lokalny IP
curl https://ipinfo.io/ip # publiczny IP
```

Uwaga: Dla Windows lub macOS uÅ¼yj odpowiednio ipconfig lub ifconfig, aby znaleÅºÄ‡ adres IP.

Sklonuj repozytorium i wejdÅº do folderu `server/`.


```sh
git clone --depth 1 https://github.com/Fosowl/agenticSeek.git
cd agenticSeek/llm_server/
```

Zainstaluj wymagania serwera:

```sh
pip3 install -r requirements.txt
```

Uruchom skrypt serwera.

```sh
python3 app.py --provider ollama --port 3333
```

Masz wybÃ³r pomiÄ™dzy `ollama` i `llamacpp` jako usÅ‚ugÄ… LLM.


Teraz na swoim komputerze osobistym:

ZmieÅ„ plik `config.ini`, ustawiajÄ…c `provider_name` na `server` oraz `provider_model` na `deepseek-r1:xxb`.
Ustaw `provider_server_address` na adres IP maszyny, ktÃ³ra bÄ™dzie uruchamiaÅ‚a model.

```sh
[MAIN]
is_local = False
provider_name = server
provider_model = deepseek-r1:70b
provider_server_address = x.x.x.x:3333
```


NastÄ™pny krok: [Uruchom usÅ‚ugi i AgenticSeek](#Start-services-and-Run)  

---

## Rozpoznawanie mowy (Speech to Text)

Uwaga: rozpoznawanie mowy dziaÅ‚a obecnie tylko w trybie CLI.

PamiÄ™taj, Å¼e obecnie rozpoznawanie mowy dziaÅ‚a tylko w jÄ™zyku angielskim.

FunkcjonalnoÅ›Ä‡ rozpoznawania mowy jest domyÅ›lnie wyÅ‚Ä…czona. Aby jÄ… wÅ‚Ä…czyÄ‡, ustaw opcjÄ™ listen na True w pliku config.ini:

```
listen = True
```

Po wÅ‚Ä…czeniu, funkcja rozpoznawania mowy czeka na sÅ‚owo kluczowe (nazwÄ™ agenta), zanim zacznie przetwarzaÄ‡ Twoje polecenie. MoÅ¼esz dostosowaÄ‡ nazwÄ™ agenta, aktualizujÄ…c wartoÅ›Ä‡ `agent_name` w pliku *config.ini*:

```
agent_name = Friday
```

Dla optymalnego rozpoznawania zalecamy uÅ¼ycie popularnego angielskiego imienia, takiego jak "John" lub "Emma" jako nazwy agenta

Gdy zobaczysz, Å¼e transkrypcja zaczyna siÄ™ pojawiaÄ‡, wypowiedz gÅ‚oÅ›no imiÄ™ agenta, aby go obudziÄ‡ (np. "Friday").

Wypowiedz swoje zapytanie wyraÅºnie.

ZakoÅ„cz swojÄ… proÅ›bÄ™ frazÄ… potwierdzajÄ…cÄ…, aby zasygnalizowaÄ‡ systemowi, Å¼e ma przejÅ›Ä‡ dalej. PrzykÅ‚ady fraz potwierdzajÄ…cych to:
```
"do it", "go ahead", "execute", "run", "start", "thanks", "would ya", "please", "okay?", "proceed", "continue", "go on", "do that", "go it", "do you understand?"
```

## Konfiguracja

PrzykÅ‚adowa konfiguracja:
```
[MAIN]
is_local = True
provider_name = ollama
provider_model = deepseek-r1:32b
provider_server_address = http://127.0.0.1:11434 # PrzykÅ‚ad dla Ollama; uÅ¼yj http://127.0.0.1:1234 dla LM-Studio
agent_name = Friday
recover_last_session = False
save_session = False
speak = False
listen = False

jarvis_personality = False
languages = en zh # Lista jÄ™zykÃ³w dla TTS i potencjalnie routingu.
[BROWSER]
headless_browser = False
stealth_mode = False
```

**WyjaÅ›nienie ustawieÅ„ `config.ini`**:

*   **Sekcja `[MAIN]`:**
    *   `is_local`: `True` jeÅ›li korzystasz z lokalnego dostawcy LLM (Ollama, LM-Studio, lokalny serwer zgodny z OpenAI) lub opcji serwera self-hosted. `False` jeÅ›li uÅ¼ywasz API w chmurze (OpenAI, Google, itd.).
    *   `provider_name`: OkreÅ›la dostawcÄ™ LLM.
        *   Opcje lokalne: `ollama`, `lm-studio`, `openai` (dla lokalnych serwerÃ³w zgodnych z OpenAI), `server` (dla wÅ‚asnego serwera self-hosted).
        *   Opcje API: `openai`, `google`, `deepseek`, `huggingface`, `togetherAI`.
    *   `provider_model`: Konkretna nazwa lub ID modelu dla wybranego dostawcy (np. `deepseekcoder:6.7b` dla Ollama, `gpt-3.5-turbo` dla OpenAI API, `mistralai/Mixtral-8x7B-Instruct-v0.1` dla TogetherAI).
    *   `provider_server_address`: Adres twojego dostawcy LLM.
        *   Dla dostawcÃ³w lokalnych: np. `http://127.0.0.1:11434` dla Ollama, `http://127.0.0.1:1234` dla LM-Studio.
        *   Dla typu `server`: Adres twojego wÅ‚asnego serwera LLM (np. `http://your_server_ip:3333`).
        *   Dla API w chmurze (`is_local = False`): Zazwyczaj ignorowane lub moÅ¼na zostawiÄ‡ puste, poniewaÅ¼ endpoint API jest zazwyczaj obsÅ‚ugiwany przez bibliotekÄ™ klienckÄ….
    *   `agent_name`: Nazwa asystenta AI (np. Friday). UÅ¼ywana jako sÅ‚owo wybudzajÄ…ce dla rozpoznawania mowy, jeÅ›li jest wÅ‚Ä…czone.
    *   `recover_last_session`: `True` aby przywrÃ³ciÄ‡ stan poprzedniej sesji, `False` aby rozpoczÄ…Ä‡ od nowa.
    *   `save_session`: `True` aby zapisaÄ‡ stan bieÅ¼Ä…cej sesji do ewentualnego przywrÃ³cenia, `False` w przeciwnym wypadku.
    *   `speak`: `True` aby wÅ‚Ä…czyÄ‡ syntezÄ™ mowy (TTS), `False` aby wyÅ‚Ä…czyÄ‡.
    *   `listen`: `True` aby wÅ‚Ä…czyÄ‡ rozpoznawanie mowy (STT) w trybie CLI, `False` aby wyÅ‚Ä…czyÄ‡.
    *   `work_dir`: **Istotne:** Katalog, w ktÃ³rym AgenticSeek bÄ™dzie czytaÄ‡/zapisywaÄ‡ pliki. **Upewnij siÄ™, Å¼e ta Å›cieÅ¼ka jest poprawna i dostÄ™pna na twoim systemie.**
    *   `jarvis_personality`: `True` aby uÅ¼yÄ‡ bardziej "Jarvisowego" prompta systemowego (eksperymentalne), `False` dla standardowego prompta.
    *   `languages`: Lista jÄ™zykÃ³w rozdzielona przecinkami (np. `en, zh, fr`). UÅ¼ywana do wyboru gÅ‚osu TTS (domyÅ›lnie pierwszy) i moÅ¼e pomagaÄ‡ routerowi LLM. Unikaj zbyt wielu lub bardzo podobnych jÄ™zykÃ³w dla efektywnoÅ›ci routera.
*   **Sekcja `[BROWSER]`:**
    *   `headless_browser`: `True` aby uruchomiÄ‡ zautomatyzowanÄ… przeglÄ…darkÄ™ bez widocznego okna (zalecane do interfejsu webowego lub uÅ¼ytku nieinteraktywnego). `False` aby pokazaÄ‡ okno przeglÄ…darki (przydatne w trybie CLI lub debugowaniu).
    *   `stealth_mode`: `True` aby wÅ‚Ä…czyÄ‡ Å›rodki utrudniajÄ…ce wykrycie automatyzacji przeglÄ…darki. MoÅ¼e wymagaÄ‡ rÄ™cznej instalacji rozszerzeÅ„, takich jak anticaptcha.

Ta sekcja podsumowuje obsÅ‚ugiwane typy dostawcÃ³w LLM. Skonfiguruj je w `config.ini`.

**Dostawcy lokalni (uruchamiani na twoim sprzÄ™cie):**

| Nazwa dostawcy w `config.ini` | `is_local` | Opis                                                                       | Sekcja konfiguracji                                                 |
|-------------------------------|------------|----------------------------------------------------------------------------|---------------------------------------------------------------------|
| `ollama`                      | `True`     | UÅ¼yj Ollama do serwowania lokalnych LLM.                                   | [Konfiguracja lokalnego LLM](#setup-for-running-llm-locally-on-your-machine) |
| `lm-studio`                   | `True`     | UÅ¼yj LM-Studio do serwowania lokalnych LLM.                                | [Konfiguracja lokalnego LLM](#setup-for-running-llm-locally-on-your-machine) |
| `openai` (dla lokalnego serwera) | `True` | PoÅ‚Ä…cz z lokalnym serwerem udostÄ™pniajÄ…cym API zgodne z OpenAI (np. llama.cpp). | [Konfiguracja lokalnego LLM](#setup-for-running-llm-locally-on-your-machine) |
| `server`                      | `False`    | PoÅ‚Ä…cz z wÅ‚asnym serwerem LLM AgenticSeek uruchomionym na innej maszynie.  | [Konfiguracja wÅ‚asnego serwera LLM](#setup-to-run-the-llm-on-your-own-server) |

**Dostawcy API (chmurowi):**

| Nazwa dostawcy w `config.ini` | `is_local` | Opis                                            | Sekcja konfiguracji                                    |
|-------------------------------|------------|--------------------------------------------------|--------------------------------------------------------|
| `openai`                      | `False`    | UÅ¼yj oficjalnego API OpenAI (np. GPT-3.5, GPT-4).| [Konfiguracja z API](#setup-to-run-with-an-api)         |
| `google`                      | `False`    | UÅ¼yj modeli Gemini Google przez API.             | [Konfiguracja z API](#setup-to-run-with-an-api)         |
| `deepseek`                    | `False`    | UÅ¼yj oficjalnego API Deepseek.                   | [Konfiguracja z API](#setup-to-run-with-an-api)         |
| `huggingface`                 | `False`    | UÅ¼yj Hugging Face Inference API.                 | [Konfiguracja z API](#setup-to-run-with-an-api)         |
| `togetherAI`                  | `False`    | UÅ¼yj API TogetherAI dla rÃ³Å¼nych modeli open.     | [Konfiguracja z API](#setup-to-run-with-an-api)         |

---
## RozwiÄ…zywanie problemÃ³w

JeÅ›li napotkasz problemy, ta sekcja zawiera wskazÃ³wki.

# Znane problemy

## Problemy z ChromeDriver

**PrzykÅ‚ad bÅ‚Ä™du:** `SessionNotCreatedException: Message: session not created: This version of ChromeDriver only supports Chrome version XXX`

*   **Przyczyna:** Zainstalowana wersja ChromeDriver jest niezgodna z wersjÄ… przeglÄ…darki Google Chrome.
*   **RozwiÄ…zanie:**
    1.  **SprawdÅº wersjÄ™ Chrome:** OtwÃ³rz Google Chrome, przejdÅº do `Ustawienia > O Google Chrome`, aby znaleÅºÄ‡ wersjÄ™ (np. "Wersja 120.0.6099.110").
    2.  **Pobierz pasujÄ…cÄ… wersjÄ™ ChromeDriver:**
        *   Dla Chrome w wersji 115 i nowszych: PrzejdÅº do [Chrome for Testing (CfT) JSON Endpoints](https://googlechromelabs.github.io/chrome-for-testing/). ZnajdÅº kanaÅ‚ "stable" i pobierz ChromeDriver dla swojego systemu operacyjnego, zgodny z gÅ‚Ã³wnÄ… wersjÄ… przeglÄ…darki Chrome.
        *   Dla starszych wersji (rzadziej spotykane): MoÅ¼esz je znaleÅºÄ‡ na stronie [ChromeDriver - WebDriver for Chrome](https://chromedriver.chromium.org/downloads).
        *   PoniÅ¼szy obrazek przedstawia przykÅ‚ad ze strony CfT:
            ![Download Chromedriver specific version from Chrome for Testing page](https://raw.githubusercontent.com/Fosowl/agenticSeek/main/media/chromedriver_readme.png)
    3.  **Zainstaluj ChromeDriver:**
        *   Upewnij siÄ™, Å¼e pobrany plik `chromedriver` (lub `chromedriver.exe` w Windows) znajduje siÄ™ w katalogu, ktÃ³ry jest na liÅ›cie PATH w systemie (np. `/usr/local/bin` w Linux/macOS lub wÅ‚asny folder skryptÃ³w dodany do PATH w Windows).
        *   Alternatywnie umieÅ›Ä‡ go w katalogu gÅ‚Ã³wnym projektu `agenticSeek`.
        *   Upewnij siÄ™, Å¼e sterownik ma prawa wykonywania (np. `chmod +x chromedriver` w Linux/macOS).
    4.  Zajrzyj do sekcji [ChromeDriver Installation](#chromedriver-installation) w gÅ‚Ã³wnym przewodniku instalacji po wiÄ™cej szczegÃ³Å‚Ã³w.

JeÅ›li ta sekcja jest niepeÅ‚na lub napotkasz inne problemy z ChromeDriver, rozwaÅ¼ sprawdzenie istniejÄ…cych [GitHub Issues](https://github.com/Fosowl/agenticSeek/issues) lub zgÅ‚oszenie nowego problemu.

`Exception: Failed to initialize browser: Message: session not created: This version of ChromeDriver only supports Chrome version 113
Current browser version is 134.0.6998.89 with binary path`

To dzieje siÄ™, jeÅ›li wersje przeglÄ…darki i chromedrivera siÄ™ nie zgadzajÄ….

Musisz przejÅ›Ä‡ do pobrania najnowszej wersji:

https://developer.chrome.com/docs/chromedriver/downloads

JeÅ›li uÅ¼ywasz Chrome w wersji 115 lub nowszej przejdÅº do:

https://googlechromelabs.github.io/chrome-for-testing/

I pobierz wersjÄ™ chromedrivera odpowiedniÄ… dla twojego systemu operacyjnego.

![alt text](https://raw.githubusercontent.com/Fosowl/agenticSeek/main/media/chromedriver_readme.png)

JeÅ›li ta sekcja jest niepeÅ‚na, zgÅ‚oÅ› problem.

## Problemy z connection adapters

```
Exception: Provider lm-studio failed: HTTP request failed: No connection adapters were found for '127.0.0.1:1234/v1/chat/completions'` (Uwaga: port moÅ¼e byÄ‡ inny)
```

*   **Przyczyna:** `provider_server_address` w `config.ini` dla `lm-studio` (lub innych podobnych lokalnych serwerÃ³w zgodnych z OpenAI) nie zawiera prefiksu `http://` lub wskazuje zÅ‚y port.
*   **RozwiÄ…zanie:**
    *   Upewnij siÄ™, Å¼e adres zawiera `http://`. LM-Studio domyÅ›lnie to `http://127.0.0.1:1234`.
    *   Popraw `config.ini`: `provider_server_address = http://127.0.0.1:1234` (lub twÃ³j faktyczny port serwera LM-Studio).

## Nie podano podstawowego adresu URL SearxNG

```
raise ValueError("SearxNG base URL must be provided either as an argument or via the SEARXNG_BASE_URL environment variable.")
ValueError: SearxNG base URL must be provided either as an argument or via the SEARXNG_BASE_URL environment variable.`
```

## FAQ

**Q: Jakiego sprzÄ™tu potrzebujÄ™?**  

| Rozmiar modelu | GPU  | Komentarz                                                   |
|----------------|------|------------------------------------------------------------|
| 7B             | 8GB Vram | âš ï¸ Niezalecane. SÅ‚aba wydajnoÅ›Ä‡, czÄ™ste halucynacje, agenci planujÄ…cy prawdopodobnie zawiodÄ…. |
| 14B            | 12 GB VRAM (np. RTX 3060) | âœ… UÅ¼ywalny do prostych zadaÅ„. MoÅ¼e mieÄ‡ trudnoÅ›ci z przeglÄ…daniem sieci i zadaniami planistycznymi. |
| 32B            | 24+ GB VRAM (np. RTX 4090) | ğŸš€ Sukces w wiÄ™kszoÅ›ci zadaÅ„, nadal moÅ¼e mieÄ‡ trudnoÅ›ci z planowaniem zadaÅ„ |
| 70B+           | 48+ GB Vram | ğŸ’ª DoskonaÅ‚y. Zalecany do zaawansowanych zastosowaÅ„.      |

**Q: OtrzymujÄ™ bÅ‚Ä…d, co mam zrobiÄ‡?**  

Upewnij siÄ™, Å¼e lokalny serwer dziaÅ‚a (`ollama serve`), twoje `config.ini` pasuje do wybranego dostawcy, a zaleÅ¼noÅ›ci sÄ… zainstalowane. JeÅ›li Å¼adne nie dziaÅ‚a, Å›miaÅ‚o zgÅ‚oÅ› problem.

**Q: Czy to naprawdÄ™ moÅ¼e dziaÅ‚aÄ‡ w 100% lokalnie?**  

Tak, z dostawcami Ollama, lm-studio lub server wszystkie modele STT, LLM i TTS dziaÅ‚ajÄ… lokalnie. Opcje nielokalne (OpenAI lub inne API) sÄ… opcjonalne.

**Q: Dlaczego mam uÅ¼ywaÄ‡ AgenticSeek, skoro mam Manus?**

W przeciwieÅ„stwie do Manus, AgenticSeek stawia na niezaleÅ¼noÅ›Ä‡ od zewnÄ™trznych systemÃ³w, dajÄ…c ci wiÄ™kszÄ… kontrolÄ™, prywatnoÅ›Ä‡ i brak kosztÃ³w API.

**Q: Kto stoi za projektem?**

Projekt zostaÅ‚ stworzony przeze mnie, wraz z dwoma przyjaciÃ³Å‚mi, ktÃ³rzy sÄ… maintainerami i kontrybutorami z open-source na GitHubie. JesteÅ›my po prostu grupÄ… pasjonatÃ³w, a nie startupem ani organizacjÄ….

KaÅ¼de konto AgenticSeek na X poza moim osobistym kontem (https://x.com/Martin993886460) jest podszywaniem siÄ™.

## WspÃ³Å‚twÃ³rz

Szukamy developerÃ³w do rozwoju AgenticSeek! Zajrzyj do otwartych zgÅ‚oszeÅ„ lub dyskusji.

[Przewodnik kontrybucji](https://raw.githubusercontent.com/Fosowl/agenticSeek/main/docs/CONTRIBUTING.md)

[![Star History Chart](https://api.star-history.com/svg?repos=Fosowl/agenticSeek&type=Date)](https://www.star-history.com/#Fosowl/agenticSeek&Date)

## Maintainerzy:

 > [Fosowl](https://github.com/Fosowl) | czas paryski 

 > [antoineVIVIES](https://github.com/antoineVIVIES) | czas tajpejski 

 > [steveh8758](https://github.com/steveh8758) | czas tajpejski 

## Specjalne podziÄ™kowania:

 > [tcsenpai](https://github.com/tcsenpai) oraz [plitc](https://github.com/plitc) za pomoc w dockerowaniu backendu

## Sponsorzy:

Sponsorzy z miesiÄ™cznÄ… wpÅ‚atÄ… 5$ lub wiÄ™cej pojawiÄ… siÄ™ tutaj:
- **tatra-labs**
It seems you haven't provided the text of the technical document that needs to be translated. Please provide the content you'd like translated (Part 4 of 4), and I'll proceed with the translation while preserving the original Markdown format and updating the relative paths as requested.

---

Tranlated By [Open Ai Tx](https://github.com/OpenAiTx/OpenAiTx) | Last indexed: 2025-06-16

---