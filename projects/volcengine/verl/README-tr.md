<div align="center">
 ğŸ‘‹ Merhaba, herkese! 
    verl, <b>ByteDance Seed ekibi</b> tarafÄ±ndan baÅŸlatÄ±lan ve verl topluluÄŸu tarafÄ±ndan sÃ¼rdÃ¼rÃ¼len bir RL eÄŸitim kÃ¼tÃ¼phanesidir.
    <br>
    <br>
</div>

<div align="center">

[<img src="https://devin.ai/assets/deepwiki-badge.png" alt="Ask DeepWiki.com" height="20"/>](https://deepwiki.com/volcengine/verl)
[![GitHub Repo stars](https://img.shields.io/github/stars/volcengine/verl)](https://github.com/volcengine/verl/stargazers)
[![Twitter](https://img.shields.io/twitter/follow/verl_project)](https://twitter.com/verl_project)
<a href="https://join.slack.com/t/verlgroup/shared_invite/zt-2w5p9o4c3-yy0x2Q56s_VlGLsJ93A6vA"><img src="https://img.shields.io/badge/Slack-verl-blueviolet?logo=slack&amp"></a>
<a href="https://arxiv.org/pdf/2409.19256"><img src="https://img.shields.io/static/v1?label=EuroSys&message=Paper&color=red"></a>
[![Documentation](https://img.shields.io/badge/documentation-blue)](https://verl.readthedocs.io/en/latest/)
<a href="https://raw.githubusercontent.com/eric-haibin-lin/verl-community/refs/heads/main/WeChat.JPG"><img src="https://img.shields.io/badge/å¾®ä¿¡-green?logo=wechat&amp"></a>

</div>

![seed logo](https://github.com/user-attachments/assets/c42e675e-497c-4508-8bb9-093ad4d1f216)

<h1 style="text-align: center;">verl: LLM'ler iÃ§in Volcano Engine Takviyeli Ã–ÄŸrenme (Reinforcement Learning)</h1>

verl, bÃ¼yÃ¼k dil modelleri (LLM'ler) iÃ§in esnek, verimli ve Ã¼retime hazÄ±r bir RL eÄŸitim kÃ¼tÃ¼phanesidir.

verl, **[HybridFlow: A Flexible and Efficient RLHF Framework](https://arxiv.org/abs/2409.19256v2)** makalesinin aÃ§Ä±k kaynaklÄ± versiyonudur.

verl, aÅŸaÄŸÄ±daki Ã¶zellikleriyle esnek ve kullanÄ±mÄ± kolaydÄ±r:

- **Ã‡eÅŸitli RL algoritmalarÄ±nÄ±n kolayca geniÅŸletilmesi:** Hibrid-kontrolcÃ¼ programlama modeli, karmaÅŸÄ±k eÄŸitim sonrasÄ± veri akÄ±ÅŸlarÄ±nÄ±n esnek ÅŸekilde temsil edilmesini ve verimli ÅŸekilde yÃ¼rÃ¼tÃ¼lmesini saÄŸlar. GRPO, PPO gibi RL veri akÄ±ÅŸlarÄ±nÄ± birkaÃ§ satÄ±r kod ile oluÅŸturun.

- **Mevcut LLM altyapÄ±sÄ± ile modÃ¼ler API'ler ile sorunsuz entegrasyon:** Hesaplama ve veri baÄŸÄ±mlÄ±lÄ±klarÄ±nÄ± ayÄ±rÄ±r, mevcut LLM framework'leriyle (FSDP, Megatron-LM, vLLM, SGLang vb.) sorunsuz entegrasyona olanak tanÄ±r.

- **Esnek cihaz haritalama:** Modellerin farklÄ± GPU kÃ¼melerine yerleÅŸtirilmesini destekler; kaynaklarÄ±n verimli kullanÄ±mÄ± ve farklÄ± kÃ¼me boyutlarÄ± arasÄ±nda Ã¶lÃ§eklenebilirlik saÄŸlar.

- PopÃ¼ler HuggingFace modelleriyle hazÄ±r entegrasyon

verl hÄ±zlÄ±dÄ±r Ã§Ã¼nkÃ¼:

- **En gÃ¼ncel (SOTA) aktarÄ±m oranÄ±:** SOTA LLM eÄŸitim ve Ã§Ä±karÄ±m motoru entegrasyonlarÄ± ve SOTA RL aktarÄ±m hÄ±zÄ±.

- **3D-HybridEngine ile verimli aktÃ¶r modeli yeniden bÃ¶lÃ¼tleme (resharding):** EÄŸitim ve Ã¼retim aÅŸamalarÄ± arasÄ±ndaki geÃ§iÅŸlerde bellek fazlalÄ±ÄŸÄ±nÄ± ortadan kaldÄ±rÄ±r ve iletiÅŸim yÃ¼kÃ¼nÃ¼ Ã¶nemli Ã¶lÃ§Ã¼de azaltÄ±r.

</p>

## Haberler

- [2025/06] Megatron backend ile verl, [DeepSeek-671b ve Qwen3-236b](https://verl.readthedocs.io/en/latest/perf/dpsk.html) gibi bÃ¼yÃ¼k MoE modellerini destekliyor.
- [2025/06] verl ekibi [PyTorch Day China](https://www.lfasiallc.com/pytorch-day-china/) etkinliÄŸinde 7 Haziran'da son proje gÃ¼ncellemelerini sunacak. Pekin'de geliÅŸtirme ekibimizle tanÄ±ÅŸÄ±n!
- [2025/05] [PF-PPO](https://arxiv.org/abs/2409.06957), ICML 2025'e kabul edildi ve artÄ±k verl'de destekleniyor! PF-PPO, potansiyel olarak gÃ¼rÃ¼ltÃ¼lÃ¼ Ã¶dÃ¼l sinyallerini filtreleyerek ve yÃ¼ksek kaliteli deneyimleri tekrar kullanarak politika Ã¶ÄŸrenme verimliliÄŸini ve saÄŸlamlÄ±ÄŸÄ±nÄ± artÄ±rÄ±r.
- [2025/04] [ICLR 2025 Expo](https://iclr.cc/virtual/2025/calendar?filter_events=Expo+Talk+Panel&filter_rooms=), [SCI-FM workshop](https://open-foundation-model.github.io/) ve [LMSys afterparty](https://lu.ma/d23nyynm) etkinliklerinde verl ile ilgili en yeni eÄŸitim sonrasÄ± teknikler ve programlama rehberi hakkÄ±nda bir eÄŸitim vereceÄŸiz. Sunum materyallerine [buradan](https://github.com/eric-haibin-lin/verl-community/tree/main/iclr25) ulaÅŸabilirsiniz.
- [2025/04] [Seed-Thinking-v1.5](https://github.com/ByteDance-Seed/Seed-Thinking-v1.5/blob/main/seed-thinking-v1.5.pdf) teknik raporu yayÄ±mlandÄ±! verl ile eÄŸitilen Seed-Thinking-v1.5, AIME 2024'te 86.7, Codeforces'da 55.0, GPQA'da 77.3 puan alarak STEM ve kodlama alanlarÄ±nda mÃ¼kemmel akÄ±l yÃ¼rÃ¼tme yetenekleri sergilemektedir. YÃ¶ntem ayrÄ±ca, Ã§eÅŸitli alanlarda dikkate deÄŸer genelleme kabiliyeti gÃ¶stermektedir.
- [2025/04] [VAPO](https://arxiv.org/pdf/2504.05118) (deÄŸer tabanlÄ± geliÅŸtirilmiÅŸ PPO) makalesi, akÄ±l yÃ¼rÃ¼tme modelleri iÃ§in en yeni RL metodumuzu kapsar. Qwen-32B-base modelinden eÄŸitilen VAPO, AIME 2024'te 60.4 skoruna ulaÅŸarak DAPO-32B'yi geride bÄ±rakmÄ±ÅŸtÄ±r.
- [2025/03] verl v0.3.0.post1 yayÄ±mlandÄ±! AyrÄ±ntÄ±lar iÃ§in [sÃ¼rÃ¼m notuna](https://github.com/volcengine/verl/releases/) bakÄ±n. Ã–nceki sÃ¼rÃ¼mlere kÄ±yasla [~1.4x hÄ±z artÄ±ÅŸÄ±](https://tongyx361.github.io/blogs/posts/verl-intro/#/verl-flexible-and-efficient-rl-for-llms) elde edilmiÅŸtir.
- [2025/03] [DAPO](https://dapo-sia.github.io/) aÃ§Ä±k kaynak SOTA RL algoritmasÄ±dÄ±r ve Qwen2.5-32B Ã¶n-eÄŸitimli modeli ile AIME 2024'te 50 puan elde ederek DeepSeek'in GRPO'sunu (DeepSeek-R1-Zero-Qwen-32B) geÃ§miÅŸtir. DAPO'nun eÄŸitimi tamamen verl ile yapÄ±lmaktadÄ±r ve yeniden Ã¼retim kodu artÄ±k `recipe/dapo` dizininde mevcuttur.
<details><summary> daha fazla... </summary>
<ul>
  <li>[2025/05] verl, [A2M Shanghai](https://a2m.msup.com.cn/home/?aid=4488&city=shanghai) etkinliÄŸinde 16-17 MayÄ±s'ta sunulacaktÄ±r.</li>
  <li>[2025/05] verl, [GOSIM x PyTorch Day 2025](https://paris2025.gosim.org/) etkinliÄŸinde sunulacak. Paris'te gÃ¶rÃ¼ÅŸmek Ã¼zere!</li>
  <li>[2025/03] verl'in programlama modelini [vLLM Beijing Meetup](https://mp.weixin.qq.com/s/n77GibL2corAtQHtVEAzfg) ve [SGLang-LMSYS Org Meetup](https://lu.ma/ntjrr7ig) etkinliklerinde tanÄ±ttÄ±k, ayrÄ±ntÄ±lar iÃ§in [verl intro and updates](https://github.com/eric-haibin-lin/verl-community/blob/main/slides/verl-lmsys-meetup.pdf).</li>
  <li>[2025/03] verl(HybridFlow) EuroSys 2025'te sunulacak. Rotterdam'da gÃ¶rÃ¼ÅŸmek Ã¼zere!</li>
  <li>[2025/02] verl v0.2.0.post2 yayÄ±mlandÄ±!</li>
  <li>[2025/02] verl'i <a href="https://lu.ma/ji7atxux">Bytedance/NVIDIA/Anyscale Ray Meetup</a>'ta sunduk. San Jose'de gÃ¶rÃ¼ÅŸmek Ã¼zere!</li>
  <li>[2025/01] [Doubao-1.5-pro](https://team.doubao.com/zh/special/doubao_1_5_pro), LLM & VLM'de SOTA seviyesinde performans ile yayÄ±mlandÄ±. RL Ã¶lÃ§ekleme Ã¶nizleme modeli verl kullanÄ±larak eÄŸitildi ve matematik benchmarklarÄ±nda OpenAI O1 seviyesine ulaÅŸtÄ± (AIME'de 70.0 pass@1).</li>
  <li>[2024/12] verl, Ray Forward 2024'te sunuldu. Sunum dosyasÄ±na <a href="https://github.com/eric-haibin-lin/verl-community/blob/main/slides/Ray_Forward_2024_%E5%B7%AB%E9%94%A1%E6%96%8C.pdf">buradan</a> ulaÅŸabilirsiniz.</li>
  <li>[2024/12] Ekip, NeurIPS 2024'te <a href="https://neurips.cc/Expo/Conferences/2024/workshop/100677">Post-training LLMs: From Algorithms to Infrastructure</a> baÅŸlÄ±klÄ± sunumu gerÃ§ekleÅŸtirdi. <a href="https://github.com/eric-haibin-lin/verl-data/tree/neurips">Sunumlar</a> ve <a href="https://neurips.cc/Expo/Conferences/2024/workshop/100677">video</a> mevcut.</li>
  <li>[2024/10] verl, Ray Summit'te sunuldu. <a href="https://www.youtube.com/watch?v=MrhMcXkXvJU&list=PLzTswPQNepXntmT8jr9WaNfqQ60QwW7-U&index=37">Youtube videosu</a> mevcut.</li>
  <li>[2024/08] HybridFlow (verl), EuroSys 2025'e kabul edildi.</li>
</ul>   
</details>

## Temel Ã–zellikler

- EÄŸitim iÃ§in **FSDP**, **FSDP2** ve **Megatron-LM**.
- Rollout Ã¼retimi iÃ§in **vLLM**, **SGLang** ve **HF Transformers**.
- Hugging Face Transformers ve Modelscope Hub ile uyumlu: [Qwen-3](https://raw.githubusercontent.com/volcengine/verl/main/examples/grpo_trainer/run_qwen3-8b.sh), Qwen-2.5, Llama3.1, Gemma2, DeepSeek-LLM vb.
- Denetimli ince ayar (supervised fine-tuning).
- [PPO](https://raw.githubusercontent.com/volcengine/verl/main/examples/ppo_trainer/), [GRPO](https://raw.githubusercontent.com/volcengine/verl/main/examples/grpo_trainer/), [ReMax](https://raw.githubusercontent.com/volcengine/verl/main/examples/remax_trainer/), [REINFORCE++](https://verl.readthedocs.io/en/latest/examples/config.html#algorithm), [RLOO](https://raw.githubusercontent.com/volcengine/verl/main/examples/rloo_trainer/), [PRIME](https://raw.githubusercontent.com/volcengine/verl/main/recipe/prime/), [DAPO](https://raw.githubusercontent.com/volcengine/verl/main/recipe/dapo/), [DrGRPO](https://raw.githubusercontent.com/volcengine/verl/main/recipe/drgrpo/) gibi takviyeli Ã¶ÄŸrenme algoritmalarÄ±.
  - Matematik, [kodlama](https://raw.githubusercontent.com/volcengine/verl/main/recipe/dapo/) vb. iÃ§in model tabanlÄ± Ã¶dÃ¼l ve fonksiyon tabanlÄ± Ã¶dÃ¼l (doÄŸrulanabilir Ã¶dÃ¼l) desteÄŸi
  - GÃ¶rÃ¼ntÃ¼-dil modelleri (VLM'ler) ve [Ã§ok modlu RL](https://raw.githubusercontent.com/volcengine/verl/main/examples/grpo_trainer/run_qwen2_5_vl-7b.sh) iÃ§in destek (Qwen2.5-vl, Kimi-VL)
  - [AraÃ§ Ã§aÄŸrÄ±sÄ± ile Ã§oklu tur](https://raw.githubusercontent.com/volcengine/verl/main/examples/sglang_multiturn/)
- [Kendi kendine oyun tercih optimizasyonu (SPPO)](https://raw.githubusercontent.com/volcengine/verl/main/recipe/sppo/) gibi LLM hizalama tarifleri
- Flash attention 2, [dizi paketleme (sequence packing)](https://raw.githubusercontent.com/volcengine/verl/main/examples/ppo_trainer/run_qwen2-7b_seq_balance.sh), [dizi paralelliÄŸi (sequence parallelism)](https://raw.githubusercontent.com/volcengine/verl/main/examples/ppo_trainer/run_deepseek7b_llm_sp2.sh) desteÄŸi (DeepSpeed Ulysses ile), [LoRA](https://raw.githubusercontent.com/volcengine/verl/main/examples/sft/gsm8k/run_qwen_05_peft.sh), [Liger-kernel](https://raw.githubusercontent.com/volcengine/verl/main/examples/sft/gsm8k/run_qwen_05_sp2_liger.sh)
- [Uzman paralelliÄŸi](https://github.com/volcengine/verl/pull/1467) ile 671B modele ve yÃ¼zlerce GPU'ya Ã¶lÃ§eklenebilirlik
- Bellekten tasarruf iÃ§in Ã§oklu GPU ile [LoRA RL](https://verl.readthedocs.io/en/latest/advance/ppo_lora.html) desteÄŸi
- wandb, swanlab, mlflow ve tensorboard ile deney takibi

## YaklaÅŸan Ã–zellikler ve DeÄŸiÅŸiklikler

- Yol haritasÄ±: https://github.com/volcengine/verl/issues/710
- Megatron v0.11 ile DeepSeek 671b optimizasyonlarÄ±: https://github.com/volcengine/verl/issues/708
- Ã‡oklu tur rollout ve araÃ§ kullanÄ±mÄ± optimizasyonlarÄ±: https://github.com/volcengine/verl/issues/1882
- Ortam etkileÅŸimleri: https://github.com/volcengine/verl/issues/1172
- v0.3'ten bu yana yapÄ±lan yÄ±kÄ±cÄ± deÄŸiÅŸiklikler: https://github.com/volcengine/verl/discussions/943, entropy_coeff varsayÄ±lan olarak 0
- RL iÃ§in Lora: https://github.com/volcengine/verl/pull/1127 

## BaÅŸlarken

<a href="https://verl.readthedocs.io/en/latest/index.html"><b>DokÃ¼mantasyon</b></a>

**HÄ±zlÄ± BaÅŸlangÄ±Ã§:**

- [Kurulum](https://verl.readthedocs.io/en/latest/start/install.html)
- [HÄ±zlÄ± BaÅŸlangÄ±Ã§](https://verl.readthedocs.io/en/latest/start/quickstart.html)
- [Programlama Rehberi](https://verl.readthedocs.io/en/latest/hybrid_flow.html)
- [verl'de PPO](https://verl.readthedocs.io/en/latest/algo/ppo.html)
- [verl'de GRPO](https://verl.readthedocs.io/en/latest/algo/grpo.html)

**AdÄ±m adÄ±m bir PPO Ã¶rneÄŸi Ã§alÄ±ÅŸtÄ±rmak:**

- [EÄŸitim SonrasÄ± iÃ§in Veri HazÄ±rlama](https://verl.readthedocs.io/en/latest/preparation/prepare_data.html)
- [Veri Seti iÃ§in Ã–dÃ¼l Fonksiyonu Uygulama](https://verl.readthedocs.io/en/latest/preparation/reward_function.html)
- [PPO Ã–rneÄŸi Mimarisi](https://verl.readthedocs.io/en/latest/examples/ppo_code_architecture.html)
- [YapÄ±landÄ±rma AÃ§Ä±klamasÄ±](https://verl.readthedocs.io/en/latest/examples/config.html)

**Tekrarlanabilir algoritma taban Ã§izgileri:**

- [Kodlama, matematikte RL performansÄ±](https://verl.readthedocs.io/en/latest/algo/baseline.html)

**Kod aÃ§Ä±klamasÄ± ve ileri seviye kullanÄ±m (geniÅŸletme) iÃ§in:**

- PPO EÄŸitici ve Ã‡alÄ±ÅŸanlar
  - [PPO Ray EÄŸitici](https://verl.readthedocs.io/en/latest/workers/ray_trainer.html)
  - [PyTorch FSDP Backend](https://verl.readthedocs.io/en/latest/workers/fsdp_workers.html)
  - [Megatron-LM Backend](https://verl.readthedocs.io/en/latest/index.html)

- Ä°leri DÃ¼zey KullanÄ±m ve GeniÅŸletme
  - [FSDP Backend ile Model Ekleme](https://verl.readthedocs.io/en/latest/advance/fsdp_extension.html)
  - [Megatron-LM Backend ile Model Ekleme](https://verl.readthedocs.io/en/latest/advance/megatron_extension.html)
  - [Ã‡oklu Tur Rollout DesteÄŸi](https://verl.readthedocs.io/en/latest/sglang_multiturn/multiturn.html)
  - [Arama AracÄ± Entegrasyonu](https://verl.readthedocs.io/en/latest/sglang_multiturn/search_tool_example.html)
  - [Sandbox Fusion Entegrasyonu](https://verl.readthedocs.io/en/latest/examples/sandbox_fusion_example.html)
  - [AyrÄ± GPU KaynaklarÄ± ile DaÄŸÄ±tÄ±m](https://raw.githubusercontent.com/volcengine/verl/main/examples/split_placement/)
  - [DiÄŸer RL(HF) algoritmalarÄ±na geniÅŸletme](https://verl.readthedocs.io/en/latest/advance/dpo_extension.html)
  - [Ray API tasarÄ±m eÄŸitimi](https://verl.readthedocs.io/en/latest/advance/placement.html)

**Topluluktan Bloglar**

- [SGLang, verl, OpenBMB ve Tsinghua Ãœniversitesi: UÃ§tan Uca Ã‡oklu Tur RLHF'de Ã–ncÃ¼lÃ¼k](https://github.com/zhaochenyang20/Awesome-ML-SYS-Tutorial/blob/main/rlhf/verl/multi-turn/verl-multiturn-rollout-Release.md)
- [verl ve ROCm Entegrasyonu ile AMD GPU'larda Ä°nsan Geri Bildirimli Takviyeli Ã–ÄŸrenme](https://rocm.blogs.amd.com/artificial-intelligence/verl-large-scale/README.html)
- [veMLP x verl ï¼šTakviyeli Ã–ÄŸrenme EÄŸitiminde UstalÄ±k](https://mp.weixin.qq.com/s/7nbqxk4knMGd-hQE9ls2tA)
- [verl ile GRPO DaÄŸÄ±tÄ±k Takviyeli Ã–ÄŸrenme En Ä°yi UygulamalarÄ±](https://www.volcengine.com/docs/6459/1463942)
- [HybridFlow verl Orijinal Metin Analizi](https://github.com/zhaochenyang20/Awesome-ML-SYS-Tutorial/blob/main/rlhf/verl/readme.md)
- [Maksimum 20 Kat ArtÄ±ÅŸ! Doubao BÃ¼yÃ¼k Model Ekibi Yeni RLHF Ã‡erÃ§evesini YayÄ±nladÄ±, Åimdi AÃ§Ä±k Kaynak!](https://team.doubao.com/en/blog/%E6%9C%80%E9%AB%98%E6%8F%90%E5%8D%8720%E5%80%8D%E5%90%9E%E5%90%90%E9%87%8F-%E8%B1%86%E5%8C%85%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%9B%A2%E9%98%9F%E5%8F%91%E5%B8%83%E5%85%A8%E6%96%B0-rlhf-%E6%A1%86%E6%9E%B6-%E7%8E%B0%E5%B7%B2%E5%BC%80%E6%BA%90)

## Performans Ayarlama Rehberi

On-policy RL algoritmasÄ± iÃ§in performans kritiktir. PerformansÄ± optimize etmenize yardÄ±mcÄ± olmak iÃ§in ayrÄ±ntÄ±lÄ± bir [performans ayarlama rehberi](https://verl.readthedocs.io/en/latest/perf/perf_tuning.html) yazdÄ±k.

## vLLM >= v0.8.2'ye YÃ¼kseltme

verl, eÄŸitim backend'i olarak FSDP kullanÄ±ldÄ±ÄŸÄ±nda artÄ±k vLLM>=0.8.2'yi destekliyor. Kurulum rehberi ve daha fazla bilgi iÃ§in [bu dokÃ¼mana](https://raw.githubusercontent.com/volcengine/verl/main/docs/README_vllm0.8.md) bakabilirsiniz. OOM ve beklenmeyen hatalara yol aÃ§abileceÄŸi iÃ§in vllm 0.7.x kullanmaktan kaÃ§Ä±nÄ±n.

## En GÃ¼ncel SGLang'i KullanÄ±n

SGLang, verl ile tamamen uyumludur ve SGLang RL Grubu Ã§oklu tur ajan RL, VLM RLHF, sunucu tabanlÄ± RL ve kÄ±smi rollout gibi Ã¶zellikler Ã¼zerinde yoÄŸun ÅŸekilde Ã§alÄ±ÅŸmaktadÄ±r. Kurulum rehberi ve daha fazla bilgi iÃ§in [bu dokÃ¼mana](https://verl.readthedocs.io/en/latest/workers/sglang_worker.html) bakabilirsiniz.

## FSDP2'ye YÃ¼kseltme

verl, FSDP2'yi tamamen benimsiyor! FSDP2, torch distributed ekibi tarafÄ±ndan Ã¶nerilmekte olup daha iyi aktarÄ±m hÄ±zÄ± ve bellek kullanÄ±mÄ± saÄŸlar ve diÄŸer Ã¶zelliklerle (Ã¶rn. torch.compile) birlikte kullanÄ±labilir. FSDP2'yi etkinleÅŸtirmek iÃ§in, verl main'i kullanÄ±n ve aÅŸaÄŸÄ±daki seÃ§enekleri ayarlayÄ±n:
```
actor_rollout_ref.ref.strategy=fsdp2
actor_rollout_ref.actor.strategy=fsdp2
critic.strategy=fsdp2 
reward_model.strategy=fsdp2 
```
AyrÄ±ca, FSDP2 cpu offload, gradient accumulation ile uyumludur. Bellekten tasarruf etmek iÃ§in `actor_rollout_ref.actor.offload_policy=True` olarak ayarlayabilirsiniz. Daha fazla detay iÃ§in: https://github.com/volcengine/verl/pull/1026

## AMD DesteÄŸi (ROCm Kernel)

verl, eÄŸitim motoru olarak FSDP'yi (yakÄ±nda Megatron desteÄŸi de gelecek) ve Ã§Ä±karÄ±m motoru olarak vLLM ve SGLang entegrasyonlarÄ±nÄ± desteklemektedir. Kurulum rehberi ve daha fazla bilgi iÃ§in [bu dokÃ¼mana](https://raw.githubusercontent.com/volcengine/verl/main/docs/amd_tutorial/amd_build_dockerfile_page.rst) ve ROCm iÃ§in vLLM performans ayarlama iÃ§in [bu dokÃ¼mana](https://raw.githubusercontent.com/volcengine/verl/main/docs/amd_tutorial/amd_vllm_page.rst) bakabilirsiniz.


## AtÄ±f ve TeÅŸekkÃ¼r

Projeyi faydalÄ± bulursanÄ±z, lÃ¼tfen ÅŸu makaleleri atÄ±f gÃ¶sterin:

- [HybridFlow: A Flexible and Efficient RLHF Framework](https://arxiv.org/abs/2409.19256v2)
- [A Framework for Training Large Language Models for Code Generation via Proximal Policy Optimization](https://i.cs.hku.hk/~cwu/papers/gmsheng-NL2Code24.pdf)

```bibtex
@article{sheng2024hybridflow,
  title   = {HybridFlow: A Flexible and Efficient RLHF Framework},
  author  = {Guangming Sheng and Chi Zhang and Zilingfeng Ye and Xibin Wu and Wang Zhang and Ru Zhang and Yanghua Peng and Haibin Lin and Chuan Wu},
  year    = {2024},
  journal = {arXiv preprint arXiv: 2409.19256}
}
```

verl, Nemo-Aligner, Deepspeed-chat ve OpenRLHF tasarÄ±mÄ±ndan ilham alÄ±narak geliÅŸtirilmiÅŸtir. Projeye Bytedance, Anyscale, LMSys.org, [Alibaba Qwen ekibi](https://github.com/QwenLM/), Shanghai AI Lab, Tsinghua Ãœniversitesi, UC Berkeley, UCLA, UIUC, Hong Kong Ãœniversitesi, ke.com, [All Hands AI](https://www.all-hands.dev/), [ModelBest](http://modelbest.cn/), OpenPipe, JD AI Lab, Microsoft Research, [StepFun](https://www.stepfun.com/), Amazon, Linkedin, Meituan, [Camel-AI](https://www.camel-ai.org/), [OpenManus](https://github.com/OpenManus), Xiaomi, Prime Intellect, NVIDIA research, [Baichuan](https://www.baichuan-ai.com/home), [RedNote](https://www.xiaohongshu.com/), [SwissAI](https://www.swiss-ai.org/), [Moonshot AI (Kimi)](https://www.moonshot-ai.com/), Baidu, Snowflake ve daha birÃ§ok kurum katkÄ±da bulunmuÅŸtur.

## verl kullanan muhteÅŸem Ã§alÄ±ÅŸmalar

- [TinyZero](https://github.com/Jiayi-Pan/TinyZero): **DeepSeek R1 Zero** tarifinin akÄ±l yÃ¼rÃ¼tme gÃ¶revleri iÃ§in yeniden Ã¼retimi ![GitHub Repo stars](https://img.shields.io/github/stars/Jiayi-Pan/TinyZero)
- [SkyThought](https://github.com/NovaSky-AI/SkyThought): NovaSky AI ekibi tarafÄ±ndan Sky-T1-7B iÃ§in RL eÄŸitimi ![GitHub Repo stars](https://img.shields.io/github/stars/NovaSky-AI/SkyThought)
- [simpleRL-reason](https://github.com/hkust-nlp/simpleRL-reason): SimpleRL-Zoo: AÃ§Ä±k temel modellerde SÄ±fÄ±r Takviyeli Ã–ÄŸrenmeyi inceleme ve yÃ¶netme ![GitHub Repo stars](https://img.shields.io/github/stars/hkust-nlp/simpleRL-reason)
- [Easy-R1](https://github.com/hiyouga/EasyR1): **Ã‡ok modlu** RL eÄŸitim Ã§erÃ§evesi ![GitHub Repo stars](https://img.shields.io/github/stars/hiyouga/EasyR1)
- [OpenManus-RL](https://github.com/OpenManus/OpenManus-RL): Birden fazla ajan ortamÄ± iÃ§in LLM ajan RL ince ayar Ã§erÃ§evesi ![GitHub Repo stars](https://img.shields.io/github/stars/OpenManus/OpenManus-RL)
- [rllm](https://github.com/agentica-project/rllm): [verl-pipeline](https://github.com/agentica-project/verl-pipeline) ile asenkron RL eÄŸitimi ![GitHub Repo stars](https://img.shields.io/github/stars/agentica-project/rllm)
- [PRIME](https://github.com/PRIME-RL/PRIME): DolaylÄ± Ã¶dÃ¼llerle sÃ¼reÃ§ takviyelendirme ![GitHub Repo stars](https://img.shields.io/github/stars/PRIME-RL/PRIME)
- [RAGEN](https://github.com/ZihanWang314/ragen): Genel amaÃ§lÄ± akÄ±l yÃ¼rÃ¼tme **ajanÄ±** eÄŸitim Ã§erÃ§evesi ![GitHub Repo stars](https://img.shields.io/github/stars/ZihanWang314/ragen)
- [Search-R1](https://github.com/PeterGriffinJin/Search-R1): AkÄ±l yÃ¼rÃ¼tme ve **arama (araÃ§ Ã§aÄŸrÄ±sÄ±)** iÃ§ iÃ§e geÃ§miÅŸ LLM'ler ile RL ![GitHub Repo stars](https://img.shields.io/github/stars/PeterGriffinJin/Search-R1)
- [DeepRetrieval](https://github.com/pat-jj/DeepRetrieval): **Arama/AraÅŸtÄ±rma SonuÃ§larÄ±** ile **Arama AjanÄ±**'nÄ±n RL EÄŸitimi ![GitHub Repo stars](https://img.shields.io/github/stars/pat-jj/DeepRetrieval)
- [ReSearch](https://github.com/Agent-RL/ReSearch): Takviyeli Ã¶ÄŸrenme ile LLM'lerde **Arama ile AkÄ±l YÃ¼rÃ¼tme**yi Ã–ÄŸrenmek ![GitHub Repo stars](https://img.shields.io/github/stars/Agent-RL/ReSearch)
- [Code-R1](https://github.com/ganler/code-r1): **Kod** iÃ§in R1'in gÃ¼venilir Ã¶dÃ¼llerle yeniden Ã¼retimi ![GitHub Repo stars](https://img.shields.io/github/stars/ganler/code-r1)
- [Skywork-OR1](https://github.com/SkyworkAI/Skywork-OR1): Skywork aÃ§Ä±k akÄ±l yÃ¼rÃ¼tÃ¼cÃ¼ serisi ![GitHub Repo stars](https://img.shields.io/github/stars/SkyworkAI/Skywork-OR1)
- [ToRL](https://github.com/GAIR-NLP/ToRL): AraÃ§ entegre RL Ã¶lÃ§eklendirme ![GitHub Repo stars](https://img.shields.io/github/stars/GAIR-NLP/ToRL)
- [verl-agent](https://github.com/langfengQ/verl-agent): **Uzun ufuklu LLM/VLM ajanlarÄ±** iÃ§in Ã¶lÃ§eklenebilir eÄŸitim Ã§erÃ§evesi ve yeni algoritma **GiGPO** ![GitHub Repo stars](https://img.shields.io/github/stars/langfengQ/verl-agent)
- [PF-PPO](https://arxiv.org/abs/2409.06957): Daha verimli ve saÄŸlam RLHF iÃ§in Ã¶dÃ¼l sinyallerinin gÃ¼venilirliÄŸine dayalÄ± PPO iÃ§in Politika Filtrasyonu.
- [GUI-R1](https://github.com/ritzz-ai/GUI-R1): **GUI-R1**: **GUI AjanlarÄ±** iÃ§in Genelci R1 tarzÄ± GÃ¶rsel-Dil Eylem Modeli ![GitHub Repo stars](https://img.shields.io/github/stars/ritzz-ai/GUI-R1)
- [DeepResearcher](https://github.com/GAIR-NLP/DeepResearcher): GerÃ§ek dÃ¼nya ortamlarÄ±nda takviyeli Ã¶ÄŸrenme ile derin araÅŸtÄ±rmayÄ± Ã¶lÃ§eklendirme ![GitHub Repo stars](https://img.shields.io/github/stars/GAIR-NLP/DeepResearcher)
- [VAGEN](https://github.com/RAGEN-AI/VAGEN): Ã‡oklu tur takviyeli Ã¶ÄŸrenme ile VLM ajanlarÄ± eÄŸitimi ![GitHub Repo stars](https://img.shields.io/github/stars/RAGEN-AI/VAGEN)
- [ReTool](https://retool-rl.github.io/): LLM'lerde stratejik araÃ§ kullanÄ±mÄ± iÃ§in takviyeli Ã¶ÄŸrenme. Kod yakÄ±nda yayÄ±nlanacak...
- [RM-R1](https://arxiv.org/abs/2505.02387): AkÄ±l yÃ¼rÃ¼tme Ã¶dÃ¼l modellerinin RL ile eÄŸitimi ![GitHub Repo stars](https://img.shields.io/github/stars/RM-R1-UIUC/RM-R1)
- [Absolute Zero Reasoner](https://arxiv.org/abs/2505.03335): AkÄ±l yÃ¼rÃ¼tme iÃ§in insan tarafÄ±ndan hazÄ±rlanmÄ±ÅŸ veri gerektirmeyen kendi kendine oyun Ã§erÃ§evesi ![GitHub Repo stars](https://img.shields.io/github/stars/LeapLabTHU/Absolute-Zero-Reasoner)
- [LUFFY](https://arxiv.org/pdf/2504.14945): PolitikalarÄ± politika dÄ±ÅŸÄ± rehberlikle Ã¶ÄŸrenmek ![GitHub Repo stars](https://img.shields.io/github/stars/ElliottYan/LUFFY)
- [verl-tool](https://github.com/TIGER-AI-Lab/verl-tool): verl tabanlÄ± birleÅŸik ve kolay geniÅŸletilebilir bir araÃ§-ajan eÄŸitim Ã§erÃ§evesi ![GitHub Repo stars](https://img.shields.io/github/stars/TIGER-AI-Lab/verl-tool)
- [DeepMath](https://github.com/zwhe99/DeepMath): Matematiksel akÄ±l yÃ¼rÃ¼tme iÃ§in DeepMath-103K veri seti ve model serisi ![GitHub Repo stars](https://img.shields.io/github/stars/zwhe99/DeepMath)

ve daha fazlasÄ± [recipe](https://raw.githubusercontent.com/volcengine/verl/main/recipe/README.md) dizininde listelenmiÅŸtir.
## KatkÄ± Rehberi

Topluluktan katkÄ±lar memnuniyetle karÅŸÄ±lanÄ±r! [Proje yol haritasÄ±nÄ±](https://github.com/volcengine/verl/issues/710) ve [iyi ilk sorunlar](https://github.com/volcengine/verl/issues?q=is%3Aissue%20state%3Aopen%20label%3A%22good%20first%20issue%22) listesini inceleyerek katkÄ±da bulunabileceÄŸiniz alanlarÄ± gÃ¶rebilirsiniz.

### Kod Lint ve BiÃ§imlendirme

Kod kalitesini artÄ±rmak iÃ§in pre-commit kullanÄ±yoruz. Pre-commit'i baÅŸlatmak iÃ§in:

```bash
pip install pre-commit
pre-commit install
```

CI hatalarÄ±nÄ± yerelde Ã§Ã¶zmek iÃ§in pre-commit'i manuel olarak Ã§alÄ±ÅŸtÄ±rabilirsiniz:

```bash
pre-commit run
```

### CI Testleri Ekleme

MÃ¼mkÃ¼nse, yeni Ã¶zelliÄŸiniz iÃ§in CI testi ekleyin:

1. En ilgili workflow yml dosyasÄ±nÄ± bulun, genellikle bir `hydra` varsayÄ±lan yapÄ±landÄ±rmasÄ±na karÅŸÄ±lÄ±k gelir (Ã¶rn. `ppo_trainer`, `ppo_megatron_trainer`, `sft_trainer` vb).
2. HenÃ¼z eklenmemiÅŸse ilgili yol desenlerini `paths` bÃ¶lÃ¼mÃ¼ne ekleyin.
3. Test betiklerinin iÅŸ yÃ¼kÃ¼nÃ¼ minimuma indirin (Ã¶rnekler iÃ§in mevcut betiklere bakÄ±n).

## [ByteDance Seed Ekibi](https://team.doubao.com/) HakkÄ±nda

2023 yÄ±lÄ±nda kurulan ByteDance Seed Ekibi, sektÃ¶rdeki en ileri AI temel modellerini geliÅŸtirmeye kendini adamÄ±ÅŸtÄ±r. Ekip, dÃ¼nya Ã§apÄ±nda bir araÅŸtÄ±rma ekibi olmayÄ± ve bilime ve topluma Ã¶nemli katkÄ±lar saÄŸlamayÄ± hedeflemektedir. Bytedance Seed hakkÄ±nda daha fazla bilgi iÃ§in aÅŸaÄŸÄ±daki kanallarÄ± ziyaret edebilirsinizğŸ‘‡
<div>
  <a href="https://team.doubao.com/">
    <img src="https://img.shields.io/badge/Website-%231e37ff?style=for-the-badge&logo=bytedance&logoColor=white"></a>
  <a href="https://github.com/user-attachments/assets/469535a8-42f2-4797-acdf-4f7a1d4a0c3e">
    <img src="https://img.shields.io/badge/WeChat-07C160?style=for-the-badge&logo=wechat&logoColor=white"></a>
 <a href="https://www.xiaohongshu.com/user/profile/668e7e15000000000303157d?xsec_token=ABl2-aqekpytY6A8TuxjrwnZskU-6BsMRE_ufQQaSAvjc%3D&xsec_source=pc_search">
    <img src="https://img.shields.io/badge/Xiaohongshu-%23FF2442?style=for-the-badge&logo=xiaohongshu&logoColor=white"></a>
  <a href="https://www.zhihu.com/org/dou-bao-da-mo-xing-tuan-dui/">
    <img src="https://img.shields.io/badge/zhihu-%230084FF?style=for-the-badge&logo=zhihu&logoColor=white"></a>
</div>
---

Ä°ÅE ALIM YAPIYORUZ! RL ile ajanlar konusunda staj/FTE fÄ±rsatlarÄ±yla ilgileniyorsanÄ±z bize bir [e-posta](mailto:haibin.lin@bytedance.com) gÃ¶nderin.

---

Tranlated By [Open Ai Tx](https://github.com/OpenAiTx/OpenAiTx) | Last indexed: 2025-06-07

---