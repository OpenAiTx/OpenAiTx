# ACEBench: ë„êµ¬ ì‚¬ìš©ì—ì„œ ë§¤ì¹˜ í¬ì¸íŠ¸ë¥¼ ëˆ„ê°€ ì°¨ì§€í•˜ëŠ”ê°€?

<p align="center">
  <a href="https://arxiv.org/abs/2501.12851">ğŸ“ƒ ë…¼ë¬¸ </a>
  <b>&nbsp;Â·&nbsp;</b> <a href="https://chenchen0103.github.io/ACEBench/">ğŸ† ë¦¬ë”ë³´ë“œ (ì§€ì† ì—…ë°ì´íŠ¸ ì¤‘)</a>
</p>

English | [ä¸­æ–‡](https://raw.githubusercontent.com/chenchen0103/ACEBench/main/README_CN.md)

## ğŸ“š ëª©ì°¨

- [1\. ì´ˆë¡](#abstract)
- [2\. ë²¤ì¹˜ë§ˆí¬ í†µê³„](#statistics)
- [3\. ë¦¬ë”ë³´ë“œ](#leaderboard)
- [4\. ì„¤ì •](#setup)
- [5\. ë°ì´í„°](#data)
- [6\. ì¶”ë¡ ](#inference)
  - [6.1\. ì¶”ë¡  ìŠ¤í¬ë¦½íŠ¸](#open_source_inference)
  - [6.2\. ì¶”ë¡  ì˜ˆì‹œ](#openai_inference)
- [7\. í‰ê°€](#evaluation)
- [ì¸ìš©](#citation)

---

## ğŸ› ï¸ ì—…ë°ì´íŠ¸ [[ë§¨ ìœ„ë¡œ]](#content)

### [2025.10.29]

1 normal_atom_enum_9, normal_atom_number_17, normal_atom_list_34 ë°ì´í„°ì…‹ì—ì„œ ê°€ëŠ¥í•œ ë‹µë³€ì„ ìˆ˜ì •í•˜ì˜€ìŠµë‹ˆë‹¤.


<span id="abstract">
</span>

## ğŸ“˜ 1\. ì´ˆë¡ [[ë§¨ ìœ„ë¡œ]](#content)

Large Language Models (LLMs) have demonstrated significant potential in decision-making and reasoning, particularly when integrated with various tools to effectively solve complex problems. However, existing benchmarks for evaluating LLMs' tool usage face several limitations: (1) limited evaluation scenarios, often lacking assessments in real multi-turn dialogue contexts; (2) narrow evaluation dimensions, with insufficient detailed assessments of how LLMs use tools; and (3) reliance on LLMs or real API executions for evaluation, which introduces significant overhead. To address these challenges, we introduce ACEBench, a comprehensive benchmark for assessing tool usage in LLMs. ACEBench categorizes data into three primary types based on evaluation methodology: Normal, Special, and Agent. "Normal" evaluates tool usage in basic scenarios; "Special" evaluates tool usage in situations with ambiguous or incomplete instructions; "Agent" evaluates tool usage through multi-agent interactions to simulate real-world, multi-turn dialogues. We conducted extensive experiments using ACEBench, analyzing various LLMs in-depth and providing a more granular examination of error causes across different data types.

---

<span id="statistics">
</span>

## ğŸ“Š 2.ë²¤ì¹˜ë§ˆí¬ ë°ì´í„° ë¶„ì„ [[ë§¨ ìœ„ë¡œ]](#content)

### **API ë„ë©”ì¸**

- ACEBenchëŠ” ê¸°ìˆ , ê¸ˆìœµ, ì—”í„°í…Œì¸ë¨¼íŠ¸, ì‚¬íšŒ, ê±´ê°•, ë¬¸í™”, í™˜ê²½ ë“± **8ê°œ ì£¼ìš” ë„ë©”ì¸**ê³¼ **68ê°œ í•˜ìœ„ ë„ë©”ì¸**ì„ í¬í•¨í•©ë‹ˆë‹¤.
- ì¤‘êµ­ì–´ì™€ ì˜ì–´ë¡œ ì´ **4,538ê°œì˜ API**ë¥¼ í¬í•¨í•˜ê³  ìˆìŠµë‹ˆë‹¤.
- ë„ë©”ì¸ë³„ API ë¶„í¬ëŠ” ì•„ë˜ ê·¸ë¦¼ì— ì‹œê°í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤:

<p align="center">
  <img src="https://raw.githubusercontent.com/chenchen0103/ACEBench/main/./fig/api_domain.png" alt="API Domain Distribution" width="60%">
</p>

### **ë°ì´í„° êµ¬ì„±**

- ACEBenchëŠ” ì„¸ ê°€ì§€ ì£¼ìš” ë²”ì£¼ì˜ í…ŒìŠ¤íŠ¸ ìƒ˜í”Œë¡œ êµ¬ì„±ë©ë‹ˆë‹¤:
  - **ì¼ë°˜(Normal)**: ê¸°ë³¸ ë„êµ¬ ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤.
  - **ì—ì´ì „íŠ¸(Agent)**: ì‚¬ìš©ìì™€ í™˜ê²½ ê°„ì˜ ë‹¤ì¤‘ í„´ ìƒí˜¸ì‘ìš©.
  - **íŠ¹ìˆ˜(Special)**: ì—¬ëŸ¬ ë‹¨ê³„ë¥¼ ìš”êµ¬í•˜ê±°ë‚˜ ì‹¤í–‰ ë¶ˆê°€ëŠ¥í•œ ë„êµ¬ í˜¸ì¶œì„ ì²˜ë¦¬í•˜ëŠ” ë³µì¡í•œ ì‹œë‚˜ë¦¬ì˜¤.
- ë°ì´í„° êµ¬ì„±ì€ ì•„ë˜ì™€ ê°™ì´ ì‹œê°í™”ë˜ì–´ ë„êµ¬ ì‚¬ìš© ëŠ¥ë ¥ì˜ í¬ê´„ì  ë²”ìœ„ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤:

<p align="center">
  <img src="https://raw.githubusercontent.com/chenchen0103/ACEBench/main/./fig/data_composition.png" alt="Data Composition" width="50%">
</p>

<span id="leaderboard">
</span>

## ğŸ† 3\. ë¦¬ë”ë³´ë“œ [[ë§¨ ìœ„ë¡œ]](#content)

| ëª¨ë¸                                   | ì¼ë°˜    | íŠ¹ìˆ˜    | ì—ì´ì „íŠ¸ | ì „ì²´    |
| ------------------------------------- | ------ | ------- | ------- | ------- |
| **ë¹„ê³µê°œ ì†ŒìŠ¤ ëª¨ë¸**                   |
| gpt-4o-2024-11-20                     | 0.927  | 0.933   | 0.715   | 0.896   |
| gpt-4-turbo-2024-04-09                | 0.917  | 0.913   | 0.725   | 0.886   |
| qwen-max                              | 0.887  | 0.740   | 0.685 | 0.817   |
| o1-preview                            | 0.830  | 0.793   | 0.735 | 0.806   |
| deepseek-chat                         | 0.926  | 0.733   | 0.350 | 0.785   |
| gpt-4o-mini-2024-07-18                | 0.834  | 0.813   | 0.390 | 0.760   |
| claude-3-5-sonnet-20241022            | 0.835  | 0.820   | 0.350 | 0.756   |
| gemini-1.5-pro                        | 0.822  | 0.800   | 0.250 | 0.728   |
| o1-mini                               | 0.774  | 0.673   | 0.610 | 0.722   |
| doubao-pro-32k                        | 0.750  | 0.593   | 0.235 | 0.628   |
| **ì˜¤í”ˆ ì†ŒìŠ¤ ëª¨ë¸**                    |
| Qwen2.5-Coder-32B-Instruct-local      | 0.908  | 0.813   | 0.715 | 0.853   |
| Qwen2.5-32B-Instruct-local            | 0.852  | 0.747   | 0.690 | 0.799   |
| Qwen2.5-72B-Instruct-local            | 0.873  | 0.773   | 0.525 | 0.793   |
| Qwen2.5-Coder-14B-Instruct-local      | 0.868  | 0.647   | 0.525 | 0.756   |
| Qwen2.5-14B-Instruct-local            | 0.790  | 0.540   | 0.250 | 0.640   |
| Llama-3.1-70B-Instruct-local          | 0.753  | 0.473   | 0.435 | 0.629   |
| Qwen2.5-7B-Instruct-local             | 0.759  | 0.447   | 0.125 | 0.578   |
| DeepSeek-Coder-V2-Lite-Instruct-local | 0.688  | 0.413   | 0.015 | 0.511   |
| Qwen2.5-Coder-7B-Instruct-local       | 0.735  | 0.193   | 0.125 | 0.496   |
| watt-tool-8B-local                    | 0.763  | 0.100   | 0.040 | 0.474   |
| ToolACE-8B-local                      | 0.782  | 0.013   | 0.040 | 0.462   |
| Hammer2.1-7b-local                    | 0.627  | 0.260   | 0.185 | 0.461   |
| Meta-Llama-3.1-8B-Instruct-local      | 0.450  | 0.267   | 0.040 | 0.338   |
| Qwen2.5-Coder-3B-Instruct-local       | 0.495  | 0.100   | 0.065 | 0.323   |
| Phi-3-mini-128k-instruct-local        | 0.389  | 0.253   | 0.015 | 0.295   |
| Qwen2.5-3B-Instruct-local             | 0.408  | 0.127   | 0.065 | 0.280   |
| Llama-3.2-3B-Instruct-local           | 0.327  | 0.100   | 0.000 | 0.216   |
| xLAM-7b-r-local                       | 0.187  | 0.013   | 0.075 | 0.123   |
| Hammer2.1-3b-local                    | 0.118  | 0.013   | 0.015 | 0.074   |

---

<span id="setup">
</span>

## ğŸ› ï¸ 4\. ì„¤ì¹˜ [[ë§¨ ìœ„ë¡œ ì´ë™]](#content)

ì¶”ë¡  ë° í‰ê°€ì— í•„ìš”í•œ ì˜ì¡´ì„±ì„ ì„¤ì¹˜í•˜ë ¤ë©´ ë‹¤ìŒ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”:

```bash
pip install -r requirements.txt
```

---

## ğŸ—‚ï¸ 5\. ë°ì´í„° [[ë§¨ ìœ„ë¡œ]](#content)

<span id="load_data">
</span>

ëª¨ë“  ë°ì´í„°ëŠ” data_all ë””ë ‰í„°ë¦¬ì— ì €ì¥ë˜ì–´ ìˆìœ¼ë©°, ì˜ì–´ì™€ ì¤‘êµ­ì–´ ë¶€ë¶„ìœ¼ë¡œ ë‚˜ëˆ„ì–´ì ¸ ê°ê° data_en ë° data_zh í´ë”ì— ìœ„ì¹˜í•©ë‹ˆë‹¤. ê° í´ë”ì—ëŠ” data_{category}.json í˜•ì‹ìœ¼ë¡œ ì´ë¦„ ë¶™ì—¬ì§„ ì—¬ëŸ¬ ê°œì˜ JSON íŒŒì¼ì´ í¬í•¨ë˜ì–´ ìˆìœ¼ë©°, ì—¬ê¸°ì„œ categoryëŠ” ë°ì´í„° ìœ í˜•ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.

```
data_all/
â”œâ”€â”€ possible_answer_en/        
â”‚   â”œâ”€â”€ data_{normal}.json
â”‚   â”œâ”€â”€ data_{special}.json
â”‚   â”œâ”€â”€ data_{agent}.json
â”œâ”€â”€ possible_answer_zh/        
â”‚   â”œâ”€â”€ data_{normal}.json
â”‚   â”œâ”€â”€ data_{special}.json
â”‚   â”œâ”€â”€ data_{agent}.json
...
```
## ğŸ§  6\. ì¶”ë¡  [[ë§¨ ìœ„ë¡œ]](#content)

<span id="open_source_inference">
</span>

### 6.1 ì¶”ë¡  ìŠ¤í¬ë¦½íŠ¸

cmodelsë¡œ ì¶”ë¡ ì„ ì‹¤í–‰í•˜ë ¤ë©´ `generate.py` ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”. ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ë‹¤ì–‘í•œ ëª¨ë¸, ì¹´í…Œê³ ë¦¬ ë° ì–¸ì–´ë¥¼ ì§€ì›í•©ë‹ˆë‹¤.

### ê¸°ë³¸ ì‚¬ìš©ë²•


```bash
python generate.py  --model <model_name>  --model_path <model_path>  
--category <category> --language <language> 
```
Arguments:

- `--model`: ì¶”ë¡ ì— ì‚¬ìš©í•  ëª¨ë¸ì„ ì§€ì •í•©ë‹ˆë‹¤.
- `--model_path`: ëª¨ë¸ì˜ ë¡œì»¬ ê²½ë¡œë¥¼ ì§€ì •í•©ë‹ˆë‹¤ (ì˜¤í”ˆ ì†ŒìŠ¤ ëª¨ë¸ì—ë§Œ í•´ë‹¹).
- `--category`: í‰ê°€í•  ì‘ì—… ë˜ëŠ” ë°ì´í„°ì…‹ì˜ ì¹´í…Œê³ ë¦¬ë¥¼ ì •ì˜í•©ë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥í•œ ì¹´í…Œê³ ë¦¬ëŠ” eval_checker/eval_checker_constant.pyì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- `--language`: ì…ë ¥/ì¶œë ¥ì˜ ì–¸ì–´ë¥¼ ì§€ì •í•©ë‹ˆë‹¤. ì§€ì› ì–¸ì–´: "en" (ì˜ì–´), "zh" (ì¤‘êµ­ì–´)

<!-- - `--do_sample`: ìƒì„± ì¤‘ í† í° ìƒ˜í”Œë§ì„ í™œì„±í™”í•©ë‹ˆë‹¤. ê¸°ë³¸ê°’ì€ ê·¸ë¦¬ë”” ë””ì½”ë”©ì…ë‹ˆë‹¤.
- `--temperature`: ìƒ˜í”Œë§ ì˜¨ë„, `--do_sample`ê³¼ í•¨ê»˜ë§Œ ì ìš©ë©ë‹ˆë‹¤.
- `--top_p`: í† í° ìƒ˜í”Œë§ì„ ìœ„í•œ ëˆ„ì  í™•ë¥  ì„ê³„ê°’, `--do_sample`ê³¼ í•¨ê»˜ë§Œ ì ìš©ë©ë‹ˆë‹¤.
- `--max_new_tokens`: ìƒì„±í•  ìµœëŒ€ í† í° ìˆ˜, ê¸°ë³¸ê°’ì€ 1024ì…ë‹ˆë‹¤. -->

### 6.2\. ì¶”ë¡  ì˜ˆì œ

ë¹„ê³µê°œ ì†ŒìŠ¤ ëª¨ë¸ìš©


```bash
python generate.py --model qwen-max --category test_all --language zh
```
ë¡œì»¬ ëª¨ë¸ìš©


```bash
python generate.py --model Qwen2.5-3B-Instruct-local --model-path /mnt/nas/ckpt/Qwen2.5-3B-Instruct --category test_all --language zh
```

### 6.3\. ì£¼ì˜ì‚¬í•­

* í”„ë¡œê·¸ë¨ì„ ì‹¤í–‰í•˜ê¸° ì „ì— í™˜ê²½ ë³€ìˆ˜ .env íŒŒì¼ì´ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”. OpenAIë¥¼ í˜¸ì¶œí•˜ë ¤ë©´ ì™¸ë¶€ ë„¤íŠ¸ì›Œí¬ë¥¼ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤. í™˜ê²½ ë³€ìˆ˜ https_proxyì™€ http_proxyë¥¼ ì„¤ì •í•˜ì„¸ìš”. gemini ëª¨ë¸ì„ ì‚¬ìš©í•˜ë ¤ë©´ ì¼ë³¸ í”„ë¡ì‹œë¥¼ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.
* í‰ê°€í•  ëª¨ë¸ì€ model_inference/inference_map.pyì— ë§¤í•‘ë˜ì–´ì•¼ í•©ë‹ˆë‹¤. OpenAIë¥¼ í†µí•´ í˜¸ì¶œë˜ëŠ” ëª¨ë¸ì€ APIModelInference ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€í•  ìˆ˜ ìˆìœ¼ë©°, ì»¤ìŠ¤í„°ë§ˆì´ì¦ˆëœ ì¶”ë¡  ëª¨ë¸ì€ CommonInference ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë¡œì»¬ ëª¨ë¸ì˜ ì´ë¦„ì€ -localë¡œ ëë‚©ë‹ˆë‹¤.
* ì»¤ìŠ¤í„°ë§ˆì´ì¦ˆëœ í‰ê°€ ëª¨ë¸ì„ ì¶”ê°€í•˜ë ¤ë©´ model_inference/model_infer.pyë¥¼ ì°¸ê³ í•˜ì—¬ model_dictì— ëª¨ë¸ í´ë˜ìŠ¤ë¥¼ ì¶”ê°€í•˜ì„¸ìš”.
* ì˜¤í”ˆ ì†ŒìŠ¤ ëª¨ë¸ì€ Hugging Faceì—ì„œ í‰ê°€í•˜ì„¸ìš”. LoRA ê°€ì¤‘ì¹˜ë¥¼ ê²°í•©í•˜ì—¬ ì¶”ë¡ í•˜ë ¤ë©´ LLaMA-Factoryë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ê¶Œì¥ë©ë‹ˆë‹¤.

## ğŸ“ˆ 7. í‰ê°€ [[ë§¨ ìœ„ë¡œ]](#content)

ëª¨ë¸ ì„±ëŠ¥ì„ í‰ê°€í•˜ë ¤ë©´ `eval_main.py` ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”. ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ë‹¤ì–‘í•œ í‰ê°€ ì§€í‘œë¥¼ ì§€ì›í•˜ë©° ì˜¤í”ˆ ì†ŒìŠ¤ ë° íì‡„ ì†ŒìŠ¤ ëª¨ë¸ ëª¨ë‘ì— ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ê¸°ë³¸ ì‚¬ìš©ë²•

```bash
python eval_main.py --model <model_name> --category <category> --language <language>
```

## ğŸ“„ ì¸ìš©

ì €í¬ ë…¼ë¬¸ê³¼ ìë£Œê°€ ìœ ìš©í•˜ë‹¤ë©´, ë…¼ë¬¸ì„ ì¸ìš©í•´ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤:

```bibtex
@article{chen2025acebench,
  title={ACEBench: Who Wins the Match Point in Tool Learning?},
  author={Chen, Chen and Hao, Xinlong and Liu, Weiwen and Huang, Xu and Zeng, Xingshan and Yu, Shuai and Li, Dexun and Wang, Shuai and Gan, Weinan and Huang, Yuefeng and others},
  journal={arXiv preprint arXiv:2501.12851},
  year={2025}
}
```


---

Tranlated By [Open Ai Tx](https://github.com/OpenAiTx/OpenAiTx) | Last indexed: 2025-12-19

---