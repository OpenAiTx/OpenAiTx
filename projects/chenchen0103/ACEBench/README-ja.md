# ACEBench: ãƒ„ãƒ¼ãƒ«ä½¿ç”¨ã®ãƒãƒƒãƒãƒã‚¤ãƒ³ãƒˆã‚’åˆ¶ã™ã‚‹ã®ã¯èª°ã‹ï¼Ÿ

<p align="center">
  <a href="https://arxiv.org/abs/2501.12851">ğŸ“ƒ è«–æ–‡ </a>
  <b>&nbsp;Â·&nbsp;</b> <a href="https://chenchen0103.github.io/ACEBench/">ğŸ† ãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰ï¼ˆç¶™ç¶šçš„ã«æ›´æ–°ä¸­ï¼‰</a>
</p>

English | [ä¸­æ–‡](https://raw.githubusercontent.com/chenchen0103/ACEBench/main/README_CN.md)

## ğŸ“š ã‚³ãƒ³ãƒ†ãƒ³ãƒ„

- [1\. ã‚¢ãƒ–ã‚¹ãƒˆãƒ©ã‚¯ãƒˆ](#abstract)
- [2\. ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµ±è¨ˆ](#statistics)
- [3\. ãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰](#leaderboard)
- [4\. ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—](#setup)
- [5\. ãƒ‡ãƒ¼ã‚¿](#data)
- [6\. æ¨è«–](#inference)
  - [6.1\. æ¨è«–ã‚¹ã‚¯ãƒªãƒ—ãƒˆ](#open_source_inference)
  - [6.2\. æ¨è«–ä¾‹](#openai_inference)
- [7\. è©•ä¾¡](#evaluation)
- [å¼•ç”¨](#citation)

---

## ğŸ› ï¸ æ›´æ–°æƒ…å ± [[ãƒˆãƒƒãƒ—ã«æˆ»ã‚‹]](#content)

### [2025.10.29]

1 normal_atom_enum_9ã€normal_atom_number_17ã€ãŠã‚ˆã³ normal_atom_list_34 ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®å¯èƒ½ãªå›ç­”ã‚’ä¿®æ­£ã—ã¾ã—ãŸã€‚


<span id="abstract">
</span>

## ğŸ“˜ 1\. ã‚¢ãƒ–ã‚¹ãƒˆãƒ©ã‚¯ãƒˆ [[ãƒˆãƒƒãƒ—ã«æˆ»ã‚‹]](#content)

Large Language Models (LLMs) have demonstrated significant potential in decision-making and reasoning, particularly when integrated with various tools to effectively solve complex problems. However, existing benchmarks for evaluating LLMs' tool usage face several limitations: (1) limited evaluation scenarios, often lacking assessments in real multi-turn dialogue contexts; (2) narrow evaluation dimensions, with insufficient detailed assessments of how LLMs use tools; and (3) reliance on LLMs or real API executions for evaluation, which introduces significant overhead. To address these challenges, we introduce ACEBench, a comprehensive benchmark for assessing tool usage in LLMs. ACEBench categorizes data into three primary types based on evaluation methodology: Normal, Special, and Agent. "Normal" evaluates tool usage in basic scenarios; "Special" evaluates tool usage in situations with ambiguous or incomplete instructions; "Agent" evaluates tool usage through multi-agent interactions to simulate real-world, multi-turn dialogues. We conducted extensive experiments using ACEBench, analyzing various LLMs in-depth and providing a more granular examination of error causes across different data types.

---

<span id="statistics">
</span>

## ğŸ“Š 2.Benchmarkãƒ‡ãƒ¼ã‚¿åˆ†æ [[ãƒˆãƒƒãƒ—ã«æˆ»ã‚‹]](#content)

### **APIã®ãƒ‰ãƒ¡ã‚¤ãƒ³**

- ACEBenchã¯ã€æŠ€è¡“ã€é‡‘èã€ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ†ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆã€ç¤¾ä¼šã€å¥åº·ã€æ–‡åŒ–ã€ç’°å¢ƒãªã©ã€**8ã¤ã®ä¸»è¦ãƒ‰ãƒ¡ã‚¤ãƒ³**ã¨**68ã®ã‚µãƒ–ãƒ‰ãƒ¡ã‚¤ãƒ³**ã‚’ã‚«ãƒãƒ¼ã—ã¦ã„ã¾ã™ã€‚
- ä¸­å›½èªã¨è‹±èªã®ä¸¡æ–¹ã§åˆè¨ˆ**4,538ã®API**ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚
- ãƒ‰ãƒ¡ã‚¤ãƒ³åˆ¥ã®APIåˆ†å¸ƒã¯ä¸‹å›³ã«ç¤ºã•ã‚Œã¦ã„ã¾ã™:

<p align="center">
  <img src="https://raw.githubusercontent.com/chenchen0103/ACEBench/main/./fig/api_domain.png" alt="APIãƒ‰ãƒ¡ã‚¤ãƒ³åˆ†å¸ƒ" width="60%">
</p>

### **ãƒ‡ãƒ¼ã‚¿æ§‹æˆ**

- ACEBenchã¯ä¸»ã«3ã¤ã®ãƒ†ã‚¹ãƒˆã‚µãƒ³ãƒ—ãƒ«ã‚«ãƒ†ã‚´ãƒªã§æ§‹æˆã•ã‚Œã¦ã„ã¾ã™:
  - **Normal**: åŸºæœ¬çš„ãªãƒ„ãƒ¼ãƒ«ä½¿ç”¨ã‚·ãƒŠãƒªã‚ªã€‚
  - **Agent**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ç’°å¢ƒã®ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã€‚
  - **Special**: è¤‡æ•°ã‚¹ãƒ†ãƒƒãƒ—ã‚’è¦ã™ã‚‹è¤‡é›‘ãªã‚·ãƒŠãƒªã‚ªã‚„å®Ÿè¡Œä¸å¯èƒ½ãªãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ã‚’æ‰±ã†ã‚‚ã®ã€‚
- ãƒ‡ãƒ¼ã‚¿æ§‹æˆã¯ä¸‹å›³ã«ç¤ºã•ã‚Œã€ãƒ„ãƒ¼ãƒ«ä½¿ç”¨èƒ½åŠ›ã®åŒ…æ‹¬çš„ãªã‚«ãƒãƒ¬ãƒƒã‚¸ã‚’ç¤ºã—ã¦ã„ã¾ã™:

<p align="center">
  <img src="https://raw.githubusercontent.com/chenchen0103/ACEBench/main/./fig/data_composition.png" alt="ãƒ‡ãƒ¼ã‚¿æ§‹æˆ" width="50%">
</p>

<span id="leaderboard">
</span>

## ğŸ† 3\. ãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰ [[ãƒˆãƒƒãƒ—ã«æˆ»ã‚‹]](#content)

| ãƒ¢ãƒ‡ãƒ«                                | normal | special | agent | overall |
| ------------------------------------- | ------ | ------- | ----- | ------- |
| **ã‚¯ãƒ­ãƒ¼ã‚ºãƒ‰ã‚½ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«**            |
| gpt-4o-2024-11-20                     | 0.927  | 0.933   | 0.715 | 0.896   |
| gpt-4-turbo-2024-04-09                | 0.917  | 0.913   | 0.725 | 0.886   |
| qwen-max                              | 0.887  | 0.740   | 0.685 | 0.817   |
| o1-preview                            | 0.830  | 0.793   | 0.735 | 0.806   |
| deepseek-chat                         | 0.926  | 0.733   | 0.350 | 0.785   |
| gpt-4o-mini-2024-07-18                | 0.834  | 0.813   | 0.390 | 0.760   |
| claude-3-5-sonnet-20241022            | 0.835  | 0.820   | 0.350 | 0.756   |
| gemini-1.5-pro                        | 0.822  | 0.800   | 0.250 | 0.728   |
| o1-mini                               | 0.774  | 0.673   | 0.610 | 0.722   |
| doubao-pro-32k                        | 0.750  | 0.593   | 0.235 | 0.628   |
| **ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«**                 |
| Qwen2.5-Coder-32B-Instruct-local      | 0.908  | 0.813   | 0.715 | 0.853   |
| Qwen2.5-32B-Instruct-local            | 0.852  | 0.747   | 0.690 | 0.799   |
| Qwen2.5-72B-Instruct-local            | 0.873  | 0.773   | 0.525 | 0.793   |
| Qwen2.5-Coder-14B-Instruct-local      | 0.868  | 0.647   | 0.525 | 0.756   |
| Qwen2.5-14B-Instruct-local            | 0.790  | 0.540   | 0.250 | 0.640   |
| Llama-3.1-70B-Instruct-local          | 0.753  | 0.473   | 0.435 | 0.629   |
| Qwen2.5-7B-Instruct-local             | 0.759  | 0.447   | 0.125 | 0.578   |
| DeepSeek-Coder-V2-Lite-Instruct-local | 0.688  | 0.413   | 0.015 | 0.511   |
| Qwen2.5-Coder-7B-Instruct-local       | 0.735  | 0.193   | 0.125 | 0.496   |
| watt-tool-8B-local                    | 0.763  | 0.100   | 0.040 | 0.474   |
| ToolACE-8B-local                      | 0.782  | 0.013   | 0.040 | 0.462   |
| Hammer2.1-7b-local                    | 0.627  | 0.260   | 0.185 | 0.461   |
| Meta-Llama-3.1-8B-Instruct-local      | 0.450  | 0.267   | 0.040 | 0.338   |
| Qwen2.5-Coder-3B-Instruct-local       | 0.495  | 0.100   | 0.065 | 0.323   |
| Phi-3-mini-128k-instruct-local        | 0.389  | 0.253   | 0.015 | 0.295   |
| Qwen2.5-3B-Instruct-local             | 0.408  | 0.127   | 0.065 | 0.280   |
| Llama-3.2-3B-Instruct-local           | 0.327  | 0.100   | 0.000 | 0.216   |
| xLAM-7b-r-local                       | 0.187  | 0.013   | 0.075 | 0.123   |
| Hammer2.1-3b-local                    | 0.118  | 0.013   | 0.015 | 0.074   |

---

<span id="setup">
</span>

## ğŸ› ï¸ 4\. ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ— [[ãƒˆãƒƒãƒ—ã«æˆ»ã‚‹]](#content)

æ¨è«–ã¨è©•ä¾¡ã«å¿…è¦ãªä¾å­˜é–¢ä¿‚ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹ã«ã¯ã€ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„:

```bash
pip install -r requirements.txt
```

---

## ğŸ—‚ï¸ 5\. ãƒ‡ãƒ¼ã‚¿ [[ãƒˆãƒƒãƒ—ã¸æˆ»ã‚‹]](#content)

<span id="load_data">
</span>

ã™ã¹ã¦ã®ãƒ‡ãƒ¼ã‚¿ã¯ data_all ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ä¿å­˜ã•ã‚Œã¦ãŠã‚Šã€è‹±èªã¨ä¸­å›½èªã®éƒ¨åˆ†ã«åˆ†ã‹ã‚Œã¦ã„ã¾ã™ã€‚ã“ã‚Œã‚‰ã¯ãã‚Œãã‚Œ data_en ã¨ data_zh ãƒ•ã‚©ãƒ«ãƒ€ã«ã‚ã‚Šã¾ã™ã€‚å„ãƒ•ã‚©ãƒ«ãƒ€ã«ã¯è¤‡æ•°ã® JSON ãƒ•ã‚¡ã‚¤ãƒ«ãŒå«ã¾ã‚Œã¦ãŠã‚Šã€ãƒ•ã‚¡ã‚¤ãƒ«åã¯ data_{category}.json ã®å½¢å¼ã§ã€category ã¯ãƒ‡ãƒ¼ã‚¿ã®ç¨®é¡ã‚’è¡¨ã—ã¦ã„ã¾ã™ã€‚

```
data_all/
â”œâ”€â”€ possible_answer_en/        
â”‚   â”œâ”€â”€ data_{normal}.json
â”‚   â”œâ”€â”€ data_{special}.json
â”‚   â”œâ”€â”€ data_{agent}.json
â”œâ”€â”€ possible_answer_zh/        
â”‚   â”œâ”€â”€ data_{normal}.json
â”‚   â”œâ”€â”€ data_{special}.json
â”‚   â”œâ”€â”€ data_{agent}.json
...
```

## ğŸ§  6\. æ¨è«– [[ãƒˆãƒƒãƒ—ã¸æˆ»ã‚‹]](#content)

<span id="open_source_inference">
</span>

### 6.1 æ¨è«–ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

cmodelsã§æ¨è«–ã‚’å®Ÿè¡Œã™ã‚‹ã«ã¯ã€`generate.py`ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ä½¿ç”¨ã—ã¾ã™ã€‚ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ã•ã¾ã–ã¾ãªãƒ¢ãƒ‡ãƒ«ã€ã‚«ãƒ†ã‚´ãƒªã€è¨€èªã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™ã€‚

### åŸºæœ¬çš„ãªä½¿ã„æ–¹

```bash
python generate.py  --model <model_name>  --model_path <model_path>  
--category <category> --language <language> 
```

Arguments:

- `--model`: æ¨è«–ã«ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’æŒ‡å®šã—ã¾ã™ã€‚
- `--model_path`: ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‘ã‚¹ã‚’æŒ‡å®šã—ã¾ã™ï¼ˆã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã®ã¿ï¼‰ã€‚
- `--category`: è©•ä¾¡ã™ã‚‹ã‚¿ã‚¹ã‚¯ã¾ãŸã¯ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã‚«ãƒ†ã‚´ãƒªã‚’å®šç¾©ã—ã¾ã™ã€‚åˆ©ç”¨å¯èƒ½ãªã‚«ãƒ†ã‚´ãƒªã¯eval_checker/eval_checker_constant.pyã§ç¢ºèªã§ãã¾ã™ã€‚
- `--language`: å…¥å‡ºåŠ›ã®è¨€èªã‚’æŒ‡å®šã—ã¾ã™ã€‚å¯¾å¿œè¨€èªï¼š"en"ï¼ˆè‹±èªï¼‰ã€"zh"ï¼ˆä¸­å›½èªï¼‰

<!-- - `--do_sample`: ç”Ÿæˆæ™‚ã«ãƒˆãƒ¼ã‚¯ãƒ³ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã‚’æœ‰åŠ¹ã«ã—ã¾ã™ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯è²ªæ¬²ãƒ‡ã‚³ãƒ¼ãƒ‰ã§ã™ã€‚
- `--temperature`: ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ¸©åº¦ã§ã€`--do_sample`ä½¿ç”¨æ™‚ã®ã¿é©ç”¨ã•ã‚Œã¾ã™ã€‚
- `--top_p`: ãƒˆãƒ¼ã‚¯ãƒ³ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã®ç´¯ç©ç¢ºç‡é–¾å€¤ã§ã€`--do_sample`ä½¿ç”¨æ™‚ã®ã¿é©ç”¨ã•ã‚Œã¾ã™ã€‚
- `--max_new_tokens`: ç”Ÿæˆã™ã‚‹æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã§ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯1024ã§ã™ã€‚ -->

### 6.2\. æ¨è«–ä¾‹

ã‚¯ãƒ­ãƒ¼ã‚ºãƒ‰ã‚½ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã®å ´åˆ

```bash
python generate.py --model qwen-max --category test_all --language zh
```
ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ãƒ‡ãƒ«ç”¨


```bash
python generate.py --model Qwen2.5-3B-Instruct-local --model-path /mnt/nas/ckpt/Qwen2.5-3B-Instruct --category test_all --language zh
```

### 6.3\. æ³¨æ„äº‹é …

* ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’å®Ÿè¡Œã™ã‚‹å‰ã«ã€ç’°å¢ƒå¤‰æ•° .env ãƒ•ã‚¡ã‚¤ãƒ«ãŒæ­£ã—ãè¨­å®šã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚OpenAI ã‚’å‘¼ã³å‡ºã™ã«ã¯å¤–éƒ¨ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’ä½¿ç”¨ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ç’°å¢ƒå¤‰æ•° https_proxy ã¨ http_proxy ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚gemini ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹ã«ã¯ã€æ—¥æœ¬ã®ãƒ—ãƒ­ã‚­ã‚·ã‚’ä½¿ç”¨ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚
* è©•ä¾¡å¯¾è±¡ã®ãƒ¢ãƒ‡ãƒ«ã¯ model_inference/inference_map.py ã«ãƒãƒƒãƒ”ãƒ³ã‚°ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚OpenAI ã‚’é€šã˜ã¦å‘¼ã³å‡ºã™ãƒ¢ãƒ‡ãƒ«ã¯ APIModelInference ãƒªã‚¹ãƒˆã«è¿½åŠ ã§ãã€ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã—ãŸæ¨è«–ãƒ¢ãƒ‡ãƒ«ã¯ CommonInference ãƒªã‚¹ãƒˆã«è¿½åŠ ã§ãã¾ã™ã€‚ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ãƒ‡ãƒ«ã®åå‰ã¯ -local ã§çµ‚ã‚ã‚Šã¾ã™ã€‚
* ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã—ãŸè©•ä¾¡ãƒ¢ãƒ‡ãƒ«ã‚’è¿½åŠ ã™ã‚‹ã«ã¯ã€model_inference/model_infer.py ã‚’å‚ç…§ã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚¯ãƒ©ã‚¹ã‚’ model_dict ã«è¿½åŠ ã—ã¦ãã ã•ã„ã€‚
* ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã‚’ Hugging Face ä¸Šã§è©•ä¾¡ã™ã‚‹å ´åˆã¯ã€LLaMA-Factory ã‚’ä½¿ç”¨ã—ã¦ LoRA ã‚¦ã‚§ã‚¤ãƒˆã‚’çµ„ã¿åˆã‚ã›ã¦ã‹ã‚‰æ¨è«–ã™ã‚‹ã“ã¨ã‚’æ¨å¥¨ã—ã¾ã™ã€‚

## ğŸ“ˆ 7. è©•ä¾¡ [[ãƒˆãƒƒãƒ—ã¸æˆ»ã‚‹]](#content)

ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’è©•ä¾¡ã™ã‚‹ã«ã¯ã€`eval_main.py` ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ä½¿ç”¨ã—ã¾ã™ã€‚ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯æ§˜ã€…ãªè©•ä¾¡æŒ‡æ¨™ã«å¯¾å¿œã—ã¦ãŠã‚Šã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãŠã‚ˆã³ã‚¯ãƒ­ãƒ¼ã‚ºãƒ‰ã‚½ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã®ä¸¡æ–¹ã«ä½¿ç”¨ã§ãã¾ã™ã€‚

### åŸºæœ¬çš„ãªä½¿ã„æ–¹

```bash
python eval_main.py --model <model_name> --category <category> --language <language>
```

## ğŸ“„ å¼•ç”¨

å½“ç¤¾ã®è«–æ–‡ã‚„ãƒªã‚½ãƒ¼ã‚¹ãŒå½¹ã«ç«‹ã£ãŸå ´åˆã¯ã€ãœã²å½“ç¤¾ã®è«–æ–‡ã‚’å¼•ç”¨ã—ã¦ãã ã•ã„ã€‚

```bibtex
@article{chen2025acebench,
  title={ACEBench: Who Wins the Match Point in Tool Learning?},
  author={Chen, Chen and Hao, Xinlong and Liu, Weiwen and Huang, Xu and Zeng, Xingshan and Yu, Shuai and Li, Dexun and Wang, Shuai and Gan, Weinan and Huang, Yuefeng and others},
  journal={arXiv preprint arXiv:2501.12851},
  year={2025}
}
```


---

Tranlated By [Open Ai Tx](https://github.com/OpenAiTx/OpenAiTx) | Last indexed: 2025-12-19

---