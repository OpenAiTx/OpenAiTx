
<div align="right">
  <details>
    <summary >üåê Idioma</summary>
    <div>
      <div align="center">
        <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=en">English</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=zh-CN">ÁÆÄ‰Ωì‰∏≠Êñá</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=zh-TW">ÁπÅÈ´î‰∏≠Êñá</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=ja">Êó•Êú¨Ë™û</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=ko">ÌïúÍµ≠Ïñ¥</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=hi">‡§π‡§ø‡§®‡•ç‡§¶‡•Ä</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=th">‡πÑ‡∏ó‡∏¢</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=fr">Fran√ßais</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=de">Deutsch</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=es">Espa√±ol</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=it">Italiano</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=ru">–†—É—Å—Å–∫–∏–π</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=pt">Portugu√™s</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=nl">Nederlands</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=pl">Polski</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=ar">ÿßŸÑÿπÿ±ÿ®Ÿäÿ©</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=fa">ŸÅÿßÿ±ÿ≥€å</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=tr">T√ºrk√ße</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=vi">Ti·∫øng Vi·ªát</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=id">Bahasa Indonesia</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=as">‡¶Ö‡¶∏‡¶Æ‡ßÄ‡¶Ø‡¶º‡¶æ</
      </div>
    </div>
  </details>
</div>

# Mapperatorinator

Experimente o modelo generativo [aqui](https://colab.research.google.com/github/OliBomby/Mapperatorinator/blob/main/colab/mapperatorinator_inference.ipynb), ou o MaiMod [aqui](https://colab.research.google.com/github/OliBomby/Mapperatorinator/blob/main/colab/mai_mod_inference.ipynb). Veja uma demonstra√ß√£o em v√≠deo [aqui](https://youtu.be/FEr7t1L2EoA).

Mapperatorinator √© uma estrutura multi-modelo que utiliza entradas de espectrograma para gerar mapas de osu! completos para todos os modos de jogo e [auxiliar na modera√ß√£o de mapas](#maimod-the-ai-driven-modding-tool).
O objetivo deste projeto √© gerar automaticamente mapas de osu! com qualidade ranke√°vel a partir de qualquer m√∫sica, com alto grau de personaliza√ß√£o.

Este projeto √© baseado em [osuT5](https://github.com/gyataro/osuT5) e [osu-diffusion](https://github.com/OliBomby/osu-diffusion). No desenvolvimento, gastei cerca de 2500 horas de processamento de GPU em 142 execu√ß√µes na minha 4060 Ti e aluguei inst√¢ncias 4090 na vast.ai.

#### Use esta ferramenta de forma respons√°vel. Sempre divulgue o uso de IA em seus beatmaps.

## Instala√ß√£o

A instru√ß√£o abaixo permite que voc√™ gere beatmaps em sua m√°quina local, alternativamente voc√™ pode execut√°-la na nuvem com o [notebook do colab](https://colab.research.google.com/github/OliBomby/Mapperatorinator/blob/main/colab/mapperatorinator_inference.ipynb).

### 1. Clone o reposit√≥rio

```sh
git clone https://github.com/OliBomby/Mapperatorinator.git
cd Mapperatorinator
```

### 2. (Opcional) Crie um ambiente virtual

Use Python 3.10, vers√µes posteriores podem n√£o ser compat√≠veis com as depend√™ncias.

```sh
python -m venv .venv

# In cmd.exe
.venv\Scripts\activate.bat
# In PowerShell
.venv\Scripts\Activate.ps1
# In Linux or MacOS
source .venv/bin/activate
```

### 3. Instale as depend√™ncias

- Python 3.10
- [Git](https://git-scm.com/downloads)
- [ffmpeg](http://www.ffmpeg.org/)
- [CUDA](https://developer.nvidia.com/cuda-zone) (Para GPUs NVIDIA) ou [ROCm](https://rocmdocs.amd.com/en/latest/Installation_Guide/Installation-Guide.html) (Para GPUs AMD no Linux)
- [PyTorch](https://pytorch.org/get-started/locally/): Certifique-se de seguir o guia Get Started para instalar `torch` e `torchaudio` com suporte a GPU. Selecione a vers√£o correta da Plataforma de Computa√ß√£o que voc√™ instalou na etapa anterior.

- e as demais depend√™ncias Python:

```sh
pip install -r requirements.txt
```

## Interface Web (Recomendado)

Para uma experi√™ncia mais amig√°vel, considere usar a interface Web. Ela fornece uma interface gr√°fica para configurar os par√¢metros de gera√ß√£o, iniciar o processo e monitorar a sa√≠da.

### Iniciar a GUI

Navegue at√© o diret√≥rio clonado `Mapperatorinator` no seu terminal e execute:

```sh
python web-ui.py
```
Isso iniciar√° um servidor web local e abrir√° automaticamente a interface em uma nova janela.

### Usando a GUI

- **Configurar:** Defina os caminhos de entrada/sa√≠da usando os campos do formul√°rio e os bot√µes "Procurar". Ajuste os par√¢metros de gera√ß√£o como modo de jogo, dificuldade, estilo (ano, ID do mapeador, descritores), tempo, recursos espec√≠ficos (hitsounds, super timing) e mais, espelhando as op√ß√µes da linha de comando. (Nota: Se voc√™ fornecer um `beatmap_path`, a interface determinar√° automaticamente o `audio_path` e o `output_path` a partir dele, ent√£o voc√™ pode deixar esses campos em branco)
- **Iniciar:** Clique no bot√£o "Iniciar Infer√™ncia" para come√ßar a gera√ß√£o do beatmap.
- **Cancelar:** Voc√™ pode interromper o processo em andamento usando o bot√£o "Cancelar Infer√™ncia".
- **Abrir Sa√≠da:** Quando finalizar, use o bot√£o "Abrir Pasta de Sa√≠da" para acessar rapidamente os arquivos gerados.

A interface web atua como um wrapper conveniente em torno do script `inference.py`. Para op√ß√µes avan√ßadas ou resolu√ß√£o de problemas, consulte as instru√ß√µes da linha de comando.

![python_u3zyW0S3Vs](https://github.com/user-attachments/assets/5312a45f-d51c-4b37-9389-da3258ddd0a1)

## Infer√™ncia pela Linha de Comando

Para usu√°rios que preferem a linha de comando ou precisam acessar configura√ß√µes avan√ßadas, siga os passos abaixo. **Nota:** Para uma interface gr√°fica mais simples, consulte a se√ß√£o [Web UI (Recomendado)](#web-ui-recommended) acima.

Execute `inference.py` e passe alguns argumentos para gerar beatmaps. Para isso, use a [sintaxe de override do Hydra](https://hydra.cc/docs/advanced/override_grammar/basic/). Veja `configs/inference_v29.yaml` para todos os par√¢metros dispon√≠veis.

```
python inference.py \
  audio_path           [Path to input audio] \
  output_path          [Path to output directory] \
  beatmap_path         [Path to .osu file to autofill metadata, and output_path, or use as reference] \
  
  gamemode             [Game mode to generate 0=std, 1=taiko, 2=ctb, 3=mania] \
  difficulty           [Difficulty star rating to generate] \
  mapper_id            [Mapper user ID for style] \
  year                 [Upload year to simulate] \
  hitsounded           [Whether to add hitsounds] \
  slider_multiplier    [Slider velocity multiplier] \
  circle_size          [Circle size] \
  keycount             [Key count for mania] \
  hold_note_ratio      [Hold note ratio for mania 0-1] \
  scroll_speed_ratio   [Scroll speed ratio for mania and ctb 0-1] \
  descriptors          [List of beatmap user tags for style] \
  negative_descriptors [List of beatmap user tags for classifier-free guidance] \
  
  add_to_beatmap       [Whether to add generated content to the reference beatmap instead of making a new beatmap] \
  start_time           [Generation start time in milliseconds] \
  end_time             [Generation end time in milliseconds] \
  in_context           [List of additional context to provide to the model [NONE,TIMING,KIAI,MAP,GD,NO_HS]] \
  output_type          [List of content types to generate] \
  cfg_scale            [Scale of the classifier-free guidance] \
  super_timing         [Whether to use slow accurate variable BPM timing generator] \
  seed                 [Random seed for generation] \
```

Exemplo:
```
python inference.py beatmap_path="'C:\Users\USER\AppData\Local\osu!\Songs\1 Kenji Ninuma - DISCO PRINCE\Kenji Ninuma - DISCOPRINCE (peppy) [Normal].osu'" gamemode=0 difficulty=5.5 year=2023 descriptors="['jump aim','clean']" in_context=[TIMING,KIAI]
```

## CLI Interativo
Para quem prefere um fluxo de trabalho baseado em terminal, mas deseja uma configura√ß√£o guiada, o script CLI interativo √© uma excelente alternativa √† interface web.

### Iniciar o CLI
Navegue at√© o diret√≥rio clonado. Voc√™ pode precisar tornar o script execut√°vel primeiro.

```sh
# Make the script executable (only needs to be done once)
chmod +x cli_inference.sh
```

```sh
# Run the script
./cli_inference.sh
```

### Usando o CLI
O script ir√° gui√°-lo por uma s√©rie de prompts para configurar todos os par√¢metros de gera√ß√£o, assim como a interface Web.

Ele utiliza uma interface com c√≥digo de cores para maior clareza.
Oferece um menu avan√ßado de m√∫ltipla sele√ß√£o para escolher os descritores de estilo usando as teclas de seta e barra de espa√ßo.
Ap√≥s responder todas as perguntas, exibir√° o comando final para sua revis√£o.
Voc√™ pode ent√£o confirmar para execut√°-lo diretamente ou cancelar e copiar o comando para uso manual.

## Dicas de Gera√ß√£o

- Voc√™ pode editar o arquivo `configs/inference_v29.yaml` e adicionar seus argumentos l√° ao inv√©s de digit√°-los no terminal toda vez.
- Todos os descritores dispon√≠veis podem ser encontrados [aqui](https://osu.ppy.sh/wiki/en/Beatmap/Beatmap_tags).
- Sempre forne√ßa um argumento de ano entre 2007 e 2023. Se deixar desconhecido, o modelo pode gerar com um estilo inconsistente.
- Sempre forne√ßa um argumento de dificuldade. Se deixar desconhecido, o modelo pode gerar com uma dificuldade inconsistente.
- Aumente o par√¢metro `cfg_scale` para aumentar a efetividade dos argumentos `mapper_id` e `descriptors`.
- Voc√™ pode usar o argumento `negative_descriptors` para direcionar o modelo a evitar certos estilos. Isso s√≥ funciona quando `cfg_scale > 1`. Certifique-se de que o n√∫mero de descritores negativos seja igual ao n√∫mero de descritores.
- Se o estilo da sua m√∫sica e o estilo de beatmap desejado n√£o combinarem bem, o modelo pode n√£o seguir suas dire√ß√µes. Por exemplo, √© dif√≠cil gerar um beatmap de SR alto e SV alto para uma m√∫sica calma.
- Se voc√™ j√° tem timing e kiai times prontos para uma m√∫sica, pode fornec√™-los ao modelo para aumentar muito a velocidade e precis√£o da infer√™ncia: Use os argumentos `beatmap_path` e `in_context=[TIMING,KIAI]`.
- Para remapear apenas uma parte do seu beatmap, use os argumentos `beatmap_path`, `start_time`, `end_time`, e `add_to_beatmap=true`.
- Para gerar uma dificuldade guest para um beatmap, use os argumentos `beatmap_path` e `in_context=[GD,TIMING,KIAI]`.
- Para gerar hitsounds para um beatmap, use os argumentos `beatmap_path` e `in_context=[NO_HS,TIMING,KIAI]`.
- Para gerar apenas o timing para uma m√∫sica, use os argumentos `super_timing=true` e `output_type=[TIMING]`.

## MaiMod: A Ferramenta de Modding com IA

MaiMod √© uma ferramenta de modding para beatmaps do osu! que utiliza previs√µes do Mapperatorinator para encontrar poss√≠veis falhas e inconsist√™ncias que n√£o podem ser detectadas por outras ferramentas autom√°ticas de modding como a [Mapset Verifier](https://github.com/Naxesss/MapsetVerifier).
Ela pode detectar problemas como:
- Snapping incorreto ou padr√µes r√≠tmicos inconsistentes
- Pontos de timing imprecisos
- Posi√ß√µes inconsistentes de hit objects ou placements de new combo
- Formatos estranhos de sliders
- Hitsounds ou volumes inconsistentes

Voc√™ pode experimentar o MaiMod [aqui](https://colab.research.google.com/github/OliBomby/Mapperatorinator/blob/main/colab/mai_mod_inference.ipynb), ou execut√°-lo localmente:
Para executar o MaiMod localmente, ser√° necess√°rio instalar o Mapperatorinator. Depois, execute o script `mai_mod.py`, especificando o caminho do seu beatmap com o argumento `beatmap_path`.
```sh
python mai_mod.py beatmap_path="'C:\Users\USER\AppData\Local\osu!\Songs\1 Kenji Ninuma - DISCO PRINCE\Kenji Ninuma - DISCOPRINCE (peppy) [Normal].osu'"
```
Isso imprimir√° as sugest√µes de modding no console, que voc√™ poder√° ent√£o aplicar manualmente ao seu beatmap.
As sugest√µes s√£o ordenadas cronologicamente e agrupadas em categorias.
O primeiro valor no c√≠rculo indica o 'surprisal', que √© uma medida de qu√£o inesperado o modelo considerou o problema, para que voc√™ possa priorizar as quest√µes mais importantes.

O modelo pode cometer erros, especialmente em quest√µes de baixo surprisal, ent√£o sempre confira as sugest√µes antes de aplic√°-las ao seu beatmap.
O objetivo principal √© ajud√°-lo a reduzir o espa√ßo de busca por poss√≠veis problemas, para que voc√™ n√£o precise verificar manualmente cada objeto de hit no seu beatmap.

### MaiMod GUI
Para executar a interface web do MaiMod, voc√™ precisar√° instalar o Mapperatorinator.
Em seguida, execute o script `mai_mod_ui.py`. Isso iniciar√° um servidor web local e abrir√° automaticamente a interface em uma nova janela:

```sh
python mai_mod_ui.py
```

<img width="850" height="1019" alt="afbeelding" src="https://github.com/user-attachments/assets/67c03a43-a7bd-4265-a5b1-5e4d62aca1fa" />

## Vis√£o Geral

### Tokeniza√ß√£o

Mapperatorinator converte mapas de ritmo do osu! em uma representa√ß√£o intermedi√°ria de eventos que pode ser convertida diretamente para e de tokens.
Inclui objetos de acerto, sons de acerto, velocidades de slider, novos combos, pontos de tempo, tempos de kiai e velocidades de rolagem de taiko/mania.

Aqui est√° um pequeno exemplo do processo de tokeniza√ß√£o:

![mapperatorinator_parser](https://github.com/user-attachments/assets/84efde76-4c27-48a1-b8ce-beceddd9e695)

Para economizar no tamanho do vocabul√°rio, os eventos de tempo s√£o quantizados em intervalos de 10ms e as coordenadas de posi√ß√£o s√£o quantizadas em pontos de grade de 32 pixels.

### Arquitetura do modelo
O modelo √© basicamente um wrapper em torno do [HF Transformers Whisper](https://huggingface.co/docs/transformers/en/model_doc/whisper#transformers.WhisperForConditionalGeneration), com embeddings de entrada e fun√ß√£o de perda personalizados.
O tamanho do modelo √© de 219M par√¢metros.
Este modelo foi considerado mais r√°pido e preciso do que o T5 para esta tarefa.

A vis√£o geral de alto n√≠vel da entrada e sa√≠da do modelo √© a seguinte:

![Picture2](https://user-images.githubusercontent.com/28675590/201044116-1384ad72-c540-44db-a285-7319dd01caad.svg)

O modelo utiliza frames de espectrograma Mel como entrada do encoder, com um frame por posi√ß√£o de entrada. A sa√≠da do decoder do modelo em cada passo √© uma distribui√ß√£o softmax sobre um vocabul√°rio discreto e predefinido de eventos. As sa√≠das s√£o esparsas, os eventos s√≥ s√£o necess√°rios quando um objeto de acerto ocorre, em vez de anotar cada frame de √°udio.

### Formato de treinamento multitarefa

![Multitask training format](https://github.com/user-attachments/assets/62f490bc-a567-4671-a7ce-dbcc5f9cd6d9)

Antes do token SOS existem tokens adicionais que facilitam a gera√ß√£o condicional. Estes tokens incluem o modo de jogo, dificuldade, ID do mapeador, ano e outros metadados.
Durante o treinamento, esses tokens n√£o possuem r√≥tulos correspondentes, ent√£o nunca s√£o emitidos pelo modelo.
Tamb√©m durante o treinamento existe uma chance aleat√≥ria de um token de metadado ser substitu√≠do por um token 'desconhecido', assim durante a infer√™ncia podemos usar esses tokens 'desconhecidos' para reduzir a quantidade de metadados que precisamos fornecer ao modelo.

### Gera√ß√£o longa cont√≠nua

O comprimento de contexto do modelo √© de 8.192 segundos. Isso obviamente n√£o √© suficiente para gerar um mapa completo, ent√£o precisamos dividir a m√∫sica em v√°rias janelas e gerar o mapa em pequenas partes.
Para garantir que o mapa gerado n√£o tenha costuras percept√≠veis entre as janelas, usamos uma sobreposi√ß√£o de 90% e geramos as janelas sequencialmente.
Cada janela de gera√ß√£o, exceto a primeira, come√ßa com o decoder pr√©-preenchido at√© 50% da janela de gera√ß√£o com tokens das janelas anteriores.
Usamos um processador de logit para garantir que o modelo n√£o possa gerar tokens de tempo que estejam nos primeiros 50% da janela de gera√ß√£o.
Al√©m disso, os √∫ltimos 40% da janela de gera√ß√£o s√£o reservados para a pr√≥xima janela. Quaisquer tokens de tempo gerados nesse intervalo s√£o tratados como tokens EOS.
Isso garante que cada token gerado seja condicionado a pelo menos 4 segundos de tokens anteriores e 3,3 segundos de √°udio futuro a antecipar.

Para evitar o desvio de offset durante gera√ß√µes longas, offsets aleat√≥rios foram adicionados aos eventos de tempo no decodificador durante o treinamento.
Isso o obriga a corrigir erros de temporiza√ß√£o ouvindo os onsets no √°udio, resultando em um offset consistentemente preciso.

### Coordenadas refinadas com difus√£o

As coordenadas de posi√ß√£o geradas pelo decodificador s√£o quantizadas para pontos de grade de 32 pixels, ent√£o depois usamos difus√£o para remover o ru√≠do das coordenadas at√© as posi√ß√µes finais.
Para isso, treinamos uma vers√£o modificada do [osu-diffusion](https://github.com/OliBomby/osu-diffusion) especializada apenas nos √∫ltimos 10% do cronograma de ru√≠do, e aceita tokens de metadados mais avan√ßados que o Mapperatorinator usa para gera√ß√£o condicional.

Como o modelo Mapperatorinator gera o SV dos sliders, o comprimento necess√°rio do slider √© fixo independentemente do formato do caminho dos pontos de controle.
Portanto, tentamos guiar o processo de difus√£o para criar coordenadas que se ajustem aos comprimentos necess√°rios dos sliders.
Fazemos isso recalculando as posi√ß√µes finais do slider ap√≥s cada etapa do processo de difus√£o com base no comprimento requerido e no caminho atual dos pontos de controle.
Isso significa que o processo de difus√£o n√£o tem controle direto sobre as posi√ß√µes finais dos sliders, mas ainda pode influenci√°-las alterando o caminho dos pontos de controle.

### P√≥s-processamento

O Mapperatorinator faz um p√≥s-processamento extra para melhorar a qualidade do beatmap gerado:

- Refinar coordenadas de posi√ß√£o com difus√£o.
- Resnap de eventos de tempo para o tick mais pr√≥ximo usando os divisores de snap gerados pelo modelo.
- Ajustar sobreposi√ß√µes posicionais quase perfeitas.
- Converter eventos de coluna mania em coordenadas X.
- Gerar caminhos de slider para drumrolls de taiko.
- Corrigir grandes discrep√¢ncias entre comprimento necess√°rio do slider e comprimento do caminho dos pontos de controle.

### Super timing generator

Super timing generator √© um algoritmo que melhora a precis√£o e acur√°cia do tempo gerado inferindo o tempo de toda a m√∫sica 20 vezes e fazendo a m√©dia dos resultados.
Isso √© √∫til para m√∫sicas com BPM vari√°vel ou com mudan√ßas de BPM. O resultado √© quase perfeito, restando apenas por vezes uma se√ß√£o que precisa de ajuste manual.

## Treinamento

A instru√ß√£o abaixo cria um ambiente de treinamento em sua m√°quina local.

### 1. Clone o reposit√≥rio

```sh
git clone https://github.com/OliBomby/Mapperatorinator.git
cd Mapperatorinator
```

### 2. Criar conjunto de dados

Crie seu pr√≥prio conjunto de dados usando o [aplicativo de console Mapperator](https://github.com/mappingtools/Mapperator/blob/master/README.md#create-a-high-quality-dataset). Ele exige um [token de cliente OAuth do osu!](https://osu.ppy.sh/home/account/edit) para verificar beatmaps e obter metadados adicionais. Coloque o conjunto de dados em um diret√≥rio `datasets` ao lado do diret√≥rio `Mapperatorinator`.

```sh
Mapperator.ConsoleApp.exe dataset2 -t "/Mapperatorinator/datasets/beatmap_descriptors.csv" -i "path/to/osz/files" -o "/datasets/cool_dataset"
```

### 3. (Opcional) Configure o Weight & Biases para registro
Crie uma conta no [Weight & Biases](https://wandb.ai/site) e obtenha sua chave de API nas configura√ß√µes da sua conta.
Em seguida, defina a vari√°vel de ambiente `WANDB_API_KEY`, para que o processo de treinamento saiba registrar usando essa chave.

```sh
export WANDB_API_KEY=<your_api_key>
```

### 4. Criar cont√™iner Docker
Tamb√©m √© poss√≠vel treinar no seu venv, mas recomendamos o uso do Docker no WSL para melhor desempenho.
```sh
docker compose up -d --force-recreate
docker attach mapperatorinator_space
cd Mapperatorinator
```

### 5. Configure par√¢metros e inicie o treinamento

Todas as configura√ß√µes est√£o localizadas em `./configs/train/default.yaml`.
Certifique-se de definir corretamente os par√¢metros `train_dataset_path` e `test_dataset_path` para o seu conjunto de dados, assim como os √≠ndices inicial e final do mapset para divis√£o de treino/teste.
O caminho √© local para o container docker, ent√£o se voc√™ colocou seu conjunto de dados chamado `cool_dataset` no diret√≥rio `datasets`, ele deve ser `/workspace/datasets/cool_dataset`.

Recomendo criar um arquivo de configura√ß√£o personalizado que substitua a configura√ß√£o padr√£o, para que voc√™ tenha um registro da sua configura√ß√£o de treinamento para reprodutibilidade.

```yaml
data:
  train_dataset_path: "/workspace/datasets/cool_dataset"
  test_dataset_path: "/workspace/datasets/cool_dataset"
  train_dataset_start: 0
  train_dataset_end: 90
  test_dataset_start: 90
  test_dataset_end: 100
```

Begin training by calling `python osuT5/train.py` or `torchrun --nproc_per_node=NUM_GPUS osuT5/train.py` for multi-GPU training.


```sh
python osuT5/train.py -cn train_v29 train_dataset_path="/workspace/datasets/cool_dataset" test_dataset_path="/workspace/datasets/cool_dataset" train_dataset_end=90 test_dataset_start=90 test_dataset_end=100
```

### 6. Ajuste fino com LoRA

Voc√™ tamb√©m pode ajustar um modelo pr√©-treinado com [LoRA](https://arxiv.org/abs/2106.09685) para adapt√°-lo a um estilo ou modo de jogo espec√≠fico.
Para isso, adapte `configs/train/lora.yaml` conforme suas necessidades e execute a configura√ß√£o de treinamento `lora`:

```sh
python osuT5/train.py -cn lora train_dataset_path="/workspace/datasets/cool_dataset" test_dataset_path="/workspace/datasets/cool_dataset" train_dataset_end=90 test_dataset_start=90 test_dataset_end=100
```
Par√¢metros importantes do LoRA a considerar:
- `pretrained_path`: Caminho ou reposit√≥rio HF do modelo base para ajuste fino.
- `r`: Rank das matrizes LoRA. Valores maiores aumentam a capacidade do modelo, mas tamb√©m o uso de mem√≥ria.
- `lora_alpha`: Fator de escala para as atualiza√ß√µes do LoRA.
- `total_steps`: N√∫mero total de passos de treinamento. Equilibre isso de acordo com o tamanho do seu conjunto de dados.
- `enable_lora`: Se deve usar LoRA ou ajuste fino do modelo completo.

Durante a infer√™ncia, voc√™ pode especificar os pesos do LoRA a serem usados com o argumento `lora_path`.
Isto pode ser um caminho local ou um reposit√≥rio do Hugging Face.

## Veja tamb√©m
- [Mapper Classifier](https://raw.githubusercontent.com/OliBomby/Mapperatorinator/main/./classifier/README.md)
- [RComplexion](https://raw.githubusercontent.com/OliBomby/Mapperatorinator/main/./rcomplexion/README.md)

## Cr√©ditos

Agradecimentos especiais a:
1. Os autores do [osuT5](https://github.com/gyataro/osuT5) pelo c√≥digo de treinamento.
2. Equipe do Hugging Face por suas [ferramentas](https://huggingface.co/docs/transformers/index).
3. [Jason Won](https://github.com/jaswon) e [Richard Nagyfi](https://github.com/sedthh) pelas trocas de ideias.
4. [Marvin](https://github.com/minetoblend) por doar cr√©ditos de treinamento.
5. A comunidade osu! pelos beatmaps.

## Trabalhos relacionados

1. [osu! Beatmap Generator](https://github.com/Syps/osu_beatmap_generator) por Syps (Nick Sypteras)
2. [osumapper](https://github.com/kotritrona/osumapper) por kotritrona, jyvden, Yoyolick (Ryan Zmuda)
3. [osu-diffusion](https://github.com/OliBomby/osu-diffusion) por OliBomby (Olivier Schipper), NiceAesth (Andrei Baciu)
4. [osuT5](https://github.com/gyataro/osuT5) por gyataro (Xiwen Teoh)
5. [Beat Learning](https://github.com/sedthh/BeatLearning) por sedthh (Richard Nagyfi)
6. [osu!dreamer](https://github.com/jaswon/osu-dreamer) por jaswon (Jason Won)



---

Tranlated By [Open Ai Tx](https://github.com/OpenAiTx/OpenAiTx) | Last indexed: 2026-01-24

---