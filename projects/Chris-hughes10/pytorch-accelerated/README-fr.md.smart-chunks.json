[
  {
    "Id": 1,
    "Content": "\n<div align=\"right\">\n  <details>\n    <summary >üåê Language</summary>\n    <div>\n      <div align=\"center\">\n        <a href=\"https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=en\">English</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=zh-CN\">ÁÆÄ‰Ωì‰∏≠Êñá</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=zh-TW\">ÁπÅÈ´î‰∏≠Êñá</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=ja\">Êó•Êú¨Ë™û</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=ko\">ÌïúÍµ≠Ïñ¥</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=hi\">‡§π‡§ø‡§®‡•ç‡§¶‡•Ä</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=th\">‡πÑ‡∏ó‡∏¢</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=fr\">Fran√ßais</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=de\">Deutsch</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=es\">Espa√±ol</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=it\">Italiano</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=ru\">–†—É—Å—Å–∫–∏–π</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=pt\">Portugu√™s</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=nl\">Nederlands</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=pl\">Polski</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=ar\">ÿßŸÑÿπÿ±ÿ®Ÿäÿ©</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=fa\">ŸÅÿßÿ±ÿ≥€å</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=tr\">T√ºrk√ße</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=vi\">Ti·∫øng Vi·ªát</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=id\">Bahasa Indonesia</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=as\">‡¶Ö‡¶∏‡¶Æ‡ßÄ‡¶Ø‡¶º‡¶æ</\n      </div>\n    </div>\n  </details>\n</div>\n\n# pytorch-accelerated\n\n`pytorch-accelerated` is a lightweight library designed to accelerate the process of training PyTorch models\n by providing a minimal, but extensible training loop - encapsulated in a single `Trainer` \nobject - which is flexible enough to handle the majority of use cases, and capable of utilizing different hardware\n options with no code changes required.\n \n`pytorch-accelerated` offers a streamlined feature set, and places a huge emphasis on **simplicity** and **transparency**,",
    "ContentSha": "AirAcpF+fk5I7JzgDq83XmvnyDVC8QNwjGYLlLCLRGE=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "\n<div align=\"right\">\n  <details>\n    <summary >üåê Langue</summary>\n    <div>\n      <div align=\"center\">\n        <a href=\"https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=en\">Anglais</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=zh-CN\">ÁÆÄ‰Ωì‰∏≠Êñá</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=zh-TW\">ÁπÅÈ´î‰∏≠Êñá</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=ja\">Êó•Êú¨Ë™û</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=ko\">ÌïúÍµ≠Ïñ¥</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=hi\">‡§π‡§ø‡§®‡•ç‡§¶‡•Ä</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=th\">‡πÑ‡∏ó‡∏¢</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=fr\">Fran√ßais</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=de\">Deutsch</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=es\">Espa√±ol</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=it\">Italiano</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=ru\">–†—É—Å—Å–∫–∏–π</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=pt\">Portugu√™s</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=nl\">Nederlands</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=pl\">Polski</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=ar\">ÿßŸÑÿπÿ±ÿ®Ÿäÿ©</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=fa\">ŸÅÿßÿ±ÿ≥€å</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=tr\">T√ºrk√ße</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=vi\">Ti·∫øng Vi·ªát</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=id\">Bahasa Indonesia</a>\n        | <a href=\"https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=as\">‡¶Ö‡¶∏‡¶Æ‡ßÄ‡¶Ø‡¶º‡¶æ</\n      </div>\n    </div>\n  </details>\n</div>\n\n# pytorch-accelerated\n\n`pytorch-accelerated` est une biblioth√®que l√©g√®re con√ßue pour acc√©l√©rer le processus d'entra√Ænement des mod√®les PyTorch\n en fournissant une boucle d'entra√Ænement minimale mais extensible - encapsul√©e dans un objet unique `Trainer`\nqui est suffisamment flexible pour g√©rer la majorit√© des cas d'utilisation, et capable d'utiliser diff√©rents mat√©riels\n sans n√©cessiter de modification du code.\n \n`pytorch-accelerated` offre un ensemble de fonctionnalit√©s simplifi√©es, et accorde une grande importance √† la **simplicit√©** et √† la **transparence**,",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 2,
        "rowsha": "cWgam+tnnXudu7i74+ahMEGk/A9dQS+EwWLAIfi3dHk=",
        "originContent": "<div align=\"right\">",
        "translatedContent": "<div align=\"right\">"
      },
      {
        "row": 3,
        "rowsha": "orOcu5ARna/hb3RUkj6dBI8pHTM3WHeTvby17l5E0h0=",
        "originContent": "  <details>",
        "translatedContent": "  <details>"
      },
      {
        "row": 4,
        "rowsha": "TtgkLzblnvP0q9aAIVXt6s2LczXjy5k+QvHKcU0/5Ms=",
        "originContent": "    <summary >üåê Language</summary>",
        "translatedContent": "    <summary >üåê Langue</summary>"
      },
      {
        "row": 5,
        "rowsha": "fZtk4rPTAJEEslnbhSVkHEcPlsctYSzAV7CDPL3rJmA=",
        "originContent": "    <div>",
        "translatedContent": "    <div>"
      },
      {
        "row": 6,
        "rowsha": "9KQxOeJSigvTmGWO+mtnl8kZY9zQfueoy8sk4lYm09Q=",
        "originContent": "      <div align=\"center\">",
        "translatedContent": "      <div align=\"center\">"
      },
      {
        "row": 7,
        "rowsha": "NRuis6rIU5ZGi9tt0F5lWE7qvTZlZjDDo3IDuxE3s7o=",
        "originContent": "        <a href=\"https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=en\">English</a>",
        "translatedContent": "        <a href=\"https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=en\">Anglais</a>"
      },
      {
        "row": 8,
        "rowsha": "zNs0ouI1fK+qVMCNEUW8JZconGm1E50EhS+uZNK+W4U=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=zh-CN\">ÁÆÄ‰Ωì‰∏≠Êñá</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=zh-CN\">ÁÆÄ‰Ωì‰∏≠Êñá</a>"
      },
      {
        "row": 9,
        "rowsha": "bwnOfeeNYFV1Cj4ZP5sTrs31wZuLg4Q0cAQ4mHTvy/k=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=zh-TW\">ÁπÅÈ´î‰∏≠Êñá</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=zh-TW\">ÁπÅÈ´î‰∏≠Êñá</a>"
      },
      {
        "row": 10,
        "rowsha": "yGyeP4HRqHZFUj9A5PsKq16+/OUdhj9rYn3FrdsrrBk=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=ja\">Êó•Êú¨Ë™û</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=ja\">Êó•Êú¨Ë™û</a>"
      },
      {
        "row": 11,
        "rowsha": "CXn73JJpJ40fRqMIlr+6zk8O6Myl9zFGAO5zdQgNkcU=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=ko\">ÌïúÍµ≠Ïñ¥</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=ko\">ÌïúÍµ≠Ïñ¥</a>"
      },
      {
        "row": 12,
        "rowsha": "blsmdQyG8iEByWzVI3asGoIJ8o+8X1CT3VJqqxNGFxo=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=hi\">‡§π‡§ø‡§®‡•ç‡§¶‡•Ä</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=hi\">‡§π‡§ø‡§®‡•ç‡§¶‡•Ä</a>"
      },
      {
        "row": 13,
        "rowsha": "1uaoHUhv5EL7YttClpcTrfybn2ia+GakfxxOKyLw4YY=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=th\">‡πÑ‡∏ó‡∏¢</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=th\">‡πÑ‡∏ó‡∏¢</a>"
      },
      {
        "row": 14,
        "rowsha": "sO1q7R0nAYnVFwEtx+RyhEH/6uUsfEroV63cyrTWfII=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=fr\">Fran√ßais</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=fr\">Fran√ßais</a>"
      },
      {
        "row": 15,
        "rowsha": "Zvqju1mK20fbFCOKo62FvkYF8CiTPY8tb4OecWKBY7I=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=de\">Deutsch</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=de\">Deutsch</a>"
      },
      {
        "row": 16,
        "rowsha": "S12ixQbzjXwKRB7bhej0J6wHla1/ADPa64H2uKjf0SU=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=es\">Espa√±ol</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=es\">Espa√±ol</a>"
      },
      {
        "row": 17,
        "rowsha": "6ceaZU2NVSHInu4tT+XUDXFr2qhChcUZnDraPAZ1CeI=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=it\">Italiano</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=it\">Italiano</a>"
      },
      {
        "row": 18,
        "rowsha": "UMqPQPPj7KT+hDXyr4Dp3OaptqSHGo3LopDnzCgGHEg=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=ru\">–†—É—Å—Å–∫–∏–π</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=ru\">–†—É—Å—Å–∫–∏–π</a>"
      },
      {
        "row": 19,
        "rowsha": "NHAMpBSnwfYetOsU+F214d55k1RnPJclYwhjzSPglN4=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=pt\">Portugu√™s</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=pt\">Portugu√™s</a>"
      },
      {
        "row": 20,
        "rowsha": "+hf/F/dbOfB3bmqW/bgHM1vzUgAzCG4wUdrtkdHPkWw=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=nl\">Nederlands</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=nl\">Nederlands</a>"
      },
      {
        "row": 21,
        "rowsha": "/XKqzq6Y6vdWeaou2MEBL1EESRGVTR0eUtkvKexDyrg=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=pl\">Polski</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=pl\">Polski</a>"
      },
      {
        "row": 22,
        "rowsha": "v5CIA5G7oP1gA3DuidfxPvjhtLCdY15qk1LfSPmLzl4=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=ar\">ÿßŸÑÿπÿ±ÿ®Ÿäÿ©</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=ar\">ÿßŸÑÿπÿ±ÿ®Ÿäÿ©</a>"
      },
      {
        "row": 23,
        "rowsha": "rcerB9lHpsne9c+9owQ/1reKSn0KEet+q78NaAQo0Mo=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=fa\">ŸÅÿßÿ±ÿ≥€å</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=fa\">ŸÅÿßÿ±ÿ≥€å</a>"
      },
      {
        "row": 24,
        "rowsha": "ChkZy2CsylHW7D8d40vTCqVQrRMQlDD32mMMBivaKlM=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=tr\">T√ºrk√ße</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=tr\">T√ºrk√ße</a>"
      },
      {
        "row": 25,
        "rowsha": "Np7qylwtFFtlELV/pmr4QBFnoKE7+gqpd0DK0MkYSLc=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=vi\">Ti·∫øng Vi·ªát</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=vi\">Ti·∫øng Vi·ªát</a>"
      },
      {
        "row": 26,
        "rowsha": "NdKzpkKJdIVZILre2SkKU9b9Q4VHbJVXEq8gxRc7g1g=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=id\">Bahasa Indonesia</a>",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=id\">Bahasa Indonesia</a>"
      },
      {
        "row": 27,
        "rowsha": "inc4RmnG3gYZARyWzWOZ/8vlQ4S6HInM5dr7aGl8Knc=",
        "originContent": "        | <a href=\"https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=as\">‡¶Ö‡¶∏‡¶Æ‡ßÄ‡¶Ø‡¶º‡¶æ</",
        "translatedContent": "        | <a href=\"https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=as\">‡¶Ö‡¶∏‡¶Æ‡ßÄ‡¶Ø‡¶º‡¶æ</"
      },
      {
        "row": 28,
        "rowsha": "0OM5wNEm0TO56MEBvQzL7AUZM7/3OpgIeqRf2zFre3Q=",
        "originContent": "      </div>",
        "translatedContent": "      </div>"
      },
      {
        "row": 29,
        "rowsha": "fcjTfY+fs8YnY5slBs1sZvWPAqEQR7tzaBDO54skkGQ=",
        "originContent": "    </div>",
        "translatedContent": "    </div>"
      },
      {
        "row": 30,
        "rowsha": "+fQNH2ldI7UM/rqRscP3hUSWAmw1HvQ2wEKDN8JagT0=",
        "originContent": "  </details>",
        "translatedContent": "  </details>"
      },
      {
        "row": 31,
        "rowsha": "qsMmUbEPVnxGG5tPJV1vsfpoWbU2jYvZpRr5IKshzyM=",
        "originContent": "</div>",
        "translatedContent": "</div>"
      },
      {
        "row": 32,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 33,
        "rowsha": "Ovo2hAoRL04j7OWgQniaVNvDKJsuOI0WYj/jcn//3TY=",
        "originContent": "# pytorch-accelerated",
        "translatedContent": "# pytorch-accelerated"
      },
      {
        "row": 34,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 35,
        "rowsha": "V1+fC0KmDrHhr28o2TvxNMFheNhgFmzJ5L1oPXfAV4I=",
        "originContent": "`pytorch-accelerated` is a lightweight library designed to accelerate the process of training PyTorch models",
        "translatedContent": "`pytorch-accelerated` est une biblioth√®que l√©g√®re con√ßue pour acc√©l√©rer le processus d'entra√Ænement des mod√®les PyTorch"
      },
      {
        "row": 36,
        "rowsha": "eT4onK20NEf4wVfWei3oCVbTPWbTamGt+TMt4kSmW38=",
        "originContent": " by providing a minimal, but extensible training loop - encapsulated in a single `Trainer` ",
        "translatedContent": " en fournissant une boucle d'entra√Ænement minimale mais extensible - encapsul√©e dans un objet unique `Trainer`"
      },
      {
        "row": 37,
        "rowsha": "MfIE3rH27rKv8Xu+nGR2+60NMM3iPDEp+aDqstGOyNg=",
        "originContent": "object - which is flexible enough to handle the majority of use cases, and capable of utilizing different hardware",
        "translatedContent": "qui est suffisamment flexible pour g√©rer la majorit√© des cas d'utilisation, et capable d'utiliser diff√©rents mat√©riels"
      },
      {
        "row": 38,
        "rowsha": "3Nk33pJiSpyEKwlcABLxbnmpZ8H+jIUVasYZRACbQ8I=",
        "originContent": " options with no code changes required.",
        "translatedContent": " sans n√©cessiter de modification du code."
      },
      {
        "row": 39,
        "rowsha": "Nqnn8clbgv+5l0PgxcTOldg8mkMKrFn4TvPL+rYUUGg=",
        "originContent": " ",
        "translatedContent": " "
      },
      {
        "row": 40,
        "rowsha": "MhFfYMQIm+m+qz49IEBvjf0M3uBe/lPgf4qBzThbR6o=",
        "originContent": "`pytorch-accelerated` offers a streamlined feature set, and places a huge emphasis on **simplicity** and **transparency**,",
        "translatedContent": "`pytorch-accelerated` offre un ensemble de fonctionnalit√©s simplifi√©es, et accorde une grande importance √† la **simplicit√©** et √† la **transparence**,"
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 2,
    "Content": "to enable users to understand exactly what is going on under the hood, but without having to write and maintain the boilerplate themselves!\n   \nThe key features are:\n- A simple and contained, but easily customisable, training loop, which should work out of the box in straightforward cases;\n behaviour can be customised using inheritance and/or callbacks.\n- Handles device placement, mixed-precision, DeepSpeed integration, multi-GPU and distributed training with no code changes.\n- Uses pure PyTorch components, with no additional modifications or wrappers, and easily interoperates\n with other popular libraries such as [timm](https://github.com/rwightman/pytorch-image-models), \n [transformers](https://huggingface.co/transformers/) and [torchmetrics](https://torchmetrics.readthedocs.io/en/latest/).\n- A small, streamlined API ensures that there is a minimal learning curve for existing PyTorch users.\n\nSignificant effort has been taken to ensure that every part of the library - both internal and external components - is as clear and simple as possible, \nmaking it easy to customise, debug and understand exactly what is going on behind the scenes at each step; most of the \nbehaviour of the trainer is contained in a single class! \nIn the spirit of Python, nothing is hidden and everything is accessible.\n\n`pytorch-accelerated` is proudly and transparently built on top of \n[Hugging Face Accelerate](https://github.com/huggingface/accelerate), which is responsible for the \nmovement of data between devices and launching of training configurations. When customizing the trainer, or launching\ntraining, users are encouraged to consult the [Accelerate documentation](https://huggingface.co/docs/accelerate/) \nto understand all available options; Accelerate provides convenient functions for operations such gathering tensors \nand gradient clipping, usage of which can be seen in the `pytorch-accelerated` \n[examples](https://github.com/Chris-hughes10/pytorch-accelerated/tree/main/examples) folder! \n\nTo learn more about the motivations behind this library, along with a detailed getting started guide, check out [this blog post](https://medium.com/@chris.p.hughes10/introducing-pytorch-accelerated-6ba99530608c?source=friends_link&sk=868c2d2ec5229fdea42877c0bf82b968).\n\n## Installation\n\n`pytorch-accelerated` can be installed from pip using the following command:",
    "ContentSha": "Re8w0YNFegHoCPqH2C3icJNTywrgvkM/JJ4v0WjIddI=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "pour permettre aux utilisateurs de comprendre exactement ce qui se passe sous le capot, mais sans avoir √† √©crire et maintenir eux-m√™mes le code standard !\n   \nLes principales fonctionnalit√©s sont :\n- Une boucle d'entra√Ænement simple et contenue, mais facilement personnalisable, qui devrait fonctionner d√®s la sortie de la bo√Æte dans les cas simples ;\n le comportement peut √™tre personnalis√© via l'h√©ritage et/ou des callbacks.\n- G√®re le placement des appareils, la pr√©cision mixte, l'int√©gration DeepSpeed, l'entra√Ænement multi-GPU et distribu√© sans modification du code.\n- Utilise des composants PyTorch purs, sans modifications ou wrappers suppl√©mentaires, et s'interop√®re facilement\n avec d'autres biblioth√®ques populaires telles que [timm](https://github.com/rwightman/pytorch-image-models), \n [transformers](https://huggingface.co/transformers/) et [torchmetrics](https://torchmetrics.readthedocs.io/en/latest/).\n- Une API petite et √©pur√©e garantit une courbe d'apprentissage minimale pour les utilisateurs PyTorch existants.\n\nUn effort important a √©t√© fait pour garantir que chaque partie de la biblioth√®que - composants internes et externes - soit aussi claire et simple que possible,\nrendant facile la personnalisation, le d√©bogage et la compr√©hension exacte de ce qui se passe en coulisses √† chaque √©tape ; la plupart du\ncomportement de l'entra√Æneur est contenu dans une seule classe !\nDans l'esprit de Python, rien n'est cach√© et tout est accessible.\n\n`pytorch-accelerated` est fi√®rement et transparent construit sur \n[Hugging Face Accelerate](https://github.com/huggingface/accelerate), qui est responsable du\ntransfert des donn√©es entre appareils et du lancement des configurations d'entra√Ænement. Lors de la personnalisation de l'entra√Æneur, ou du lancement\nde l'entra√Ænement, il est conseill√© aux utilisateurs de consulter la [documentation Accelerate](https://huggingface.co/docs/accelerate/)\npour comprendre toutes les options disponibles ; Accelerate fournit des fonctions pratiques pour des op√©rations telles que la collecte de tenseurs\net la coupure de gradient, dont l'utilisation peut √™tre vue dans le dossier \n[exemples](https://github.com/Chris-hughes10/pytorch-accelerated/tree/main/examples) de `pytorch-accelerated` !\n\nPour en savoir plus sur les motivations derri√®re cette biblioth√®que, ainsi qu'un guide d√©taill√© pour bien d√©marrer, consultez [cet article de blog](https://medium.com/@chris.p.hughes10/introducing-pytorch-accelerated-6ba99530608c?source=friends_link&sk=868c2d2ec5229fdea42877c0bf82b968).\n\n## Installation\n\n`pytorch-accelerated` peut √™tre install√© via pip en utilisant la commande suivante :",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "ssbGgmAymNRugCm8+IzwVJuAxPQfG5XBYYvLbi2qPy4=",
        "originContent": "to enable users to understand exactly what is going on under the hood, but without having to write and maintain the boilerplate themselves!",
        "translatedContent": "pour permettre aux utilisateurs de comprendre exactement ce qui se passe sous le capot, mais sans avoir √† √©crire et maintenir eux-m√™mes le code standard !"
      },
      {
        "row": 2,
        "rowsha": "Cq19p30u1Zw5bJmnTknzpFJNzby1FjJRsUM9ZAJHrrQ=",
        "originContent": "   ",
        "translatedContent": "   "
      },
      {
        "row": 3,
        "rowsha": "1y6u9cnEFXjEhfkhf1X3ko1hgLUQJF757V+ghWVCnog=",
        "originContent": "The key features are:",
        "translatedContent": "Les principales fonctionnalit√©s sont :"
      },
      {
        "row": 4,
        "rowsha": "IPLfpwj4ziOBALCB6gmlvasLPprBg6FSDZYvqU38l5I=",
        "originContent": "- A simple and contained, but easily customisable, training loop, which should work out of the box in straightforward cases;",
        "translatedContent": "- Une boucle d'entra√Ænement simple et contenue, mais facilement personnalisable, qui devrait fonctionner d√®s la sortie de la bo√Æte dans les cas simples ;"
      },
      {
        "row": 5,
        "rowsha": "f2KREYooaFiTMUE05+AkmiwAL5/l2dp0432IMwxUDJI=",
        "originContent": " behaviour can be customised using inheritance and/or callbacks.",
        "translatedContent": " le comportement peut √™tre personnalis√© via l'h√©ritage et/ou des callbacks."
      },
      {
        "row": 6,
        "rowsha": "2Z/JXmfKSpjCDzHZj24T+tI43Z0cphdj6HhL7mg0hMw=",
        "originContent": "- Handles device placement, mixed-precision, DeepSpeed integration, multi-GPU and distributed training with no code changes.",
        "translatedContent": "- G√®re le placement des appareils, la pr√©cision mixte, l'int√©gration DeepSpeed, l'entra√Ænement multi-GPU et distribu√© sans modification du code."
      },
      {
        "row": 7,
        "rowsha": "DVrYrWOy6ErnqrdPWRadTk3BxAFgn1/mJb7L+bJBzuo=",
        "originContent": "- Uses pure PyTorch components, with no additional modifications or wrappers, and easily interoperates",
        "translatedContent": "- Utilise des composants PyTorch purs, sans modifications ou wrappers suppl√©mentaires, et s'interop√®re facilement"
      },
      {
        "row": 8,
        "rowsha": "owB5chi1658CL4G41Ngm7UZjpwjddDULbF1xOMUSB+k=",
        "originContent": " with other popular libraries such as [timm](https://github.com/rwightman/pytorch-image-models), ",
        "translatedContent": " avec d'autres biblioth√®ques populaires telles que [timm](https://github.com/rwightman/pytorch-image-models), "
      },
      {
        "row": 9,
        "rowsha": "5KvCb1FfhuvudzyMJBV7DnEnRyyfbaE/ab4o84YSmY8=",
        "originContent": " [transformers](https://huggingface.co/transformers/) and [torchmetrics](https://torchmetrics.readthedocs.io/en/latest/).",
        "translatedContent": " [transformers](https://huggingface.co/transformers/) et [torchmetrics](https://torchmetrics.readthedocs.io/en/latest/)."
      },
      {
        "row": 10,
        "rowsha": "Hx8VUAJX5ZJfKR5dwC5uJwx+VSCFrsmz1nIAD8RGig0=",
        "originContent": "- A small, streamlined API ensures that there is a minimal learning curve for existing PyTorch users.",
        "translatedContent": "- Une API petite et √©pur√©e garantit une courbe d'apprentissage minimale pour les utilisateurs PyTorch existants."
      },
      {
        "row": 11,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 12,
        "rowsha": "0l19uHsKgEjT+pCdrxMKHYSx44lrp9AUfWYedNtkYJ4=",
        "originContent": "Significant effort has been taken to ensure that every part of the library - both internal and external components - is as clear and simple as possible, ",
        "translatedContent": "Un effort important a √©t√© fait pour garantir que chaque partie de la biblioth√®que - composants internes et externes - soit aussi claire et simple que possible,"
      },
      {
        "row": 13,
        "rowsha": "tQ6xs3eWRJcAugV9IMVI9ZFiTHzm8ldxy/FlFZi599Q=",
        "originContent": "making it easy to customise, debug and understand exactly what is going on behind the scenes at each step; most of the ",
        "translatedContent": "rendant facile la personnalisation, le d√©bogage et la compr√©hension exacte de ce qui se passe en coulisses √† chaque √©tape ; la plupart du"
      },
      {
        "row": 14,
        "rowsha": "U8Lk3fDthAY3IGsatV12CyVScv+fFq1/4/V8MOP4fnU=",
        "originContent": "behaviour of the trainer is contained in a single class! ",
        "translatedContent": "comportement de l'entra√Æneur est contenu dans une seule classe !"
      },
      {
        "row": 15,
        "rowsha": "/whT4AQ96kipZjAixx9mjEXUBxoDqhpzoiVqIj0Xc9A=",
        "originContent": "In the spirit of Python, nothing is hidden and everything is accessible.",
        "translatedContent": "Dans l'esprit de Python, rien n'est cach√© et tout est accessible."
      },
      {
        "row": 16,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 17,
        "rowsha": "+Ma+mBydO/gjIEj0ghgpfwb3C7rwk53ieeVaKdYVm0Y=",
        "originContent": "`pytorch-accelerated` is proudly and transparently built on top of ",
        "translatedContent": "`pytorch-accelerated` est fi√®rement et transparent construit sur "
      },
      {
        "row": 18,
        "rowsha": "8RTBfFcoxZcsTCebatDy+K8dea2HJ4Dnr3tUlZJm7sc=",
        "originContent": "[Hugging Face Accelerate](https://github.com/huggingface/accelerate), which is responsible for the ",
        "translatedContent": "[Hugging Face Accelerate](https://github.com/huggingface/accelerate), qui est responsable du"
      },
      {
        "row": 19,
        "rowsha": "KWrzvit2RSs9e5cHQ9Qx7INZE7vbHBmXDoawmsK7iaI=",
        "originContent": "movement of data between devices and launching of training configurations. When customizing the trainer, or launching",
        "translatedContent": "transfert des donn√©es entre appareils et du lancement des configurations d'entra√Ænement. Lors de la personnalisation de l'entra√Æneur, ou du lancement"
      },
      {
        "row": 20,
        "rowsha": "QWTWCntKbU2aiDIRaMLSqJTWlVhjDLRrc78xXyC9vTk=",
        "originContent": "training, users are encouraged to consult the [Accelerate documentation](https://huggingface.co/docs/accelerate/) ",
        "translatedContent": "de l'entra√Ænement, il est conseill√© aux utilisateurs de consulter la [documentation Accelerate](https://huggingface.co/docs/accelerate/)"
      },
      {
        "row": 21,
        "rowsha": "0Ke2gK6hpdOZQgkCoikqWYJuC0qf6bicptb8LM4REWI=",
        "originContent": "to understand all available options; Accelerate provides convenient functions for operations such gathering tensors ",
        "translatedContent": "pour comprendre toutes les options disponibles ; Accelerate fournit des fonctions pratiques pour des op√©rations telles que la collecte de tenseurs"
      },
      {
        "row": 22,
        "rowsha": "Z+jDiWJvnT7/mxCgM+w8fqEp8rYgk89xmk3yzecuaHQ=",
        "originContent": "and gradient clipping, usage of which can be seen in the `pytorch-accelerated` ",
        "translatedContent": "et la coupure de gradient, dont l'utilisation peut √™tre vue dans le dossier "
      },
      {
        "row": 23,
        "rowsha": "5EzPSPzfhWTdL39BvPRnvvqvzzeF+wMYOCUzaQE11s8=",
        "originContent": "[examples](https://github.com/Chris-hughes10/pytorch-accelerated/tree/main/examples) folder! ",
        "translatedContent": "[exemples](https://github.com/Chris-hughes10/pytorch-accelerated/tree/main/examples) de `pytorch-accelerated` !"
      },
      {
        "row": 24,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 25,
        "rowsha": "o1hUUqvNT5RQBJ3IouYH941prDc7w09T8cYYT4AqFvs=",
        "originContent": "To learn more about the motivations behind this library, along with a detailed getting started guide, check out [this blog post](https://medium.com/@chris.p.hughes10/introducing-pytorch-accelerated-6ba99530608c?source=friends_link&sk=868c2d2ec5229fdea42877c0bf82b968).",
        "translatedContent": "Pour en savoir plus sur les motivations derri√®re cette biblioth√®que, ainsi qu'un guide d√©taill√© pour bien d√©marrer, consultez [cet article de blog](https://medium.com/@chris.p.hughes10/introducing-pytorch-accelerated-6ba99530608c?source=friends_link&sk=868c2d2ec5229fdea42877c0bf82b968)."
      },
      {
        "row": 26,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 27,
        "rowsha": "oV0SUDvwD2VN8Gi9nlr2JZ2xcDrASmE2W5kc5SVX5eo=",
        "originContent": "## Installation",
        "translatedContent": "## Installation"
      },
      {
        "row": 28,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 29,
        "rowsha": "mrQka787Ih5R3WLU0/Ljk4A51DEgUo8QGfvkUZmCvhY=",
        "originContent": "`pytorch-accelerated` can be installed from pip using the following command:",
        "translatedContent": "`pytorch-accelerated` peut √™tre install√© via pip en utilisant la commande suivante :"
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 3,
    "Content": "```\npip install pytorch-accelerated\n```",
    "ContentSha": "ZnNgJ/nz2P77SvZTYBc33IuNzMJd0jANMQtHeL5bJJI=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```\npip install pytorch-accelerated\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 4,
    "Content": "\nTo make the package as slim as possible, the packages required to run the examples are not included by default. To include these packages, you can use the following command:",
    "ContentSha": "sAgNNj8U2N8S4Z0z+JjmBI/VRyEdyr9gxmq/7O2h15s=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "\nPour rendre le package aussi l√©ger que possible, les packages n√©cessaires pour ex√©cuter les exemples ne sont pas inclus par d√©faut. Pour inclure ces packages, vous pouvez utiliser la commande suivante :",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 5,
    "Content": "```\npip install pytorch-accelerated[examples]\n```",
    "ContentSha": "OKZf7EaXdDdphOru+mZj1vm/34POonzhRRmcH3RFD+k=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```\npip install pytorch-accelerated[examples]\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 6,
    "Content": "\n## Quickstart\n\nTo get started, simply import and use the pytorch-accelerated `Trainer` ,as demonstrated in the following snippet,\nand then launch training using the \n[accelerate CLI](https://huggingface.co/docs/accelerate/quicktour.html#launching-your-distributed-script)\ndescribed below.\n",
    "ContentSha": "EvwZFNiwRJaSw5NDTn+12KIeTQwtrpp16PegIEAzmqA=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "\n## D√©marrage rapide\n\nPour commencer, importez simplement et utilisez le `Trainer` acc√©l√©r√© par pytorch, comme d√©montr√© dans l'extrait suivant,\npuis lancez l'entra√Ænement en utilisant la \n[CLI accelerate](https://huggingface.co/docs/accelerate/quicktour.html#launching-your-distributed-script)\nd√©crite ci-dessous.\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 7,
    "Content": "```python\n# examples/core/train_mnist.py\nimport os\n\nfrom torch import nn, optim\nfrom torch.utils.data import random_split\nfrom torchvision import transforms\nfrom torchvision.datasets import MNIST\n\nfrom pytorch_accelerated import Trainer\n\nclass MNISTModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.main = nn.Sequential(\n            nn.Linear(in_features=784, out_features=128),\n            nn.ReLU(),\n            nn.Linear(in_features=128, out_features=64),\n            nn.ReLU(),\n            nn.Linear(in_features=64, out_features=10),\n        )\n\n    def forward(self, input):\n        return self.main(input.view(input.shape[0], -1))\n\ndef main():\n    dataset = MNIST(os.getcwd(), download=True, transform=transforms.ToTensor())\n    train_dataset, validation_dataset, test_dataset = random_split(dataset, [50000, 5000, 5000])\n    model = MNISTModel()\n    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n    loss_func = nn.CrossEntropyLoss()\n\n    trainer = Trainer(\n            model,\n            loss_func=loss_func,\n            optimizer=optimizer,\n    )\n\n    trainer.train(\n        train_dataset=train_dataset,\n        eval_dataset=validation_dataset,\n        num_epochs=8,\n        per_device_batch_size=32,\n    )\n\n    trainer.evaluate(\n        dataset=test_dataset,\n        per_device_batch_size=64,\n    )\n    \nif __name__ == \"__main__\":\n    main()\n```",
    "ContentSha": "bv7OiKBzLLU70Q4tGxwc/P7bYmTXRA02BosGXYu8oO4=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```python\n# examples/core/train_mnist.py\nimport os\n\nfrom torch import nn, optim\nfrom torch.utils.data import random_split\nfrom torchvision import transforms\nfrom torchvision.datasets import MNIST\n\nfrom pytorch_accelerated import Trainer\n\nclass MNISTModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.main = nn.Sequential(\n            nn.Linear(in_features=784, out_features=128),\n            nn.ReLU(),\n            nn.Linear(in_features=128, out_features=64),\n            nn.ReLU(),\n            nn.Linear(in_features=64, out_features=10),\n        )\n\n    def forward(self, input):\n        return self.main(input.view(input.shape[0], -1))\n\ndef main():\n    dataset = MNIST(os.getcwd(), download=True, transform=transforms.ToTensor())\n    train_dataset, validation_dataset, test_dataset = random_split(dataset, [50000, 5000, 5000])\n    model = MNISTModel()\n    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n    loss_func = nn.CrossEntropyLoss()\n\n    trainer = Trainer(\n            model,\n            loss_func=loss_func,\n            optimizer=optimizer,\n    )\n\n    trainer.train(\n        train_dataset=train_dataset,\n        eval_dataset=validation_dataset,\n        num_epochs=8,\n        per_device_batch_size=32,\n    )\n\n    trainer.evaluate(\n        dataset=test_dataset,\n        per_device_batch_size=64,\n    )\n    \nif __name__ == \"__main__\":\n    main()\n```",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": true
  },
  {
    "Id": 8,
    "Content": "\nTo launch training using the [accelerate CLI](https://huggingface.co/docs/accelerate/quicktour.html#launching-your-distributed-script)\n, on your machine(s), run:\n\n` accelerate config --config_file accelerate_config.yaml`\n\nand answer the questions asked. This will generate a config file that will be used to properly set the default options when doing\n\n`accelerate launch --config_file accelerate_config.yaml train.py [--training-args]`\n\n*Note*: Using the [accelerate CLI](https://huggingface.co/docs/accelerate/quicktour.html#launching-your-distributed-script) is completely optional, training can also be launched in the usual way using:\n\n`python train.py` / `python -m torch.distributed ...`\n\ndepending on your infrastructure configuration, for users who would like to maintain a more fine-grained control \nover the launch command.\n\nMore complex training examples can be seen in the examples folder \n[here](https://github.com/Chris-hughes10/pytorch-accelerated/tree/main/examples). \n\nAlternatively, if you would rather understand the core concepts first, this can be found in the [documentation](https://pytorch-accelerated.readthedocs.io/en/latest/).\n\n## Usage\n\n### Who is pytorch-accelerated aimed at?\n\n- Users that are familiar with PyTorch but would like to avoid having to write the common training loop boilerplate\nto focus on the interesting parts of the training loop.\n- Users who like, and are comfortable with, selecting and creating their own models, loss functions, optimizers and datasets.\n- Users who value a simple and streamlined feature set, where the behaviour is easy to debug, understand, and reason about!\n\n### When shouldn't I use pytorch-accelerated?\n\n- If you are looking for an end-to-end solution, encompassing everything from loading data to inference,\n  which helps you to select a model, optimizer or loss function, you would probably be better suited to\n  [fastai](https://github.com/fastai/fastai). `pytorch-accelerated` focuses only on the training process, with all other\n  concerns being left to the responsibility of the user.\n- If you would like to write the entire training loop yourself, just without all of the device management headaches, \nyou would probably be best suited to using [Accelerate](https://github.com/huggingface/accelerate) directly! Whilst it\nis possible to customize every part of the `Trainer`, the training loop is fundamentally broken up into a number of ",
    "ContentSha": "bnsMOVn0+travAMOp2mypFimkbJLHUhHrIn6M8VVL1Q=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "Pour lancer l'entra√Ænement en utilisant le [CLI accelerate](https://huggingface.co/docs/accelerate/quicktour.html#launching-your-distributed-script)\n, sur votre(s) machine(s), ex√©cutez :\n\n` accelerate config --config_file accelerate_config.yaml`\n\net r√©pondez aux questions pos√©es. Cela g√©n√©rera un fichier de configuration qui sera utilis√© pour d√©finir correctement les options par d√©faut lors de l'ex√©cution de\n\n`accelerate launch --config_file accelerate_config.yaml train.py [--training-args]`\n\n*Note* : L'utilisation du [CLI accelerate](https://huggingface.co/docs/accelerate/quicktour.html#launching-your-distributed-script) est totalement optionnelle, l'entra√Ænement peut √©galement √™tre lanc√© de la mani√®re habituelle via :\n\n`python train.py` / `python -m torch.distributed ...`\n\nselon la configuration de votre infrastructure, pour les utilisateurs qui souhaitent garder un contr√¥le plus pr√©cis\nsur la commande de lancement.\n\nDes exemples d'entra√Ænement plus complexes sont disponibles dans le dossier examples\n[ici](https://github.com/Chris-hughes10/pytorch-accelerated/tree/main/examples).\n\nAlternativement, si vous pr√©f√©rez comprendre d'abord les concepts de base, vous pouvez les trouver dans la [documentation](https://pytorch-accelerated.readthedocs.io/en/latest/).\n\n## Utilisation\n\n### √Ä qui s'adresse pytorch-accelerated ?\n\n- Aux utilisateurs familiers avec PyTorch mais qui souhaitent √©viter d'√©crire la structure standard de la boucle d'entra√Ænement\npour se concentrer sur les parties int√©ressantes de la boucle d'entra√Ænement.\n- Aux utilisateurs qui aiment, et sont √† l'aise avec, la s√©lection et la cr√©ation de leurs propres mod√®les, fonctions de perte, optimiseurs et ensembles de donn√©es.\n- Aux utilisateurs qui appr√©cient un ensemble de fonctionnalit√©s simple et √©pur√©, o√π le comportement est facile √† d√©boguer, comprendre et analyser !\n\n### Quand ne devrais-je pas utiliser pytorch-accelerated ?\n\n- Si vous cherchez une solution compl√®te, couvrant tout depuis le chargement des donn√©es jusqu'√† l'inf√©rence,\n  qui vous aide √† s√©lectionner un mod√®le, un optimiseur ou une fonction de perte, vous seriez probablement mieux servi par\n  [fastai](https://github.com/fastai/fastai). `pytorch-accelerated` se concentre uniquement sur le processus d'entra√Ænement, toutes les autres\n  pr√©occupations restant de la responsabilit√© de l'utilisateur.\n- Si vous souhaitez √©crire vous-m√™me toute la boucle d'entra√Ænement, simplement sans toutes les complications li√©es √† la gestion des appareils,\nvous seriez probablement mieux servi en utilisant directement [Accelerate](https://github.com/huggingface/accelerate) ! Bien qu'il\nsoit possible de personnaliser chaque partie du `Trainer`, la boucle d'entra√Ænement est fondamentalement d√©coup√©e en un certain nombre de\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  },
  {
    "Id": 9,
    "Content": "different methods that you would have to override. But, before you go, is writing those `for` loops really important \nenough to warrant starting from scratch *again* üòâ.\n- If you are working on a custom, highly complex, use case which does not fit the patterns of usual training loops\nand want to squeeze out every last bit of performance on your chosen hardware, you are probably best off sticking\n with vanilla PyTorch; any high-level API becomes an overhead in highly specialized cases!\n\n\n## Acknowledgements\n\nMany aspects behind the design and features of `pytorch-accelerated` were greatly inspired by a number of excellent \nlibraries and frameworks such as [fastai](https://github.com/fastai/fastai), [timm](https://github.com/rwightman/pytorch-image-models), \n[PyTorch-lightning](https://github.com/PyTorchLightning/pytorch-lightning) and [Hugging Face Accelerate](https://github.com/huggingface/accelerate). Each of these tools \nhave made an enormous impact on both this library and the machine learning community, and their influence can not be \nstated enough!\n\n`pytorch-accelerated` has taken only inspiration from these tools, and all of the functionality contained has been implemented\n from scratch in a way that benefits this library. The only exceptions to this are some of the scripts in the \n [examples](https://github.com/Chris-hughes10/pytorch-accelerated/tree/main/examples)\n folder in which existing resources were taken and modified in order to showcase the features of `pytorch-accelerated`;\n these cases are clearly marked, with acknowledgement being given to the original authors.\n \n",
    "ContentSha": "yAPUAy31Lm7EmynexVatuVsTgMAV36ObD1Na2ZJyWPk=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "diff√©rentes m√©thodes que vous devrez surcharger. Mais, avant de partir, est-ce que l'√©criture de ces boucles `for` est vraiment assez importante  \npour justifier de repartir de z√©ro *encore* üòâ.  \n- Si vous travaillez sur un cas d'utilisation personnalis√©, tr√®s complexe, qui ne correspond pas aux sch√©mas habituels des boucles d'entra√Ænement  \net que vous souhaitez exploiter chaque dernier bit de performance sur votre mat√©riel choisi, il est probablement pr√©f√©rable de rester  \navec PyTorch vanilla ; toute API de haut niveau devient une surcharge dans les cas hautement sp√©cialis√©s !  \n\n\n## Remerciements  \n\nDe nombreux aspects derri√®re la conception et les fonctionnalit√©s de `pytorch-accelerated` ont √©t√© grandement inspir√©s par un certain nombre d'excellentes  \nbiblioth√®ques et frameworks tels que [fastai](https://github.com/fastai/fastai), [timm](https://github.com/rwightman/pytorch-image-models),  \n[PyTorch-lightning](https://github.com/PyTorchLightning/pytorch-lightning) et [Hugging Face Accelerate](https://github.com/huggingface/accelerate). Chacun de ces outils  \na eu un impact √©norme √† la fois sur cette biblioth√®que et sur la communaut√© de l'apprentissage automatique, et leur influence ne peut  \n√™tre assez soulign√©e !  \n\n`pytorch-accelerated` s'est inspir√© uniquement de ces outils, et toute la fonctionnalit√© contenue a √©t√© impl√©ment√©e  \n√† partir de z√©ro de mani√®re √† b√©n√©ficier √† cette biblioth√®que. Les seules exceptions sont certains scripts dans le  \n[dossier examples](https://github.com/Chris-hughes10/pytorch-accelerated/tree/main/examples)  \ndans lesquels des ressources existantes ont √©t√© prises et modifi√©es afin de pr√©senter les fonctionnalit√©s de `pytorch-accelerated` ;  \nces cas sont clairement indiqu√©s, avec une reconnaissance donn√©e aux auteurs originaux.  \n\n",
    "Status": "ok",
    "RowTranslations": [],
    "IsCodeBlock": false
  }
]