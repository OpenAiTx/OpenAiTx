
<div align="right">
  <details>
    <summary >ğŸŒ JÄ™zyk</summary>
    <div>
      <div align="center">
        <a href="https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=en">English</a>
        | <a href="https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=zh-CN">ç®€ä½“ä¸­æ–‡</a>
        | <a href="https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=zh-TW">ç¹é«”ä¸­æ–‡</a>
        | <a href="https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=ja">æ—¥æœ¬èª</a>
        | <a href="https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=ko">í•œêµ­ì–´</a>
        | <a href="https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=hi">à¤¹à¤¿à¤¨à¥à¤¦à¥€</a>
        | <a href="https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=th">à¹„à¸—à¸¢</a>
        | <a href="https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=fr">FranÃ§ais</a>
        | <a href="https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=de">Deutsch</a>
        | <a href="https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=es">EspaÃ±ol</a>
        | <a href="https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=it">Italiano</a>
        | <a href="https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=ru">Ğ ÑƒÑÑĞºĞ¸Ğ¹</a>
        | <a href="https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=pt">PortuguÃªs</a>
        | <a href="https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=nl">Nederlands</a>
        | <a href="https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=pl">Polski</a>
        | <a href="https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=ar">Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©</a>
        | <a href="https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=fa">ÙØ§Ø±Ø³ÛŒ</a>
        | <a href="https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=tr">TÃ¼rkÃ§e</a>
        | <a href="https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=vi">Tiáº¿ng Viá»‡t</a>
        | <a href="https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=id">Bahasa Indonesia</a>
        | <a href="https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=as">à¦…à¦¸à¦®à§€à¦¯à¦¼à¦¾</
      </div>
    </div>
  </details>
</div>

# pytorch-accelerated

`pytorch-accelerated` to lekka biblioteka zaprojektowana, aby przyspieszyÄ‡ proces trenowania modeli PyTorch
 poprzez udostÄ™pnienie minimalnej, ale rozszerzalnej pÄ™tli treningowej â€“ zamkniÄ™tej w jednym obiekcie `Trainer` â€“ 
ktÃ³ra jest na tyle elastyczna, by obsÅ‚uÅ¼yÄ‡ wiÄ™kszoÅ›Ä‡ przypadkÃ³w uÅ¼ycia oraz pozwala na wykorzystanie rÃ³Å¼nych opcji sprzÄ™towych
 bez koniecznoÅ›ci zmiany kodu.
 
`pytorch-accelerated` oferuje uproszczony zestaw funkcji i kÅ‚adzie ogromny nacisk na **prostotÄ™** i **przejrzystoÅ›Ä‡**,
aby umoÅ¼liwiÄ‡ uÅ¼ytkownikom dokÅ‚adne zrozumienie, co dzieje siÄ™ "pod maskÄ…", ale bez koniecznoÅ›ci pisania i utrzymywania kodu szablonowego samodzielnie!
   
GÅ‚Ã³wne cechy to:
- Prosta i zamkniÄ™ta, ale Å‚atwo konfigurowalna pÄ™tla treningowa, ktÃ³ra powinna dziaÅ‚aÄ‡ od razu w prostych przypadkach;
 zachowanie moÅ¼na dostosowaÄ‡ przy uÅ¼yciu dziedziczenia i/lub callbackÃ³w.
- ObsÅ‚uguje przypisywanie urzÄ…dzeÅ„, precyzjÄ™ mieszanÄ…, integracjÄ™ z DeepSpeed, trening na wielu GPU i w trybie rozproszonym bez zmian w kodzie.
- Wykorzystuje czyste komponenty PyTorch, bez dodatkowych modyfikacji ani wrapperÃ³w, i Å‚atwo wspÃ³Å‚pracuje
 z innymi popularnymi bibliotekami, takimi jak [timm](https://github.com/rwightman/pytorch-image-models), 
 [transformers](https://huggingface.co/transformers/) oraz [torchmetrics](https://torchmetrics.readthedocs.io/en/latest/).
- MaÅ‚e, uproszczone API zapewnia minimalnÄ… krzywÄ… uczenia dla obecnych uÅ¼ytkownikÃ³w PyTorch.

WÅ‚oÅ¼ono znaczÄ…cy wysiÅ‚ek, by kaÅ¼da czÄ™Å›Ä‡ biblioteki â€“ zarÃ³wno komponenty wewnÄ™trzne, jak i zewnÄ™trzne â€“ byÅ‚a jak najprostsza i najbardziej przejrzysta,
co uÅ‚atwia dostosowanie, debugowanie i zrozumienie dokÅ‚adnie tego, co dzieje siÄ™ w tle na kaÅ¼dym etapie; wiÄ™kszoÅ›Ä‡
zachowaÅ„ trenera jest zawarta w jednej klasie!
W duchu Pythona nic nie jest ukryte, wszystko jest dostÄ™pne.

`pytorch-accelerated` jest dumnie i transparentnie zbudowany na
bazie [Hugging Face Accelerate](https://github.com/huggingface/accelerate), ktÃ³ry odpowiada za
przemieszczanie danych miÄ™dzy urzÄ…dzeniami i uruchamianie konfiguracji treningowych. Podczas dostosowywania trenera lub uruchamiania
treningu uÅ¼ytkownicy sÄ… zachÄ™cani do zapoznania siÄ™ z [dokumentacjÄ… Accelerate](https://huggingface.co/docs/accelerate/)
aby poznaÄ‡ wszystkie dostÄ™pne opcje; Accelerate zapewnia wygodne funkcje do operacji takich jak zbieranie tensorÃ³w
i obcinanie gradientÃ³w, ktÃ³rych uÅ¼ycie moÅ¼na zobaczyÄ‡ w folderze
[examples](https://github.com/Chris-hughes10/pytorch-accelerated/tree/main/examples) `pytorch-accelerated`!

Aby dowiedzieÄ‡ siÄ™ wiÄ™cej o motywacjach stojÄ…cych za tÄ… bibliotekÄ… oraz przeczytaÄ‡ szczegÃ³Å‚owy przewodnik na start, sprawdÅº [ten wpis na blogu](https://medium.com/@chris.p.hughes10/introducing-pytorch-accelerated-6ba99530608c?source=friends_link&sk=868c2d2ec5229fdea42877c0bf82b968).

## Instalacja

`pytorch-accelerated` moÅ¼na zainstalowaÄ‡ z pip, korzystajÄ…c z poniÅ¼szego polecenia:
```
pip install pytorch-accelerated
```
Aby uczyniÄ‡ pakiet moÅ¼liwie jak najbardziej smukÅ‚ym, domyÅ›lnie nie sÄ… doÅ‚Ä…czone pakiety wymagane do uruchomienia przykÅ‚adÃ³w. Aby doÅ‚Ä…czyÄ‡ te pakiety, moÅ¼esz uÅ¼yÄ‡ nastÄ™pujÄ…cego polecenia:

```
pip install pytorch-accelerated[examples]
```

## Szybki start

Aby rozpoczÄ…Ä‡, po prostu zaimportuj i uÅ¼yj `Trainer` z pytorch-accelerated, jak pokazano w poniÅ¼szym fragmencie,
a nastÄ™pnie uruchom trening, korzystajÄ…c z 
[accelerate CLI](https://huggingface.co/docs/accelerate/quicktour.html#launching-your-distributed-script)
opisanego poniÅ¼ej.

```python
# examples/core/train_mnist.py
import os

from torch import nn, optim
from torch.utils.data import random_split
from torchvision import transforms
from torchvision.datasets import MNIST

from pytorch_accelerated import Trainer

class MNISTModel(nn.Module):
    def __init__(self):
        super().__init__()
        self.main = nn.Sequential(
            nn.Linear(in_features=784, out_features=128),
            nn.ReLU(),
            nn.Linear(in_features=128, out_features=64),
            nn.ReLU(),
            nn.Linear(in_features=64, out_features=10),
        )

    def forward(self, input):
        return self.main(input.view(input.shape[0], -1))

def main():
    dataset = MNIST(os.getcwd(), download=True, transform=transforms.ToTensor())
    train_dataset, validation_dataset, test_dataset = random_split(dataset, [50000, 5000, 5000])
    model = MNISTModel()
    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)
    loss_func = nn.CrossEntropyLoss()

    trainer = Trainer(
            model,
            loss_func=loss_func,
            optimizer=optimizer,
    )

    trainer.train(
        train_dataset=train_dataset,
        eval_dataset=validation_dataset,
        num_epochs=8,
        per_device_batch_size=32,
    )

    trainer.evaluate(
        dataset=test_dataset,
        per_device_batch_size=64,
    )
    
if __name__ == "__main__":
    main()
```
Aby uruchomiÄ‡ trening za pomocÄ… [accelerate CLI](https://huggingface.co/docs/accelerate/quicktour.html#launching-your-distributed-script)
, na swoim komputerze/komputerach uruchom:

` accelerate config --config_file accelerate_config.yaml`

i odpowiedz na zadane pytania. To wygeneruje plik konfiguracyjny, ktÃ³ry zostanie uÅ¼yty do poprawnego ustawienia domyÅ›lnych opcji podczas uruchamiania

`accelerate launch --config_file accelerate_config.yaml train.py [--training-args]`

*Uwaga*: UÅ¼ycie [accelerate CLI](https://huggingface.co/docs/accelerate/quicktour.html#launching-your-distributed-script) jest caÅ‚kowicie opcjonalne, trening moÅ¼na rÃ³wnieÅ¼ uruchomiÄ‡ w tradycyjny sposÃ³b uÅ¼ywajÄ…c:

`python train.py` / `python -m torch.distributed ...`

w zaleÅ¼noÅ›ci od konfiguracji infrastruktury, dla uÅ¼ytkownikÃ³w, ktÃ³rzy chcÄ… mieÄ‡ wiÄ™kszÄ… kontrolÄ™ 
nad poleceniem uruchamiajÄ…cym.

Bardziej zÅ‚oÅ¼one przykÅ‚ady treningu moÅ¼na zobaczyÄ‡ w folderze examples 
[tu](https://github.com/Chris-hughes10/pytorch-accelerated/tree/main/examples). 

Alternatywnie, jeÅ›li wolisz najpierw poznaÄ‡ podstawowe pojÄ™cia, znajdziesz je w [dokumentacji](https://pytorch-accelerated.readthedocs.io/en/latest/).

## UÅ¼ycie

### Do kogo skierowany jest pytorch-accelerated?

- Do uÅ¼ytkownikÃ³w zaznajomionych z PyTorch, ktÃ³rzy chcÄ… uniknÄ…Ä‡ pisania typowej powtarzalnej pÄ™tli treningowej
aby skupiÄ‡ siÄ™ na ciekawszych aspektach treningu.
- Do uÅ¼ytkownikÃ³w, ktÃ³rzy lubiÄ… i potrafiÄ… samodzielnie wybieraÄ‡ oraz tworzyÄ‡ wÅ‚asne modele, funkcje straty, optymalizatory i zbiory danych.
- Do uÅ¼ytkownikÃ³w ceniÄ…cych sobie prostotÄ™ i przejrzysty zestaw funkcji, gdzie zachowanie jest Å‚atwe do debugowania, zrozumienia i przewidzenia!

### Kiedy nie powinieneÅ› uÅ¼ywaÄ‡ pytorch-accelerated?

- JeÅ›li szukasz kompletnego rozwiÄ…zania od koÅ„ca do koÅ„ca, obejmujÄ…cego wszystko od Å‚adowania danych po inferencjÄ™,
  pomagajÄ…cego w wyborze modelu, optymalizatora lub funkcji straty, prawdopodobnie lepszym wyborem bÄ™dzie
  [fastai](https://github.com/fastai/fastai). `pytorch-accelerated` skupia siÄ™ wyÅ‚Ä…cznie na procesie treningowym, pozostawiajÄ…c caÅ‚Ä… resztÄ™
  po stronie uÅ¼ytkownika.
- JeÅ›li chciaÅ‚byÅ› samodzielnie napisaÄ‡ caÅ‚Ä… pÄ™tlÄ™ treningowÄ…, ale bez wszystkich problemÃ³w z zarzÄ…dzaniem urzÄ…dzeniami,
najlepiej bÄ™dzie bezpoÅ›rednio uÅ¼yÄ‡ [Accelerate](https://github.com/huggingface/accelerate)! ChociaÅ¼ moÅ¼liwa jest peÅ‚na personalizacja `Trainer`, pÄ™tla treningowa jest zasadniczo podzielona na kilka 


rÃ³Å¼ne metody, ktÃ³re musiaÅ‚byÅ› nadpisaÄ‡. Ale zanim pÃ³jdziesz, czy naprawdÄ™ pisanie tych pÄ™tli `for` jest aÅ¼ tak waÅ¼ne, Å¼eby *znowu* zaczynaÄ‡ od zera ğŸ˜‰.
- JeÅ›li pracujesz nad niestandardowym, bardzo zÅ‚oÅ¼onym przypadkiem uÅ¼ycia, ktÃ³ry nie pasuje do wzorcÃ³w typowych pÄ™tli treningowych
i chcesz wycisnÄ…Ä‡ maksimum wydajnoÅ›ci z wybranego sprzÄ™tu, prawdopodobnie najlepiej bÄ™dzie pozostaÄ‡ przy czystym PyTorch; kaÅ¼da wysokopoziomowa API staje siÄ™ narzutem w wysoce wyspecjalizowanych przypadkach!


## PodziÄ™kowania

Wiele aspektÃ³w projektowych i funkcjonalnych `pytorch-accelerated` zostaÅ‚o silnie zainspirowanych przez znakomite 
biblioteki i frameworki takie jak [fastai](https://github.com/fastai/fastai), [timm](https://github.com/rwightman/pytorch-image-models), 
[PyTorch-lightning](https://github.com/PyTorchLightning/pytorch-lightning) oraz [Hugging Face Accelerate](https://github.com/huggingface/accelerate). KaÅ¼de z tych narzÄ™dzi 
wywarÅ‚o ogromny wpÅ‚yw zarÃ³wno na tÄ™ bibliotekÄ™, jak i na spoÅ‚ecznoÅ›Ä‡ uczenia maszynowego, i ich wpÅ‚yw nie moÅ¼e byÄ‡ 
wystarczajÄ…co doceniony!

`pytorch-accelerated` czerpaÅ‚ jedynie inspiracjÄ™ z tych narzÄ™dzi, a caÅ‚a zawarta funkcjonalnoÅ›Ä‡ zostaÅ‚a zaimplementowana
od zera w sposÃ³b korzystny dla tej biblioteki. Jedynymi wyjÄ…tkami sÄ… niektÃ³re skrypty w folderze 
[examples](https://github.com/Chris-hughes10/pytorch-accelerated/tree/main/examples),
w ktÃ³rych wykorzystano i zmodyfikowano istniejÄ…ce zasoby, aby zaprezentowaÄ‡ moÅ¼liwoÅ›ci `pytorch-accelerated`;
te przypadki sÄ… wyraÅºnie oznaczone, z podaniem uznania dla oryginalnych autorÃ³w.





---

Tranlated By [Open Ai Tx](https://github.com/OpenAiTx/OpenAiTx) | Last indexed: 2026-02-28

---