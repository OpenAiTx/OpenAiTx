<div align="center">

# s3 - é€šè¿‡å¼ºåŒ–å­¦ä¹ å®ç°é«˜æ•ˆä¸”æœ‰æ•ˆçš„æœç´¢ä»£ç†è®­ç»ƒ
***è®­ç»ƒæœç´¢ä»£ç†ä¸éœ€è¦é‚£ä¹ˆå¤šæ•°æ®***

<p align="center">

  <a href="https://arxiv.org/abs/2505.14146">
    <img src="https://img.shields.io/badge/arXiv-2505.14146-b31b1b.svg" alt="arXiv">
  </a>
</p>
</div>

**æ€§èƒ½æ¦‚è§ˆï¼š**

<img src="https://raw.githubusercontent.com/pat-jj/s3/main/images/performance_overview.png" alt="performance_overview" width="800">



## ä»€ä¹ˆæ˜¯ s3ï¼Ÿ

<div align="center">
<img src="https://raw.githubusercontent.com/pat-jj/s3/main/images/framework.png" alt="framework" width="800">

**s3 æ¡†æ¶**
</div>

`s3` æ˜¯ä¸€ä¸ªç®€å•è€Œå¼ºå¤§çš„æ¡†æ¶ï¼Œç”¨äºè®­ç»ƒæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ä¸­çš„æœç´¢ä»£ç†ã€‚å®ƒæ•™ä¼šè¯­è¨€æ¨¡å‹å¦‚ä½•æ›´æœ‰æ•ˆåœ°æœç´¢â€”â€”è€Œæ— éœ€æ›´æ”¹ç”Ÿæˆå™¨æœ¬èº«ã€‚é€šè¿‡ä¸“æ³¨äºæœç´¢ç»„ä»¶ï¼Œ`s3` åªç”¨å…ˆå‰æ–¹æ³•çš„ä¸€å°éƒ¨åˆ†æ•°æ®å°±èƒ½åœ¨é—®ç­”ä»»åŠ¡ä¸­å®ç°å¼ºåŠ²çš„æ€§èƒ½ã€‚å®ƒæ¨¡å—åŒ–ã€é«˜æ•ˆï¼Œå¹¶è®¾è®¡ä¸ºèƒ½æ— ç¼å…¼å®¹ä»»ä½•é»‘ç›’å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ã€‚



## ç›®å½•

- [ğŸ“¦ å®‰è£…](#-installation)
- [ğŸ’¡ å‡†å¤‡](#-preparation)
- [ğŸ‹ï¸ è¿è¡Œè®­ç»ƒ](https://github.com/pat-jj/s3?tab=readme-ov-file#%EF%B8%8F-run-training)
- [ğŸ” è¿è¡Œæœç´¢/æ£€ç´¢](https://github.com/pat-jj/s3?tab=readme-ov-file#-run-searchretrieval)
- [ğŸ“ˆ è¿è¡Œè¯„ä¼°](#-run-evaluation)

## ğŸ“¦ å®‰è£…

**æœç´¢å™¨ & ç”Ÿæˆå™¨ç¯å¢ƒ**
```bash
conda create -n s3 python=3.9
# install torch [or you can skip this step and let vllm to install the correct version for you]
pip install torch==2.4.0 --index-url https://download.pytorch.org/whl/cu121
# install vllm
pip3 install vllm==0.6.3 # or you can install 0.5.4, 0.4.2 and 0.3.1
pip3 install ray

# verl
cd code
pip install -e .

# flash attention 2
pip3 install flash-attn --no-build-isolation

# we use pyserini for efficient retrieval and evaluation
pip install pyserini    # the version we used is 0.22.1

# quality of life
pip install wandb IPython matplotlib huggingface_hub
```
**æ£€ç´¢å™¨ç¯å¢ƒ**

```bash
conda create -n ret python=3.10
conda activate ret

conda install pytorch==2.4.0 torchvision==0.19.0 torchaudio==2.4.0 pytorch-cuda=12.1 -c pytorch -c nvidia
pip install transformers datasets pyserini
conda install -c pytorch -c nvidia faiss-gpu=1.8.0
pip install uvicorn fastapi
```
<translate-content>


## ğŸ’¡ å‡†å¤‡å·¥ä½œ
***ä¸‹è½½ç´¢å¼•å’Œè¯­æ–™åº“***</translate-content>
```bash
python scripts/download.py --save_path $save_path
cat $save_path/part_* > $save_path/e5_Flat.index
gzip -d $save_path/wiki-18.jsonl.gz
```
***é¢„è®¡ç®—æœ´ç´ RAGåˆå§‹åŒ–***


```bash
# deploy retriever
bash scripts/deploy_retriever/retrieval_launch.sh # or scripts/deploy_retriever/retrieval_launch_mirage.sh for MedCorp corpus.
# deploy generator
bash generator_llms/host.sh # modify tensor-parallel-size to the number of GPUs you use
# run precompute
bash scripts/precompute.sh # this step will take a while, as it will precompute the naÃ¯ve RAG Cache for training
```
## ğŸ‹ï¸ è¿è¡Œè®­ç»ƒ
***æ­¤æ­¥éª¤ç”¨äºS3çš„è®­ç»ƒ***



```bash
# deploy retriever
bash scripts/deploy_retriever/retrieval_launch.sh 
# deploy generator
bash generator_llms/host.sh
# run training
bash scripts/train/train_s3.sh
```
## ğŸ” è¿è¡Œæœç´¢/æ£€ç´¢
***æ­¤æ­¥éª¤ç”¨äºs3 / åŸºçº¿çš„ä¸Šä¸‹æ–‡æ”¶é›†***

**s3**


```bash
# deploy retriever
bash scripts/deploy_retriever/retrieval_launch.sh 
# run s3 inference
bash scripts/s3_inference/evaluate-8-3-3.sh
```
<translate-content>
<details>
<summary>åŸºçº¿</summary>

**RAG**</translate-content>
```bash
bash scripts/deploy_retriever/retrieval_launch.sh # or retrieval_launch_bm25.sh # deploy retriever
bash scripts/baselines/rag.sh # run RAG 
```
**æ·±åº¦æ£€ç´¢**

```bash
bash retrieval_launch_bm25.sh # deploy BM25 Model
bash generator_llms/deepretrieval.sh # deploy DeepRetrieval Model
bash scripts/baselines/deepretrieval.sh # run DeepRetrieval Query Rewriting + Retrieval
```
<translate-content>
**æœç´¢-R1**</translate-content>
```bash
bash retrieval_launch.sh # deploy e5 retriever
bash scripts/baselines/search_r1.sh # run Search-R1
```
<translate-content>
**IRCoT**</translate-content>
```bash
bash retrieval_launch.sh # deploy e5 retriever
python scripts/baselines/ircot.py
```
<translate-content>
**æœç´¢-o1**</translate-content>
```bash
bash retrieval_launch.sh # deploy e5 retriever
bash scripts/baselines/search_o1.sh # run Search-o1
```
</details>


## ğŸ“ˆ è¿è¡Œè¯„ä¼°
***æ­¤æ­¥éª¤ç”¨äºè¯„ä¼° s3 / åŸºçº¿***



```bash
bash scripts/evaluation/run.sh
```
<translate-content>

## è‡´è°¢
æˆ‘ä»¬è¦æ„Ÿè°¢ä»¥ä¸‹é¡¹ç›®ï¼š
[verl](https://github.com/volcengine/verl), [RAGEN](https://github.com/RAGEN-AI/RAGEN), [Search-R1](https://github.com/PeterGriffinJin/Search-R1), [DeepRetrieval](https://github.com/pat-jj/DeepRetrieval), [PySerini](https://github.com/castorini/pySerini).
 

## å¼•ç”¨</translate-content>
```bibtex
@article{jiang2025s3,
  title={s3: You Don't Need That Much Data to Train a Search Agent via RL},
  author={Jiang, Pengcheng and Xu, Xueqiang and Lin, Jiacheng and Xiao, Jinfeng and Wang, Zifeng and Sun, Jimeng and Han, Jiawei},
  journal={arXiv preprint arXiv:2505.14146},
  year={2025}
}
```
æ„Ÿè°¢æ‚¨å¯¹æˆ‘ä»¬å·¥ä½œçš„å…³æ³¨ï¼






---

Tranlated By [Open Ai Tx](https://github.com/OpenAiTx/OpenAiTx) | Last indexed: 2025-07-16

---