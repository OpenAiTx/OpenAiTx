
<div align="right">
  <details>
    <summary >ğŸŒ è¨€èª</summary>
    <div>
      <div align="center">
        <a href="https://openaitx.github.io/view.html?user=pat-jj&project=s3&lang=en">English</a>
        | <a href="https://openaitx.github.io/view.html?user=pat-jj&project=s3&lang=zh-CN">ç®€ä½“ä¸­æ–‡</a>
        | <a href="https://openaitx.github.io/view.html?user=pat-jj&project=s3&lang=zh-TW">ç¹é«”ä¸­æ–‡</a>
        | <a href="https://openaitx.github.io/view.html?user=pat-jj&project=s3&lang=ja">æ—¥æœ¬èª</a>
        | <a href="https://openaitx.github.io/view.html?user=pat-jj&project=s3&lang=ko">í•œêµ­ì–´</a>
        | <a href="https://openaitx.github.io/view.html?user=pat-jj&project=s3&lang=hi">à¤¹à¤¿à¤¨à¥à¤¦à¥€</a>
        | <a href="https://openaitx.github.io/view.html?user=pat-jj&project=s3&lang=th">à¹„à¸—à¸¢</a>
        | <a href="https://openaitx.github.io/view.html?user=pat-jj&project=s3&lang=fr">FranÃ§ais</a>
        | <a href="https://openaitx.github.io/view.html?user=pat-jj&project=s3&lang=de">Deutsch</a>
        | <a href="https://openaitx.github.io/view.html?user=pat-jj&project=s3&lang=es">EspaÃ±ol</a>
        | <a href="https://openaitx.github.io/view.html?user=pat-jj&project=s3&lang=it">Itapano</a>
        | <a href="https://openaitx.github.io/view.html?user=pat-jj&project=s3&lang=ru">Ğ ÑƒÑÑĞºĞ¸Ğ¹</a>
        | <a href="https://openaitx.github.io/view.html?user=pat-jj&project=s3&lang=pt">PortuguÃªs</a>
        | <a href="https://openaitx.github.io/view.html?user=pat-jj&project=s3&lang=nl">Nederlands</a>
        | <a href="https://openaitx.github.io/view.html?user=pat-jj&project=s3&lang=pl">Polski</a>
        | <a href="https://openaitx.github.io/view.html?user=pat-jj&project=s3&lang=ar">Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©</a>
        | <a href="https://openaitx.github.io/view.html?user=pat-jj&project=s3&lang=fa">ÙØ§Ø±Ø³ÛŒ</a>
        | <a href="https://openaitx.github.io/view.html?user=pat-jj&project=s3&lang=tr">TÃ¼rkÃ§e</a>
        | <a href="https://openaitx.github.io/view.html?user=pat-jj&project=s3&lang=vi">Tiáº¿ng Viá»‡t</a>
        | <a href="https://openaitx.github.io/view.html?user=pat-jj&project=s3&lang=id">Bahasa Indonesia</a>
      </div>
    </div>
  </details>
</div>

<div align="center">

# s3 - åŠ¹ç‡çš„ã‹ã¤åŠ¹æœçš„ãªæ¤œç´¢ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å¼·åŒ–å­¦ç¿’ã«ã‚ˆã‚‹ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°
***æ¤œç´¢ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã«ã¯ãã‚Œã»ã©å¤šãã®ãƒ‡ãƒ¼ã‚¿ã¯å¿…è¦ã‚ã‚Šã¾ã›ã‚“***

<p align="center">

  <a href="https://arxiv.org/abs/2505.14146">
    <img src="https://img.shields.io/badge/arXiv-2505.14146-b31b1b.svg" alt="arXiv">
  </a>
</p>
</div>

**ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¦‚è¦ï¼š**

<img src="https://raw.githubusercontent.com/pat-jj/s3/main/images/performance_overview.png" alt="performance_overview" width="800">



## s3ã¨ã¯ä½•ã§ã™ã‹ï¼Ÿ

<div align="center">
<img src="https://raw.githubusercontent.com/pat-jj/s3/main/images/framework.png" alt="framework" width="800">

**s3ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯**
</div>

`s3`ã¯ã€æ¤œç´¢ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’è¨“ç·´ã™ã‚‹ãŸã‚ã®ã‚·ãƒ³ãƒ—ãƒ«ã§å¼·åŠ›ãªãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã‚ã‚Šã€æ¤œç´¢å¼·åŒ–ç”Ÿæˆï¼ˆRAGï¼‰ã§åˆ©ç”¨ã•ã‚Œã¾ã™ã€‚ã“ã‚Œã¯è¨€èªãƒ¢ãƒ‡ãƒ«ã«ã€ç”Ÿæˆå™¨è‡ªä½“ã‚’å¤‰æ›´ã™ã‚‹ã“ã¨ãªãã€ã‚ˆã‚ŠåŠ¹æœçš„ã«æ¤œç´¢ã™ã‚‹æ–¹æ³•ã‚’æ•™ãˆã¾ã™ã€‚æ¤œç´¢ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®ã¿ã«æ³¨åŠ›ã™ã‚‹ã“ã¨ã§ã€`s3`ã¯å¾“æ¥æ‰‹æ³•ã®ã”ãä¸€éƒ¨ã®ãƒ‡ãƒ¼ã‚¿ã®ã¿ã§ã€QAã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦é«˜ã„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å®Ÿç¾ã—ã¾ã™ã€‚ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«æ§‹é€ ã§åŠ¹ç‡çš„ã€ã‚ã‚‰ã‚†ã‚‹ãƒ–ãƒ©ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹LLMã¨ã‚·ãƒ¼ãƒ ãƒ¬ã‚¹ã«å‹•ä½œã™ã‚‹ã‚ˆã†è¨­è¨ˆã•ã‚Œã¦ã„ã¾ã™ã€‚



## ç›®æ¬¡

- [ğŸ“¦ ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«](#-installation)
- [ğŸ’¡ æº–å‚™](#-preparation)
- [ğŸ‹ï¸ ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®å®Ÿè¡Œ](https://github.com/pat-jj/s3?tab=readme-ov-file#%EF%B8%8F-run-training)
- [ğŸ” æ¤œç´¢/ãƒªãƒˆãƒªãƒ¼ãƒãƒ«ã®å®Ÿè¡Œ](https://github.com/pat-jj/s3?tab=readme-ov-file#-run-searchretrieval)
- [ğŸ“ˆ è©•ä¾¡ã®å®Ÿè¡Œ](#-run-evaluation)

## ğŸ“¦ ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

**ã‚µãƒ¼ãƒãƒ£ãƒ¼ï¼†ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼ç’°å¢ƒ**
```bash
conda create -n s3 python=3.9
# install torch [or you can skip this step and let vllm to install the correct version for you]
pip install torch==2.4.0 --index-url https://download.pytorch.org/whl/cu121
# install vllm
pip3 install vllm==0.6.3 # or you can install 0.5.4, 0.4.2 and 0.3.1
pip3 install ray

# verl
# cd code
pip install -e .

# flash attention 2
pip3 install flash-attn --no-build-isolation

# we use pyserini for efficient retrieval and evaluation
pip install pyserini    # the version we used is 0.22.1

# quality of life
pip install wandb IPython matplotlib huggingface_hub
```
**ãƒªãƒˆãƒªãƒ¼ãƒãƒ¼ç’°å¢ƒ**

```bash
conda create -n ret python=3.10
conda activate ret

conda install pytorch==2.4.0 torchvision==0.19.0 torchaudio==2.4.0 pytorch-cuda=12.1 -c pytorch -c nvidia
pip install transformers datasets pyserini
conda install -c pytorch -c nvidia faiss-gpu=1.8.0
pip install uvicorn fastapi
```




## ğŸ’¡ æº–å‚™
***ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¨ã‚³ãƒ¼ãƒ‘ã‚¹ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰***

```bash
python scripts/download.py --save_path $save_path
cat $save_path/part_* > $save_path/e5_Flat.index
gzip -d $save_path/wiki-18.jsonl.gz
```

***ãƒŠã‚¤ãƒ¼ãƒ–RAGåˆæœŸåŒ–ã®äº‹å‰è¨ˆç®—***ï¼ˆã¾ãŸã¯ã€ã“ã¡ã‚‰ã‹ã‚‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã™ï¼š[huggingface](https://huggingface.co/datasets/pat-jj/s3_processed_data)ï¼‰

```bash
# deploy retriever
bash scripts/deploy_retriever/retrieval_launch.sh # or scripts/deploy_retriever/retrieval_launch_mirage.sh for MedCorp corpus.
# deploy generator
bash generator_llms/host.sh # modify tensor-parallel-size to the number of GPUs you use
# run precompute
bash scripts/precompute.sh # this step will take a while, as it will precompute the naÃ¯ve RAG Cache for training
```
## ğŸ‹ï¸ ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®å®Ÿè¡Œ
***ã“ã®ã‚¹ãƒ†ãƒƒãƒ—ã¯S3ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ç”¨ã§ã™***



```bash
# deploy retriever
bash scripts/deploy_retriever/retrieval_launch.sh 
# deploy generator
bash generator_llms/host.sh
# run training
bash scripts/train/train_s3.sh
```
## ğŸ” æ¤œç´¢ï¼å–å¾—ã®å®Ÿè¡Œ
***ã“ã®ã‚¹ãƒ†ãƒƒãƒ—ã¯ s3 / ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆåé›†ã®ãŸã‚ã®ã‚‚ã®ã§ã™***

**s3**


```bash
# deploy retriever
bash scripts/deploy_retriever/retrieval_launch.sh 
# run s3 inference
bash scripts/s3_inference/evaluate-8-3-3.sh
```
<details>
<summary>ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³</summary>

**RAG**

```bash
bash scripts/deploy_retriever/retrieval_launch.sh # or retrieval_launch_bm25.sh # deploy retriever
bash scripts/baselines/rag.sh # run RAG 
```
**DeepRetrieval**

```bash
bash retrieval_launch_bm25.sh # deploy BM25 Model
bash generator_llms/deepretrieval.sh # deploy DeepRetrieval Model
bash scripts/baselines/deepretrieval.sh # run DeepRetrieval Query Rewriting + Retrieval
```
**æ¤œç´¢-R1**

```bash
bash retrieval_launch.sh # deploy e5 retriever
bash scripts/baselines/search_r1.sh # run Search-R1
```
**IRCoT**

```bash
bash retrieval_launch.sh # deploy e5 retriever
python scripts/baselines/ircot.py
```
**æ¤œç´¢-o1**

```bash
bash retrieval_launch.sh # deploy e5 retriever
bash scripts/baselines/search_o1.sh # run Search-o1
```
</details>


## ğŸ“ˆ å®Ÿè¡Œè©•ä¾¡
***ã“ã®ã‚¹ãƒ†ãƒƒãƒ—ã¯s3 / ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã®è©•ä¾¡ç”¨ã§ã™***



```bash
bash scripts/evaluation/run.sh
```

## Q&A
### ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã«ã¤ã„ã¦
ç‹¬è‡ªã®ã‚³ãƒ¼ãƒ‘ã‚¹ã‚„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ s3 ã‚’ãƒ†ã‚¹ãƒˆã—ãŸã„å ´åˆã¯ã€ã“ã®ã‚³ãƒŸãƒƒãƒˆã‚’å‚è€ƒã«ã—ã¦ç‹¬è‡ªã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’æ§‹ç¯‰ã™ã‚‹æ‰‹é †ã‚’ç¢ºèªã§ãã¾ã™: [commit 8420538](https://github.com/pat-jj/s3/commit/8420538836febbe59d5bcbe41187f16908c9c36c)

### çµæœã®å†ç¾ã«ã¤ã„ã¦
è¤‡æ•°ã®é–‹ç™ºè€…ãŒã™ã§ã«å½“ç¤¾ã®çµæœã‚’æ­£å¸¸ã«å†ç¾ã—ã¦ã„ã¾ã™ã€‚ã”è³ªå•ã‚„å•é¡ŒãŒç™ºç”Ÿã—ãŸå ´åˆã¯ã€[issue ã‚’ã‚ªãƒ¼ãƒ—ãƒ³](https://github.com/pat-jj/s3/issues) ã—ã¦ãã ã•ã„ â€” å®Ÿè·µçš„ãªã‚¬ã‚¤ãƒ€ãƒ³ã‚¹ã‚’å–œã‚“ã§æä¾›ã—ã¾ã™ï¼ˆ[ã“ã®ä¾‹](https://github.com/pat-jj/s3/issues/20) ã‚’ã”å‚ç…§ãã ã•ã„ï¼‰ã€‚

ãƒ¢ãƒ‡ãƒ«ã®å†ç¾è‡ªä½“ã¯ç°¡å˜ã§ã™ãŒã€å®Ÿéš›ã«ã¯**ä¸€ã‹ã‚‰ã®å­¦ç¿’ã‚’æ¨å¥¨ã—ã¦ã„ã¾ã™**ã€‚è©•ä¾¡ã¯å¤šãã®å ´åˆã€å­¦ç¿’ã‚ˆã‚Šã‚‚ã¯ã‚‹ã‹ã«æ™‚é–“ãŒã‹ã‹ã‚‹ãŸã‚ã§ã™ã€‚å‚è€ƒç”¨ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚‚æä¾›ã—ã¦ã„ã¾ã™: [s3-8-3-3-20steps](https://huggingface.co/pat-jj/s3-8-3-3-20steps)ï¼ˆç´„1æ™‚é–“ã§å­¦ç¿’æ¸ˆã¿ï¼‰ã€‚



## å¼•ç”¨
```bibtex
@article{jiang2025s3,
  title={s3: You Don't Need That Much Data to Train a Search Agent via RL},
  author={Jiang, Pengcheng and Xu, Xueqiang and Lin, Jiacheng and Xiao, Jinfeng and Wang, Zifeng and Sun, Jimeng and Han, Jiawei},
  journal={arXiv preprint arXiv:2505.14146},
  year={2025}
}
```
ã”é–¢å¿ƒã‚’ãŠå¯„ã›ã„ãŸã ãã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ï¼






---

Tranlated By [Open Ai Tx](https://github.com/OpenAiTx/OpenAiTx) | Last indexed: 2025-12-30

---