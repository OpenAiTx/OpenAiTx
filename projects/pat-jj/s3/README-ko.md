<translate-content><div align="center">

# s3 - RLì„ í†µí•œ íš¨ìœ¨ì ì´ë©´ì„œë„ íš¨ê³¼ì ì¸ ê²€ìƒ‰ ì—ì´ì „íŠ¸ í•™ìŠµ
***ê²€ìƒ‰ ì—ì´ì „íŠ¸ë¥¼ í•™ìŠµì‹œí‚¤ê¸° ìœ„í•´ ê·¸ë ‡ê²Œ ë§ì€ ë°ì´í„°ê°€ í•„ìš”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤***

<p align="center">

  <a href="https://arxiv.org/abs/2505.14146">
    <img src="https://img.shields.io/badge/arXiv-2505.14146-b31b1b.svg" alt="arXiv">
  </a>
</p>
</div>

**ì„±ëŠ¥ ê°œìš”:**

<img src="https://raw.githubusercontent.com/pat-jj/s3/main/images/performance_overview.png" alt="performance_overview" width="800">



## s3ë€?

<div align="center">
<img src="https://raw.githubusercontent.com/pat-jj/s3/main/images/framework.png" alt="framework" width="800">

**s3 í”„ë ˆì„ì›Œí¬**
</div>

`s3`ëŠ” ê²€ìƒ‰ ê°•í™” ìƒì„±(RAG)ì—ì„œ ê²€ìƒ‰ ì—ì´ì „íŠ¸ë¥¼ í•™ìŠµì‹œí‚¤ê¸° ìœ„í•œ ë‹¨ìˆœí•˜ì§€ë§Œ ê°•ë ¥í•œ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤. ìƒì„±ê¸° ìì²´ë¥¼ ë³€ê²½í•˜ì§€ ì•Šê³  ì–¸ì–´ ëª¨ë¸ì—ê²Œ ë” íš¨ê³¼ì ìœ¼ë¡œ ê²€ìƒ‰í•˜ëŠ” ë°©ë²•ì„ ê°€ë¥´ì¹©ë‹ˆë‹¤. ê²€ìƒ‰ êµ¬ì„± ìš”ì†Œì—ë§Œ ì§‘ì¤‘í•¨ìœ¼ë¡œì¨ `s3`ëŠ” ì´ì „ ë°©ë²•ì´ ì‚¬ìš©í•˜ëŠ” ë°ì´í„°ì˜ ì¼ë¶€ë§Œìœ¼ë¡œ QA ì‘ì—…ì—ì„œ ê°•ë ¥í•œ ì„±ëŠ¥ì„ ë‹¬ì„±í•©ë‹ˆë‹¤. ëª¨ë“ˆì‹ì´ë©° íš¨ìœ¨ì ì´ê³ , ì–´ë–¤ ë¸”ë™ë°•ìŠ¤ LLMê³¼ë„ ì›í™œí•˜ê²Œ ì‘ë™í•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.



## ëª©ì°¨

- [ğŸ“¦ ì„¤ì¹˜](#-installation)
- [ğŸ’¡ ì¤€ë¹„](#-preparation)
- [ğŸ‹ï¸ í•™ìŠµ ì‹¤í–‰](https://github.com/pat-jj/s3?tab=readme-ov-file#%EF%B8%8F-run-training)
- [ğŸ” ê²€ìƒ‰/ê²€ìƒ‰ ì‹¤í–‰](https://github.com/pat-jj/s3?tab=readme-ov-file#-run-searchretrieval)
- [ğŸ“ˆ í‰ê°€ ì‹¤í–‰](#-run-evaluation)

## ğŸ“¦ ì„¤ì¹˜

**ê²€ìƒ‰ê¸° ë° ìƒì„±ê¸° í™˜ê²½**</translate-content>
```bash
conda create -n s3 python=3.9
# install torch [or you can skip this step and let vllm to install the correct version for you]
pip install torch==2.4.0 --index-url https://download.pytorch.org/whl/cu121
# install vllm
pip3 install vllm==0.6.3 # or you can install 0.5.4, 0.4.2 and 0.3.1
pip3 install ray

# verl
cd code
pip install -e .

# flash attention 2
pip3 install flash-attn --no-build-isolation

# we use pyserini for efficient retrieval and evaluation
pip install pyserini    # the version we used is 0.22.1

# quality of life
pip install wandb IPython matplotlib huggingface_hub
```
**ê²€ìƒ‰ê¸° í™˜ê²½**

```bash
conda create -n ret python=3.10
conda activate ret

conda install pytorch==2.4.0 torchvision==0.19.0 torchaudio==2.4.0 pytorch-cuda=12.1 -c pytorch -c nvidia
pip install transformers datasets pyserini
conda install -c pytorch -c nvidia faiss-gpu=1.8.0
pip install uvicorn fastapi
```
<translate-content>


## ğŸ’¡ ì¤€ë¹„í•˜ê¸°
***ìƒ‰ì¸ ë° ë§ë­‰ì¹˜ ë‹¤ìš´ë¡œë“œ***</translate-content>
```bash
python scripts/download.py --save_path $save_path
cat $save_path/part_* > $save_path/e5_Flat.index
gzip -d $save_path/wiki-18.jsonl.gz
```
***ë¯¸ë¦¬ ê³„ì‚°ëœ ìˆœì§„í•œ RAG ì´ˆê¸°í™”***


```bash
# deploy retriever
bash scripts/deploy_retriever/retrieval_launch.sh # or scripts/deploy_retriever/retrieval_launch_mirage.sh for MedCorp corpus.
# deploy generator
bash generator_llms/host.sh # modify tensor-parallel-size to the number of GPUs you use
# run precompute
bash scripts/precompute.sh # this step will take a while, as it will precompute the naÃ¯ve RAG Cache for training
```
<translate-content>

## ğŸ‹ï¸ í›ˆë ¨ ì‹¤í–‰
***ì´ ë‹¨ê³„ëŠ” S3 í›ˆë ¨ì„ ìœ„í•œ ê²ƒì…ë‹ˆë‹¤***
</translate-content>
```bash
# deploy retriever
bash scripts/deploy_retriever/retrieval_launch.sh 
# deploy generator
bash generator_llms/host.sh
# run training
bash scripts/train/train_s3.sh
```
<translate-content>

## ğŸ” ê²€ìƒ‰/ê²€ìƒ‰ ì‹¤í–‰
***ì´ ë‹¨ê³„ëŠ” s3 / ê¸°ì¤€ì„ ì˜ ì»¨í…ìŠ¤íŠ¸ ìˆ˜ì§‘ì„ ìœ„í•œ ê²ƒì…ë‹ˆë‹¤***

**s3**</translate-content>
```bash
# deploy retriever
bash scripts/deploy_retriever/retrieval_launch.sh 
# run s3 inference
bash scripts/s3_inference/evaluate-8-3-3.sh
```
<translate-content>
<details>
<summary>ê¸°ì¤€ì„ </summary>

**RAG**</translate-content>
```bash
bash scripts/deploy_retriever/retrieval_launch.sh # or retrieval_launch_bm25.sh # deploy retriever
bash scripts/baselines/rag.sh # run RAG 
```
<translate-content>
**ë”¥ë¦¬íŠ¸ë¦¬ë²Œ**</translate-content>
```bash
bash retrieval_launch_bm25.sh # deploy BM25 Model
bash generator_llms/deepretrieval.sh # deploy DeepRetrieval Model
bash scripts/baselines/deepretrieval.sh # run DeepRetrieval Query Rewriting + Retrieval
```
**ê²€ìƒ‰-R1**

```bash
bash retrieval_launch.sh # deploy e5 retriever
bash scripts/baselines/search_r1.sh # run Search-R1
```
**IRCoT**

```bash
bash retrieval_launch.sh # deploy e5 retriever
python scripts/baselines/ircot.py
```
**ê²€ìƒ‰-o1**

```bash
bash retrieval_launch.sh # deploy e5 retriever
bash scripts/baselines/search_o1.sh # run Search-o1
```
<translate-content>
</details>


## ğŸ“ˆ ì‹¤í–‰ í‰ê°€
***ì´ ë‹¨ê³„ëŠ” s3 / ê¸°ì¤€ì„  í‰ê°€ë¥¼ ìœ„í•œ ë‹¨ê³„ì…ë‹ˆë‹¤***

</translate-content>
```bash
bash scripts/evaluation/run.sh
```
## ê°ì‚¬ì˜ ê¸€
ë‹¤ìŒ í”„ë¡œì íŠ¸ì— ê°ì‚¬ë¥¼ í‘œí•©ë‹ˆë‹¤:
[verl](https://github.com/volcengine/verl), [RAGEN](https://github.com/RAGEN-AI/RAGEN), [Search-R1](https://github.com/PeterGriffinJin/Search-R1), [DeepRetrieval](https://github.com/pat-jj/DeepRetrieval), [PySerini](https://github.com/castorini/pySerini).
 

## ì¸ìš©ë¬¸í—Œ


```bibtex
@article{jiang2025s3,
  title={s3: You Don't Need That Much Data to Train a Search Agent via RL},
  author={Jiang, Pengcheng and Xu, Xueqiang and Lin, Jiacheng and Xiao, Jinfeng and Wang, Zifeng and Sun, Jimeng and Han, Jiawei},
  journal={arXiv preprint arXiv:2505.14146},
  year={2025}
}
```
<translate-content>
ìš°ë¦¬ ì‘ì—…ì— ê´€ì‹¬ì„ ê°€ì ¸ ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤!



</translate-content>

---

Tranlated By [Open Ai Tx](https://github.com/OpenAiTx/OpenAiTx) | Last indexed: 2025-07-16

---