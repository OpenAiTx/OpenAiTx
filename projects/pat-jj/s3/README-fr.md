
<div align="right">
  <details>
    <summary >ğŸŒ Langue</summary>
    <div>
      <div align="center">
        <a href="https://openaitx.github.io/view.html?user=pat-jj&project=s3&lang=en">English</a>
        | <a href="https://openaitx.github.io/view.html?user=pat-jj&project=s3&lang=zh-CN">ç®€ä½“ä¸­æ–‡</a>
        | <a href="https://openaitx.github.io/view.html?user=pat-jj&project=s3&lang=zh-TW">ç¹é«”ä¸­æ–‡</a>
        | <a href="https://openaitx.github.io/view.html?user=pat-jj&project=s3&lang=ja">æ—¥æœ¬èª</a>
        | <a href="https://openaitx.github.io/view.html?user=pat-jj&project=s3&lang=ko">í•œêµ­ì–´</a>
        | <a href="https://openaitx.github.io/view.html?user=pat-jj&project=s3&lang=hi">à¤¹à¤¿à¤¨à¥à¤¦à¥€</a>
        | <a href="https://openaitx.github.io/view.html?user=pat-jj&project=s3&lang=th">à¹„à¸—à¸¢</a>
        | <a href="https://openaitx.github.io/view.html?user=pat-jj&project=s3&lang=fr">FranÃ§ais</a>
        | <a href="https://openaitx.github.io/view.html?user=pat-jj&project=s3&lang=de">Deutsch</a>
        | <a href="https://openaitx.github.io/view.html?user=pat-jj&project=s3&lang=es">EspaÃ±ol</a>
        | <a href="https://openaitx.github.io/view.html?user=pat-jj&project=s3&lang=it">Itapano</a>
        | <a href="https://openaitx.github.io/view.html?user=pat-jj&project=s3&lang=ru">Ğ ÑƒÑÑĞºĞ¸Ğ¹</a>
        | <a href="https://openaitx.github.io/view.html?user=pat-jj&project=s3&lang=pt">PortuguÃªs</a>
        | <a href="https://openaitx.github.io/view.html?user=pat-jj&project=s3&lang=nl">Nederlands</a>
        | <a href="https://openaitx.github.io/view.html?user=pat-jj&project=s3&lang=pl">Polski</a>
        | <a href="https://openaitx.github.io/view.html?user=pat-jj&project=s3&lang=ar">Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©</a>
        | <a href="https://openaitx.github.io/view.html?user=pat-jj&project=s3&lang=fa">ÙØ§Ø±Ø³ÛŒ</a>
        | <a href="https://openaitx.github.io/view.html?user=pat-jj&project=s3&lang=tr">TÃ¼rkÃ§e</a>
        | <a href="https://openaitx.github.io/view.html?user=pat-jj&project=s3&lang=vi">Tiáº¿ng Viá»‡t</a>
        | <a href="https://openaitx.github.io/view.html?user=pat-jj&project=s3&lang=id">Bahasa Indonesia</a>
      </div>
    </div>
  </details>
</div>

<div align="center">

# s3 - Agent de Recherche Efficace et Performant via lâ€™Apprentissage par Renforcement
***Vous nâ€™avez pas besoin de tant de donnÃ©es pour entraÃ®ner un agent de recherche***

<p align="center">

  <a href="https://arxiv.org/abs/2505.14146">
    <img src="https://img.shields.io/badge/arXiv-2505.14146-b31b1b.svg" alt="arXiv">
  </a>
</p>
</div>

**AperÃ§u des performances :**

<img src="https://raw.githubusercontent.com/pat-jj/s3/main/images/performance_overview.png" alt="performance_overview" width="800">



## Qu'est-ce que s3 ?

<div align="center">
<img src="https://raw.githubusercontent.com/pat-jj/s3/main/images/framework.png" alt="framework" width="800">

**Framework s3**
</div>

`s3` est un framework simple mais puissant pour entraÃ®ner des agents de recherche dans la gÃ©nÃ©ration augmentÃ©e par rÃ©cupÃ©ration (RAG). Il apprend aux modÃ¨les de langage Ã  rechercher plus efficacementâ€”sans modifier le gÃ©nÃ©rateur lui-mÃªme. En se concentrant uniquement sur le composant de recherche, `s3` obtient d'excellentes performances sur les tÃ¢ches de QA avec seulement une fraction des donnÃ©es utilisÃ©es par les mÃ©thodes prÃ©cÃ©dentes. Il est modulaire, efficace et conÃ§u pour fonctionner parfaitement avec n'importe quel LLM boÃ®te noire.



## Table des matiÃ¨res

- [ğŸ“¦ Installation](#-installation)
- [ğŸ’¡ PrÃ©paration](#-preparation)
- [ğŸ‹ï¸ Lancer lâ€™entraÃ®nement](https://github.com/pat-jj/s3?tab=readme-ov-file#%EF%B8%8F-run-training)
- [ğŸ” Lancer la recherche/rÃ©cupÃ©ration](https://github.com/pat-jj/s3?tab=readme-ov-file#-run-searchretrieval)
- [ğŸ“ˆ Lancer lâ€™Ã©valuation](#-run-evaluation)

## ğŸ“¦ Installation

**Environnement du chercheur & gÃ©nÃ©rateur**
```bash
conda create -n s3 python=3.9
# install torch [or you can skip this step and let vllm to install the correct version for you]
pip install torch==2.4.0 --index-url https://download.pytorch.org/whl/cu121
# install vllm
pip3 install vllm==0.6.3 # or you can install 0.5.4, 0.4.2 and 0.3.1
pip3 install ray

# verl
# cd code
pip install -e .

# flash attention 2
pip3 install flash-attn --no-build-isolation

# we use pyserini for efficient retrieval and evaluation
pip install pyserini    # the version we used is 0.22.1

# quality of life
pip install wandb IPython matplotlib huggingface_hub
```
**Environnement Retriever**

```bash
conda create -n ret python=3.10
conda activate ret

conda install pytorch==2.4.0 torchvision==0.19.0 torchaudio==2.4.0 pytorch-cuda=12.1 -c pytorch -c nvidia
pip install transformers datasets pyserini
conda install -c pytorch -c nvidia faiss-gpu=1.8.0
pip install uvicorn fastapi
```
## ğŸ’¡ PrÃ©paration
***TÃ©lÃ©charger lâ€™Index & le Corpus***



```bash
python scripts/download.py --save_path $save_path
cat $save_path/part_* > $save_path/e5_Flat.index
gzip -d $save_path/wiki-18.jsonl.gz
```

***PrÃ©-calculer l'initialisation RAG naÃ¯ve*** (ou vous pouvez tÃ©lÃ©charger nos donnÃ©es traitÃ©es ici : [huggingface](https://huggingface.co/datasets/pat-jj/s3_processed_data))

```bash
# deploy retriever
bash scripts/deploy_retriever/retrieval_launch.sh # or scripts/deploy_retriever/retrieval_launch_mirage.sh for MedCorp corpus.
# deploy generator
bash generator_llms/host.sh # modify tensor-parallel-size to the number of GPUs you use
# run precompute
bash scripts/precompute.sh # this step will take a while, as it will precompute the naÃ¯ve RAG Cache for training
```
## ğŸ‹ï¸ ExÃ©cuter l'entraÃ®nement
***Cette Ã©tape concerne l'entraÃ®nement de S3***



```bash
# deploy retriever
bash scripts/deploy_retriever/retrieval_launch.sh 
# deploy generator
bash generator_llms/host.sh
# run training
bash scripts/train/train_s3.sh
```
## ğŸ” ExÃ©cuter la recherche/rÃ©cupÃ©ration
***Cette Ã©tape concerne la collecte de contexte de s3 / bases de rÃ©fÃ©rence***

**s3**


```bash
# deploy retriever
bash scripts/deploy_retriever/retrieval_launch.sh 
# run s3 inference
bash scripts/s3_inference/evaluate-8-3-3.sh
```
<details>
<summary>RÃ©fÃ©rences de base</summary>

**RAG**

```bash
bash scripts/deploy_retriever/retrieval_launch.sh # or retrieval_launch_bm25.sh # deploy retriever
bash scripts/baselines/rag.sh # run RAG 
```
**DeepRetrieval**
**DeepRetrieval**
```bash
bash retrieval_launch_bm25.sh # deploy BM25 Model
bash generator_llms/deepretrieval.sh # deploy DeepRetrieval Model
bash scripts/baselines/deepretrieval.sh # run DeepRetrieval Query Rewriting + Retrieval
```
**Recherche-R1**

```bash
bash retrieval_launch.sh # deploy e5 retriever
bash scripts/baselines/search_r1.sh # run Search-R1
```
**IRCoT**

```bash
bash retrieval_launch.sh # deploy e5 retriever
python scripts/baselines/ircot.py
```
**Recherche-o1**

```bash
bash retrieval_launch.sh # deploy e5 retriever
bash scripts/baselines/search_o1.sh # run Search-o1
```
</details>


## ğŸ“ˆ ExÃ©cuter l'Ã©valuation
***Cette Ã©tape concerne l'Ã©valuation de s3 / des lignes de base***



```bash
bash scripts/evaluation/run.sh
```

## Q&R
### DonnÃ©es personnalisÃ©es ?
Si vous souhaitez tester s3 sur votre propre corpus/ensemble de donnÃ©es, vous pouvez consulter ce commit pour voir ce quâ€™il faut faire afin de construire votre propre pipeline : [commit 8420538](https://github.com/pat-jj/s3/commit/8420538836febbe59d5bcbe41187f16908c9c36c)

### Reproduire les rÃ©sultats ?
Plusieurs dÃ©veloppeurs ont dÃ©jÃ  rÃ©ussi Ã  reproduire nos rÃ©sultats. Si vous avez des questions ou rencontrez des problÃ¨mes, nâ€™hÃ©sitez pas Ã  [ouvrir une issue](https://github.com/pat-jj/s3/issues) â€” nous serons heureux de vous guider directement (voir [cet exemple](https://github.com/pat-jj/s3/issues/20)).

Bien que reproduire le modÃ¨le vous-mÃªme soit simple â€” et nous **recommandons en fait de lâ€™entraÃ®ner depuis zÃ©ro**, car lâ€™Ã©valuation est souvent beaucoup plus chronophage que lâ€™entraÃ®nement â€” nous fournissons Ã©galement un checkpoint de rÃ©fÃ©rence : [s3-8-3-3-20steps](https://huggingface.co/pat-jj/s3-8-3-3-20steps), entraÃ®nÃ© en environ une heure.



## Remerciements
Nous tenons Ã  remercier les projets suivants :
[verl](https://github.com/volcengine/verl), [RAGEN](https://github.com/RAGEN-AI/RAGEN), [Search-R1](https://github.com/PeterGriffinJin/Search-R1), [DeepRetrieval](https://github.com/pat-jj/DeepRetrieval), [PySerini](https://github.com/castorini/pySerini).
 

## Citation
```bibtex
@article{jiang2025s3,
  title={s3: You Don't Need That Much Data to Train a Search Agent via RL},
  author={Jiang, Pengcheng and Xu, Xueqiang and Lin, Jiacheng and Xiao, Jinfeng and Wang, Zifeng and Sun, Jimeng and Han, Jiawei},
  journal={arXiv preprint arXiv:2505.14146},
  year={2025}
}
```
Merci de l'intÃ©rÃªt que vous portez Ã  notre travail !






---

Tranlated By [Open Ai Tx](https://github.com/OpenAiTx/OpenAiTx) | Last indexed: 2025-10-06

---