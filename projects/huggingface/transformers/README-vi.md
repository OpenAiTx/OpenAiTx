<!---
B·∫£n quy·ªÅn 2020 Nh√≥m HuggingFace. ƒê√£ ƒëƒÉng k√Ω m·ªçi quy·ªÅn.

ƒê∆∞·ª£c c·∫•p ph√©p theo Gi·∫•y ph√©p Apache, Phi√™n b·∫£n 2.0 ("Gi·∫•y ph√©p");
b·∫°n kh√¥ng ƒë∆∞·ª£c s·ª≠ d·ª•ng t·ªáp n√†y ngo·∫°i tr·ª´ tu√¢n th·ªß Gi·∫•y ph√©p.
B·∫°n c√≥ th·ªÉ l·∫•y m·ªôt b·∫£n sao c·ªßa Gi·∫•y ph√©p t·∫°i

    http://www.apache.org/licenses/LICENSE-2.0

Tr·ª´ khi lu·∫≠t ph√°p y√™u c·∫ßu ho·∫∑c ƒë∆∞·ª£c ƒë·ªìng √Ω b·∫±ng vƒÉn b·∫£n, ph·∫ßn m·ªÅm
ph√¢n ph·ªëi theo Gi·∫•y ph√©p n√†y ƒë∆∞·ª£c ph√¢n ph·ªëi "NGUY√äN TR·∫†NG",
KH√îNG C√ì B·∫§T K·ª≤ B·∫¢O ƒê·∫¢M N√ÄO, c·∫£ r√µ r√†ng l·∫´n ng·ª• √Ω.
Xem Gi·∫•y ph√©p ƒë·ªÉ bi·∫øt c√°c quy ƒë·ªãnh v·ªÅ quy·ªÅn h·∫°n v√†
gi·ªõi h·∫°n theo Gi·∫•y ph√©p.
-->

<p align="center">
  <picture>
    <source media="(prefers-color-scheme: dark)" srcset="https://huggingface.co/datasets/huggingface/documentation-images/raw/main/transformers-logo-dark.svg">
    <source media="(prefers-color-scheme: light)" srcset="https://huggingface.co/datasets/huggingface/documentation-images/raw/main/transformers-logo-light.svg">
    <img alt="Th∆∞ vi·ªán Hugging Face Transformers" src="https://huggingface.co/datasets/huggingface/documentation-images/raw/main/transformers-logo-light.svg" width="352" height="59" style="max-width: 100%;">
  </picture>
  <br/>
  <br/>
</p>

<p align="center">
    <a href="https://huggingface.com/models"><img alt="Checkpoints tr√™n Hub" src="https://img.shields.io/endpoint?url=https://huggingface.co/api/shields/models&color=brightgreen"></a>
    <a href="https://circleci.com/gh/huggingface/transformers"><img alt="Build" src="https://img.shields.io/circleci/build/github/huggingface/transformers/main"></a>
    <a href="https://github.com/huggingface/transformers/blob/main/LICENSE"><img alt="GitHub" src="https://img.shields.io/github/license/huggingface/transformers.svg?color=blue"></a>
    <a href="https://huggingface.co/docs/transformers/index"><img alt="T√†i li·ªáu" src="https://img.shields.io/website/http/huggingface.co/docs/transformers/index.svg?down_color=red&down_message=offline&up_message=online"></a>
    <a href="https://github.com/huggingface/transformers/releases"><img alt="Ph√°t h√†nh tr√™n GitHub" src="https://img.shields.io/github/release/huggingface/transformers.svg"></a>
    <a href="https://github.com/huggingface/transformers/blob/main/CODE_OF_CONDUCT.md"><img alt="Contributor Covenant" src="https://img.shields.io/badge/Contributor%20Covenant-v2.0%20adopted-ff69b4.svg"></a>
    <a href="https://zenodo.org/badge/latestdoi/155220641"><img src="https://zenodo.org/badge/155220641.svg" alt="DOI"></a>
</p>

<h4 align="center">
    <p>
        <b>English</b> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_zh-hans.md">ÁÆÄ‰Ωì‰∏≠Êñá</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_zh-hant.md">ÁπÅÈ´î‰∏≠Êñá</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ko.md">ÌïúÍµ≠Ïñ¥</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_es.md">Espa√±ol</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ja.md">Êó•Êú¨Ë™û</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_hd.md">‡§π‡§ø‡§®‡•ç‡§¶‡•Ä</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ru.md">–†—É—Å—Å–∫–∏–π</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_pt-br.md">–†ortugu√™s</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_te.md">‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_fr.md">Fran√ßais</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_de.md">Deutsch</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_vi.md">Ti·∫øng Vi·ªát</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ar.md">ÿßŸÑÿπÿ±ÿ®Ÿäÿ©</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ur.md">ÿßÿ±ÿØŸà</a> |
    </p>
</h4>

<h3 align="center">
    <p>M√¥ h√¨nh pretrained ti√™n ti·∫øn nh·∫•t cho suy lu·∫≠n v√† hu·∫•n luy·ªán</p>
</h3>

<h3 align="center">
    <a href="https://hf.co/course"><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/course_banner.png"></a>
</h3>

Transformers l√† m·ªôt th∆∞ vi·ªán c√°c m√¥ h√¨nh vƒÉn b·∫£n, th·ªã gi√°c m√°y t√≠nh, √¢m thanh, video v√† ƒëa ph∆∞∆°ng th·ª©c ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán s·∫µn cho m·ª•c ƒë√≠ch suy lu·∫≠n v√† hu·∫•n luy·ªán. S·ª≠ d·ª•ng Transformers ƒë·ªÉ tinh ch·ªânh m√¥ h√¨nh tr√™n d·ªØ li·ªáu c·ªßa b·∫°n, x√¢y d·ª±ng c√°c ·ª©ng d·ª•ng suy lu·∫≠n v√† cho c√°c tr∆∞·ªùng h·ª£p s·ª≠ d·ª•ng AI t·∫°o sinh tr√™n nhi·ªÅu ph∆∞∆°ng th·ª©c kh√°c nhau.

C√≥ h∆°n 500.000+ [checkpoint m√¥ h√¨nh](https://huggingface.co/models?library=transformers&sort=trending) Transformers tr√™n [Hugging Face Hub](https://huggingface.com/models) m√† b·∫°n c√≥ th·ªÉ s·ª≠ d·ª•ng.

Kh√°m ph√° [Hub](https://huggingface.com/) ngay h√¥m nay ƒë·ªÉ t√¨m m·ªôt m√¥ h√¨nh v√† s·ª≠ d·ª•ng Transformers ƒë·ªÉ b·∫Øt ƒë·∫ßu ngay l·∫≠p t·ª©c.

## C√†i ƒë·∫∑t

Transformers l√†m vi·ªác v·ªõi Python 3.9+ [PyTorch](https://pytorch.org/get-started/locally/) 2.1+, [TensorFlow](https://www.tensorflow.org/install/pip) 2.6+, v√† [Flax](https://flax.readthedocs.io/en/latest/) 0.4.1+.

T·∫°o v√† k√≠ch ho·∫°t m·ªôt m√¥i tr∆∞·ªùng ·∫£o v·ªõi [venv](https://docs.python.org/3/library/venv.html) ho·∫∑c [uv](https://docs.astral.sh/uv/), m·ªôt tr√¨nh qu·∫£n l√Ω g√≥i v√† d·ª± √°n Python nhanh d·ª±a tr√™n Rust.

```py
# venv
python -m venv .my-env
source .my-env/bin/activate
# uv
uv venv .my-env
source .my-env/bin/activate
```

C√†i ƒë·∫∑t Transformers trong m√¥i tr∆∞·ªùng ·∫£o c·ªßa b·∫°n.

```py
# pip
pip install "transformers[torch]"

# uv
uv pip install "transformers[torch]"
```

C√†i ƒë·∫∑t Transformers t·ª´ m√£ ngu·ªìn n·∫øu b·∫°n mu·ªën c·∫≠p nh·∫≠t nh·ªØng thay ƒë·ªïi m·ªõi nh·∫•t c·ªßa th∆∞ vi·ªán ho·∫∑c c√≥ √Ω ƒë·ªãnh ƒë√≥ng g√≥p ph√°t tri·ªÉn. Tuy nhi√™n, phi√™n b·∫£n *m·ªõi nh·∫•t* c√≥ th·ªÉ kh√¥ng ·ªïn ƒë·ªãnh. H√£y m·ªü [issue](https://github.com/huggingface/transformers/issues) n·∫øu b·∫°n g·∫∑p l·ªói.

```shell
git clone https://github.com/huggingface/transformers.git
cd transformers

# pip
pip install .[torch]

# uv
uv pip install .[torch]
```

## Kh·ªüi ƒë·ªông nhanh

B·∫Øt ƒë·∫ßu v·ªõi Transformers ngay l·∫≠p t·ª©c v·ªõi API [Pipeline](https://huggingface.co/docs/transformers/pipeline_tutorial). `Pipeline` l√† m·ªôt l·ªõp suy lu·∫≠n c·∫•p cao h·ªó tr·ª£ c√°c t√°c v·ª• vƒÉn b·∫£n, √¢m thanh, th·ªã gi√°c v√† ƒëa ph∆∞∆°ng th·ª©c. N√≥ x·ª≠ l√Ω ti·ªÅn x·ª≠ l√Ω ƒë·∫ßu v√†o v√† tr·∫£ v·ªÅ ƒë·∫ßu ra ph√π h·ª£p.

Kh·ªüi t·∫°o m·ªôt pipeline v√† ch·ªâ ƒë·ªãnh m√¥ h√¨nh s·ª≠ d·ª•ng cho sinh vƒÉn b·∫£n. M√¥ h√¨nh s·∫Ω ƒë∆∞·ª£c t·∫£i v·ªÅ v√† l∆∞u v√†o b·ªô nh·ªõ ƒë·ªám ƒë·ªÉ c√≥ th·ªÉ s·ª≠ d·ª•ng l·∫°i d·ªÖ d√†ng. Cu·ªëi c√πng, truy·ªÅn v√†o m·ªôt ƒëo·∫°n vƒÉn b·∫£n ƒë·ªÉ m√¥ h√¨nh sinh k·∫øt qu·∫£.

```py
from transformers import pipeline

pipeline = pipeline(task="text-generation", model="Qwen/Qwen2.5-1.5B")
pipeline("the secret to baking a really good cake is ")
[{'generated_text': 'the secret to baking a really good cake is 1) to use the right ingredients and 2) to follow the recipe exactly. the recipe for the cake is as follows: 1 cup of sugar, 1 cup of flour, 1 cup of milk, 1 cup of butter, 1 cup of eggs, 1 cup of chocolate chips. if you want to make 2 cakes, how much sugar do you need? To make 2 cakes, you will need 2 cups of sugar.'}]
```

ƒê·ªÉ tr√≤ chuy·ªán v·ªõi m·ªôt m√¥ h√¨nh, c√°ch s·ª≠ d·ª•ng c≈©ng t∆∞∆°ng t·ª±. S·ª± kh√°c bi·ªát duy nh·∫•t l√† b·∫°n c·∫ßn x√¢y d·ª±ng l·ªãch s·ª≠ h·ªôi tho·∫°i (ƒë·∫ßu v√†o cho `Pipeline`) gi·ªØa b·∫°n v√† h·ªá th·ªëng.

> [!TIP]
> B·∫°n c≈©ng c√≥ th·ªÉ tr√≤ chuy·ªán v·ªõi m√¥ h√¨nh tr·ª±c ti·∫øp t·ª´ d√≤ng l·ªánh.
> ```shell
> transformers chat Qwen/Qwen2.5-0.5B-Instruct
> ```

```py
import torch
from transformers import pipeline

chat = [
    {"role": "system", "content": "B·∫°n l√† m·ªôt robot h√†i h∆∞·ªõc, tr·∫£ treo nh∆∞ t∆∞·ªüng t∆∞·ª£ng c·ªßa Hollywood nƒÉm 1986."},
    {"role": "user", "content": "N√†y, b·∫°n c√≥ th·ªÉ g·ª£i √Ω v√†i ƒëi·ªÅu th√∫ v·ªã ƒë·ªÉ l√†m ·ªü New York kh√¥ng?"}
]

pipeline = pipeline(task="text-generation", model="meta-llama/Meta-Llama-3-8B-Instruct", torch_dtype=torch.bfloat16, device_map="auto")
response = pipeline(chat, max_new_tokens=512)
print(response[0]["generated_text"][-1]["content"])
```

M·ªü r·ªông c√°c v√≠ d·ª• b√™n d∆∞·ªõi ƒë·ªÉ xem `Pipeline` ho·∫°t ƒë·ªông v·ªõi c√°c ph∆∞∆°ng th·ª©c v√† t√°c v·ª• kh√°c nhau nh∆∞ th·∫ø n√†o.

<details>
<summary>Nh·∫≠n di·ªán gi·ªçng n√≥i t·ª± ƒë·ªông</summary>

```py
from transformers import pipeline

pipeline = pipeline(task="automatic-speech-recognition", model="openai/whisper-large-v3")
pipeline("https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac")
{'text': ' I have a dream that one day this nation will rise up and live out the true meaning of its creed.'}
```

</details>

<details>
<summary>Ph√¢n lo·∫°i h√¨nh ·∫£nh</summary>

<h3 align="center">
    <a><img src="https://huggingface.co/datasets/Narsil/image_dummy/raw/main/parrots.png"></a>
</h3>

```py
from transformers import pipeline

pipeline = pipeline(task="image-classification", model="facebook/dinov2-small-imagenet1k-1-layer")
pipeline("https://huggingface.co/datasets/Narsil/image_dummy/raw/main/parrots.png")
[{'label': 'macaw', 'score': 0.997848391532898},
 {'label': 'sulphur-crested cockatoo, Kakatoe galerita, Cacatua galerita',
  'score': 0.0016551691805943847},
 {'label': 'lorikeet', 'score': 0.00018523589824326336},
 {'label': 'African grey, African gray, Psittacus erithacus',
  'score': 7.85409429227002e-05},
 {'label': 'quail', 'score': 5.502637941390276e-05}]
```

</details>

<details>
<summary>H·ªèi ƒë√°p h√¨nh ·∫£nh</summary>


<h3 align="center">
    <a><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/idefics-few-shot.jpg"></a>
</h3>

```py
from transformers import pipeline

pipeline = pipeline(task="visual-question-answering", model="Salesforce/blip-vqa-base")
pipeline(
    image="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/idefics-few-shot.jpg",
    question="What is in the image?",
)
[{'answer': 'statue of liberty'}]
```

</details>

## T·∫°i sao n√™n s·ª≠ d·ª•ng Transformers?

1. M√¥ h√¨nh ti√™n ti·∫øn d·ªÖ s·ª≠ d·ª•ng:
    - Hi·ªáu nƒÉng cao ƒë·ªëi v·ªõi c√°c t√°c v·ª• hi·ªÉu & sinh ng√¥n ng·ªØ t·ª± nhi√™n, th·ªã gi√°c m√°y t√≠nh, √¢m thanh, video v√† ƒëa ph∆∞∆°ng th·ª©c.
    - Gi·∫£m r√†o c·∫£n cho c√°c nh√† nghi√™n c·ª©u, k·ªπ s∆∞ v√† l·∫≠p tr√¨nh vi√™n.
    - Ch·ªâ c·∫ßn h·ªçc ba l·ªõp tr·ª´u t∆∞·ª£ng h∆∞·ªõng ng∆∞·ªùi d√πng.
    - API th·ªëng nh·∫•t cho t·∫•t c·∫£ c√°c m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán s·∫µn.

1. Gi·∫£m chi ph√≠ t√≠nh to√°n, gi·∫£m d·∫•u ch√¢n carbon:
    - Chia s·∫ª m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán thay v√¨ hu·∫•n luy·ªán l·∫°i t·ª´ ƒë·∫ßu.
    - Gi·∫£m th·ªùi gian t√≠nh to√°n v√† chi ph√≠ s·∫£n xu·∫•t.
    - H√†ng ch·ª•c ki·∫øn tr√∫c m√¥ h√¨nh v·ªõi h∆°n 1 tri·ªáu checkpoint pretrained tr√™n m·ªçi ph∆∞∆°ng th·ª©c.

1. T·ª± do ch·ªçn framework ph√π h·ª£p cho m·ªçi giai ƒëo·∫°n v√≤ng ƒë·ªùi m√¥ h√¨nh:
    - Hu·∫•n luy·ªán m√¥ h√¨nh ti√™n ti·∫øn ch·ªâ v·ªõi 3 d√≤ng l·ªánh.
    - D·ªÖ d√†ng chuy·ªÉn m√¥ h√¨nh gi·ªØa PyTorch/JAX/TF2.0.
    - Ch·ªçn framework ph√π h·ª£p cho hu·∫•n luy·ªán, ƒë√°nh gi√° v√† s·∫£n xu·∫•t.

1. D·ªÖ d√†ng t√πy ch·ªânh m√¥ h√¨nh ho·∫∑c v√≠ d·ª• cho nhu c·∫ßu c·ªßa b·∫°n:
    - Cung c·∫•p v√≠ d·ª• cho t·ª´ng ki·∫øn tr√∫c ƒë·ªÉ t√°i t·∫°o k·∫øt qu·∫£ ƒë√£ c√¥ng b·ªë.
    - L√µi m√¥ h√¨nh ƒë∆∞·ª£c l·ªô ra m·ªôt c√°ch nh·∫•t qu√°n.
    - File m√¥ h√¨nh c√≥ th·ªÉ d√πng ƒë·ªôc l·∫≠p v·ªõi th∆∞ vi·ªán ƒë·ªÉ th·ª≠ nghi·ªám nhanh.

<a target="_blank" href="https://huggingface.co/enterprise">
    <img alt="Hugging Face Enterprise Hub" src="https://github.com/user-attachments/assets/247fb16d-d251-4583-96c4-d3d76dda4925">
</a><br>

## Khi n√†o KH√îNG n√™n s·ª≠ d·ª•ng Transformers?

- Th∆∞ vi·ªán n√†y kh√¥ng ph·∫£i l√† m·ªôt b·ªô c√¥ng c·ª• m√¥-ƒëun c√°c kh·ªëi x√¢y d·ª±ng m·∫°ng n∆°-ron. M√£ ngu·ªìn trong file m√¥ h√¨nh kh√¥ng ƒë∆∞·ª£c t√°i c·∫•u tr√∫c v·ªõi c√°c tr·ª´u t∆∞·ª£ng b·ªï sung, nh·∫±m gi√∫p c√°c nh√† nghi√™n c·ª©u c√≥ th·ªÉ th·ª≠ nghi·ªám nhanh tr√™n t·ª´ng m√¥ h√¨nh m√† kh√¥ng c·∫ßn ƒëi s√¢u v√†o nhi·ªÅu l·ªõp tr·ª´u t∆∞·ª£ng/file kh√°c.
- API hu·∫•n luy·ªán ƒë∆∞·ª£c t·ªëi ∆∞u ƒë·ªÉ l√†m vi·ªác v·ªõi m√¥ h√¨nh PyTorch m√† Transformers cung c·∫•p. N·∫øu c·∫ßn v√≤ng l·∫∑p m√°y h·ªçc t·ªïng qu√°t, b·∫°n n√™n d√πng th∆∞ vi·ªán kh√°c nh∆∞ [Accelerate](https://huggingface.co/docs/accelerate).
- [C√°c script v√≠ d·ª•](https://github.com/huggingface/transformers/tree/main/examples) ch·ªâ l√† *v√≠ d·ª•*. Ch√∫ng c√≥ th·ªÉ kh√¥ng ho·∫°t ƒë·ªông ngay v·ªõi tr∆∞·ªùng h·ª£p s·ª≠ d·ª•ng c·ªßa b·∫°n v√† b·∫°n c·∫ßn ƒëi·ªÅu ch·ªânh l·∫°i m√£ ngu·ªìn.

## 100 d·ª± √°n s·ª≠ d·ª•ng Transformers

Transformers kh√¥ng ch·ªâ l√† m·ªôt b·ªô c√¥ng c·ª• s·ª≠ d·ª•ng m√¥ h√¨nh pretrained, m√† c√≤n l√† m·ªôt c·ªông ƒë·ªìng c√°c d·ª± √°n x√¢y d·ª±ng xung quanh n√≥ v√†
Hugging Face Hub. Ch√∫ng t√¥i mu·ªën Transformers gi√∫p c√°c l·∫≠p tr√¨nh vi√™n, nh√† nghi√™n c·ª©u, sinh vi√™n, gi·∫£ng vi√™n, k·ªπ s∆∞, v√† b·∫•t k·ª≥ ai kh√°c x√¢y d·ª±ng d·ª± √°n m∆° ∆∞·ªõc c·ªßa h·ªç.

ƒê·ªÉ k·ª∑ ni·ªám Transformers ƒë·∫°t 100.000 stars, ch√∫ng t√¥i mu·ªën t√¥n vinh c·ªông ƒë·ªìng v·ªõi trang [awesome-transformers](./awesome-transformers.md) li·ªát k√™ 100 d·ª± √°n tuy·ªát v·ªùi x√¢y d·ª±ng b·∫±ng Transformers.

N·∫øu b·∫°n s·ªü h·ªØu ho·∫∑c s·ª≠ d·ª•ng m·ªôt d·ª± √°n x·ª©ng ƒë√°ng n·∫±m trong danh s√°ch n√†y, h√£y m·ªü PR ƒë·ªÉ b·ªï sung nh√©!

## M·ªôt s·ªë m√¥ h√¨nh v√≠ d·ª•

B·∫°n c√≥ th·ªÉ th·ª≠ h·∫ßu h·∫øt c√°c m√¥ h√¨nh tr·ª±c ti·∫øp tr√™n [trang m√¥ h√¨nh tr√™n Hub](https://huggingface.co/models).

M·ªü r·ªông t·ª´ng ph∆∞∆°ng th·ª©c b√™n d∆∞·ªõi ƒë·ªÉ xem m·ªôt s·ªë m√¥ h√¨nh v√≠ d·ª• cho c√°c tr∆∞·ªùng h·ª£p s·ª≠ d·ª•ng kh√°c nhau.

<details>
<summary>√Çm thanh</summary>

- Ph√¢n lo·∫°i √¢m thanh v·ªõi [Whisper](https://huggingface.co/openai/whisper-large-v3-turbo)
- Nh·∫≠n di·ªán gi·ªçng n√≥i t·ª± ƒë·ªông v·ªõi [Moonshine](https://huggingface.co/UsefulSensors/moonshine)
- Ph√°t hi·ªán t·ª´ kh√≥a v·ªõi [Wav2Vec2](https://huggingface.co/superb/wav2vec2-base-superb-ks)
- Chuy·ªÉn ƒë·ªïi l·ªùi n√≥i sang l·ªùi n√≥i v·ªõi [Moshi](https://huggingface.co/kyutai/moshiko-pytorch-bf16)
- VƒÉn b·∫£n sang √¢m thanh v·ªõi [MusicGen](https://huggingface.co/facebook/musicgen-large)
- VƒÉn b·∫£n sang gi·ªçng n√≥i v·ªõi [Bark](https://huggingface.co/suno/bark)

</details>

<details>
<summary>Th·ªã gi√°c m√°y t√≠nh</summary>

- Sinh m·∫∑t n·∫° t·ª± ƒë·ªông v·ªõi [SAM](https://huggingface.co/facebook/sam-vit-base)
- ∆Ø·ªõc l∆∞·ª£ng ƒë·ªô s√¢u v·ªõi [DepthPro](https://huggingface.co/apple/DepthPro-hf)
- Ph√¢n lo·∫°i h√¨nh ·∫£nh v·ªõi [DINO v2](https://huggingface.co/facebook/dinov2-base)
- Ph√°t hi·ªán keypoint v·ªõi [SuperGlue](https://huggingface.co/magic-leap-community/superglue_outdoor)
- Gh√©p keypoint v·ªõi [SuperGlue](https://huggingface.co/magic-leap-community/superglue)
- Ph√°t hi·ªán v·∫≠t th·ªÉ v·ªõi [RT-DETRv2](https://huggingface.co/PekingU/rtdetr_v2_r50vd)
- ∆Ø·ªõc l∆∞·ª£ng t∆∞ th·∫ø v·ªõi [VitPose](https://huggingface.co/usyd-community/vitpose-base-simple)
- Ph√¢n ƒëo·∫°n ƒëa nƒÉng v·ªõi [OneFormer](https://huggingface.co/shi-labs/oneformer_ade20k_swin_large)
- Ph√¢n lo·∫°i video v·ªõi [VideoMAE](https://huggingface.co/MCG-NJU/videomae-large)

</details>

<details>
<summary>ƒêa ph∆∞∆°ng th·ª©c</summary>

- √Çm thanh ho·∫∑c vƒÉn b·∫£n sang vƒÉn b·∫£n v·ªõi [Qwen2-Audio](https://huggingface.co/Qwen/Qwen2-Audio-7B)
- H·ªèi ƒë√°p t√†i li·ªáu v·ªõi [LayoutLMv3](https://huggingface.co/microsoft/layoutlmv3-base)
- H√¨nh ·∫£nh ho·∫∑c vƒÉn b·∫£n sang vƒÉn b·∫£n v·ªõi [Qwen-VL](https://huggingface.co/Qwen/Qwen2.5-VL-3B-Instruct)
- Sinh ch√∫ th√≠ch h√¨nh ·∫£nh v·ªõi [BLIP-2](https://huggingface.co/Salesforce/blip2-opt-2.7b)
- Hi·ªÉu t√†i li·ªáu d·ª±a tr√™n OCR v·ªõi [GOT-OCR2](https://huggingface.co/stepfun-ai/GOT-OCR-2.0-hf)
- H·ªèi ƒë√°p b·∫£ng v·ªõi [TAPAS](https://huggingface.co/google/tapas-base)
- Hi·ªÉu v√† sinh ƒëa ph∆∞∆°ng th·ª©c th·ªëng nh·∫•t v·ªõi [Emu3](https://huggingface.co/BAAI/Emu3-Gen)
- Th·ªã gi√°c sang vƒÉn b·∫£n v·ªõi [Llava-OneVision](https://huggingface.co/llava-hf/llava-onevision-qwen2-0.5b-ov-hf)
- H·ªèi ƒë√°p h√¨nh ·∫£nh v·ªõi [Llava](https://huggingface.co/llava-hf/llava-1.5-7b-hf)
- Ph√¢n ƒëo·∫°n bi·ªÉu th·ª©c tham chi·∫øu h√¨nh ·∫£nh v·ªõi [Kosmos-2](https://huggingface.co/microsoft/kosmos-2-patch14-224)

</details>

<details>
<summary>X·ª≠ l√Ω ng√¥n ng·ªØ t·ª± nhi√™n (NLP)</summary>

- ƒêi·ªÅn t·ª´ thi·∫øu v·ªõi [ModernBERT](https://huggingface.co/answerdotai/ModernBERT-base)
- Nh·∫≠n di·ªán th·ª±c th·ªÉ c√≥ t√™n v·ªõi [Gemma](https://huggingface.co/google/gemma-2-2b)
- H·ªèi ƒë√°p v·ªõi [Mixtral](https://huggingface.co/mistralai/Mixtral-8x7B-v0.1)
- T√≥m t·∫Øt v·ªõi [BART](https://huggingface.co/facebook/bart-large-cnn)
- D·ªãch v·ªõi [T5](https://huggingface.co/google-t5/t5-base)
- Sinh vƒÉn b·∫£n v·ªõi [Llama](https://huggingface.co/meta-llama/Llama-3.2-1B)
- Ph√¢n lo·∫°i vƒÉn b·∫£n v·ªõi [Qwen](https://huggingface.co/Qwen/Qwen2.5-0.5B)

</details>

## Tr√≠ch d·∫´n

Ch√∫ng t√¥i hi·ªán ƒë√£ c√≥ [b√†i b√°o](https://www.aclweb.org/anthology/2020.emnlp-demos.6/) b·∫°n c√≥ th·ªÉ tr√≠ch d·∫´n cho th∆∞ vi·ªán ü§ó Transformers:
```bibtex
@inproceedings{wolf-etal-2020-transformers,
    title = "Transformers: State-of-the-Art Natural Language Processing",
    author = "Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and R√©mi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
    month = oct,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.emnlp-demos.6",
    pages = "38--45"
}
```

---

[Powered By OpenAiTx](https://github.com/OpenAiTx/OpenAiTx)

---