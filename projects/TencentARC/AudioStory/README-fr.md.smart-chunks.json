[
  {
    "Id": 1,
    "Content": "# AudioStory: Generating Long-Form Narrative Audio with Large Language Models\n\n**[Yuxin Guo<sup>1,2</sup>](https://scholar.google.com/citations?user=x_0spxgAAAAJ&hl=en), \n[Teng Wang<sup>2,&#9993;</sup>](http://ttengwang.com/), \n[Yuying Ge<sup>2</sup>](https://geyuying.github.io/), \n[Shijie Ma<sup>1,2</sup>](https://mashijie1028.github.io/), \n[Yixiao Ge<sup>2</sup>](https://geyixiao.com/), \n[Wei Zou<sup>1</sup>](https://people.ucas.ac.cn/~zouwei),\n[Ying Shan<sup>2</sup>](https://scholar.google.com/citations?user=4oXBp9UAAAAJ&hl=en)**\n<br>\n<sup>1</sup>Institute of Automation, CAS\n<sup>2</sup>ARC Lab, Tencent PCG\n<br>\n\n\n\n## üìñ Release\n\n[2025/8/28] üî•üî• We release the inference code!\n\n[2025/8/28] üî•üî• We release our demo videos!\n\n\n\n## üîé Introduction\n\n![audiostory](https://raw.githubusercontent.com/TencentARC/AudioStory/main/audiostory.png)\n\n‚ú® **TL; DR: We propose a model for long-form narrative audio generation built upon a unified understanding‚Äìgeneration framework, capable of handling video dubbing, audio continuation, and long-form narrative audio synthesis.**\n\nRecent advances in text-to-audio (TTA) generation excel at synthesizing short audio clips but struggle with long-form narrative audio, which requires temporal coherence and compositional reasoning. To address this gap, we propose AudioStory, a unified framework that integrates large language models (LLMs) with TTA systems to generate structured, long-form audio narratives. AudioStory possesses strong instruction-following reasoning generation capabilities. It employs LLMs to decompose complex narrative queries into temporally ordered sub-tasks with contextual cues, enabling coherent scene transitions and emotional tone consistency. AudioStory has two appealing features: \n\n1) Decoupled bridging mechanism: AudioStory disentangles LLM-diffuser collaboration into two specialized components‚Äîa bridging query for intra-event semantic alignment and a consistency query for cross-event coherence preservation.\n2) End-to-end training: By unifying instruction comprehension and audio generation within a single end-to-end framework, AudioStory eliminates the need for modular training pipelines while enhancing synergy between components. \n    Furthermore, we establish a benchmark AudioStory-10K, encompassing diverse domains such as animated soundscapes and natural sound narratives.\n\nExtensive experiments show the superiority of AudioStory on both single-audio generation and narrative audio generation, surpassing prior TTA baselines in both instruction-following ability and audio fidelity.\n\n\n",
    "ContentSha": "IRBwHNPnjtSW48yqd+7r6sEmf9DaFT127infPDaIdwc=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "# AudioStory : G√©n√©ration d'audio narratif long format avec de grands mod√®les de langage\n\n**[Yuxin Guo<sup>1,2</sup>](https://scholar.google.com/citations?user=x_0spxgAAAAJ&hl=en),  \n[Teng Wang<sup>2,&#9993;</sup>](http://ttengwang.com/),  \n[Yuying Ge<sup>2</sup>](https://geyuying.github.io/),  \n[Shijie Ma<sup>1,2</sup>](https://mashijie1028.github.io/),  \n[Yixiao Ge<sup>2</sup>](https://geyixiao.com/),  \n[Wei Zou<sup>1</sup>](https://people.ucas.ac.cn/~zouwei),  \n[Ying Shan<sup>2</sup>](https://scholar.google.com/citations?user=4oXBp9UAAAAJ&hl=en)**  \n<br>  \n<sup>1</sup>Institut d‚ÄôAutomatisation, CAS  \n<sup>2</sup>ARC Lab, Tencent PCG  \n<br>  \n\n## üìñ Publication\n\n[2025/8/28] üî•üî• Nous publions le code d‚Äôinf√©rence !\n\n[2025/8/28] üî•üî• Nous publions nos vid√©os de d√©monstration !\n\n## üîé Introduction\n\n![audiostory](https://raw.githubusercontent.com/TencentARC/AudioStory/main/audiostory.png)\n\n‚ú® **TL; DR : Nous proposons un mod√®le de g√©n√©ration audio narrative long format bas√© sur un cadre unifi√© de compr√©hension‚Äìg√©n√©ration, capable de g√©rer le doublage vid√©o, la continuation audio et la synth√®se audio narrative longue.**\n\nLes avanc√©es r√©centes dans la g√©n√©ration texte-√†-audio (TTA) excellent √† synth√©tiser de courts clips audio mais peinent avec l‚Äôaudio narratif long format, qui requiert coh√©rence temporelle et raisonnement compositionnel. Pour combler ce vide, nous proposons AudioStory, un cadre unifi√© int√©grant de grands mod√®les de langage (LLM) avec des syst√®mes TTA pour g√©n√©rer des narrations audio longues et structur√©es. AudioStory poss√®de de fortes capacit√©s de g√©n√©ration raisonn√©e suivant des instructions. Il utilise les LLM pour d√©composer des requ√™tes narratives complexes en sous-t√¢ches ordonn√©es temporellement avec des indices contextuels, permettant des transitions de sc√®nes coh√©rentes et une consistance du ton √©motionnel. AudioStory pr√©sente deux caract√©ristiques attrayantes :\n\n1) M√©canisme de liaison d√©coupl√© : AudioStory dissocie la collaboration LLM-diffuseur en deux composants sp√©cialis√©s ‚Äî une requ√™te de liaison pour l‚Äôalignement s√©mantique intra-√©v√©nement et une requ√™te de coh√©rence pour la pr√©servation de la coh√©rence inter-√©v√©nements.  \n2) Entra√Ænement de bout en bout : En unifiant la compr√©hension des instructions et la g√©n√©ration audio dans un cadre unique de bout en bout, AudioStory √©limine le besoin de pipelines d‚Äôentra√Ænement modulaires tout en renfor√ßant la synergie entre les composants.  \n    De plus, nous √©tablissons un benchmark AudioStory-10K, englobant divers domaines tels que paysages sonores anim√©s et narrations de sons naturels.\n\nDes exp√©riences approfondies d√©montrent la sup√©riorit√© d‚ÄôAudioStory tant sur la g√©n√©ration audio unique que sur la g√©n√©ration audio narrative, surpassant les baselines TTA ant√©rieures en capacit√© de suivi d‚Äôinstructions et fid√©lit√© audio.\n\n\n\n\n\n\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "FSlWJLuo6Mj/8UOqAMnfG0FeLewjwHFxahfOi9F7aXs=",
        "originContent": "# AudioStory: Generating Long-Form Narrative Audio with Large Language Models",
        "translatedContent": "# AudioStory : G√©n√©ration d'audio narratif long format avec de grands mod√®les de langage"
      },
      {
        "row": 2,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 3,
        "rowsha": "7pj5MxCr6a6JgMDyv96FwXC+eTQMNiHkELvRBSfLdCc=",
        "originContent": "**[Yuxin Guo<sup>1,2</sup>](https://scholar.google.com/citations?user=x_0spxgAAAAJ&hl=en), ",
        "translatedContent": "**[Yuxin Guo<sup>1,2</sup>](https://scholar.google.com/citations?user=x_0spxgAAAAJ&hl=en),  "
      },
      {
        "row": 4,
        "rowsha": "I8/1UUE5gpzu9Xb3Q5CB33oVLk+LUWuyHO5K3kNeDqQ=",
        "originContent": "[Teng Wang<sup>2,&#9993;</sup>](http://ttengwang.com/), ",
        "translatedContent": "[Teng Wang<sup>2,&#9993;</sup>](http://ttengwang.com/),  "
      },
      {
        "row": 5,
        "rowsha": "LLQhB41AUK9J3r1VCRpBRcEia2fI/o7MDG/fVzObYkc=",
        "originContent": "[Yuying Ge<sup>2</sup>](https://geyuying.github.io/), ",
        "translatedContent": "[Yuying Ge<sup>2</sup>](https://geyuying.github.io/),  "
      },
      {
        "row": 6,
        "rowsha": "wtaTd0Ja9Uv/7/T6mpuKkSdm/A3+fh81hpB8nQObPD8=",
        "originContent": "[Shijie Ma<sup>1,2</sup>](https://mashijie1028.github.io/), ",
        "translatedContent": "[Shijie Ma<sup>1,2</sup>](https://mashijie1028.github.io/),  "
      },
      {
        "row": 7,
        "rowsha": "wWudxOacsyCruyB5ku8i8KaYdwV5du8s5qJ+K0qfMpc=",
        "originContent": "[Yixiao Ge<sup>2</sup>](https://geyixiao.com/), ",
        "translatedContent": "[Yixiao Ge<sup>2</sup>](https://geyixiao.com/),  "
      },
      {
        "row": 8,
        "rowsha": "FPZEFhOdadaxGtx5yM4lffPGGkx7gAxM+9sAn5ARaWM=",
        "originContent": "[Wei Zou<sup>1</sup>](https://people.ucas.ac.cn/~zouwei),",
        "translatedContent": "[Wei Zou<sup>1</sup>](https://people.ucas.ac.cn/~zouwei),  "
      },
      {
        "row": 9,
        "rowsha": "/XwtaWm1xbCxCliGLcLK3zuGeMMuF+5XP1t/r0xFkoo=",
        "originContent": "[Ying Shan<sup>2</sup>](https://scholar.google.com/citations?user=4oXBp9UAAAAJ&hl=en)**",
        "translatedContent": "[Ying Shan<sup>2</sup>](https://scholar.google.com/citations?user=4oXBp9UAAAAJ&hl=en)**  "
      },
      {
        "row": 10,
        "rowsha": "Za7xrbqGcqX+eTLZ+fDcNcJDWJP2URKsrGKNLcF6C88=",
        "originContent": "<br>",
        "translatedContent": "<br>  "
      },
      {
        "row": 11,
        "rowsha": "nQpF63Jn9FCPUpA8HVx2mbqsqMxzTv8xAxeS1jMrgu4=",
        "originContent": "<sup>1</sup>Institute of Automation, CAS",
        "translatedContent": "<sup>1</sup>Institut d‚ÄôAutomatisation, CAS  "
      },
      {
        "row": 12,
        "rowsha": "N/ZhVTwOyG0vyNutSAHfKXyvVJklXWMgttqLXCizzGE=",
        "originContent": "<sup>2</sup>ARC Lab, Tencent PCG",
        "translatedContent": "<sup>2</sup>ARC Lab, Tencent PCG  "
      },
      {
        "row": 13,
        "rowsha": "Za7xrbqGcqX+eTLZ+fDcNcJDWJP2URKsrGKNLcF6C88=",
        "originContent": "<br>",
        "translatedContent": "<br>  "
      },
      {
        "row": 14,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 15,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "## üìñ Publication"
      },
      {
        "row": 16,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 17,
        "rowsha": "VAliztezgn/ssMixKQZIXx0YRgi9SKETFrH/ywehwmM=",
        "originContent": "## üìñ Release",
        "translatedContent": "[2025/8/28] üî•üî• Nous publions le code d‚Äôinf√©rence !"
      },
      {
        "row": 18,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 19,
        "rowsha": "AVq/FCM66s4bjizL3qgI01Qe8E6u8UbzxY0aDpZTzWc=",
        "originContent": "[2025/8/28] üî•üî• We release the inference code!",
        "translatedContent": "[2025/8/28] üî•üî• Nous publions nos vid√©os de d√©monstration !"
      },
      {
        "row": 20,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 21,
        "rowsha": "iRSsrbzu7Kg7wogXrPePZYadG7GnGEgRsT7KdmyG+W0=",
        "originContent": "[2025/8/28] üî•üî• We release our demo videos!",
        "translatedContent": "## üîé Introduction"
      },
      {
        "row": 22,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 23,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "![audiostory](https://raw.githubusercontent.com/TencentARC/AudioStory/main/audiostory.png)"
      },
      {
        "row": 24,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 25,
        "rowsha": "9bwc96MXV71svorL6Wnrty1lSDppDxKmeyGe4Wj5fn8=",
        "originContent": "## üîé Introduction",
        "translatedContent": "‚ú® **TL; DR : Nous proposons un mod√®le de g√©n√©ration audio narrative long format bas√© sur un cadre unifi√© de compr√©hension‚Äìg√©n√©ration, capable de g√©rer le doublage vid√©o, la continuation audio et la synth√®se audio narrative longue.**"
      },
      {
        "row": 26,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 27,
        "rowsha": "PcywANjK1M4GDEjOoHORQ/c5jRpQZKP5F6P6TiSpF9E=",
        "originContent": "![audiostory](https://raw.githubusercontent.com/TencentARC/AudioStory/main/audiostory.png)",
        "translatedContent": "Les avanc√©es r√©centes dans la g√©n√©ration texte-√†-audio (TTA) excellent √† synth√©tiser de courts clips audio mais peinent avec l‚Äôaudio narratif long format, qui requiert coh√©rence temporelle et raisonnement compositionnel. Pour combler ce vide, nous proposons AudioStory, un cadre unifi√© int√©grant de grands mod√®les de langage (LLM) avec des syst√®mes TTA pour g√©n√©rer des narrations audio longues et structur√©es. AudioStory poss√®de de fortes capacit√©s de g√©n√©ration raisonn√©e suivant des instructions. Il utilise les LLM pour d√©composer des requ√™tes narratives complexes en sous-t√¢ches ordonn√©es temporellement avec des indices contextuels, permettant des transitions de sc√®nes coh√©rentes et une consistance du ton √©motionnel. AudioStory pr√©sente deux caract√©ristiques attrayantes :"
      },
      {
        "row": 28,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 29,
        "rowsha": "q00ZP1xd2vElr43vj7gKmpvpsWsJBuCJNMCyAMyMPrc=",
        "originContent": "‚ú® **TL; DR: We propose a model for long-form narrative audio generation built upon a unified understanding‚Äìgeneration framework, capable of handling video dubbing, audio continuation, and long-form narrative audio synthesis.**",
        "translatedContent": "1) M√©canisme de liaison d√©coupl√© : AudioStory dissocie la collaboration LLM-diffuseur en deux composants sp√©cialis√©s ‚Äî une requ√™te de liaison pour l‚Äôalignement s√©mantique intra-√©v√©nement et une requ√™te de coh√©rence pour la pr√©servation de la coh√©rence inter-√©v√©nements.  "
      },
      {
        "row": 30,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "2) Entra√Ænement de bout en bout : En unifiant la compr√©hension des instructions et la g√©n√©ration audio dans un cadre unique de bout en bout, AudioStory √©limine le besoin de pipelines d‚Äôentra√Ænement modulaires tout en renfor√ßant la synergie entre les composants.  "
      },
      {
        "row": 31,
        "rowsha": "s+AOmNtiFdwIChjGJAHn8zgEw+jeBT8PKsiT83fXzDQ=",
        "originContent": "Recent advances in text-to-audio (TTA) generation excel at synthesizing short audio clips but struggle with long-form narrative audio, which requires temporal coherence and compositional reasoning. To address this gap, we propose AudioStory, a unified framework that integrates large language models (LLMs) with TTA systems to generate structured, long-form audio narratives. AudioStory possesses strong instruction-following reasoning generation capabilities. It employs LLMs to decompose complex narrative queries into temporally ordered sub-tasks with contextual cues, enabling coherent scene transitions and emotional tone consistency. AudioStory has two appealing features: ",
        "translatedContent": "    De plus, nous √©tablissons un benchmark AudioStory-10K, englobant divers domaines tels que paysages sonores anim√©s et narrations de sons naturels."
      },
      {
        "row": 32,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 33,
        "rowsha": "XZUHI5mmiyNBevVzm/OkDO8EkkoJyWVA7rBQVhqnsto=",
        "originContent": "1) Decoupled bridging mechanism: AudioStory disentangles LLM-diffuser collaboration into two specialized components‚Äîa bridging query for intra-event semantic alignment and a consistency query for cross-event coherence preservation.",
        "translatedContent": "Des exp√©riences approfondies d√©montrent la sup√©riorit√© d‚ÄôAudioStory tant sur la g√©n√©ration audio unique que sur la g√©n√©ration audio narrative, surpassant les baselines TTA ant√©rieures en capacit√© de suivi d‚Äôinstructions et fid√©lit√© audio."
      },
      {
        "row": 34,
        "rowsha": "LR7DR8cVmI/lcvgNhEyRIkxgrBu8Wf1evvjFOEDTK/M=",
        "originContent": "2) End-to-end training: By unifying instruction comprehension and audio generation within a single end-to-end framework, AudioStory eliminates the need for modular training pipelines while enhancing synergy between components. ",
        "translatedContent": ""
      },
      {
        "row": 35,
        "rowsha": "CiD/Ews3JkyHETo7ElTT6cc6NoxBUUOZ5UVkesYTWt8=",
        "originContent": "    Furthermore, we establish a benchmark AudioStory-10K, encompassing diverse domains such as animated soundscapes and natural sound narratives.",
        "translatedContent": ""
      },
      {
        "row": 36,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 37,
        "rowsha": "hLpBif+fzMIMVGvpyrRBQWNm7pP0Jlud9b+uGbB0nBA=",
        "originContent": "Extensive experiments show the superiority of AudioStory on both single-audio generation and narrative audio generation, surpassing prior TTA baselines in both instruction-following ability and audio fidelity.",
        "translatedContent": ""
      },
      {
        "row": 38,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 39,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 40,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 2,
    "Content": "## ‚≠ê Demos\n\n### 1. Video Dubbing (Tom & Jerry style)\n> Dubbing is achieved using AudioStory (trained on Tom & Jerry) with visual captions extracted from videos.\n\n<table class=\"center\">\n  <td><video src=\"https://github.com/user-attachments/assets/f06b5999-6649-44d3-af38-63fdcecd833c\"></video></td>\n  <td><video src=\"https://github.com/user-attachments/assets/17727c2a-bfea-4252-9aa8-48fc9ac33500\"></video></td>\n  <td><video src=\"https://github.com/user-attachments/assets/09589d82-62c9-47a6-838a-5a62319f35e2\"></video></td>\n  <tr>\n</table >\n\n\n### 2. Cross-domain Video Dubbing (Tom & Jerry style)\n\n<table class=\"center\">\n    <td><video src=\"https://github.com/user-attachments/assets/e62d0c09-cdf0-4e51-b550-0a2c23f8d68d\"></video></td>\n    <td><video src=\"https://github.com/user-attachments/assets/736d22ca-6636-4ef0-99f3-768e4dfb112a\"></video></td>\n    <td><video src=\"https://github.com/user-attachments/assets/f2f7c94c-7f72-4cc0-8edc-290910980b04\"></video></td>\n  <tr>\n  <td><video src=\"https://github.com/user-attachments/assets/d3e58dd4-31ae-4e32-aef1-03f1e649cb0c\"></video></td>\n  <td><video src=\"https://github.com/user-attachments/assets/4f68199f-e48a-4be7-b6dc-1acb8d377a6e\"></video></td>\n  <td><video src=\"https://github.com/user-attachments/assets/062236c3-1d26-4622-b843-cc0cd0c58053\"></video></td>\n\t<tr>\n  <td><video src=\"https://github.com/user-attachments/assets/8931f428-dd4d-430f-9927-068f2912dd36\"></video></td>\n  <td><video src=\"https://github.com/user-attachments/assets/ab7e46d5-f42c-472e-b66e-df786b658210\"></video></td>      \n  <td><video src=\"https://github.com/user-attachments/assets/9a0998ad-b5a4-42ac-bdaf-ceaf796fc586\"></video></td>\n  <tr>\n</table >\n\n\n\n### 3. Text-to-Long Audio (Natural sound)\n\n<table class=\"center\">\n  <td style=\"text-align:center;\" width=\"480\">Instruction: \"Develop a comprehensive audio that fully represents jake shimabukuro performs a complex ukulele piece in a studio, receives applause, and discusses his career in an interview. The total duration is 49.9 seconds.\"</td>\n  <td><video src=\"https://github.com/user-attachments/assets/461e8a34-4217-454e-87b3-e4285f36ec43\"></video></td>\n\t<tr>\n  <td style=\"text-align:center;\" width=\"480\">Instruction: \"Develop a comprehensive audio that fully represents a fire truck leaves the station with sirens blaring, signaling an emergency response, and drives away. The total duration is 35.1 seconds.\"</td>\n  <td><video src=\"https://github.com/user-attachments/assets/aac0243f-5d12-480e-9850-a7f6720e4f9c\"></video></td>",
    "ContentSha": "yRhZGCetsdPAFtaXJWFJd3W84q9IEM8trADc5+qPgP8=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "## ‚≠ê D√©mos\n\n### 1. Doublage vid√©o (style Tom & Jerry)\n> Le doublage est r√©alis√© √† l'aide d'AudioStory (entra√Æn√© sur Tom & Jerry) avec des sous-titres visuels extraits des vid√©os.\n\n<table class=\"center\">\n  <td><video src=\"https://github.com/user-attachments/assets/f06b5999-6649-44d3-af38-63fdcecd833c\"></video></td>\n  <td><video src=\"https://github.com/user-attachments/assets/17727c2a-bfea-4252-9aa8-48fc9ac33500\"></video></td>\n  <td><video src=\"https://github.com/user-attachments/assets/09589d82-62c9-47a6-838a-5a62319f35e2\"></video></td>\n  <tr>\n</table >\n\n\n### 2. Doublage vid√©o inter-domaines (style Tom & Jerry)\n\n<table class=\"center\">\n    <td><video src=\"https://github.com/user-attachments/assets/e62d0c09-cdf0-4e51-b550-0a2c23f8d68d\"></video></td>\n    <td><video src=\"https://github.com/user-attachments/assets/736d22ca-6636-4ef0-99f3-768e4dfb112a\"></video></td>\n    <td><video src=\"https://github.com/user-attachments/assets/f2f7c94c-7f72-4cc0-8edc-290910980b04\"></video></td>\n  <tr>\n  <td><video src=\"https://github.com/user-attachments/assets/d3e58dd4-31ae-4e32-aef1-03f1e649cb0c\"></video></td>\n  <td><video src=\"https://github.com/user-attachments/assets/4f68199f-e48a-4be7-b6dc-1acb8d377a6e\"></video></td>\n  <td><video src=\"https://github.com/user-attachments/assets/062236c3-1d26-4622-b843-cc0cd0c58053\"></video></td>\n\t<tr>\n  <td><video src=\"https://github.com/user-attachments/assets/8931f428-dd4d-430f-9927-068f2912dd36\"></video></td>\n  <td><video src=\"https://github.com/user-attachments/assets/ab7e46d5-f42c-472e-b66e-df786b658210\"></video></td>      \n  <td><video src=\"https://github.com/user-attachments/assets/9a0998ad-b5a4-42ac-bdaf-ceaf796fc586\"></video></td>\n  <tr>\n</table >\n\n\n\n### 3. Texte vers audio long (Son naturel)\n\n<table class=\"center\">\n  <td style=\"text-align:center;\" width=\"480\">Instruction : \"D√©veloppez un audio complet qui repr√©sente pleinement Jake Shimabukuro interpr√©tant un morceau complexe de ukul√©l√© en studio, re√ßoit des applaudissements, et parle de sa carri√®re lors d'une interview. La dur√©e totale est de 49,9 secondes.\"</td>\n  <td><video src=\"https://github.com/user-attachments/assets/461e8a34-4217-454e-87b3-e4285f36ec43\"></video></td>\n\t<tr>\n  <td style=\"text-align:center;\" width=\"480\">Instruction : \"D√©veloppez un audio complet qui repr√©sente pleinement un camion de pompiers quittant la caserne avec les sir√®nes hurlantes, signalant une intervention d'urgence, et s'√©loignant. La dur√©e totale est de 35,1 secondes.\"</td>\n  <td><video src=\"https://github.com/user-attachments/assets/aac0243f-5d12-480e-9850-a7f6720e4f9c\"></video></td>",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "F2o4YxK5/okZTc8xAnW0ki0KPjAob5+4+EOhbNq8W4Y=",
        "originContent": "## ‚≠ê Demos",
        "translatedContent": "## ‚≠ê D√©mos"
      },
      {
        "row": 2,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 3,
        "rowsha": "d1aRTIXZKc38vEEa0aTxU1AK2CuZu0MPPd8ANvLBksY=",
        "originContent": "### 1. Video Dubbing (Tom & Jerry style)",
        "translatedContent": "### 1. Doublage vid√©o (style Tom & Jerry)"
      },
      {
        "row": 4,
        "rowsha": "xsuruvjWyp4/2tQLFG0owyXKXwcXVZRcDmPey5E3z+w=",
        "originContent": "> Dubbing is achieved using AudioStory (trained on Tom & Jerry) with visual captions extracted from videos.",
        "translatedContent": "> Le doublage est r√©alis√© √† l'aide d'AudioStory (entra√Æn√© sur Tom & Jerry) avec des sous-titres visuels extraits des vid√©os."
      },
      {
        "row": 5,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 6,
        "rowsha": "7FG0iwt8PZSz598R2HJFKtpFGDfFezhtVCdnqadcLCQ=",
        "originContent": "<table class=\"center\">",
        "translatedContent": "<table class=\"center\">"
      },
      {
        "row": 7,
        "rowsha": "Be1u8gQovOwpLxd4PoQZgOSz0nWWDBPJ/j3FrcTMmos=",
        "originContent": "  <td><video src=\"https://github.com/user-attachments/assets/f06b5999-6649-44d3-af38-63fdcecd833c\"></video></td>",
        "translatedContent": "  <td><video src=\"https://github.com/user-attachments/assets/f06b5999-6649-44d3-af38-63fdcecd833c\"></video></td>"
      },
      {
        "row": 8,
        "rowsha": "UQ1j0QNf3cuxPGkERqHp/8a1bn3v/sG6lzui/xPdnFE=",
        "originContent": "  <td><video src=\"https://github.com/user-attachments/assets/17727c2a-bfea-4252-9aa8-48fc9ac33500\"></video></td>",
        "translatedContent": "  <td><video src=\"https://github.com/user-attachments/assets/17727c2a-bfea-4252-9aa8-48fc9ac33500\"></video></td>"
      },
      {
        "row": 9,
        "rowsha": "bY1aa91+o6Lj8GiuHFVga5VyhYxYNu5seIoXPIQgfDQ=",
        "originContent": "  <td><video src=\"https://github.com/user-attachments/assets/09589d82-62c9-47a6-838a-5a62319f35e2\"></video></td>",
        "translatedContent": "  <td><video src=\"https://github.com/user-attachments/assets/09589d82-62c9-47a6-838a-5a62319f35e2\"></video></td>"
      },
      {
        "row": 10,
        "rowsha": "6o+qeLcGxX0dvrGBva8HKZWaO7Np0FI8WMiMEuNtFfo=",
        "originContent": "  <tr>",
        "translatedContent": "  <tr>"
      },
      {
        "row": 11,
        "rowsha": "+hgoFVIJCNdOMAGtb2zTTnLrSdPnvT/pIoTy2M2EOaI=",
        "originContent": "</table >",
        "translatedContent": "</table >"
      },
      {
        "row": 12,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 13,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 14,
        "rowsha": "XiXvIW8MSuKVMG/Ubq2sxIrsI04P8LAAWR1F9+rcL8w=",
        "originContent": "### 2. Cross-domain Video Dubbing (Tom & Jerry style)",
        "translatedContent": "### 2. Doublage vid√©o inter-domaines (style Tom & Jerry)"
      },
      {
        "row": 15,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 16,
        "rowsha": "7FG0iwt8PZSz598R2HJFKtpFGDfFezhtVCdnqadcLCQ=",
        "originContent": "<table class=\"center\">",
        "translatedContent": "<table class=\"center\">"
      },
      {
        "row": 17,
        "rowsha": "rC3Gg9ZB9dkeQADRH8X0y7BJ9NRFWRPUKfXUq4jK5A8=",
        "originContent": "    <td><video src=\"https://github.com/user-attachments/assets/e62d0c09-cdf0-4e51-b550-0a2c23f8d68d\"></video></td>",
        "translatedContent": "    <td><video src=\"https://github.com/user-attachments/assets/e62d0c09-cdf0-4e51-b550-0a2c23f8d68d\"></video></td>"
      },
      {
        "row": 18,
        "rowsha": "q7k6xpgdTW2XaA00mXwPguhjbz62JBzFx2mgQi3MF58=",
        "originContent": "    <td><video src=\"https://github.com/user-attachments/assets/736d22ca-6636-4ef0-99f3-768e4dfb112a\"></video></td>",
        "translatedContent": "    <td><video src=\"https://github.com/user-attachments/assets/736d22ca-6636-4ef0-99f3-768e4dfb112a\"></video></td>"
      },
      {
        "row": 19,
        "rowsha": "f/NV8lJG3/wKBuvpWIe44S3uqSsyCu6QnhQNdP+m+x4=",
        "originContent": "    <td><video src=\"https://github.com/user-attachments/assets/f2f7c94c-7f72-4cc0-8edc-290910980b04\"></video></td>",
        "translatedContent": "    <td><video src=\"https://github.com/user-attachments/assets/f2f7c94c-7f72-4cc0-8edc-290910980b04\"></video></td>"
      },
      {
        "row": 20,
        "rowsha": "6o+qeLcGxX0dvrGBva8HKZWaO7Np0FI8WMiMEuNtFfo=",
        "originContent": "  <tr>",
        "translatedContent": "  <tr>"
      },
      {
        "row": 21,
        "rowsha": "4gr1GgVFlU3L3QjwTtUsfD17IHjNN34F/9NKaoIf0hY=",
        "originContent": "  <td><video src=\"https://github.com/user-attachments/assets/d3e58dd4-31ae-4e32-aef1-03f1e649cb0c\"></video></td>",
        "translatedContent": "  <td><video src=\"https://github.com/user-attachments/assets/d3e58dd4-31ae-4e32-aef1-03f1e649cb0c\"></video></td>"
      },
      {
        "row": 22,
        "rowsha": "40t9Y3yyaNH5W/E377F5s1ZeMWoyl8tA14tFCJgnNwc=",
        "originContent": "  <td><video src=\"https://github.com/user-attachments/assets/4f68199f-e48a-4be7-b6dc-1acb8d377a6e\"></video></td>",
        "translatedContent": "  <td><video src=\"https://github.com/user-attachments/assets/4f68199f-e48a-4be7-b6dc-1acb8d377a6e\"></video></td>"
      },
      {
        "row": 23,
        "rowsha": "E65VGlVfX8z4s1OMSSsebyozZw1yRIhcXnI2xq/cle4=",
        "originContent": "  <td><video src=\"https://github.com/user-attachments/assets/062236c3-1d26-4622-b843-cc0cd0c58053\"></video></td>",
        "translatedContent": "  <td><video src=\"https://github.com/user-attachments/assets/062236c3-1d26-4622-b843-cc0cd0c58053\"></video></td>"
      },
      {
        "row": 24,
        "rowsha": "OiNQYEf9lQ4VY4ev1P8fYEqhldXvPCT4oCAzyfkyWEs=",
        "originContent": "\t<tr>",
        "translatedContent": "\t<tr>"
      },
      {
        "row": 25,
        "rowsha": "qAjHrxg1MaGiBckyj/fm3Bg0IJFroNsOGgqNgjWD1rw=",
        "originContent": "  <td><video src=\"https://github.com/user-attachments/assets/8931f428-dd4d-430f-9927-068f2912dd36\"></video></td>",
        "translatedContent": "  <td><video src=\"https://github.com/user-attachments/assets/8931f428-dd4d-430f-9927-068f2912dd36\"></video></td>"
      },
      {
        "row": 26,
        "rowsha": "EDqm9uTGhUaiwbJOXO504J5Q7fhCeBn3W/+HloAmKZs=",
        "originContent": "  <td><video src=\"https://github.com/user-attachments/assets/ab7e46d5-f42c-472e-b66e-df786b658210\"></video></td>      ",
        "translatedContent": "  <td><video src=\"https://github.com/user-attachments/assets/ab7e46d5-f42c-472e-b66e-df786b658210\"></video></td>      "
      },
      {
        "row": 27,
        "rowsha": "xf9Jp12r2D1odgr6MJ+40q5xuyv277conuiNnh6Fpt0=",
        "originContent": "  <td><video src=\"https://github.com/user-attachments/assets/9a0998ad-b5a4-42ac-bdaf-ceaf796fc586\"></video></td>",
        "translatedContent": "  <td><video src=\"https://github.com/user-attachments/assets/9a0998ad-b5a4-42ac-bdaf-ceaf796fc586\"></video></td>"
      },
      {
        "row": 28,
        "rowsha": "6o+qeLcGxX0dvrGBva8HKZWaO7Np0FI8WMiMEuNtFfo=",
        "originContent": "  <tr>",
        "translatedContent": "  <tr>"
      },
      {
        "row": 29,
        "rowsha": "+hgoFVIJCNdOMAGtb2zTTnLrSdPnvT/pIoTy2M2EOaI=",
        "originContent": "</table >",
        "translatedContent": "</table >"
      },
      {
        "row": 30,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 31,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 32,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 33,
        "rowsha": "bqRMr9Ypst45FZhaZtIL960+4R8vcRhCw4XVLHj851M=",
        "originContent": "### 3. Text-to-Long Audio (Natural sound)",
        "translatedContent": "### 3. Texte vers audio long (Son naturel)"
      },
      {
        "row": 34,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 35,
        "rowsha": "7FG0iwt8PZSz598R2HJFKtpFGDfFezhtVCdnqadcLCQ=",
        "originContent": "<table class=\"center\">",
        "translatedContent": "<table class=\"center\">"
      },
      {
        "row": 36,
        "rowsha": "kMl1wJJ0HS3Ld38pT9ZOCTUq1CtHLTO6iKBL9jjBh00=",
        "originContent": "  <td style=\"text-align:center;\" width=\"480\">Instruction: \"Develop a comprehensive audio that fully represents jake shimabukuro performs a complex ukulele piece in a studio, receives applause, and discusses his career in an interview. The total duration is 49.9 seconds.\"</td>",
        "translatedContent": "  <td style=\"text-align:center;\" width=\"480\">Instruction : \"D√©veloppez un audio complet qui repr√©sente pleinement Jake Shimabukuro interpr√©tant un morceau complexe de ukul√©l√© en studio, re√ßoit des applaudissements, et parle de sa carri√®re lors d'une interview. La dur√©e totale est de 49,9 secondes.\"</td>"
      },
      {
        "row": 37,
        "rowsha": "bVjjQDN5t3tZPc6WndJCodkwijyURdfLT+irZpx6NMQ=",
        "originContent": "  <td><video src=\"https://github.com/user-attachments/assets/461e8a34-4217-454e-87b3-e4285f36ec43\"></video></td>",
        "translatedContent": "  <td><video src=\"https://github.com/user-attachments/assets/461e8a34-4217-454e-87b3-e4285f36ec43\"></video></td>"
      },
      {
        "row": 38,
        "rowsha": "OiNQYEf9lQ4VY4ev1P8fYEqhldXvPCT4oCAzyfkyWEs=",
        "originContent": "\t<tr>",
        "translatedContent": "\t<tr>"
      },
      {
        "row": 39,
        "rowsha": "WbDkggqFZprYFRmHly74ThpjAst9amNC4V84yMr1nd0=",
        "originContent": "  <td style=\"text-align:center;\" width=\"480\">Instruction: \"Develop a comprehensive audio that fully represents a fire truck leaves the station with sirens blaring, signaling an emergency response, and drives away. The total duration is 35.1 seconds.\"</td>",
        "translatedContent": "  <td style=\"text-align:center;\" width=\"480\">Instruction : \"D√©veloppez un audio complet qui repr√©sente pleinement un camion de pompiers quittant la caserne avec les sir√®nes hurlantes, signalant une intervention d'urgence, et s'√©loignant. La dur√©e totale est de 35,1 secondes.\"</td>"
      },
      {
        "row": 40,
        "rowsha": "9lkZnoSiQ/+N8CvPzh6Ssopa76N50YfMqCRiFMNU26U=",
        "originContent": "  <td><video src=\"https://github.com/user-attachments/assets/aac0243f-5d12-480e-9850-a7f6720e4f9c\"></video></td>",
        "translatedContent": "  <td><video src=\"https://github.com/user-attachments/assets/aac0243f-5d12-480e-9850-a7f6720e4f9c\"></video></td>"
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 3,
    "Content": "\t<tr>\n     <td style=\"text-align:center;\" width=\"480\">Instruction: \"Understand the input audio, infer the subsequent events, and generate the continued audio of the coach giving basketball lessons to the players. The total duration is 36.6 seconds.\"</td>    \n    <td><video src=\"https://github.com/user-attachments/assets/c4ed306a-651e-43d6-aeea-ee159542418a\"></video></td>\n\t<tr>\n</table >\n\n\n\n\n## üîé Methods\n\n![audiostory_framework](https://raw.githubusercontent.com/TencentARC/AudioStory/main/audiostory_framework.png)\n\nTo achieve effective instruction-following audio generation, the ability to understand the input instruction or audio stream and reason about relevant audio sub-events is essential. To this end,  AudioStory adopts a unified understanding-generation framework (Fig.). Specifically, given textual instruction or audio input, the LLM analyzes and decomposes it into structured audio sub-events with context. Based on the inferred sub-events, the LLM performs **interleaved reasoning generation**, sequentially producing captions, semantic tokens, and residual tokens for each audio clip. These two types of tokens are fused and passed to the DiT, effectively bridging the LLM with the audio generator. Through progressive training, AudioStory ultimately achieves both strong instruction comprehension and high-quality audio generation.\n\n\n\n## üî© Installation\n\n### Dependencies\n\n* Python >= 3.10 (Recommend to use [Anaconda](https://www.anaconda.com/download/#linux))\n* [PyTorch >=2.1.0](https://pytorch.org/)\n* NVIDIA GPU + [CUDA](https://developer.nvidia.com/cuda-downloads)\n\n### Installation\n",
    "ContentSha": "/GyPwsJGVpnaZEh9wkUBW13gnt3S8xfye/LjEg7KI5Q=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "\t<tr>\n     <td style=\"text-align:center;\" width=\"480\">Instruction : \"Comprendre l'audio d'entr√©e, d√©duire les √©v√©nements suivants, et g√©n√©rer l'audio continu du coach donnant des le√ßons de basketball aux joueurs. La dur√©e totale est de 36,6 secondes.\"</td>    \n    <td><video src=\"https://github.com/user-attachments/assets/c4ed306a-651e-43d6-aeea-ee159542418a\"></video></td>\n\t<tr>\n</table >\n\n\n\n\n## üîé M√©thodes\n\n![audiostory_framework](https://raw.githubusercontent.com/TencentARC/AudioStory/main/audiostory_framework.png)\n\nPour parvenir √† une g√©n√©ration audio suivant efficacement les instructions, la capacit√© √† comprendre l'instruction ou le flux audio d'entr√©e et √† raisonner sur les sous-√©v√©nements audio pertinents est essentielle. √Ä cette fin, AudioStory adopte un cadre unifi√© de compr√©hension-g√©n√©ration (Fig.). Plus pr√©cis√©ment, donn√© une instruction textuelle ou une entr√©e audio, le LLM l'analyse et la d√©compose en sous-√©v√©nements audio structur√©s avec contexte. Sur la base des sous-√©v√©nements d√©duits, le LLM effectue une **g√©n√©ration par raisonnement entrelac√©**, produisant s√©quentiellement des l√©gendes, des tokens s√©mantiques, et des tokens r√©siduels pour chaque clip audio. Ces deux types de tokens sont fusionn√©s et transmis au DiT, reliant efficacement le LLM au g√©n√©rateur audio. Gr√¢ce √† un entra√Ænement progressif, AudioStory atteint finalement √† la fois une forte compr√©hension des instructions et une g√©n√©ration audio de haute qualit√©.\n\n\n\n## üî© Installation\n\n### D√©pendances\n\n* Python >= 3.10 (Recommand√© d'utiliser [Anaconda](https://www.anaconda.com/download/#linux))\n* [PyTorch >=2.1.0](https://pytorch.org/)\n* GPU NVIDIA + [CUDA](https://developer.nvidia.com/cuda-downloads)\n\n### Installation\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "OiNQYEf9lQ4VY4ev1P8fYEqhldXvPCT4oCAzyfkyWEs=",
        "originContent": "\t<tr>",
        "translatedContent": "\t<tr>"
      },
      {
        "row": 2,
        "rowsha": "Ubj/ESZSw8PuG2wDYpXEupbQmCK4+A6G3TJPe8f9dj0=",
        "originContent": "     <td style=\"text-align:center;\" width=\"480\">Instruction: \"Understand the input audio, infer the subsequent events, and generate the continued audio of the coach giving basketball lessons to the players. The total duration is 36.6 seconds.\"</td>    ",
        "translatedContent": "     <td style=\"text-align:center;\" width=\"480\">Instruction : \"Comprendre l'audio d'entr√©e, d√©duire les √©v√©nements suivants, et g√©n√©rer l'audio continu du coach donnant des le√ßons de basketball aux joueurs. La dur√©e totale est de 36,6 secondes.\"</td>    "
      },
      {
        "row": 3,
        "rowsha": "kSoQNgOfaTU7IxCn8zhbXySiTHuy7pubDSaVGFNhc0U=",
        "originContent": "    <td><video src=\"https://github.com/user-attachments/assets/c4ed306a-651e-43d6-aeea-ee159542418a\"></video></td>",
        "translatedContent": "    <td><video src=\"https://github.com/user-attachments/assets/c4ed306a-651e-43d6-aeea-ee159542418a\"></video></td>"
      },
      {
        "row": 4,
        "rowsha": "OiNQYEf9lQ4VY4ev1P8fYEqhldXvPCT4oCAzyfkyWEs=",
        "originContent": "\t<tr>",
        "translatedContent": "\t<tr>"
      },
      {
        "row": 5,
        "rowsha": "+hgoFVIJCNdOMAGtb2zTTnLrSdPnvT/pIoTy2M2EOaI=",
        "originContent": "</table >",
        "translatedContent": "</table >"
      },
      {
        "row": 6,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 7,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 8,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 9,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 10,
        "rowsha": "DSR9DEZFtYlp7rFmJdaJn543CfSMiyJtVeJd41Shuqk=",
        "originContent": "## üîé Methods",
        "translatedContent": "## üîé M√©thodes"
      },
      {
        "row": 11,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 12,
        "rowsha": "9BH0xGdcfBS+VhBWoWwKAVZ3mgHTm/j1BgvwybER7o8=",
        "originContent": "![audiostory_framework](https://raw.githubusercontent.com/TencentARC/AudioStory/main/audiostory_framework.png)",
        "translatedContent": "![audiostory_framework](https://raw.githubusercontent.com/TencentARC/AudioStory/main/audiostory_framework.png)"
      },
      {
        "row": 13,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 14,
        "rowsha": "GPV5B4bE7PBjL8Nf8gfo6IGZc0RTyX/CfLJH6fpFaAs=",
        "originContent": "To achieve effective instruction-following audio generation, the ability to understand the input instruction or audio stream and reason about relevant audio sub-events is essential. To this end,  AudioStory adopts a unified understanding-generation framework (Fig.). Specifically, given textual instruction or audio input, the LLM analyzes and decomposes it into structured audio sub-events with context. Based on the inferred sub-events, the LLM performs **interleaved reasoning generation**, sequentially producing captions, semantic tokens, and residual tokens for each audio clip. These two types of tokens are fused and passed to the DiT, effectively bridging the LLM with the audio generator. Through progressive training, AudioStory ultimately achieves both strong instruction comprehension and high-quality audio generation.",
        "translatedContent": "Pour parvenir √† une g√©n√©ration audio suivant efficacement les instructions, la capacit√© √† comprendre l'instruction ou le flux audio d'entr√©e et √† raisonner sur les sous-√©v√©nements audio pertinents est essentielle. √Ä cette fin, AudioStory adopte un cadre unifi√© de compr√©hension-g√©n√©ration (Fig.). Plus pr√©cis√©ment, donn√© une instruction textuelle ou une entr√©e audio, le LLM l'analyse et la d√©compose en sous-√©v√©nements audio structur√©s avec contexte. Sur la base des sous-√©v√©nements d√©duits, le LLM effectue une **g√©n√©ration par raisonnement entrelac√©**, produisant s√©quentiellement des l√©gendes, des tokens s√©mantiques, et des tokens r√©siduels pour chaque clip audio. Ces deux types de tokens sont fusionn√©s et transmis au DiT, reliant efficacement le LLM au g√©n√©rateur audio. Gr√¢ce √† un entra√Ænement progressif, AudioStory atteint finalement √† la fois une forte compr√©hension des instructions et une g√©n√©ration audio de haute qualit√©."
      },
      {
        "row": 15,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 16,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 17,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 18,
        "rowsha": "K5BKhOEr4dNsKz5aQYjGDFsb5cAXzh2rRww3aq1fToY=",
        "originContent": "## üî© Installation",
        "translatedContent": "## üî© Installation"
      },
      {
        "row": 19,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 20,
        "rowsha": "cA9I4m4MLDGazdniXFF/VJ7jgnkzPSvBbISFVX7s/5s=",
        "originContent": "### Dependencies",
        "translatedContent": "### D√©pendances"
      },
      {
        "row": 21,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 22,
        "rowsha": "ybFy651pkGBiUaSzaUrVuJTCbVsItiZJqXTekxenDOs=",
        "originContent": "* Python >= 3.10 (Recommend to use [Anaconda](https://www.anaconda.com/download/#linux))",
        "translatedContent": "* Python >= 3.10 (Recommand√© d'utiliser [Anaconda](https://www.anaconda.com/download/#linux))"
      },
      {
        "row": 23,
        "rowsha": "2clsJHIWgOmQ5F5S50Xg0VdGp29U34jP7Md27T2D6hQ=",
        "originContent": "* [PyTorch >=2.1.0](https://pytorch.org/)",
        "translatedContent": "* [PyTorch >=2.1.0](https://pytorch.org/)"
      },
      {
        "row": 24,
        "rowsha": "jayRuOQfJklvG5CCRlsnsLExVb7ZiAnQNvgN4dziUNE=",
        "originContent": "* NVIDIA GPU + [CUDA](https://developer.nvidia.com/cuda-downloads)",
        "translatedContent": "* GPU NVIDIA + [CUDA](https://developer.nvidia.com/cuda-downloads)"
      },
      {
        "row": 25,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 26,
        "rowsha": "JuAC4s82hMbNkRqX17s0ltqjVmeI/HhsmWljgf+i7Kg=",
        "originContent": "### Installation",
        "translatedContent": "### Installation"
      },
      {
        "row": 27,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 4,
    "Content": "```\ngit clone https://github.com/TencentARC/AudioStory.git\ncd AudioStory\nconda create -n audiostory python=3.10 -y\nconda activate audiostory\nbash install_audiostory.sh\n```",
    "ContentSha": "torQeDrtkkKZDXrpn1NU9BCi1oPIYyqAjGXcQv3AB1A=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```\ngit clone https://github.com/TencentARC/AudioStory.git\ncd AudioStory\nconda create -n audiostory python=3.10 -y\nconda activate audiostory\nbash install_audiostory.sh\n```",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      },
      {
        "row": 2,
        "rowsha": "EPmucZkseZe9CkGYkev1GLT10FBhL1aNrGP/yj11YCk=",
        "originContent": "git clone https://github.com/TencentARC/AudioStory.git",
        "translatedContent": "git clone https://github.com/TencentARC/AudioStory.git"
      },
      {
        "row": 3,
        "rowsha": "0NZ9wSgVtafsjHQpQHI6UrYESexC7Zt6QfFMDCs6no4=",
        "originContent": "cd AudioStory",
        "translatedContent": "cd AudioStory"
      },
      {
        "row": 4,
        "rowsha": "b6InjqOMdN4MWLHgzMqBe0kIp8aZoXOify/79OYxSoQ=",
        "originContent": "conda create -n audiostory python=3.10 -y",
        "translatedContent": "conda create -n audiostory python=3.10 -y"
      },
      {
        "row": 5,
        "rowsha": "6EvnIjWjc45YgSD65Q5ld8GdStTLPBPMF2Y7UsLJrxg=",
        "originContent": "conda activate audiostory",
        "translatedContent": "conda activate audiostory"
      },
      {
        "row": 6,
        "rowsha": "lz0yrVadp6kN4Y0yuBpmqXWQj5H72CMu8CZollmEaKA=",
        "originContent": "bash install_audiostory.sh",
        "translatedContent": "bash install_audiostory.sh"
      },
      {
        "row": 7,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      }
    ],
    "IsCodeBlock": true
  },
  {
    "Id": 5,
    "Content": "\n\n\n## üìä Evaluation\n\n### inference\n",
    "ContentSha": "VXPWsF6XWv8o+fu5ShnIm806PI4eUZhbnTgIUOFTXow=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "\n\n\n## üìä Evaluation\n\n### inference\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 2,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 3,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 4,
        "rowsha": "RV/lkFyd4r4TQLY1qeDzx60mM+znUBMQr8fvaK78ARc=",
        "originContent": "## üìä Evaluation",
        "translatedContent": "## üìä Evaluation"
      },
      {
        "row": 5,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 6,
        "rowsha": "nPTFwGS68FhDKEEpm6ZdfcFiiCl0YPFcoEoP4JW/kgc=",
        "originContent": "### inference",
        "translatedContent": "### inference"
      },
      {
        "row": 7,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 6,
    "Content": "```\npython evaluate/inference.py --model_path /path/to/ckpt --guidance 4.0 --save_folder_name audiostory --total_duration 50\n```",
    "ContentSha": "KaFRY3J/KQfqoMUzdWhseF4Ie11Qsa5GX7kzvSuPb/8=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```\npython evaluate/inference.py --model_path /path/to/ckpt --guidance 4.0 --save_folder_name audiostory --total_duration 50\n```",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      },
      {
        "row": 2,
        "rowsha": "ZnsFCbLX8ufyjJRVjZqrJuJpwkDqjg17DUZ4Jls4H38=",
        "originContent": "python evaluate/inference.py --model_path /path/to/ckpt --guidance 4.0 --save_folder_name audiostory --total_duration 50",
        "translatedContent": "python evaluate/inference.py --model_path /path/to/ckpt --guidance 4.0 --save_folder_name audiostory --total_duration 50"
      },
      {
        "row": 3,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      }
    ],
    "IsCodeBlock": true
  },
  {
    "Id": 7,
    "Content": "\n\n\n## üîã Acknowledgement\n\nWhen building the codebase of continuous denosiers, we refer to [SEED-X](https://github.com/AILab-CVC/SEED-X) and [TangoFlux](https://github.com/declare-lab/TangoFlux). Thanks for their wonderful projects.\n\n\n\n## üìÜ TO DO\n\n- [ ] Release our gradio demo.\n- [ ] Release checkpoints of AudioStory.\n- [ ] Release training codes of all three stages.\n\n\n\n## üìú License\n\nThis repository is under the [Apache 2 License](https://github.com/mashijie1028/Gen4Rep/blob/main/LICENSE).\n\n\n\n## üìö BibTeX\n",
    "ContentSha": "KqevFHQFhagGOJl+ZPG92WY3KPbdVOYnC0wRC6I3Syo=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "## üîã Remerciements\n\nLors de la cr√©ation de la base de code des d√©bruiteurs continus, nous nous sommes r√©f√©r√©s √† [SEED-X](https://github.com/AILab-CVC/SEED-X) et [TangoFlux](https://github.com/declare-lab/TangoFlux). Merci pour leurs projets remarquables.\n\n\n\n## üìÜ √Ä FAIRE\n\n- [ ] Publier notre d√©monstration gradio.\n- [ ] Publier les points de contr√¥le d'AudioStory.\n- [ ] Publier les codes d'entra√Ænement des trois √©tapes.\n\n\n\n## üìú Licence\n\nCe d√©p√¥t est sous la [Licence Apache 2](https://github.com/mashijie1028/Gen4Rep/blob/main/LICENSE).\n\n\n\n## üìö BibTeX\n\n\n\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "## üîã Remerciements"
      },
      {
        "row": 2,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 3,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "Lors de la cr√©ation de la base de code des d√©bruiteurs continus, nous nous sommes r√©f√©r√©s √† [SEED-X](https://github.com/AILab-CVC/SEED-X) et [TangoFlux](https://github.com/declare-lab/TangoFlux). Merci pour leurs projets remarquables."
      },
      {
        "row": 4,
        "rowsha": "2wITwUlzAo4l/8qItt2XUr+0BnCsPysASmH5gx69T7w=",
        "originContent": "## üîã Acknowledgement",
        "translatedContent": ""
      },
      {
        "row": 5,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 6,
        "rowsha": "8lTT7v2VuQ0QtdsydJaX8vAjYN5nizcwZ/fhChW28pA=",
        "originContent": "When building the codebase of continuous denosiers, we refer to [SEED-X](https://github.com/AILab-CVC/SEED-X) and [TangoFlux](https://github.com/declare-lab/TangoFlux). Thanks for their wonderful projects.",
        "translatedContent": ""
      },
      {
        "row": 7,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "## üìÜ √Ä FAIRE"
      },
      {
        "row": 8,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 9,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "- [ ] Publier notre d√©monstration gradio."
      },
      {
        "row": 10,
        "rowsha": "GC23nj3oE9/vfv7oaTalUvYrK5FOFDTk7jfTM6fZ59w=",
        "originContent": "## üìÜ TO DO",
        "translatedContent": "- [ ] Publier les points de contr√¥le d'AudioStory."
      },
      {
        "row": 11,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "- [ ] Publier les codes d'entra√Ænement des trois √©tapes."
      },
      {
        "row": 12,
        "rowsha": "Ev8F7RO049LbUw2wYkPRhR9N/P+kHtNfq+/JqoYCKTQ=",
        "originContent": "- [ ] Release our gradio demo.",
        "translatedContent": ""
      },
      {
        "row": 13,
        "rowsha": "NdhvCxdI7tcZ2BADUj+Lf1faPs4omgHrlmDe9OLatKw=",
        "originContent": "- [ ] Release checkpoints of AudioStory.",
        "translatedContent": ""
      },
      {
        "row": 14,
        "rowsha": "cU6Kqe85RhIzRzZZSmmW6go4ItSFAE13SJGOKdBAlk8=",
        "originContent": "- [ ] Release training codes of all three stages.",
        "translatedContent": ""
      },
      {
        "row": 15,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "## üìú Licence"
      },
      {
        "row": 16,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 17,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "Ce d√©p√¥t est sous la [Licence Apache 2](https://github.com/mashijie1028/Gen4Rep/blob/main/LICENSE)."
      },
      {
        "row": 18,
        "rowsha": "Xg7z9THMMv8mm3IS7LJHSaXGCrZhD8D4NGbb/+/ra/Y=",
        "originContent": "## üìú License",
        "translatedContent": ""
      },
      {
        "row": 19,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 20,
        "rowsha": "EZFCjf6XUzozZCx6zuDMh0DwwcxgS9mIiOHr2h1fT2k=",
        "originContent": "This repository is under the [Apache 2 License](https://github.com/mashijie1028/Gen4Rep/blob/main/LICENSE).",
        "translatedContent": ""
      },
      {
        "row": 21,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "## üìö BibTeX"
      },
      {
        "row": 22,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 23,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 24,
        "rowsha": "Ol70b6U8dEWdUG46wK7jYP1taws7iJl4nBgER5ckRWk=",
        "originContent": "## üìö BibTeX",
        "translatedContent": ""
      },
      {
        "row": 25,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 8,
    "Content": "```\n@misc{guo2025audiostory,\n      title={AudioStory: Generating Long-Form Narrative Audio with Large Language Models}, \n      author={Yuxin Guo and Teng Wang and Yuying Ge and Shijie Ma and Yixiao Ge and Wei Zou and Ying Shan},\n      year={2025},\n      eprint={2508.20088},\n      archivePrefix={arXiv},\n      primaryClass={cs.CV},\n      url={https://arxiv.org/abs/2508.20088}, \n}\n```",
    "ContentSha": "tDvow+Q6zrM97CRU0hSl4LYmQnB/4O/k83/ptCYWq3I=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```\n@misc{guo2025audiostory,\n      title={AudioStory: Generating Long-Form Narrative Audio with Large Language Models}, \n      author={Yuxin Guo and Teng Wang and Yuying Ge and Shijie Ma and Yixiao Ge and Wei Zou and Ying Shan},\n      year={2025},\n      eprint={2508.20088},\n      archivePrefix={arXiv},\n      primaryClass={cs.CV},\n      url={https://arxiv.org/abs/2508.20088}, \n}\n```",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      },
      {
        "row": 2,
        "rowsha": "zG+SHLM1YaUdKpVrhSHgd+F3ENF1Tu0sdECnTtfj2T0=",
        "originContent": "@misc{guo2025audiostory,",
        "translatedContent": "@misc{guo2025audiostory,"
      },
      {
        "row": 3,
        "rowsha": "wRos7vm1oMESsZP/y3oCTU8pDdBwTNkutSMbCenULPQ=",
        "originContent": "      title={AudioStory: Generating Long-Form Narrative Audio with Large Language Models}, ",
        "translatedContent": "      title={AudioStory: Generating Long-Form Narrative Audio with Large Language Models}, "
      },
      {
        "row": 4,
        "rowsha": "J3AFWUtKeIdEng2gdsNNS/aaTvmB5y4qXjaM19l1ros=",
        "originContent": "      author={Yuxin Guo and Teng Wang and Yuying Ge and Shijie Ma and Yixiao Ge and Wei Zou and Ying Shan},",
        "translatedContent": "      author={Yuxin Guo and Teng Wang and Yuying Ge and Shijie Ma and Yixiao Ge and Wei Zou and Ying Shan},"
      },
      {
        "row": 5,
        "rowsha": "1cuvfM9h03loQfZOlvsx9juVCvU41kevaYb2CnD9Gak=",
        "originContent": "      year={2025},",
        "translatedContent": "      year={2025},"
      },
      {
        "row": 6,
        "rowsha": "aVyrdaXiDdq72O2IEEra144lvU5mp8vtcvui+Yc67Y8=",
        "originContent": "      eprint={2508.20088},",
        "translatedContent": "      eprint={2508.20088},"
      },
      {
        "row": 7,
        "rowsha": "Fr73/KLqU4TaDaJVUDLO211nM029JE4YRpN5hXSZZqk=",
        "originContent": "      archivePrefix={arXiv},",
        "translatedContent": "      archivePrefix={arXiv},"
      },
      {
        "row": 8,
        "rowsha": "RPNBhgHdrY2A+XYLnuhpAr/aqag2LU2pAjasgtM0tg4=",
        "originContent": "      primaryClass={cs.CV},",
        "translatedContent": "      primaryClass={cs.CV},"
      },
      {
        "row": 9,
        "rowsha": "hP+VcwdqOvUO3cyxMORLXst2UhI7aWcsza6RkNrQcLU=",
        "originContent": "      url={https://arxiv.org/abs/2508.20088}, ",
        "translatedContent": "      url={https://arxiv.org/abs/2508.20088}, "
      },
      {
        "row": 10,
        "rowsha": "0Qs2qnSlm89KiBhYN/ZYr682Ru/yuxbDko0OkzXpRdI=",
        "originContent": "}",
        "translatedContent": "}"
      },
      {
        "row": 11,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      }
    ],
    "IsCodeBlock": true
  },
  {
    "Id": 9,
    "Content": "\n\n\n## üìß Contact\n\nIf you have further questions, feel free to contact me: guoyuxin2021@ia.ac.cn\n\nDiscussions and potential collaborations are also welcome.\n",
    "ContentSha": "ep0eO4/5mD+WOJt3GO3K6E+5j9UwGmybkmcqBkIPIEU=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "## üìß Contact\n\nSi vous avez d'autres questions, n'h√©sitez pas √† me contacter : guoyuxin2021@ia.ac.cn\n\nLes discussions et les collaborations potentielles sont √©galement les bienvenues.\n\n\n\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "## üìß Contact"
      },
      {
        "row": 2,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 3,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "Si vous avez d'autres questions, n'h√©sitez pas √† me contacter : guoyuxin2021@ia.ac.cn"
      },
      {
        "row": 4,
        "rowsha": "9XM9zLdHzI7rLQpxWwSAIpta/O8ZZ3JUA/iWlKatt1U=",
        "originContent": "## üìß Contact",
        "translatedContent": ""
      },
      {
        "row": 5,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "Les discussions et les collaborations potentielles sont √©galement les bienvenues."
      },
      {
        "row": 6,
        "rowsha": "CVhFCz7Qsh+ZlaXPyiCOrHyQDF3GIS9j8RaIjP6cP44=",
        "originContent": "If you have further questions, feel free to contact me: guoyuxin2021@ia.ac.cn",
        "translatedContent": ""
      },
      {
        "row": 7,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 8,
        "rowsha": "G3RStoG3klhI6y7b7G1lU2zdGS23bL1DBPh+G2x4V2I=",
        "originContent": "Discussions and potential collaborations are also welcome.",
        "translatedContent": ""
      },
      {
        "row": 9,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  }
]