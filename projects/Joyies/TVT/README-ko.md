<div align="center">
<h2>ì „ì´ VAE í•™ìŠµì„ í†µí•œ ë¯¸ì„¸êµ¬ì¡° ë³´ì¡´ ì‹¤ì œ ì´ë¯¸ì§€ ì´ˆí•´ìƒí™”</h2>

ğŸš© ICCV2025 ì±„íƒ

[Qiaosi Yi](https://dblp.org/pid/249/8335.html)<sup>1,2</sup>
| [Shuai Li](https://scholar.google.com/citations?hl=zh-CN&user=Bd73ldQAAAAJ)<sup>1</sup>
| [Rongyuan Wu](https://scholar.google.com/citations?user=A-U8zE8AAAAJ&hl=zh-CN)<sup>1,2</sup>
| [Lingchen Sun](https://scholar.google.com/citations?hl=zh-CN&tzom=-480&user=ZCDjTn8AAAAJ)<sup>1,2</sup>
| [Yuhui Wu](https://dblp.org/pid/41/915-1.html)<sup>1,2</sup>
| [Lei Zhang](https://www4.comp.polyu.edu.hk/~cslzhang)<sup>1,2</sup>

<sup>1</sup>í™ì½© í´ë¦¬í…ëŒ€í•™êµ, <sup>2</sup>OPPO ì—°êµ¬ì†Œ
</div>

[![](https://img.shields.io/badge/ArXiv%20-Paper-b31b1b?logo=arxiv&logoColor=red)](https://arxiv.org/pdf/2507.20291)&nbsp; [![weights](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-model%20weights-blue)](https://huggingface.co/Joypop/TVTSR/tree/main)


## â° ì—…ë°ì´íŠ¸
- **2025.7.29**: ë…¼ë¬¸ì´ [ArXiv](https://arxiv.org/pdf/2507.20291)ì— ê³µê°œë˜ì—ˆìŠµë‹ˆë‹¤.
- **2025.7.28**: í•™ìŠµ ì½”ë“œì™€ í…ŒìŠ¤íŠ¸ ì½”ë“œê°€ ê³µê°œë˜ì—ˆìŠµë‹ˆë‹¤.
- **2025.7.24**: ì €ì¥ì†Œê°€ ê³µê°œë˜ì—ˆìŠµë‹ˆë‹¤.

:star: TVTê°€ ì—¬ëŸ¬ë¶„ì˜ ì´ë¯¸ì§€ë‚˜ í”„ë¡œì íŠ¸ì— ë„ì›€ì´ ëœë‹¤ë©´, ì´ ì €ì¥ì†Œì— ë³„ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”. ê°ì‚¬í•©ë‹ˆë‹¤! :hugs:

### í•  ì¼
- [x] ì¶”ë¡ ìš© ì½”ë“œ ê³µê°œ.
- [x] í•™ìŠµ ì½”ë“œ ì—…ë°ì´íŠ¸.
- [ ] fp16 VAED4.


## âš™ ì˜ì¡´ì„± ë° ì„¤ì¹˜
```shell
## git clone this repository
git clone https://github.com/Joyies/TVT.git
cd TVT


# create an environment
conda create -n TVT python=3.10
conda activate TVT
pip install --upgrade pip
pip install -r requirements.txt
```
## ğŸ‚ ë¹ ë¥¸ ì¶”ë¡ 

### ì‹¤ì œ ì´ë¯¸ì§€ ì´ˆí•´ìƒë„

#### 1ë‹¨ê³„: ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
- ì‚¬ì „ í•™ìŠµëœ SD-2.1-base ëª¨ë¸ì„ [![weights](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-SD%202.1%20Base-blue)](https://huggingface.co/Joypop/stable-diffusion-2-1-base)&nbsp;ì—ì„œ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.
- ëª¨ë¸ ê°€ì¤‘ì¹˜([VAED4](https://huggingface.co/Joypop/TVTSR/tree/main/ckp), [TVT ëª¨ë¸](https://huggingface.co/Joypop/TVTSR/tree/main/ckp), [TVTUNet](https://huggingface.co/Joypop/TVTSR/tree/main/ckp), [DAPE](https://huggingface.co/Joypop/TVTSR/tree/main/ckp), ê·¸ë¦¬ê³  [RAM](https://huggingface.co/Joypop/TVTSR/tree/main/ckp))ë¥¼ [![weights](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-model%20weights-blue)](https://huggingface.co/Joypop/TVTSR/tree/main)&nbsp;ì—ì„œ ë‹¤ìš´ë¡œë“œí•˜ì—¬ `ckp/`ì— ë„£ìŠµë‹ˆë‹¤.

#### 2ë‹¨ê³„: í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„ ë° í…ŒìŠ¤íŠ¸ ëª…ë ¹ ì‹¤í–‰
ì…ë ¥ ê²½ë¡œ(input_path)ì™€ ì¶œë ¥ ê²½ë¡œ(output_path)ë¥¼ ìˆ˜ì •í•˜ì—¬ í…ŒìŠ¤íŠ¸ ëª…ë ¹ì„ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì…ë ¥ ê²½ë¡œëŠ” í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ê²½ë¡œì´ê³  ì¶œë ¥ ê²½ë¡œëŠ” ì¶œë ¥ ì´ë¯¸ì§€ê°€ ì €ì¥ë  ê²½ë¡œì…ë‹ˆë‹¤.

```
python TVT/inferences/inference.py \
--input_image input_path \
--output_dir output_path \
--pretrained_path ckp/model_TVT.pkl \
--pretrained_model_name_or_path stabilityai/stable-diffusion-2-1-base \
--pretrained_unet_path ckp/TVTUNet \
--vae4d_path ckp/vae.ckpt \
--ram_ft_path ckp/DAPE.pth \
--negprompt 'dotted, noise, blur, lowres, smooth' \
--prompt 'clean, high-resolution, 8k' \
--upscale 4 \
--time_step 1
```
or 
```
bash scripts/test/test_realsr.sh
```
ë˜í•œ ì¶”ë¡  ì‹œ GPU ë©”ëª¨ë¦¬ë¥¼ ì ˆì•½í•˜ê¸° ìœ„í•œ íƒ€ì¼ ì½”ë“œë¥¼ ì œê³µí•©ë‹ˆë‹¤. ì‹¤í–‰ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•˜ê³  ì¥ì¹˜ì˜ VRAMì— ë”°ë¼ íƒ€ì¼ í¬ê¸°ì™€ ìŠ¤íŠ¸ë¼ì´ë“œë¥¼ ë³€ê²½í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
```
python TVT/inferences/inference_tile.py \
--input_image input_path \
--output_dir output_path \
--pretrained_path ckp/model_TVT.pkl \
--pretrained_model_name_or_path stabilityai/stable-diffusion-2-1-base \
--pretrained_unet_path ckp/TVTUNet \
--vae4d_path ckp/vae.ckpt \
--ram_ft_path ckp/DAPE.pth \
--negprompt 'dotted, noise, blur, lowres, smooth' \
--prompt 'clean, high-resolution, 8k' \
--upscale 4 \
--time_step 1 \
--tiled_size 96 \
--tiled_overlap 32
```
## ğŸš„ í•™ìŠµ ë‹¨ê³„

### OpenImage ë°ì´í„°ì…‹ê³¼ LSDIR ë°ì´í„°ì…‹ìœ¼ë¡œ VAED4 í•™ìŠµ
#### Step1: í•™ìŠµ ë°ì´í„° ì¤€ë¹„
[OpenImage ë°ì´í„°ì…‹](https://storage.googleapis.com/openimages/web/index.html)ê³¼ [LSIDR ë°ì´í„°ì…‹](https://github.com/ofsoundof/LSDIR)ì„ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤. LSDIR ë°ì´í„°ì…‹ì˜ ê° ì´ë¯¸ì§€ì— ëŒ€í•´, ìŠ¤íŠ¸ë¼ì´ë“œ 64 í”½ì…€ì˜ ìŠ¬ë¼ì´ë”© ìœˆë„ìš°ë¥¼ ì‚¬ìš©í•´ ì—¬ëŸ¬ ê°œì˜ 512Ã—512 ì´ë¯¸ì§€ íŒ¨ì¹˜ë¥¼ ìë¦…ë‹ˆë‹¤;

#### Step2: VAED4 í•™ìŠµ
VAED4 í•™ìŠµì—ëŠ” [LDM ì½”ë“œ](https://github.com/CompVis/latent-diffusion)ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. 


### Real-ISR ë°ì´í„°ì…‹ìœ¼ë¡œ TVTSR í•™ìŠµ
#### Step1: í•™ìŠµ ë°ì´í„° ì¤€ë¹„

[LSIDR ë°ì´í„°ì…‹](https://github.com/ofsoundof/LSDIR)ê³¼ ì²˜ìŒ 1ë§Œ ì¥ì˜ [FFHQ ë°ì´í„°ì…‹](https://github.com/NVlabs/ffhq-dataset)ì„ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤. ì´í›„ í•™ìŠµ ë°ì´í„°ì…‹ì— ëŒ€í•´ ë°ì´í„° ì¦ê°•ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. êµ¬ì²´ì ìœ¼ë¡œ, LSDIR ë°ì´í„°ì…‹ì˜ ê° ì´ë¯¸ì§€ì— ëŒ€í•´ ìŠ¤íŠ¸ë¼ì´ë“œ 64 í”½ì…€ì˜ ìŠ¬ë¼ì´ë”© ìœˆë„ìš°ë¡œ ì—¬ëŸ¬ ê°œì˜ 512Ã—512 ì´ë¯¸ì§€ íŒ¨ì¹˜ë¥¼ ìë¥´ê³ ; FFHQ ë°ì´í„°ì…‹ì˜ ê²½ìš° ëª¨ë“  ì´ë¯¸ì§€ë¥¼ 512Ã—512ë¡œ ì§ì ‘ ë¦¬ì‚¬ì´ì¦ˆí•©ë‹ˆë‹¤.

#### Step2: Real-ISR ëª¨ë¸ í•™ìŠµ

1. [VAED4](https://huggingface.co/Joypop/TVTSR/tree/main/ckp), [TVTUNet](https://huggingface.co/Joypop/TVTSR/tree/main/ckp), [RAM](https://huggingface.co/Joypop/TVTSR/tree/main/ckp) ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•˜ê³ , ì´ ëª¨ë¸ë“¤ì„ `ckp/` í´ë”ì— ë„£ìŠµë‹ˆë‹¤. 

2. í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤.

    ```shell
   accelerate launch --gpu_ids=0,1,2,3, --num_processes=4 TVT/train_TVTSR/train.py \
    --pretrained_model_name_or_path="stabilityai/stable-diffusion-2-1-base" \
    --pretrained_model_name_or_path_vsd="stabilityai/stable-diffusion-2-1-base" \
    --pretrained_unet_path='ckp/TVTUNet' \
    --vae4d_path='ckp/vae.ckpt' \
    --dataset_folder="data_path" \
    --testdataset_folder="test_path" \
    --resolution=512 \
    --learning_rate=5e-5 \
    --train_batch_size=2 \
    --gradient_accumulation_steps=2 \
    --enable_xformers_memory_efficient_attention \
    --eval_freq 500 \
    --checkpointing_steps 500 \
    --mixed_precision='fp16' \
    --report_to "tensorboard" \
    --output_dir="output_path" \
    --lora_rank_unet_vsd=4 \
    --lora_rank_unet=4 \
    --lambda_lpips=2 \
    --lambda_l2=1 \
    --lambda_vsd=1 \
    --lambda_vsd_lora=1 \
    --min_dm_step_ratio=0.25 \
    --max_dm_step_ratio=0.75 \
    --use_vae_encode_lora \
    --align_method="adain" \
    --use_online_deg \
    --deg_file_path="params_TVT.yml" \
    --negative_prompt='painting, oil painting, illustration, drawing, art, sketch, oil painting, cartoon, CG Style, 3D render, unreal engine, blurring, dirty, messy, worst quality, low quality, frames, watermark, signature, jpeg artifacts, deformed, lowres, over-smooth' \
    --test_image_prep='no_resize' \
    --time_step=1 \
    --tracker_project_name "experiment_track_name"
    ```
    or
    ```shell
   bash scripts/train/train.sh
    ```

## ğŸ”— ì¸ìš©
ì €í¬ ì½”ë“œê°€ ì—°êµ¬ë‚˜ ì‘ì—…ì— ë„ì›€ì´ ë˜ì…¨ë‹¤ë©´, ë…¼ë¬¸ ì¸ìš©ì„ ê³ ë ¤í•´ ì£¼ì„¸ìš”.
ë‹¤ìŒì€ BibTeX ì°¸ê³ ë¬¸í—Œì…ë‹ˆë‹¤:

```
@article{yi2025fine,
  title={Fine-structure Preserved Real-world Image Super-resolution via Transfer VAE Training},
  author={Yi, Qiaosi and Li, Shuai and Wu, Rongyuan and Sun, Lingchen and Wu, Yuhui and Zhang, Lei},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  year={2025}
}
```
## Â©ï¸ ë¼ì´ì„ ìŠ¤
ì´ í”„ë¡œì íŠ¸ëŠ” [Apache 2.0 ë¼ì´ì„ ìŠ¤](LICENSE) í•˜ì— ê³µê°œë˜ì–´ ìˆìŠµë‹ˆë‹¤.

## ğŸ“§ ì—°ë½ì²˜
ë¬¸ì˜ì‚¬í•­ì´ ìˆìœ¼ë©´ ë‹¤ìŒ ì£¼ì†Œë¡œ ì—°ë½í•´ ì£¼ì„¸ìš”: qiaosiyijoyies@gmail.com

## ê°ì‚¬ì˜ ê¸€
ì´ í”„ë¡œì íŠ¸ëŠ” [diffusers](https://github.com/huggingface/diffusers), [LDM](https://github.com/CompVis/latent-diffusion), [OSEDiff](https://github.com/cswry/OSEDiff) ë° [PiSA-SR](https://github.com/csslc/PiSA-SR)ì„ ê¸°ë°˜ìœ¼ë¡œ í•©ë‹ˆë‹¤. í›Œë¥­í•œ ì‘ì—…ì— ê°ì‚¬ë“œë¦½ë‹ˆë‹¤.

<details>
<summary>í†µê³„</summary>

![ë°©ë¬¸ì](https://visitor-badge.laobi.icu/badge?page_id=Joyies/TVT)

</details>



---

Tranlated By [Open Ai Tx](https://github.com/OpenAiTx/OpenAiTx) | Last indexed: 2026-02-22

---