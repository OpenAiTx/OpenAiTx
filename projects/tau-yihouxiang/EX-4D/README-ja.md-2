{
  "id": 2,
  "origin": "\n| Method | FID (Extreme) â†“ | FVD (Extreme) â†“ | VBench Score â†‘ |\n|--------|-----------------|-----------------|----------------|\n| ReCamMaster | 64.68 | 943.45 | 0.434 |\n| TrajectoryCrafter | 65.33 | 893.80 | 0.447 |\n| TrajectoryAttention | 62.49 | 912.14 | 0.389 |\n| **EX-4D (Ours)** | **55.42** | **823.61** | **0.450** | -->\n\n### User Study Results\n\n- **70.7%** of participants preferred EX-4D over baseline methods\n- Superior performance in physical consistency and extreme viewpoint quality\n- Significant improvement as camera angles become more extreme\n\n\n## ğŸ¯ Applications\n\n- **ğŸ® Gaming**: Create immersive 3D game cinematics from 2D footage\n- **ğŸ¬ Film Production**: Generate novel camera angles for post-production\n- **ğŸ¥½ VR/AR**: Create free-viewpoint video experiences\n- **ğŸ“± Social Media**: Generate dynamic camera movements for content creation\n- **ğŸ¢ Architecture**: Visualize spaces from multiple viewpoints\n\n<!-- ## ğŸ“ˆ Benchmarks -->\n\n<!-- ### Viewpoint Range Evaluation\n\n| Range | Small (0Â°â†’30Â°) | Large (0Â°â†’60Â°) | Extreme (0Â°â†’90Â°) | Full (-90Â°â†’90Â°) |\n|-------|----------------|----------------|------------------|-----------------|\n| FID Score | 44.19 | 50.30 | 55.42 | - |\n| Performance Gap | +9.1% better | +8.9% better | +11.3% better | +15.5% better | -->\n\n<!-- *Performance gap compared to the second-best method in each category.* -->\n\n## âš ï¸ Limitations\n\n- **Depth Dependency**: Performance relies on monocular depth estimation quality\n- **Computational Cost**: Requires significant computation for high-resolution videos\n- **Reflective Surfaces**: Challenges with reflective or transparent materials\n\n## ğŸ”® Future Work\n- [ ] Real-time inference optimization (3DGS / 4DGS)\n- [ ] Support for higher resolutions (1K, 2K)\n- [ ] Neural mesh refinement techniques\n\n## ğŸ™ Acknowledgments\n\nWe would like to thank the [DiffSynth-Studio v1.1.1](https://github.com/modelscope/DiffSynth-Studio/tree/v1.1.1) project for providing the foundational diffusion framework.\n\n## ğŸ“š Citation\n\nIf you find our work useful, please consider citing:\n\n```bibtex\n@misc{hu2025ex4dextremeviewpoint4d,\n      title={EX-4D: EXtreme Viewpoint 4D Video Synthesis via Depth Watertight Mesh}, \n      author={Tao Hu and Haoyang Peng and Xiao Liu and Yuewen Ma},\n      year={2025},\n      eprint={2506.05554},\n      archivePrefix={arXiv},\n      primaryClass={cs.CV},\n      url={https://arxiv.org/abs/2506.05554}, \n}\n```\n",
  "origin_sha": "MqODIYJGtSeyW7gMiMBJ9jTkV4ymtK2QYcLxg6W8I6k=",
  "translate": "| æ‰‹æ³• | FIDï¼ˆExtremeï¼‰â†“ | FVDï¼ˆExtremeï¼‰â†“ | VBench ã‚¹ã‚³ã‚¢ â†‘ |\n|--------|-----------------|-----------------|----------------|\n| ReCamMaster | 64.68 | 943.45 | 0.434 |\n| TrajectoryCrafter | 65.33 | 893.80 | 0.447 |\n| TrajectoryAttention | 62.49 | 912.14 | 0.389 |\n| **EX-4Dï¼ˆæœ¬ç ”ç©¶ï¼‰** | **55.42** | **823.61** | **0.450** | -->\n\n### ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¹ã‚¿ãƒ‡ã‚£çµæœ\n\n- å‚åŠ è€…ã®**70.7%**ãŒãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ‰‹æ³•ã‚ˆã‚Šã‚‚EX-4Dã‚’é¸æŠ\n- ç‰©ç†çš„ä¸€è²«æ€§ãŠã‚ˆã³æ¥µç«¯è¦–ç‚¹ã§ã®å“è³ªã§å„ªã‚ŒãŸæ€§èƒ½\n- ã‚«ãƒ¡ãƒ©ã‚¢ãƒ³ã‚°ãƒ«ãŒã‚ˆã‚Šæ¥µç«¯ã«ãªã‚‹ã»ã©é¡•è‘—ãªæ”¹å–„\n\n## ğŸ¯ å¿œç”¨ä¾‹\n\n- **ğŸ® ã‚²ãƒ¼ãƒ **: 2Dæ˜ åƒã‹ã‚‰æ²¡å…¥æ„Ÿã®ã‚ã‚‹3Dã‚²ãƒ¼ãƒ ã‚·ãƒãƒãƒ†ã‚£ã‚¯ã‚¹ã‚’ç”Ÿæˆ\n- **ğŸ¬ æ˜ ç”»åˆ¶ä½œ**: ãƒã‚¹ãƒˆãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³ç”¨ã®æ–°è¦ã‚«ãƒ¡ãƒ©ã‚¢ãƒ³ã‚°ãƒ«ç”Ÿæˆ\n- **ğŸ¥½ VR/AR**: ãƒ•ãƒªãƒ¼ãƒ“ãƒ¥ãƒ¼ãƒã‚¤ãƒ³ãƒˆãƒ“ãƒ‡ã‚ªä½“é¨“ã®å‰µå‡º\n- **ğŸ“± ã‚½ãƒ¼ã‚·ãƒ£ãƒ«ãƒ¡ãƒ‡ã‚£ã‚¢**: ã‚³ãƒ³ãƒ†ãƒ³ãƒ„åˆ¶ä½œå‘ã‘ã®ãƒ€ã‚¤ãƒŠãƒŸãƒƒã‚¯ãªã‚«ãƒ¡ãƒ©å‹•ä½œç”Ÿæˆ\n- **ğŸ¢ å»ºç¯‰**: è¤‡æ•°è¦–ç‚¹ã‹ã‚‰ã®ç©ºé–“å¯è¦–åŒ–\n\n<!-- ## ğŸ“ˆ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ -->\n\n<!-- ### è¦–ç‚¹ç¯„å›²è©•ä¾¡\n\n| ç¯„å›² | å°ï¼ˆ0Â°â†’30Â°ï¼‰ | å¤§ï¼ˆ0Â°â†’60Â°ï¼‰ | æ¥µç«¯ï¼ˆ0Â°â†’90Â°ï¼‰ | ãƒ•ãƒ«ï¼ˆ-90Â°â†’90Â°ï¼‰ |\n|-------|----------------|----------------|------------------|-----------------|\n| FID ã‚¹ã‚³ã‚¢ | 44.19 | 50.30 | 55.42 | - |\n| æ€§èƒ½å·® | +9.1% å‘ä¸Š | +8.9% å‘ä¸Š | +11.3% å‘ä¸Š | +15.5% å‘ä¸Š | -->\n\n<!-- *å„ã‚«ãƒ†ã‚´ãƒªã§2ç•ªç›®ã«å„ªã‚ŒãŸæ‰‹æ³•ã¨ã®æ¯”è¼ƒã«ã‚ˆã‚‹æ€§èƒ½å·®ã€‚* -->\n\n## âš ï¸ åˆ¶é™äº‹é …\n\n- **æ·±åº¦ä¾å­˜**: ãƒ¢ãƒã‚­ãƒ¥ãƒ©ãƒ¼æ·±åº¦æ¨å®šã®å“è³ªã«æ€§èƒ½ãŒä¾å­˜\n- **è¨ˆç®—ã‚³ã‚¹ãƒˆ**: é«˜è§£åƒåº¦ãƒ“ãƒ‡ã‚ªã«ã¯å¤šå¤§ãªè¨ˆç®—è³‡æºã‚’å¿…è¦ã¨ã™ã‚‹\n- **åå°„é¢**: åå°„æ€§ã‚„é€æ˜ãªç´ æã®å‡¦ç†ã«èª²é¡Œ\n\n## ğŸ”® ä»Šå¾Œã®èª²é¡Œ\n- [ ] ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¨è«–ã®æœ€é©åŒ–ï¼ˆ3DGS / 4DGSï¼‰\n- [ ] ã‚ˆã‚Šé«˜è§£åƒåº¦ï¼ˆ1K, 2Kï¼‰å¯¾å¿œ\n- [ ] ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒ¡ãƒƒã‚·ãƒ¥ãƒªãƒ•ã‚¡ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆæŠ€è¡“ã®å°å…¥\n\n## ğŸ™ è¬è¾\n\n[DiffSynth-Studio v1.1.1](https://github.com/modelscope/DiffSynth-Studio/tree/v1.1.1) ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«ã€åŸºç›¤ã¨ãªã‚‹æ‹¡æ•£ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã®æä¾›ã«æ„Ÿè¬ã„ãŸã—ã¾ã™ã€‚\n\n## ğŸ“š å¼•ç”¨\n\næœ¬ç ”ç©¶ãŒæœ‰ç”¨ã§ã‚ã‚Œã°ã€ä»¥ä¸‹ã®ã‚ˆã†ã«å¼•ç”¨ã—ã¦ãã ã•ã„ï¼š\n\n```bibtex\n@misc{hu2025ex4dextremeviewpoint4d,\n      title={EX-4D: EXtreme Viewpoint 4D Video Synthesis via Depth Watertight Mesh}, \n      author={Tao Hu and Haoyang Peng and Xiao Liu and Yuewen Ma},\n      year={2025},\n      eprint={2506.05554},\n      archivePrefix={arXiv},\n      primaryClass={cs.CV},\n      url={https://arxiv.org/abs/2506.05554}, \n}\n```",
  "status": "ok"
}