{
  "id": 2,
  "origin": "\n| Method | FID (Extreme) ↓ | FVD (Extreme) ↓ | VBench Score ↑ |\n|--------|-----------------|-----------------|----------------|\n| ReCamMaster | 64.68 | 943.45 | 0.434 |\n| TrajectoryCrafter | 65.33 | 893.80 | 0.447 |\n| TrajectoryAttention | 62.49 | 912.14 | 0.389 |\n| **EX-4D (Ours)** | **55.42** | **823.61** | **0.450** | -->\n\n### User Study Results\n\n- **70.7%** of participants preferred EX-4D over baseline methods\n- Superior performance in physical consistency and extreme viewpoint quality\n- Significant improvement as camera angles become more extreme\n\n\n## 🎯 Applications\n\n- **🎮 Gaming**: Create immersive 3D game cinematics from 2D footage\n- **🎬 Film Production**: Generate novel camera angles for post-production\n- **🥽 VR/AR**: Create free-viewpoint video experiences\n- **📱 Social Media**: Generate dynamic camera movements for content creation\n- **🏢 Architecture**: Visualize spaces from multiple viewpoints\n\n<!-- ## 📈 Benchmarks -->\n\n<!-- ### Viewpoint Range Evaluation\n\n| Range | Small (0°→30°) | Large (0°→60°) | Extreme (0°→90°) | Full (-90°→90°) |\n|-------|----------------|----------------|------------------|-----------------|\n| FID Score | 44.19 | 50.30 | 55.42 | - |\n| Performance Gap | +9.1% better | +8.9% better | +11.3% better | +15.5% better | -->\n\n<!-- *Performance gap compared to the second-best method in each category.* -->\n\n## ⚠️ Limitations\n\n- **Depth Dependency**: Performance relies on monocular depth estimation quality\n- **Computational Cost**: Requires significant computation for high-resolution videos\n- **Reflective Surfaces**: Challenges with reflective or transparent materials\n\n## 🔮 Future Work\n- [ ] Real-time inference optimization (3DGS / 4DGS)\n- [ ] Support for higher resolutions (1K, 2K)\n- [ ] Neural mesh refinement techniques\n\n## 🙏 Acknowledgments\n\nWe would like to thank the [DiffSynth-Studio v1.1.1](https://github.com/modelscope/DiffSynth-Studio/tree/v1.1.1) project for providing the foundational diffusion framework.\n\n## 📚 Citation\n\nIf you find our work useful, please consider citing:\n\n```bibtex\n@misc{hu2025ex4dextremeviewpoint4d,\n      title={EX-4D: EXtreme Viewpoint 4D Video Synthesis via Depth Watertight Mesh}, \n      author={Tao Hu and Haoyang Peng and Xiao Liu and Yuewen Ma},\n      year={2025},\n      eprint={2506.05554},\n      archivePrefix={arXiv},\n      primaryClass={cs.CV},\n      url={https://arxiv.org/abs/2506.05554}, \n}\n```\n",
  "origin_sha": "MqODIYJGtSeyW7gMiMBJ9jTkV4ymtK2QYcLxg6W8I6k=",
  "translate": "| روش | FID (اکستریم) ↓ | FVD (اکستریم) ↓ | امتیاز VBench ↑ |\n|--------|-----------------|-----------------|----------------|\n| ReCamMaster | ۶۴.۶۸ | ۹۴۳.۴۵ | ۰.۴۳۴ |\n| TrajectoryCrafter | ۶۵.۳۳ | ۸۹۳.۸۰ | ۰.۴۴۷ |\n| TrajectoryAttention | ۶۲.۴۹ | ۹۱۲.۱۴ | ۰.۳۸۹ |\n| **EX-4D (مال ما)** | **۵۵.۴۲** | **۸۲۳.۶۱** | **۰.۴۵۰** | -->\n\n### نتایج مطالعه کاربری\n\n- **۷۰.۷٪** از شرکت‌کنندگان EX-4D را نسبت به روش‌های پایه ترجیح دادند\n- عملکرد برتر در سازگاری فیزیکی و کیفیت نماهای دید افراطی\n- بهبود قابل توجه با افراطی‌تر شدن زوایای دوربین\n\n\n## 🎯 کاربردها\n\n- **🎮 بازی‌سازی**: ساخت سینماتیک‌های سه‌بعدی جذاب از ویدئوهای دوبعدی\n- **🎬 تولید فیلم**: تولید زوایای جدید دوربین برای پس‌تولید\n- **🥽 واقعیت مجازی/افزوده**: ایجاد تجربه ویدئویی با زاویه دید آزاد\n- **📱 شبکه‌های اجتماعی**: تولید حرکات پویا برای ساخت محتوا\n- **🏢 معماری**: نمایش فضاها از دیدگاه‌های مختلف\n\n<!-- ## 📈 بنچمارک‌ها -->\n\n<!-- ### ارزیابی بازه زاویه دید\n\n| بازه | کوچک (۰°→۳۰°) | بزرگ (۰°→۶۰°) | اکستریم (۰°→۹۰°) | کامل (-۹۰°→۹۰°) |\n|-------|----------------|----------------|------------------|-----------------|\n| امتیاز FID | ۴۴.۱۹ | ۵۰.۳۰ | ۵۵.۴۲ | - |\n| فاصله عملکرد | +۹.۱٪ بهتر | +۸.۹٪ بهتر | +۱۱.۳٪ بهتر | +۱۵.۵٪ بهتر | -->\n\n<!-- *فاصله عملکرد نسبت به دومین روش برتر در هر دسته.* -->\n\n## ⚠️ محدودیت‌ها\n\n- **وابستگی به عمق**: عملکرد وابسته به کیفیت برآورد عمق تک‌چشمی است\n- **هزینه محاسباتی**: نیازمند محاسبات قابل توجه برای ویدئوهای با وضوح بالا\n- **سطوح بازتابنده**: چالش در مواد بازتابنده یا شفاف\n\n## 🔮 کارهای آینده\n- [ ] بهینه‌سازی استنتاج بلادرنگ (۳DGS / 4DGS)\n- [ ] پشتیبانی از وضوح‌های بالاتر (۱K، ۲K)\n- [ ] تکنیک‌های بهبود مش عصبی\n\n## 🙏 تقدیر و تشکر\n\nاز پروژه [DiffSynth-Studio v1.1.1](https://github.com/modelscope/DiffSynth-Studio/tree/v1.1.1) بابت فراهم کردن چارچوب دیفیوژن پایه سپاسگزاریم.\n\n## 📚 ارجاع\n\nاگر این پژوهش برای شما مفید بود، لطفاً استناد نمایید:\n\n```bibtex\n@misc{hu2025ex4dextremeviewpoint4d,\n      title={EX-4D: EXtreme Viewpoint 4D Video Synthesis via Depth Watertight Mesh}, \n      author={Tao Hu and Haoyang Peng and Xiao Liu and Yuewen Ma},\n      year={2025},\n      eprint={2506.05554},\n      archivePrefix={arXiv},\n      primaryClass={cs.CV},\n      url={https://arxiv.org/abs/2506.05554}, \n}\n```",
  "status": "ok"
}