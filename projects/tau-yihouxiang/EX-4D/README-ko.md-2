{
  "id": 2,
  "origin": "\n| Method | FID (Extreme) â†“ | FVD (Extreme) â†“ | VBench Score â†‘ |\n|--------|-----------------|-----------------|----------------|\n| ReCamMaster | 64.68 | 943.45 | 0.434 |\n| TrajectoryCrafter | 65.33 | 893.80 | 0.447 |\n| TrajectoryAttention | 62.49 | 912.14 | 0.389 |\n| **EX-4D (Ours)** | **55.42** | **823.61** | **0.450** | -->\n\n### User Study Results\n\n- **70.7%** of participants preferred EX-4D over baseline methods\n- Superior performance in physical consistency and extreme viewpoint quality\n- Significant improvement as camera angles become more extreme\n\n\n## ğŸ¯ Applications\n\n- **ğŸ® Gaming**: Create immersive 3D game cinematics from 2D footage\n- **ğŸ¬ Film Production**: Generate novel camera angles for post-production\n- **ğŸ¥½ VR/AR**: Create free-viewpoint video experiences\n- **ğŸ“± Social Media**: Generate dynamic camera movements for content creation\n- **ğŸ¢ Architecture**: Visualize spaces from multiple viewpoints\n\n<!-- ## ğŸ“ˆ Benchmarks -->\n\n<!-- ### Viewpoint Range Evaluation\n\n| Range | Small (0Â°â†’30Â°) | Large (0Â°â†’60Â°) | Extreme (0Â°â†’90Â°) | Full (-90Â°â†’90Â°) |\n|-------|----------------|----------------|------------------|-----------------|\n| FID Score | 44.19 | 50.30 | 55.42 | - |\n| Performance Gap | +9.1% better | +8.9% better | +11.3% better | +15.5% better | -->\n\n<!-- *Performance gap compared to the second-best method in each category.* -->\n\n## âš ï¸ Limitations\n\n- **Depth Dependency**: Performance relies on monocular depth estimation quality\n- **Computational Cost**: Requires significant computation for high-resolution videos\n- **Reflective Surfaces**: Challenges with reflective or transparent materials\n\n## ğŸ”® Future Work\n- [ ] Real-time inference optimization (3DGS / 4DGS)\n- [ ] Support for higher resolutions (1K, 2K)\n- [ ] Neural mesh refinement techniques\n\n## ğŸ™ Acknowledgments\n\nWe would like to thank the [DiffSynth-Studio v1.1.1](https://github.com/modelscope/DiffSynth-Studio/tree/v1.1.1) project for providing the foundational diffusion framework.\n\n## ğŸ“š Citation\n\nIf you find our work useful, please consider citing:\n\n```bibtex\n@misc{hu2025ex4dextremeviewpoint4d,\n      title={EX-4D: EXtreme Viewpoint 4D Video Synthesis via Depth Watertight Mesh}, \n      author={Tao Hu and Haoyang Peng and Xiao Liu and Yuewen Ma},\n      year={2025},\n      eprint={2506.05554},\n      archivePrefix={arXiv},\n      primaryClass={cs.CV},\n      url={https://arxiv.org/abs/2506.05554}, \n}\n```\n",
  "origin_sha": "MqODIYJGtSeyW7gMiMBJ9jTkV4ymtK2QYcLxg6W8I6k=",
  "translate": "| Method | FID (Extreme) â†“ | FVD (Extreme) â†“ | VBench Score â†‘ |\n|--------|-----------------|-----------------|----------------|\n| ReCamMaster | 64.68 | 943.45 | 0.434 |\n| TrajectoryCrafter | 65.33 | 893.80 | 0.447 |\n| TrajectoryAttention | 62.49 | 912.14 | 0.389 |\n| **EX-4D (Ours)** | **55.42** | **823.61** | **0.450** | -->\n\n### ì‚¬ìš©ì ì—°êµ¬ ê²°ê³¼\n\n- ì°¸ê°€ìì˜ **70.7%**ê°€ EX-4Dë¥¼ ê¸°ì¡´ ë°©ë²•ë³´ë‹¤ ì„ í˜¸í•¨\n- ë¬¼ë¦¬ì  ì¼ê´€ì„±ê³¼ ê·¹ë‹¨ì  ì‹œì  í’ˆì§ˆì—ì„œ ìš°ìˆ˜í•œ ì„±ëŠ¥\n- ì¹´ë©”ë¼ ì•µê¸€ì´ ë” ê·¹ë‹¨ì ìœ¼ë¡œ ë³€í• ìˆ˜ë¡ ìœ ì˜ë¯¸í•œ ì„±ëŠ¥ í–¥ìƒ\n\n\n## ğŸ¯ ì‘ìš© ë¶„ì•¼\n\n- **ğŸ® ê²Œì„**: 2D ì˜ìƒì—ì„œ ëª°ì…í˜• 3D ê²Œì„ ì‹œë„¤ë§ˆí‹± ìƒì„±\n- **ğŸ¬ ì˜í™” ì œì‘**: í›„ë°˜ ì œì‘ì„ ìœ„í•œ ìƒˆë¡œìš´ ì¹´ë©”ë¼ ì‹œì  ìƒì„±\n- **ğŸ¥½ VR/AR**: ììœ  ì‹œì  ë¹„ë””ì˜¤ ê²½í—˜ ì œê³µ\n- **ğŸ“± ì†Œì…œ ë¯¸ë””ì–´**: ì½˜í…ì¸  ì œì‘ì„ ìœ„í•œ ë™ì ì¸ ì¹´ë©”ë¼ ë¬´ë¹™ ìƒì„±\n- **ğŸ¢ ê±´ì¶•**: ë‹¤ì–‘í•œ ì‹œì ì—ì„œ ê³µê°„ ì‹œê°í™”\n\n<!-- ## ğŸ“ˆ Benchmarks -->\n\n<!-- ### Viewpoint Range Evaluation\n\n| Range | Small (0Â°â†’30Â°) | Large (0Â°â†’60Â°) | Extreme (0Â°â†’90Â°) | Full (-90Â°â†’90Â°) |\n|-------|----------------|----------------|------------------|-----------------|\n| FID Score | 44.19 | 50.30 | 55.42 | - |\n| Performance Gap | +9.1% better | +8.9% better | +11.3% better | +15.5% better | -->\n\n<!-- *Performance gap compared to the second-best method in each category.* -->\n\n## âš ï¸ í•œê³„ì \n\n- **ê¹Šì´ ì˜ì¡´ì„±**: ë‹¨ì•ˆ ê¹Šì´ ì¶”ì • í’ˆì§ˆì— ë”°ë¼ ì„±ëŠ¥ì´ ì¢Œìš°ë¨\n- **ì—°ì‚° ë¹„ìš©**: ê³ í•´ìƒë„ ë¹„ë””ì˜¤ ì²˜ë¦¬ ì‹œ ìƒë‹¹í•œ ì—°ì‚° ìì› í•„ìš”\n- **ë°˜ì‚¬ë©´**: ë°˜ì‚¬ ë˜ëŠ” íˆ¬ëª…í•œ ì†Œì¬ì—ì„œëŠ” ì–´ë ¤ì›€ ë°œìƒ\n\n## ğŸ”® í–¥í›„ ì—°êµ¬ ë°©í–¥\n- [ ] ì‹¤ì‹œê°„ ì¶”ë¡  ìµœì í™” (3DGS / 4DGS)\n- [ ] ê³ í•´ìƒë„(1K, 2K) ì§€ì›\n- [ ] ì‹ ê²½ë§ ë©”ì‹œ ì •ì œ ê¸°ë²•\n\n## ğŸ™ ê°ì‚¬ì˜ ë§ì”€\n\nê¸°ì´ˆì ì¸ ë””í“¨ì „ í”„ë ˆì„ì›Œí¬ë¥¼ ì œê³µí•´ì£¼ì‹  [DiffSynth-Studio v1.1.1](https://github.com/modelscope/DiffSynth-Studio/tree/v1.1.1) í”„ë¡œì íŠ¸ì— ê°ì‚¬ë“œë¦½ë‹ˆë‹¤.\n\n## ğŸ“š ì¸ìš©\n\në³¸ ì—°êµ¬ê°€ ìœ ìš©í•˜ë‹¤ë©´, ì•„ë˜ì™€ ê°™ì´ ì¸ìš©í•´ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤:\n\n```bibtex\n@misc{hu2025ex4dextremeviewpoint4d,\n      title={EX-4D: EXtreme Viewpoint 4D Video Synthesis via Depth Watertight Mesh}, \n      author={Tao Hu and Haoyang Peng and Xiao Liu and Yuewen Ma},\n      year={2025},\n      eprint={2506.05554},\n      archivePrefix={arXiv},\n      primaryClass={cs.CV},\n      url={https://arxiv.org/abs/2506.05554}, \n}\n```",
  "status": "ok"
}