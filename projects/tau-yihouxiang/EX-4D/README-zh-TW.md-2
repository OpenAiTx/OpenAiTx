{
  "id": 2,
  "origin": "\n| Method | FID (Extreme) â†“ | FVD (Extreme) â†“ | VBench Score â†‘ |\n|--------|-----------------|-----------------|----------------|\n| ReCamMaster | 64.68 | 943.45 | 0.434 |\n| TrajectoryCrafter | 65.33 | 893.80 | 0.447 |\n| TrajectoryAttention | 62.49 | 912.14 | 0.389 |\n| **EX-4D (Ours)** | **55.42** | **823.61** | **0.450** | -->\n\n### User Study Results\n\n- **70.7%** of participants preferred EX-4D over baseline methods\n- Superior performance in physical consistency and extreme viewpoint quality\n- Significant improvement as camera angles become more extreme\n\n\n## ğŸ¯ Applications\n\n- **ğŸ® Gaming**: Create immersive 3D game cinematics from 2D footage\n- **ğŸ¬ Film Production**: Generate novel camera angles for post-production\n- **ğŸ¥½ VR/AR**: Create free-viewpoint video experiences\n- **ğŸ“± Social Media**: Generate dynamic camera movements for content creation\n- **ğŸ¢ Architecture**: Visualize spaces from multiple viewpoints\n\n<!-- ## ğŸ“ˆ Benchmarks -->\n\n<!-- ### Viewpoint Range Evaluation\n\n| Range | Small (0Â°â†’30Â°) | Large (0Â°â†’60Â°) | Extreme (0Â°â†’90Â°) | Full (-90Â°â†’90Â°) |\n|-------|----------------|----------------|------------------|-----------------|\n| FID Score | 44.19 | 50.30 | 55.42 | - |\n| Performance Gap | +9.1% better | +8.9% better | +11.3% better | +15.5% better | -->\n\n<!-- *Performance gap compared to the second-best method in each category.* -->\n\n## âš ï¸ Limitations\n\n- **Depth Dependency**: Performance relies on monocular depth estimation quality\n- **Computational Cost**: Requires significant computation for high-resolution videos\n- **Reflective Surfaces**: Challenges with reflective or transparent materials\n\n## ğŸ”® Future Work\n- [ ] Real-time inference optimization (3DGS / 4DGS)\n- [ ] Support for higher resolutions (1K, 2K)\n- [ ] Neural mesh refinement techniques\n\n## ğŸ™ Acknowledgments\n\nWe would like to thank the [DiffSynth-Studio v1.1.1](https://github.com/modelscope/DiffSynth-Studio/tree/v1.1.1) project for providing the foundational diffusion framework.\n\n## ğŸ“š Citation\n\nIf you find our work useful, please consider citing:\n\n```bibtex\n@misc{hu2025ex4dextremeviewpoint4d,\n      title={EX-4D: EXtreme Viewpoint 4D Video Synthesis via Depth Watertight Mesh}, \n      author={Tao Hu and Haoyang Peng and Xiao Liu and Yuewen Ma},\n      year={2025},\n      eprint={2506.05554},\n      archivePrefix={arXiv},\n      primaryClass={cs.CV},\n      url={https://arxiv.org/abs/2506.05554}, \n}\n```\n",
  "origin_sha": "MqODIYJGtSeyW7gMiMBJ9jTkV4ymtK2QYcLxg6W8I6k=",
  "translate": "| æ–¹æ³• | FID (æ¥µç«¯) â†“ | FVD (æ¥µç«¯) â†“ | VBench åˆ†æ•¸ â†‘ |\n|--------|-----------------|-----------------|----------------|\n| ReCamMaster | 64.68 | 943.45 | 0.434 |\n| TrajectoryCrafter | 65.33 | 893.80 | 0.447 |\n| TrajectoryAttention | 62.49 | 912.14 | 0.389 |\n| **EX-4D (æœ¬è«–æ–‡)** | **55.42** | **823.61** | **0.450** | -->\n\n### ä½¿ç”¨è€…ç ”ç©¶çµæœ\n\n- **70.7%** çš„åƒèˆ‡è€…æ›´åå¥½ EX-4D ç›¸è¼ƒæ–¼åŸºç·šæ–¹æ³•\n- åœ¨ç‰©ç†ä¸€è‡´æ€§åŠæ¥µç«¯è¦–è§’å“è³ªä¸Šè¡¨ç¾æ›´å„ªç•°\n- éš¨è‘—é¡é ­è§’åº¦è¶Šæ¥µç«¯ï¼Œæ”¹å–„å¹…åº¦æ›´é¡¯è‘—\n\n\n## ğŸ¯ æ‡‰ç”¨å ´æ™¯\n\n- **ğŸ® éŠæˆ²**ï¼šå¾ 2D å½±åƒå‰µå»ºæ²‰æµ¸å¼ 3D éŠæˆ²å‹•ç•«\n- **ğŸ¬ é›»å½±è£½ä½œ**ï¼šç‚ºå¾ŒæœŸè£½ä½œç”Ÿæˆæ–°ç©çš„é¡é ­è§’åº¦\n- **ğŸ¥½ VR/AR**ï¼šå‰µå»ºè‡ªç”±è¦–è§’çš„å½±åƒé«”é©—\n- **ğŸ“± ç¤¾ç¾¤åª’é«”**ï¼šç‚ºå…§å®¹å‰µä½œç”Ÿæˆå‹•æ…‹é¡é ­é‹å‹•\n- **ğŸ¢ å»ºç¯‰**ï¼šå¾å¤šå€‹è¦–è§’å¯è¦–åŒ–ç©ºé–“\n\n<!-- ## ğŸ“ˆ åŸºæº–æ¸¬è©¦ -->\n\n<!-- ### è¦–è§’ç¯„åœè©•ä¼°\n\n| ç¯„åœ | å° (0Â°â†’30Â°) | å¤§ (0Â°â†’60Â°) | æ¥µç«¯ (0Â°â†’90Â°) | å…¨åŸŸ (-90Â°â†’90Â°) |\n|-------|----------------|----------------|------------------|-----------------|\n| FID åˆ†æ•¸ | 44.19 | 50.30 | 55.42 | - |\n| æ€§èƒ½å·®è· | +9.1% æ›´ä½³ | +8.9% æ›´ä½³ | +11.3% æ›´ä½³ | +15.5% æ›´ä½³ | -->\n\n<!-- *æ€§èƒ½å·®è·ç‚ºç›¸è¼ƒæ–¼æ¯ä¸€é¡åˆ¥ä¸­ç¬¬äºŒä½³æ–¹æ³•çš„æå‡å¹…åº¦ã€‚* -->\n\n## âš ï¸ é™åˆ¶\n\n- **æ·±åº¦ä¾è³´**ï¼šæ€§èƒ½ä¾è³´æ–¼å–®ç›®æ·±åº¦ä¼°è¨ˆçš„å“è³ª\n- **è¨ˆç®—æˆæœ¬**ï¼šé«˜è§£æåº¦å½±ç‰‡éœ€å¤§é‡é‹ç®—\n- **åå…‰è¡¨é¢**ï¼šå°åå°„æˆ–é€æ˜æè³ªä»å…·æŒ‘æˆ°\n\n## ğŸ”® æœªä¾†å·¥ä½œ\n- [ ] å¯¦æ™‚æ¨ç†å„ªåŒ–ï¼ˆ3DGS / 4DGSï¼‰\n- [ ] æ”¯æ´æ›´é«˜è§£æåº¦ï¼ˆ1Kã€2Kï¼‰\n- [ ] ç¥ç¶“ç¶²æ ¼ç´°åŒ–æŠ€è¡“\n\n## ğŸ™ è‡´è¬\n\næ„Ÿè¬ [DiffSynth-Studio v1.1.1](https://github.com/modelscope/DiffSynth-Studio/tree/v1.1.1) å°ˆæ¡ˆæä¾›åŸºç¤çš„æ“´æ•£æ¡†æ¶ã€‚\n\n## ğŸ“š åƒè€ƒæ–‡ç»\n\nå¦‚æœæ‚¨è¦ºå¾—æœ¬ç ”ç©¶æœ‰å¹«åŠ©ï¼Œè«‹è€ƒæ…®å¼•ç”¨ï¼š\n\n```bibtex\n@misc{hu2025ex4dextremeviewpoint4d,\n      title={EX-4D: EXtreme Viewpoint 4D Video Synthesis via Depth Watertight Mesh}, \n      author={Tao Hu and Haoyang Peng and Xiao Liu and Yuewen Ma},\n      year={2025},\n      eprint={2506.05554},\n      archivePrefix={arXiv},\n      primaryClass={cs.CV},\n      url={https://arxiv.org/abs/2506.05554}, \n}\n```",
  "status": "ok"
}