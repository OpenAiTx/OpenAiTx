{
  "id": 1,
  "origin": "# EX-4D: EXtreme Viewpoint 4D Video Synthesis via Depth Watertight Mesh\n\n<div align=\"center\">\n\n<img src=\"https://raw.githubusercontent.com/tau-yihouxiang/EX-4D/main/docs/Logo.png\" alt=\"EX-4D Logo\" width=\"250\">\n\n[📄 Paper](https://arxiv.org/abs/2506.05554)  |  [🎥 Homepage](https://tau-yihouxiang.github.io/projects/EX-4D/EX-4D.html)  |  [💻 Code](https://github.com/tau-yihouxiang/EX-4D)\n\n</div>\n\n\n\n## 🌟 Highlights\n\n- **🎯 Extreme Viewpoint Synthesis**: Generate high-quality 4D videos with camera movements ranging from -90° to 90°\n- **🔧 Depth Watertight Mesh**: Novel geometric representation that models both visible and occluded regions\n- **⚡ Lightweight Architecture**: Only 1% trainable parameters (140M) of the 14B video diffusion backbone\n- **🎭 No Multi-view Training**: Innovative masking strategy eliminates the need for expensive multi-view datasets\n- **🏆 State-of-the-art Performance**: Outperforms existing methods, especially on extreme camera angles\n\n## 🎬 Demo Results\n\n<div align=\"center\">\n<img src=\"https://raw.githubusercontent.com/tau-yihouxiang/EX-4D/main/docs/teaser.png\" alt=\"EX-4D Demo Results\" width=\"800\">\n</div>\n\n*EX-4D transforms monocular videos into camera-controllable 4D experiences with physically consistent results under extreme viewpoints.*\n\n## 🏗️ Framework Overview\n\n<div align=\"center\">\n<img src=\"https://raw.githubusercontent.com/tau-yihouxiang/EX-4D/main/docs/overview.png\" alt=\"EX-4D Architecture\">\n</div>\n\nOur framework consists of three key components:\n\n1. **🔺 Depth Watertight Mesh Construction**: Creates a robust geometric prior that explicitly models both visible and occluded regions\n2. **🎭 Simulated Masking Strategy**: Generates effective training data from monocular videos without multi-view datasets\n3. **⚙️ Lightweight LoRA Adapter**: Efficiently integrates geometric information with pre-trained video diffusion models\n\n## 🚀 Quick Start\n\n### Installation\n\n```bash\n# Clone the repository\ngit clone https://github.com/tau-yihouxiang/EX-4D.git\ncd EX-4D\n\n# Create conda environment\nconda create -n ex4d python=3.10\nconda activate ex4d\n# Install PyTorch (2.x recommended)\npip install torch==2.4.1 torchvision==0.19.1 torchaudio==2.4.1 --index-url https://download.pytorch.org/whl/cu124\n# Install Nvdiffrast\npip install git+https://github.com/NVlabs/nvdiffrast.git\n# Install dependencies and diffsynth\npip install -e .\n# Install depthcrafter for depth estimation. (Follow DepthCrafter's installing instruction for checkpoints preparation.)\ngit clone https://github.com/Tencent/DepthCrafter.git\n```\n\n### Download Pretrained Model\n```bash\nhuggingface-cli download Wan-AI/Wan2.1-I2V-14B-480P --local-dir ./models/Wan-AI\nhuggingface-cli download yihouxiang/EX-4D --local-dir ./models/EX-4D\n```\n\n### Example Usage\n#### 1. DW-Mesh Reconstruction\n```bash\n# --cam 180 (30 / 60 / 90 / zoom_in / zoom_out )\npython recon.py --input_video examples/flower/input.mp4 --cam 180 --output_dir outputs/flower --save_mesh\n```\n#### 2. EX-4D Generation (48GB VRAM required)\n```bash\npython generate.py --color_video outputs/flower/color_180.mp4 --mask_video outputs/flower/mask_180.mp4 --output_video outputs/flower/output.mp4\n```\n\n<table>\n<tr>\n<td width=\"45%\" align=\"center\">\n<img src=\"https://raw.githubusercontent.com/tau-yihouxiang/EX-4D/main/examples/flower/input.gif\" width=\"100%\">\n<br><b>Input Video</b>\n</td>\n<td align=\"center\">\n<div style=\"font-size: 2em; color: #4A90E2; padding: 0 0px;\">\n  ➜\n</div>\n</td>\n<td width=\"45%\" align=\"center\">\n<img src=\"https://raw.githubusercontent.com/tau-yihouxiang/EX-4D/main/examples/flower/output.gif\" width=\"100%\">\n<br><b>Output Video</b>\n</td>\n</tr> \n</table>\n\n<!-- ## 📊 Performance\n\n### Quantitative Results",
  "origin_sha": "z/SjAGRVytkbxDboQkPKdL4sDyxhY8jlopCaz23Kuro=",
  "translate": "# EX-4D: 깊이 워터타이트 메시를 통한 익스트림 시점 4D 비디오 합성\n\n<div align=\"center\">\n\n<img src=\"https://raw.githubusercontent.com/tau-yihouxiang/EX-4D/main/docs/Logo.png\" alt=\"EX-4D Logo\" width=\"250\">\n\n[📄 논문](https://arxiv.org/abs/2506.05554)  |  [🎥 홈페이지](https://tau-yihouxiang.github.io/projects/EX-4D/EX-4D.html)  |  [💻 코드](https://github.com/tau-yihouxiang/EX-4D)\n\n</div>\n\n\n\n## 🌟 하이라이트\n\n- **🎯 익스트림 시점 합성**: -90°에서 90°까지의 카메라 이동으로 고품질 4D 비디오 생성\n- **🔧 깊이 워터타이트 메시**: 가시 영역과 가려진 영역 모두를 모델링하는 새로운 기하학적 표현\n- **⚡ 경량화된 아키텍처**: 14B 비디오 디퓨전 백본의 1%인 1억 4천만 개의 학습 가능 파라미터만 사용\n- **🎭 멀티뷰 학습 불필요**: 혁신적인 마스킹 전략으로 고가의 멀티뷰 데이터셋 없이 학습 가능\n- **🏆 최첨단 성능**: 기존 방법 대비 특히 극단적 카메라 각도에서 더 우수한 성능 제공\n\n## 🎬 데모 결과\n\n<div align=\"center\">\n<img src=\"https://raw.githubusercontent.com/tau-yihouxiang/EX-4D/main/docs/teaser.png\" alt=\"EX-4D Demo Results\" width=\"800\">\n</div>\n\n*EX-4D는 단안 비디오를 물리적으로 일관된 결과와 함께 카메라 제어가 가능한 4D 경험으로 변환합니다.*\n\n## 🏗️ 프레임워크 개요\n\n<div align=\"center\">\n<img src=\"https://raw.githubusercontent.com/tau-yihouxiang/EX-4D/main/docs/overview.png\" alt=\"EX-4D Architecture\">\n</div>\n\n본 프레임워크는 세 가지 주요 구성 요소로 이루어져 있습니다:\n\n1. **🔺 깊이 워터타이트 메시 구축**: 가시 영역과 가려진 영역을 모두 명시적으로 모델링하는 강력한 기하학적 프라이어 생성\n2. **🎭 시뮬레이션 마스킹 전략**: 멀티뷰 데이터셋 없이 단안 비디오에서 효과적인 학습 데이터를 생성\n3. **⚙️ 경량화된 LoRA 어댑터**: 사전 학습된 비디오 디퓨전 모델과 기하학 정보를 효율적으로 통합\n\n## 🚀 빠른 시작\n\n### 설치\n\n```bash\n# 저장소 클론\ngit clone https://github.com/tau-yihouxiang/EX-4D.git\ncd EX-4D\n\n# conda 환경 생성\nconda create -n ex4d python=3.10\nconda activate ex4d\n# PyTorch 설치 (2.x 권장)\npip install torch==2.4.1 torchvision==0.19.1 torchaudio==2.4.1 --index-url https://download.pytorch.org/whl/cu124\n# Nvdiffrast 설치\npip install git+https://github.com/NVlabs/nvdiffrast.git\n# 의존성 및 diffsynth 설치\npip install -e .\n# 깊이 추정을 위한 depthcrafter 설치 (체크포인트 준비는 DepthCrafter 설치 안내 참고)\ngit clone https://github.com/Tencent/DepthCrafter.git\n```\n\n### 사전학습 모델 다운로드\n```bash\nhuggingface-cli download Wan-AI/Wan2.1-I2V-14B-480P --local-dir ./models/Wan-AI\nhuggingface-cli download yihouxiang/EX-4D --local-dir ./models/EX-4D\n```\n\n### 사용 예시\n#### 1. DW-메시 재구성\n```bash\n# --cam 180 (30 / 60 / 90 / zoom_in / zoom_out )\npython recon.py --input_video examples/flower/input.mp4 --cam 180 --output_dir outputs/flower --save_mesh\n```\n#### 2. EX-4D 생성 (48GB VRAM 필요)\n```bash\npython generate.py --color_video outputs/flower/color_180.mp4 --mask_video outputs/flower/mask_180.mp4 --output_video outputs/flower/output.mp4\n```\n\n<table>\n<tr>\n<td width=\"45%\" align=\"center\">\n<img src=\"https://raw.githubusercontent.com/tau-yihouxiang/EX-4D/main/examples/flower/input.gif\" width=\"100%\">\n<br><b>입력 비디오</b>\n</td>\n<td align=\"center\">\n<div style=\"font-size: 2em; color: #4A90E2; padding: 0 0px;\">\n  ➜\n</div>\n</td>\n<td width=\"45%\" align=\"center\">\n<img src=\"https://raw.githubusercontent.com/tau-yihouxiang/EX-4D/main/examples/flower/output.gif\" width=\"100%\">\n<br><b>출력 비디오</b>\n</td>\n</tr> \n</table>\n\n<!-- ## 📊 Performance\n\n### Quantitative Results",
  "status": "ok"
}