# EX-4D: Synteza wideo 4D z ekstremalnych punktÃ³w widzenia za pomocÄ… szczelnej siatki gÅ‚Ä™bi

<div align="center">

<img src="https://raw.githubusercontent.com/tau-yihouxiang/EX-4D/main/docs/Logo.png" alt="EX-4D Logo" width="250">

[ğŸ“„ ArtykuÅ‚](https://arxiv.org/abs/2506.05554)  |  [ğŸ¥ Strona domowa](https://tau-yihouxiang.github.io/projects/EX-4D/EX-4D.html)  |  [ğŸ’» Kod](https://github.com/tau-yihouxiang/EX-4D)

</div>



## ğŸŒŸ NajwaÅ¼niejsze cechy

- **ğŸ¯ Synteza z ekstremalnych punktÃ³w widzenia**: Generowanie wysokiej jakoÅ›ci wideo 4D z ruchem kamery od -90Â° do 90Â°
- **ğŸ”§ Szczelna siatka gÅ‚Ä™bi**: Nowatorska reprezentacja geometryczna modelujÄ…ca zarÃ³wno widoczne, jak i zasÅ‚oniÄ™te obszary
- **âš¡ Lekka architektura**: Tylko 1% parametrÃ³w uczÄ…cych siÄ™ (140M) w stosunku do 14B gÅ‚Ã³wnego modelu dyfuzji wideo
- **ğŸ­ Bez treningu na wielu widokach**: Innowacyjna strategia maskowania eliminuje potrzebÄ™ kosztownych zestawÃ³w danych z wielu kamer
- **ğŸ† NajwyÅ¼sza jakoÅ›Ä‡**: PrzewyÅ¼sza istniejÄ…ce metody, szczegÃ³lnie przy ekstremalnych kÄ…tach kamery

## ğŸ¬ Wyniki demonstracyjne

<div align="center">
<img src="https://raw.githubusercontent.com/tau-yihouxiang/EX-4D/main/docs/teaser.png" alt="EX-4D Demo Results" width="800">
</div>

*EX-4D przeksztaÅ‚ca filmy monokularne w doÅ›wiadczenia 4D sterowane kamerÄ…, zapewniajÄ…c fizycznie spÃ³jne wyniki pod ekstremalnymi kÄ…tami widzenia.*

## ğŸ—ï¸ PrzeglÄ…d frameworku

<div align="center">
<img src="https://raw.githubusercontent.com/tau-yihouxiang/EX-4D/main/docs/overview.png" alt="EX-4D Architecture">
</div>

Nasz framework skÅ‚ada siÄ™ z trzech kluczowych komponentÃ³w:

1. **ğŸ”º Konstrukcja szczelnej siatki gÅ‚Ä™bi (Depth Watertight Mesh)**: Tworzy solidny priorytet geometryczny, ktÃ³ry jawnie modeluje zarÃ³wno widoczne, jak i ukryte obszary
2. **ğŸ­ Symulowana strategia maskowania**: Generuje skuteczne dane treningowe z filmÃ³w monokularnych bez uÅ¼ycia zestawÃ³w danych z wielu widokÃ³w
3. **âš™ï¸ Lekki adapter LoRA**: Efektywnie integruje informacje geometryczne z wytrenowanymi modelami dyfuzji wideo

## ğŸš€ Szybki start

### Instalacja

```bash
# Sklonuj repozytorium
git clone https://github.com/tau-yihouxiang/EX-4D.git
cd EX-4D

# UtwÃ³rz Å›rodowisko conda
conda create -n ex4d python=3.10
conda activate ex4d
# Zainstaluj PyTorch (zalecana wersja 2.x)
pip install torch==2.4.1 torchvision==0.19.1 torchaudio==2.4.1 --index-url https://download.pytorch.org/whl/cu124
# Zainstaluj Nvdiffrast
pip install git+https://github.com/NVlabs/nvdiffrast.git
# Zainstaluj zaleÅ¼noÅ›ci oraz diffsynth
pip install -e .
# Zainstaluj depthcrafter do estymacji gÅ‚Ä™bi. (PostÄ™puj zgodnie z instrukcjÄ… DepthCrafter dotyczÄ…cÄ… przygotowania punktÃ³w kontrolnych.)
git clone https://github.com/Tencent/DepthCrafter.git
```

### Pobierz wytrenowany model
```bash
huggingface-cli download Wan-AI/Wan2.1-I2V-14B-480P --local-dir ./models/Wan-AI
huggingface-cli download yihouxiang/EX-4D --local-dir ./models/EX-4D
```

### PrzykÅ‚ad uÅ¼ycia
#### 1. Rekonstrukcja DW-Mesh
```bash
# --cam 180 (30 / 60 / 90 / zoom_in / zoom_out )
python recon.py --input_video examples/flower/input.mp4 --cam 180 --output_dir outputs/flower --save_mesh
```
#### 2. Generowanie EX-4D (wymagane 48GB VRAM)
```bash
python generate.py --color_video outputs/flower/color_180.mp4 --mask_video outputs/flower/mask_180.mp4 --output_video outputs/flower/output.mp4
```

<table>
<tr>
<td width="45%" align="center">
<img src="https://raw.githubusercontent.com/tau-yihouxiang/EX-4D/main/examples/flower/input.gif" width="100%">
<br><b>Wideo wejÅ›ciowe</b>
</td>
<td align="center">
<div style="font-size: 2em; color: #4A90E2; padding: 0 0px;">
  âœ
</div>
</td>
<td width="45%" align="center">
<img src="https://raw.githubusercontent.com/tau-yihouxiang/EX-4D/main/examples/flower/output.gif" width="100%">
<br><b>Wideo wyjÅ›ciowe</b>
</td>
</tr> 
</table>

<!-- ## ğŸ“Š Performance

### Quantitative Results
| Metoda | FID (Ekstremalny) â†“ | FVD (Ekstremalny) â†“ | Wynik VBench â†‘ |
|--------|---------------------|---------------------|----------------|
| ReCamMaster | 64.68 | 943.45 | 0.434 |
| TrajectoryCrafter | 65.33 | 893.80 | 0.447 |
| TrajectoryAttention | 62.49 | 912.14 | 0.389 |
| **EX-4D (Nasza metoda)** | **55.42** | **823.61** | **0.450** | -->

### Wyniki badaÅ„ uÅ¼ytkownikÃ³w

- **70,7%** uczestnikÃ³w preferowaÅ‚o EX-4D wzglÄ™dem metod bazowych
- Lepsza spÃ³jnoÅ›Ä‡ fizyczna i jakoÅ›Ä‡ przy ekstremalnych kÄ…tach widzenia
- ZnaczÄ…ca poprawa wraz ze wzrostem ekstremalnoÅ›ci kÄ…tÃ³w kamery


## ğŸ¯ Zastosowania

- **ğŸ® Gry**: Tworzenie immersyjnych filmowych scen 3D na podstawie materiaÅ‚u 2D
- **ğŸ¬ Produkcja filmowa**: Generowanie nowych ujÄ™Ä‡ kamery do postprodukcji
- **ğŸ¥½ VR/AR**: Tworzenie doÅ›wiadczeÅ„ wideo z dowolnego punktu widzenia
- **ğŸ“± Media spoÅ‚ecznoÅ›ciowe**: Generowanie dynamicznych ruchÃ³w kamery do tworzenia treÅ›ci
- **ğŸ¢ Architektura**: Wizualizacja przestrzeni z wielu punktÃ³w widzenia

<!-- ## ğŸ“ˆ Benchmarki -->

<!-- ### Ocena zakresu punktÃ³w widzenia

| Zakres | MaÅ‚y (0Â°â†’30Â°) | DuÅ¼y (0Â°â†’60Â°) | Ekstremalny (0Â°â†’90Â°) | PeÅ‚ny (-90Â°â†’90Â°) |
|--------|---------------|---------------|----------------------|------------------|
| Wynik FID | 44.19 | 50.30 | 55.42 | - |
| RÃ³Å¼nica wydajnoÅ›ci | +9,1% lepiej | +8,9% lepiej | +11,3% lepiej | +15,5% lepiej | -->

<!-- *RÃ³Å¼nica wydajnoÅ›ci wzglÄ™dem drugiej najlepszej metody w kaÅ¼dej kategorii.* -->

## âš ï¸ Ograniczenia

- **ZaleÅ¼noÅ›Ä‡ od gÅ‚Ä™bi**: WydajnoÅ›Ä‡ zaleÅ¼y od jakoÅ›ci estymacji gÅ‚Ä™bi z jednego obrazu
- **Koszt obliczeniowy**: Wymaga duÅ¼ej mocy obliczeniowej dla filmÃ³w w wysokiej rozdzielczoÅ›ci
- **Powierzchnie refleksyjne**: TrudnoÅ›ci z materiaÅ‚ami odblaskowymi lub przezroczystymi

## ğŸ”® PrzyszÅ‚e prace
- [ ] Optymalizacja wnioskowania w czasie rzeczywistym (3DGS / 4DGS)
- [ ] Wsparcie dla wyÅ¼szych rozdzielczoÅ›ci (1K, 2K)
- [ ] Techniki neuronowego udoskonalania siatek (mesh refinement)

## ğŸ™ PodziÄ™kowania

ChcielibyÅ›my podziÄ™kowaÄ‡ projektowi [DiffSynth-Studio v1.1.1](https://github.com/modelscope/DiffSynth-Studio/tree/v1.1.1) za udostÄ™pnienie podstawowego frameworka dyfuzyjnego.

## ğŸ“š Cytowanie

JeÅ›li nasza praca okazaÅ‚a siÄ™ przydatna, prosimy o cytowanie:

```bibtex
@misc{hu2025ex4dextremeviewpoint4d,
      title={EX-4D: EXtreme Viewpoint 4D Video Synthesis via Depth Watertight Mesh}, 
      author={Tao Hu and Haoyang Peng and Xiao Liu and Yuewen Ma},
      year={2025},
      eprint={2506.05554},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2506.05554}, 
}
```

---

Tranlated By [Open Ai Tx](https://github.com/OpenAiTx/OpenAiTx) | Last indexed: 2025-07-08

---