# OpenDeepWiki

[‰∏≠Êñá](https://raw.githubusercontent.com/AIDotNet/OpenDeepWiki/main/README.zh-CN.md) | [English](https://raw.githubusercontent.com/AIDotNet/OpenDeepWiki/main/README.md)

<div align="center">
  <img src="https://raw.githubusercontent.com/AIDotNet/OpenDeepWiki/main/img/favicon.png" alt="OpenDeepWiki Logo" width="200" />
  <h3>Base de Connaissances de Code Pilot√©e par l‚ÄôIA</h3>
</div>

# Sponsor

[![image](https://github.com/user-attachments/assets/b1bcb56e-38cb-47bf-adfe-7a21d83774b4)](https://share.302.ai/jXcaTv)

[302.AI](https://share.302.ai/jXcaTv) est une plateforme d'application IA d'entreprise tout-en-un, √† la consommation. Elle propose une plateforme ouverte et un √©cosyst√®me open source, permettant √† l'IA de trouver des solutions √† tous les besoins. Cliquez [ici](https://share.302.ai/jXcaTv) pour obtenir votre cr√©dit gratuit de 1 $ !

## Fonctionnalit√©s

- **Conversion Rapide :** Tous les d√©p√¥ts de code Github, Gitlab, Gitee, Gitea et autres peuvent √™tre convertis en bases de connaissances en quelques minutes.
- **Support Multilingue :** L‚Äôanalyse de code et la g√©n√©ration de documentation sont prises en charge pour tous les langages de programmation.
- **Structure du Code :** Des diagrammes Mermaid automatiques sont g√©n√©r√©s pour comprendre la structure du code.
- **Mod√®les Personnalis√©s :** Les mod√®les personnalis√©s et les API personnalis√©es sont support√©s, permettant une extension selon les besoins.
- **Analyse Intelligente par IA :** Analyse de code et compr√©hension des relations dans le code gr√¢ce √† l‚ÄôIA.
- **SEO Facile :** G√©n√©rez des documents et bases de connaissances adapt√©s au SEO avec Next.js, facilitant l‚Äôindexation par les moteurs de recherche.
- **Interaction Dialogique :** Prend en charge l‚Äôinteraction dialogique avec l‚ÄôIA pour obtenir des informations d√©taill√©es et des m√©thodes d‚Äôutilisation du code, et pour comprendre en profondeur le code.

Liste des fonctionnalit√©s :
- [x] Supporte plusieurs d√©p√¥ts de code (Github, Gitlab, Gitee, Gitea, etc.)
- [x] Supporte plusieurs langages de programmation (Python, Java, C#, JavaScript, etc.)
- [x] Supporte la gestion des d√©p√¥ts, offrant des fonctions pour ajouter, supprimer, modifier et interroger les d√©p√¥ts
- [x] Supporte plusieurs fournisseurs IA (OpenAI, AzureOpenAI, Anthropic, etc.)
- [x] Supporte plusieurs bases de donn√©es (SQLite, PostgreSQL, SqlServer, etc.)
- [x] Supporte plusieurs langues (Chinois, Anglais, Fran√ßais, etc.)
- [x] Supporte le t√©l√©chargement de fichiers ZIP et de fichiers locaux
- [x] Propose une plateforme de fine-tuning des donn√©es pour g√©n√©rer des jeux de donn√©es de fine-tuning
- [x] Supporte la gestion des r√©pertoires des d√©p√¥ts, permettant la g√©n√©ration personnalis√©e de r√©pertoires et la cr√©ation dynamique de documentation
- [x] Supporte la gestion des r√©pertoires de d√©p√¥ts, permettant la modification des r√©pertoires de d√©p√¥t
- [x] Supporte la gestion au niveau utilisateur, offrant des fonctions de gestion des utilisateurs pour ajouter, supprimer, modifier et interroger les utilisateurs
- [ ] Supporte la gestion des permissions utilisateurs, offrant des fonctions de gestion des permissions pour ajouter, supprimer, modifier et interroger les permissions
- [x] Supporte la g√©n√©ration de diff√©rents jeux de donn√©es de fine-tuning au niveau du d√©p√¥t

# Pr√©sentation du Projet

OpenDeepWiki est un projet open source inspir√© par [DeepWiki](https://deepwiki.com/), d√©velopp√© avec .NET 9 et Semantic Kernel. Il vise √† aider les d√©veloppeurs √† mieux comprendre et utiliser les bases de code en fournissant des fonctionnalit√©s telles que l‚Äôanalyse de code, la g√©n√©ration de documentation et la cr√©ation de graphes de connaissances.
- Analyse de la structure du code
- Comprendre les concepts cl√©s des d√©p√¥ts
- G√©n√©rer la documentation du code
- Cr√©er automatiquement un README.md pour le code
  Prise en charge MCP

OpenDeepWiki prend en charge MCP (Model Context Protocol)
- Prend en charge la fourniture d‚Äôun MCPServer pour un seul d√©p√¥t et l‚Äôanalyse sur ce d√©p√¥t unique.

Utilisation : Voici l‚Äôutilisation du curseur :
```json
{
  "mcpServers": {
    "OpenDeepWiki":{
      "url": "http://Votre IP:port du service OpenDeepWiki/sse?owner=AIDotNet&name=OpenDeepWiki"
    }
  }
}
```
- owner : C‚Äôest le nom de l‚Äôorganisation ou du propri√©taire du d√©p√¥t.
- name : C‚Äôest le nom du d√©p√¥t.

Apr√®s avoir ajout√© le d√©p√¥t, testez en posant une question (veuillez noter qu‚Äôavant de faire cela, le d√©p√¥t doit d‚Äôabord √™tre trait√©) : Qu‚Äôest-ce qu‚ÄôOpenDeepWiki ? Le r√©sultat est illustr√© ci-dessous : ![](https://raw.githubusercontent.com/AIDotNet/OpenDeepWiki/main/img/mcp.png)

De cette mani√®re, vous pouvez utiliser OpenDeepWiki comme un MCPServer, le rendant disponible pour d‚Äôautres mod√®les IA, facilitant l‚Äôanalyse et la compr√©hension d‚Äôun projet open source.

## üöÄ D√©marrage Rapide

1. Clonez le d√©p√¥t
```bash
git clone https://github.com/AIDotNet/OpenDeepWiki.git
cd OpenDeepWiki
```

2. Ouvrez le fichier `docker-compose.yml` et modifiez les variables d‚Äôenvironnement suivantes :

Ollama :
```yaml
services:
  koalawiki:
    environment:
      - KOALAWIKI_REPOSITORIES=/repositories
      - TASK_MAX_SIZE_PER_USER=5 # Nombre maximum de t√¢ches parall√®les de g√©n√©ration de documents par utilisateur via l‚ÄôIA
      - CHAT_MODEL=qwen2.5:32b # Le mod√®le doit prendre en charge les fonctions
      - ANALYSIS_MODEL=qwen2.5:32b # Mod√®le utilis√© pour g√©n√©rer la structure du r√©pertoire du d√©p√¥t
      - CHAT_API_KEY=sk-xxxxx # Votre cl√© API
      - LANGUAGE= # D√©finir la langue par d√©faut pour la g√©n√©ration sur "Chinois"
      - ENDPOINT=https://Votre IP Ollama:Port/v1
      - DB_TYPE=sqlite
      - MODEL_PROVIDER=OpenAI # Fournisseur du mod√®le, par d√©faut OpenAI, prend en charge AzureOpenAI et Anthropic
      - DB_CONNECTION_STRING=Data Source=/data/KoalaWiki.db
      - EnableSmartFilter=true # Si le filtrage intelligent est activ√© ou non peut affecter la mani√®re dont l‚ÄôIA obtient le r√©pertoire du d√©p√¥t
      - UPDATE_INTERVAL # Intervalle de mise √† jour incr√©mentielle du d√©p√¥t, unit√© : jours
      - MAX_FILE_LIMIT=100 # Limite maximale d‚Äôenvoi de fichiers, en Mo
      - DEEP_RESEARCH_MODEL= # Recherche approfondie sur le mod√®le, utilise CHAT_MODEL si vide
      - ENABLE_INCREMENTAL_UPDATE=true # Activer ou non les mises √† jour incr√©mentielles
      - ENABLE_CODED_DEPENDENCY_ANALYSIS=false # Activer ou non l‚Äôanalyse de d√©pendance du code. Cela peut avoir un impact sur la qualit√© du code.
      - ENABLE_WAREHOUSE_FUNCTION_PROMPT_TASK=false # Activer ou non la g√©n√©ration du prompt MCP.
      - ENABLE_WAREHOUSE_DESCRIPTION_TASK=false # Activer ou non la g√©n√©ration de la Description du d√©p√¥t
```

OpenAI :
```yaml
services:
  koalawiki:
    environment:
      - KOALAWIKI_REPOSITORIES=/repositories
      - TASK_MAX_SIZE_PER_USER=5 # Nombre maximum de t√¢ches parall√®les de g√©n√©ration de documents par utilisateur via l‚ÄôIA
      - CHAT_MODEL=DeepSeek-V3 # Le mod√®le doit prendre en charge les fonctions
      - ANALYSIS_MODEL= # Mod√®le utilis√© pour g√©n√©rer la structure du r√©pertoire du d√©p√¥t
      - CHAT_API_KEY= # Votre cl√© API
      - LANGUAGE= # D√©finir la langue par d√©faut pour la g√©n√©ration sur "Chinois"
      - ENDPOINT=https://api.token-ai.cn/v1
      - DB_TYPE=sqlite
      - MODEL_PROVIDER=OpenAI # Fournisseur du mod√®le, par d√©faut OpenAI, prend en charge AzureOpenAI et Anthropic
      - DB_CONNECTION_STRING=Data Source=/data/KoalaWiki.db
      - EnableSmartFilter=true # Si le filtrage intelligent est activ√© ou non peut affecter la mani√®re dont l‚ÄôIA obtient le r√©pertoire du d√©p√¥t
      - UPDATE_INTERVAL # Intervalle de mise √† jour incr√©mentielle du d√©p√¥t, unit√© : jours
      - MAX_FILE_LIMIT=100 # Limite maximale d‚Äôenvoi de fichiers, en Mo
      - DEEP_RESEARCH_MODEL= # Recherche approfondie sur le mod√®le, utilise CHAT_MODEL si vide
      - ENABLE_INCREMENTAL_UPDATE=true # Activer ou non les mises √† jour incr√©mentielles
      - ENABLE_CODED_DEPENDENCY_ANALYSIS=false # Activer ou non l‚Äôanalyse de d√©pendance du code. Cela peut avoir un impact sur la qualit√© du code.
      - ENABLE_WAREHOUSE_FUNCTION_PROMPT_TASK=false # Activer ou non la g√©n√©ration du prompt MCP.
      - ENABLE_WAREHOUSE_DESCRIPTION_TASK=false # Activer ou non la g√©n√©ration de la Description du d√©p√¥t
```

AzureOpenAI :
```yaml
services:
  koalawiki:
    environment:
      - KOALAWIKI_REPOSITORIES=/repositories
      - TASK_MAX_SIZE_PER_USER=5 # Nombre maximum de t√¢ches parall√®les de g√©n√©ration de documents par utilisateur via l‚ÄôIA
      - CHAT_MODEL=DeepSeek-V3 # Le mod√®le doit prendre en charge les fonctions
      - ANALYSIS_MODEL= # Mod√®le utilis√© pour g√©n√©rer la structure du r√©pertoire du d√©p√¥t
      - CHAT_API_KEY= # Votre cl√© API
      - LANGUAGE= # D√©finir la langue par d√©faut pour la g√©n√©ration sur "Chinois"
      - ENDPOINT=https://your-azure-address.openai.azure.com/
      - DB_TYPE=sqlite
      - MODEL_PROVIDER=AzureOpenAI # Fournisseur du mod√®le, par d√©faut OpenAI, prend en charge AzureOpenAI et Anthropic
      - DB_CONNECTION_STRING=Data Source=/data/KoalaWiki.db
      - EnableSmartFilter=true # Si le filtrage intelligent est activ√© ou non peut affecter la mani√®re dont l‚ÄôIA obtient le r√©pertoire du d√©p√¥t
      - UPDATE_INTERVAL # Intervalle de mise √† jour incr√©mentielle du d√©p√¥t, unit√© : jours
      - MAX_FILE_LIMIT=100 # Limite maximale d‚Äôenvoi de fichiers, en Mo
      - DEEP_RESEARCH_MODEL= # Recherche approfondie sur le mod√®le, utilise CHAT_MODEL si vide
      - ENABLE_INCREMENTAL_UPDATE=true # Activer ou non les mises √† jour incr√©mentielles
      - ENABLE_CODED_DEPENDENCY_ANALYSIS=false # Activer ou non l‚Äôanalyse de d√©pendance du code. Cela peut avoir un impact sur la qualit√© du code.
      - ENABLE_WAREHOUSE_FUNCTION_PROMPT_TASK=false # Activer ou non la g√©n√©ration du prompt MCP.
      - ENABLE_WAREHOUSE_DESCRIPTION_TASK=false # Activer ou non la g√©n√©ration de la Description du d√©p√¥t
```

Anthropic :
```yaml
services:
  koalawiki:
    environment:
      - KOALAWIKI_REPOSITORIES=/repositories
      - TASK_MAX_SIZE_PER_USER=5 # Nombre maximum de t√¢ches parall√®les de g√©n√©ration de documents par utilisateur via l‚ÄôIA
      - CHAT_MODEL=DeepSeek-V3 # Le mod√®le doit prendre en charge les fonctions
      - ANALYSIS_MODEL= # Mod√®le utilis√© pour g√©n√©rer la structure du r√©pertoire du d√©p√¥t
      - CHAT_API_KEY= # Votre cl√© API
      - LANGUAGE= # D√©finir la langue par d√©faut pour la g√©n√©ration sur "Chinois"
      - ENDPOINT=https://api.anthropic.com/
      - DB_TYPE=sqlite
      - MODEL_PROVIDER=Anthropic # Fournisseur du mod√®le, par d√©faut OpenAI, prend en charge AzureOpenAI et Anthropic
      - DB_CONNECTION_STRING=Data Source=/data/KoalaWiki.db
      - EnableSmartFilter=true # Si le filtrage intelligent est activ√© ou non peut affecter la mani√®re dont l‚ÄôIA obtient le r√©pertoire du d√©p√¥t
      - UPDATE_INTERVAL # Intervalle de mise √† jour incr√©mentielle du d√©p√¥t, unit√© : jours
      - MAX_FILE_LIMIT=100 # Limite maximale d‚Äôenvoi de fichiers, en Mo
      - DEEP_RESEARCH_MODEL= # Recherche approfondie sur le mod√®le, utilise CHAT_MODEL si vide
      - ENABLE_INCREMENTAL_UPDATE=true # Activer ou non les mises √† jour incr√©mentielles
      - ENABLE_CODED_DEPENDENCY_ANALYSIS=false # Activer ou non l‚Äôanalyse de d√©pendance du code. Cela peut avoir un impact sur la qualit√© du code.
      - ENABLE_WAREHOUSE_FUNCTION_PROMPT_TASK=false # Activer ou non la g√©n√©ration du prompt MCP.
      - ENABLE_WAREHOUSE_DESCRIPTION_TASK=false # Activer ou non la g√©n√©ration de la Description du d√©p√¥t
```

> üí° **Comment obtenir une cl√© API :**
> - Obtenez une cl√© Google API sur [Google AI Studio](https://makersuite.google.com/app/apikey)
> - Obtenez une cl√© OpenAI sur [OpenAI Platform](https://platform.openai.com/api-keys)
> - Obtenez une cl√© CoresHub sur [CoresHub](https://console.coreshub.cn/xb3/maas/global-keys) [Cliquez ici pour 50 millions de tokens gratuits](https://account.coreshub.cn/signup?invite=ZmpMQlZxYVU=)
> - Obtenez une cl√© TokenAI sur [TokenAI](https://api.token-ai.cn/)

3. D√©marrer le service

Vous pouvez utiliser les commandes Makefile fournies pour g√©rer facilement l‚Äôapplication :

```bash
# Construire toutes les images Docker
make build

# D√©marrer tous les services en mode arri√®re-plan
make up

# Ou d√©marrer en mode d√©veloppement (avec logs visibles)
```
make dev
```

Puis rendez-vous sur http://localhost:8090 pour acc√©der √† la base de connaissances.

Pour plus de commandes :
```bash
make help
```

### Pour les utilisateurs Windows (sans make)

Si vous utilisez Windows et que vous n'avez pas `make` disponible, vous pouvez utiliser directement ces commandes Docker Compose :

```bash
# Construire toutes les images Docker
docker-compose build

# D√©marrer tous les services en mode arri√®re-plan
docker-compose up -d

# D√©marrer en mode d√©veloppement (avec logs visibles)
docker-compose up

# Arr√™ter tous les services
docker-compose down

# Afficher les logs
docker-compose logs -f
```

Pour construire des architectures ou services sp√©cifiques, utilisez :

```bash
# Construire uniquement le backend
docker-compose build koalawiki

# Construire uniquement le frontend
docker-compose build koalawiki-web

# Construire avec des param√®tres d‚Äôarchitecture
docker-compose build --build-arg ARCH=arm64
docker-compose build --build-arg ARCH=amd64
```


### D√©ployer sur Sealos avec acc√®s Internet public
[![](https://raw.githubusercontent.com/labring-actions/templates/main/Deploy-on-Sealos.svg)](https://bja.sealos.run/?openapp=system-template%3FtemplateName%3DOpenDeepWiki)
Pour des √©tapes d√©taill√©es, r√©f√©rez-vous √† : [D√©ploiement en un clic d‚ÄôOpenDeepWiki en tant qu‚Äôapplication Sealos expos√©e au r√©seau public √† l‚Äôaide de templates](scripts/sealos/README.zh-CN.md)

## üîç Fonctionnement

OpenDeepWiki utilise l‚ÄôIA pour :
 - Cloner le d√©p√¥t de code localement
 - Analyser √† partir du fichier README.md du d√©p√¥t
 - Analyser la structure du code et lire les fichiers de code selon les besoins, puis g√©n√©rer les donn√©es json du r√©pertoire
 - Traiter les t√¢ches selon le r√©pertoire, chaque t√¢che √©tant un document
 - Lire les fichiers de code, analyser les fichiers de code, g√©n√©rer la documentation du code, et cr√©er des sch√©mas Mermaid repr√©sentant les d√©pendances de structure du code
 - G√©n√©rer le document final de la base de connaissances
 - Analyser le d√©p√¥t par interaction conversationnelle et r√©pondre aux questions des utilisateurs

```mermaid
graph TD
    A[Cloner le d√©p√¥t de code] --> B[Analyser README.md]
    B --> C[Analyser la structure du code]
    C --> D[G√©n√©rer les donn√©es json du r√©pertoire]
    D --> E[Traiter plusieurs t√¢ches]
    E --> F[Lire les fichiers de code]
    F --> G[Analyser les fichiers de code]
    G --> H[G√©n√©rer la documentation du code]
    H --> I[Cr√©er des diagrammes Mermaid]
    I --> J[G√©n√©rer le document de la base de connaissances]
    J --> K[Interaction conversationnelle]
```
## Configuration avanc√©e

### Variables d‚Äôenvironnement
  - KOALAWIKI_REPOSITORIES  Chemin de stockage des d√©p√¥ts
  - TASK_MAX_SIZE_PER_USER  Nombre maximum de t√¢ches parall√®les de g√©n√©ration de documents IA par utilisateur
  - CHAT_MODEL  Le mod√®le doit supporter les fonctions
  - ENDPOINT  Point d‚Äôacc√®s API
  - ANALYSIS_MODEL  Mod√®le d‚Äôanalyse pour g√©n√©rer la structure de r√©pertoire du d√©p√¥t
  - CHAT_API_KEY  Votre cl√© API
  - LANGUAGE  Changer la langue des documents g√©n√©r√©s
  - DB_TYPE  Type de base de donn√©es, par d√©faut sqlite
  - MODEL_PROVIDER  Fournisseur de mod√®le, par d√©faut OpenAI, supporte Azure, OpenAI et Anthropic
  - DB_CONNECTION_STRING  Cha√Æne de connexion √† la base de donn√©es
  - EnableSmartFilter Activer ou non le filtrage intelligent peut affecter la fa√ßon dont l‚ÄôIA obtient l‚Äôarborescence des fichiers du d√©p√¥t
  - UPDATE_INTERVAL Intervalle de mise √† jour incr√©mentielle du d√©p√¥t, unit√© : jours
  - MAX_FILE_LIMIT Limite maximale de t√©l√©chargement de fichiers, en Mo
  - DEEP_RESEARCH_MODEL Effectuer une recherche approfondie sur le mod√®le et utiliser CHAT_MODEL pour l‚Äôabsence de valeur
  - ENABLE_INCREMENTAL_UPDATE Activer ou non les mises √† jour incr√©mentielles
  - ENABLE_CODED_DEPENDENCY_ANALYSIS Activer ou non l‚Äôanalyse des d√©pendances du code, cela peut avoir un impact sur la qualit√© du code.
  - ENABLE_WAREHOUSE_FUNCTION_PROMPT_TASK  # Activer ou non la g√©n√©ration de MCP Prompt.
  - ENABLE_WAREHOUSE_DESCRIPTION_TASK # Activer ou non la g√©n√©ration de la description du d√©p√¥t

### Compilation pour diff√©rentes architectures
Le Makefile propose des commandes pour compiler pour diff√©rentes architectures CPU :

```bash
# Compiler pour l‚Äôarchitecture ARM
make build-arm

# Compiler pour l‚Äôarchitecture AMD
make build-amd

# Compiler uniquement le backend pour ARM
make build-backend-arm

# Compiler uniquement le frontend pour AMD
make build-frontend-amd
```

## Discord

[rejoignez-nous](https://discord.gg/8sxUNacv)

## WeChat 

![b62354e40046f409b88528dd5631ed45](https://github.com/user-attachments/assets/2bb0055f-9e45-4db2-b9c9-f1e251996e01)

## üìÑ Licence
Ce projet est sous licence MIT - voir le fichier [LICENSE](./LICENSE) pour plus de d√©tails.

## Historique des √©toiles

[![Star History Chart](https://api.star-history.com/svg?repos=AIDotNet/OpenDeepWiki&type=Date)](https://www.star-history.com/#AIDotNet/OpenDeepWiki&Date)


---

Tranlated By [Open Ai Tx](https://github.com/OpenAiTx/OpenAiTx) | Last indexed: 2025-06-11

---