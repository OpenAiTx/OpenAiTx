{
  "id": 1,
  "origin": "![image.png](https://raw.githubusercontent.com/AgibotTech/genie_sim/main/./docs/image.jpg)\n<div align=\"center\">\n  <a href=\"https://github.com/AgibotTech/genie_sim\">\n    <img src=\"https://img.shields.io/badge/GitHub-grey?logo=GitHub\" alt=\"GitHub\">\n  </a>\n  <a href=\"https://huggingface.co/datasets/agibot-world/GenieSimAssets\">\n    <img src=\"https://img.shields.io/badge/HuggingFace-yellow?logo=HuggingFace\" alt=\"HuggingFace\">\n  </a>\n  <a href=\"https://agibot-world.com/sim-evaluation\">\n    <img src=\"https://img.shields.io/badge/Genie%20Sim%20Benchmark-blue?style=plastic\" alt=\"Genie Sim Benchmark\">\n  </a>\n  <a href=\"https://genie.agibot.com/en/geniestudio\">\n    <img src=\"https://img.shields.io/badge/Genie_Studio-green?style=flat\" alt=\"Genie Studio\">\n  </a>\n</div>\n\n# 1. Genie Sim Benchmark\nGenie Sim is the simulation framework from AgiBot, which provides developers efficient data generation capabilities and evaluation benchmarks to accelerate embodied intelligence development. Genie Sim has established a comprehensive closed loop pipeline, encompassing trajectory generation, model training, benchmarking, and deployment validation. Users can quickly validate algorithm performance and optimize models through this efficient simulation toolchain. Whether for simple grasping tasks or complex long-range operations, Genie Sim can provide a highly realistic simulation environment and precise evaluation metrics, empowering developers to efficiently complete the development and iteration of robotic technologies.\n\nGenie Sim Benchmark, as the open-source evaluation version of Genie Sim, is dedicated to providing precise performance testing and optimization support for embodied AI models.\n\n# 2. Features\n- Flexible and user-friendly simulation configuration and interface\n- Simulation benchmarks and evaluation tasks for 10+ manipulation tasks\n- Teleoperation capability based on VR and keyboard\n- All Joints and end effector pose record and replay\n- 550+ High fidelity and physically accurate 3D simulation environment and assets\n- Standardized evaluation metrics to quantify performance of embodied AI models\n- Evaluation results achieve less than 5% sim to real evaluation error on GO-1 model\n- Support UniVLA baseline model in simulation evaluation\n\n# 3. Updates\n- [6/25/2025] v2.1\n  - Add 10 more manipulation tasks for Agibot World Challenge 2025 including all simulation assets\n  - Open-source synthetic datasets for 10 manipulation tasks on Huggingface\n  https://huggingface.co/datasets/agibot-world/AgiBotWorldChallenge-2025/tree/main/Manipulation-SimData\n  - Integrate UniVLA policy and support model inference simulation evaluation\n  - Update IK solver sdk which supports cross-embodiment IK solving for other robots\n  - Optimize communication framework and improve simulation running speed by 2x\n  - Update automatic evaluation framework for more complicated long-range tasks\n\n# 4. Contents\n\n## 4.1 Introduction\nEmbodied intelligence simulation benchmarks in Genie Sim are designed to evaluate and advance the development of embodied AI models. These benchmarks provide realistic environments, diverse tasks and standardized metrics to measure the performance of robotic AI systems, which reduce the requirement of expensive physical hardware and real-world testing, avoid risky and dangerous testing scenarios and accelerate training and evaluaiton process of AI agents.\n\n## 4.2 Getting Started\nPlease refer to [this page](https://agibot-world.com/sim-evaluation/docs/#/v2) for installation, user guide and API reference\n\n## 4.3 Support\n<img src=\"https://raw.githubusercontent.com/AgibotTech/genie_sim/main/./docs/wechat.JPEG\" width=\"30%\"/>\n\n## 4.4 TODO List\n- [x] Release more long-horizon benchmark mainuplation tasks\n- [x] More scenes and assets for each benchmark task\n- [x] Support Agibot World Challenge baseline model\n- [ ] Scenario layout and manipulation trajectory generalization toolkit\n\n## 4.5 FAQ\n- How to shut down the isaac sim server when errors occur, causing the process not responding?\n  Kill the process in terminal using `pkill -9 -f raise_standalone_sim`\n- How to choose different render modes?\n  The default render mode is `RaytracedLighting(RealTime)`. For tasks that contain transparent objects, use `RealTimePathTracing(RealTime-2.0)` for perspective relationship of objects\n\n## 4.6 License and Citation\nAll the data and code within this repo are under Mozilla Public License 2.0\nPlease consider citing our work either way below if it helps your research.\n```\n@misc{2025geniesim,\n  title={GenieSim},\n  author={GenieSim Team},\n  year={2025},\n  url={https://github.com/AgibotTech/genie_sim}\n}\n```\n\n## 4.7 References\n1. PDDL Parser (2020). Version 1.1. [Source code]. https://github.com/pucrs-automated-planning/pddl-parser.\n2. BDDL. Version 1.x.x [Source code]. https://github.com/StanfordVL/bddl\n3. CUROBO [Source code]. https://github.com/NVlabs/curobo\n4. Isaac Lab [Source code]. https://github.com/isaac-sim/IsaacLab\n5. Omni Gibson [Source code]. https://github.com/StanfordVL/OmniGibson\n",
  "origin_sha": "GaeEJoT9NXaFLnFCgiIenMhfQaDLeGdeMZ2eUm4keBI=",
  "translate": "![image.png](https://raw.githubusercontent.com/AgibotTech/genie_sim/main/./docs/image.jpg)\n<div align=\"center\">\n  <a href=\"https://github.com/AgibotTech/genie_sim\">\n    <img src=\"https://img.shields.io/badge/GitHub-grey?logo=GitHub\" alt=\"GitHub\">\n  </a>\n  <a href=\"https://huggingface.co/datasets/agibot-world/GenieSimAssets\">\n    <img src=\"https://img.shields.io/badge/HuggingFace-yellow?logo=HuggingFace\" alt=\"HuggingFace\">\n  </a>\n  <a href=\"https://agibot-world.com/sim-evaluation\">\n    <img src=\"https://img.shields.io/badge/Genie%20Sim%20Benchmark-blue?style=plastic\" alt=\"Genie Sim Benchmark\">\n  </a>\n  <a href=\"https://genie.agibot.com/en/geniestudio\">\n    <img src=\"https://img.shields.io/badge/Genie_Studio-green?style=flat\" alt=\"Genie Studio\">\n  </a>\n</div>\n\n# ۱. بنچمارک Genie Sim\nGenie Sim چارچوب شبیه‌سازی ارائه‌شده توسط AgiBot است که قابلیت‌های کارآمدی برای تولید داده و بنچمارک‌های ارزیابی به توسعه‌دهندگان ارائه می‌دهد تا توسعه هوش تجسم‌یافته را تسریع کنند. Genie Sim یک خط لوله جامع حلقه بسته ایجاد کرده است که شامل تولید مسیر، آموزش مدل، بنچمارک‌گیری و اعتبارسنجی استقرار می‌باشد. کاربران می‌توانند به‌سرعت عملکرد الگوریتم را اعتبارسنجی کرده و مدل‌ها را از طریق این زنجیره ابزار شبیه‌سازی بهینه کنند. چه برای وظایف ساده گرفتن اشیا و چه برای عملیات پیچیده برد بلند، Genie Sim می‌تواند محیط شبیه‌سازی بسیار واقع‌گرایانه و معیارهای ارزیابی دقیقی ارائه دهد و به توسعه‌دهندگان این امکان را می‌دهد که توسعه و تکرار فناوری‌های رباتیک را به‌صورت کارآمد تکمیل کنند.\n\nبنچمارک Genie Sim به‌عنوان نسخه ارزیابی متن‌باز Genie Sim، متعهد به ارائه تست عملکرد دقیق و پشتیبانی از بهینه‌سازی برای مدل‌های هوش تجسم‌یافته است.\n\n# ۲. ویژگی‌ها\n- پیکربندی و رابط شبیه‌سازی انعطاف‌پذیر و کاربرپسند\n- بنچمارک‌های شبیه‌سازی و وظایف ارزیابی برای بیش از ۱۰ وظیفه دستکاری\n- قابلیت کنترل از راه دور مبتنی بر VR و صفحه‌کلید\n- ضبط و پخش مجدد تمام مفاصل و وضعیت اندافکتور\n- بیش از ۵۵۰ محیط و دارایی سه‌بعدی با دقت فیزیکی بالا\n- معیارهای ارزیابی استاندارد برای سنجش عملکرد مدل‌های هوش تجسم‌یافته\n- نتایج ارزیابی با خطای کمتر از ۵٪ شبیه‌سازی تا واقعیت بر روی مدل GO-1\n- پشتیبانی از مدل پایه UniVLA در ارزیابی شبیه‌سازی\n\n# ۳. به‌روزرسانی‌ها\n- [۲۵/۶/۲۰۲۵] نسخه ۲.۱\n  - افزودن ۱۰ وظیفه دستکاری جدید برای مسابقه Agibot World Challenge 2025، شامل تمامی دارایی‌های شبیه‌سازی\n  - متن‌باز شدن مجموعه داده‌های مصنوعی برای ۱۰ وظیفه دستکاری روی Huggingface\n  https://huggingface.co/datasets/agibot-world/AgiBotWorldChallenge-2025/tree/main/Manipulation-SimData\n  - یکپارچه‌سازی سیاست UniVLA و پشتیبانی از ارزیابی شبیه‌سازی استنتاج مدل\n  - به‌روزرسانی SDK حل‌گر IK که حل IK میان‌تجسمی برای ربات‌های دیگر را پشتیبانی می‌کند\n  - بهینه‌سازی چارچوب ارتباطی و افزایش سرعت اجرای شبیه‌سازی تا ۲ برابر\n  - به‌روزرسانی چارچوب ارزیابی خودکار برای وظایف پیچیده‌تر برد بلند\n\n# ۴. محتوا\n\n## ۴.۱ مقدمه\nبنچمارک‌های شبیه‌سازی هوش تجسم‌یافته در Genie Sim برای ارزیابی و پیشرفت توسعه مدل‌های هوش تجسم‌یافته طراحی شده‌اند. این بنچمارک‌ها محیط‌های واقع‌گرایانه، وظایف متنوع و معیارهای استانداردی برای سنجش عملکرد سیستم‌های رباتیک هوشمند فراهم می‌کنند که نیاز به سخت‌افزار فیزیکی گران‌قیمت و آزمایش‌های دنیای واقعی را کاهش می‌دهند، از سناریوهای پرخطر جلوگیری کرده و فرآیند آموزش و ارزیابی عامل‌های هوش مصنوعی را تسریع می‌کنند.\n\n## ۴.۲ شروع کار\nلطفاً برای نصب، راهنمای کاربر و مرجع API به [این صفحه](https://agibot-world.com/sim-evaluation/docs/#/v2) مراجعه کنید.\n\n## ۴.۳ پشتیبانی\n<img src=\"https://raw.githubusercontent.com/AgibotTech/genie_sim/main/./docs/wechat.JPEG\" width=\"30%\"/>\n\n## ۴.۴ لیست کارهای آینده\n- [x] انتشار وظایف بنچمارک دستکاری با افق زمانی بلندتر\n- [x] صحنه‌ها و دارایی‌های بیشتر برای هر وظیفه بنچمارک\n- [x] پشتیبانی از مدل پایه Agibot World Challenge\n- [ ] جعبه‌ابزار چیدمان سناریو و تعمیم مسیر دستکاری\n\n## ۴.۵ سوالات متداول\n- چگونه سرور isaac sim را هنگام بروز خطا که باعث عدم پاسخگویی فرآیند می‌شود، خاموش کنیم؟\n  فرآیند را در ترمینال با دستور `pkill -9 -f raise_standalone_sim` خاتمه دهید.\n- چگونه حالت‌های مختلف رندر را انتخاب کنیم؟\n  حالت پیش‌فرض رندر `RaytracedLighting(RealTime)` است. برای وظایفی که اشیای شفاف دارند، از حالت `RealTimePathTracing(RealTime-2.0)` برای نمایش صحیح رابطه پرسپکتیو اشیا استفاده کنید.\n\n## ۴.۶ مجوز و استناد\nتمام داده‌ها و کدهای موجود در این مخزن تحت مجوز عمومی موزیلا نسخه ۲.۰ هستند.\nدر صورت استفاده در تحقیقات خود، لطفاً به یکی از روش‌های زیر به ما استناد کنید.\n```\n@misc{2025geniesim,\n  title={GenieSim},\n  author={GenieSim Team},\n  year={2025},\n  url={https://github.com/AgibotTech/genie_sim}\n}\n```\n\n## ۴.۷ منابع\n1. PDDL Parser (2020). نسخه ۱.۱. [کد منبع]. https://github.com/pucrs-automated-planning/pddl-parser.\n2. BDDL. نسخه ۱.x.x [کد منبع]. https://github.com/StanfordVL/bddl\n3. CUROBO [کد منبع]. https://github.com/NVlabs/curobo\n4. Isaac Lab [کد منبع]. https://github.com/isaac-sim/IsaacLab\n5. Omni Gibson [کد منبع]. https://github.com/StanfordVL/OmniGibson",
  "status": "ok"
}