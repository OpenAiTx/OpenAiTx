# Arpeggiatore a Gesti Manuali

Arpeggiatore controllato con le mani, drum machine e visualizzatore audio reattivo. Alza le mani per alzare il volume!

Un'app web interattiva costruita con threejs, mediapipe computer vision, rosebud AI e tone.js.

- Mano #1 controlla gli arpeggi (alza la mano per alzare la tonalitÃ , pizzica per cambiare il volume)
- Mano #2 controlla la batteria (alza dita diverse per cambiare il pattern)

[Video](https://youtu.be/JepIs-DTBgk?si=4Y-FrQDF6KNy662C) | [Demo Live](https://collidingscopes.github.io/arpeggiator/) | [Altri Codici & Tutorial](https://funwithcomputervision.com/)

<img src="https://raw.githubusercontent.com/collidingScopes/arpeggiator/main/assets/demo.png">

## Requisiti

- Browser web moderno con supporto WebGL
- Accesso alla fotocamera abilitato per il tracciamento delle mani

## Tecnologie

- **MediaPipe** per il tracciamento delle mani e il riconoscimento dei gesti
- **Three.js** per il rendering visivo audio reattivo
- **Tone.js** per i suoni del sintetizzatore
- **HTML5 Canvas** per il feedback visivo
- **JavaScript** per l'interazione in tempo reale
## Configurazione per lo Sviluppo

```bash
# Clona questo repository
git clone https://github.com/collidingScopes/arpeggiator

# Vai nella directory del progetto
cd arpeggiator

# Servi il progetto con il metodo che preferisci (esempio usando Python)
python -m http.server
```

Poi naviga su `http://localhost:8000` nel tuo browser.

## Licenza

Licenza MIT

## Crediti
- Three.js - https://threejs.org/
- MediaPipe - https://mediapipe.dev/
- Rosebud AI - https://rosebud.ai/
- Tone.js - https://tonejs.github.io/

## Progetti Correlati

Ho pubblicato diversi progetti di visione artificiale (con codice + tutorial) qui:
[Fun With Computer Vision](https://www.funwithcomputervision.com/)

Puoi acquistare lâ€™accesso a vita e ricevere tutti i file di progetto e i tutorial completi. Sto aggiungendo regolarmente nuovi contenuti ðŸª¬

Potrebbero interessarti anche alcuni dei miei altri progetti open source:

- [3D Model Playground](https://collidingScopes.github.io/3d-model-playground) - controlla modelli 3D con la voce e i gesti delle mani
- [Tutorial di hand tracking con Threejs](https://collidingScopes.github.io/threejs-handtracking-101) - Configurazione base di hand tracking con threejs e visione artificiale MediaPipe
- [Particular Drift](https://collidingScopes.github.io/particular-drift) - Trasforma foto in animazioni di particelle fluide
- [Video-to-ASCII](https://collidingScopes.github.io/ascii) - Converti video in pixel art ASCII
## Contatti

- Instagram: [@stereo.drift](https://www.instagram.com/stereo.drift/)
- Twitter/X: [@measure_plan](https://x.com/measure_plan)
- Email: [stereodriftvisuals@gmail.com](https://raw.githubusercontent.com/collidingScopes/arpeggiator/main/mailto:stereodriftvisuals@gmail.com)
- GitHub: [collidingScopes](https://github.com/collidingScopes)

## Donazioni

Se hai trovato utile questo strumento, sentiti libero di offrirmi un caffÃ¨.

Mi chiamo Alan e mi piace sviluppare software open source per computer vision, giochi e altro ancora. Sarebbe molto apprezzato durante le sessioni di programmazione notturne!

[![Offrimi un caffÃ¨](https://www.buymeacoffee.com/assets/img/custom_images/yellow_img.png)](https://www.buymeacoffee.com/stereoDrift)

---

Tranlated By [Open Ai Tx](https://github.com/OpenAiTx/OpenAiTx) | Last indexed: 2025-07-11

---