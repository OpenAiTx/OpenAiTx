# Arpeggiator Sterowany Gestami Rąk

Sterowany rękami arpeggiator, automat perkusyjny oraz wizualizator reagujący na dźwięk. Podnieś ręce, by podnieść sufit!

Interaktywna aplikacja webowa zbudowana z użyciem threejs, mediapipe (wizja komputerowa), rosebud AI oraz tone.js.

- Ręka #1 steruje arpeggiami (podnieś rękę, by podnieść wysokość dźwięku, uszczypnij, aby zmienić głośność)
- Ręka #2 steruje perkusją (podnieś różne palce, by zmienić wzór)

[Wideo](https://youtu.be/JepIs-DTBgk?si=4Y-FrQDF6KNy662C) | [Demo na żywo](https://collidingscopes.github.io/arpeggiator/) | [Więcej kodu i tutoriali](https://funwithcomputervision.com/)

<img src="https://raw.githubusercontent.com/collidingScopes/arpeggiator/main/assets/demo.png">

## Wymagania

- Nowoczesna przeglądarka internetowa z obsługą WebGL
- Dostęp do kamery włączony do śledzenia rąk

## Technologie

- **MediaPipe** do śledzenia rąk i rozpoznawania gestów
- **Three.js** do wizualizacji reagującej na dźwięk
- **Tone.js** do generowania dźwięków syntezatora
- **HTML5 Canvas** do wizualnej informacji zwrotnej
- **JavaScript** do interakcji w czasie rzeczywistym
## Konfiguracja środowiska deweloperskiego

```bash
# Sklonuj to repozytorium
git clone https://github.com/collidingScopes/arpeggiator

# Przejdź do katalogu projektu
cd arpeggiator

# Uruchom serwer wybraną metodą (przykład z użyciem Pythona)
python -m http.server
```

Następnie przejdź do `http://localhost:8000` w swojej przeglądarce.

## Licencja

Licencja MIT

## Podziękowania
- Three.js - https://threejs.org/
- MediaPipe - https://mediapipe.dev/
- Rosebud AI - https://rosebud.ai/
- Tone.js - https://tonejs.github.io/

## Powiązane Projekty

Opublikowałem kilka projektów z zakresu widzenia komputerowego (z kodem + samouczkami) tutaj:
[Fun With Computer Vision](https://www.funwithcomputervision.com/)

Możesz wykupić dożywotni dostęp i otrzymać pełne pliki projektów oraz samouczki. Regularnie dodaję nowe treści 🪬

Możesz także zainteresować się niektórymi z moich innych projektów open source:

- [3D Model Playground](https://collidingScopes.github.io/3d-model-playground) - sterowanie modelami 3D za pomocą głosu i gestów dłoni
- [Threejs hand tracking tutorial](https://collidingScopes.github.io/threejs-handtracking-101) - Podstawowa konfiguracja śledzenia dłoni z użyciem threejs i komputerowego widzenia MediaPipe
- [Particular Drift](https://collidingScopes.github.io/particular-drift) - Zamień zdjęcia w płynące animacje cząsteczek
- [Video-to-ASCII](https://collidingScopes.github.io/ascii) - Konwertuj filmy na pikselową grafikę ASCII
## Kontakt

- Instagram: [@stereo.drift](https://www.instagram.com/stereo.drift/)
- Twitter/X: [@measure_plan](https://x.com/measure_plan)
- Email: [stereodriftvisuals@gmail.com](https://raw.githubusercontent.com/collidingScopes/arpeggiator/main/mailto:stereodriftvisuals@gmail.com)
- GitHub: [collidingScopes](https://github.com/collidingScopes)

## Darowizny

Jeśli uznałeś to narzędzie za przydatne, możesz postawić mi kawę.

Mam na imię Alan i lubię tworzyć otwarte oprogramowanie z zakresu widzenia komputerowego, gier i nie tylko. To bardzo pomaga podczas nocnych sesji programowania!

[![Postaw mi kawę](https://www.buymeacoffee.com/assets/img/custom_images/yellow_img.png)](https://www.buymeacoffee.com/stereoDrift)

---

Tranlated By [Open Ai Tx](https://github.com/OpenAiTx/OpenAiTx) | Last indexed: 2025-07-11

---