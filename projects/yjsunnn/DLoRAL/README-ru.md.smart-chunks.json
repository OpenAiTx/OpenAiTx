[
  {
    "Id": 1,
    "Content": "<div align=\"center\">\n<h2>One-Step Diffusion for Detail-Rich and Temporally Consistent Video Super-Resolution</h2>\n\n[Yujing Sun](https://yjsunnn.github.io/)<sup>1,2, *</sup> | \n[Lingchen Sun](https://scholar.google.com/citations?hl=zh-CN&tzom=-480&user=ZCDjTn8AAAAJ)<sup>1,2, *</sup> | \n[Shuaizheng Liu](https://scholar.google.com/citations?user=wzdCc-QAAAAJ&hl=en)<sup>1,2</sup> | \n[Rongyuan Wu](https://scholar.google.com/citations?user=A-U8zE8AAAAJ&hl=zh-CN)<sup>1,2</sup> | \n[Zhengqiang Zhang](https://scholar.google.com.tw/citations?user=UX26wSMAAAAJ&hl=en)<sup>1,2</sup> | \n[Lei Zhang](https://www4.comp.polyu.edu.hk/~cslzhang)<sup>1,2</sup>\n\n<sup>1</sup>The Hong Kong Polytechnic University, <sup>2</sup>OPPO Research Institute\n</div>\n\n<div>\n    <h4 align=\"center\">\n        <a href=\"https://yjsunnn.github.io/DLoRAL-project/\" target='_blank'>\n        <img src=\"https://img.shields.io/badge/üí°-Project%20Page-gold\">\n        </a>\n        <a href=\"https://arxiv.org/pdf/2506.15591\" target='_blank'>\n        <img src=\"https://img.shields.io/badge/arXiv-2312.06640-b31b1b.svg\">\n        </a>\n        <a href=\"https://www.youtube.com/embed/Jsk8zSE3U-w?si=jz1Isdzxt_NqqDFL&vq=hd1080\" target='_blank'>\n        <img src=\"https://img.shields.io/badge/Demo%20Video-%23FF0000.svg?logo=YouTube&logoColor=white\">\n        </a>\n        <a href=\"https://www.youtube.com/embed/xzZL8X10_KU?si=vOB3chIa7Zo0l54v\" target=\"_blank\">\n        <img src=\"https://img.shields.io/badge/2--Min%20Explainer-brightgreen?logo=YouTube&logoColor=white\">\n        </a>\n        </a>\n        <a href=\"https://github.com/yjsunnn/Awesome-video-super-resolution-diffusion\" target=\"_blank\">\n        <img src=\"https://img.shields.io/badge/GitHub-Awesome--VSR--Diffusion-181717.svg?logo=github&logoColor=white\">\n        </a>\n<!--         <a href=\"https://www.youtube.com/embed/Jsk8zSE3U-w?si=jz1Isdzxt_NqqDFL&vq=hd1080\" target='_blank'>\n        <img src=\"https://img.shields.io/badge/1--Min%20Algorithm%20Explainer-%23FF0000.svg?logo=YouTube&logoColor=white\">\n        </a> -->\n        <a href=\"https://github.com/yjsunnn/DLoRAL\" target='_blank' style=\"text-decoration: none;\"><img src=\"https://visitor-badge.laobi.icu/badge?page_id=yjsunnn/DLoRAL\"></a>\n    </h4>\n</div>\n\n<p align=\"center\">\n\n<img src=\"https://raw.githubusercontent.com/yjsunnn/DLoRAL/main/assets/visual_results.svg\" alt=\"Visual Results\">\n\n</p>\n",
    "ContentSha": "bVvVxNHO5h3vkATLAmVTtzDCag2JgKRyJH13Z0uT2Dw=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "<div align=\"center\">\n<h2>–û–¥–Ω–æ—à–∞–≥–æ–≤–∞—è –¥–∏—Ñ—Ñ—É–∑–∏—è –¥–ª—è –¥–µ—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∏ –≤—Ä–µ–º–µ–Ω–Ω–æ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ–≥–æ —É–≤–µ–ª–∏—á–µ–Ω–∏—è —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è –≤–∏–¥–µ–æ</h2>\n\n[Yujing Sun](https://yjsunnn.github.io/)<sup>1,2, *</sup> | \n[Lingchen Sun](https://scholar.google.com/citations?hl=zh-CN&tzom=-480&user=ZCDjTn8AAAAJ)<sup>1,2, *</sup> | \n[Shuaizheng Liu](https://scholar.google.com/citations?user=wzdCc-QAAAAJ&hl=en)<sup>1,2</sup> | \n[Rongyuan Wu](https://scholar.google.com/citations?user=A-U8zE8AAAAJ&hl=zh-CN)<sup>1,2</sup> | \n[Zhengqiang Zhang](https://scholar.google.com.tw/citations?user=UX26wSMAAAAJ&hl=en)<sup>1,2</sup> | \n[Lei Zhang](https://www4.comp.polyu.edu.hk/~cslzhang)<sup>1,2</sup>\n\n<sup>1</sup>–ì–æ–Ω–∫–æ–Ω–≥—Å–∫–∏–π –ø–æ–ª–∏—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç, <sup>2</sup>–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –∏–Ω—Å—Ç–∏—Ç—É—Ç OPPO\n</div>\n\n<div>\n    <h4 align=\"center\">\n        <a href=\"https://yjsunnn.github.io/DLoRAL-project/\" target='_blank'>\n        <img src=\"https://img.shields.io/badge/üí°-Project%20Page-gold\">\n        </a>\n        <a href=\"https://arxiv.org/pdf/2506.15591\" target='_blank'>\n        <img src=\"https://img.shields.io/badge/arXiv-2312.06640-b31b1b.svg\">\n        </a>\n        <a href=\"https://www.youtube.com/embed/Jsk8zSE3U-w?si=jz1Isdzxt_NqqDFL&vq=hd1080\" target='_blank'>\n        <img src=\"https://img.shields.io/badge/Demo%20Video-%23FF0000.svg?logo=YouTube&logoColor=white\">\n        </a>\n        <a href=\"https://www.youtube.com/embed/xzZL8X10_KU?si=vOB3chIa7Zo0l54v\" target=\"_blank\">\n        <img src=\"https://img.shields.io/badge/2--Min%20Explainer-brightgreen?logo=YouTube&logoColor=white\">\n        </a>\n        </a>\n        <a href=\"https://github.com/yjsunnn/Awesome-video-super-resolution-diffusion\" target=\"_blank\">\n        <img src=\"https://img.shields.io/badge/GitHub-Awesome--VSR--Diffusion-181717.svg?logo=github&logoColor=white\">\n        </a>\n<!--         <a href=\"https://www.youtube.com/embed/Jsk8zSE3U-w?si=jz1Isdzxt_NqqDFL&vq=hd1080\" target='_blank'>\n        <img src=\"https://img.shields.io/badge/1--Min%20Algorithm%20Explainer-%23FF0000.svg?logo=YouTube&logoColor=white\">\n        </a> -->\n        <a href=\"https://github.com/yjsunnn/DLoRAL\" target='_blank' style=\"text-decoration: none;\"><img src=\"https://visitor-badge.laobi.icu/badge?page_id=yjsunnn/DLoRAL\"></a>\n    </h4>\n</div>\n\n<p align=\"center\">\n\n<img src=\"https://raw.githubusercontent.com/yjsunnn/DLoRAL/main/assets/visual_results.svg\" alt=\"–í–∏–∑—É–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\">\n\n</p>\n",
    "Status": "ok"
  },
  {
    "Id": 2,
    "Content": "## ‚è∞ Update\n\n- **2025.07.08**: The inference code and pretrained weights are available.\n- **2025.06.24**: The project page is available, including a brief 2-minute explanation video, more visual results and relevant researches.\n- **2025.06.17**: The repo is released.\n\n:star: If DLoRAL is helpful to your videos or projects, please help star this repo. Thanks! :hugs:\n\nüòä You may also want to check our relevant works:\n\n1. **OSEDiff (NIPS2024)** [Paper](https://arxiv.org/abs/2406.08177) | [Code](https://github.com/cswry/OSEDiff/)  \n\n   Real-time Image SR algorithm that has been applied to the OPPO Find X8 series.\n\n2. **PiSA-SR (CVPR2025)** [Paper](https://arxiv.org/pdf/2412.03017) | [Code](https://github.com/csslc/PiSA-SR) \n\n   Pioneering exploration of Dual-LoRA paradigm in Image SR.\n\n3. **Awesome Diffusion Models for Video Super-Resolution** [Repo](https://github.com/yjsunnn/Awesome-video-super-resolution-diffusion)\n\n   A curated list of resources for Video Super-Resolution (VSR) using Diffusion Models.\n",
    "ContentSha": "dfxVaVa+I0eZ9HnE6Yp/PsWOOtEK1Z+QwdmjxrtNNfg=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "## ‚è∞ –û–±–Ω–æ–≤–ª–µ–Ω–∏—è\n\n- **2025.07.08**: –î–æ—Å—Ç—É–ø–µ–Ω –∫–æ–¥ –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ –∏ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–µ –≤–µ—Å–∞.\n- **2025.06.24**: –î–æ—Å—Ç—É–ø–Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –ø—Ä–æ–µ–∫—Ç–∞, –≤–∫–ª—é—á–∞—è –∫—Ä–∞—Ç–∫–æ–µ 2-–º–∏–Ω—É—Ç–Ω–æ–µ –æ–±—ä—è—Å–Ω—è—é—â–µ–µ –≤–∏–¥–µ–æ, –±–æ–ª—å—à–µ –≤–∏–∑—É–∞–ª—å–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π.\n- **2025.06.17**: –†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω.\n\n:star: –ï—Å–ª–∏ DLoRAL –æ–∫–∞–∑–∞–ª—Å—è –ø–æ–ª–µ–∑–µ–Ω –¥–ª—è –≤–∞—à–∏—Ö –≤–∏–¥–µ–æ –∏–ª–∏ –ø—Ä–æ–µ–∫—Ç–æ–≤, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ—Å—Ç–∞–≤—å—Ç–µ –∑–≤–µ–∑–¥—É —ç—Ç–æ–º—É —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—é. –°–ø–∞—Å–∏–±–æ! :hugs:\n\nüòä –í–æ–∑–º–æ–∂–Ω–æ, –≤–∞–º —Ç–∞–∫–∂–µ –±—É–¥—É—Ç –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã –Ω–∞—à–∏ —Å–º–µ–∂–Ω—ã–µ —Ä–∞–±–æ—Ç—ã:\n\n1. **OSEDiff (NIPS2024)** [–°—Ç–∞—Ç—å—è](https://arxiv.org/abs/2406.08177) | [–ö–æ–¥](https://github.com/cswry/OSEDiff/)  \n\n   –ê–ª–≥–æ—Ä–∏—Ç–º —Å—É–ø–µ—Ä—Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏, –∫–æ—Ç–æ—Ä—ã–π –±—ã–ª –ø—Ä–∏–º–µ–Ω—ë–Ω –≤ —Å–µ—Ä–∏–∏ OPPO Find X8.\n\n2. **PiSA-SR (CVPR2025)** [–°—Ç–∞—Ç—å—è](https://arxiv.org/pdf/2412.03017) | [–ö–æ–¥](https://github.com/csslc/PiSA-SR) \n\n   –ü–µ—Ä–≤–æ–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–∞—Ä–∞–¥–∏–≥–º—ã Dual-LoRA –≤ —Å—É–ø–µ—Ä—Ä–∞–∑—Ä–µ—à–µ–Ω–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π.\n\n3. **Awesome Diffusion Models for Video Super-Resolution** [–†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π](https://github.com/yjsunnn/Awesome-video-super-resolution-diffusion)\n\n   –ö—É—Ä–∞—Ç–æ—Ä—Å–∫–∏–π —Å–ø–∏—Å–æ–∫ —Ä–µ—Å—É—Ä—Å–æ–≤ –ø–æ —Å—É–ø–µ—Ä—Ä–∞–∑—Ä–µ—à–µ–Ω–∏—é –≤–∏–¥–µ–æ (VSR) —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π.",
    "Status": "ok"
  },
  {
    "Id": 3,
    "Content": "## üëÄ TODO\n- [x] Release inference code.\n- [ ] Colab and Huggingface UI for convenient test (Soon!).\n- [ ] Release training code.\n- [ ] Release training data.\n\n\n## üåü Overview Framework\n\n<p align=\"center\">\n\n<img src=\"https://raw.githubusercontent.com/yjsunnn/DLoRAL/main/assets/pipeline.svg\" alt=\"DLoRAL Framework\">\n\n</p>\n\n**Training**: A dynamic dual-stage training scheme alternates between optimizing temporal coherence (consistency stage) and refining high-frequency spatial details (enhancement stage) with smooth loss interpolation to ensure stability.\n\n**Inference**: During inference, both C-LoRA and D-LoRA are merged into the frozen diffusion UNet, enabling one-step enhancement of low-quality inputs into high-quality outputs.\n\n",
    "ContentSha": "ZGelK9ipNT81XA+Ow1at5yuSzYjWCpL6tnO6FOf9+7I=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "## üëÄ TODO\n- [x] –í—ã–ø—É—Å—Ç–∏—Ç—å –∫–æ–¥ –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞.\n- [ ] Colab –∏ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å Huggingface –¥–ª—è —É–¥–æ–±–Ω–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (–°–∫–æ—Ä–æ!).\n- [ ] –í—ã–ø—É—Å—Ç–∏—Ç—å –∫–æ–¥ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è.\n- [ ] –í—ã–ø—É—Å—Ç–∏—Ç—å –æ–±—É—á–∞—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ.\n\n\n## üåü –û–±–∑–æ—Ä —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–∞\n\n<p align=\"center\">\n\n<img src=\"https://raw.githubusercontent.com/yjsunnn/DLoRAL/main/assets/pipeline.svg\" alt=\"DLoRAL Framework\">\n\n</p>\n\n**–û–±—É—á–µ–Ω–∏–µ**: –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∞—è –¥–≤—É—Ö—ç—Ç–∞–ø–Ω–∞—è —Å—Ö–µ–º–∞ –æ–±—É—á–µ–Ω–∏—è –ø–æ–æ—á–µ—Ä–µ–¥–Ω–æ –æ–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω—É—é —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å (—ç—Ç–∞–ø —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏) –∏ —É–ª—É—á—à–∞–µ—Ç –≤—ã—Å–æ–∫–æ—á–∞—Å—Ç–æ—Ç–Ω—ã–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω—ã–µ –¥–µ—Ç–∞–ª–∏ (—ç—Ç–∞–ø –ø–æ–≤—ã—à–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞) —Å –ø–ª–∞–≤–Ω–æ–π –∏–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏–µ–π –ø–æ—Ç–µ—Ä—å –¥–ª—è –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏.\n\n**–ò–Ω—Ñ–µ—Ä–µ–Ω—Å**: –í–æ –≤—Ä–µ–º—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ C-LoRA –∏ D-LoRA –æ–±—ä–µ–¥–∏–Ω—è—é—Ç—Å—è –≤–æ –≤—Å—Ç—Ä–æ–µ–Ω–Ω–æ–π (–∑–∞–º–æ—Ä–æ–∂–µ–Ω–Ω–æ–π) –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω–æ–π UNet, —á—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –∑–∞ –æ–¥–∏–Ω —à–∞–≥ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤—ã–≤–∞—Ç—å –Ω–∏–∑–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ –≤—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –≤—ã—Ö–æ–¥–Ω—ã–µ.",
    "Status": "ok"
  },
  {
    "Id": 4,
    "Content": "## üîß Dependencies and Installation\n\n1. Clone repo\n    ```bash\n    git clone https://github.com/yjsunnn/DLoRAL.git\n    cd DLoRAL\n    ```\n\n2. Install dependent packages\n    ```bash\n    conda create -n DLoRAL python=3.10 -y\n    conda activate DLoRAL\n    pip install -r requirements.txt\n    ```\n\n3. Download Models \n#### Dependent Models\n* [SD21 Base](https://huggingface.co/stabilityai/stable-diffusion-2-1-base) --> put into **/path/to/DLoRAL/preset_models/stable-diffusion-2-1-base**\n* [Bert-Base](https://huggingface.co/google-bert/bert-base-uncased) --> put into **/path/to/DLoRAL/preset_models/bert-base-uncased**\n* [RAM](https://huggingface.co/spaces/xinyu1205/recognize-anything/blob/main/ram_swin_large_14m.pth) --> put into **/path/to/DLoRAL/preset/models/ram_swin_large_14m.pth**\n* [DAPE](https://drive.google.com/file/d/1KIV6VewwO2eDC9g4Gcvgm-a0LDI7Lmwm/view?usp=drive_link) --> put into **/path/to/DLoRAL/preset/models/DAPE.pth**\n* [Pretrained Weights](https://drive.google.com/file/d/1vpcaySpRx_K-tXq2D2EBqFZ-03Foky8G/view?usp=sharing) --> put into **/path/to/DLoRAL/preset/models/checkpoints/model.pkl**\n\nEach path can be modified according to its own requirements, and the corresponding changes should also be applied to the command line and the code.\n",
    "ContentSha": "vvwBfkJn4SJeRBMzLa2/Uod2dvEBbBZ+Waj2PNmgQek=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "",
    "Status": "error"
  },
  {
    "Id": 5,
    "Content": "## üñºÔ∏è Quick Inference\nFor Real-World Video Super-Resolution:\n\n```\npython src/test_DLoRAL.py     \\\n--pretrained_model_path /path/to/stable-diffusion-2-1-base     \\\n--ram_ft_path /path/to/DAPE.pth     \\\n--ram_path '/path/to/ram_swin_large_14m.pth'     \\\n--merge_and_unload_lora False     \\\n--process_size 512     \\\n--pretrained_model_name_or_path '/path/to/stable-diffusion-2-1-base'     \\\n--vae_encoder_tiled_size 4096     \\\n--load_cfr     \\\n--pretrained_path /path/to/model_checkpoint.pkl     \\\n--stages 1     \\\n-i /path/to/input_videos/     \\\n-o /path/to/results\n```\n\n\n",
    "ContentSha": "ktj+podNwub3lDyiQLZjTmjqDb9M6mdrGxjfY/EiWXU=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "",
    "Status": "error"
  },
  {
    "Id": 6,
    "Content": "### Citations\nIf our code helps your research or work, please consider citing our paper.\nThe following are BibTeX references:\n\n```\n@misc{sun2025onestepdiffusiondetailrichtemporally,\n      title={One-Step Diffusion for Detail-Rich and Temporally Consistent Video Super-Resolution}, \n      author={Yujing Sun and Lingchen Sun and Shuaizheng Liu and Rongyuan Wu and Zhengqiang Zhang and Lei Zhang},\n      year={2025},\n      eprint={2506.15591},\n      archivePrefix={arXiv},\n      primaryClass={cs.CV},\n      url={https://arxiv.org/abs/2506.15591}, \n}\n",
    "ContentSha": "8oig3poiN8He5uh3Lud+BRL7mNg6+g0kMUL4Om73m68=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "### –¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è\n–ï—Å–ª–∏ –Ω–∞—à –∫–æ–¥ –ø–æ–º–æ–≥ –≤–∞—à–µ–π –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–π —Ä–∞–±–æ—Ç–µ –∏–ª–∏ –ø—Ä–æ–µ–∫—Ç—É, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, —Ä–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –Ω–∞—à–µ–π —Å—Ç–∞—Ç—å–∏.\n–ù–∏–∂–µ –ø—Ä–∏–≤–µ–¥–µ–Ω—ã —Å—Å—ã–ª–∫–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ BibTeX:\n\n```\n@misc{sun2025onestepdiffusiondetailrichtemporally,\n      title={One-Step Diffusion for Detail-Rich and Temporally Consistent Video Super-Resolution}, \n      author={Yujing Sun and Lingchen Sun and Shuaizheng Liu and Rongyuan Wu and Zhengqiang Zhang and Lei Zhang},\n      year={2025},\n      eprint={2506.15591},\n      archivePrefix={arXiv},\n      primaryClass={cs.CV},\n      url={https://arxiv.org/abs/2506.15591}, \n}\n```",
    "Status": "ok"
  }
]