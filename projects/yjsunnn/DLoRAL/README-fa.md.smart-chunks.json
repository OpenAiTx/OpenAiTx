[
  {
    "Id": 1,
    "Content": "<div align=\"center\">\n<h2>One-Step Diffusion for Detail-Rich and Temporally Consistent Video Super-Resolution</h2>\n\n[Yujing Sun](https://yjsunnn.github.io/)<sup>1,2, *</sup> | \n[Lingchen Sun](https://scholar.google.com/citations?hl=zh-CN&tzom=-480&user=ZCDjTn8AAAAJ)<sup>1,2, *</sup> | \n[Shuaizheng Liu](https://scholar.google.com/citations?user=wzdCc-QAAAAJ&hl=en)<sup>1,2</sup> | \n[Rongyuan Wu](https://scholar.google.com/citations?user=A-U8zE8AAAAJ&hl=zh-CN)<sup>1,2</sup> | \n[Zhengqiang Zhang](https://scholar.google.com.tw/citations?user=UX26wSMAAAAJ&hl=en)<sup>1,2</sup> | \n[Lei Zhang](https://www4.comp.polyu.edu.hk/~cslzhang)<sup>1,2</sup>\n\n<sup>1</sup>The Hong Kong Polytechnic University, <sup>2</sup>OPPO Research Institute\n</div>\n\n<div>\n    <h4 align=\"center\">\n        <a href=\"https://yjsunnn.github.io/DLoRAL-project/\" target='_blank'>\n        <img src=\"https://img.shields.io/badge/ğŸ’¡-Project%20Page-gold\">\n        </a>\n        <a href=\"https://arxiv.org/pdf/2506.15591\" target='_blank'>\n        <img src=\"https://img.shields.io/badge/arXiv-2312.06640-b31b1b.svg\">\n        </a>\n        <a href=\"https://www.youtube.com/embed/Jsk8zSE3U-w?si=jz1Isdzxt_NqqDFL&vq=hd1080\" target='_blank'>\n        <img src=\"https://img.shields.io/badge/Demo%20Video-%23FF0000.svg?logo=YouTube&logoColor=white\">\n        </a>\n        <a href=\"https://www.youtube.com/embed/xzZL8X10_KU?si=vOB3chIa7Zo0l54v\" target=\"_blank\">\n        <img src=\"https://img.shields.io/badge/2--Min%20Explainer-brightgreen?logo=YouTube&logoColor=white\">\n        </a>\n        </a>\n        <a href=\"https://github.com/yjsunnn/Awesome-video-super-resolution-diffusion\" target=\"_blank\">\n        <img src=\"https://img.shields.io/badge/GitHub-Awesome--VSR--Diffusion-181717.svg?logo=github&logoColor=white\">\n        </a>\n<!--         <a href=\"https://www.youtube.com/embed/Jsk8zSE3U-w?si=jz1Isdzxt_NqqDFL&vq=hd1080\" target='_blank'>\n        <img src=\"https://img.shields.io/badge/1--Min%20Algorithm%20Explainer-%23FF0000.svg?logo=YouTube&logoColor=white\">\n        </a> -->\n        <a href=\"https://github.com/yjsunnn/DLoRAL\" target='_blank' style=\"text-decoration: none;\"><img src=\"https://visitor-badge.laobi.icu/badge?page_id=yjsunnn/DLoRAL\"></a>\n    </h4>\n</div>\n\n<p align=\"center\">\n\n<img src=\"https://raw.githubusercontent.com/yjsunnn/DLoRAL/main/assets/visual_results.svg\" alt=\"Visual Results\">\n\n</p>\n",
    "ContentSha": "bVvVxNHO5h3vkATLAmVTtzDCag2JgKRyJH13Z0uT2Dw=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "<div align=\"center\">\n<h2>Ø§Ù†ØªØ´Ø§Ø± ÛŒÚ©â€ŒÙ…Ø±Ø­Ù„Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø§ÙØ²Ø§ÛŒØ´ ÙˆØ¶ÙˆØ­ ÙˆÛŒØ¯ÛŒÙˆ Ø¨Ø§ Ø¬Ø²Ø¦ÛŒØ§Øª ØºÙ†ÛŒ Ùˆ Ø³Ø§Ø²Ú¯Ø§Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ</h2>\n\n[Yujing Sun](https://yjsunnn.github.io/)<sup>1,2, *</sup> | \n[Lingchen Sun](https://scholar.google.com/citations?hl=zh-CN&tzom=-480&user=ZCDjTn8AAAAJ)<sup>1,2, *</sup> | \n[Shuaizheng Liu](https://scholar.google.com/citations?user=wzdCc-QAAAAJ&hl=en)<sup>1,2</sup> | \n[Rongyuan Wu](https://scholar.google.com/citations?user=A-U8zE8AAAAJ&hl=zh-CN)<sup>1,2</sup> | \n[Zhengqiang Zhang](https://scholar.google.com.tw/citations?user=UX26wSMAAAAJ&hl=en)<sup>1,2</sup> | \n[Lei Zhang](https://www4.comp.polyu.edu.hk/~cslzhang)<sup>1,2</sup>\n\n<sup>1</sup>Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ Ù¾Ù„ÛŒâ€ŒØªÚ©Ù†ÛŒÚ© Ù‡Ù†Ú¯â€ŒÚ©Ù†Ú¯ØŒ <sup>2</sup>Ù…Ø¤Ø³Ø³Ù‡ ØªØ­Ù‚ÛŒÙ‚Ø§Øª OPPO\n</div>\n\n<div>\n    <h4 align=\"center\">\n        <a href=\"https://yjsunnn.github.io/DLoRAL-project/\" target='_blank'>\n        <img src=\"https://img.shields.io/badge/ğŸ’¡-Project%20Page-gold\">\n        </a>\n        <a href=\"https://arxiv.org/pdf/2506.15591\" target='_blank'>\n        <img src=\"https://img.shields.io/badge/arXiv-2312.06640-b31b1b.svg\">\n        </a>\n        <a href=\"https://www.youtube.com/embed/Jsk8zSE3U-w?si=jz1Isdzxt_NqqDFL&vq=hd1080\" target='_blank'>\n        <img src=\"https://img.shields.io/badge/Demo%20Video-%23FF0000.svg?logo=YouTube&logoColor=white\">\n        </a>\n        <a href=\"https://www.youtube.com/embed/xzZL8X10_KU?si=vOB3chIa7Zo0l54v\" target=\"_blank\">\n        <img src=\"https://img.shields.io/badge/2--Min%20Explainer-brightgreen?logo=YouTube&logoColor=white\">\n        </a>\n        </a>\n        <a href=\"https://github.com/yjsunnn/Awesome-video-super-resolution-diffusion\" target=\"_blank\">\n        <img src=\"https://img.shields.io/badge/GitHub-Awesome--VSR--Diffusion-181717.svg?logo=github&logoColor=white\">\n        </a>\n<!--         <a href=\"https://www.youtube.com/embed/Jsk8zSE3U-w?si=jz1Isdzxt_NqqDFL&vq=hd1080\" target='_blank'>\n        <img src=\"https://img.shields.io/badge/1--Min%20Algorithm%20Explainer-%23FF0000.svg?logo=YouTube&logoColor=white\">\n        </a> -->\n        <a href=\"https://github.com/yjsunnn/DLoRAL\" target='_blank' style=\"text-decoration: none;\"><img src=\"https://visitor-badge.laobi.icu/badge?page_id=yjsunnn/DLoRAL\"></a>\n    </h4>\n</div>\n\n<p align=\"center\">\n\n<img src=\"https://raw.githubusercontent.com/yjsunnn/DLoRAL/main/assets/visual_results.svg\" alt=\"Ù†ØªØ§ÛŒØ¬ Ø¨ØµØ±ÛŒ\">\n\n</p>",
    "Status": "ok"
  },
  {
    "Id": 2,
    "Content": "## â° Update\n\n- **2025.07.08**: The inference code and pretrained weights are available.\n- **2025.06.24**: The project page is available, including a brief 2-minute explanation video, more visual results and relevant researches.\n- **2025.06.17**: The repo is released.\n\n:star: If DLoRAL is helpful to your videos or projects, please help star this repo. Thanks! :hugs:\n\nğŸ˜Š You may also want to check our relevant works:\n\n1. **OSEDiff (NIPS2024)** [Paper](https://arxiv.org/abs/2406.08177) | [Code](https://github.com/cswry/OSEDiff/)  \n\n   Real-time Image SR algorithm that has been applied to the OPPO Find X8 series.\n\n2. **PiSA-SR (CVPR2025)** [Paper](https://arxiv.org/pdf/2412.03017) | [Code](https://github.com/csslc/PiSA-SR) \n\n   Pioneering exploration of Dual-LoRA paradigm in Image SR.\n\n3. **Awesome Diffusion Models for Video Super-Resolution** [Repo](https://github.com/yjsunnn/Awesome-video-super-resolution-diffusion)\n\n   A curated list of resources for Video Super-Resolution (VSR) using Diffusion Models.\n",
    "ContentSha": "dfxVaVa+I0eZ9HnE6Yp/PsWOOtEK1Z+QwdmjxrtNNfg=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "## â° Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ\n\n- **Û²Û°Û²Ûµ.Û°Û·.Û°Û¸**: Ú©Ø¯ Ø§Ø³ØªÙ†ØªØ§Ø¬ Ùˆ ÙˆØ²Ù†â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´â€ŒØ¢Ù…ÙˆØ²Ø´â€ŒÛŒØ§ÙØªÙ‡ Ù…Ù†ØªØ´Ø± Ø´Ø¯Ù†Ø¯.\n- **Û²Û°Û²Ûµ.Û°Û¶.Û²Û´**: ØµÙØ­Ù‡ Ù¾Ø±ÙˆÚ˜Ù‡ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù‚Ø±Ø§Ø± Ú¯Ø±ÙØª Ú©Ù‡ Ø´Ø§Ù…Ù„ ÛŒÚ© ÙˆÛŒØ¯ÛŒÙˆÛŒ ØªÙˆØ¶ÛŒØ­ÛŒ Û² Ø¯Ù‚ÛŒÙ‚Ù‡â€ŒØ§ÛŒØŒ Ù†ØªØ§ÛŒØ¬ Ø¨ØµØ±ÛŒ Ø¨ÛŒØ´ØªØ± Ùˆ Ù¾Ú˜ÙˆÙ‡Ø´â€ŒÙ‡Ø§ÛŒ Ù…Ø±ØªØ¨Ø· Ø§Ø³Øª.\n- **Û²Û°Û²Ûµ.Û°Û¶.Û±Û·**: Ù…Ø®Ø²Ù† Ù…Ù†ØªØ´Ø± Ø´Ø¯.\n\n:star: Ø§Ú¯Ø± DLoRAL Ø¨Ø±Ø§ÛŒ ÙˆÛŒØ¯ÛŒÙˆÙ‡Ø§ ÛŒØ§ Ù¾Ø±ÙˆÚ˜Ù‡â€ŒÙ‡Ø§ÛŒ Ø´Ù…Ø§ Ù…ÙÛŒØ¯ Ø¨ÙˆØ¯ØŒ Ù„Ø·ÙØ§Ù‹ Ø¨Ù‡ Ø§ÛŒÙ† Ù…Ø®Ø²Ù† Ø³ØªØ§Ø±Ù‡ Ø¨Ø¯Ù‡ÛŒØ¯. Ø³Ù¾Ø§Ø³Ú¯Ø²Ø§Ø±ÛŒÙ…! :hugs:\n\nğŸ˜Š Ù‡Ù…Ú†Ù†ÛŒÙ† Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø¨Ø®ÙˆØ§Ù‡ÛŒØ¯ Ø¢Ø«Ø§Ø± Ù…Ø±ØªØ¨Ø· Ù…Ø§ Ø±Ø§ Ù…Ø´Ø§Ù‡Ø¯Ù‡ Ú©Ù†ÛŒØ¯:\n\n1. **OSEDiff (NIPS2024)** [Ù…Ù‚Ø§Ù„Ù‡](https://arxiv.org/abs/2406.08177) | [Ú©Ø¯](https://github.com/cswry/OSEDiff/)  \n\n   Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ… Ø¨Ø²Ø±Ú¯â€ŒÙ†Ù…Ø§ÛŒÛŒ ØªØµÙˆÛŒØ± Ø¨Ù„Ø§Ø¯Ø±Ù†Ú¯ Ú©Ù‡ Ø¯Ø± Ø³Ø±ÛŒ OPPO Find X8 Ø¨Ù‡ Ú©Ø§Ø± Ø±ÙØªÙ‡ Ø§Ø³Øª.\n\n2. **PiSA-SR (CVPR2025)** [Ù…Ù‚Ø§Ù„Ù‡](https://arxiv.org/pdf/2412.03017) | [Ú©Ø¯](https://github.com/csslc/PiSA-SR) \n\n   Ù¾ÛŒØ´Ú¯Ø§Ù… Ø¯Ø± Ú©Ø§ÙˆØ´ Ù¾Ø§Ø±Ø§Ø¯Ø§ÛŒÙ… Dual-LoRA Ø¯Ø± Ø¨Ø²Ø±Ú¯â€ŒÙ†Ù…Ø§ÛŒÛŒ ØªØµÙˆÛŒØ±.\n\n3. **Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø§Ù†ØªØ´Ø§Ø± Ø´Ú¯ÙØªâ€ŒØ§Ù†Ú¯ÛŒØ² Ø¨Ø±Ø§ÛŒ Ø¨Ø²Ø±Ú¯â€ŒÙ†Ù…Ø§ÛŒÛŒ ÙˆÛŒØ¯ÛŒÙˆÛŒÛŒ** [Ù…Ø®Ø²Ù†](https://github.com/yjsunnn/Awesome-video-super-resolution-diffusion)\n\n   ÙÙ‡Ø±Ø³Øª Ù…Ù†ØªØ®Ø¨ Ù…Ù†Ø§Ø¨Ø¹ Ø¨Ø±Ø§ÛŒ Ø¨Ø²Ø±Ú¯â€ŒÙ†Ù…Ø§ÛŒÛŒ ÙˆÛŒØ¯ÛŒÙˆÛŒÛŒ (VSR) Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø§Ù†ØªØ´Ø§Ø±.",
    "Status": "ok"
  },
  {
    "Id": 3,
    "Content": "## ğŸ‘€ TODO\n- [x] Release inference code.\n- [ ] Colab and Huggingface UI for convenient test (Soon!).\n- [ ] Release training code.\n- [ ] Release training data.\n\n\n## ğŸŒŸ Overview Framework\n\n<p align=\"center\">\n\n<img src=\"https://raw.githubusercontent.com/yjsunnn/DLoRAL/main/assets/pipeline.svg\" alt=\"DLoRAL Framework\">\n\n</p>\n\n**Training**: A dynamic dual-stage training scheme alternates between optimizing temporal coherence (consistency stage) and refining high-frequency spatial details (enhancement stage) with smooth loss interpolation to ensure stability.\n\n**Inference**: During inference, both C-LoRA and D-LoRA are merged into the frozen diffusion UNet, enabling one-step enhancement of low-quality inputs into high-quality outputs.\n\n",
    "ContentSha": "ZGelK9ipNT81XA+Ow1at5yuSzYjWCpL6tnO6FOf9+7I=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "## ğŸ‘€ Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒÙ‡Ø§ÛŒ Ø¢ÛŒÙ†Ø¯Ù‡\n- [x] Ø§Ù†ØªØ´Ø§Ø± Ú©Ø¯ Ø§Ø³ØªÙ†ØªØ§Ø¬.\n- [ ] Ø±Ø§Ø¨Ø· Ú©Ø§Ø±Ø¨Ø±ÛŒ Colab Ùˆ Huggingface Ø¨Ø±Ø§ÛŒ ØªØ³Øª Ø¢Ø³Ø§Ù† (Ø¨Ù‡â€ŒØ²ÙˆØ¯ÛŒ!).\n- [ ] Ø§Ù†ØªØ´Ø§Ø± Ú©Ø¯ Ø¢Ù…ÙˆØ²Ø´.\n- [ ] Ø§Ù†ØªØ´Ø§Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ÛŒ.\n\n\n## ğŸŒŸ Ú†Ø§Ø±Ú†ÙˆØ¨ Ú©Ù„ÛŒ\n\n<p align=\"center\">\n\n<img src=\"https://raw.githubusercontent.com/yjsunnn/DLoRAL/main/assets/pipeline.svg\" alt=\"DLoRAL Framework\">\n\n</p>\n\n**Ø¢Ù…ÙˆØ²Ø´**: ÛŒÚ© Ø·Ø±Ø­ Ø¢Ù…ÙˆØ²Ø´ Ø¯Ùˆ Ù…Ø±Ø­Ù„Ù‡â€ŒØ§ÛŒ Ù¾ÙˆÛŒØ§ Ø¨Ù‡â€ŒØ·ÙˆØ± Ù…ØªÙ†Ø§ÙˆØ¨ Ø¨ÛŒÙ† Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø§Ù†Ø³Ø¬Ø§Ù… Ø²Ù…Ø§Ù†ÛŒ (Ù…Ø±Ø­Ù„Ù‡â€ŒÛŒ Ø³Ø§Ø²Ú¯Ø§Ø±ÛŒ) Ùˆ Ø¨Ù‡Ø¨ÙˆØ¯ Ø¬Ø²Ø¦ÛŒØ§Øª Ù…Ú©Ø§Ù†ÛŒ Ø¨Ø§ ÙØ±Ú©Ø§Ù†Ø³ Ø¨Ø§Ù„Ø§ (Ù…Ø±Ø­Ù„Ù‡â€ŒÛŒ Ø§Ø±ØªÙ‚Ø§Ø¡) Ø¨Ø§ Ø¯Ø±ÙˆÙ†â€ŒÛŒØ§Ø¨ÛŒ Ø±ÙˆØ§Ù† Ø¶Ø±Ø± Ø¨Ø±Ø§ÛŒ Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² Ù¾Ø§ÛŒØ¯Ø§Ø±ÛŒ Ø¬Ø§Ø¨Ø¬Ø§ Ù…ÛŒâ€ŒØ´ÙˆØ¯.\n\n**Ø§Ø³ØªÙ†ØªØ§Ø¬**: Ø¯Ø± Ù…Ø±Ø­Ù„Ù‡ Ø§Ø³ØªÙ†ØªØ§Ø¬ØŒ Ù‡Ø± Ø¯Ùˆ C-LoRA Ùˆ D-LoRA Ø¯Ø± Ù…Ø¯Ù„ UNet Ø§Ù†ØªØ´Ø§Ø± Ù…Ù†Ø¬Ù…Ø¯ Ø§Ø¯ØºØ§Ù… Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯ Ùˆ Ø§Ø±ØªÙ‚Ø§Ø¡ ÛŒÚ©â€ŒÙ…Ø±Ø­Ù„Ù‡â€ŒØ§ÛŒ ÙˆØ±ÙˆØ¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ú©Ù…â€ŒÚ©ÛŒÙÛŒØª Ø¨Ù‡ Ø®Ø±ÙˆØ¬ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¨Ø§ Ú©ÛŒÙÛŒØª Ø¨Ø§Ù„Ø§ Ø±Ø§ Ù…Ù…Ú©Ù† Ù…ÛŒâ€ŒØ³Ø§Ø²Ù†Ø¯.",
    "Status": "ok"
  },
  {
    "Id": 4,
    "Content": "## ğŸ”§ Dependencies and Installation\n\n1. Clone repo\n    ```bash\n    git clone https://github.com/yjsunnn/DLoRAL.git\n    cd DLoRAL\n    ```\n\n2. Install dependent packages\n    ```bash\n    conda create -n DLoRAL python=3.10 -y\n    conda activate DLoRAL\n    pip install -r requirements.txt\n    ```\n\n3. Download Models \n#### Dependent Models\n* [SD21 Base](https://huggingface.co/stabilityai/stable-diffusion-2-1-base) --> put into **/path/to/DLoRAL/preset_models/stable-diffusion-2-1-base**\n* [Bert-Base](https://huggingface.co/google-bert/bert-base-uncased) --> put into **/path/to/DLoRAL/preset_models/bert-base-uncased**\n* [RAM](https://huggingface.co/spaces/xinyu1205/recognize-anything/blob/main/ram_swin_large_14m.pth) --> put into **/path/to/DLoRAL/preset/models/ram_swin_large_14m.pth**\n* [DAPE](https://drive.google.com/file/d/1KIV6VewwO2eDC9g4Gcvgm-a0LDI7Lmwm/view?usp=drive_link) --> put into **/path/to/DLoRAL/preset/models/DAPE.pth**\n* [Pretrained Weights](https://drive.google.com/file/d/1vpcaySpRx_K-tXq2D2EBqFZ-03Foky8G/view?usp=sharing) --> put into **/path/to/DLoRAL/preset/models/checkpoints/model.pkl**\n\nEach path can be modified according to its own requirements, and the corresponding changes should also be applied to the command line and the code.\n",
    "ContentSha": "vvwBfkJn4SJeRBMzLa2/Uod2dvEBbBZ+Waj2PNmgQek=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "## ğŸ”§ ÙˆØ§Ø¨Ø³ØªÚ¯ÛŒâ€ŒÙ‡Ø§ Ùˆ Ù†ØµØ¨\n\n1. Ú©Ù„ÙˆÙ† Ú©Ø±Ø¯Ù† Ù…Ø®Ø²Ù†\n    ```bash\n    git clone https://github.com/yjsunnn/DLoRAL.git\n    cd DLoRAL\n    ```\n\n2. Ù†ØµØ¨ Ø¨Ø³ØªÙ‡â€ŒÙ‡Ø§ÛŒ ÙˆØ§Ø¨Ø³ØªÙ‡\n    ```bash\n    conda create -n DLoRAL python=3.10 -y\n    conda activate DLoRAL\n    pip install -r requirements.txt\n    ```\n\n3. Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø¯Ù„â€ŒÙ‡Ø§ \n#### Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ ÙˆØ§Ø¨Ø³ØªÙ‡\n* [SD21 Base](https://huggingface.co/stabilityai/stable-diffusion-2-1-base) --> Ø¯Ø± Ù…Ø³ÛŒØ± **/path/to/DLoRAL/preset_models/stable-diffusion-2-1-base** Ù‚Ø±Ø§Ø± Ø¯Ù‡ÛŒØ¯\n* [Bert-Base](https://huggingface.co/google-bert/bert-base-uncased) --> Ø¯Ø± Ù…Ø³ÛŒØ± **/path/to/DLoRAL/preset_models/bert-base-uncased** Ù‚Ø±Ø§Ø± Ø¯Ù‡ÛŒØ¯\n* [RAM](https://huggingface.co/spaces/xinyu1205/recognize-anything/blob/main/ram_swin_large_14m.pth) --> Ø¯Ø± Ù…Ø³ÛŒØ± **/path/to/DLoRAL/preset/models/ram_swin_large_14m.pth** Ù‚Ø±Ø§Ø± Ø¯Ù‡ÛŒØ¯\n* [DAPE](https://drive.google.com/file/d/1KIV6VewwO2eDC9g4Gcvgm-a0LDI7Lmwm/view?usp=drive_link) --> Ø¯Ø± Ù…Ø³ÛŒØ± **/path/to/DLoRAL/preset/models/DAPE.pth** Ù‚Ø±Ø§Ø± Ø¯Ù‡ÛŒØ¯\n* [Pretrained Weights](https://drive.google.com/file/d/1vpcaySpRx_K-tXq2D2EBqFZ-03Foky8G/view?usp=sharing) --> Ø¯Ø± Ù…Ø³ÛŒØ± **/path/to/DLoRAL/preset/models/checkpoints/model.pkl** Ù‚Ø±Ø§Ø± Ø¯Ù‡ÛŒØ¯\n\nÙ‡Ø± Ù…Ø³ÛŒØ± Ø±Ø§ Ù…ÛŒâ€ŒØªÙˆØ§Ù† Ù…Ø·Ø§Ø¨Ù‚ Ù†ÛŒØ§Ø² Ø®ÙˆØ¯ ØªØºÛŒÛŒØ± Ø¯Ø§Ø¯ Ùˆ ØªØºÛŒÛŒØ±Ø§Øª Ù…Ø±Ø¨ÙˆØ·Ù‡ Ø¨Ø§ÛŒØ¯ Ø¯Ø± Ø®Ø· ÙØ±Ù…Ø§Ù† Ùˆ Ú©Ø¯ Ù†ÛŒØ² Ø§Ø¹Ù…Ø§Ù„ Ø´ÙˆØ¯.",
    "Status": "ok"
  },
  {
    "Id": 5,
    "Content": "## ğŸ–¼ï¸ Quick Inference\nFor Real-World Video Super-Resolution:\n\n```\npython src/test_DLoRAL.py     \\\n--pretrained_model_path /path/to/stable-diffusion-2-1-base     \\\n--ram_ft_path /path/to/DAPE.pth     \\\n--ram_path '/path/to/ram_swin_large_14m.pth'     \\\n--merge_and_unload_lora False     \\\n--process_size 512     \\\n--pretrained_model_name_or_path '/path/to/stable-diffusion-2-1-base'     \\\n--vae_encoder_tiled_size 4096     \\\n--load_cfr     \\\n--pretrained_path /path/to/model_checkpoint.pkl     \\\n--stages 1     \\\n-i /path/to/input_videos/     \\\n-o /path/to/results\n```\n\n\n",
    "ContentSha": "ktj+podNwub3lDyiQLZjTmjqDb9M6mdrGxjfY/EiWXU=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "## ğŸ–¼ï¸ Ø§Ø³ØªÙ†ØªØ§Ø¬ Ø³Ø±ÛŒØ¹\nØ¨Ø±Ø§ÛŒ Ø§ÙØ²Ø§ÛŒØ´ ÙˆØ¶ÙˆØ­ ÙˆÛŒØ¯Ø¦ÙˆÛŒ Ø¯Ù†ÛŒØ§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ:\n\n```\npython src/test_DLoRAL.py     \\\n--pretrained_model_path /path/to/stable-diffusion-2-1-base     \\\n--ram_ft_path /path/to/DAPE.pth     \\\n--ram_path '/path/to/ram_swin_large_14m.pth'     \\\n--merge_and_unload_lora False     \\\n--process_size 512     \\\n--pretrained_model_name_or_path '/path/to/stable-diffusion-2-1-base'     \\\n--vae_encoder_tiled_size 4096     \\\n--load_cfr     \\\n--pretrained_path /path/to/model_checkpoint.pkl     \\\n--stages 1     \\\n-i /path/to/input_videos/     \\\n-o /path/to/results\n```\n",
    "Status": "ok"
  },
  {
    "Id": 6,
    "Content": "### Citations\nIf our code helps your research or work, please consider citing our paper.\nThe following are BibTeX references:\n\n```\n@misc{sun2025onestepdiffusiondetailrichtemporally,\n      title={One-Step Diffusion for Detail-Rich and Temporally Consistent Video Super-Resolution}, \n      author={Yujing Sun and Lingchen Sun and Shuaizheng Liu and Rongyuan Wu and Zhengqiang Zhang and Lei Zhang},\n      year={2025},\n      eprint={2506.15591},\n      archivePrefix={arXiv},\n      primaryClass={cs.CV},\n      url={https://arxiv.org/abs/2506.15591}, \n}\n",
    "ContentSha": "8oig3poiN8He5uh3Lud+BRL7mNg6+g0kMUL4Om73m68=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "### Ø§Ø±Ø¬Ø§Ø¹Ø§Øª\nØ§Ú¯Ø± Ú©Ø¯ Ù…Ø§ Ø¨Ù‡ Ù¾Ú˜ÙˆÙ‡Ø´ ÛŒØ§ Ú©Ø§Ø± Ø´Ù…Ø§ Ú©Ù…Ú© Ú©Ø±Ø¯Ù‡ Ø§Ø³ØªØŒ Ù„Ø·ÙØ§Ù‹ Ù…Ù‚Ø§Ù„Ù‡ Ù…Ø§ Ø±Ø§ Ø§Ø±Ø¬Ø§Ø¹ Ø¯Ù‡ÛŒØ¯.\nØ§Ø±Ø¬Ø§Ø¹Ø§Øª BibTeX Ø¨Ù‡ Ø´Ø±Ø­ Ø²ÛŒØ± Ø§Ø³Øª:\n\n```\n@misc{sun2025onestepdiffusiondetailrichtemporally,\n      title={One-Step Diffusion for Detail-Rich and Temporally Consistent Video Super-Resolution}, \n      author={Yujing Sun and Lingchen Sun and Shuaizheng Liu and Rongyuan Wu and Zhengqiang Zhang and Lei Zhang},\n      year={2025},\n      eprint={2506.15591},\n      archivePrefix={arXiv},\n      primaryClass={cs.CV},\n      url={https://arxiv.org/abs/2506.15591}, \n}\n```",
    "Status": "ok"
  }
]