[
  {
    "row": 1,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "<div align=\"center\">"
  },
  {
    "row": 2,
    "rowsha": "94MDjHJY1ZLwHNTLIEUIfk7TMc9cq1L/1FmwhqBTe/k=",
    "originContent": "<div align=\"center\">",
    "translatedContent": "<h1>"
  },
  {
    "row": 3,
    "rowsha": "Dzts6KPKpSA5sdedO9xd4B7/ZDPSjLXxN/jme5pXqnU=",
    "originContent": "<h1>",
    "translatedContent": "感知一切：识别、解释、描述及分割图像和视频中的任何内容（PAM）"
  },
  {
    "row": 4,
    "rowsha": "pfgjdvVaQ4wypc5VZ0GNuVLaL0LpY1LV4SHvu3ThA9U=",
    "originContent": "Perceive Anything: Recognize, Explain, Caption, and Segement Anything in Images and Videos (PAM)",
    "translatedContent": "</h1>"
  },
  {
    "row": 5,
    "rowsha": "jx7VTIaGwMtwY3ZiSh8xEG0MuMzGD34Xs/9PCAcDvw8=",
    "originContent": "</h1>",
    "translatedContent": ""
  },
  {
    "row": 6,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "</div>"
  },
  {
    "row": 7,
    "rowsha": "qsMmUbEPVnxGG5tPJV1vsfpoWbU2jYvZpRr5IKshzyM=",
    "originContent": "</div>",
    "translatedContent": ""
  },
  {
    "row": 8,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "<div align=\"center\">"
  },
  {
    "row": 9,
    "rowsha": "94MDjHJY1ZLwHNTLIEUIfk7TMc9cq1L/1FmwhqBTe/k=",
    "originContent": "<div align=\"center\">",
    "translatedContent": ""
  },
  {
    "row": 10,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "[林伟峰](), [魏新宇](), [安瑞川](), [任天河](), [陈廷伟](), [张仁睿](), [郭子宇]() <br>"
  },
  {
    "row": 11,
    "rowsha": "IaQ0RSzOo0imFmlkVU+wjK5t3lchin+c/8rmpM8UeUs=",
    "originContent": "[Weifeng Lin](), [Xinyu Wei](), [Ruichuan An](), [Tianhe Ren](), [Tingwei Chen](), [Renrui Zhang](), [Ziyu Guo]() <br>",
    "translatedContent": "[张文涛](), [张磊](), [李宏胜]() <br>"
  },
  {
    "row": 12,
    "rowsha": "l6P9U8DtLiAqDCn+M0x2kBXKDR7cUmrpjNmsKqSBL1c=",
    "originContent": "[Wentao Zhang](), [Lei Zhang](), [Hongsheng Li]() <br>",
    "translatedContent": "中大，港大，理大，北京大学"
  },
  {
    "row": 13,
    "rowsha": "9Ura2GxNVQSaS/z8+5Mmzp7TlU1glEkdOZjo1MbqGFM=",
    "originContent": "CUHK, HKU, PolyU, PekingU",
    "translatedContent": ""
  },
  {
    "row": 14,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "</div>"
  },
  {
    "row": 15,
    "rowsha": "qsMmUbEPVnxGG5tPJV1vsfpoWbU2jYvZpRr5IKshzyM=",
    "originContent": "</div>",
    "translatedContent": ""
  },
  {
    "row": 16,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "<p align=\"center\">"
  },
  {
    "row": 17,
    "rowsha": "+/a9XmPwQixGFroME/GMEOLpReZZV4ARosR9orAplJY=",
    "originContent": "<p align=\"center\">",
    "translatedContent": "  <a href=\"https://Perceive-Anything.github.io\"><b>🌐 项目网站</b></a> |"
  },
  {
    "row": 18,
    "rowsha": "KmbGYC8ak9Hs+OgBqGfnmc+jbit1hTEgmyyZKXKHJI0=",
    "originContent": "  <a href=\"https://Perceive-Anything.github.io\"><b>🌐 Project Website</b></a> |",
    "translatedContent": "  <a href=\"https://arxiv.org/abs/2506.05302\"><b>📕 论文</b></a> |"
  },
  {
    "row": 19,
    "rowsha": "PEa6uaE+6c08jcyuVJ9SMfyMWSptPAaRdz+NLR4MB1g=",
    "originContent": "  <a href=\"https://arxiv.org/abs/2506.05302\"><b>📕 Paper</b></a> |",
    "translatedContent": "  <a href=\"https://huggingface.co/Perceive-Anything/PAM-3B\"><b>📥 模型下载</b></a> |"
  },
  {
    "row": 20,
    "rowsha": "dHaOl889gR0sejugmc+pvhv+mmis+fVu5xoQ/kWkJ+E=",
    "originContent": "  <a href=\"https://huggingface.co/Perceive-Anything/PAM-3B\"><b>📥 Model Download</b></a> |",
    "translatedContent": "  <a href=\"https://huggingface.co/datasets/Perceive-Anything/PAM-data\"><b>🤗 数据集</b></a> |"
  },
  {
    "row": 21,
    "rowsha": "+IfUJYNSrFhXIvg/vV0OyYYdrdjvP9reJ9EjqUkEQso=",
    "originContent": "  <a href=\"https://huggingface.co/datasets/Perceive-Anything/PAM-data\"><b>🤗 Dataset</b></a> |",
    "translatedContent": "  <a href=\"#quick-start\"><b>⚡快速开始</b></a> <br>"
  },
  {
    "row": 22,
    "rowsha": "DilCNafHeWiI7o+zgDMdsmCt7EUdcZFu17pAiPo5+fk=",
    "originContent": "  <a href=\"#quick-start\"><b>⚡Quick Start</b></a> <br>",
    "translatedContent": "  <a href=\"#license\"><b>📜 许可证</b></a> |"
  },
  {
    "row": 23,
    "rowsha": "Whtcr+jlBmKMFnlmTMYPe4qYrQ8SswHSc81wwYVdk74=",
    "originContent": "  <a href=\"#license\"><b>📜 License</b></a> |",
    "translatedContent": "  <a href=\"#citation\"><b>📖 引用 (BibTeX)</b></a> <br>"
  },
  {
    "row": 24,
    "rowsha": "s5oMOrkixrIRvzViHZ3o9/Wuyji5PdqFUBNeEYfBOwo=",
    "originContent": "  <a href=\"#citation\"><b>📖 Citation (BibTeX)</b></a> <br>",
    "translatedContent": "</p>"
  },
  {
    "row": 25,
    "rowsha": "dSdvPNAZSmR86FDDSF6tkQUCVfI9qmACHOR5tThOetY=",
    "originContent": "</p>",
    "translatedContent": ""
  },
  {
    "row": 26,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "<p align=\"center\">"
  },
  {
    "row": 27,
    "rowsha": "+/a9XmPwQixGFroME/GMEOLpReZZV4ARosR9orAplJY=",
    "originContent": "<p align=\"center\">",
    "translatedContent": "    <img src=\"https://raw.githubusercontent.com/Perceive-Anything/PAM/main/assets/teaser_img.jpg\" width=\"95%\"> <br>"
  },
  {
    "row": 28,
    "rowsha": "yC3+svpuSrBNQsABTNeeMhssLYzhE9/j1dEYFKFEbk0=",
    "originContent": "    <img src=\"https://raw.githubusercontent.com/Perceive-Anything/PAM/main/assets/teaser_img.jpg\" width=\"95%\"> <br>",
    "translatedContent": "    <img src=\"https://raw.githubusercontent.com/Perceive-Anything/PAM/main/assets/teaser_video.jpg\" width=\"95%\"> <br>"
  },
  {
    "row": 29,
    "rowsha": "Yu12YUUrRcW54dGmy/S33FMw2OBQsiHJBhz/z8QNKVM=",
    "originContent": "    <img src=\"https://raw.githubusercontent.com/Perceive-Anything/PAM/main/assets/teaser_video.jpg\" width=\"95%\"> <br>",
    "translatedContent": "</p>"
  },
  {
    "row": 30,
    "rowsha": "dSdvPNAZSmR86FDDSF6tkQUCVfI9qmACHOR5tThOetY=",
    "originContent": "</p>",
    "translatedContent": ""
  },
  {
    "row": 31,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "## 新闻"
  },
  {
    "row": 32,
    "rowsha": "4SzYJwNNDn2R2kkHsB4X4H4ZhUVuQo9QZvhInidlbxE=",
    "originContent": "## News",
    "translatedContent": ""
  },
  {
    "row": 33,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "<!-- **2025.06.20**: 发布Gradio演示 ([在线演示]() 和 [本地](#gradio-demo)) -->"
  },
  {
    "row": 34,
    "rowsha": "DvO2mRH79y/s564QyZ2J1KNV/QF1laSqmz/YKbmYdTs=",
    "originContent": "<!-- **2025.06.20**: Release Gradio demo ([online demo]() and [local](#gradio-demo)) -->",
    "translatedContent": ""
  },
  {
    "row": 35,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "<!-- **2025.06.05**: 评估代码，请参阅 [此链接](). -->"
  },
  {
    "row": 36,
    "rowsha": "hSacIbxwmFBK7ooEKlvh4QT0YtNYmDLLAs+FDj6qbac=",
    "originContent": "<!-- **2025.06.05**: Evaluation code Please refer to [this link](). -->",
    "translatedContent": ""
  },
  {
    "row": 37,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "**2025.06.08**：模型权重（1.5B / 3B）和训练数据集已发布。请参阅 [PAM-1.5B](https://huggingface.co/Perceive-Anything/PAM-1.5B)、[PAM-3B](https://huggingface.co/Perceive-Anything/PAM-3B) 和 [数据集](https://huggingface.co/datasets/Perceive-Anything/PAM-data)。"
  },
  {
    "row": 38,
    "rowsha": "TSf+7SKd1Oe09VjUnMdOMjvJEcMQT0DuHbBLR2IoyqI=",
    "originContent": "**2025.06.08**: Model weights (1.5B / 3B) and training datasets are released. Please refer to [PAM-1.5B](https://huggingface.co/Perceive-Anything/PAM-1.5B), [PAM-3B](https://huggingface.co/Perceive-Anything/PAM-3B) and [Datasets](https://huggingface.co/datasets/Perceive-Anything/PAM-data).",
    "translatedContent": ""
  },
  {
    "row": 39,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "**2025.06.08**：PAM发布，一种简单的端到端区域级视觉语言模型，用于对象分割和理解。详见 [论文](https://arxiv.org/abs/2506.05302)"
  },
  {
    "row": 40,
    "rowsha": "ruwIfjYXZO0CkGbsxTJDaB7wvaBXSfLGXDYB+Po7WqM=",
    "originContent": "**2025.06.08**: PAM is released, a simple end-to-end region-level VLM for object segmentation and understanding. See [paper](https://arxiv.org/abs/2506.05302)",
    "translatedContent": ""
  },
  {
    "row": 41,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 42,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "## 介绍"
  },
  {
    "row": 43,
    "rowsha": "11PvuraB+k2oJHDZqDscIC3lj5L9SY53omnBFjvEcUs=",
    "originContent": "## Introduction",
    "translatedContent": ""
  },
  {
    "row": 44,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "**感知一切模型（PAM）** 是一个概念上简单高效的框架，用于图像和视频中全面的区域级视觉理解。我们的方法在SAM 2的基础上整合了大型语言模型（LLMs），实现了对象分割与多样化区域语义输出的同步生成，包括类别、标签定义、功能解释和详细描述。我们提出高效转换SAM 2丰富的视觉特征，这些特征本质上包含通用视觉、定位和语义先验，转化为LLM可理解的多模态标记。为支持稳健的多粒度理解，我们开发了专门的数据精炼和增强流程，产出高质量的[**数据集**](https://huggingface.co/datasets/Perceive-Anything/PAM-data) ，包含图像和视频区域语义标注，包括新颖的区域级流媒体视频描述数据。"
  },
  {
    "row": 45,
    "rowsha": "Bdq1FyT78I/1pkG10SE2KIkm7FB1RB1orauszkM+h68=",
    "originContent": "**Perceive Anything Model (PAM)** is a conceptually simple and efficient framework for comprehensive region-level visual understanding in images and videos. Our approach extends SAM 2 by integrating Large Language Models (LLMs), enabling simultaneous object segmentation with the generation of diverse, region-specific semantic outputs, including categories, label definition, functional explanations, and detailed captions. We propose to efficiently transform SAM 2's rich visual features, which inherently carry general vision, localization, and semantic priors into multi-modal tokens for LLM comprehension. To support robust multi-granularity understanding, we develop a dedicated data refinement and augmentation pipeline, yielding a high-quality [**dataset**](https://huggingface.co/datasets/Perceive-Anything/PAM-data) of image and video region-semantic annotations, including novel region-level streaming video caption data.",
    "translatedContent": ""
  },
  {
    "row": 46,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 47,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "<p align=\"center\">"
  },
  {
    "row": 48,
    "rowsha": "+/a9XmPwQixGFroME/GMEOLpReZZV4ARosR9orAplJY=",
    "originContent": "<p align=\"center\">",
    "translatedContent": "    <img src=\"https://raw.githubusercontent.com/Perceive-Anything/PAM/main/assets/PAM_comp.jpg\" width=\"95%\"> <br>"
  },
  {
    "row": 49,
    "rowsha": "ZSwTYAS1dNyDxDCS/a4EJrDpLZf4FAG+Z+S+Aw/sIXY=",
    "originContent": "    <img src=\"https://raw.githubusercontent.com/Perceive-Anything/PAM/main/assets/PAM_comp.jpg\" width=\"95%\"> <br>",
    "translatedContent": "    <img src=\"https://raw.githubusercontent.com/Perceive-Anything/PAM/main/assets/PAM_arch.jpg\" width=\"95%\"> <br>"
  },
  {
    "row": 50,
    "rowsha": "z9qqwvEppZK5P+b/aAfq5/QMzFxIeQfUiIqAJUU+TqA=",
    "originContent": "    <img src=\"https://raw.githubusercontent.com/Perceive-Anything/PAM/main/assets/PAM_arch.jpg\" width=\"95%\"> <br>",
    "translatedContent": "</p>"
  },
  {
    "row": 51,
    "rowsha": "dSdvPNAZSmR86FDDSF6tkQUCVfI9qmACHOR5tThOetY=",
    "originContent": "</p>",
    "translatedContent": ""
  },
  {
    "row": 52,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "## 安装"
  },
  {
    "row": 53,
    "rowsha": "oV0SUDvwD2VN8Gi9nlr2JZ2xcDrASmE2W5kc5SVX5eo=",
    "originContent": "## Installation",
    "translatedContent": ""
  },
  {
    "row": 54,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "1. 克隆此仓库并进入基础文件夹</translate-content>"
  },
  {
    "row": 55,
    "rowsha": "voiiRpesg8vjXsT8FqO8cq1sOtFtqFs41tO/WrkMBgc=",
    "originContent": "1. Clone this repository and navigate to the base folder",
    "translatedContent": ""
  },
  {
    "row": 56,
    "rowsha": "rTMjNc+qNIxb1xXDR5hEYiJw1fc4muBwuBsTXVIaIho=",
    "originContent": "```bash",
    "translatedContent": "```bash"
  },
  {
    "row": 57,
    "rowsha": "mEKkmo14+SWiH+6KBI7znE6QWuGo+sg6KI+GqFs6R2Q=",
    "originContent": "git clone https://github.com/Afeng-x/PAM.git",
    "translatedContent": "git clone https://github.com/Afeng-x/PAM.git"
  },
  {
    "row": 58,
    "rowsha": "jH8XNhpI4d50FKbDb66lS+RMNc94TgAGq6EMb174rmA=",
    "originContent": "cd PAM",
    "translatedContent": "cd PAM"
  },
  {
    "row": 59,
    "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
    "originContent": "```",
    "translatedContent": "```"
  },
  {
    "row": 60,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "<translate-content>"
  },
  {
    "row": 61,
    "rowsha": "YmdM1BbfXpu/69Eru9NthqOiR9jXo55stWI6bDViwCA=",
    "originContent": "2. Install packages",
    "translatedContent": "2. 安装软件包</translate-content>"
  },
  {
    "row": 62,
    "rowsha": "rTMjNc+qNIxb1xXDR5hEYiJw1fc4muBwuBsTXVIaIho=",
    "originContent": "```bash",
    "translatedContent": "```bash"
  },
  {
    "row": 63,
    "rowsha": "zEmoMt1kGX6NST6M5xp0vRRoJBDQAIj/xQzul+O2fIg=",
    "originContent": "### packages for base",
    "translatedContent": "### packages for base"
  },
  {
    "row": 64,
    "rowsha": "5+ULBRv+3pFYQfNHwrAPC7Yo5+Pn+NU3/p1bj9RMrA4=",
    "originContent": "conda create -n PAM python=3.10 -y",
    "translatedContent": "conda create -n PAM python=3.10 -y"
  },
  {
    "row": 65,
    "rowsha": "ubnXA7HQ3iPf2eW23mh9sJlez8++fzsS/vQFs2lWYaQ=",
    "originContent": "conda activate PAM",
    "translatedContent": "conda activate PAM"
  },
  {
    "row": 66,
    "rowsha": "4HeOXyfmyX7wD0EclkMirgRrNQ+Zcno14B5zcF529Ls=",
    "originContent": "pip install --upgrade pip",
    "translatedContent": "pip install --upgrade pip"
  },
  {
    "row": 67,
    "rowsha": "hAjfhuHMe5Nt5kw4qY0uNDRQWSvw4fUY40vaxOd7k1Y=",
    "originContent": "pip install -e \".[train]\"",
    "translatedContent": "pip install -e \".[train]\""
  },
  {
    "row": 68,
    "rowsha": "oc9kklpjmzwqajStiHR4OVVoDFIJjpPRbzToZxluuBM=",
    "originContent": "### packages for sam2",
    "translatedContent": "### packages for sam2"
  },
  {
    "row": 69,
    "rowsha": "H12ZPPG6i2Q9nciDWoPLP4IL25lwIucqfClSrcG3udU=",
    "originContent": "cd sam2",
    "translatedContent": "cd sam2"
  },
  {
    "row": 70,
    "rowsha": "8e/IIcidN+paHo5qiONUlERAjxcuh5IkLAFR3aW1Hc0=",
    "originContent": "pip install -e \".[notebooks]\"",
    "translatedContent": "pip install -e \".[notebooks]\""
  },
  {
    "row": 71,
    "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
    "originContent": "```",
    "translatedContent": "```"
  },
  {
    "row": 72,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "3. 安装 Flash-Attention"
  },
  {
    "row": 73,
    "rowsha": "dcCsbI9WBUEfHDQwqHhnZ5b4WHSZMZ02bdMXjc7n30k=",
    "originContent": "3. Install Flash-Attention",
    "translatedContent": ""
  },
  {
    "row": 74,
    "rowsha": "rTMjNc+qNIxb1xXDR5hEYiJw1fc4muBwuBsTXVIaIho=",
    "originContent": "```bash",
    "translatedContent": "```bash"
  },
  {
    "row": 75,
    "rowsha": "XUy+Rsnrdygsnp+qxpwAV8gWF2O92l0+ExXhvmi5Epw=",
    "originContent": "pip install flash-attn --no-build-isolation",
    "translatedContent": "pip install flash-attn --no-build-isolation"
  },
  {
    "row": 76,
    "rowsha": "rTwF83f5fOxhfZWSmEGonIElsfeoEpGXLuc3JTr4O4w=",
    "originContent": "### (If the method mentioned above don’t work for you, try the following one)",
    "translatedContent": "### (If the method mentioned above don’t work for you, try the following one)"
  },
  {
    "row": 77,
    "rowsha": "3HxNjYJ9tigcDs03u6J8qtVVNfekedO1kmBUji6tKes=",
    "originContent": "git clone https://github.com/Dao-AILab/flash-attention.git",
    "translatedContent": "git clone https://github.com/Dao-AILab/flash-attention.git"
  },
  {
    "row": 78,
    "rowsha": "utv7W/KxWJRkwdZcZVkG7j0C0RFW7LIwwqfdYGKEHYY=",
    "originContent": "cd flash-attention",
    "translatedContent": "cd flash-attention"
  },
  {
    "row": 79,
    "rowsha": "ZTt6UdZddAnjGeKdUdXuKvZdYhrZ72IUjn6s+Z4omHk=",
    "originContent": "python setup.py install",
    "translatedContent": "python setup.py install"
  },
  {
    "row": 80,
    "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
    "originContent": "```",
    "translatedContent": "```"
  },
  {
    "row": 81,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "4. 下载 SAM2.1-h-large 检查点："
  },
  {
    "row": 82,
    "rowsha": "Q5aFFrhD4gB65A4ZsTME93MqrxqdKqfZXgGRZyqUZOQ=",
    "originContent": "4. Download the SAM2.1-h-large checkpoint:",
    "translatedContent": ""
  },
  {
    "row": 83,
    "rowsha": "rTMjNc+qNIxb1xXDR5hEYiJw1fc4muBwuBsTXVIaIho=",
    "originContent": "```bash",
    "translatedContent": "```bash"
  },
  {
    "row": 84,
    "rowsha": "IQB0dXX2uk5OJZOvlix0gzHTg4m6p1jvttloUjI2puU=",
    "originContent": "cd llava/model/multimodal_encoder",
    "translatedContent": "cd llava/model/multimodal_encoder"
  },
  {
    "row": 85,
    "rowsha": "M4skbOeEjFDq0jtmVnoVMd2EAlTaJVThk7Y3F1NxboU=",
    "originContent": "bash download_ckpts.sh",
    "translatedContent": "bash download_ckpts.sh"
  },
  {
    "row": 86,
    "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
    "originContent": "```",
    "translatedContent": "```"
  },
  {
    "row": 87,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "## 快速开始"
  },
  {
    "row": 88,
    "rowsha": "GYXdIjDxn3gFPf/dh+IWvA3hUoHtZx8D7kUCccNTdZA=",
    "originContent": "## Quick Start",
    "translatedContent": ""
  },
  {
    "row": 89,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "- 图片：请参考[image_infer_example.ipynb](https://raw.githubusercontent.com/Perceive-Anything/PAM/main/./notebooks/image_infer_example.ipynb)中的示例"
  },
  {
    "row": 90,
    "rowsha": "FniYRGjdiJ8TxzAPVffTtECa2LMlASoypV4BSUbwbh4=",
    "originContent": "- Image: Please refer to the examples in [image_infer_example.ipynb](https://raw.githubusercontent.com/Perceive-Anything/PAM/main/./notebooks/image_infer_example.ipynb)",
    "translatedContent": "- 视频：请参考[video_infer_example.ipynb](https://raw.githubusercontent.com/Perceive-Anything/PAM/main/./notebooks/video_infer_example.ipynb)中的示例"
  },
  {
    "row": 91,
    "rowsha": "d6AB+1SBmpJkm8SH9AzEjFK+osnCrxd1JhDOusQK3j0=",
    "originContent": "- Video: Please refer to the examples in [video_infer_example.ipynb](https://raw.githubusercontent.com/Perceive-Anything/PAM/main/./notebooks/video_infer_example.ipynb)",
    "translatedContent": "- 视频流：请参考[video_stream_infer_example.ipynb](https://raw.githubusercontent.com/Perceive-Anything/PAM/main/./notebooks/video_stream_infer_example.ipynb)中的示例"
  },
  {
    "row": 92,
    "rowsha": "LGJM5HrYG1F8BVICnV5ROsj8lgmm83M506sAb8tGLgU=",
    "originContent": "- Video Stream: Please refer to the examples in [video_stream_infer_example.ipynb](https://raw.githubusercontent.com/Perceive-Anything/PAM/main/./notebooks/video_stream_infer_example.ipynb)",
    "translatedContent": ""
  },
  {
    "row": 93,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "## 数据集"
  },
  {
    "row": 94,
    "rowsha": "b78xXK39qETPK4hVKtMuRkDqmW+LfM4n0ASOYbXbu9c=",
    "originContent": "## Dataset",
    "translatedContent": ""
  },
  {
    "row": 95,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "请访问[此链接](https://huggingface.co/datasets/Perceive-Anything/PAM-data)下载我们精炼和增强的数据注释。"
  },
  {
    "row": 96,
    "rowsha": "6yBaKsXHT33RlIGhiUwickFdR4yptAFsaeHIiCrFMnw=",
    "originContent": "Please refer to [this link](https://huggingface.co/datasets/Perceive-Anything/PAM-data) to download our refined and augmented data annotations.",
    "translatedContent": ""
  },
  {
    "row": 97,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "**注意：** 我们不直接提供源图像。但对于每个数据集，我们会提供相关的下载链接或官方网站地址，以指导用户如何下载。[DATA_README](https://raw.githubusercontent.com/Perceive-Anything/PAM/main/data/README.md)"
  },
  {
    "row": 98,
    "rowsha": "6Hsur4fPrVj7Ckvg1w1qfdDbzHk2LtrQJ5YuX8eARmg=",
    "originContent": "**Note:** We do not directly provide the source images. However, for each dataset, we will provide the relevant download links or official website addresses to guide users on how to download them. [DATA_README](https://raw.githubusercontent.com/Perceive-Anything/PAM/main/data/README.md)",
    "translatedContent": ""
  },
  {
    "row": 99,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "<!-- ## 训练 PAM"
  },
  {
    "row": 100,
    "rowsha": "v5WqTWmYgyQWgqIbCsfVZ9upxYlL/X8cEuKg1nIuQlI=",
    "originContent": "<!-- ## Training PAM",
    "translatedContent": ""
  },
  {
    "row": 101,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "您可以在自定义的图像、视频或两者混合数据集上训练或微调 PAM。请查看训练[README](https://raw.githubusercontent.com/Perceive-Anything/PAM/main/training/README.md)了解如何开始。 -->"
  },
  {
    "row": 102,
    "rowsha": "13nvsuvRk2eeIidr9j3DlODt6SK8rHwVhiPF5jCqua0=",
    "originContent": "You can train or fine-tune PAM on custom datasets of images, videos, or both. Please check the training [README](https://raw.githubusercontent.com/Perceive-Anything/PAM/main/training/README.md) on how to get started. -->",
    "translatedContent": ""
  },
  {
    "row": 103,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": "## PAM 本地 Gradio 演示"
  },
  {
    "row": 104,
    "rowsha": "M0mxAU5cSD2o/QatE14PKkzx00xnQZJ0F+QWnhD0gfA=",
    "originContent": "## Local Gradio Demo for PAM",
    "translatedContent": "进行中 ......"
  },
  {
    "row": 105,
    "rowsha": "Fqq+rxZMa8/3MPUv913AwH4BuA7H5McKgo801FlJO2o=",
    "originContent": "In progress ......",
    "translatedContent": ""
  },
  {
    "row": 106,
    "rowsha": "X7a4jS3651swy5ANmGbDUBuRWjUlDbLaqVQ/A0db38g=",
    "originContent": "<!-- ### Simple Gradio Demo for Image",
    "translatedContent": "<!-- ### 简单的图片 Gradio 演示"
  },
  {
    "row": 107,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 108,
    "rowsha": "d+QSwhe/aMa8wJTHwqIBVqUfYF0X+CCGvuirDCk2usM=",
    "originContent": "[`pam_image.py`](https://raw.githubusercontent.com/Perceive-Anything/PAM/main/pam_image.py) - Interactive Gradio web interface for drawing masks on images and getting semantics. **This demo is tested with `gradio` 5.5.0.**",
    "translatedContent": "[`pam_image.py`](https://raw.githubusercontent.com/Perceive-Anything/PAM/main/pam_image.py) - 用于在图像上绘制掩码并获取语义的交互式 Gradio 网络界面。**该演示已在 `gradio` 5.5.0 版本测试。**"
  },
  {
    "row": 109,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 110,
    "rowsha": "AEHzeUNa2bh4+D1Mr/H/3MRA4QmuzHsH8blIIys4Ya0=",
    "originContent": "### Simple Gradio Demo for Video",
    "translatedContent": "### 简单的视频 Gradio 演示"
  },
  {
    "row": 111,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 112,
    "rowsha": "vbrnItjnReH1BKxR5/fBDoH2vtTE9mlfohi7EM/WJNY=",
    "originContent": "[`pam_video.py`](https://raw.githubusercontent.com/Perceive-Anything/PAM/main/pam_video.py) - Interactive Gradio web interface for drawing masks on videos and getting semantics. **This demo is tested with `gradio` 5.5.0.** -->",
    "translatedContent": "[`pam_video.py`](https://raw.githubusercontent.com/Perceive-Anything/PAM/main/pam_video.py) - 用于在视频上绘制掩码并获取语义的交互式 Gradio 网络界面。**该演示已在 `gradio` 5.5.0 版本测试。** -->"
  },
  {
    "row": 113,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 114,
    "rowsha": "bFSaVtsB4CHySNjaeCiaMZfT24b+DTbTM4HQ38cR6Lw=",
    "originContent": "## License",
    "translatedContent": "## 许可"
  },
  {
    "row": 115,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 116,
    "rowsha": "AF9nb80DaT8BnpedW5RyOIKjTDw3dWBNkEhMdQv4UrA=",
    "originContent": "This code repository is licensed under [Apache 2.0](./LICENSE).",
    "translatedContent": "本代码库采用[Apache 2.0](./LICENSE)许可协议。"
  },
  {
    "row": 117,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 118,
    "rowsha": "zeUL2mcUYd628fTHqknKcxv2uqjN5wj1hlMFcVnzrpU=",
    "originContent": "## Acknowledgement",
    "translatedContent": "## 致谢"
  },
  {
    "row": 119,
    "rowsha": "rVu5UB+QsUrtMJB8OQu7ZEUX1A1ilZEU8ZA+D99SfqM=",
    "originContent": "We would like to thank the following projects for their contributions to this work:",
    "translatedContent": "我们感谢以下项目对本工作的贡献："
  },
  {
    "row": 120,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 121,
    "rowsha": "hX3rgAq0rtpM4Q4t18VEfL0stVBASB6I2FwS5heqGC0=",
    "originContent": "- [LLaVA-Next](https://github.com/LLaVA-VL/LLaVA-NeXT)",
    "translatedContent": "- [LLaVA-Next](https://github.com/LLaVA-VL/LLaVA-NeXT)"
  },
  {
    "row": 122,
    "rowsha": "406OoSziw7952fVcWIXGbrz86NwrAh3RYYSWBFg9YyA=",
    "originContent": "- [SAM](https://github.com/facebookresearch/segment-anything)",
    "translatedContent": "- [SAM](https://github.com/facebookresearch/segment-anything)"
  },
  {
    "row": 123,
    "rowsha": "6MDJdOZh1zfHl4U0dY8vU/wWsjOnSXnmGHw53OiLqlY=",
    "originContent": "- [SAM 2](https://github.com/facebookresearch/sam2)",
    "translatedContent": "- [SAM 2](https://github.com/facebookresearch/sam2)"
  },
  {
    "row": 124,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 125,
    "rowsha": "ZwTp5ajUmpHTJefyHhIKzXcG2wnB1jv8iv8cvmdcb/g=",
    "originContent": "## Citation",
    "translatedContent": "## 引用"
  },
  {
    "row": 126,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 127,
    "rowsha": "IfUdVHL0Y6WthdLTe7g1FRzV2HI+6Mh2w7TxLrsTBSA=",
    "originContent": "If you find PAM useful for your research and applications, or use our dataset in your research, please use the following BibTeX entry.",
    "translatedContent": "如果您发现 PAM 对您的研究和应用有用，或在研究中使用了我们的数据集，请使用以下 BibTeX 条目。"
  },
  {
    "row": 128,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 129,
    "rowsha": "o+TmyQ6wneV6/FQB6aUlRSjIGr2/YLJtnz5uxBgsScQ=",
    "originContent": "```bibtex",
    "translatedContent": "```bibtex"
  },
  {
    "row": 130,
    "rowsha": "li5emVkiOq0Isx//nA/oz9cR5yjnaqjVVmOQs+EskJU=",
    "originContent": "@misc{lin2025perceiveanythingrecognizeexplain,",
    "translatedContent": "@misc{lin2025perceiveanythingrecognizeexplain,"
  },
  {
    "row": 131,
    "rowsha": "FrJtZCu3SE/fzqpptIj6tAEoqh34yPE7rhg2H4G5NA4=",
    "originContent": "      title={Perceive Anything: Recognize, Explain, Caption, and Segment Anything in Images and Videos}, ",
    "translatedContent": "      title={Perceive Anything: Recognize, Explain, Caption, and Segment Anything in Images and Videos}, "
  },
  {
    "row": 132,
    "rowsha": "ZYIizhu1oaj7dJG/yV351K2/vq3ghf4FR9PmkfouK6A=",
    "originContent": "      author={Weifeng Lin and Xinyu Wei and Ruichuan An and Tianhe Ren and Tingwei Chen and Renrui Zhang and Ziyu Guo and Wentao Zhang and Lei Zhang and Hongsheng Li},",
    "translatedContent": "      author={Weifeng Lin and Xinyu Wei and Ruichuan An and Tianhe Ren and Tingwei Chen and Renrui Zhang and Ziyu Guo and Wentao Zhang and Lei Zhang and Hongsheng Li},"
  },
  {
    "row": 133,
    "rowsha": "1cuvfM9h03loQfZOlvsx9juVCvU41kevaYb2CnD9Gak=",
    "originContent": "      year={2025},",
    "translatedContent": "      year={2025},"
  },
  {
    "row": 134,
    "rowsha": "62XrX8MO6yVEmpfSz9W6MlqPFggOvmVkN2p0lbF/8qM=",
    "originContent": "      eprint={2506.05302},",
    "translatedContent": "      eprint={2506.05302},"
  },
  {
    "row": 135,
    "rowsha": "Fr73/KLqU4TaDaJVUDLO211nM029JE4YRpN5hXSZZqk=",
    "originContent": "      archivePrefix={arXiv},",
    "translatedContent": "      archivePrefix={arXiv},"
  },
  {
    "row": 136,
    "rowsha": "RPNBhgHdrY2A+XYLnuhpAr/aqag2LU2pAjasgtM0tg4=",
    "originContent": "      primaryClass={cs.CV},",
    "translatedContent": "      primaryClass={cs.CV},"
  },
  {
    "row": 137,
    "rowsha": "8x681W0MrZUYt6PwtBSJtAEsYEjdij3GHuES+7UreY0=",
    "originContent": "      url={https://arxiv.org/abs/2506.05302}, ",
    "translatedContent": "      url={https://arxiv.org/abs/2506.05302}, "
  },
  {
    "row": 138,
    "rowsha": "0Qs2qnSlm89KiBhYN/ZYr682Ru/yuxbDko0OkzXpRdI=",
    "originContent": "}",
    "translatedContent": "}"
  },
  {
    "row": 139,
    "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
    "originContent": "```",
    "translatedContent": "```"
  },
  {
    "row": 140,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  },
  {
    "row": 141,
    "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
    "originContent": "",
    "translatedContent": ""
  }
]