<div align="center">
<h1>
ä½•ã§ã‚‚èªè­˜ï¼šç”»åƒã¨å‹•ç”»ã®ã‚ã‚‰ã‚†ã‚‹ã‚‚ã®ã‚’èªè­˜ã€èª¬æ˜ã€ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ä»˜ã‘ã€ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåŒ–ï¼ˆPAMï¼‰
</h1>

</div>

<div align="center">

[Weifeng Lin](), [Xinyu Wei](), [Ruichuan An](), [Tianhe Ren](), [Tingwei Chen](), [Renrui Zhang](), [Ziyu Guo]() <br>
[Wentao Zhang](), [Lei Zhang](), [Hongsheng Li]() <br>
CUHKã€HKUã€PolyUã€åŒ—äº¬å¤§å­¦

</div>

<p align="center">
  <a href="https://Perceive-Anything.github.io"><b>ğŸŒ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚µã‚¤ãƒˆ</b></a> |
  <a href="https://arxiv.org/abs/2506.05302"><b>ğŸ“• è«–æ–‡</b></a> |
  <a href="https://huggingface.co/Perceive-Anything/PAM-3B"><b>ğŸ“¥ ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰</b></a> |
  <a href="https://huggingface.co/datasets/Perceive-Anything/PAM-data"><b>ğŸ¤— ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ</b></a> |
  <a href="#quick-start"><b>âš¡ ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ</b></a> <br>
  <a href="#license"><b>ğŸ“œ ãƒ©ã‚¤ã‚»ãƒ³ã‚¹</b></a> |
  <a href="#citation"><b>ğŸ“– å¼•ç”¨ (BibTeX)</b></a> <br>
</p>

<p align="center">
    <img src="https://raw.githubusercontent.com/Perceive-Anything/PAM/main/assets/teaser_img.jpg" width="95%"> <br>
    <img src="https://raw.githubusercontent.com/Perceive-Anything/PAM/main/assets/teaser_video.jpg" width="95%"> <br>
</p>

## ãƒ‹ãƒ¥ãƒ¼ã‚¹

<!-- **2025.06.20**: Gradioãƒ‡ãƒ¢å…¬é–‹ï¼ˆ[ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ãƒ‡ãƒ¢]() ã¨ [ãƒ­ãƒ¼ã‚«ãƒ«](#gradio-demo)ï¼‰ -->

<!-- **2025.06.05**: è©•ä¾¡ã‚³ãƒ¼ãƒ‰ã¯[ã“ã¡ã‚‰]()ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚ -->

**2025.06.08**: ãƒ¢ãƒ‡ãƒ«é‡ã¿ï¼ˆ1.5B / 3Bï¼‰ãŠã‚ˆã³å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’å…¬é–‹ã—ã¾ã—ãŸã€‚è©³ç´°ã¯ [PAM-1.5B](https://huggingface.co/Perceive-Anything/PAM-1.5B)ã€[PAM-3B](https://huggingface.co/Perceive-Anything/PAM-3B)ã€ãŠã‚ˆã³ [ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ](https://huggingface.co/datasets/Perceive-Anything/PAM-data)ã‚’ã”è¦§ãã ã•ã„ã€‚

**2025.06.08**: PAMã‚’ãƒªãƒªãƒ¼ã‚¹ã—ã¾ã—ãŸã€‚ã“ã‚Œã¯ç‰©ä½“ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã¨ç†è§£ã®ãŸã‚ã®ã‚·ãƒ³ãƒ—ãƒ«ãªã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ã®é ˜åŸŸãƒ¬ãƒ™ãƒ«VLMã§ã™ã€‚è«–æ–‡ã¯[ã“ã¡ã‚‰](https://arxiv.org/abs/2506.05302)ã‚’ã”è¦§ãã ã•ã„ã€‚


## ã¯ã˜ã‚ã«

**Perceive Anything Model (PAM)** ã¯ã€ç”»åƒãŠã‚ˆã³å‹•ç”»ã®åŒ…æ‹¬çš„ãªé ˜åŸŸãƒ¬ãƒ™ãƒ«ã®è¦–è¦šç†è§£ã®ãŸã‚ã®ã€æ¦‚å¿µçš„ã«ã‚·ãƒ³ãƒ—ãƒ«ã§åŠ¹ç‡çš„ãªãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã™ã€‚ç§ãŸã¡ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯ã€SAM 2ã‚’æ‹¡å¼µã—ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMï¼‰ã‚’çµ±åˆã™ã‚‹ã“ã¨ã§ã€å¤šæ§˜ã§é ˜åŸŸç‰¹æœ‰ã®ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯å‡ºåŠ›ï¼ˆã‚«ãƒ†ã‚´ãƒªã€ãƒ©ãƒ™ãƒ«å®šç¾©ã€æ©Ÿèƒ½èª¬æ˜ã€è©³ç´°ãªã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ãªã©ï¼‰ã‚’ç”Ÿæˆã—ãªãŒã‚‰ã€åŒæ™‚ã«ç‰©ä½“ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å¯èƒ½ã«ã—ã¾ã™ã€‚SAM 2ã®è±Šå¯Œãªè¦–è¦šç‰¹å¾´ã¯ã€ä¸€èˆ¬çš„ãªãƒ“ã‚¸ãƒ§ãƒ³ã€ä½ç½®ç‰¹å®šã€ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯äº‹å‰çŸ¥è­˜ã‚’æœ¬è³ªçš„ã«å«ã‚“ã§ã„ã‚‹ãŸã‚ã€ã“ã‚Œã‚’åŠ¹ç‡çš„ã«ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒˆãƒ¼ã‚¯ãƒ³ã«å¤‰æ›ã—ã€LLMãŒç†è§£ã§ãã‚‹ã‚ˆã†ã«ã—ã¦ã„ã¾ã™ã€‚å …ç‰¢ãªå¤šç²’åº¦ç†è§£ã‚’æ”¯ãˆã‚‹ãŸã‚ã«ã€å°‚ç”¨ã®ãƒ‡ãƒ¼ã‚¿ç²¾è£½ãŠã‚ˆã³æ‹¡å¼µãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’é–‹ç™ºã—ã€æ–°ã—ã„é ˜åŸŸãƒ¬ãƒ™ãƒ«ã®ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‹•ç”»ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚€é«˜å“è³ªãª[**ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ**](https://huggingface.co/datasets/Perceive-Anything/PAM-data)ã‚’ç”Ÿæˆã—ã¾ã—ãŸã€‚


<p align="center">
    <img src="https://raw.githubusercontent.com/Perceive-Anything/PAM/main/assets/PAM_comp.jpg" width="95%"> <br>
    <img src="https://raw.githubusercontent.com/Perceive-Anything/PAM/main/assets/PAM_arch.jpg" width="95%"> <br>
</p>

## ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

1. ã“ã®ãƒªãƒã‚¸ãƒˆãƒªã‚’ã‚¯ãƒ­ãƒ¼ãƒ³ã—ã€ãƒ™ãƒ¼ã‚¹ãƒ•ã‚©ãƒ«ãƒ€ã«ç§»å‹•ã—ã¾ã™</translate-content>

```bash
git clone https://github.com/Afeng-x/PAM.git
cd PAM
```
2. ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹

```bash
### packages for base
conda create -n PAM python=3.10 -y
conda activate PAM
pip install --upgrade pip
pip install -e ".[train]"
### packages for sam2
cd sam2
pip install -e ".[notebooks]"
```
3. Flash-Attentionã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

```bash
pip install flash-attn --no-build-isolation
### (If the method mentioned above donâ€™t work for you, try the following one)
git clone https://github.com/Dao-AILab/flash-attention.git
cd flash-attention
python setup.py install
```
4. SAM2.1-h-large ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ï¼š

```bash
cd llava/model/multimodal_encoder
bash download_ckpts.sh
```
## ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ

- ç”»åƒï¼š [image_infer_example.ipynb](https://raw.githubusercontent.com/Perceive-Anything/PAM/main/./notebooks/image_infer_example.ipynb) ã®ä¾‹ã‚’å‚ç…§ã—ã¦ãã ã•ã„
- ãƒ“ãƒ‡ã‚ªï¼š [video_infer_example.ipynb](https://raw.githubusercontent.com/Perceive-Anything/PAM/main/./notebooks/video_infer_example.ipynb) ã®ä¾‹ã‚’å‚ç…§ã—ã¦ãã ã•ã„
- ãƒ“ãƒ‡ã‚ªã‚¹ãƒˆãƒªãƒ¼ãƒ ï¼š [video_stream_infer_example.ipynb](https://raw.githubusercontent.com/Perceive-Anything/PAM/main/./notebooks/video_stream_infer_example.ipynb) ã®ä¾‹ã‚’å‚ç…§ã—ã¦ãã ã•ã„

## ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ

å½“ç¤¾ã®æ´—ç·´ã•ã‚ŒãŸæ‹¡å¼µãƒ‡ãƒ¼ã‚¿æ³¨é‡ˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã«ã¯ã€[ã“ã¡ã‚‰ã®ãƒªãƒ³ã‚¯](https://huggingface.co/datasets/Perceive-Anything/PAM-data)ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚

**æ³¨æ„:** ã‚½ãƒ¼ã‚¹ç”»åƒã¯ç›´æ¥æä¾›ã—ã¦ã„ã¾ã›ã‚“ã€‚ãŸã ã—ã€å„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ã¤ã„ã¦ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ–¹æ³•ã‚’æ¡ˆå†…ã§ãã‚‹ã‚ˆã†ã«ã€é–¢é€£ã™ã‚‹ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒªãƒ³ã‚¯ã¾ãŸã¯å…¬å¼ã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆã®ã‚¢ãƒ‰ãƒ¬ã‚¹ã‚’æä¾›ã—ã¾ã™ã€‚ [DATA_README](https://raw.githubusercontent.com/Perceive-Anything/PAM/main/data/README.md)

<!-- ## PAMã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°

ç”»åƒã€ãƒ“ãƒ‡ã‚ªã€ã¾ãŸã¯ãã®ä¸¡æ–¹ã®ã‚«ã‚¹ã‚¿ãƒ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§PAMã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¾ãŸã¯ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã§ãã¾ã™ã€‚é–‹å§‹æ–¹æ³•ã«ã¤ã„ã¦ã¯ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®[README](https://raw.githubusercontent.com/Perceive-Anything/PAM/main/training/README.md)ã‚’ã”ç¢ºèªãã ã•ã„ã€‚ -->

## PAMã®ãƒ­ãƒ¼ã‚«ãƒ«Gradioãƒ‡ãƒ¢
é€²è¡Œä¸­ ......

<!-- ### ç”»åƒç”¨ã‚·ãƒ³ãƒ—ãƒ«Gradioãƒ‡ãƒ¢

[`pam_image.py`](https://raw.githubusercontent.com/Perceive-Anything/PAM/main/pam_image.py) - ç”»åƒä¸Šã§ãƒã‚¹ã‚¯ã‚’æç”»ã—æ„å‘³æƒ…å ±ã‚’å–å¾—ã™ã‚‹ãŸã‚ã®ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªGradioã‚¦ã‚§ãƒ–ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã€‚**ã“ã®ãƒ‡ãƒ¢ã¯ `gradio` 5.5.0ã§ãƒ†ã‚¹ãƒˆã•ã‚Œã¦ã„ã¾ã™ã€‚**

### ãƒ“ãƒ‡ã‚ªç”¨ã‚·ãƒ³ãƒ—ãƒ«Gradioãƒ‡ãƒ¢

[`pam_video.py`](https://raw.githubusercontent.com/Perceive-Anything/PAM/main/pam_video.py) - ãƒ“ãƒ‡ã‚ªä¸Šã§ãƒã‚¹ã‚¯ã‚’æç”»ã—æ„å‘³æƒ…å ±ã‚’å–å¾—ã™ã‚‹ãŸã‚ã®ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªGradioã‚¦ã‚§ãƒ–ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã€‚**ã“ã®ãƒ‡ãƒ¢ã¯ `gradio` 5.5.0ã§ãƒ†ã‚¹ãƒˆã•ã‚Œã¦ã„ã¾ã™ã€‚** -->

## ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

ã“ã®ã‚³ãƒ¼ãƒ‰ãƒªãƒã‚¸ãƒˆãƒªã¯[Apache 2.0](./LICENSE)ã®ä¸‹ã§ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã•ã‚Œã¦ã„ã¾ã™ã€‚

## è¬è¾
ã“ã®ç ”ç©¶ã«è²¢çŒ®ã—ã¦ãã ã•ã£ãŸä»¥ä¸‹ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«æ„Ÿè¬ã„ãŸã—ã¾ã™ï¼š

- [LLaVA-Next](https://github.com/LLaVA-VL/LLaVA-NeXT)
- [SAM](https://github.com/facebookresearch/segment-anything)
- [SAM 2](https://github.com/facebookresearch/sam2)

## å¼•ç”¨

PAMãŒã‚ãªãŸã®ç ”ç©¶ã‚„ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã«å½¹ç«‹ã¤å ´åˆã€ã¾ãŸã¯å½“ç¤¾ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç ”ç©¶ã«ä½¿ç”¨ã™ã‚‹å ´åˆã¯ã€ä»¥ä¸‹ã®BibTeXã‚¨ãƒ³ãƒˆãƒªã‚’ã”åˆ©ç”¨ãã ã•ã„ã€‚

```bibtex
@misc{lin2025perceiveanythingrecognizeexplain,
      title={Perceive Anything: Recognize, Explain, Caption, and Segment Anything in Images and Videos}, 
      author={Weifeng Lin and Xinyu Wei and Ruichuan An and Tianhe Ren and Tingwei Chen and Renrui Zhang and Ziyu Guo and Wentao Zhang and Lei Zhang and Hongsheng Li},
      year={2025},
      eprint={2506.05302},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2506.05302}, 
}
```



---

Tranlated By [Open Ai Tx](https://github.com/OpenAiTx/OpenAiTx) | Last indexed: 2025-07-19

---