# Open WebUI ğŸ‘‹

![GitHub stars](https://img.shields.io/github/stars/open-webui/open-webui?style=social)
![GitHub forks](https://img.shields.io/github/forks/open-webui/open-webui?style=social)
![GitHub watchers](https://img.shields.io/github/watchers/open-webui/open-webui?style=social)
![GitHub repo size](https://img.shields.io/github/repo-size/open-webui/open-webui)
![GitHub language count](https://img.shields.io/github/languages/count/open-webui/open-webui)
![GitHub top language](https://img.shields.io/github/languages/top/open-webui/open-webui)
![GitHub last commit](https://img.shields.io/github/last-commit/open-webui/open-webui?color=red)
[![Discord](https://img.shields.io/badge/Discord-Open_WebUI-blue?logo=discord&logoColor=white)](https://discord.gg/5rJgQTnV4s)
[![](https://img.shields.io/static/v1?label=Sponsor&message=%E2%9D%A4&logo=GitHub&color=%23fe8e86)](https://github.com/sponsors/tjbck)

**Open WebUI Ã© uma [plataforma de IA auto-hospedada](https://docs.openwebui.com/features/plugin/) extensÃ­vel, rica em recursos e fÃ¡cil de usar, projetada para operar totalmente offline.** Suporta vÃ¡rios interpretadores de LLM como **Ollama** e **APIs compatÃ­veis com OpenAI**, com **motor de inferÃªncia integrado** para RAG, tornando-se uma **soluÃ§Ã£o poderosa de implantaÃ§Ã£o de IA**.

![Open WebUI Demo](./demo.gif)

> [!TIP]  
> **Procurando um [Plano Empresarial](https://docs.openwebui.com/enterprise)?** â€“ **[Fale com nosso time de vendas hoje!](mailto:sales@openwebui.com)**
>
> Obtenha **capacidades aprimoradas**, incluindo **personalizaÃ§Ã£o de tema e marca**, **suporte a SLA**, **versÃµes LTS** e **muito mais!**

Para mais informaÃ§Ãµes, consulte nossa [DocumentaÃ§Ã£o Open WebUI](https://docs.openwebui.com/).

## Principais Recursos do Open WebUI â­

- ğŸš€ **ConfiguraÃ§Ã£o FÃ¡cil**: Instale facilmente usando Docker ou Kubernetes (kubectl, kustomize ou helm) para uma experiÃªncia sem complicaÃ§Ãµes com suporte para imagens marcadas como `:ollama` e `:cuda`.

- ğŸ¤ **IntegraÃ§Ã£o API Ollama/OpenAI**: Integre APIs compatÃ­veis com OpenAI para conversas versÃ¡teis junto com modelos Ollama. Personalize a URL da API OpenAI para conectar com **LMStudio, GroqCloud, Mistral, OpenRouter e mais**.

- ğŸ›¡ï¸ **PermissÃµes Granulares e Grupos de UsuÃ¡rios**: Permitindo que administradores criem funÃ§Ãµes e permissÃµes detalhadas, garantimos um ambiente seguro. Essa granularidade aprimora a seguranÃ§a e permite experiÃªncias personalizadas para os usuÃ¡rios, fomentando senso de responsabilidade.

- ğŸ“± **Design Responsivo**: Tenha uma experiÃªncia fluida em PC, notebook e dispositivos mÃ³veis.

- ğŸ“± **Progressive Web App (PWA) para Mobile**: Tenha uma experiÃªncia nativa no seu dispositivo mÃ³vel com nossa PWA, com acesso offline no localhost e interface fluida.

- âœ’ï¸ğŸ”¢ **Suporte Completo a Markdown e LaTeX**: Eleve sua experiÃªncia com LLM com recursos completos de Markdown e LaTeX para interaÃ§Ãµes enriquecidas.

- ğŸ¤ğŸ“¹ **Chamada de Voz/VÃ­deo Sem Uso das MÃ£os**: ComunicaÃ§Ã£o fluida com recursos integrados de chamada de voz e vÃ­deo, tornando o chat mais dinÃ¢mico e interativo.

- ğŸ› ï¸ **Construtor de Modelos**: Crie modelos Ollama facilmente via Web UI. Adicione personagens/agentes personalizados, ajuste elementos do chat e importe modelos via integraÃ§Ã£o com a [Comunidade Open WebUI](https://openwebui.com/).

- ğŸ **Ferramenta Nativa de Chamadas de FunÃ§Ã£o Python**: Potencialize seus LLMs com editor de cÃ³digo integrado no workspace de ferramentas. Traga sua prÃ³pria funÃ§Ã£o (BYOF) adicionando funÃ§Ãµes Python puras, integrando-as aos LLMs.

- ğŸ“š **IntegraÃ§Ã£o RAG Local**: Explore o futuro das interaÃ§Ãµes de chat com suporte inovador ao Retrieval Augmented Generation (RAG). Carregue documentos diretamente no chat ou adicione arquivos Ã  biblioteca, acessando-os facilmente com o comando `#` antes de uma consulta.

- ğŸ” **Pesquisa Web para RAG**: Realize pesquisas na web usando provedores como `SearXNG`, `Google PSE`, `Brave Search`, `serpstack`, `serper`, `Serply`, `DuckDuckGo`, `TavilySearch`, `SearchApi` e `Bing`, injetando resultados direto no chat.

- ğŸŒ **Capacidade de NavegaÃ§Ã£o Web**: Integre websites ao chat usando o comando `#` seguido de uma URL. Incorpore conteÃºdos web diretamente nas conversas, enriquecendo suas interaÃ§Ãµes.

- ğŸ¨ **IntegraÃ§Ã£o de GeraÃ§Ã£o de Imagens**: Incorpore geraÃ§Ã£o de imagens usando opÃ§Ãµes como API AUTOMATIC1111 ou ComfyUI (local), e DALL-E da OpenAI (externo), enriquecendo o chat com conteÃºdo visual dinÃ¢mico.

- âš™ï¸ **Conversas com VÃ¡rios Modelos**: Interaja com diversos modelos simultaneamente, aproveitando seus pontos fortes para respostas Ã³timas. Potencialize sua experiÃªncia com um conjunto diversificado de modelos em paralelo.

- ğŸ” **Controle de Acesso Baseado em FunÃ§Ã£o (RBAC)**: Garanta acesso seguro com permissÃµes restritas; apenas pessoas autorizadas acessam seu Ollama, e apenas administradores podem criar/puxar modelos.

- ğŸŒğŸŒ **Suporte MultilÃ­ngue**: Use o Open WebUI no idioma de sua preferÃªncia com suporte internacional (i18n). Ajude-nos a expandir os idiomas suportados! Procuramos colaboradores!

- ğŸ§© **Pipelines, Suporte a Plugins Open WebUI**: Integre lÃ³gica personalizada e bibliotecas Python usando o [Pipelines Plugin Framework](https://github.com/open-webui/pipelines). Inicie sua instÃ¢ncia Pipelines, defina a URL OpenAI para a URL do Pipelines e explore possibilidades. [Exemplos](https://github.com/open-webui/pipelines/tree/main/examples) incluem **Chamadas de FunÃ§Ã£o**, **Limite de Taxa** para controlar acesso, **Monitoramento de Uso** com Langfuse, **TraduÃ§Ã£o ao Vivo com LibreTranslate** para suporte multilÃ­ngue, **Filtro de Mensagens TÃ³xicas** e muito mais.

- ğŸŒŸ **AtualizaÃ§Ãµes ContÃ­nuas**: Estamos comprometidos em melhorar o Open WebUI com atualizaÃ§Ãµes regulares, correÃ§Ãµes e novos recursos.

Quer saber mais sobre os recursos do Open WebUI? Confira nossa [documentaÃ§Ã£o](https://docs.openwebui.com/features) para uma visÃ£o completa!

## Patrocinadores ğŸ™Œ

#### Esmeralda

<table>
  <tr>
    <td>
      <a href="https://n8n.io/" target="_blank">
        <img src="https://docs.openwebui.com/sponsors/logos/n8n.png" alt="n8n" style="width: 8rem; height: 8rem; border-radius: .75rem;" />
      </a>
    </td>
    <td>
      N8N â€¢ Sua interface jÃ¡ tem backend?<br>Experimente o <a href="https://n8n.io/">n8n</a>
    </td>
  </tr>
  <tr>
    <td>
      <a href="https://warp.dev/open-webui" target="_blank">
        <img src="https://docs.openwebui.com/sponsors/logos/warp.png" alt="n8n" style="width: 8rem; height: 8rem; border-radius: .75rem;" />
      </a>
    </td>
    <td>
      <a href="https://warp.dev/open-webui">Warp</a> â€¢ O terminal inteligente para desenvolvedores
    </td>
  </tr>
</table>

---

Somos extremamente gratos pelo apoio generoso dos nossos patrocinadores. Suas contribuiÃ§Ãµes nos ajudam a manter e melhorar o projeto, garantindo que possamos entregar trabalho de qualidade Ã  comunidade. Obrigado!

## Como Instalar ğŸš€

### InstalaÃ§Ã£o via pip do Python ğŸ

O Open WebUI pode ser instalado usando o pip, o instalador de pacotes Python. Antes de prosseguir, certifique-se de estar usando **Python 3.11** para evitar problemas de compatibilidade.

1. **Instale o Open WebUI**:
   Abra o terminal e execute o comando a seguir para instalar o Open WebUI:

   ```bash
   pip install open-webui
   ```

2. **Executando o Open WebUI**:
   ApÃ³s a instalaÃ§Ã£o, inicie o Open WebUI executando:

   ```bash
   open-webui serve
   ```

Isso iniciarÃ¡ o servidor Open WebUI, que pode ser acessado em [http://localhost:8080](http://localhost:8080)

### InÃ­cio RÃ¡pido com Docker ğŸ³

> [!NOTE]  
> Observe que em certos ambientes Docker, podem ser necessÃ¡rias configuraÃ§Ãµes adicionais. Se encontrar problemas de conexÃ£o, nosso guia detalhado na [DocumentaÃ§Ã£o Open WebUI](https://docs.openwebui.com/) estÃ¡ pronto para ajudar.

> [!WARNING]
> Ao usar Docker para instalar o Open WebUI, inclua `-v open-webui:/app/backend/data` no comando Docker. Este passo Ã© crucial para garantir que seu banco de dados seja montado corretamente e evitar perda de dados.

> [!TIP]  
> Se quiser usar o Open WebUI com Ollama incluÃ­do ou aceleraÃ§Ã£o CUDA, recomendamos as imagens oficiais com tag `:cuda` ou `:ollama`. Para ativar CUDA, instale o [Nvidia CUDA container toolkit](https://docs.nvidia.com/dgx/nvidia-container-runtime-upgrade/) no seu sistema Linux/WSL.

### InstalaÃ§Ã£o com ConfiguraÃ§Ã£o PadrÃ£o

- **Se o Ollama estÃ¡ no seu computador**, use este comando:

  ```bash
  docker run -d -p 3000:8080 --add-host=host.docker.internal:host-gateway -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:main
  ```

- **Se o Ollama estÃ¡ em outro servidor**, use este comando:

  Para conectar ao Ollama em outro servidor, altere o `OLLAMA_BASE_URL` para a URL do servidor:

  ```bash
  docker run -d -p 3000:8080 -e OLLAMA_BASE_URL=https://exemplo.com -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:main
  ```

- **Para executar o Open WebUI com suporte a GPU Nvidia**, use este comando:

  ```bash
  docker run -d -p 3000:8080 --gpus all --add-host=host.docker.internal:host-gateway -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:cuda
  ```

### InstalaÃ§Ã£o apenas para uso da API OpenAI

- **Se for usar somente a API OpenAI**, use este comando:

  ```bash
  docker run -d -p 3000:8080 -e OPENAI_API_KEY=sua_chave_secreta -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:main
  ```

### Instalando Open WebUI com Ollama Integrado

Este mÃ©todo usa uma Ãºnica imagem de container que inclui Open WebUI com Ollama, facilitando a configuraÃ§Ã£o em um Ãºnico comando. Escolha o comando de acordo com seu hardware:

- **Com Suporte a GPU**:
  Use recursos da GPU executando:

  ```bash
  docker run -d -p 3000:8080 --gpus=all -v ollama:/root/.ollama -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:ollama
  ```

- **Apenas CPU**:
  Se nÃ£o usar GPU, use este comando:

  ```bash
  docker run -d -p 3000:8080 -v ollama:/root/.ollama -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:ollama
  ```

Ambos os comandos facilitam a instalaÃ§Ã£o integrada do Open WebUI e Ollama, para que tudo funcione rapidamente.

ApÃ³s a instalaÃ§Ã£o, acesse o Open WebUI em [http://localhost:3000](http://localhost:3000). Aproveite! ğŸ˜„

### Outros MÃ©todos de InstalaÃ§Ã£o

Oferecemos alternativas de instalaÃ§Ã£o, incluindo mÃ©todos nativos (sem Docker), Docker Compose, Kustomize e Helm. Visite nossa [DocumentaÃ§Ã£o Open WebUI](https://docs.openwebui.com/getting-started/) ou entre em nossa [comunidade Discord](https://discord.gg/5rJgQTnV4s) para orientaÃ§Ã£o completa.

### SoluÃ§Ã£o de Problemas

EstÃ¡ com problemas de conexÃ£o? Nossa [DocumentaÃ§Ã£o Open WebUI](https://docs.openwebui.com/troubleshooting/) pode ajudar. Para mais suporte e para participar da comunidade, acesse o [Open WebUI Discord](https://discord.gg/5rJgQTnV4s).

#### Open WebUI: Erro de ConexÃ£o com o Servidor

Se estÃ¡ enfrentando problemas de conexÃ£o, geralmente Ã© porque o container WebUI nÃ£o consegue acessar o servidor Ollama em 127.0.0.1:11434 (host.docker.internal:11434) dentro do container. Use a flag `--network=host` no comando Docker para resolver. Note que a porta muda de 3000 para 8080, resultando em: `http://localhost:8080`.

**Exemplo de Comando Docker**:

```bash
docker run -d --network=host -v open-webui:/app/backend/data -e OLLAMA_BASE_URL=http://127.0.0.1:11434 --name open-webui --restart always ghcr.io/open-webui/open-webui:main
```

### Mantendo sua InstalaÃ§Ã£o Docker Atualizada

Para atualizar sua instalaÃ§Ã£o local Docker para a versÃ£o mais recente, use o [Watchtower](https://containrrr.dev/watchtower/):

```bash
docker run --rm --volume /var/run/docker.sock:/var/run/docker.sock containrrr/watchtower --run-once open-webui
```

No final do comando, substitua `open-webui` pelo nome do seu container, se for diferente.

Veja nosso Guia de AtualizaÃ§Ã£o disponÃ­vel na [DocumentaÃ§Ã£o Open WebUI](https://docs.openwebui.com/getting-started/updating).

### Usando a Branch Dev ğŸŒ™

> [!WARNING]
> A branch `:dev` contÃ©m os recursos e mudanÃ§as mais instÃ¡veis e recentes. Use por sua conta e risco, pois pode conter bugs ou recursos incompletos.

Se quiser experimentar recursos de ponta e aceitar instabilidade ocasional, use a tag `:dev` assim:

```bash
docker run -d -p 3000:8080 -v open-webui:/app/backend/data --name open-webui --add-host=host.docker.internal:host-gateway --restart always ghcr.io/open-webui/open-webui:dev
```

### Modo Offline

Se estiver usando o Open WebUI em ambiente offline, defina a variÃ¡vel de ambiente `HF_HUB_OFFLINE` para `1` para evitar tentativas de baixar modelos da internet.

```bash
export HF_HUB_OFFLINE=1
```

## O que Vem a Seguir? ğŸŒŸ

Descubra recursos futuros no nosso roadmap na [DocumentaÃ§Ã£o Open WebUI](https://docs.openwebui.com/roadmap/).

## LicenÃ§a ğŸ“œ

Este projeto estÃ¡ licenciado sob a [LicenÃ§a Open WebUI](LICENSE), uma licenÃ§a BSD-3-Clause revisada. VocÃª recebe os mesmos direitos da BSD-3 clÃ¡ssica: pode usar, modificar e distribuir o software, inclusive em produtos proprietÃ¡rios e comerciais, com restriÃ§Ãµes mÃ­nimas. O Ãºnico requisito adicional Ã© preservar a marca "Open WebUI", conforme detalhado no arquivo LICENSE. Para termos completos, consulte o [LICENSE](LICENSE). ğŸ“„

## Suporte ğŸ’¬

Se tiver dÃºvidas, sugestÃµes ou precisar de ajuda, abra uma issue ou entre em nossa
[comunidade Discord do Open WebUI](https://discord.gg/5rJgQTnV4s) para conversar conosco! ğŸ¤

## HistÃ³rico de Estrelas

<a href="https://star-history.com/#open-webui/open-webui&Date">
  <picture>
    <source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=open-webui/open-webui&type=Date&theme=dark" />
    <source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=open-webui/open-webui&type=Date" />
    <img alt="Star History Chart" src="https://api.star-history.com/svg?repos=open-webui/open-webui&type=Date" />
  </picture>
</a>

---

Criado por [Timothy Jaeryang Baek](https://github.com/tjbck) â€“ Vamos tornar o Open WebUI ainda mais incrÃ­vel juntos! ğŸ’ª

---

[Powered By OpenAiTx](https://github.com/OpenAiTx/OpenAiTx)

---