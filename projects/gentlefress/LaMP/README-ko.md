<translate-content># :bulb: LaMP: ëª¨ì…˜ ìƒì„±, ê²€ìƒ‰ ë° ìº¡ì…”ë‹ì„ ìœ„í•œ ì–¸ì–´-ëª¨ì…˜ ì‚¬ì „í•™ìŠµ (ICLR 2025)
### [[í”„ë¡œì íŠ¸ í˜ì´ì§€]](https://aigc3d.github.io/LaMP/) [[ë…¼ë¬¸]](https://arxiv.org/abs/2410.07093)
![teaser_image](https://github.com/gentlefress/LaMP/blob/main/teaser.png)

ì €í¬ ì½”ë“œë‚˜ ë…¼ë¬¸ì´ ë„ì›€ì´ ë˜ì…¨ë‹¤ë©´, ì €ì¥ì†Œì— ë³„ì„ ëˆŒëŸ¬ì£¼ì‹œê³  ì¸ìš©í•´ ì£¼ì‹œë©´ ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤:</translate-content>
```
@article{li2024lamp,
  title={LaMP: Language-Motion Pretraining for Motion Generation, Retrieval, and Captioning},
  author={Li, Zhe and Yuan, Weihao and He, Yisheng and Qiu, Lingteng and Zhu, Shenhao and Gu, Xiaodong and Shen, Weichao and Dong, Yuan and Dong, Zilong and Yang, Laurence T},
  journal={arXiv preprint arXiv:2410.07093},
  year={2024}
}
```
## :postbox: ë‰´ìŠ¤
ğŸ“¢ **2025-01-22** --- ğŸ”¥ğŸ”¥ğŸ”¥ ì¶•í•˜í•©ë‹ˆë‹¤! LaMPê°€ ICLR 2025ì— ì±„íƒë˜ì—ˆìŠµë‹ˆë‹¤.

ğŸ“¢ **2025-4-28** --- LaMPì˜ ì½”ë“œì™€ ëª¨ë¸ì„ ê³µê°œí•©ë‹ˆë‹¤. í•™ìŠµ/í‰ê°€/ìƒì„± ìŠ¤í¬ë¦½íŠ¸ í¬í•¨.

ğŸ“¢ **2025-4-28** --- ì›¹í˜ì´ì§€ì™€ git í”„ë¡œì íŠ¸ë¥¼ ì´ˆê¸°í™”í–ˆìŠµë‹ˆë‹¤.  


## :1st_place_medal: ì¤€ë¹„í•˜ì„¸ìš”

<details>
  
### 1. Conda í™˜ê²½</details>

```
conda env create -f environment.yml
conda activate lamp
pip install git+https://github.com/openai/CLIP.git
```
<translate-content>ìš°ë¦¬ëŠ” Python 3.9.12ì™€ PyTorch 1.12.1ì—ì„œ ì½”ë“œë¥¼ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤

### 2. ëª¨ë¸ ë° ì˜ì¡´ì„±

#### ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ</translate-content>
```
bash prepare/download_models.sh
```
#### í‰ê°€ ëª¨ë¸ ë° ì¥ê°‘ ë‹¤ìš´ë¡œë“œ  
í‰ê°€ ìš©ë„ ì „ìš©ì…ë‹ˆë‹¤.

```
bash prepare/download_evaluator.sh
bash prepare/download_glove.sh
```
#### (ì„ íƒ ì‚¬í•­) ìˆ˜ë™ ë‹¤ìš´ë¡œë“œ  
##### VQVAE ì‚¬ì „í•™ìŠµ ê°€ì¤‘ì¹˜:  
https://virutalbuy-public.oss-cn-hangzhou.aliyuncs.com/share/aigc3d/lamp/vq.tar  
##### LaMP ì‚¬ì „í•™ìŠµ ê°€ì¤‘ì¹˜:  
HumanML3D: https://virutalbuy-public.oss-cn-hangzhou.aliyuncs.com/share/aigc3d/lamp/h3d-qformer.tar  

KIT-ML: https://virutalbuy-public.oss-cn-hangzhou.aliyuncs.com/share/aigc3d/lamp/kit-qformer.tar  
##### LaMP-T2M ì‚¬ì „í•™ìŠµ ê°€ì¤‘ì¹˜:  
https://virutalbuy-public.oss-cn-hangzhou.aliyuncs.com/share/aigc3d/lamp/t2m.tar  
##### M2T-LaMP ì‚¬ì „í•™ìŠµ ê°€ì¤‘ì¹˜:  
https://virutalbuy-public.oss-cn-hangzhou.aliyuncs.com/share/aigc3d/lamp/m2t.pth  
### 3. ë°ì´í„° ë°›ê¸°  

ì—¬ê¸°ì—ëŠ” ë‘ ê°€ì§€ ì˜µì…˜ì´ ìˆìŠµë‹ˆë‹¤:  
* **ë°ì´í„° ë°›ê¸° ê±´ë„ˆë›°ê¸°**, *ìì‹ ì˜* ì„¤ëª…ì„ ì‚¬ìš©í•˜ì—¬ ëª¨ì…˜ì„ ìƒì„±í•˜ë ¤ëŠ” ê²½ìš°.  
* **ì „ì²´ ë°ì´í„° ë°›ê¸°**, ëª¨ë¸ì„ *ì¬í•™ìŠµ* ë° *í‰ê°€*í•˜ë ¤ëŠ” ê²½ìš°.  

**(a). ì „ì²´ ë°ì´í„° (í…ìŠ¤íŠ¸ + ëª¨ì…˜)**  

**HumanML3D** - [HumanML3D](https://github.com/EricGuo5513/HumanML3D.git) ì§€ì¹¨ì„ ë”°ë¥´ê³ , ê²°ê³¼ ë°ì´í„°ì…‹ì„ ìš°ë¦¬ ì €ì¥ì†Œì— ë³µì‚¬í•˜ì„¸ìš”:


```
cp -r ../HumanML3D/HumanML3D ./dataset/HumanML3D
```
**KIT**-[HumanML3D](https://github.com/EricGuo5513/HumanML3D.git)ì—ì„œ ë‹¤ìš´ë¡œë“œí•œ í›„ ê²°ê³¼ë¥¼ `./dataset/KIT-ML`ì— ë°°ì¹˜í•˜ì„¸ìš”.

#### 

</details>

## :fire: ë°ëª¨
<details>

### (a) ë‹¨ì¼ í”„ë¡¬í”„íŠ¸ì—ì„œ ìƒì„±í•˜ê¸°
```
python gen_t2m.py --gpu_id 1 --ext exp1 --text_prompt "A person is running on a treadmill."
```
### (b) í”„ë¡¬í”„íŠ¸ íŒŒì¼ì—ì„œ ìƒì„±í•˜ê¸°
í”„ë¡¬í”„íŠ¸ íŒŒì¼ ì˜ˆì‹œëŠ” `./assets/text_prompt.txt`ì— ìˆìŠµë‹ˆë‹¤. ê° ì¤„ë§ˆë‹¤ `<í…ìŠ¤íŠ¸ ì„¤ëª…>#<ëª¨ì…˜ ê¸¸ì´>` í˜•ì‹ì„ ë”°ë¼ì£¼ì„¸ìš”. ëª¨ì…˜ ê¸¸ì´ëŠ” í¬ì¦ˆì˜ ê°œìˆ˜ë¥¼ ë‚˜íƒ€ë‚´ë©°, ì •ìˆ˜ì—¬ì•¼ í•˜ê³  4ì˜ ë°°ìˆ˜ë¡œ ë°˜ì˜¬ë¦¼ë©ë‹ˆë‹¤. ë³¸ ì—°êµ¬ì—ì„œëŠ” ëª¨ì…˜ì´ 20fpsì…ë‹ˆë‹¤.

ë§Œì•½ `<í…ìŠ¤íŠ¸ ì„¤ëª…>#NA`ë¡œ ì‘ì„±í•˜ë©´, ëª¨ë¸ì´ ê¸¸ì´ë¥¼ ê²°ì •í•©ë‹ˆë‹¤. í•œ ê°œì˜ **NA**ê°€ ìˆìœ¼ë©´ ë‚˜ë¨¸ì§€ë„ ëª¨ë‘ ìë™ìœ¼ë¡œ **NA**ê°€ ë©ë‹ˆë‹¤.

```
python gen_t2m.py --gpu_id 1 --ext exp2 --text_path ./assets/text_prompt.txt
```
ëª‡ ê°€ì§€ ì¶”ê°€ë¡œ ê´€ì‹¬ ìˆì„ ë§Œí•œ íŒŒë¼ë¯¸í„°:
* `--repeat_times`: ìƒì„± ì‹œ ë³µì œ íšŸìˆ˜, ê¸°ë³¸ê°’ `1`.
* `--motion_length`: ìƒì„±í•  í¬ì¦ˆ ê°œìˆ˜ ì§€ì •, (a)ì—ì„œë§Œ ì ìš© ê°€ëŠ¥.

ì¶œë ¥ íŒŒì¼ë“¤ì€ `./generation/<ext>/` í´ë”ì— ì €ì¥ë©ë‹ˆë‹¤. íŒŒì¼ì€
* `numpy íŒŒì¼`: (nframe, 22, 3) í˜•íƒœì˜ ìƒì„±ëœ ëª¨ì…˜, `./joints` í•˜ìœ„ í´ë”ì— ìˆìŒ.
* `ë¹„ë””ì˜¤ íŒŒì¼`: mp4 í˜•ì‹ì˜ ìŠ¤í‹± í”¼ê²¨ ì• ë‹ˆë©”ì´ì…˜, `./animation` í•˜ìœ„ í´ë”ì— ìˆìŒ.
* `bvh íŒŒì¼`: ìƒì„±ëœ ëª¨ì…˜ì˜ bvh íŒŒì¼, `./animation` í•˜ìœ„ í´ë”ì— ìˆìŒ.

ìƒì„±ëœ ëª¨ì…˜ì— ë‹¨ìˆœí•œ í’‹ IKë¥¼ ì ìš©í–ˆìŠµë‹ˆë‹¤. ì ‘ë¯¸ì‚¬ `_ik`ê°€ ë¶™ì€ íŒŒì¼ì„ ì°¸ê³ í•˜ì„¸ìš”. ë•Œë¡œëŠ” ì˜ ì‘ë™í•˜ì§€ë§Œ, ì‹¤íŒ¨í•  ë•Œë„ ìˆìŠµë‹ˆë‹¤.
  
</details>

## :basketball_man: ì‹œê°í™”
<details>

ëª¨ë“  ì• ë‹ˆë©”ì´ì…˜ì€ ìˆ˜ì‘ì—…ìœ¼ë¡œ ë¸”ë Œë”ì—ì„œ ë Œë”ë§í–ˆìŠµë‹ˆë‹¤. ìºë¦­í„°ëŠ” [mixamo](https://www.mixamo.com/#/)ì—ì„œ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤. T-Pose ìƒíƒœì˜ ìŠ¤ì¼ˆë ˆí†¤ì´ í¬í•¨ëœ ìºë¦­í„°ë¥¼ ë‹¤ìš´ë¡œë“œí•´ì•¼ í•©ë‹ˆë‹¤.

### ë¦¬íƒ€ê²ŒíŒ…
ë¦¬íƒ€ê²ŒíŒ… ì‹œ, rokokoëŠ” ë°œ ë¶€ë¶„ì—ì„œ í° ì˜¤ë¥˜ë¥¼ ì¼ìœ¼í‚¤ëŠ” ê²½ìš°ê°€ ë§ì•˜ìŠµë‹ˆë‹¤. ë°˜ë©´, [keemap.rig.transfer](https://github.com/nkeeline/Keemap-Blender-Rig-ReTargeting-Addon/releases)ëŠ” ë³´ë‹¤ ì •ë°€í•œ ë¦¬íƒ€ê²ŒíŒ…ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. [íŠœí† ë¦¬ì–¼](https://www.youtube.com/watch?v=EG-VCMkVpxg)ë„ ì°¸ê³ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ë‹¤ìŒ ë‹¨ê³„ë¥¼ ë”°ë¥´ì„¸ìš”:
* githubì—ì„œ keemap.rig.transferë¥¼ ë‹¤ìš´ë¡œë“œí•˜ì—¬ ë¸”ë Œë”ì— ì„¤ì¹˜í•©ë‹ˆë‹¤.
* ëª¨ì…˜ íŒŒì¼(.bvh)ê³¼ ìºë¦­í„° íŒŒì¼(.fbx)ì„ ë¸”ë Œë”ì— ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.
* ì†ŒìŠ¤ì™€ ëŒ€ìƒ ìŠ¤ì¼ˆë ˆí†¤ì„ `Shift + ì„ íƒ`í•©ë‹ˆë‹¤. (Rest Positionì¼ í•„ìš” ì—†ìŒ)
* `í¬ì¦ˆ ëª¨ë“œ`ë¡œ ì „í™˜í•œ í›„, ë·° ìœˆë„ìš° ìš°ì¸¡ ìƒë‹¨ì˜ `KeeMapRig` ë„êµ¬ë¥¼ í¼ì¹©ë‹ˆë‹¤.
* `bone mapping file`ì— `./assets/mapping.json`(ì‘ë™í•˜ì§€ ì•Šìœ¼ë©´ `mapping6.json`)ì„ ì§€ì •í•˜ê³  `Read In Bone Mapping File`ì„ í´ë¦­í•©ë‹ˆë‹¤. ì´ íŒŒì¼ì€ ì €í¬ê°€ ìˆ˜ì‘ì—…ìœ¼ë¡œ ë§Œë“¤ì—ˆìœ¼ë©° ëŒ€ë¶€ë¶„ì˜ mixamo ìºë¦­í„°ì— ì ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.
* (ì„ íƒ ì‚¬í•­) ë³¸ ë§¤í•‘ê³¼ íšŒì „ì„ ì§ì ‘ ìˆ˜ì •í•˜ì—¬ ìì‹ ë§Œì˜ ìºë¦­í„°ì— ë§ê²Œ ì¡°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. `Save Bone Mapping File`ì€ í˜„ì¬ ë§¤í•‘ ì„¤ì •ì„ ë¡œì»¬ íŒŒì¼ì— ì €ì¥í•©ë‹ˆë‹¤.
* `Number of Samples`, `Source Rig`, `Destination Rig Name`ì„ ì¡°ì •í•©ë‹ˆë‹¤.
* `Transfer Animation from Source Destination`ì„ í´ë¦­í•˜ê³  ëª‡ ì´ˆ ê¸°ë‹¤ë¦½ë‹ˆë‹¤.

ë‹¤ë¥¸ ë¦¬íƒ€ê²ŒíŒ… ë„êµ¬ëŠ” ì‹œë„í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë” ìœ ìš©í•œ ë„êµ¬ë¥¼ ë°œê²¬í•˜ë©´ ëŒ“ê¸€ë¡œ ì•Œë ¤ì£¼ì„¸ìš”.

</details>

## :flashlight: ì§ì ‘ ëª¨ë¸ í›ˆë ¨í•˜ê¸°
<details>


**ì£¼ì˜**: ë§ˆìŠ¤í¬ë“œ/ì”ì°¨(transformers) í›ˆë ¨ ì „ì— VQ-VAEë¥¼ ë°˜ë“œì‹œ ë¨¼ì € í›ˆë ¨í•´ì•¼ í•©ë‹ˆë‹¤. í›„ìì˜ ë‘ ëª¨ë¸ì€ ë™ì‹œì— í›ˆë ¨ ê°€ëŠ¥ í•©ë‹ˆë‹¤.

### VQ-VAE í›ˆë ¨
ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•˜ë ¤ë©´ í‰ê°€ìš© ëª¨ë¸ë„ ë‹¤ìš´ë¡œë“œí•´ì•¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.


```
python train_vq.py --name vq_name --gpu_id 1 --dataset_name t2m --batch_size 256  --max_epoch 50 --quantize_dropout_prob 0.2 --gamma 0.05
```
### LaMP í›ˆë ¨

```
python train_lamp.py --name lamp_name --gpu_id 2 --dataset_name t2m --batch_size 64 --vq_name vq_name
```
### ë§ˆìŠ¤í¬ë“œ íŠ¸ëœìŠ¤í¬ë¨¸ í›ˆë ¨í•˜ê¸°

```
python train_t2m_transformer.py --name mtrans_name --gpu_id 2 --dataset_name t2m --batch_size 64 --vq_name vq_name
```
<translate-content>
* `--dataset_name`: ëª¨ì…˜ ë°ì´í„°ì…‹, HumanML3Dì˜ ê²½ìš° `t2m`, KIT-MLì˜ ê²½ìš° `kit`.  
* `--name`: ëª¨ë¸ ì´ë¦„ ì§€ì •. `./checkpoints/<dataset_name>/<name>` ê²½ë¡œì— ëª¨ë¸ ê³µê°„ì´ ìƒì„±ë©ë‹ˆë‹¤.
* `--gpu_id`: GPU ì•„ì´ë””.
* `--batch_size`: vq í•™ìŠµ ì‹œ `512` ì‚¬ìš©. ë§ˆìŠ¤í¬ë“œ/ì”ì—¬ ë³€í™˜ê¸°ì—ì„œëŠ” HumanML3Dì— `64`, KIT-MLì— `16` ì‚¬ìš©.
* `--quantize_drop_prob`: ì–‘ìí™” ë“œë¡­ì•„ì›ƒ ë¹„ìœ¨, `0.2` ì‚¬ìš©.
* `--vq_name`: ë§ˆìŠ¤í¬ë“œ/ì”ì—¬ ë³€í™˜ê¸° í•™ìŠµ ì‹œ í† í¬ë‚˜ì´ì§•ì— ì‚¬ìš©í•  vq ëª¨ë¸ ì´ë¦„ ì§€ì • í•„ìš”.
* `--cond_drop_prob`: ì¡°ê±´ ë“œë¡­ ë¹„ìœ¨, ë¶„ë¥˜ê¸° ì—†ëŠ” ê°€ì´ë˜ìŠ¤ìš©. `0.2` ì‚¬ìš©.

ëª¨ë“  ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ê³¼ ì¤‘ê°„ ê²°ê³¼ëŠ” `./checkpoints/<dataset_name>/<name>` ê²½ë¡œì— ì €ì¥ë©ë‹ˆë‹¤.

### Train M2T</translate-content>
```
python train_m2t.py --exp-name M2T --num-layers 12 --batch-size 80 --embed-dim-gpt 1024 --nb-code 512 --n-head-gpt 16 --block-size 51 --ff-rate 4 --drop-out-rate 0.1 --resume-pth your_own_vqvae --vq-name VQVAE --out-dir ./output --total-iter 150000 --lr-scheduler 75000 --lr 0.00005 --dataname kit --down-t 2 --depth 3 --quantizer ema_reset --eval-iter 10000 --pkeep 0.5 --dilation-growth-rate 3 --vq-act relu
```
<translate-content>
</details>

## :artist: í‰ê°€
<details>

### VQ-VAE ì¬êµ¬ì„± í‰ê°€:
HumanML3D:</translate-content>
```
python eval_t2m_vq.py --gpu_id 0 --name  --dataset_name t2m

```
KIT-ML:
```
python eval_t2m_vq.py --gpu_id 0 --name  --dataset_name kit
```
### LaMP-T2M í‰ê°€:
HumanML3D:

```
python eval_t2m_trans_res.py --res_name mtrans_name --dataset_name t2m --name eval_name --gpu_id 1 --cond_scale 4 --time_steps 10 --ext evaluation
```
KIT-ML:
```
python eval_t2m_trans_res.py --res_name mtrans_name_k --dataset_name kit --name eval_name_k --gpu_id 0 --cond_scale 2 --time_steps 10 --ext evaluation
```
* `--res_name`: `residual transformer` ëª¨ë¸ ì´ë¦„ì…ë‹ˆë‹¤.  
* `--name`: `masked transformer` ëª¨ë¸ ì´ë¦„ì…ë‹ˆë‹¤.  
* `--cond_scale`: í´ë˜ìŠ¤-í”„ë¦¬ ê°€ì´ë“œì˜ ìŠ¤ì¼€ì¼ì…ë‹ˆë‹¤.  
* `--time_steps`: ì¶”ë¡ ì„ ìœ„í•œ ë°˜ë³µ íšŸìˆ˜ì…ë‹ˆë‹¤.  
* `--ext`: í‰ê°€ ê²°ê³¼ ì €ì¥ íŒŒì¼ ì´ë¦„ì…ë‹ˆë‹¤.  
* `--which_epoch`: `masked transformer`ì˜ ì²´í¬í¬ì¸íŠ¸ ì´ë¦„ì…ë‹ˆë‹¤.  

ìµœì¢… í‰ê°€ ê²°ê³¼ëŠ” `./checkpoints/<dataset_name>/<name>/eval/<ext>.log`ì— ì €ì¥ë©ë‹ˆë‹¤.  

### LaMP-M2T í‰ê°€:

```
python M2T_eval.py --exp-name Test_M2T --num-layers 9 --batch-size 1 --embed-dim-gpt 1024 --nb-code 512 --n-head-gpt 16 --block-size 51 --ff-rate 4 --drop-out-rate 0.1 --resume-pth your_own_vqvae --vq-name VQVAE --out-dir ./output --total-iter 150000 --lr-scheduler 75000 --lr 0.0001 --dataname t2m --down-t 2 --depth 3 --quantizer ema_reset --eval-iter 10000 --pkeep 0.5 --dilation-growth-rate 3 --vq-act relu --resume-trans your_own_m2t
```
LaMP-BertScore ë©”íŠ¸ë¦­ì€ ë¨¼ì € LaMP-M2Të¥¼ ì‚¬ìš©í•˜ì—¬ í•©ì„±ëœ ëª¨ì…˜ì˜ í…ìŠ¤íŠ¸ ì„¤ëª…ì„ ìƒì„±í•œ í›„, ìƒì„±ëœ ì„¤ëª…ê³¼ ì‹¤ì œ í…ìŠ¤íŠ¸ ê°„ì˜ BertScoreë¥¼ ê³„ì‚°í•˜ì—¬ ì‚°ì¶œë©ë‹ˆë‹¤.

</details>

## ê°ì‚¬ì˜ ê¸€

ë³¸ ì½”ë“œê°€ ê¸°ë°˜í•œ ë‹¤ìŒ ì˜¤í”ˆ ì†ŒìŠ¤ ì‘ì—…ë“¤ì— ì§„ì‹¬ìœ¼ë¡œ ê°ì‚¬ë“œë¦½ë‹ˆë‹¤:

[T2M-GPT](https://github.com/Mael-zys/T2M-GPT) ë° [MoMask](https://github.com/EricGuo5513/momask-codes/tree/main).

## ë¼ì´ì„ ìŠ¤
ì´ ì½”ë“œëŠ” [MIT LICENSE](https://github.com/gentlefress/LaMP/blob/main/LICENSE.md) í•˜ì— ë°°í¬ë©ë‹ˆë‹¤.

ë³¸ ì½”ë“œëŠ” SMPL, SMPL-X, PyTorch3D ë“± ë‹¤ë¥¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ì— ì˜ì¡´í•˜ë©°, ê°ê¸° ë‹¤ë¥¸ ë¼ì´ì„ ìŠ¤ë¥¼ ê°–ëŠ” ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ë¯€ë¡œ ì´ë“¤ ë¼ì´ì„ ìŠ¤ë„ ì¤€ìˆ˜í•´ì•¼ í•©ë‹ˆë‹¤.

### ê¸°íƒ€
ì¶”ê°€ ë¬¸ì˜ëŠ” keycharon0122@gmail.com ìœ¼ë¡œ ì—°ë½ ë°”ëë‹ˆë‹¤.



---

Tranlated By [Open Ai Tx](https://github.com/OpenAiTx/OpenAiTx) | Last indexed: 2025-07-19

---