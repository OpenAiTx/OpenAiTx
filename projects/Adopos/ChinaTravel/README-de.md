<center>
  <h1>ChinaTravel: Ein praxisnaher Benchmark f√ºr Sprachagenten in der chinesischen Reiseplanung
</h1>
</center>

Offizieller Codebestand f√ºr das Paper "ChinaTravel: Ein praxisnaher Benchmark f√ºr Sprachagenten in der chinesischen Reiseplanung".

<!-- | [Webseite](https://www.lamda.nju.edu.cn/shaojj/chinatravel/) | [Paper](https://arxiv.org/abs/2412.13682) | [Datensatz(Huggingface)](https://huggingface.co/datasets/LAMDA-NeSy/ChinaTravel)| -->

[![Webseite](https://img.shields.io/badge/Webpage-Visit-blue)](https://www.lamda.nju.edu.cn/shaojj/chinatravel/)
[![Paper](https://img.shields.io/badge/Paper-View-red)](https://arxiv.org/abs/2412.13682)
[![Datensatz(Huggingface)](https://img.shields.io/badge/Dataset-Huggingface-yellow)](https://huggingface.co/datasets/LAMDA-NeSy/ChinaTravel)
[![Wettbewerb(TPC@IJCAI2025)](https://img.shields.io/badge/IJCAI%20Competition-TPC@IJCAI2025-green)](https://chinatravel-competition.github.io/IJCAI2025/)
[![Wettbewerb(TPC@AIC2025)](https://img.shields.io/badge/AIC%20Competition-TPC@AIC2025-green)](TPC@AIC2025/readme.md)


<!-- 
![√úbersicht](https://raw.githubusercontent.com/Adopos/ChinaTravel/main/images/overview.png) -->

## üèÜ IJCAI 2025 Reiseplanungs-Challenge (TPC@IJCAI)

Wir freuen uns bekannt zu geben, dass ChinaTravel als offizieller Benchmark f√ºr die **Travel Planning Challenge (TPC) @ IJCAI 2025** ausgew√§hlt wurde!

**Offizielle Wettbewerbswebseite**:
[https://chinatravel-competition.github.io/IJCAI2025/](https://chinatravel-competition.github.io/IJCAI2025/)

Teilnehmer sind eingeladen, neuartige Agenten zu entwickeln, die reale Reiseplanungsszenarien unter komplexen Bedingungen bew√§ltigen k√∂nnen. Dieser Wettbewerb pr√§sentiert fortschrittliche Ans√§tze in der Forschung zu Sprachagenten.

## üìù √Ñnderungsprotokoll

### 2025.09
1. Hochladen der Siegerl√∂sung des TPC@IJCAI2025 DSL-Tracks. Vielen Dank an [@evergreenee](https://github.com/evergreenee) f√ºr die Beitr√§ge.  


### 2025.06

1. Fehlerbehebung bei der Sammlung im Bewertungscode f√ºr Commonsense. 
2. Fehlerbehebung in der Pipeline des reinen Neuro-Agenten
3. Fehlerbehebung beim Laden von Datens√§tzen von Huggingface
4. Aktualisierung der Ausnahmebehandlung bei der Syntax√ºberpr√ºfung


### 2025.05

1. Protokollieren Sie die Aktualisierungen f√ºr die neueste Version.
2. Stellen Sie den Bewertungscode f√ºr das TPC bereit.

### 2025.04

1. Lokaler Datenlader hinzugef√ºgt. Benutzer k√∂nnen nun benutzerdefinierte Abfragen lokal laden. Bei Angabe von nicht standardm√§√üigen splits_name-Werten (z. B. "abc") f√ºr "run_exp.py" l√§dt das System automatisch entsprechende Dateien aus evaluation/default_splits/abc.txt, wobei die TXT-Datei die Dateinamen der Zielabfragen enth√§lt.
2. Detaillierte Klassifizierung von Einschr√§nkungen. Siehe ausf√ºhrliche Dokumentation unter [Evaluation README](https://raw.githubusercontent.com/Adopos/ChinaTravel/main/chinatravel/symbol_verification/readme.md)
3. LLM-Modulo-Baseline eingef√ºhrt
   Implementierung der LLM-Modulo-Pipeline mit einem symbolischen Ground-Truth-Verifizierer.
   Basierend auf der Methodik aus:
   Paper: Robust Planning with Compound LLM Architectures: An LLM-Modulo Approach
   Codebasis: https://github.com/Atharva-Gundawar/LLM-Modulo-prompts
4. Unterst√ºtzung f√ºr lokale LLM-Inferenz mit Qwen3-8B/4B.

## üöÄ Schnellstart

### ‚öôÔ∏è Einrichtung

1. Erstellen Sie eine Conda-Umgebung und installieren Sie die Abh√§ngigkeiten:

```bash
conda create -n chinatravel python=3.9  
conda activate chinatravel  
pip install -r requirements.txt  
```

2. Laden Sie die Datenbank herunter und entpacken Sie sie in das Verzeichnis "chinatravel/environment/"

Download-Links: [Google Drive](https://drive.google.com/drive/folders/1bJ7jA5cfExO_NKxKfi9qgcxEbkYeSdAU), [NJU Drive](https://box.nju.edu.cn/d/dd83e5a4a9e242ed8eb4/)

3. Laden Sie die Open-Source-LLMs herunter (optional).

```bash
bash download_llm.sh
```

4. Laden Sie die Tokenizer herunter.

```bash
wget https://cdn.deepseek.com/api-docs/deepseek_v3_tokenizer.zip -P chinatravel/local_llm/
unzip chinatravel/local_llm/deepseek_v3_tokenizer.zip -d chinatravel/local_llm/
```

### ‚ñ∂Ô∏è Ausf√ºhrung

Wir unterst√ºtzen Deepseek (offizielle API von Deepseek), GPT-4o (chatgpt-4o-latest), GLM4-Plus und lokale Inferenz mit Qwen (Qwen3-8B), Llama, Mistral (Mistral-7B-Instruct-v0.3) usw.

```bash
export OPENAI_API_KEY=""

python run_exp.py --splits easy --agent LLMNeSy --llm deepseek --oracle_translation
python run_exp.py --splits medium --agent LLMNeSy --llm deepseek --oracle_translation
python run_exp.py --splits human --agent LLMNeSy --llm deepseek --oracle_translation

python run_exp.py --splits human --agent LLMNeSy --llm Qwen3-8B --oracle_translation


python run_exp.py --splits human --agent LLMNeSy --llm deepseek 
python run_exp.py --splits human --agent LLMNeSy --llm Qwen3-8B 


python run_exp.py --splits human --agent LLM-modulo --llm deepseek --refine_steps 10 --oracle_translation
python run_exp.py --splits human --agent LLM-modulo --llm Qwen3-8B --refine_steps 10 --oracle_translation
```

**Hinweis**:

- Das Flag `--oracle_translation` erm√∂glicht den Zugriff auf annotierte Ground-Truth-Daten, einschlie√ülich:

  - `hard_logic_py`: Ausf√ºhrbarer Verifizierungs-DSL-Code
  - `hard_logic_nl`: Die entsprechenden Beschreibungen der Einschr√§nkungen
  - Beispielstruktur der Annotation:

  ```python
  {
    "hard_logic_py": [
      "
      total_cost=0 
      for activity in allactivities(plan):
          total_cost+=activity_cost(activity)
              total_cost += innercity_transport_cost(activity_transports(activity))
      result=(total_cost<=1000)
      ", 
      "
      innercity_transport_set=set()
      for activity in allactivities(plan):
          if activity_transports(activity)!=[]:              
              innercity_transport_set.add(innercity_transport_type(activity_transports(activity)))
      result=(innercity_transport_set<={'taxi'})
      "
    ], 
    "hard_logic_nl": ["ÊÄªÈ¢ÑÁÆó‰∏∫1800ÂÖÉ", "Â∏ÇÂÜÖ‰∫§ÈÄöÈÄâÊã©taxi"], 
  }
  ```
- Die LLM-Modulo-Methode **erfordert** den Oracle_Translation-Modus f√ºr ihren symbolischen Verfeinerungsprozess

### üìä Bewertung

```bash
python eval_exp.py --splits human --method LLMNeSy_deepseek_oracletranslation
python eval_exp.py --splits human --method LLMNeSy_deepseek
python eval_exp.py --splits human --method LLM-modulo_deepseek_10steps_oracletranslation
python eval_exp.py --splits human --method LLM-modulo_Qwen3-8B_10steps_oracletranslation

```

Im TPC@IJCAI2025 wird der Bewertungscode in der Datei `eval_tpc.py` bereitgestellt. Sie k√∂nnen den Bewertungscode wie folgt ausf√ºhren:

```bash
python eval_tpc.py --splits tpc_phase1 --method YOUR_METHOD_NAME
```

## üìö Dokumentation

[Umgebung](https://raw.githubusercontent.com/Adopos/ChinaTravel/main/chinatravel/environment/readme.md)
[Einschr√§nkungen](https://raw.githubusercontent.com/Adopos/ChinaTravel/main/chinatravel/symbol_verification/readme.md)

## üõ†Ô∏è Erweiterte Entwicklung

### 1. Entwickeln Sie Ihren eigenen Agenten-Algorithmus

Um Ihren eigenen Agenten-Algorithmus zu entwickeln, m√ºssen Sie die Klasse `BaseAgent` aus `chinatravel/agent/base.py` erben und die Logik f√ºr Ihren Algorithmus in die Funktion `init_agent` in `chinatravel/agent/load_model.py` einf√ºgen. Wir stellen ein Beispiel f√ºr einen leeren Agenten namens `TPCAgent` bereit.

Schritte:

- **Erben Sie die Klasse `BaseAgent`**: Erstellen Sie eine neue Python-Datei im Verzeichnis `chinatravel/agent` und definieren Sie Ihre eigene Agentenklasse, indem Sie von `BaseAgent` erben.

```python:chinatravel/agent/your_agent.py
from .base import BaseAgent

class YourAgent(BaseAgent):
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        # Initialization logic

    def act(self, observation):
        # Implement the decision - making logic of the agent
        pass
```

- **F√ºgen Sie Code zur Funktion init_agent hinzu**: √ñffnen Sie die Datei chinatravel/agent/load_model.py und f√ºgen Sie Unterst√ºtzung f√ºr Ihren neuen Agenten in der Funktion init_agent hinzu.

```python:
def init_agent(kwargs):
    # ... existing code ...
    elif kwargs["method"] == "YourMethodName":
        agent = YourAgent(
            **kwargs
        )
    # ... existing code ...
    return agent
```

### 2. Entwickeln Sie Ihr eigenes lokales LLM

Um Ihr eigenes lokales Large Language Model (LLM) zu entwickeln, m√ºssen Sie die AbstractLLM-Klasse aus chinatravel/agent/llms.py erben und den entsprechenden lokalen LLM-Inferenzcode in llms.py hinzuf√ºgen. Wir stellen ein leeres LLM-Beispiel namens TPCLLM bereit.
Schritte:

- **Erben Sie die AbstractLLM-Klasse**: Definieren Sie Ihre eigene LLM-Klasse in der Datei chinatravel/agent/llms.py, indem Sie von AbstractLLM erben.

```python
class YourLLM(AbstractLLM):
    def __init__(self):
        super().__init__()
        # Initialization logic
        self.name = "YourLLMName"

    def _get_response(self, messages, one_line, json_mode):
        # Implement the response logic of the LLM
        response = "Your LLM response"
        if json_mode:
            # Handle JSON mode
            pass
        elif one_line:
            # Handle one - line mode
            response = response.split("\n")[0]
        return response
```

- **F√ºgen Sie Code zur Funktion init_agent hinzu**: √ñffnen Sie die Datei chinatravel/agent/load_model.py und f√ºgen Sie Unterst√ºtzung f√ºr Ihr neues LLM in der Funktion init_llm hinzu.

```python:
def init_llm(kwargs):
    # ... existing code ...
    elif llm_name == "glm4-plus":
        llm = YourLLM()
    # ... existing code ...
    return llm
```

### 3. F√ºhren Sie Ihren Code mit Experiment-Skripten aus

Nach Abschluss der oben genannten Entwicklung k√∂nnen Sie die Experiment-Skripte verwenden, um Ihren Code auszuf√ºhren.

Beispiel f√ºr die Ausf√ºhrung:

```bash
python run_tpc.py --splits easy --agent TPCAgent --llm TPCLLM
python run_exp.py --splits easy --agent YourMethodName --llm YourLLMName
```

Die Ergebnisse werden im Verzeichnis `results/YourMethodName_YourLLMName_xxx` gespeichert, z. B. `results/TPCAgent_TPCLLM`.

## ‚úâÔ∏è Kontakt

Bei Problemen wenden Sie sich bitte an [Jie-Jing Shao](https://raw.githubusercontent.com/Adopos/ChinaTravel/main/shaojj@lamda.nju.edu.cn), [Bo-Wen Zhang](https://raw.githubusercontent.com/Adopos/ChinaTravel/main/221900200@smail.nju.edu.cn), [Xiao-Wen Yang](https://raw.githubusercontent.com/Adopos/ChinaTravel/main/yangxw@lamda.nju.edu.cn).

## üìå Zitation

Wenn unsere Arbeit oder verwandte Ressourcen f√ºr Ihre Forschung wertvoll sind, bitten wir um eine entsprechende Zitation.

```
@misc{shao2024chinatravelrealworldbenchmarklanguage,
      title={ChinaTravel: A Real-World Benchmark for Language Agents in Chinese Travel Planning}, 
      author={Jie-Jing Shao and Xiao-Wen Yang and Bo-Wen Zhang and Baizhi Chen and Wen-Da Wei and Guohao Cai and Zhenhua Dong and Lan-Zhe Guo and Yu-feng Li},
      year={2024},
      eprint={2412.13682},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2412.13682}, 
}
```
[English](https://openaitx.github.io/#/view?user=Adopos&project=ChinaTravel&lang=en) | [ÁÆÄ‰Ωì‰∏≠Êñá](https://openaitx.github.io/#/view?user=Adopos&project=ChinaTravel&lang=zh-CN) | [ÁπÅÈ´î‰∏≠Êñá](https://openaitx.github.io/#/view?user=Adopos&project=ChinaTravel&lang=zh-TW) | [Êó•Êú¨Ë™û](https://openaitx.github.io/#/view?user=Adopos&project=ChinaTravel&lang=ja) | [ÌïúÍµ≠Ïñ¥](https://openaitx.github.io/#/view?user=Adopos&project=ChinaTravel&lang=ko) | [‡§π‡§ø‡§®‡•ç‡§¶‡•Ä](https://openaitx.github.io/#/view?user=Adopos&project=ChinaTravel&lang=hi) | [‡πÑ‡∏ó‡∏¢](https://openaitx.github.io/#/view?user=Adopos&project=ChinaTravel&lang=th) | [Fran√ßais](https://openaitx.github.io/#/view?user=Adopos&project=ChinaTravel&lang=fr) | [Deutsch](https://openaitx.github.io/#/view?user=Adopos&project=ChinaTravel&lang=de) | [Espa√±ol](https://openaitx.github.io/#/view?user=Adopos&project=ChinaTravel&lang=es) | [Italiano](https://openaitx.github.io/#/view?user=Adopos&project=ChinaTravel&lang=it) | [–†—É—Å—Å–∫–∏–π](https://openaitx.github.io/#/view?user=Adopos&project=ChinaTravel&lang=ru) | [Portugu√™s](https://openaitx.github.io/#/view?user=Adopos&project=ChinaTravel&lang=pt) | [Nederlands](https://openaitx.github.io/#/view?user=Adopos&project=ChinaTravel&lang=nl) | [Polski](https://openaitx.github.io/#/view?user=Adopos&project=ChinaTravel&lang=pl) | [ÿßŸÑÿπÿ±ÿ®Ÿäÿ©](https://openaitx.github.io/#/view?user=Adopos&project=ChinaTravel&lang=ar) | [ŸÅÿßÿ±ÿ≥€å](https://openaitx.github.io/#/view?user=Adopos&project=ChinaTravel&lang=fa) | [T√ºrk√ße](https://openaitx.github.io/#/view?user=Adopos&project=ChinaTravel&lang=tr) | [Ti·∫øng Vi·ªát](https://openaitx.github.io/#/view?user=Adopos&project=ChinaTravel&lang=vi) | [Bahasa Indonesia](https://openaitx.github.io/#/view?user=Adopos&project=ChinaTravel&lang=id) | [‡¶Ö‡¶∏‡¶Æ‡ßÄ‡¶Ø‡¶º‡¶æ](https://openaitx.github.io/#/view?user=Adopos&project=ChinaTravel&lang=as)


---

Tranlated By [Open Ai Tx](https://github.com/OpenAiTx/OpenAiTx) | Last indexed: 2025-10-11

---