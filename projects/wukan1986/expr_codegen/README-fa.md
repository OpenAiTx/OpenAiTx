# expr_codegen مفسر عبارات

## پیش‌زمینه پروژه

پس از انتشار کتابخانه جدید [polars_ta](https://github.com/wukan1986/polars_ta)، دوباره به این فکر کردم که `expr_codegen` چیست.

> `expr_codegen` در اصل یک `DSL` (زبان خاص دامنه - Domain Specific Language) است. اما دستور زبان جدیدی تعریف نمی‌کند.

این ابزار دو مشکل را حل می‌کند:

1. با `polars_ta` می‌توان به راحتی عبارات محاسبه ویژگی را نوشت، اما هنگام مواجهه با عبارات مخلوط از توالی زمانی و مقطع، استفاده از `expr_codegen` می‌تواند گروه‌بندی خودکار را انجام داده و کار را بسیار ساده‌تر کند.
2. `expr_codegen` با بهره‌گیری از حذف عبارات فرعی مشترک (`Common Subexpression Elimination`)، محاسبات تکراری را به طور چشمگیری کاهش داده و بهره‌وری را افزایش می‌دهد.

حتی در حوزه کوانت، پژوهشگران مبتدی که فقط شاخص‌های زمانی استفاده می‌کنند، می‌توانند فقط از `polars_ta` استفاده کنند، اما پژوهشگران متوسط و پیشرفته که از شاخص‌های مقطع استفاده می‌کنند، توصیه می‌شود از `expr_codegen` بهره ببرند.

گرچه این پروژه در حال حاضر وابستگی نزدیکی به `polars_ta` دارد، اما قابلیت ترجمه به کتابخانه‌های دیگر مانند `pandas` یا `cudf.pandas` را نیز دارد، فقط فعلاً یک کتابخانه ساده برای این کار وجود ندارد.

## نمایش آنلاین

https://exprcodegen.streamlit.app

کاربران مبتدی می‌توانند مستقیماً به این لینک مراجعه کرده و عبارات را ترجمه کنند و نیازی به نصب نرم‌افزار اضافی ندارند. (این ابزار به صورت رایگان در خارج از کشور میزبانی شده و ممکن است باز شدن آن کمی طول بکشد)

برای مثال‌های کامل‌تر به [alpha_examples](https://github.com/wukan1986/alpha_examples) مراجعه کنید.

## نمونه استفاده

```python
import sys
from io import StringIO

import polars as pl

from expr_codegen import codegen_exec


def _code_block_1():
    # ناحیه ویرایش عامل، می‌توانید از راهنمای هوشمند IDE برای ویرایش عامل‌ها در این بخش استفاده کنید
    LOG_MC_ZS = cs_mad_zscore(log1p(market_cap))


def _code_block_2():
    # بسیاری از عملگرهای زیر مجموعه from polars_ta.prefix به طور پیش‌فرض در قالب وارد شده‌اند،
    # اما talib به طور پیش‌فرض وارد نشده است. این روش می‌تواند وارد کردن آن را در کد تولید شده انجام دهد.
    from polars_ta.prefix.talib import ts_LINEARREG_SLOPE  # noqa

    # همچنین پشتیبانی از وارد کردن مستقیم def و class وجود دارد
    def cs_rank_if(condition, factor):
        return cs_rank(if_else(condition, factor, None))

    class Clazz:
        pass

    # 1. متغیرهایی که با زیرخط شروع می‌شوند فقط متغیر میانی هستند و به طور خودکار تغییر نام می‌دهند و در خروجی نهایی حذف می‌شوند.
    # 2. متغیرهایی که با زیرخط شروع می‌شوند می‌توانند چند بار استفاده شوند. هنگام نوشتن چند خطی عامل‌های پیچیده با متغیر میانی تکراری دیگر تداخل ندارند.
    _avg = ts_mean(corr, 20)
    _std = ts_std_dev(corr, 20)
    _beta = ts_LINEARREG_SLOPE(corr, 20)

    # 3. متغیرهایی که با زیرخط شروع می‌شوند حلقه انتساب دارند. هنگام اشکال‌زدایی می‌توان به سرعت با کامنت تغییر حالت داد.
    _avg = cs_mad_zscore_resid(_avg, LOG_MC_ZS, ONE)
    _std = cs_mad_zscore_resid(_std, LOG_MC_ZS, ONE)
    # _beta = cs_mad_zscore_resid(_beta, LOG_MC_ZS, ONE)

    _corr = cs_zscore(_avg) + cs_zscore(_std)
    CPV = cs_zscore(_corr) + cs_zscore(_beta)


code = codegen_exec(None, _code_block_1, _code_block_2, over_null='partition_by', output_file=sys.stdout)  # چاپ کد
code = codegen_exec(None, _code_block_1, _code_block_2, over_null='partition_by', output_file="output.py")  # ذخیره در فایل
code = codegen_exec(None, _code_block_1, _code_block_2, over_null='partition_by')  # فقط اجرا، بدون ذخیره کد

code = StringIO()
codegen_exec(None, _code_block_1, _code_block_2, over_null='partition_by', output_file=code)  # ذخیره در رشته
code.seek(0)
code.read()  # خواندن کد

# TODO داده مناسب را جایگزین کنید
df = pl.DataFrame()
df = codegen_exec(df.lazy(), _code_block_1, _code_block_2, over_null='partition_by').collect()  # Lazy CPU
df = codegen_exec(df.lazy(), _code_block_1, _code_block_2, over_null='partition_by').collect(engine="gpu")  # Lazy GPU

```

## ساختار پوشه‌ها

```commandline
│  requirements.txt # نصب وابستگی‌ها با دستور `pip install -r requirements.txt`
├─data
│      prepare_date.py # آماده‌سازی داده‌ها
├─examples
│      demo_express.py # مثال سریع. نمایش نحوه تبدیل عبارت به کد
│      demo_exec_pl.py # نمایش اجرای کد تبدیل شده و رسم نمودار
│      demo_transformer.py # نمایش تبدیل عبارات شخص ثالث به عبارات داخلی
│      output.py # خروجی نتایج. بدون نیاز به تغییر کد، می‌تواند در پروژه‌های دیگر وارد شود
│      show_tree.py # رسم نمودار درختی عبارات. برای تحلیل و مقایسه بهینه‌سازی نتایج
│      sympy_define.py # تعریف نمادها، به دلیل تکرار زیاد، استخراج و یکپارچه شده است
├─expr_codegen
│   │  expr.py # توابع پایه پردازش عبارات
│   │  tool.py # کد ابزارهای اصلی
│   ├─polars
│   │  │  code.py # تولید کد برای دستور زبان polars
│   │  │  template.py.j2 # قالب `Jinja2` برای تولید فایل‌های py مربوطه، معمولاً نیازی به تغییر ندارد
│   │  │  printer.py # ارث‌بری از `StrPrinter` در `Sympy`، هنگام افزودن توابع جدید ممکن است نیاز به تغییر این فایل باشد
```

## نحوه کار

این پروژه به پروژه `sympy` وابسته است. توابع اصلی مورد استفاده عبارتند از:

1. `simplify`: ساده‌سازی عبارات پیچیده
2. `cse`: حذف عبارات فرعی مشترک (`Common Subexpression Elimination`)
3. `StrPrinter`: خروجی رشته‌های متفاوت بر اساس توابع مختلف. با سفارشی‌سازی این کد می‌توان از زبان‌ها یا کتابخانه‌های دیگر پشتیبانی کرد

از آنجا که `groupby` و `sort` زمان‌بر هستند، اگر فرمول‌ها را از قبل دسته‌بندی کنیم و هر دسته از `groupby` متفاوت استفاده کند، زمان محاسبه کاهش می‌یابد.

1. `ts_xxx(ts_xxx)`: محاسبه در یک `groupby` قابل انجام است
2. `cs_xxx(cs_xxx)`: محاسبه در یک `groupby` قابل انجام است
3. `ts_xxx(cs_xxx)`: نیاز به محاسبه در `groupby`های مختلف دارد
4. `cs_xxx(ts_xxx(cs_xxx))`: نیاز به محاسبه در سه `groupby` مختلف دارد
5. `gp_xxx(aa, )+gp_xxx(bb, )`: چون `aa` و `bb` متفاوت هستند، به دو `groupby` مختلف نیاز است

بنابراین:

1. باید تابعی برای دریافت دسته‌بندی عبارت جاری (`get_current`) و دسته‌بندی عبارات فرعی (`get_children`) وجود داشته باشد
2. اگر دسته‌بندی جاری با دسته‌بندی فرعی متفاوت باشد، می‌توان فرمول کوتاه را استخراج کرد (`extract`). عبارات هم‌رده در سطوح مختلف اولویت دارند و نمی‌توانند در یک `groupby` قرار بگیرند
3. با استفاده از ویژگی `cse`، عبارات بلند جایگزین عبارات کوتاه استخراج شده قبلی می‌شوند و سپس به گراف جهت‌دار بدون دور (`DAG`) وارد می‌شوند
4. با جریان‌یابی در گراف جهت‌دار بدون دور، لایه‌بندی انجام می‌شود. در هر لایه `ts`، `cs`، `gp` ترتیب اهمیتی ندارد
5. در هر لایه، بر اساس `ts`، `cs`، `gp` گروه‌بندی انجام شده و سپس کد تولید می‌شود (`codegen`)

اطلاعات ضمنی:

1. `ts`: sort(by=[ASSET, DATE]).groupby(by=[ASSET], maintain_order=True)
2. `cs`: sort(by=[DATE]).groupby(by=[DATE], maintain_order=False)
3. `gp`: sort(by=[DATE, GROUP]).groupby(by=[DATE, GROUP], maintain_order=False)

یعنی:

1. توابع زمانی دو فیلد `ASSET, DATE` را به صورت پنهان دارند و توابع مقطع یک فیلد `DATE` را پنهان دارند
2. توابع گروه‌بندی یک فیلد `GROUP` را اضافه می‌کنند و همزمان یک فیلد `DATE` را پنهان می‌کنند

دو روش دسته‌بندی:

1. دسته‌بندی بر اساس پیشوند عملگر (`get_current_by_prefix`) که الزاماً باید عملگر با `ts_`، `cs_` یا `gp_` شروع شود
2. دسته‌بندی بر اساس نام کامل عملگر (`get_current_by_name`) که دیگر به نام عملگر محدود نیست. مثلاً `cs_rank` می‌تواند به سادگی `rank` نامیده شود

## پردازش Null

چگونه `null` ایجاد می‌شود؟

1. توقف معاملات. قبل از محاسبه فیلتر شده و تأثیری بر محاسبات بعدی ندارد.
2. تفاوت در زمان معاملات دارایی‌های مختلف
3. تولید در محاسبات. `null` در دو انتهای دنباله تأثیری بر نتایج توابع زمانی ندارد، اما اگر در وسط ظاهر شود تأثیرگذار است. مثال: `if_else(close<2, None, close)`

https://github.com/pola-rs/polars/issues/12925#issuecomment-2552764629

ایده بسیار خوبی است و به طور خلاصه دو روش پیاده‌سازی وجود دارد:

1. تقسیم `null` و `not_null` به دو گروه. باید دو بار فراخوانی شود
2. فقط یک گروه، اما با مرتب‌سازی ترکیبی، `null`ها در ابتدا و `not_null`ها در انتها قرار می‌گیرند. فقط یک بار فراخوانی و کمی سریع‌تر

```python
X1 = (ts_returns(CLOSE, 3)).over(CLOSE.is_not_null(), _ASSET_, order_by=_DATE_),
X2 = (ts_returns(CLOSE, 3)).over(_ASSET_, order_by=[CLOSE.is_not_null(), _DATE_]),
X3 = (ts_returns(CLOSE, 3)).over(_ASSET_, order_by=_DATE_),
```

در حالت دوم، اینکه آیا ناحیه ابتدایی `null` بر نتیجه تأثیر دارد یا نه، بستگی به عملگر دارد، به ویژه هنگام ورود چند ستون ممکن است داده وجود داشته باشد.

1. `over_null='partition_by'`: تقسیم به دو ناحیه
2. `over_null='order_by'`: تقسیم به یک ناحیه و قرار دادن `null`ها در ابتدا
3. `over_null=None`: بدون پردازش، مستقیماً فراخوانی می‌شود و سرعت بیشتری دارد. اگر مطمئن هستید که در وسط دنباله `null` تولید نمی‌شود، استفاده از این گزینه پیشنهاد می‌شود

`codegen_exec(over_null='partition_by')` به صورت سراسری از `partition_by` استفاده می‌کند. اما برای توابعی مثل `ts_count_nulls` که به `null` نیاز دارند باید از `over_null=None` استفاده کرد، بنابراین در این ابزار امکان درج پارامتر برای هر خط به صورت کامنت نیز اضافه شده است.

1. `# --over_null partition_by`: فقط یک خط با `over_null='partition_by'`
2. `# --over_null=order_by`: فقط یک خط با `over_null='order_by'`
3. `# --over_null`: فقط یک خط با `over_null=None`
4. `#`: مقدار پارامتر `over_null` که به `codegen_exec` منتقل شده را می‌گیرد

توجه:

1. کامنت `# --over_null` فقط باید در انتهای عبارت تک‌خطی نوشته شود، اگر به صورت خط جداگانه باشد، نادیده گرفته می‌شود
2. اگر چندین `# --over_null` باشد، فقط اولین مقدار معتبر در نظر گرفته می‌شود
3. فقط برای تابع `ts` در لایه بیرونی مؤثر است. اگر تابع `ts` در لایه بیرونی نباشد باید به صورت دستی استخراج شود. مثال:
   ```python
   X1 = cs_rank(ts_mean(CLOSE, 3)) # --over_null=order_by # اینجا روی cs_rank اعمال می‌شود که بی‌معنی است
   X2 = ts_rank(ts_mean(CLOSE, 3), 5) # --over_null=order_by # تصور می‌شود روی ts_rank(ts_mean) اعمال شود، اما به دلیل وجود ts_mean مشترک در واقع روی ts_rank(_x_0) اعمال می‌شود
   ```

   باید به صورت زیر نوشته شود:

   ```python
   _x_0 = ts_mean(CLOSE, 3)  # --over_null=order_by 
   X1 = cs_rank(_x_0)
   X2 = ts_rank(_x_0, 5)
   ```
4. به دلیل احتمال اشتباه، اکیداً توصیه می‌شود فایل خروجی (`output_file`) تولید و صحت کد تولید شده را بررسی کنید.

## محدودیت‌های `expr_codegen`

1. `DAG` فقط می‌تواند ستون اضافه کند و حذف ستون امکان‌پذیر نیست. در صورت اضافه کردن ستون با نام تکراری، مقدار قبلی جایگزین می‌شود
2. حذف سطر پشتیبانی نمی‌شود، اما می‌توانید یک ستون نشانه حذف اضافه کنید و سپس سطرها را در خارج حذف کنید. حذف سطر همه ستون‌ها را تحت تأثیر قرار می‌دهد و با ساختار `DAG` سازگار نیست
3. بازنمونه‌گیری (Resampling) پشتیبانی نمی‌شود، دلیل آن همان حذف سطر است. باید خارج از ابزار انجام شود
4. می‌توان حذف سطر و بازنمونه‌گیری را به عنوان خط جداکننده در نظر گرفت و هر بخش کد را به چندین `DAG` متصل تقسیم کرد. این کار پیچیده و نامفهوم است، بنابراین در نهایت پیاده‌سازی نشده است

## دستور زبان ویژه

1. پشتیبانی از عبارات سه‌گانه `C?T:F` (فقط در رشته‌ها). در سطح پایین ابتدا به `C or True if( T )else F` تبدیل، سپس به `T if C else F` اصلاح و در نهایت به `if_else(C,T,F)` تبدیل می‌شود. امکان ترکیب با `if else` نیز وجود دارد
2. `(A<B)*-1` در سطح پایین به `int_(A<B)*-1` تبدیل می‌شود
3. برای جلوگیری از جایگزینی `A==B` با `False` توسط `sympy`، در سطح پایین به `Eq(A,B)` تبدیل می‌شود
4. معنای `A^B` به پارامتر `convert_xor` بستگی دارد، اگر `convert_xor=True` باشد در سطح پایین به `Pow(A,B)` وگرنه به `Xor(A,B)` تبدیل می‌شود. به طور پیش‌فرض `False` است و برای توان از `**` استفاده کنید
5. پشتیبانی از `A&B&C` وجود دارد، اما `A==B==C` پشتیبانی نمی‌شود. اگر C بولین و AB عددی باشند می‌توان به صورت دستی به `(A==B)==C` جایگزین کرد. اگر ABC همه عددی باشند باید به صورت دستی به `(A==B)&(B==C)` جایگزین شوند
6. از `A<=B<=C` پشتیبانی نمی‌شود و باید به صورت دستی به `(A<=B)&(B<=C)` جایگزین شود
7. پشتیبانی از `A[0]+B[1]+C[2]` وجود دارد که در سطح پایین به `A+ts_delay(B,1)+ts_delay(C,2)` تبدیل می‌شود
8. پشتیبانی از `~A` وجود دارد که در سطح پایین به `Not(A)` تبدیل می‌شود
9. توابعی که با `gp_` شروع می‌شوند همواره تابع معادل `cs_` را بازمی‌گردانند. مثلاً `gp_func(A,B,C)` به `cs_func(B,C)` جایگزین می‌شود و `A` در `groupby([date, A])` استفاده می‌شود
10. پشتیبانی از بازکردن بسته‌های چندتایی مانند `A,B,C=MACD()` وجود دارد که در سطح پایین به صورت زیر جایگزین می‌شود:
   ```python
   _x_0 = MACD()
   A = unpack(_x_0, 0)
   B = unpack(_x_0, 1)
   C = unpack(_x_0, 2)
   ```
11. کامنت تک‌خطی پشتیبانی از ورودی پارامتر دارد مانند: `# --over_null`، `# --over_null=order_by`، `# --over_null=partition_by`
12. در بلوک کد، سه دستور `import`، `def` و `class` به صورت خودکار بدون تغییر به کد تولید شده اضافه می‌شوند

## متغیرهای شروع شده با زیرخط

1. تمام ستون‌هایی که با `_` شروع می‌شوند در خروجی داده به طور خودکار حذف می‌شوند. بنابراین متغیرهایی که باید نگه‌داشته شوند نباید با `_` شروع شوند
2. برای کاهش محاسبات تکراری، متغیرهای میانی به صورت خودکار با پیشوند `_x_` مانند `_x_0`، `_x_1` و غیره اضافه می‌شوند و در نهایت حذف خواهند شد
3. اگر عبارت تک‌خطی طولانی یا تکرار محاسبات وجود داشته باشد، می‌توان با استفاده از متغیر میانی، عبارت را به چند خط تقسیم کرد. اگر متغیر میانی با `_` شروع شود، به طور خودکار پسوند عددی اضافه می‌شود و متغیرهای متفاوتی مانند `_A_0_`، `_A_1_` و غیره ایجاد می‌شود. موارد استفاده:
    1. استفاده تکراری از یک نام متغیر که در اصل متغیرهای متفاوت هستند
    2. انتساب حلقه‌ای، اما `DAG` از حلقه پشتیبانی نمی‌کند. متغیرهای هم‌نام در دو طرف `=` در واقع متغیرهای متفاوتی هستند

## نمونه نتیجه ترجمه

قطعه کد ترجمه شده، برای مشاهده کد کامل به [نسخه Polars](examples/output_polars.py) مراجعه کنید

```python
def func_0_ts__asset(df: pl.DataFrame) -> pl.DataFrame:
    df = df.sort(by=[_DATE_])
    # ========================================
    df = df.with_columns(
        _x_0=1 / ts_delay(OPEN, -1),
        LABEL_CC_1=(-CLOSE + ts_delay(CLOSE, -1)) / CLOSE,
    )
    # ========================================
    df = df.with_columns(
        LABEL_OO_1=_x_0 * ts_delay(OPEN, -2) - 1,
        LABEL_OO_2=_x_0 * ts_delay(OPEN, -3) - 1,
    )
    return df
```

قطعه کد ترجمه شده، برای مشاهده کد کامل به [نسخه Pandas](examples/output_pandas.py) مراجعه کنید

```python
def func_2_cs__date(df: pd.DataFrame) -> pd.DataFrame:
    # expr_4 = cs_rank(x_7)
    df["expr_4"] = (df["x_7"]).rank(pct=True)
    return df


def func_3_ts__asset__date(df: pd.DataFrame) -> pd.DataFrame:
    # expr_5 = -ts_corr(OPEN, CLOSE, 10)
    df["expr_5"] = -(df["OPEN"]).rolling(10).corr(df["CLOSE"])
    # expr_6 = ts_delta(OPEN, 10)
    df["expr_6"] = df["OPEN"].diff(10)
    return df

```

## راه‌اندازی رابط وب تعاملی محلی

کافیست `streamlit run streamlit_app.py` را اجرا کنید.

---

[Powered By OpenAiTx](https://github.com/OpenAiTx/OpenAiTx) - 2025-06-07

---