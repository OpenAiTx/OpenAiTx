[
  {
    "Id": 1,
    "Content": "\n<h2 align=\"center\"> <a href=\"https://arxiv.org/abs/2412.09606\">Feat2GS: Probing Visual Foundation Models with Gaussian Splatting</a>\n</h2>\n\n<h5 align=\"center\">\n\n[![arXiv](https://img.shields.io/badge/Arxiv-2412.09606-b31b1b.svg?logo=arXiv)](https://arxiv.org/abs/2412.09606) \n[![Home Page](https://img.shields.io/badge/Project-Website-green.svg)](https://fanegg.github.io/Feat2GS/)  [![youtube](https://img.shields.io/badge/Video-E33122?logo=Youtube)](https://youtu.be/4fT5lzcAJqo?si=_fCSIuXNBSmov2VA)  [![Gradio](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Demo-orange)](https://huggingface.co/spaces/endless-ai/Feat2GS)  [![X](https://img.shields.io/badge/@Yue%20Chen-black?logo=X)](https://twitter.com/faneggchen)  [![Bluesky](https://img.shields.io/badge/@Yue%20Chen-white?logo=Bluesky)](https://bsky.app/profile/fanegg.bsky.social)\n\n[Yue Chen](https://fanegg.github.io/),\n[Xingyu Chen](https://rover-xingyu.github.io/),\n[Anpei Chen](https://apchenstu.github.io/),\n[Gerard Pons-Moll](https://virtualhumans.mpi-inf.mpg.de/),\n[Yuliang Xiu](https://xiuyuliang.cn/)\n</h5>\n\n<div align=\"center\">\nThis repository is the official implementation of Feat2GS, a unified framework to probe “texturel and geometry awareness” of visual foundation models. Novel view synthesis serves as an effective proxy for 3D evaluation.\n</div>\n<br>\n\nhttps://github.com/user-attachments/assets/07ebb8e1-6001-47bf-bf74-984b0032cc17\n\n\n## Updates\n\n- [July 10, 2025] Add a new evaluation of VGGT encoder and decoder features. See the results [here](https://raw.githubusercontent.com/fanegg/Feat2GS/main/assets/Feat2GS_Benchmark.pdf).\n\n## Get Started\n\n### Installation\n1. Clone Feat2GS and download pre-trained model from [DUSt3R](https://github.com/naver/dust3r)/[MASt3R](https://github.com/naver/mast3r).",
    "ContentSha": "KoTgEzp2o1sraNuueC/bhbUFwP0YW5KVcUvei3y3uyE=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "<h2 align=\"center\"> <a href=\"https://arxiv.org/abs/2412.09606\">Feat2GS: 가우시안 스플래팅을 이용한 시각 기초 모델 탐색</a>\n</h2>\n\n<h5 align=\"center\">\n\n[![arXiv](https://img.shields.io/badge/Arxiv-2412.09606-b31b1b.svg?logo=arXiv)](https://arxiv.org/abs/2412.09606) \n[![Home Page](https://img.shields.io/badge/Project-Website-green.svg)](https://fanegg.github.io/Feat2GS/)  [![youtube](https://img.shields.io/badge/Video-E33122?logo=Youtube)](https://youtu.be/4fT5lzcAJqo?si=_fCSIuXNBSmov2VA)  [![Gradio](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Demo-orange)](https://huggingface.co/spaces/endless-ai/Feat2GS)  [![X](https://img.shields.io/badge/@Yue%20Chen-black?logo=X)](https://twitter.com/faneggchen)  [![Bluesky](https://img.shields.io/badge/@Yue%20Chen-white?logo=Bluesky)](https://bsky.app/profile/fanegg.bsky.social)\n\n[Yue Chen](https://fanegg.github.io/),\n[Xingyu Chen](https://rover-xingyu.github.io/),\n[Anpei Chen](https://apchenstu.github.io/),\n[Gerard Pons-Moll](https://virtualhumans.mpi-inf.mpg.de/),\n[Yuliang Xiu](https://xiuyuliang.cn/)\n</h5>\n\n<div align=\"center\">\n이 저장소는 시각 기초 모델의 “텍스처 및 기하학 인식”을 탐색하기 위한 통합 프레임워크인 Feat2GS의 공식 구현체입니다. 새로운 뷰 합성은 3D 평가를 위한 효과적인 대리 지표로 작용합니다.\n</div>\n<br>\n\nhttps://github.com/user-attachments/assets/07ebb8e1-6001-47bf-bf74-984b0032cc17\n\n\n## 업데이트\n\n- [2025년 7월 10일] VGGT 인코더 및 디코더 특징의 새로운 평가 추가. 결과는 [여기](https://raw.githubusercontent.com/fanegg/Feat2GS/main/assets/Feat2GS_Benchmark.pdf)에서 확인하세요.\n\n## 시작하기\n\n### 설치\n1. Feat2GS를 클론하고 [DUSt3R](https://github.com/naver/dust3r)/[MASt3R](https://github.com/naver/mast3r)에서 사전 학습된 모델을 다운로드하세요.\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "<h2 align=\"center\"> <a href=\"https://arxiv.org/abs/2412.09606\">Feat2GS: 가우시안 스플래팅을 이용한 시각 기초 모델 탐색</a>"
      },
      {
        "row": 2,
        "rowsha": "vC9c/qs7/NxfXeQjCEj48IRriejMFB98IrWPNXpAZUI=",
        "originContent": "<h2 align=\"center\"> <a href=\"https://arxiv.org/abs/2412.09606\">Feat2GS: Probing Visual Foundation Models with Gaussian Splatting</a>",
        "translatedContent": "</h2>"
      },
      {
        "row": 3,
        "rowsha": "zvkhCrDoF8KgpHtRKAFP1Wd8gMoco105aBgHZaKSw3E=",
        "originContent": "</h2>",
        "translatedContent": ""
      },
      {
        "row": 4,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "<h5 align=\"center\">"
      },
      {
        "row": 5,
        "rowsha": "8+zfK9kBhhsLwJaEPhEVyCGp11UJQ3HBO6F/B2a8x7E=",
        "originContent": "<h5 align=\"center\">",
        "translatedContent": ""
      },
      {
        "row": 6,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "[![arXiv](https://img.shields.io/badge/Arxiv-2412.09606-b31b1b.svg?logo=arXiv)](https://arxiv.org/abs/2412.09606) "
      },
      {
        "row": 7,
        "rowsha": "MKGX+bHo9gwbTVAMJcblRlOvV0zqPumBDhbClQzjH6Q=",
        "originContent": "[![arXiv](https://img.shields.io/badge/Arxiv-2412.09606-b31b1b.svg?logo=arXiv)](https://arxiv.org/abs/2412.09606) ",
        "translatedContent": "[![Home Page](https://img.shields.io/badge/Project-Website-green.svg)](https://fanegg.github.io/Feat2GS/)  [![youtube](https://img.shields.io/badge/Video-E33122?logo=Youtube)](https://youtu.be/4fT5lzcAJqo?si=_fCSIuXNBSmov2VA)  [![Gradio](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Demo-orange)](https://huggingface.co/spaces/endless-ai/Feat2GS)  [![X](https://img.shields.io/badge/@Yue%20Chen-black?logo=X)](https://twitter.com/faneggchen)  [![Bluesky](https://img.shields.io/badge/@Yue%20Chen-white?logo=Bluesky)](https://bsky.app/profile/fanegg.bsky.social)"
      },
      {
        "row": 8,
        "rowsha": "do31fv9FL0PIXYX9mQnqYIhVQxRHEDwdEjp31d3iYjo=",
        "originContent": "[![Home Page](https://img.shields.io/badge/Project-Website-green.svg)](https://fanegg.github.io/Feat2GS/)  [![youtube](https://img.shields.io/badge/Video-E33122?logo=Youtube)](https://youtu.be/4fT5lzcAJqo?si=_fCSIuXNBSmov2VA)  [![Gradio](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Demo-orange)](https://huggingface.co/spaces/endless-ai/Feat2GS)  [![X](https://img.shields.io/badge/@Yue%20Chen-black?logo=X)](https://twitter.com/faneggchen)  [![Bluesky](https://img.shields.io/badge/@Yue%20Chen-white?logo=Bluesky)](https://bsky.app/profile/fanegg.bsky.social)",
        "translatedContent": ""
      },
      {
        "row": 9,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "[Yue Chen](https://fanegg.github.io/),"
      },
      {
        "row": 10,
        "rowsha": "nRSrYW1mw81kFgtJ/xvkDoIk1P4RQjgFs0Za6PPtSj4=",
        "originContent": "[Yue Chen](https://fanegg.github.io/),",
        "translatedContent": "[Xingyu Chen](https://rover-xingyu.github.io/),"
      },
      {
        "row": 11,
        "rowsha": "5+y0CDtS3zaS4hvM063Knd15EjtsKU8El2uogxq6vyE=",
        "originContent": "[Xingyu Chen](https://rover-xingyu.github.io/),",
        "translatedContent": "[Anpei Chen](https://apchenstu.github.io/),"
      },
      {
        "row": 12,
        "rowsha": "LUbk3k1jI3Mc89dggAoiaR0Wiu/9orP+SjmvscwawE4=",
        "originContent": "[Anpei Chen](https://apchenstu.github.io/),",
        "translatedContent": "[Gerard Pons-Moll](https://virtualhumans.mpi-inf.mpg.de/),"
      },
      {
        "row": 13,
        "rowsha": "KMB51Qk4jiAlwf6DK66RIzsxUoXYY5vJuR0hHqwZ/GI=",
        "originContent": "[Gerard Pons-Moll](https://virtualhumans.mpi-inf.mpg.de/),",
        "translatedContent": "[Yuliang Xiu](https://xiuyuliang.cn/)"
      },
      {
        "row": 14,
        "rowsha": "SevLIVxRfCyl2HuxWSPV+1zOlZvJzg2voawhyv8r+BY=",
        "originContent": "[Yuliang Xiu](https://xiuyuliang.cn/)",
        "translatedContent": "</h5>"
      },
      {
        "row": 15,
        "rowsha": "YM0w/+Gy2nPkE/+F3BY5fsV16Jbdv4iAtRjMamnhSqE=",
        "originContent": "</h5>",
        "translatedContent": ""
      },
      {
        "row": 16,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "<div align=\"center\">"
      },
      {
        "row": 17,
        "rowsha": "94MDjHJY1ZLwHNTLIEUIfk7TMc9cq1L/1FmwhqBTe/k=",
        "originContent": "<div align=\"center\">",
        "translatedContent": "이 저장소는 시각 기초 모델의 “텍스처 및 기하학 인식”을 탐색하기 위한 통합 프레임워크인 Feat2GS의 공식 구현체입니다. 새로운 뷰 합성은 3D 평가를 위한 효과적인 대리 지표로 작용합니다."
      },
      {
        "row": 18,
        "rowsha": "6vpf0mDzfMZdRfwTeScabW4busZywD2188E/jZHF7fA=",
        "originContent": "This repository is the official implementation of Feat2GS, a unified framework to probe “texturel and geometry awareness” of visual foundation models. Novel view synthesis serves as an effective proxy for 3D evaluation.",
        "translatedContent": "</div>"
      },
      {
        "row": 19,
        "rowsha": "qsMmUbEPVnxGG5tPJV1vsfpoWbU2jYvZpRr5IKshzyM=",
        "originContent": "</div>",
        "translatedContent": "<br>"
      },
      {
        "row": 20,
        "rowsha": "Za7xrbqGcqX+eTLZ+fDcNcJDWJP2URKsrGKNLcF6C88=",
        "originContent": "<br>",
        "translatedContent": ""
      },
      {
        "row": 21,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "https://github.com/user-attachments/assets/07ebb8e1-6001-47bf-bf74-984b0032cc17"
      },
      {
        "row": 22,
        "rowsha": "7etccVSGoIaHFRrJ/VR82YagRjZcogyVSyfpq1ZMWeE=",
        "originContent": "https://github.com/user-attachments/assets/07ebb8e1-6001-47bf-bf74-984b0032cc17",
        "translatedContent": ""
      },
      {
        "row": 23,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 24,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "## 업데이트"
      },
      {
        "row": 25,
        "rowsha": "33rz/QaTx1fSJq1J/I+4UruMGDlkyUTWsPmF1Y9FSSI=",
        "originContent": "## Updates",
        "translatedContent": ""
      },
      {
        "row": 26,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "- [2025년 7월 10일] VGGT 인코더 및 디코더 특징의 새로운 평가 추가. 결과는 [여기](https://raw.githubusercontent.com/fanegg/Feat2GS/main/assets/Feat2GS_Benchmark.pdf)에서 확인하세요."
      },
      {
        "row": 27,
        "rowsha": "q7cB1jdhwc6h3zVlrL2Y+iRRzwPhePSjuPBkxKKis+g=",
        "originContent": "- [July 10, 2025] Add a new evaluation of VGGT encoder and decoder features. See the results [here](https://raw.githubusercontent.com/fanegg/Feat2GS/main/assets/Feat2GS_Benchmark.pdf).",
        "translatedContent": ""
      },
      {
        "row": 28,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "## 시작하기"
      },
      {
        "row": 29,
        "rowsha": "fdzSvcVmecTeZF5A18WcXJ925k4OTH/HculV8+p+hkk=",
        "originContent": "## Get Started",
        "translatedContent": ""
      },
      {
        "row": 30,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "### 설치"
      },
      {
        "row": 31,
        "rowsha": "JuAC4s82hMbNkRqX17s0ltqjVmeI/HhsmWljgf+i7Kg=",
        "originContent": "### Installation",
        "translatedContent": "1. Feat2GS를 클론하고 [DUSt3R](https://github.com/naver/dust3r)/[MASt3R](https://github.com/naver/mast3r)에서 사전 학습된 모델을 다운로드하세요."
      },
      {
        "row": 32,
        "rowsha": "49zZPtxtZ5+TWXD45pS4+BoiQbybEfvyYgPlLymg490=",
        "originContent": "1. Clone Feat2GS and download pre-trained model from [DUSt3R](https://github.com/naver/dust3r)/[MASt3R](https://github.com/naver/mast3r).",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 2,
    "Content": "```bash\ngit clone https://github.com/fanegg/Feat2GS.git\ncd Feat2GS/submodules/mast3r/\nmkdir -p checkpoints/\nwget https://download.europe.naverlabs.com/ComputerVision/DUSt3R/DUSt3R_ViTLarge_BaseDecoder_512_dpt.pth -P checkpoints/\nwget https://download.europe.naverlabs.com/ComputerVision/MASt3R/MASt3R_ViTLarge_BaseDecoder_512_catmlpdpt_metric.pth -P checkpoints/\ncd ../../\n```",
    "ContentSha": "t3or5GL3W1iHOFCNQpqG/FIws3ZkuzWkP3WcN7GbExY=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\ngit clone https://github.com/fanegg/Feat2GS.git\ncd Feat2GS/submodules/mast3r/\nmkdir -p checkpoints/\nwget https://download.europe.naverlabs.com/ComputerVision/DUSt3R/DUSt3R_ViTLarge_BaseDecoder_512_dpt.pth -P checkpoints/\nwget https://download.europe.naverlabs.com/ComputerVision/MASt3R/MASt3R_ViTLarge_BaseDecoder_512_catmlpdpt_metric.pth -P checkpoints/\ncd ../../\n```",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "rTMjNc+qNIxb1xXDR5hEYiJw1fc4muBwuBsTXVIaIho=",
        "originContent": "```bash",
        "translatedContent": "```bash"
      },
      {
        "row": 2,
        "rowsha": "KNWtOD9YWyOCW8xPxzepXipNjMc68Rr0TrCdpC2pKlk=",
        "originContent": "git clone https://github.com/fanegg/Feat2GS.git",
        "translatedContent": "git clone https://github.com/fanegg/Feat2GS.git"
      },
      {
        "row": 3,
        "rowsha": "hQN4ROabtCzgGU3mdCndQQ5N1zty8ZM7DOH/QxEWgh0=",
        "originContent": "cd Feat2GS/submodules/mast3r/",
        "translatedContent": "cd Feat2GS/submodules/mast3r/"
      },
      {
        "row": 4,
        "rowsha": "h7uOu06BN+buh8TKgyuA/eq4aI2lqysF8zGhRzoY/pg=",
        "originContent": "mkdir -p checkpoints/",
        "translatedContent": "mkdir -p checkpoints/"
      },
      {
        "row": 5,
        "rowsha": "oy+nlUCKJBElJFas0wcZ9Gihz4tPfXfFGMDWhLH0blg=",
        "originContent": "wget https://download.europe.naverlabs.com/ComputerVision/DUSt3R/DUSt3R_ViTLarge_BaseDecoder_512_dpt.pth -P checkpoints/",
        "translatedContent": "wget https://download.europe.naverlabs.com/ComputerVision/DUSt3R/DUSt3R_ViTLarge_BaseDecoder_512_dpt.pth -P checkpoints/"
      },
      {
        "row": 6,
        "rowsha": "RE38fqpFJve3Kl7vJK2pnhH01H0H+ytsM7HCJQfb/dg=",
        "originContent": "wget https://download.europe.naverlabs.com/ComputerVision/MASt3R/MASt3R_ViTLarge_BaseDecoder_512_catmlpdpt_metric.pth -P checkpoints/",
        "translatedContent": "wget https://download.europe.naverlabs.com/ComputerVision/MASt3R/MASt3R_ViTLarge_BaseDecoder_512_catmlpdpt_metric.pth -P checkpoints/"
      },
      {
        "row": 7,
        "rowsha": "VqqupK46U7dreT5Sz49BRVCaRbnekFlKpLfe/kMBdts=",
        "originContent": "cd ../../",
        "translatedContent": "cd ../../"
      },
      {
        "row": 8,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      }
    ],
    "IsCodeBlock": true
  },
  {
    "Id": 3,
    "Content": "\n2. Create the environment, here we show an example using conda.",
    "ContentSha": "uFFgdlSgaQmYZfoX1oCHZbkjMNTC1PduC9MtdEalzM0=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "2. 환경을 생성합니다. 여기서는 conda를 사용하는 예를 보여줍니다.\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "2. 환경을 생성합니다. 여기서는 conda를 사용하는 예를 보여줍니다."
      },
      {
        "row": 2,
        "rowsha": "31Dfad6AcdyB5XsnbjSCkDHWMyt/0ZHFBQUxR6ts+G0=",
        "originContent": "2. Create the environment, here we show an example using conda.",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 4,
    "Content": "```bash\nconda create -n feat2gs python=3.11 cmake=3.14.0\nconda activate feat2gs\npip install \"torch==2.5.1\" \"torchvision==0.20.1\" \"numpy<2\" --index-url https://download.pytorch.org/whl/cu121  # use the correct version of cuda for your system\ncd Feat2GS/\npip install -r requirements.txt\npip install submodules/simple-knn\n```",
    "ContentSha": "8sX30UVJKN5V1754DhfrgXqap6bLkynDqYrPBjKrfJs=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\nconda create -n feat2gs python=3.11 cmake=3.14.0\nconda activate feat2gs\npip install \"torch==2.5.1\" \"torchvision==0.20.1\" \"numpy<2\" --index-url https://download.pytorch.org/whl/cu121  # use the correct version of cuda for your system\ncd Feat2GS/\npip install -r requirements.txt\npip install submodules/simple-knn\n```",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "rTMjNc+qNIxb1xXDR5hEYiJw1fc4muBwuBsTXVIaIho=",
        "originContent": "```bash",
        "translatedContent": "```bash"
      },
      {
        "row": 2,
        "rowsha": "TU8r4YRtPy0BPhGvTAclNrKD5SJsHWJhaGrgIaywFgM=",
        "originContent": "conda create -n feat2gs python=3.11 cmake=3.14.0",
        "translatedContent": "conda create -n feat2gs python=3.11 cmake=3.14.0"
      },
      {
        "row": 3,
        "rowsha": "7kjIC79MlG/MpK8QuXLdSyowA2dowatnh80qKkWpaCU=",
        "originContent": "conda activate feat2gs",
        "translatedContent": "conda activate feat2gs"
      },
      {
        "row": 4,
        "rowsha": "ktJCkyrGjdIAfji4IEOoIOpMHJ4gB5iwrS3FK8NcHNM=",
        "originContent": "pip install \"torch==2.5.1\" \"torchvision==0.20.1\" \"numpy<2\" --index-url https://download.pytorch.org/whl/cu121  # use the correct version of cuda for your system",
        "translatedContent": "pip install \"torch==2.5.1\" \"torchvision==0.20.1\" \"numpy<2\" --index-url https://download.pytorch.org/whl/cu121  # use the correct version of cuda for your system"
      },
      {
        "row": 5,
        "rowsha": "nh53AYypS0/Tr1LsO5AhIi+IKa7hThkX9h50d8NB59c=",
        "originContent": "cd Feat2GS/",
        "translatedContent": "cd Feat2GS/"
      },
      {
        "row": 6,
        "rowsha": "9jQ5Tmvmy0Rca8gZGuieLw3iHyIU3Ba5zS4ICtZgsdw=",
        "originContent": "pip install -r requirements.txt",
        "translatedContent": "pip install -r requirements.txt"
      },
      {
        "row": 7,
        "rowsha": "99v7zxn+r+Rpv8lk939YdtT1GG9vsNPW8rkppdV+Uas=",
        "originContent": "pip install submodules/simple-knn",
        "translatedContent": "pip install submodules/simple-knn"
      },
      {
        "row": 8,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      }
    ],
    "IsCodeBlock": true
  },
  {
    "Id": 5,
    "Content": "\n3. Optional but highly suggested, compile the cuda kernels for RoPE (as in CroCo v2).",
    "ContentSha": "gfUkk9XXLVcOc/X68AxDeWPu6UH4LwsEWe8QIGoeGIA=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "3. 선택 사항이지만 강력히 권장되며, RoPE용 cuda 커널을 컴파일하십시오(크로코 v2와 동일).\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "3. 선택 사항이지만 강력히 권장되며, RoPE용 cuda 커널을 컴파일하십시오(크로코 v2와 동일)."
      },
      {
        "row": 2,
        "rowsha": "0lSA6isCfWwhKrJIZBCgjjY9U1ssabLnih2YbZYiYQw=",
        "originContent": "3. Optional but highly suggested, compile the cuda kernels for RoPE (as in CroCo v2).",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 6,
    "Content": "```bash\n# DUST3R relies on RoPE positional embeddings for which you can compile some cuda kernels for faster runtime.\ncd submodules/mast3r/dust3r/croco/models/curope/\npython setup.py build_ext --inplace\ncd ../../../../../../\n```",
    "ContentSha": "7fY0ILYKdws3HKMqxxU2dhLdFihHG4/TdIIazN/1cGc=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\n# DUST3R relies on RoPE positional embeddings for which you can compile some cuda kernels for faster runtime.\ncd submodules/mast3r/dust3r/croco/models/curope/\npython setup.py build_ext --inplace\ncd ../../../../../../\n```",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "rTMjNc+qNIxb1xXDR5hEYiJw1fc4muBwuBsTXVIaIho=",
        "originContent": "```bash",
        "translatedContent": "```bash"
      },
      {
        "row": 2,
        "rowsha": "bXaezCPkCY9nE+2TYEI9f1Qp5QEiWdAwfWeyNb1Z87c=",
        "originContent": "# DUST3R relies on RoPE positional embeddings for which you can compile some cuda kernels for faster runtime.",
        "translatedContent": "# DUST3R relies on RoPE positional embeddings for which you can compile some cuda kernels for faster runtime."
      },
      {
        "row": 3,
        "rowsha": "nDNvDTPP/t8wB+yYbxHpNEiNSFda3PiARDBZ3D4BYf8=",
        "originContent": "cd submodules/mast3r/dust3r/croco/models/curope/",
        "translatedContent": "cd submodules/mast3r/dust3r/croco/models/curope/"
      },
      {
        "row": 4,
        "rowsha": "EO6iGOJXxFWOCJlIhhvRylaZpoa1R8PznZM9jDek55w=",
        "originContent": "python setup.py build_ext --inplace",
        "translatedContent": "python setup.py build_ext --inplace"
      },
      {
        "row": 5,
        "rowsha": "3bSltk/gaM8Hghqf4THiH0Z4//OVZK2ZQMFL+cib1H8=",
        "originContent": "cd ../../../../../../",
        "translatedContent": "cd ../../../../../../"
      },
      {
        "row": 6,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      }
    ],
    "IsCodeBlock": true
  },
  {
    "Id": 7,
    "Content": "\n4. (Optional) follow [this instruction](https://github.com/cvlab-columbia/zero123?tab=readme-ov-file#novel-view-synthesis-1) to install requirements for probing [Zero123](https://github.com/cvlab-columbia/zero123).\n\n### Usage\n1. Data preparation (We provide our evaluation and inference datasets: [link](https://drive.google.com/file/d/1PLTFcvJfiPucrB-pIwfp5QG-AIHcJdjN/view?usp=drive_link))",
    "ContentSha": "cH1zYhlIZItViD2dAGGso0EL2PtqnDvQyH9Ktfl2gtA=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "4. (선택 사항) [이 지침](https://github.com/cvlab-columbia/zero123?tab=readme-ov-file#novel-view-synthesis-1)을 따라 [Zero123](https://github.com/cvlab-columbia/zero123) 탐색을 위한 요구 사항을 설치하세요.\n\n### 사용법\n1. 데이터 준비 (평가 및 추론 데이터셋을 제공합니다: [링크](https://drive.google.com/file/d/1PLTFcvJfiPucrB-pIwfp5QG-AIHcJdjN/view?usp=drive_link))\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "4. (선택 사항) [이 지침](https://github.com/cvlab-columbia/zero123?tab=readme-ov-file#novel-view-synthesis-1)을 따라 [Zero123](https://github.com/cvlab-columbia/zero123) 탐색을 위한 요구 사항을 설치하세요."
      },
      {
        "row": 2,
        "rowsha": "lW0arfkjUGgMnZrKbztrQvPJ+PRSqRSv0WPSe+jqhJ0=",
        "originContent": "4. (Optional) follow [this instruction](https://github.com/cvlab-columbia/zero123?tab=readme-ov-file#novel-view-synthesis-1) to install requirements for probing [Zero123](https://github.com/cvlab-columbia/zero123).",
        "translatedContent": ""
      },
      {
        "row": 3,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "### 사용법"
      },
      {
        "row": 4,
        "rowsha": "elsthwRCF+vtpOBxqAWFEGuucFIX2nKj7DKSYQAuFv8=",
        "originContent": "### Usage",
        "translatedContent": "1. 데이터 준비 (평가 및 추론 데이터셋을 제공합니다: [링크](https://drive.google.com/file/d/1PLTFcvJfiPucrB-pIwfp5QG-AIHcJdjN/view?usp=drive_link))"
      },
      {
        "row": 5,
        "rowsha": "rq2jIPDRpiyMDB1q1gxKG4WJV8c0+oPs+v1cPXknDSs=",
        "originContent": "1. Data preparation (We provide our evaluation and inference datasets: [link](https://drive.google.com/file/d/1PLTFcvJfiPucrB-pIwfp5QG-AIHcJdjN/view?usp=drive_link))",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 8,
    "Content": "```bash\n  cd <data_root>/Feat2GS/\n```",
    "ContentSha": "+ee1sZBWaUwnYmQmwWvNhS5YM96uUlTd9jD5ik88zfk=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\n  cd <data_root>/Feat2GS/\n```",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "rTMjNc+qNIxb1xXDR5hEYiJw1fc4muBwuBsTXVIaIho=",
        "originContent": "```bash",
        "translatedContent": "```bash"
      },
      {
        "row": 2,
        "rowsha": "+7+dl+U+EoaO9zYcHApeTbyqn0QleN5p/HX5yoD80vs=",
        "originContent": "  cd <data_root>/Feat2GS/",
        "translatedContent": "  cd <data_root>/Feat2GS/"
      },
      {
        "row": 3,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      }
    ],
    "IsCodeBlock": true
  },
  {
    "Id": 9,
    "Content": "\n> If you want to build custom datasets, please follow and edit:\n> ```\n> build_dataset/0_create_json.py ## create dataset_split.json to split train/test set\n> build_dataset/1_create_feat2gs_dataset.py ## use dataset_split.json to create dataset\n> ```\n\n\n2. Evaluate Visual Foundation Models:\n\n  | Step | Description (link to command) |\n  |------|-------------|\n  | (1)  | [DUSt3R initialization & Feature extraction](https://github.com/fanegg/Feat2GS/blob/b8eadaa54549d34420eba61b388548b8ec8e7325/scripts/run_feat2gs_eval_parallel.sh#L245-L250) |\n  | (2)  | [Readout 3DGS from features & Jointly optimize pose](https://github.com/fanegg/Feat2GS/blob/b8eadaa54549d34420eba61b388548b8ec8e7325/scripts/run_feat2gs_eval_parallel.sh#L253-L262) |\n  | (3)  | [Test pose initialization](https://github.com/fanegg/Feat2GS/blob/b8eadaa54549d34420eba61b388548b8ec8e7325/scripts/run_feat2gs_eval_parallel.sh#L265-L270) |\n  | (4)  | [Render test view for evaluation](https://github.com/fanegg/Feat2GS/blob/b8eadaa54549d34420eba61b388548b8ec8e7325/scripts/run_feat2gs_eval_parallel.sh#L273-L282) |\n  | (5)  | [Metric](https://github.com/fanegg/Feat2GS/blob/b8eadaa54549d34420eba61b388548b8ec8e7325/scripts/run_feat2gs_eval_parallel.sh#L298-L301) |\n  | (Optional)  | [Render video with generated trajectory](https://github.com/fanegg/Feat2GS/blob/b8eadaa54549d34420eba61b388548b8ec8e7325/scripts/run_feat2gs_eval_parallel.sh#L304-L315) |\n",
    "ContentSha": "CWDH653XyBMUo8foLOLXi6MJ1YUzkXPN+BA9THm2+9s=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "> 사용자 정의 데이터셋을 구축하려면 다음을 따르고 편집하세요:\n> ```\n> build_dataset/0_create_json.py ## train/test 세트를 분할하기 위한 dataset_split.json 생성\n> build_dataset/1_create_feat2gs_dataset.py ## dataset_split.json을 사용하여 데이터셋 생성\n> ```\n\n\n2. Visual Foundation Models 평가:\n\n  | 단계 | 설명 (명령어 링크) |\n  |------|-------------|\n  | (1)  | [DUSt3R 초기화 및 특징 추출](https://github.com/fanegg/Feat2GS/blob/b8eadaa54549d34420eba61b388548b8ec8e7325/scripts/run_feat2gs_eval_parallel.sh#L245-L250) |\n  | (2)  | [특징에서 3DGS 읽어오기 및 자세 공동 최적화](https://github.com/fanegg/Feat2GS/blob/b8eadaa54549d34420eba61b388548b8ec8e7325/scripts/run_feat2gs_eval_parallel.sh#L253-L262) |\n  | (3)  | [테스트 자세 초기화](https://github.com/fanegg/Feat2GS/blob/b8eadaa54549d34420eba61b388548b8ec8e7325/scripts/run_feat2gs_eval_parallel.sh#L265-L270) |\n  | (4)  | [평가를 위한 테스트 뷰 렌더링](https://github.com/fanegg/Feat2GS/blob/b8eadaa54549d34420eba61b388548b8ec8e7325/scripts/run_feat2gs_eval_parallel.sh#L273-L282) |\n  | (5)  | [지표](https://github.com/fanegg/Feat2GS/blob/b8eadaa54549d34420eba61b388548b8ec8e7325/scripts/run_feat2gs_eval_parallel.sh#L298-L301) |\n  | (선택)  | [생성된 경로로 비디오 렌더링](https://github.com/fanegg/Feat2GS/blob/b8eadaa54549d34420eba61b388548b8ec8e7325/scripts/run_feat2gs_eval_parallel.sh#L304-L315) |\n\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "> 사용자 정의 데이터셋을 구축하려면 다음을 따르고 편집하세요:"
      },
      {
        "row": 2,
        "rowsha": "2qw5xxkUMsasLb/ww3H9C9IiCltB+1W6aWjpJYvUKng=",
        "originContent": "> If you want to build custom datasets, please follow and edit:",
        "translatedContent": "> ```"
      },
      {
        "row": 3,
        "rowsha": "MSWTuK53TAylT2dLwAgGiANzYPowZK3H1tOGCQeahfM=",
        "originContent": "> ```",
        "translatedContent": "> build_dataset/0_create_json.py ## train/test 세트를 분할하기 위한 dataset_split.json 생성"
      },
      {
        "row": 4,
        "rowsha": "IdZFvnXuklfFm50cPyn9WjWNi/xu8CV7QVACaavvYdw=",
        "originContent": "> build_dataset/0_create_json.py ## create dataset_split.json to split train/test set",
        "translatedContent": "> build_dataset/1_create_feat2gs_dataset.py ## dataset_split.json을 사용하여 데이터셋 생성"
      },
      {
        "row": 5,
        "rowsha": "dCWFOS1Yef/haSB3/luqLngTG+cCyliSlLozRGeu/lw=",
        "originContent": "> build_dataset/1_create_feat2gs_dataset.py ## use dataset_split.json to create dataset",
        "translatedContent": "> ```"
      },
      {
        "row": 6,
        "rowsha": "MSWTuK53TAylT2dLwAgGiANzYPowZK3H1tOGCQeahfM=",
        "originContent": "> ```",
        "translatedContent": ""
      },
      {
        "row": 7,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 8,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "2. Visual Foundation Models 평가:"
      },
      {
        "row": 9,
        "rowsha": "GITcr/mrtI+NQmTwFdyeZMKVeHVHxBeWndDDrTxmqHk=",
        "originContent": "2. Evaluate Visual Foundation Models:",
        "translatedContent": ""
      },
      {
        "row": 10,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "  | 단계 | 설명 (명령어 링크) |"
      },
      {
        "row": 11,
        "rowsha": "2j5Ec0DENZGlvj7M3mJMVRNmx3fZJOJKsby+NFxDNQc=",
        "originContent": "  | Step | Description (link to command) |",
        "translatedContent": "  |------|-------------|"
      },
      {
        "row": 12,
        "rowsha": "UhIH0dBNvGPUSlO1WMiUg8zk6vBI8ffwpzu2dfzavoo=",
        "originContent": "  |------|-------------|",
        "translatedContent": "  | (1)  | [DUSt3R 초기화 및 특징 추출](https://github.com/fanegg/Feat2GS/blob/b8eadaa54549d34420eba61b388548b8ec8e7325/scripts/run_feat2gs_eval_parallel.sh#L245-L250) |"
      },
      {
        "row": 13,
        "rowsha": "RXhTxD9BP8kQ45u7ehVTyW6wGrkkLdwBHaruM1JpqwU=",
        "originContent": "  | (1)  | [DUSt3R initialization & Feature extraction](https://github.com/fanegg/Feat2GS/blob/b8eadaa54549d34420eba61b388548b8ec8e7325/scripts/run_feat2gs_eval_parallel.sh#L245-L250) |",
        "translatedContent": "  | (2)  | [특징에서 3DGS 읽어오기 및 자세 공동 최적화](https://github.com/fanegg/Feat2GS/blob/b8eadaa54549d34420eba61b388548b8ec8e7325/scripts/run_feat2gs_eval_parallel.sh#L253-L262) |"
      },
      {
        "row": 14,
        "rowsha": "HBTR6SLGNvU0KGiSM875VqufgjyutD4Xy2nohe7A+uI=",
        "originContent": "  | (2)  | [Readout 3DGS from features & Jointly optimize pose](https://github.com/fanegg/Feat2GS/blob/b8eadaa54549d34420eba61b388548b8ec8e7325/scripts/run_feat2gs_eval_parallel.sh#L253-L262) |",
        "translatedContent": "  | (3)  | [테스트 자세 초기화](https://github.com/fanegg/Feat2GS/blob/b8eadaa54549d34420eba61b388548b8ec8e7325/scripts/run_feat2gs_eval_parallel.sh#L265-L270) |"
      },
      {
        "row": 15,
        "rowsha": "h6iM7jng/Pu77UbILu621i77UnoPNu3Hc8yO/WvAJUA=",
        "originContent": "  | (3)  | [Test pose initialization](https://github.com/fanegg/Feat2GS/blob/b8eadaa54549d34420eba61b388548b8ec8e7325/scripts/run_feat2gs_eval_parallel.sh#L265-L270) |",
        "translatedContent": "  | (4)  | [평가를 위한 테스트 뷰 렌더링](https://github.com/fanegg/Feat2GS/blob/b8eadaa54549d34420eba61b388548b8ec8e7325/scripts/run_feat2gs_eval_parallel.sh#L273-L282) |"
      },
      {
        "row": 16,
        "rowsha": "dTPz9LyKUsKFG5IhO49StcEw14CilZGR1Lr/FXzArp4=",
        "originContent": "  | (4)  | [Render test view for evaluation](https://github.com/fanegg/Feat2GS/blob/b8eadaa54549d34420eba61b388548b8ec8e7325/scripts/run_feat2gs_eval_parallel.sh#L273-L282) |",
        "translatedContent": "  | (5)  | [지표](https://github.com/fanegg/Feat2GS/blob/b8eadaa54549d34420eba61b388548b8ec8e7325/scripts/run_feat2gs_eval_parallel.sh#L298-L301) |"
      },
      {
        "row": 17,
        "rowsha": "CHg2+xnfa+qJtcFOYJQvXSwoH4rKvG/ogz5lcozy6YM=",
        "originContent": "  | (5)  | [Metric](https://github.com/fanegg/Feat2GS/blob/b8eadaa54549d34420eba61b388548b8ec8e7325/scripts/run_feat2gs_eval_parallel.sh#L298-L301) |",
        "translatedContent": "  | (선택)  | [생성된 경로로 비디오 렌더링](https://github.com/fanegg/Feat2GS/blob/b8eadaa54549d34420eba61b388548b8ec8e7325/scripts/run_feat2gs_eval_parallel.sh#L304-L315) |"
      },
      {
        "row": 18,
        "rowsha": "8M6NKUO2Xu1jKQQEj42nqRrwOk/jVPU25gyW6fsUsSg=",
        "originContent": "  | (Optional)  | [Render video with generated trajectory](https://github.com/fanegg/Feat2GS/blob/b8eadaa54549d34420eba61b388548b8ec8e7325/scripts/run_feat2gs_eval_parallel.sh#L304-L315) |",
        "translatedContent": ""
      },
      {
        "row": 19,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 10,
    "Content": "```bash\n  # Run evaluation for all datasets, all VFM features, all probing modes\n  bash scripts/run_feat2gs_eval_parallel.sh\n\n  # (Example) Run evaluation for a single scene, DINO feature, Geometry mode\n  bash scripts/run_feat2gs_eval.sh\n```",
    "ContentSha": "sDivlyr/+adO2YJPhSeNwqfsEDux20gr7z+03kCeeTk=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\n  # Run evaluation for all datasets, all VFM features, all probing modes\n  bash scripts/run_feat2gs_eval_parallel.sh\n\n  # (Example) Run evaluation for a single scene, DINO feature, Geometry mode\n  bash scripts/run_feat2gs_eval.sh\n```",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "rTMjNc+qNIxb1xXDR5hEYiJw1fc4muBwuBsTXVIaIho=",
        "originContent": "```bash",
        "translatedContent": "```bash"
      },
      {
        "row": 2,
        "rowsha": "kWMulYIzkqaPC3Q8+D8w5jY0jo61xZkOrxnPxl0pS+Q=",
        "originContent": "  # Run evaluation for all datasets, all VFM features, all probing modes",
        "translatedContent": "  # Run evaluation for all datasets, all VFM features, all probing modes"
      },
      {
        "row": 3,
        "rowsha": "zcupHEvjq3Xeb/bqEdc8lkSX6nsqDaYmdJC/DqAPJVE=",
        "originContent": "  bash scripts/run_feat2gs_eval_parallel.sh",
        "translatedContent": "  bash scripts/run_feat2gs_eval_parallel.sh"
      },
      {
        "row": 4,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 5,
        "rowsha": "E54ocO3goN2/aHKIptcUa74dW2zEgUGkSFv6AV5wzAU=",
        "originContent": "  # (Example) Run evaluation for a single scene, DINO feature, Geometry mode",
        "translatedContent": "  # (Example) Run evaluation for a single scene, DINO feature, Geometry mode"
      },
      {
        "row": 6,
        "rowsha": "uPCoM4eS1/0ZEcPTzEyg1GSeq7TGp3L6MbrYdXEyQfs=",
        "originContent": "  bash scripts/run_feat2gs_eval.sh",
        "translatedContent": "  bash scripts/run_feat2gs_eval.sh"
      },
      {
        "row": 7,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      }
    ],
    "IsCodeBlock": true
  },
  {
    "Id": 11,
    "Content": "> [!NOTE]\n> To run experiments in parallel, we added a **GPU lock** feature to ensure only one evaluation experiment runs per GPU. Once an experiment finishes, the GPU is automatically unlocked. **If interrupted by `Ctrl+C`, the GPU won’t be unlocked automatically.** To fix this, manually delete the `.lock` files in your `LOCK_DIR`. To disable this feature, comment out these lines in the script:\n    [L4-L5](https://github.com/fanegg/Feat2GS/blob/b8eadaa54549d34420eba61b388548b8ec8e7325/scripts/run_feat2gs_eval_parallel.sh#L4-L5),\n    [L9-L22](https://github.com/fanegg/Feat2GS/blob/b8eadaa54549d34420eba61b388548b8ec8e7325/scripts/run_feat2gs_eval_parallel.sh#L9-L22),\n    [L223-L233](https://github.com/fanegg/Feat2GS/blob/b8eadaa54549d34420eba61b388548b8ec8e7325/scripts/run_feat2gs_eval_parallel.sh#L223-L233),\n    [L330-L331](https://github.com/fanegg/Feat2GS/blob/b8eadaa54549d34420eba61b388548b8ec8e7325/scripts/run_feat2gs_eval_parallel.sh#L330-L331).\n\n  | Config | Operation |\n  |--------|-----------------|\n  | GPU | Edit in [`<AVAILABLE_GPUS>`](https://github.com/fanegg/Feat2GS/blob/b8eadaa54549d34420eba61b388548b8ec8e7325/scripts/run_feat2gs_eval_parallel.sh#L7) |\n  | Dataset | Edit in [`<SCENES[$Dataset]>`](https://github.com/fanegg/Feat2GS/blob/b8eadaa54549d34420eba61b388548b8ec8e7325/scripts/run_feat2gs_eval_parallel.sh#L105-L111) |\n  | Scene | Edit in [`<SCENES_$Dataset>`](https://github.com/fanegg/Feat2GS/blob/b8eadaa54549d34420eba61b388548b8ec8e7325/scripts/run_feat2gs_eval_parallel.sh#L31-L99) |\n  | Visual Foundation Model | Edit in [`<FEATURES>`](https://github.com/fanegg/Feat2GS/blob/b8eadaa54549d34420eba61b388548b8ec8e7325/scripts/run_feat2gs_eval_parallel.sh#L120-L162) |\n  | Probing Mode | Edit in [`<MODELS>`](https://github.com/fanegg/Feat2GS/blob/b8eadaa54549d34420eba61b388548b8ec8e7325/scripts/run_feat2gs_eval_parallel.sh#L181-L188) |\n  | Inference-only Mode | Comment out STEP (3)(4)(5) in [`execute_command`](https://github.com/fanegg/Feat2GS/blob/main/scripts/run_feat2gs_eval_parallel.sh#L325-L327) |\n",
    "ContentSha": "CxEKrKUkjBaGZ2KPGpeIHqs4nJaP3/kbISxKmrwJBRI=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "> [!NOTE]\n> 병렬로 실험을 실행하기 위해, GPU당 하나의 평가 실험만 실행되도록 **GPU 잠금(lock)** 기능을 추가했습니다. 실험이 완료되면 GPU는 자동으로 잠금 해제됩니다. **`Ctrl+C`로 중단할 경우 GPU가 자동으로 잠금 해제되지 않습니다.** 이 문제를 해결하려면 `LOCK_DIR`에 있는 `.lock` 파일을 수동으로 삭제하세요. 이 기능을 비활성화하려면 스크립트에서 다음 줄들을 주석 처리하세요:\n    [L4-L5](https://github.com/fanegg/Feat2GS/blob/b8eadaa54549d34420eba61b388548b8ec8e7325/scripts/run_feat2gs_eval_parallel.sh#L4-L5),\n    [L9-L22](https://github.com/fanegg/Feat2GS/blob/b8eadaa54549d34420eba61b388548b8ec8e7325/scripts/run_feat2gs_eval_parallel.sh#L9-L22),\n    [L223-L233](https://github.com/fanegg/Feat2GS/blob/b8eadaa54549d34420eba61b388548b8ec8e7325/scripts/run_feat2gs_eval_parallel.sh#L223-L233),\n    [L330-L331](https://github.com/fanegg/Feat2GS/blob/b8eadaa54549d34420eba61b388548b8ec8e7325/scripts/run_feat2gs_eval_parallel.sh#L330-L331).\n\n  | 구성 | 작업 내용 |\n  |--------|-----------------|\n  | GPU | [`<AVAILABLE_GPUS>`](https://github.com/fanegg/Feat2GS/blob/b8eadaa54549d34420eba61b388548b8ec8e7325/scripts/run_feat2gs_eval_parallel.sh#L7)에서 편집 |\n  | 데이터셋 | [`<SCENES[$Dataset]>`](https://github.com/fanegg/Feat2GS/blob/b8eadaa54549d34420eba61b388548b8ec8e7325/scripts/run_feat2gs_eval_parallel.sh#L105-L111)에서 편집 |\n  | 씬 | [`<SCENES_$Dataset>`](https://github.com/fanegg/Feat2GS/blob/b8eadaa54549d34420eba61b388548b8ec8e7325/scripts/run_feat2gs_eval_parallel.sh#L31-L99)에서 편집 |\n  | 비주얼 파운데이션 모델 | [`<FEATURES>`](https://github.com/fanegg/Feat2GS/blob/b8eadaa54549d34420eba61b388548b8ec8e7325/scripts/run_feat2gs_eval_parallel.sh#L120-L162)에서 편집 |\n  | 프로빙 모드 | [`<MODELS>`](https://github.com/fanegg/Feat2GS/blob/b8eadaa54549d34420eba61b388548b8ec8e7325/scripts/run_feat2gs_eval_parallel.sh#L181-L188)에서 편집 |\n  | 추론 전용 모드 | [`execute_command`](https://github.com/fanegg/Feat2GS/blob/main/scripts/run_feat2gs_eval_parallel.sh#L325-L327)의 STEP (3)(4)(5)를 주석 처리 |\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "f7t9zCxxpXM+gn2wD3Ca/9QN2c+xK2M4aKM0xiXBqeU=",
        "originContent": "> [!NOTE]",
        "translatedContent": "> [!NOTE]"
      },
      {
        "row": 2,
        "rowsha": "FZJyCt4gj3TFJ4YNJS/psUKxDjYQteJZ2PDVZParbyw=",
        "originContent": "> To run experiments in parallel, we added a **GPU lock** feature to ensure only one evaluation experiment runs per GPU. Once an experiment finishes, the GPU is automatically unlocked. **If interrupted by `Ctrl+C`, the GPU won’t be unlocked automatically.** To fix this, manually delete the `.lock` files in your `LOCK_DIR`. To disable this feature, comment out these lines in the script:",
        "translatedContent": "> 병렬로 실험을 실행하기 위해, GPU당 하나의 평가 실험만 실행되도록 **GPU 잠금(lock)** 기능을 추가했습니다. 실험이 완료되면 GPU는 자동으로 잠금 해제됩니다. **`Ctrl+C`로 중단할 경우 GPU가 자동으로 잠금 해제되지 않습니다.** 이 문제를 해결하려면 `LOCK_DIR`에 있는 `.lock` 파일을 수동으로 삭제하세요. 이 기능을 비활성화하려면 스크립트에서 다음 줄들을 주석 처리하세요:"
      },
      {
        "row": 3,
        "rowsha": "QKQhMNYkOrgJ4AHswLhKKWLm7QaSgJZ/fEleqaxnjms=",
        "originContent": "    [L4-L5](https://github.com/fanegg/Feat2GS/blob/b8eadaa54549d34420eba61b388548b8ec8e7325/scripts/run_feat2gs_eval_parallel.sh#L4-L5),",
        "translatedContent": "    [L4-L5](https://github.com/fanegg/Feat2GS/blob/b8eadaa54549d34420eba61b388548b8ec8e7325/scripts/run_feat2gs_eval_parallel.sh#L4-L5),"
      },
      {
        "row": 4,
        "rowsha": "wEB8dSqt5T52fuMLsHYj9j+X2mLw7zwz9G/PM1znDWc=",
        "originContent": "    [L9-L22](https://github.com/fanegg/Feat2GS/blob/b8eadaa54549d34420eba61b388548b8ec8e7325/scripts/run_feat2gs_eval_parallel.sh#L9-L22),",
        "translatedContent": "    [L9-L22](https://github.com/fanegg/Feat2GS/blob/b8eadaa54549d34420eba61b388548b8ec8e7325/scripts/run_feat2gs_eval_parallel.sh#L9-L22),"
      },
      {
        "row": 5,
        "rowsha": "cOp0v5zFql4e5e7AClclwc2saS/H8qxYtmKnYgKCGiE=",
        "originContent": "    [L223-L233](https://github.com/fanegg/Feat2GS/blob/b8eadaa54549d34420eba61b388548b8ec8e7325/scripts/run_feat2gs_eval_parallel.sh#L223-L233),",
        "translatedContent": "    [L223-L233](https://github.com/fanegg/Feat2GS/blob/b8eadaa54549d34420eba61b388548b8ec8e7325/scripts/run_feat2gs_eval_parallel.sh#L223-L233),"
      },
      {
        "row": 6,
        "rowsha": "xu7kdjbMlLihyAyaUFoaIkfBO+r3ihdJ2iATvXjQcIo=",
        "originContent": "    [L330-L331](https://github.com/fanegg/Feat2GS/blob/b8eadaa54549d34420eba61b388548b8ec8e7325/scripts/run_feat2gs_eval_parallel.sh#L330-L331).",
        "translatedContent": "    [L330-L331](https://github.com/fanegg/Feat2GS/blob/b8eadaa54549d34420eba61b388548b8ec8e7325/scripts/run_feat2gs_eval_parallel.sh#L330-L331)."
      },
      {
        "row": 7,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 8,
        "rowsha": "/YQstdFWgI6LMeoMK3py40l66Xx6vn+/Nfsnzcfc4Uc=",
        "originContent": "  | Config | Operation |",
        "translatedContent": "  | 구성 | 작업 내용 |"
      },
      {
        "row": 9,
        "rowsha": "MIzUMgv8IxkOxBd43tDxKOmC5yuryzBfWu5zgkMVQRc=",
        "originContent": "  |--------|-----------------|",
        "translatedContent": "  |--------|-----------------|"
      },
      {
        "row": 10,
        "rowsha": "uzlw309N3OihOt+rRP6osG1YF3R7Cq2OMzcRLi9lFV8=",
        "originContent": "  | GPU | Edit in [`<AVAILABLE_GPUS>`](https://github.com/fanegg/Feat2GS/blob/b8eadaa54549d34420eba61b388548b8ec8e7325/scripts/run_feat2gs_eval_parallel.sh#L7) |",
        "translatedContent": "  | GPU | [`<AVAILABLE_GPUS>`](https://github.com/fanegg/Feat2GS/blob/b8eadaa54549d34420eba61b388548b8ec8e7325/scripts/run_feat2gs_eval_parallel.sh#L7)에서 편집 |"
      },
      {
        "row": 11,
        "rowsha": "ZHhiZh1+507LQ+pcrmMmZA34n9vihjwAdZKZNp/FWeA=",
        "originContent": "  | Dataset | Edit in [`<SCENES[$Dataset]>`](https://github.com/fanegg/Feat2GS/blob/b8eadaa54549d34420eba61b388548b8ec8e7325/scripts/run_feat2gs_eval_parallel.sh#L105-L111) |",
        "translatedContent": "  | 데이터셋 | [`<SCENES[$Dataset]>`](https://github.com/fanegg/Feat2GS/blob/b8eadaa54549d34420eba61b388548b8ec8e7325/scripts/run_feat2gs_eval_parallel.sh#L105-L111)에서 편집 |"
      },
      {
        "row": 12,
        "rowsha": "6l33+7qixCMeCzJBfN8KSUqSERb4Y1FqGrVFYiH22E0=",
        "originContent": "  | Scene | Edit in [`<SCENES_$Dataset>`](https://github.com/fanegg/Feat2GS/blob/b8eadaa54549d34420eba61b388548b8ec8e7325/scripts/run_feat2gs_eval_parallel.sh#L31-L99) |",
        "translatedContent": "  | 씬 | [`<SCENES_$Dataset>`](https://github.com/fanegg/Feat2GS/blob/b8eadaa54549d34420eba61b388548b8ec8e7325/scripts/run_feat2gs_eval_parallel.sh#L31-L99)에서 편집 |"
      },
      {
        "row": 13,
        "rowsha": "xWUKFAymxiCFhxTxoHWBQXsxblf8VFFJu0HOtcmPcbw=",
        "originContent": "  | Visual Foundation Model | Edit in [`<FEATURES>`](https://github.com/fanegg/Feat2GS/blob/b8eadaa54549d34420eba61b388548b8ec8e7325/scripts/run_feat2gs_eval_parallel.sh#L120-L162) |",
        "translatedContent": "  | 비주얼 파운데이션 모델 | [`<FEATURES>`](https://github.com/fanegg/Feat2GS/blob/b8eadaa54549d34420eba61b388548b8ec8e7325/scripts/run_feat2gs_eval_parallel.sh#L120-L162)에서 편집 |"
      },
      {
        "row": 14,
        "rowsha": "Cy9bb2B6FNaLoBlBZ9bdINtVkVFyilG6y/wtx9dFTgc=",
        "originContent": "  | Probing Mode | Edit in [`<MODELS>`](https://github.com/fanegg/Feat2GS/blob/b8eadaa54549d34420eba61b388548b8ec8e7325/scripts/run_feat2gs_eval_parallel.sh#L181-L188) |",
        "translatedContent": "  | 프로빙 모드 | [`<MODELS>`](https://github.com/fanegg/Feat2GS/blob/b8eadaa54549d34420eba61b388548b8ec8e7325/scripts/run_feat2gs_eval_parallel.sh#L181-L188)에서 편집 |"
      },
      {
        "row": 15,
        "rowsha": "yg6TkYVBfJ8yhP0xiQgfefqhN5CaPxcGXJiG8dFF5Oo=",
        "originContent": "  | Inference-only Mode | Comment out STEP (3)(4)(5) in [`execute_command`](https://github.com/fanegg/Feat2GS/blob/main/scripts/run_feat2gs_eval_parallel.sh#L325-L327) |",
        "translatedContent": "  | 추론 전용 모드 | [`execute_command`](https://github.com/fanegg/Feat2GS/blob/main/scripts/run_feat2gs_eval_parallel.sh#L325-L327)의 STEP (3)(4)(5)를 주석 처리 |"
      },
      {
        "row": 16,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 12,
    "Content": "```bash\n  # Evaluate Visual Foundation Models on DTU dataset\n  bash scripts/run_feat2gs_eval_dtu_parallel.sh\n\n  # Run InstantSplat for evaluation\n  bash scripts/run_instantsplat_eval_parallel.sh\n```",
    "ContentSha": "IEX4MkQVsDg8upetUP+rHfxtl7v4un+CzrJCf/fJpRA=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\n  # Evaluate Visual Foundation Models on DTU dataset\n  bash scripts/run_feat2gs_eval_dtu_parallel.sh\n\n  # Run InstantSplat for evaluation\n  bash scripts/run_instantsplat_eval_parallel.sh\n```",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "rTMjNc+qNIxb1xXDR5hEYiJw1fc4muBwuBsTXVIaIho=",
        "originContent": "```bash",
        "translatedContent": "```bash"
      },
      {
        "row": 2,
        "rowsha": "bbLlo6rqu9WXzUfrsx4Z8lZWTXNMRH8cEIH6M3Cd9jg=",
        "originContent": "  # Evaluate Visual Foundation Models on DTU dataset",
        "translatedContent": "  # Evaluate Visual Foundation Models on DTU dataset"
      },
      {
        "row": 3,
        "rowsha": "TeeNu9WEO+mgumCOE48uIPkq4EcGmHnFoUaWlr2VqMk=",
        "originContent": "  bash scripts/run_feat2gs_eval_dtu_parallel.sh",
        "translatedContent": "  bash scripts/run_feat2gs_eval_dtu_parallel.sh"
      },
      {
        "row": 4,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 5,
        "rowsha": "X0UJsYOzLzB2+I6WaKaMkpZoch6NVPjvQvST2yVS5i0=",
        "originContent": "  # Run InstantSplat for evaluation",
        "translatedContent": "  # Run InstantSplat for evaluation"
      },
      {
        "row": 6,
        "rowsha": "ipIOXrOrTF4tSQcjCo6hgAYINY2tp+TNugR4qbT+gP0=",
        "originContent": "  bash scripts/run_instantsplat_eval_parallel.sh",
        "translatedContent": "  bash scripts/run_instantsplat_eval_parallel.sh"
      },
      {
        "row": 7,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      }
    ],
    "IsCodeBlock": true
  },
  {
    "Id": 13,
    "Content": "\n\n3. After training, render RGB/depth/normal video with generated trajectory.",
    "ContentSha": "hXSGjfWq9lemgmRyJuGSzI7OF0VDDEmlQrMZ/rWqLOc=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "3. 학습 후, 생성된 경로를 사용하여 RGB/깊이/노멀 비디오를 렌더링합니다.\n\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "3. 학습 후, 생성된 경로를 사용하여 RGB/깊이/노멀 비디오를 렌더링합니다."
      },
      {
        "row": 2,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 3,
        "rowsha": "ySrFHbcmLJIXXWEpajlJbxuCv0WJBPbrnP5s5Q0KDG0=",
        "originContent": "3. After training, render RGB/depth/normal video with generated trajectory.",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 14,
    "Content": "```bash\n  # If render depth/normal, set RENDER_DEPTH_NORMAL=true\n  # Set type of generated trjectory by editing <TRAJ_SCENES>\n  bash scripts/run_video_render.sh\n\n  # Render video on DTU dataset\n  bash scripts/run_video_render_dtu.sh\n```",
    "ContentSha": "uIyIpKw70RPy3iVRcTWRJ4hZMSHSUhLq4+kca3d3/EE=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\n  # If render depth/normal, set RENDER_DEPTH_NORMAL=true\n  # Set type of generated trjectory by editing <TRAJ_SCENES>\n  bash scripts/run_video_render.sh\n\n  # Render video on DTU dataset\n  bash scripts/run_video_render_dtu.sh\n```",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "rTMjNc+qNIxb1xXDR5hEYiJw1fc4muBwuBsTXVIaIho=",
        "originContent": "```bash",
        "translatedContent": "```bash"
      },
      {
        "row": 2,
        "rowsha": "9mS2+XIZm+LcfJ597gkaoSMSdxP3JXnsQLLY04DMgok=",
        "originContent": "  # If render depth/normal, set RENDER_DEPTH_NORMAL=true",
        "translatedContent": "  # If render depth/normal, set RENDER_DEPTH_NORMAL=true"
      },
      {
        "row": 3,
        "rowsha": "8INz67rvvJUnwcOSiPo7MA2K1fab5OJcQPNJvdU2f4U=",
        "originContent": "  # Set type of generated trjectory by editing <TRAJ_SCENES>",
        "translatedContent": "  # Set type of generated trjectory by editing <TRAJ_SCENES>"
      },
      {
        "row": 4,
        "rowsha": "A4V1WkhFHXMYgM2cdJexsBgUaHO88TO4Y9jESkTx7pM=",
        "originContent": "  bash scripts/run_video_render.sh",
        "translatedContent": "  bash scripts/run_video_render.sh"
      },
      {
        "row": 5,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 6,
        "rowsha": "2DuCw1f1cHYcyGIMjZaQKZK5LEbE/UhJFg4ga+N0lCA=",
        "originContent": "  # Render video on DTU dataset",
        "translatedContent": "  # Render video on DTU dataset"
      },
      {
        "row": 7,
        "rowsha": "pFOr+xP2X4W1coV3qZOUQECMKaziE7S5FtkQZETAJOQ=",
        "originContent": "  bash scripts/run_video_render_dtu.sh",
        "translatedContent": "  bash scripts/run_video_render_dtu.sh"
      },
      {
        "row": 8,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      }
    ],
    "IsCodeBlock": true
  },
  {
    "Id": 15,
    "Content": "### 🎮 Interactive demo\n\n#### 🚀 Quickstart\n1. **Input Images**\n* Upload 2 or more images of the same scene from different views\n* For best results, ensure images have good overlap\n\n2. **Step 1: DUSt3R Initialization & Feature Extraction**\n* Click \"RUN Step 1\" to process your images\n* This step estimates initial DUSt3R point cloud and camera poses, and extracts DUSt3R features for each pixel\n\n3. **Step 2: Readout 3DGS from Features**\n* Set the number of training iterations, larger number leads to better quality but longer time (default: 2000, max: 8000) \n* Click \"RUN Step 2\" to optimize the 3D model\n\n4. **Step 3: Video Rendering**\n* Choose a camera trajectory\n* Click \"RUN Step 3\" to generate a video of your 3D model\n  ",
    "ContentSha": "MxER4jo6BleGdE+MeQhdCsKp41vJ7K3feK7jIR4TLrw=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "### 🎮 인터랙티브 데모\n\n#### 🚀 빠른 시작\n1. **입력 이미지**\n* 동일한 장면의 서로 다른 시점에서 촬영한 2장 이상의 이미지를 업로드하세요\n* 최상의 결과를 위해 이미지 간 겹침이 충분한지 확인하세요\n\n2. **1단계: DUSt3R 초기화 및 특징 추출**\n* \"RUN Step 1\"을 클릭하여 이미지를 처리하세요\n* 이 단계에서는 초기 DUSt3R 포인트 클라우드와 카메라 위치를 추정하고 각 픽셀에 대해 DUSt3R 특징을 추출합니다\n\n3. **2단계: 특징에서 3DGS 읽어오기**\n* 학습 반복 횟수를 설정하세요. 숫자가 클수록 품질은 향상되지만 시간이 더 오래 걸립니다 (기본값: 2000, 최대: 8000)\n* \"RUN Step 2\"를 클릭하여 3D 모델을 최적화하세요\n\n4. **3단계: 비디오 렌더링**\n* 카메라 궤적을 선택하세요\n* \"RUN Step 3\"을 클릭하여 3D 모델의 비디오를 생성하세요\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "nIBwHOeciEZBz236HUWuhICoTP5LgKUJVCcwKka5rAM=",
        "originContent": "### 🎮 Interactive demo",
        "translatedContent": "### 🎮 인터랙티브 데모"
      },
      {
        "row": 2,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 3,
        "rowsha": "xLOl4My32wXhrJhzzy0YDFQQUPiEDDqwVc2bYQqJCK0=",
        "originContent": "#### 🚀 Quickstart",
        "translatedContent": "#### 🚀 빠른 시작"
      },
      {
        "row": 4,
        "rowsha": "JP01ZXw9KTpPRdqX9FpGT3VqMOE8bvoYyiioy0d4GXA=",
        "originContent": "1. **Input Images**",
        "translatedContent": "1. **입력 이미지**"
      },
      {
        "row": 5,
        "rowsha": "YxPZpqDnbkd8gGWXDTkHfD3dkrjwIouLtjeQiZ2XkXg=",
        "originContent": "* Upload 2 or more images of the same scene from different views",
        "translatedContent": "* 동일한 장면의 서로 다른 시점에서 촬영한 2장 이상의 이미지를 업로드하세요"
      },
      {
        "row": 6,
        "rowsha": "QRmO3PZn0Qfgsr8dU1ch1gZpyOM3pqho2zKU9UP8B+A=",
        "originContent": "* For best results, ensure images have good overlap",
        "translatedContent": "* 최상의 결과를 위해 이미지 간 겹침이 충분한지 확인하세요"
      },
      {
        "row": 7,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 8,
        "rowsha": "6qxF6YBRu8GE/hFkuTk0M8bmVDRUg+WXBbxgAlh5Jks=",
        "originContent": "2. **Step 1: DUSt3R Initialization & Feature Extraction**",
        "translatedContent": "2. **1단계: DUSt3R 초기화 및 특징 추출**"
      },
      {
        "row": 9,
        "rowsha": "knG3qms0O6Ri19q7B5+bvKWVJmGfTZVsiq81DFrtdVk=",
        "originContent": "* Click \"RUN Step 1\" to process your images",
        "translatedContent": "* \"RUN Step 1\"을 클릭하여 이미지를 처리하세요"
      },
      {
        "row": 10,
        "rowsha": "kemsDidSJYyA4cJctYDUROav/7+6OaxMnwBVhiCpS30=",
        "originContent": "* This step estimates initial DUSt3R point cloud and camera poses, and extracts DUSt3R features for each pixel",
        "translatedContent": "* 이 단계에서는 초기 DUSt3R 포인트 클라우드와 카메라 위치를 추정하고 각 픽셀에 대해 DUSt3R 특징을 추출합니다"
      },
      {
        "row": 11,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 12,
        "rowsha": "8vGRXPF3rgEgvLuEd2gAArdqFRh49/HHLrTSbGnDyN0=",
        "originContent": "3. **Step 2: Readout 3DGS from Features**",
        "translatedContent": "3. **2단계: 특징에서 3DGS 읽어오기**"
      },
      {
        "row": 13,
        "rowsha": "99BXeZgzBlG6FLZlgQHiqhVo4O6Rgy7PUiO+ILpa92M=",
        "originContent": "* Set the number of training iterations, larger number leads to better quality but longer time (default: 2000, max: 8000) ",
        "translatedContent": "* 학습 반복 횟수를 설정하세요. 숫자가 클수록 품질은 향상되지만 시간이 더 오래 걸립니다 (기본값: 2000, 최대: 8000)"
      },
      {
        "row": 14,
        "rowsha": "zbA4HScZpM1TOMk84FW1GZQSMaNn4qCjNBiZQ7dcbQg=",
        "originContent": "* Click \"RUN Step 2\" to optimize the 3D model",
        "translatedContent": "* \"RUN Step 2\"를 클릭하여 3D 모델을 최적화하세요"
      },
      {
        "row": 15,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 16,
        "rowsha": "sGPY3JujfdoWalPBgqdA7tJRQeW98zeysn4D25yjUsk=",
        "originContent": "4. **Step 3: Video Rendering**",
        "translatedContent": "4. **3단계: 비디오 렌더링**"
      },
      {
        "row": 17,
        "rowsha": "XTQsu3V1+j8+ckCeaOiJL92wE9dOxSz+4H1+T13PDn8=",
        "originContent": "* Choose a camera trajectory",
        "translatedContent": "* 카메라 궤적을 선택하세요"
      },
      {
        "row": 18,
        "rowsha": "xZ8n2wu9wW2EURIU/Hrg3i8Gv6UEBKssx7w8lT/AIh0=",
        "originContent": "* Click \"RUN Step 3\" to generate a video of your 3D model",
        "translatedContent": "* \"RUN Step 3\"을 클릭하여 3D 모델의 비디오를 생성하세요"
      },
      {
        "row": 19,
        "rowsha": "bBefIeb2K2KQVdirQPRU7QLki2hWORNHO4V9NjjiOyg=",
        "originContent": "  ",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 16,
    "Content": "```bash\ngradio demo.py\n```",
    "ContentSha": "blXKBHFnm1c0XKMjbuCZlH6dUZGOdnv2RwhPMPYKw50=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bash\ngradio demo.py\n```",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "rTMjNc+qNIxb1xXDR5hEYiJw1fc4muBwuBsTXVIaIho=",
        "originContent": "```bash",
        "translatedContent": "```bash"
      },
      {
        "row": 2,
        "rowsha": "6TytbG68INcMNvZA7Xt5YIfECZ3n8JvYpKWxLCRotgE=",
        "originContent": "gradio demo.py",
        "translatedContent": "gradio demo.py"
      },
      {
        "row": 3,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      }
    ],
    "IsCodeBlock": true
  },
  {
    "Id": 17,
    "Content": "\n#### 💡 Tips\n* Processing time depends on image resolution and quantity\n* For optimal performance, test on high-end GPUs (A100/4090)\n* Use the mouse to interact with 3D models:\n  - Left button: Rotate\n  - Scroll wheel: Zoom\n  - Right button: Pan\n\n\n## Acknowledgement\n\nThis work is built on many amazing research works and open-source projects, thanks a lot to all the authors for sharing!\n\n- [Gaussian-Splatting](https://github.com/graphdeco-inria/gaussian-splatting) and [diff-gaussian-rasterization](https://github.com/graphdeco-inria/diff-gaussian-rasterization)\n- [gsplat](https://github.com/nerfstudio-project/gsplat)\n- [DUSt3R](https://github.com/naver/dust3r) and [MASt3R](https://github.com/naver/mast3r)\n- [InstantSplat](https://github.com/NVlabs/InstantSplat)\n- [Probe3D](https://github.com/mbanani/probe3d)\n- [FeatUp](https://github.com/mhamilton723/FeatUp)\n- [Shape of Motion](https://github.com/vye16/shape-of-motion/)\n- [Splatt3R](https://github.com/btsmart/splatt3r)\n- [VGGT](https://github.com/facebookresearch/vggt)\n\n## Citation\nIf you find our work useful in your research, please consider giving a star :star: and citing the following paper :pencil:.\n",
    "ContentSha": "OJCt33zvs8pPnb216AgtDuoSryPPlo51ja3oQpoEpOA=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "#### 💡 팁\n* 처리 시간은 이미지 해상도와 수량에 따라 다릅니다.\n* 최적의 성능을 위해 고성능 GPU(A100/4090)에서 테스트하세요.\n* 마우스를 사용하여 3D 모델과 상호작용할 수 있습니다:\n  - 왼쪽 버튼: 회전\n  - 스크롤 휠: 확대/축소\n  - 오른쪽 버튼: 이동\n\n\n## 감사의 글\n\n이 작업은 많은 훌륭한 연구 작업과 오픈 소스 프로젝트를 기반으로 합니다. 공유해주신 모든 저자분들께 진심으로 감사드립니다!\n\n- [Gaussian-Splatting](https://github.com/graphdeco-inria/gaussian-splatting) 및 [diff-gaussian-rasterization](https://github.com/graphdeco-inria/diff-gaussian-rasterization)\n- [gsplat](https://github.com/nerfstudio-project/gsplat)\n- [DUSt3R](https://github.com/naver/dust3r) 및 [MASt3R](https://github.com/naver/mast3r)\n- [InstantSplat](https://github.com/NVlabs/InstantSplat)\n- [Probe3D](https://github.com/mbanani/probe3d)\n- [FeatUp](https://github.com/mhamilton723/FeatUp)\n- [Shape of Motion](https://github.com/vye16/shape-of-motion/)\n- [Splatt3R](https://github.com/btsmart/splatt3r)\n- [VGGT](https://github.com/facebookresearch/vggt)\n\n## 인용\n본 연구가 여러분의 연구에 도움이 되었다면, 별 :star: 을 눌러주시고 다음 논문 :pencil: 을 인용해 주시기 바랍니다.\n\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "#### 💡 팁"
      },
      {
        "row": 2,
        "rowsha": "qPTFpv2Ej1UUrDsRJVxzjYdg+oB6eQZYVXxQQ9rQWdQ=",
        "originContent": "#### 💡 Tips",
        "translatedContent": "* 처리 시간은 이미지 해상도와 수량에 따라 다릅니다."
      },
      {
        "row": 3,
        "rowsha": "APnxQGdm0dLmnjgHT8eg+bG5tEVbRnSGWDnu0UC0xmU=",
        "originContent": "* Processing time depends on image resolution and quantity",
        "translatedContent": "* 최적의 성능을 위해 고성능 GPU(A100/4090)에서 테스트하세요."
      },
      {
        "row": 4,
        "rowsha": "VWnMicTJwTsA5hzwWOxORGa35CQEiF/9bmziYLnEdVU=",
        "originContent": "* For optimal performance, test on high-end GPUs (A100/4090)",
        "translatedContent": "* 마우스를 사용하여 3D 모델과 상호작용할 수 있습니다:"
      },
      {
        "row": 5,
        "rowsha": "gVHEcHzl8ePIrZod3Gx0HQoY13CVjiSqkQ8gzt6F+ok=",
        "originContent": "* Use the mouse to interact with 3D models:",
        "translatedContent": "  - 왼쪽 버튼: 회전"
      },
      {
        "row": 6,
        "rowsha": "4QtY9vjf07geLtxb3s+DdVicYD8uGxTQ4J0rB46GJ2M=",
        "originContent": "  - Left button: Rotate",
        "translatedContent": "  - 스크롤 휠: 확대/축소"
      },
      {
        "row": 7,
        "rowsha": "CN7/8ol8MepUznhwZtQ1ab58xOk9XNrtwrAcamiU4LI=",
        "originContent": "  - Scroll wheel: Zoom",
        "translatedContent": "  - 오른쪽 버튼: 이동"
      },
      {
        "row": 8,
        "rowsha": "8ynhxe1ToO9ZzKZmy7r05syP+Y7q6HRnD0zFKKP4QqY=",
        "originContent": "  - Right button: Pan",
        "translatedContent": ""
      },
      {
        "row": 9,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 10,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "## 감사의 글"
      },
      {
        "row": 11,
        "rowsha": "zeUL2mcUYd628fTHqknKcxv2uqjN5wj1hlMFcVnzrpU=",
        "originContent": "## Acknowledgement",
        "translatedContent": ""
      },
      {
        "row": 12,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "이 작업은 많은 훌륭한 연구 작업과 오픈 소스 프로젝트를 기반으로 합니다. 공유해주신 모든 저자분들께 진심으로 감사드립니다!"
      },
      {
        "row": 13,
        "rowsha": "hvk/5yyMYlM/E0WEue2tv08cxUQuAa6CST9/NYKChlI=",
        "originContent": "This work is built on many amazing research works and open-source projects, thanks a lot to all the authors for sharing!",
        "translatedContent": ""
      },
      {
        "row": 14,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "- [Gaussian-Splatting](https://github.com/graphdeco-inria/gaussian-splatting) 및 [diff-gaussian-rasterization](https://github.com/graphdeco-inria/diff-gaussian-rasterization)"
      },
      {
        "row": 15,
        "rowsha": "g8yt/SYfDCc0Mn1n4iUEHUxCyTmQH0KYkAxxBaJcxdM=",
        "originContent": "- [Gaussian-Splatting](https://github.com/graphdeco-inria/gaussian-splatting) and [diff-gaussian-rasterization](https://github.com/graphdeco-inria/diff-gaussian-rasterization)",
        "translatedContent": "- [gsplat](https://github.com/nerfstudio-project/gsplat)"
      },
      {
        "row": 16,
        "rowsha": "bN7hWTzmVv9pfKLy5H4Ket455ftRh6Nteew6lKqcuAc=",
        "originContent": "- [gsplat](https://github.com/nerfstudio-project/gsplat)",
        "translatedContent": "- [DUSt3R](https://github.com/naver/dust3r) 및 [MASt3R](https://github.com/naver/mast3r)"
      },
      {
        "row": 17,
        "rowsha": "65e1wnFCDMiDU0IugLt2jbLRDugvZkpdxQI6EZm8xoI=",
        "originContent": "- [DUSt3R](https://github.com/naver/dust3r) and [MASt3R](https://github.com/naver/mast3r)",
        "translatedContent": "- [InstantSplat](https://github.com/NVlabs/InstantSplat)"
      },
      {
        "row": 18,
        "rowsha": "ltPMmMJ25kIPez7dyspt6EctRtfZ4S6qCKg4xU2tY4Y=",
        "originContent": "- [InstantSplat](https://github.com/NVlabs/InstantSplat)",
        "translatedContent": "- [Probe3D](https://github.com/mbanani/probe3d)"
      },
      {
        "row": 19,
        "rowsha": "5DgdpRGpDJ4vlQqOd+zEzGMla2wo4WcdsXMeUXk8Kyw=",
        "originContent": "- [Probe3D](https://github.com/mbanani/probe3d)",
        "translatedContent": "- [FeatUp](https://github.com/mhamilton723/FeatUp)"
      },
      {
        "row": 20,
        "rowsha": "Woj3wcoZyYIjMFzLLml+Rv/S//x+sPX1qAf6p3eV1gA=",
        "originContent": "- [FeatUp](https://github.com/mhamilton723/FeatUp)",
        "translatedContent": "- [Shape of Motion](https://github.com/vye16/shape-of-motion/)"
      },
      {
        "row": 21,
        "rowsha": "KqVu/8ZQRDoqHfXki1GaGFIK8TnoBDvw1/QnNvKIPLA=",
        "originContent": "- [Shape of Motion](https://github.com/vye16/shape-of-motion/)",
        "translatedContent": "- [Splatt3R](https://github.com/btsmart/splatt3r)"
      },
      {
        "row": 22,
        "rowsha": "7ECFxxzjecB93PHMcVVH6AlVLneKx+7hOMWM7Z/NI6k=",
        "originContent": "- [Splatt3R](https://github.com/btsmart/splatt3r)",
        "translatedContent": "- [VGGT](https://github.com/facebookresearch/vggt)"
      },
      {
        "row": 23,
        "rowsha": "XqeQabuTI3t4n4Uu5Em99XpTBj1JimWMKr/REJT4T5g=",
        "originContent": "- [VGGT](https://github.com/facebookresearch/vggt)",
        "translatedContent": ""
      },
      {
        "row": 24,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": "## 인용"
      },
      {
        "row": 25,
        "rowsha": "ZwTp5ajUmpHTJefyHhIKzXcG2wnB1jv8iv8cvmdcb/g=",
        "originContent": "## Citation",
        "translatedContent": "본 연구가 여러분의 연구에 도움이 되었다면, 별 :star: 을 눌러주시고 다음 논문 :pencil: 을 인용해 주시기 바랍니다."
      },
      {
        "row": 26,
        "rowsha": "MtqKMhnZ++8qD6WxpyjcL8f/zvsBG+ewNAZu2GGCnfw=",
        "originContent": "If you find our work useful in your research, please consider giving a star :star: and citing the following paper :pencil:.",
        "translatedContent": ""
      },
      {
        "row": 27,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  },
  {
    "Id": 18,
    "Content": "```bibTeX\n@inproceedings{chen2025feat2gs,\n  title={Feat2gs: Probing visual foundation models with gaussian splatting},\n  author={Chen, Yue and Chen, Xingyu and Chen, Anpei and Pons-Moll, Gerard and Xiu, Yuliang},\n  booktitle={Proceedings of the Computer Vision and Pattern Recognition Conference},\n  pages={6348--6361},\n  year={2025}\n}\n```",
    "ContentSha": "WXZTfiyEJ74F6Q0/tVt3Bu99bS0JOAtE9p1HUXb8SF8=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "```bibTeX\n@inproceedings{chen2025feat2gs,\n  title={Feat2gs: Probing visual foundation models with gaussian splatting},\n  author={Chen, Yue and Chen, Xingyu and Chen, Anpei and Pons-Moll, Gerard and Xiu, Yuliang},\n  booktitle={Proceedings of the Computer Vision and Pattern Recognition Conference},\n  pages={6348--6361},\n  year={2025}\n}\n```",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "c2hAOAD620O/aTLSGxA8dyKC15a5A4RC8h2Ib1VXhQk=",
        "originContent": "```bibTeX",
        "translatedContent": "```bibTeX"
      },
      {
        "row": 2,
        "rowsha": "OrLXa+EAIhJOmZTrsV2I0XiHlG7BnRI0GRWfUmgfJs8=",
        "originContent": "@inproceedings{chen2025feat2gs,",
        "translatedContent": "@inproceedings{chen2025feat2gs,"
      },
      {
        "row": 3,
        "rowsha": "qYbPlQHdCfh6AK/ctNri2U1E8FakYUxIJ974WS4xeO4=",
        "originContent": "  title={Feat2gs: Probing visual foundation models with gaussian splatting},",
        "translatedContent": "  title={Feat2gs: Probing visual foundation models with gaussian splatting},"
      },
      {
        "row": 4,
        "rowsha": "ZlH7KeIQ37q7JFzVpWwusF6iGLFhxlz8UW4/hPK8dDA=",
        "originContent": "  author={Chen, Yue and Chen, Xingyu and Chen, Anpei and Pons-Moll, Gerard and Xiu, Yuliang},",
        "translatedContent": "  author={Chen, Yue and Chen, Xingyu and Chen, Anpei and Pons-Moll, Gerard and Xiu, Yuliang},"
      },
      {
        "row": 5,
        "rowsha": "Tdu4fB+gVh/DbAO0LazGnLUP/1XmCsy7zHrXOdVvSPs=",
        "originContent": "  booktitle={Proceedings of the Computer Vision and Pattern Recognition Conference},",
        "translatedContent": "  booktitle={Proceedings of the Computer Vision and Pattern Recognition Conference},"
      },
      {
        "row": 6,
        "rowsha": "3OEv9jKjyg2Q0KN8+RSub+OOCnyfUdbMV0s2sfajYgI=",
        "originContent": "  pages={6348--6361},",
        "translatedContent": "  pages={6348--6361},"
      },
      {
        "row": 7,
        "rowsha": "6oyqJVJ20XoZhlyGjaewQyTQsSBBtVAYmqUtTwjLbAg=",
        "originContent": "  year={2025}",
        "translatedContent": "  year={2025}"
      },
      {
        "row": 8,
        "rowsha": "0Qs2qnSlm89KiBhYN/ZYr682Ru/yuxbDko0OkzXpRdI=",
        "originContent": "}",
        "translatedContent": "}"
      },
      {
        "row": 9,
        "rowsha": "8bkBhHOQsO1+N058HkZOwXtGpCfEh6WtbL0pBkBQg9U=",
        "originContent": "```",
        "translatedContent": "```"
      }
    ],
    "IsCodeBlock": true
  },
  {
    "Id": 19,
    "Content": "\n## Contact\n\nFor feedback, questions, or press inquiries please contact [Yue Chen](https://raw.githubusercontent.com/fanegg/Feat2GS/main/mailto:faneggchen@gmail.com) and [Xingyu Chen](https://raw.githubusercontent.com/fanegg/Feat2GS/main/mailto:roverxingyu@gmail.com).\n",
    "ContentSha": "DpIHjl/2sl7HYoESSbMoLpw355oHoq8SfRYlaEqVU0k=",
    "SectionType": "",
    "StartLine": 0,
    "EndLine": 0,
    "Translation": "\n## 연락처\n\n피드백, 질문 또는 언론 문의는 [Yue Chen](https://raw.githubusercontent.com/fanegg/Feat2GS/main/mailto:faneggchen@gmail.com) 및 [Xingyu Chen](https://raw.githubusercontent.com/fanegg/Feat2GS/main/mailto:roverxingyu@gmail.com)에게 연락해 주세요.\n",
    "Status": "ok",
    "RowTranslations": [
      {
        "row": 1,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 2,
        "rowsha": "ZX9nbduzXgvmAaK8yTd+tNgwR7cV79HXV/+xbvL8suw=",
        "originContent": "## Contact",
        "translatedContent": "## 연락처"
      },
      {
        "row": 3,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      },
      {
        "row": 4,
        "rowsha": "TY+8dkkOOh6b0tc0o3eNhdK9fiBrOq65TwARUJ/OIn8=",
        "originContent": "For feedback, questions, or press inquiries please contact [Yue Chen](https://raw.githubusercontent.com/fanegg/Feat2GS/main/mailto:faneggchen@gmail.com) and [Xingyu Chen](https://raw.githubusercontent.com/fanegg/Feat2GS/main/mailto:roverxingyu@gmail.com).",
        "translatedContent": "피드백, 질문 또는 언론 문의는 [Yue Chen](https://raw.githubusercontent.com/fanegg/Feat2GS/main/mailto:faneggchen@gmail.com) 및 [Xingyu Chen](https://raw.githubusercontent.com/fanegg/Feat2GS/main/mailto:roverxingyu@gmail.com)에게 연락해 주세요."
      },
      {
        "row": 5,
        "rowsha": "47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=",
        "originContent": "",
        "translatedContent": ""
      }
    ],
    "IsCodeBlock": false
  }
]